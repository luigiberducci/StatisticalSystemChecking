Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          (None, 2)                 0         
_________________________________________________________________
dense_1 (Dense)              (None, 16)                48        
_________________________________________________________________
dense_2 (Dense)              (None, 8)                 136       
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 9         
=================================================================
Total params: 193
Trainable params: 193
Non-trainable params: 0
_________________________________________________________________
None
[Info] Start Importance Splitting on succruns-v1.
Training for 10000 steps ...
   10/10000: episode: 1, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   20/10000: episode: 2, duration: 0.005s, episode steps: 10, steps per second: 2036, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: --, mae: --, mean_q: --
   30/10000: episode: 3, duration: 0.005s, episode steps: 10, steps per second: 2011, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   40/10000: episode: 4, duration: 0.005s, episode steps: 10, steps per second: 2059, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   50/10000: episode: 5, duration: 0.005s, episode steps: 10, steps per second: 2051, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   60/10000: episode: 6, duration: 0.005s, episode steps: 10, steps per second: 2069, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   70/10000: episode: 7, duration: 0.005s, episode steps: 10, steps per second: 2173, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   80/10000: episode: 8, duration: 0.005s, episode steps: 10, steps per second: 2096, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   90/10000: episode: 9, duration: 0.005s, episode steps: 10, steps per second: 2142, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  100/10000: episode: 10, duration: 0.005s, episode steps: 10, steps per second: 2147, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  110/10000: episode: 11, duration: 0.004s, episode steps: 10, steps per second: 2234, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  120/10000: episode: 12, duration: 0.004s, episode steps: 10, steps per second: 2232, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  130/10000: episode: 13, duration: 0.004s, episode steps: 10, steps per second: 2231, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  140/10000: episode: 14, duration: 0.005s, episode steps: 10, steps per second: 2203, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  150/10000: episode: 15, duration: 0.005s, episode steps: 10, steps per second: 2092, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  160/10000: episode: 16, duration: 0.004s, episode steps: 10, steps per second: 2345, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  170/10000: episode: 17, duration: 0.004s, episode steps: 10, steps per second: 2279, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  180/10000: episode: 18, duration: 0.004s, episode steps: 10, steps per second: 2235, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  190/10000: episode: 19, duration: 0.005s, episode steps: 10, steps per second: 2212, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  200/10000: episode: 20, duration: 0.005s, episode steps: 10, steps per second: 2221, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  210/10000: episode: 21, duration: 0.005s, episode steps: 10, steps per second: 2082, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  220/10000: episode: 22, duration: 0.005s, episode steps: 10, steps per second: 2193, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  230/10000: episode: 23, duration: 0.005s, episode steps: 10, steps per second: 2175, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  240/10000: episode: 24, duration: 0.005s, episode steps: 10, steps per second: 2212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  250/10000: episode: 25, duration: 0.005s, episode steps: 10, steps per second: 2138, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  260/10000: episode: 26, duration: 0.004s, episode steps: 10, steps per second: 2244, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  270/10000: episode: 27, duration: 0.005s, episode steps: 10, steps per second: 2047, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  280/10000: episode: 28, duration: 0.005s, episode steps: 10, steps per second: 2206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  290/10000: episode: 29, duration: 0.004s, episode steps: 10, steps per second: 2227, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  300/10000: episode: 30, duration: 0.005s, episode steps: 10, steps per second: 2166, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  310/10000: episode: 31, duration: 0.005s, episode steps: 10, steps per second: 2141, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  320/10000: episode: 32, duration: 0.005s, episode steps: 10, steps per second: 2172, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  330/10000: episode: 33, duration: 0.004s, episode steps: 10, steps per second: 2289, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  340/10000: episode: 34, duration: 0.005s, episode steps: 10, steps per second: 2221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  350/10000: episode: 35, duration: 0.005s, episode steps: 10, steps per second: 2174, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  360/10000: episode: 36, duration: 0.005s, episode steps: 10, steps per second: 2129, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  370/10000: episode: 37, duration: 0.005s, episode steps: 10, steps per second: 2146, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  380/10000: episode: 38, duration: 0.005s, episode steps: 10, steps per second: 2205, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  390/10000: episode: 39, duration: 0.004s, episode steps: 10, steps per second: 2281, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  400/10000: episode: 40, duration: 0.004s, episode steps: 10, steps per second: 2257, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  410/10000: episode: 41, duration: 0.005s, episode steps: 10, steps per second: 2219, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  420/10000: episode: 42, duration: 0.005s, episode steps: 10, steps per second: 2214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  430/10000: episode: 43, duration: 0.005s, episode steps: 10, steps per second: 2065, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  440/10000: episode: 44, duration: 0.005s, episode steps: 10, steps per second: 2150, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  450/10000: episode: 45, duration: 0.005s, episode steps: 10, steps per second: 2131, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  460/10000: episode: 46, duration: 0.005s, episode steps: 10, steps per second: 2122, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  470/10000: episode: 47, duration: 0.005s, episode steps: 10, steps per second: 2164, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  480/10000: episode: 48, duration: 0.005s, episode steps: 10, steps per second: 2219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  490/10000: episode: 49, duration: 0.004s, episode steps: 10, steps per second: 2224, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  500/10000: episode: 50, duration: 0.004s, episode steps: 10, steps per second: 2225, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  510/10000: episode: 51, duration: 0.599s, episode steps: 10, steps per second: 17, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.004327, mae: 0.065923, mean_q: -0.045310
[Info] FALSIFICATION!
  520/10000: episode: 52, duration: 0.610s, episode steps: 10, steps per second: 16, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.001887, mae: 0.039373, mean_q: -0.068094
  530/10000: episode: 53, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001463, mae: 0.035457, mean_q: -0.065934
  540/10000: episode: 54, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002465, mae: 0.040908, mean_q: -0.046901
  550/10000: episode: 55, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.003021, mae: 0.038980, mean_q: -0.041109
  560/10000: episode: 56, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001235, mae: 0.032557, mean_q: -0.060422
  570/10000: episode: 57, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001643, mae: 0.034809, mean_q: -0.032946
  580/10000: episode: 58, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001700, mae: 0.031869, mean_q: -0.039668
  590/10000: episode: 59, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000725, mae: 0.027268, mean_q: -0.049360
  600/10000: episode: 60, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000697, mae: 0.025780, mean_q: -0.038488
  610/10000: episode: 61, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001332, mae: 0.025324, mean_q: -0.037530
  620/10000: episode: 62, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000534, mae: 0.022625, mean_q: -0.034333
  630/10000: episode: 63, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001144, mae: 0.021861, mean_q: -0.031482
  640/10000: episode: 64, duration: 0.045s, episode steps: 10, steps per second: 225, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000289, mae: 0.018007, mean_q: -0.036394
  650/10000: episode: 65, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001178, mae: 0.020800, mean_q: -0.027580
  660/10000: episode: 66, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001318, mae: 0.026939, mean_q: -0.016635
  670/10000: episode: 67, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002672, mae: 0.036478, mean_q: -0.004486
  680/10000: episode: 68, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001358, mae: 0.031870, mean_q: -0.009901
  690/10000: episode: 69, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002463, mae: 0.038036, mean_q: -0.012781
  700/10000: episode: 70, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001100, mae: 0.028607, mean_q: -0.025346
  710/10000: episode: 71, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001168, mae: 0.026512, mean_q: -0.007394
  720/10000: episode: 72, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000328, mae: 0.016372, mean_q: -0.012586
  730/10000: episode: 73, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002237, mae: 0.029343, mean_q: -0.003769
  740/10000: episode: 74, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000488, mae: 0.020697, mean_q: -0.008771
  750/10000: episode: 75, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000226, mae: 0.014627, mean_q: -0.014891
  760/10000: episode: 76, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001568, mae: 0.022155, mean_q: 0.001730
  770/10000: episode: 77, duration: 0.044s, episode steps: 10, steps per second: 227, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001024, mae: 0.021010, mean_q: -0.007742
  780/10000: episode: 78, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000893, mae: 0.021136, mean_q: -0.006864
  790/10000: episode: 79, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001794, mae: 0.028106, mean_q: -0.003175
  800/10000: episode: 80, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001321, mae: 0.023333, mean_q: 0.004021
  810/10000: episode: 81, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001314, mae: 0.022014, mean_q: 0.000771
  820/10000: episode: 82, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000486, mae: 0.017514, mean_q: -0.005636
  830/10000: episode: 83, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000485, mae: 0.016311, mean_q: 0.000169
  840/10000: episode: 84, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000984, mae: 0.020577, mean_q: 0.004517
  850/10000: episode: 85, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000812, mae: 0.021036, mean_q: -0.006725
  860/10000: episode: 86, duration: 0.045s, episode steps: 10, steps per second: 225, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001011, mae: 0.020952, mean_q: -0.001276
  870/10000: episode: 87, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000885, mae: 0.021182, mean_q: 0.002145
  880/10000: episode: 88, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000888, mae: 0.018372, mean_q: 0.007678
  890/10000: episode: 89, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000234, mae: 0.012924, mean_q: 0.000019
  900/10000: episode: 90, duration: 0.045s, episode steps: 10, steps per second: 225, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000367, mae: 0.015593, mean_q: -0.001609
  910/10000: episode: 91, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000886, mae: 0.017092, mean_q: 0.012469
  920/10000: episode: 92, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000721, mae: 0.015521, mean_q: 0.007509
  930/10000: episode: 93, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000545, mae: 0.016635, mean_q: 0.007908
  940/10000: episode: 94, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000436, mae: 0.017349, mean_q: -0.002629
  950/10000: episode: 95, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000911, mae: 0.019271, mean_q: 0.002951
  960/10000: episode: 96, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000271, mae: 0.012143, mean_q: 0.004449
  970/10000: episode: 97, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000883, mae: 0.015380, mean_q: 0.007345
  980/10000: episode: 98, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001353, mae: 0.018527, mean_q: 0.012250
  990/10000: episode: 99, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001198, mae: 0.017768, mean_q: 0.010723
 1000/10000: episode: 100, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000525, mae: 0.018311, mean_q: 0.003188
 1010/10000: episode: 101, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000793, mae: 0.015422, mean_q: 0.006430
 1020/10000: episode: 102, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000347, mae: 0.014025, mean_q: 0.005489
 1030/10000: episode: 103, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001418, mae: 0.019777, mean_q: 0.013264
 1040/10000: episode: 104, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000311, mae: 0.012423, mean_q: 0.003702
 1050/10000: episode: 105, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000177, mae: 0.011259, mean_q: 0.005905
 1060/10000: episode: 106, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000957, mae: 0.018799, mean_q: 0.011261
 1070/10000: episode: 107, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000876, mae: 0.017067, mean_q: 0.015086
 1080/10000: episode: 108, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000218, mae: 0.011847, mean_q: 0.004989
 1090/10000: episode: 109, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000973, mae: 0.017933, mean_q: 0.010003
 1100/10000: episode: 110, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001459, mae: 0.021436, mean_q: 0.013624
 1110/10000: episode: 111, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001012, mae: 0.018474, mean_q: 0.010502
 1120/10000: episode: 112, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000900, mae: 0.017878, mean_q: 0.012258
 1130/10000: episode: 113, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000950, mae: 0.019329, mean_q: 0.017691
 1140/10000: episode: 114, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000854, mae: 0.015582, mean_q: 0.014022
 1150/10000: episode: 115, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000812, mae: 0.015858, mean_q: 0.009525
 1160/10000: episode: 116, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000454, mae: 0.014904, mean_q: 0.006807
 1170/10000: episode: 117, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000334, mae: 0.014825, mean_q: 0.008682
 1180/10000: episode: 118, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000129, mae: 0.008589, mean_q: 0.000754
 1190/10000: episode: 119, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000258, mae: 0.010364, mean_q: 0.002075
 1200/10000: episode: 120, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000791, mae: 0.013223, mean_q: 0.011148
 1210/10000: episode: 121, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.001071, mae: 0.017829, mean_q: 0.018609
 1220/10000: episode: 122, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000282, mae: 0.012318, mean_q: 0.009757
 1230/10000: episode: 123, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000348, mae: 0.013237, mean_q: 0.009591
 1240/10000: episode: 124, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000214, mae: 0.012659, mean_q: 0.009070
 1250/10000: episode: 125, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000893, mae: 0.011988, mean_q: 0.011302
 1260/10000: episode: 126, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000256, mae: 0.011827, mean_q: 0.005714
 1270/10000: episode: 127, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000826, mae: 0.015532, mean_q: 0.009808
 1280/10000: episode: 128, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000170, mae: 0.011541, mean_q: 0.008494
 1290/10000: episode: 129, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000247, mae: 0.010528, mean_q: 0.008841
 1300/10000: episode: 130, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000175, mae: 0.008325, mean_q: 0.010536
 1310/10000: episode: 131, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000207, mae: 0.007821, mean_q: 0.010984
 1320/10000: episode: 132, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000173, mae: 0.007975, mean_q: 0.007628
 1330/10000: episode: 133, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000265, mae: 0.008812, mean_q: 0.008798
 1340/10000: episode: 134, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001218, mae: 0.014795, mean_q: 0.012507
 1350/10000: episode: 135, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001077, mae: 0.026154, mean_q: 0.012948
 1360/10000: episode: 136, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000441, mae: 0.013173, mean_q: 0.011962
 1370/10000: episode: 137, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000695, mae: 0.016807, mean_q: 0.012270
 1380/10000: episode: 138, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000416, mae: 0.014815, mean_q: 0.005738
 1390/10000: episode: 139, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000305, mae: 0.013983, mean_q: 0.005074
 1400/10000: episode: 140, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000844, mae: 0.014357, mean_q: 0.010231
 1410/10000: episode: 141, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000728, mae: 0.015248, mean_q: 0.009888
 1420/10000: episode: 142, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000673, mae: 0.019652, mean_q: 0.014256
 1430/10000: episode: 143, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000287, mae: 0.011376, mean_q: 0.011240
 1440/10000: episode: 144, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000147, mae: 0.009063, mean_q: 0.005876
 1450/10000: episode: 145, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000297, mae: 0.014243, mean_q: 0.006109
 1460/10000: episode: 146, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001136, mae: 0.013865, mean_q: 0.014939
 1470/10000: episode: 147, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000289, mae: 0.016375, mean_q: 0.008300
 1480/10000: episode: 148, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000240, mae: 0.010657, mean_q: 0.005931
 1490/10000: episode: 149, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000315, mae: 0.011210, mean_q: 0.007567
[Info] Complete ISplit Iteration
[Info] Levels: [0.5190499]
[Info] Cond. Prob: [0.01]
[Info] Error Prob: 0.01

 1500/10000: episode: 150, duration: 0.975s, episode steps: 10, steps per second: 10, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000848, mae: 0.015238, mean_q: 0.011743
 1510/10000: episode: 151, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000844, mae: 0.015691, mean_q: 0.014738
 1520/10000: episode: 152, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000339, mae: 0.013738, mean_q: 0.010745
 1530/10000: episode: 153, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001436, mae: 0.023959, mean_q: 0.022629
 1540/10000: episode: 154, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000354, mae: 0.013778, mean_q: 0.013329
 1550/10000: episode: 155, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000400, mae: 0.013290, mean_q: 0.010280
 1560/10000: episode: 156, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000375, mae: 0.015197, mean_q: 0.010274
 1570/10000: episode: 157, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000191, mae: 0.010927, mean_q: 0.010404
 1580/10000: episode: 158, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000244, mae: 0.008473, mean_q: 0.009560
 1590/10000: episode: 159, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000234, mae: 0.008787, mean_q: 0.007610
 1600/10000: episode: 160, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000707, mae: 0.009887, mean_q: 0.009814
 1610/10000: episode: 161, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000546, mae: 0.008489, mean_q: 0.007256
 1620/10000: episode: 162, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000301, mae: 0.014248, mean_q: 0.005405
 1630/10000: episode: 163, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000120, mae: 0.009004, mean_q: 0.006273
 1640/10000: episode: 164, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000314, mae: 0.011880, mean_q: 0.013933
 1650/10000: episode: 165, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000287, mae: 0.012220, mean_q: 0.007256
 1660/10000: episode: 166, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000059, mae: 0.007152, mean_q: 0.003834
 1670/10000: episode: 167, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000233, mae: 0.009943, mean_q: 0.009292
 1680/10000: episode: 168, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001186, mae: 0.011371, mean_q: 0.008849
 1690/10000: episode: 169, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000379, mae: 0.019967, mean_q: 0.008980
 1700/10000: episode: 170, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000182, mae: 0.012402, mean_q: 0.004720
 1710/10000: episode: 171, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000289, mae: 0.011963, mean_q: 0.008844
 1720/10000: episode: 172, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000246, mae: 0.009689, mean_q: 0.006504
 1730/10000: episode: 173, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000668, mae: 0.010211, mean_q: 0.011729
 1740/10000: episode: 174, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000246, mae: 0.009964, mean_q: 0.008284
 1750/10000: episode: 175, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000128, mae: 0.008435, mean_q: 0.006800
 1760/10000: episode: 176, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000220, mae: 0.012503, mean_q: 0.007864
 1770/10000: episode: 177, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000221, mae: 0.008201, mean_q: 0.007574
 1780/10000: episode: 178, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000152, mae: 0.007858, mean_q: 0.008987
 1790/10000: episode: 179, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000326, mae: 0.011019, mean_q: 0.007139
 1800/10000: episode: 180, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000831, mae: 0.012017, mean_q: 0.012572
 1810/10000: episode: 181, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000153, mae: 0.008436, mean_q: 0.005631
 1820/10000: episode: 182, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000274, mae: 0.012182, mean_q: 0.007156
 1830/10000: episode: 183, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000133, mae: 0.008385, mean_q: 0.005143
 1840/10000: episode: 184, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000068, mae: 0.005643, mean_q: 0.004254
 1850/10000: episode: 185, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000711, mae: 0.009127, mean_q: 0.010789
 1860/10000: episode: 186, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000974, mae: 0.016530, mean_q: 0.012672
 1870/10000: episode: 187, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000508, mae: 0.018069, mean_q: 0.006347
 1880/10000: episode: 188, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000234, mae: 0.015865, mean_q: 0.008020
 1890/10000: episode: 189, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000606, mae: 0.020584, mean_q: 0.008822
 1900/10000: episode: 190, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000576, mae: 0.011760, mean_q: 0.016895
 1910/10000: episode: 191, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000272, mae: 0.011384, mean_q: 0.003108
 1920/10000: episode: 192, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000642, mae: 0.012019, mean_q: 0.012113
 1930/10000: episode: 193, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000098, mae: 0.009212, mean_q: 0.005992
 1940/10000: episode: 194, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000544, mae: 0.008391, mean_q: 0.008062
 1950/10000: episode: 195, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000237, mae: 0.008147, mean_q: 0.010526
 1960/10000: episode: 196, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000198, mae: 0.010859, mean_q: 0.005772
 1970/10000: episode: 197, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000286, mae: 0.011736, mean_q: 0.012152
 1980/10000: episode: 198, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000225, mae: 0.009444, mean_q: 0.009614
 1990/10000: episode: 199, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000302, mae: 0.009566, mean_q: 0.009048
 2000/10000: episode: 200, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000667, mae: 0.010194, mean_q: 0.005541
 2010/10000: episode: 201, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000506, mae: 0.013594, mean_q: 0.010111
 2020/10000: episode: 202, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000590, mae: 0.014924, mean_q: 0.010554
 2030/10000: episode: 203, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000202, mae: 0.009086, mean_q: 0.007177
 2040/10000: episode: 204, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000092, mae: 0.007927, mean_q: 0.004914
 2050/10000: episode: 205, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000714, mae: 0.014622, mean_q: 0.011270
 2060/10000: episode: 206, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000386, mae: 0.007727, mean_q: 0.010805
 2070/10000: episode: 207, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000982, mae: 0.015398, mean_q: 0.020764
 2080/10000: episode: 208, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000415, mae: 0.017498, mean_q: 0.004634
 2090/10000: episode: 209, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000514, mae: 0.013365, mean_q: 0.011359
 2100/10000: episode: 210, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000183, mae: 0.012137, mean_q: 0.006301
 2110/10000: episode: 211, duration: 0.044s, episode steps: 10, steps per second: 228, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000112, mae: 0.007520, mean_q: 0.007159
 2120/10000: episode: 212, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000187, mae: 0.007940, mean_q: 0.008963
 2130/10000: episode: 213, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000661, mae: 0.014905, mean_q: 0.008008
 2140/10000: episode: 214, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000211, mae: 0.010514, mean_q: 0.007872
 2150/10000: episode: 215, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000101, mae: 0.007875, mean_q: 0.007288
 2160/10000: episode: 216, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000186, mae: 0.007420, mean_q: 0.006343
 2170/10000: episode: 217, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000161, mae: 0.008711, mean_q: 0.009263
 2180/10000: episode: 218, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000109, mae: 0.008811, mean_q: 0.006592
 2190/10000: episode: 219, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000312, mae: 0.009113, mean_q: 0.009075
 2200/10000: episode: 220, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000099, mae: 0.006030, mean_q: 0.005173
 2210/10000: episode: 221, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000310, mae: 0.008443, mean_q: 0.006375
 2220/10000: episode: 222, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000258, mae: 0.009620, mean_q: 0.011191
 2230/10000: episode: 223, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000160, mae: 0.007849, mean_q: 0.007059
 2240/10000: episode: 224, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000521, mae: 0.008371, mean_q: 0.010833
 2250/10000: episode: 225, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000587, mae: 0.013301, mean_q: 0.011236
 2260/10000: episode: 226, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000240, mae: 0.015414, mean_q: 0.007138
 2270/10000: episode: 227, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000136, mae: 0.009760, mean_q: 0.007417
 2280/10000: episode: 228, duration: 0.044s, episode steps: 10, steps per second: 227, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000053, mae: 0.005082, mean_q: 0.005828
 2290/10000: episode: 229, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000465, mae: 0.010393, mean_q: 0.008875
 2300/10000: episode: 230, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000484, mae: 0.008350, mean_q: 0.009007
 2310/10000: episode: 231, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000213, mae: 0.009735, mean_q: 0.010029
 2320/10000: episode: 232, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000189, mae: 0.009792, mean_q: 0.007473
 2330/10000: episode: 233, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000635, mae: 0.014768, mean_q: 0.010149
 2340/10000: episode: 234, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000256, mae: 0.013868, mean_q: 0.009266
 2350/10000: episode: 235, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000153, mae: 0.008392, mean_q: 0.003546
 2360/10000: episode: 236, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000114, mae: 0.007740, mean_q: 0.009512
 2370/10000: episode: 237, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000377, mae: 0.007780, mean_q: 0.010860
 2380/10000: episode: 238, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000153, mae: 0.007962, mean_q: 0.006549
 2390/10000: episode: 239, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000308, mae: 0.010546, mean_q: 0.007366
 2400/10000: episode: 240, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000461, mae: 0.008317, mean_q: 0.005458
 2410/10000: episode: 241, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000214, mae: 0.010751, mean_q: 0.008402
 2420/10000: episode: 242, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000282, mae: 0.011820, mean_q: 0.011015
 2430/10000: episode: 243, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000117, mae: 0.008416, mean_q: 0.006385
 2440/10000: episode: 244, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000107, mae: 0.007088, mean_q: 0.005707
 2450/10000: episode: 245, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000181, mae: 0.011117, mean_q: 0.005089
 2460/10000: episode: 246, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000050, mae: 0.005394, mean_q: 0.006965
 2470/10000: episode: 247, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000551, mae: 0.012492, mean_q: 0.008263
 2480/10000: episode: 248, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000121, mae: 0.008295, mean_q: 0.006181
 2490/10000: episode: 249, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000614, mae: 0.013157, mean_q: 0.012730
[Info] 1-TH LEVEL FOUND: 0.06329525262117386, Considering 100/100 traces
 2500/10000: episode: 250, duration: 0.648s, episode steps: 10, steps per second: 15, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000451, mae: 0.011443, mean_q: 0.005744
[Info] 2-TH LEVEL FOUND: 0.06910595297813416, Considering 100/100 traces
 2501/10000: episode: 251, duration: 0.692s, episode steps: 1, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000896, mae: 0.015106, mean_q: 0.017485
[Info] 3-TH LEVEL FOUND: 0.08107797801494598, Considering 100/100 traces
 2502/10000: episode: 252, duration: 0.640s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000049, mae: 0.007346, mean_q: 0.008274
[Info] 4-TH LEVEL FOUND: 0.09428871423006058, Considering 100/100 traces
 2503/10000: episode: 253, duration: 0.656s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000713, mae: 0.012129, mean_q: 0.008446
[Info] 5-TH LEVEL FOUND: 0.10979468375444412, Considering 100/100 traces
 2504/10000: episode: 254, duration: 0.674s, episode steps: 1, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000060, mae: 0.006653, mean_q: 0.001894
[Info] 6-TH LEVEL FOUND: 0.12451210618019104, Considering 100/100 traces
 2505/10000: episode: 255, duration: 0.682s, episode steps: 1, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.002246, mae: 0.018104, mean_q: 0.024855
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.12451210618019104
 2506/10000: episode: 256, duration: 0.429s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000195, mae: 0.014178, mean_q: 0.031190
 2516/10000: episode: 257, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000226, mae: 0.013287, mean_q: 0.003636
 2526/10000: episode: 258, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000232, mae: 0.012044, mean_q: 0.005807
 2536/10000: episode: 259, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000481, mae: 0.014609, mean_q: 0.009517
 2546/10000: episode: 260, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000300, mae: 0.012735, mean_q: 0.008900
 2556/10000: episode: 261, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000259, mae: 0.009092, mean_q: 0.010162
 2566/10000: episode: 262, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000280, mae: 0.007775, mean_q: 0.010917
 2576/10000: episode: 263, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000151, mae: 0.007002, mean_q: 0.009352
 2586/10000: episode: 264, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000221, mae: 0.006698, mean_q: 0.008970
 2596/10000: episode: 265, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000122, mae: 0.006717, mean_q: 0.003587
 2606/10000: episode: 266, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000211, mae: 0.006671, mean_q: 0.006455
 2616/10000: episode: 267, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000190, mae: 0.009379, mean_q: 0.006430
 2626/10000: episode: 268, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000115, mae: 0.006536, mean_q: 0.005368
 2636/10000: episode: 269, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000136, mae: 0.007209, mean_q: 0.005718
 2646/10000: episode: 270, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000126, mae: 0.006667, mean_q: 0.006609
 2656/10000: episode: 271, duration: 0.045s, episode steps: 10, steps per second: 225, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000099, mae: 0.006315, mean_q: 0.007727
 2666/10000: episode: 272, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000106, mae: 0.007003, mean_q: 0.007409
 2676/10000: episode: 273, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000054, mae: 0.007160, mean_q: 0.004504
 2686/10000: episode: 274, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000343, mae: 0.012149, mean_q: 0.010174
 2696/10000: episode: 275, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000097, mae: 0.009262, mean_q: 0.005584
 2706/10000: episode: 276, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000122, mae: 0.008053, mean_q: 0.007157
 2716/10000: episode: 277, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000099, mae: 0.006248, mean_q: 0.007250
 2726/10000: episode: 278, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000026, mae: 0.005126, mean_q: 0.006280
 2736/10000: episode: 279, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000127, mae: 0.006340, mean_q: 0.009419
 2746/10000: episode: 280, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000198, mae: 0.007866, mean_q: 0.005623
 2756/10000: episode: 281, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000858, mae: 0.018629, mean_q: 0.012298
 2766/10000: episode: 282, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000230, mae: 0.014097, mean_q: 0.007026
 2776/10000: episode: 283, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000294, mae: 0.014201, mean_q: 0.006385
 2786/10000: episode: 284, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000063, mae: 0.006940, mean_q: 0.004370
 2796/10000: episode: 285, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000322, mae: 0.010242, mean_q: 0.011022
 2806/10000: episode: 286, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000193, mae: 0.012548, mean_q: 0.005664
 2816/10000: episode: 287, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000495, mae: 0.009910, mean_q: 0.007012
 2826/10000: episode: 288, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000430, mae: 0.011866, mean_q: 0.011134
 2836/10000: episode: 289, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000074, mae: 0.006859, mean_q: 0.005095
 2846/10000: episode: 290, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000161, mae: 0.009478, mean_q: 0.002968
 2856/10000: episode: 291, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000107, mae: 0.009088, mean_q: 0.003823
 2866/10000: episode: 292, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000084, mae: 0.007368, mean_q: 0.006294
 2876/10000: episode: 293, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000078, mae: 0.005300, mean_q: 0.005962
 2886/10000: episode: 294, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000209, mae: 0.008486, mean_q: 0.010124
 2896/10000: episode: 295, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000454, mae: 0.009365, mean_q: 0.008001
 2906/10000: episode: 296, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000157, mae: 0.007737, mean_q: 0.007633
 2916/10000: episode: 297, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000260, mae: 0.010431, mean_q: 0.006852
 2926/10000: episode: 298, duration: 0.044s, episode steps: 10, steps per second: 227, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000213, mae: 0.009556, mean_q: 0.006230
 2936/10000: episode: 299, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000227, mae: 0.010424, mean_q: 0.007679
 2946/10000: episode: 300, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000272, mae: 0.010368, mean_q: 0.010697
 2956/10000: episode: 301, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000112, mae: 0.008532, mean_q: 0.004922
 2966/10000: episode: 302, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000109, mae: 0.006066, mean_q: 0.005883
 2976/10000: episode: 303, duration: 0.044s, episode steps: 10, steps per second: 227, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000060, mae: 0.004994, mean_q: 0.004166
 2986/10000: episode: 304, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000037, mae: 0.005152, mean_q: 0.006583
 2996/10000: episode: 305, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000136, mae: 0.007135, mean_q: 0.010388
 3006/10000: episode: 306, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000289, mae: 0.007397, mean_q: 0.008945
 3016/10000: episode: 307, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000241, mae: 0.007376, mean_q: 0.006166
 3026/10000: episode: 308, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000155, mae: 0.008229, mean_q: 0.005308
 3036/10000: episode: 309, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000040, mae: 0.005335, mean_q: 0.006459
 3046/10000: episode: 310, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000106, mae: 0.006651, mean_q: 0.005561
 3056/10000: episode: 311, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000042, mae: 0.005205, mean_q: 0.004331
 3066/10000: episode: 312, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000197, mae: 0.009125, mean_q: 0.007102
 3076/10000: episode: 313, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000769, mae: 0.014677, mean_q: 0.012515
 3086/10000: episode: 314, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000411, mae: 0.012418, mean_q: 0.007371
 3096/10000: episode: 315, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000148, mae: 0.008831, mean_q: 0.007379
 3106/10000: episode: 316, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000314, mae: 0.013578, mean_q: 0.006487
 3116/10000: episode: 317, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000149, mae: 0.007408, mean_q: 0.005358
 3126/10000: episode: 318, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000114, mae: 0.006042, mean_q: 0.008029
 3136/10000: episode: 319, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000179, mae: 0.007013, mean_q: 0.005714
 3146/10000: episode: 320, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000109, mae: 0.006545, mean_q: 0.006327
 3156/10000: episode: 321, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000493, mae: 0.007706, mean_q: 0.006746
 3166/10000: episode: 322, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000340, mae: 0.011998, mean_q: 0.007042
 3176/10000: episode: 323, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000368, mae: 0.010931, mean_q: 0.010983
 3186/10000: episode: 324, duration: 0.044s, episode steps: 10, steps per second: 227, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000072, mae: 0.008339, mean_q: 0.004347
 3196/10000: episode: 325, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000165, mae: 0.007875, mean_q: 0.004661
 3206/10000: episode: 326, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000291, mae: 0.009613, mean_q: 0.010561
 3216/10000: episode: 327, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000197, mae: 0.008815, mean_q: 0.008582
 3226/10000: episode: 328, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000370, mae: 0.012071, mean_q: 0.007933
 3236/10000: episode: 329, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000071, mae: 0.006515, mean_q: 0.006930
 3246/10000: episode: 330, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000090, mae: 0.006841, mean_q: 0.002958
 3256/10000: episode: 331, duration: 0.044s, episode steps: 10, steps per second: 228, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000111, mae: 0.007802, mean_q: 0.007463
 3266/10000: episode: 332, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000167, mae: 0.007620, mean_q: 0.004618
 3276/10000: episode: 333, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000555, mae: 0.012257, mean_q: 0.008300
 3286/10000: episode: 334, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000178, mae: 0.013034, mean_q: 0.004563
 3296/10000: episode: 335, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000574, mae: 0.019151, mean_q: 0.002705
 3306/10000: episode: 336, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000373, mae: 0.017072, mean_q: 0.013429
 3316/10000: episode: 337, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000283, mae: 0.012640, mean_q: 0.008757
 3326/10000: episode: 338, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000137, mae: 0.008008, mean_q: 0.003460
 3336/10000: episode: 339, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000127, mae: 0.006034, mean_q: 0.007427
 3346/10000: episode: 340, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000077, mae: 0.006592, mean_q: 0.005734
 3356/10000: episode: 341, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000157, mae: 0.008843, mean_q: 0.009495
 3366/10000: episode: 342, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000076, mae: 0.007497, mean_q: 0.002922
 3376/10000: episode: 343, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000226, mae: 0.011151, mean_q: 0.006712
 3386/10000: episode: 344, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000079, mae: 0.006817, mean_q: 0.006009
 3396/10000: episode: 345, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000323, mae: 0.008482, mean_q: 0.010259
 3406/10000: episode: 346, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000288, mae: 0.009396, mean_q: 0.007948
 3416/10000: episode: 347, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000345, mae: 0.009233, mean_q: 0.005305
 3426/10000: episode: 348, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000352, mae: 0.011706, mean_q: 0.013099
 3436/10000: episode: 349, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000092, mae: 0.009174, mean_q: 0.003669
 3446/10000: episode: 350, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000422, mae: 0.011077, mean_q: 0.010220
 3456/10000: episode: 351, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000157, mae: 0.007901, mean_q: 0.006605
 3466/10000: episode: 352, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000463, mae: 0.010733, mean_q: 0.009483
 3476/10000: episode: 353, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000128, mae: 0.007290, mean_q: 0.006526
 3486/10000: episode: 354, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000108, mae: 0.007979, mean_q: 0.009439
 3496/10000: episode: 355, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000463, mae: 0.012845, mean_q: 0.008084
[Info] 1-TH LEVEL FOUND: 0.05267301946878433, Considering 100/100 traces
 3506/10000: episode: 356, duration: 0.690s, episode steps: 10, steps per second: 14, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000176, mae: 0.008969, mean_q: 0.004548
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.05267301946878433
 3507/10000: episode: 357, duration: 0.434s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000538, mae: 0.015572, mean_q: 0.028118
 3517/10000: episode: 358, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000100, mae: 0.007144, mean_q: 0.007762
 3527/10000: episode: 359, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000154, mae: 0.008217, mean_q: 0.008039
 3537/10000: episode: 360, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000308, mae: 0.012118, mean_q: 0.011852
 3547/10000: episode: 361, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000247, mae: 0.009789, mean_q: 0.005467
 3557/10000: episode: 362, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000384, mae: 0.011732, mean_q: 0.011535
 3567/10000: episode: 363, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000161, mae: 0.006618, mean_q: 0.003779
 3577/10000: episode: 364, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000401, mae: 0.010623, mean_q: 0.009864
 3587/10000: episode: 365, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000091, mae: 0.009892, mean_q: 0.002788
 3597/10000: episode: 366, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000105, mae: 0.008095, mean_q: 0.006006
 3607/10000: episode: 367, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000085, mae: 0.007317, mean_q: 0.006166
 3617/10000: episode: 368, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000126, mae: 0.007869, mean_q: 0.005961
 3627/10000: episode: 369, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000176, mae: 0.007811, mean_q: 0.005085
 3637/10000: episode: 370, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000051, mae: 0.006133, mean_q: 0.004680
 3647/10000: episode: 371, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000293, mae: 0.007406, mean_q: 0.008295
 3657/10000: episode: 372, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000621, mae: 0.010961, mean_q: 0.011613
 3667/10000: episode: 373, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000194, mae: 0.009496, mean_q: 0.011445
 3677/10000: episode: 374, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000219, mae: 0.009893, mean_q: 0.006068
 3687/10000: episode: 375, duration: 0.045s, episode steps: 10, steps per second: 225, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000044, mae: 0.005757, mean_q: 0.005175
 3697/10000: episode: 376, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000503, mae: 0.011000, mean_q: 0.002586
 3707/10000: episode: 377, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000253, mae: 0.009348, mean_q: 0.011307
 3717/10000: episode: 378, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000115, mae: 0.008355, mean_q: 0.005820
 3727/10000: episode: 379, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000335, mae: 0.010347, mean_q: 0.010683
 3737/10000: episode: 380, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000091, mae: 0.008765, mean_q: 0.005593
 3747/10000: episode: 381, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000198, mae: 0.007968, mean_q: 0.007305
 3757/10000: episode: 382, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000199, mae: 0.006281, mean_q: 0.004366
 3767/10000: episode: 383, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000271, mae: 0.008081, mean_q: 0.010484
 3777/10000: episode: 384, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000626, mae: 0.012049, mean_q: 0.011419
 3787/10000: episode: 385, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000256, mae: 0.013604, mean_q: 0.005320
 3797/10000: episode: 386, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000245, mae: 0.013839, mean_q: 0.006124
 3807/10000: episode: 387, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000727, mae: 0.017824, mean_q: 0.010447
 3817/10000: episode: 388, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000158, mae: 0.011481, mean_q: 0.006653
 3827/10000: episode: 389, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000392, mae: 0.008840, mean_q: 0.008780
 3837/10000: episode: 390, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000436, mae: 0.007329, mean_q: 0.007702
 3847/10000: episode: 391, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000249, mae: 0.011684, mean_q: 0.008699
 3857/10000: episode: 392, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000347, mae: 0.011143, mean_q: 0.011573
 3867/10000: episode: 393, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000115, mae: 0.009787, mean_q: 0.006863
 3877/10000: episode: 394, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000092, mae: 0.007299, mean_q: 0.005882
 3887/10000: episode: 395, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000091, mae: 0.006870, mean_q: 0.006087
 3897/10000: episode: 396, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000359, mae: 0.007867, mean_q: 0.007787
 3907/10000: episode: 397, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000037, mae: 0.004776, mean_q: 0.007248
 3917/10000: episode: 398, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000579, mae: 0.008221, mean_q: 0.010383
 3927/10000: episode: 399, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000112, mae: 0.006688, mean_q: 0.006801
 3937/10000: episode: 400, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000073, mae: 0.005937, mean_q: 0.006797
 3947/10000: episode: 401, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000193, mae: 0.008440, mean_q: 0.005626
 3957/10000: episode: 402, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000106, mae: 0.007197, mean_q: 0.002296
 3967/10000: episode: 403, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000111, mae: 0.006087, mean_q: 0.005079
 3977/10000: episode: 404, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000642, mae: 0.010620, mean_q: 0.008536
 3987/10000: episode: 405, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000586, mae: 0.014051, mean_q: 0.013028
 3997/10000: episode: 406, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000187, mae: 0.012345, mean_q: 0.004222
 4007/10000: episode: 407, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000760, mae: 0.016149, mean_q: 0.013850
 4017/10000: episode: 408, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000196, mae: 0.013100, mean_q: 0.003715
 4027/10000: episode: 409, duration: 0.045s, episode steps: 10, steps per second: 225, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000324, mae: 0.014859, mean_q: 0.005089
 4037/10000: episode: 410, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000104, mae: 0.010277, mean_q: 0.004754
 4047/10000: episode: 411, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000161, mae: 0.008417, mean_q: 0.004474
 4057/10000: episode: 412, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000230, mae: 0.006189, mean_q: 0.007467
 4067/10000: episode: 413, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000033, mae: 0.004104, mean_q: 0.003981
 4077/10000: episode: 414, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000545, mae: 0.010243, mean_q: 0.013878
 4087/10000: episode: 415, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000203, mae: 0.014389, mean_q: 0.003609
 4097/10000: episode: 416, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000130, mae: 0.010885, mean_q: 0.003818
 4107/10000: episode: 417, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000106, mae: 0.010084, mean_q: 0.007845
 4117/10000: episode: 418, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000241, mae: 0.006332, mean_q: 0.007397
 4127/10000: episode: 419, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000354, mae: 0.010949, mean_q: 0.010138
 4137/10000: episode: 420, duration: 0.044s, episode steps: 10, steps per second: 227, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000069, mae: 0.006805, mean_q: 0.002845
 4147/10000: episode: 421, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000121, mae: 0.005996, mean_q: 0.008680
 4157/10000: episode: 422, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000081, mae: 0.005737, mean_q: 0.005178
 4167/10000: episode: 423, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000526, mae: 0.013192, mean_q: 0.004302
 4177/10000: episode: 424, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000108, mae: 0.008395, mean_q: 0.007675
 4187/10000: episode: 425, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000298, mae: 0.005989, mean_q: 0.009952
 4197/10000: episode: 426, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000222, mae: 0.008987, mean_q: 0.011583
 4207/10000: episode: 427, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000140, mae: 0.010401, mean_q: 0.003197
 4217/10000: episode: 428, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000535, mae: 0.012250, mean_q: 0.004437
 4227/10000: episode: 429, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000086, mae: 0.008440, mean_q: 0.004787
 4237/10000: episode: 430, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000095, mae: 0.008256, mean_q: 0.009231
 4247/10000: episode: 431, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000111, mae: 0.005567, mean_q: 0.003671
 4257/10000: episode: 432, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000192, mae: 0.007733, mean_q: 0.006083
 4267/10000: episode: 433, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000238, mae: 0.007728, mean_q: 0.006370
 4277/10000: episode: 434, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000111, mae: 0.007841, mean_q: 0.006017
 4287/10000: episode: 435, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000136, mae: 0.009367, mean_q: 0.005092
 4297/10000: episode: 436, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000128, mae: 0.010966, mean_q: 0.003574
 4307/10000: episode: 437, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000141, mae: 0.009667, mean_q: 0.006137
 4317/10000: episode: 438, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000050, mae: 0.005136, mean_q: 0.004226
 4327/10000: episode: 439, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000063, mae: 0.004629, mean_q: 0.004635
 4337/10000: episode: 440, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000527, mae: 0.006515, mean_q: 0.006031
 4347/10000: episode: 441, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000158, mae: 0.012661, mean_q: 0.007528
 4357/10000: episode: 442, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000152, mae: 0.008570, mean_q: 0.003721
 4367/10000: episode: 443, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000031, mae: 0.005349, mean_q: 0.005057
 4377/10000: episode: 444, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000078, mae: 0.004647, mean_q: 0.007243
 4387/10000: episode: 445, duration: 0.044s, episode steps: 10, steps per second: 228, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000062, mae: 0.005237, mean_q: 0.004090
 4397/10000: episode: 446, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000068, mae: 0.005674, mean_q: 0.005181
 4407/10000: episode: 447, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.000082, mae: 0.007255, mean_q: 0.004135
 4417/10000: episode: 448, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000159, mae: 0.007777, mean_q: 0.007113
 4427/10000: episode: 449, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000021, mae: 0.004380, mean_q: 0.003445
 4437/10000: episode: 450, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000186, mae: 0.005660, mean_q: 0.009422
 4447/10000: episode: 451, duration: 0.045s, episode steps: 10, steps per second: 225, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000046, mae: 0.006024, mean_q: 0.003206
 4457/10000: episode: 452, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000172, mae: 0.006903, mean_q: 0.007686
 4467/10000: episode: 453, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000114, mae: 0.007307, mean_q: 0.007320
 4477/10000: episode: 454, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000106, mae: 0.007824, mean_q: 0.005156
 4487/10000: episode: 455, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000697, mae: 0.014274, mean_q: 0.006590
 4497/10000: episode: 456, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000045, mae: 0.006819, mean_q: 0.004509
[Info] 1-TH LEVEL FOUND: 0.05403532832860947, Considering 12/100 traces
 4507/10000: episode: 457, duration: 0.645s, episode steps: 10, steps per second: 15, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000115, mae: 0.006362, mean_q: 0.007944
 4514/10000: episode: 458, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000045, mae: 0.004344, mean_q: 0.004329
 4521/10000: episode: 459, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000145, mae: 0.006052, mean_q: 0.008193
 4528/10000: episode: 460, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000298, mae: 0.006311, mean_q: 0.004214
 4535/10000: episode: 461, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000271, mae: 0.009386, mean_q: 0.007742
 4542/10000: episode: 462, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000180, mae: 0.008045, mean_q: 0.008835
 4549/10000: episode: 463, duration: 0.032s, episode steps: 7, steps per second: 218, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000071, mae: 0.005907, mean_q: 0.004160
 4556/10000: episode: 464, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000036, mae: 0.005710, mean_q: 0.002782
[Info] FALSIFICATION!
 4562/10000: episode: 465, duration: 0.256s, episode steps: 6, steps per second: 23, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000104, mae: 0.005871, mean_q: 0.008631
 4569/10000: episode: 466, duration: 0.038s, episode steps: 7, steps per second: 185, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000104, mae: 0.006748, mean_q: 0.007010
 4576/10000: episode: 467, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000147, mae: 0.008448, mean_q: 0.002989
 4583/10000: episode: 468, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000079, mae: 0.007075, mean_q: 0.003494
 4590/10000: episode: 469, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.001283, mae: 0.015641, mean_q: 0.017129
 4597/10000: episode: 470, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000367, mae: 0.019178, mean_q: 0.006230
 4604/10000: episode: 471, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000291, mae: 0.013723, mean_q: 0.004713
 4611/10000: episode: 472, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000126, mae: 0.012608, mean_q: 0.001985
 4618/10000: episode: 473, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000748, mae: 0.012351, mean_q: 0.007088
 4625/10000: episode: 474, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000251, mae: 0.014271, mean_q: 0.004114
 4632/10000: episode: 475, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000387, mae: 0.011022, mean_q: 0.009253
 4639/10000: episode: 476, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000112, mae: 0.007698, mean_q: 0.009436
 4646/10000: episode: 477, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000105, mae: 0.007124, mean_q: 0.006170
 4653/10000: episode: 478, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000350, mae: 0.008617, mean_q: 0.011038
 4660/10000: episode: 479, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000090, mae: 0.006418, mean_q: 0.010224
 4667/10000: episode: 480, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000076, mae: 0.005604, mean_q: 0.008138
 4674/10000: episode: 481, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000061, mae: 0.006680, mean_q: 0.007987
 4681/10000: episode: 482, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000578, mae: 0.010253, mean_q: 0.008650
 4688/10000: episode: 483, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000080, mae: 0.006949, mean_q: 0.005901
 4695/10000: episode: 484, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000287, mae: 0.012419, mean_q: 0.004002
[Info] FALSIFICATION!
 4701/10000: episode: 485, duration: 0.254s, episode steps: 6, steps per second: 24, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000390, mae: 0.015740, mean_q: 0.004872
 4708/10000: episode: 486, duration: 0.038s, episode steps: 7, steps per second: 184, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000732, mae: 0.021225, mean_q: 0.007632
 4715/10000: episode: 487, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000394, mae: 0.021730, mean_q: 0.011970
 4722/10000: episode: 488, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000225, mae: 0.013975, mean_q: 0.013209
 4729/10000: episode: 489, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000187, mae: 0.012941, mean_q: 0.010230
 4736/10000: episode: 490, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000245, mae: 0.011426, mean_q: 0.007185
[Info] FALSIFICATION!
 4742/10000: episode: 491, duration: 0.170s, episode steps: 6, steps per second: 35, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000122, mae: 0.008528, mean_q: 0.004576
 4749/10000: episode: 492, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000858, mae: 0.010842, mean_q: 0.009396
 4756/10000: episode: 493, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000353, mae: 0.015467, mean_q: 0.007186
 4763/10000: episode: 494, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000488, mae: 0.011425, mean_q: 0.010959
 4770/10000: episode: 495, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000485, mae: 0.013554, mean_q: 0.006666
 4777/10000: episode: 496, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000135, mae: 0.007520, mean_q: 0.007216
 4784/10000: episode: 497, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000115, mae: 0.007124, mean_q: 0.005201
 4791/10000: episode: 498, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000753, mae: 0.013554, mean_q: 0.017155
 4798/10000: episode: 499, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000324, mae: 0.007937, mean_q: 0.011964
 4805/10000: episode: 500, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000381, mae: 0.012177, mean_q: 0.012666
 4812/10000: episode: 501, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000178, mae: 0.008579, mean_q: 0.011319
 4819/10000: episode: 502, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000733, mae: 0.012240, mean_q: 0.009563
 4826/10000: episode: 503, duration: 0.032s, episode steps: 7, steps per second: 216, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000200, mae: 0.010195, mean_q: 0.008028
 4833/10000: episode: 504, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000636, mae: 0.012522, mean_q: 0.016642
 4840/10000: episode: 505, duration: 0.032s, episode steps: 7, steps per second: 216, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000616, mae: 0.010930, mean_q: 0.009021
 4847/10000: episode: 506, duration: 0.033s, episode steps: 7, steps per second: 215, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000132, mae: 0.010147, mean_q: 0.005243
 4854/10000: episode: 507, duration: 0.032s, episode steps: 7, steps per second: 218, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000339, mae: 0.012312, mean_q: 0.016103
 4861/10000: episode: 508, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000664, mae: 0.013262, mean_q: 0.007694
 4868/10000: episode: 509, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000556, mae: 0.017859, mean_q: 0.011676
 4875/10000: episode: 510, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000284, mae: 0.015762, mean_q: 0.007367
 4882/10000: episode: 511, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000332, mae: 0.013064, mean_q: 0.009623
 4889/10000: episode: 512, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000179, mae: 0.009561, mean_q: 0.013183
 4896/10000: episode: 513, duration: 0.032s, episode steps: 7, steps per second: 217, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000145, mae: 0.008806, mean_q: 0.009489
 4903/10000: episode: 514, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000165, mae: 0.009433, mean_q: 0.008743
 4910/10000: episode: 515, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000152, mae: 0.007040, mean_q: 0.005548
 4917/10000: episode: 516, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000422, mae: 0.010262, mean_q: 0.011405
 4924/10000: episode: 517, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000839, mae: 0.016806, mean_q: 0.016690
 4931/10000: episode: 518, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000078, mae: 0.008236, mean_q: 0.005381
 4938/10000: episode: 519, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000490, mae: 0.014482, mean_q: 0.010565
 4945/10000: episode: 520, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000543, mae: 0.012941, mean_q: 0.010035
 4952/10000: episode: 521, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000167, mae: 0.009717, mean_q: 0.007861
 4959/10000: episode: 522, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000414, mae: 0.014074, mean_q: 0.015886
 4966/10000: episode: 523, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000277, mae: 0.008651, mean_q: 0.008606
 4973/10000: episode: 524, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000226, mae: 0.010930, mean_q: 0.006855
 4980/10000: episode: 525, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000391, mae: 0.009940, mean_q: 0.011248
 4987/10000: episode: 526, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000202, mae: 0.007415, mean_q: 0.007789
 4994/10000: episode: 527, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000558, mae: 0.014747, mean_q: 0.012739
 5001/10000: episode: 528, duration: 0.032s, episode steps: 7, steps per second: 218, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000121, mae: 0.010487, mean_q: 0.010215
 5008/10000: episode: 529, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000307, mae: 0.009999, mean_q: 0.009908
 5015/10000: episode: 530, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000228, mae: 0.009945, mean_q: 0.006682
 5022/10000: episode: 531, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000125, mae: 0.008820, mean_q: 0.007387
 5029/10000: episode: 532, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000484, mae: 0.009115, mean_q: 0.014748
 5036/10000: episode: 533, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000394, mae: 0.010867, mean_q: 0.008436
 5043/10000: episode: 534, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000487, mae: 0.012826, mean_q: 0.008080
 5050/10000: episode: 535, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000126, mae: 0.011015, mean_q: 0.010259
 5057/10000: episode: 536, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000358, mae: 0.011382, mean_q: 0.010936
 5064/10000: episode: 537, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000764, mae: 0.014780, mean_q: 0.013672
 5071/10000: episode: 538, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000361, mae: 0.016066, mean_q: 0.003489
 5078/10000: episode: 539, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000251, mae: 0.015765, mean_q: 0.002665
 5085/10000: episode: 540, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000210, mae: 0.011820, mean_q: 0.002196
[Info] FALSIFICATION!
 5091/10000: episode: 541, duration: 0.255s, episode steps: 6, steps per second: 24, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000158, mae: 0.007989, mean_q: 0.006226
 5098/10000: episode: 542, duration: 0.038s, episode steps: 7, steps per second: 185, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000133, mae: 0.007130, mean_q: 0.009750
 5105/10000: episode: 543, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000111, mae: 0.006668, mean_q: 0.007453
 5112/10000: episode: 544, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000270, mae: 0.009345, mean_q: 0.011987
[Info] Complete ISplit Iteration
[Info] Levels: [0.05403533, 0.59541506]
[Info] Cond. Prob: [0.12, 0.04]
[Info] Error Prob: 0.0048

 5119/10000: episode: 545, duration: 0.823s, episode steps: 7, steps per second: 9, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000224, mae: 0.010638, mean_q: 0.008706
 5129/10000: episode: 546, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000728, mae: 0.019702, mean_q: 0.009970
 5139/10000: episode: 547, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001303, mae: 0.024331, mean_q: 0.017260
 5149/10000: episode: 548, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000288, mae: 0.017827, mean_q: 0.010050
 5159/10000: episode: 549, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000140, mae: 0.010536, mean_q: 0.006948
 5169/10000: episode: 550, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000061, mae: 0.007210, mean_q: 0.007224
 5179/10000: episode: 551, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000476, mae: 0.011018, mean_q: 0.009461
 5189/10000: episode: 552, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000282, mae: 0.011709, mean_q: 0.015022
 5199/10000: episode: 553, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000258, mae: 0.010413, mean_q: 0.010441
 5209/10000: episode: 554, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000098, mae: 0.007207, mean_q: 0.008446
 5219/10000: episode: 555, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000524, mae: 0.014551, mean_q: 0.008303
 5229/10000: episode: 556, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000538, mae: 0.016075, mean_q: 0.012899
 5239/10000: episode: 557, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000236, mae: 0.014127, mean_q: 0.007750
 5249/10000: episode: 558, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000974, mae: 0.019028, mean_q: 0.016211
 5259/10000: episode: 559, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000136, mae: 0.010136, mean_q: 0.008480
 5269/10000: episode: 560, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000333, mae: 0.009568, mean_q: 0.012652
 5279/10000: episode: 561, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000371, mae: 0.011687, mean_q: 0.011585
 5289/10000: episode: 562, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000546, mae: 0.014636, mean_q: 0.010502
 5299/10000: episode: 563, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000588, mae: 0.015077, mean_q: 0.015838
 5309/10000: episode: 564, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000162, mae: 0.009694, mean_q: 0.008982
 5319/10000: episode: 565, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000350, mae: 0.012445, mean_q: 0.009417
 5329/10000: episode: 566, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000313, mae: 0.009208, mean_q: 0.011081
 5339/10000: episode: 567, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000374, mae: 0.010972, mean_q: 0.009086
 5349/10000: episode: 568, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000455, mae: 0.018659, mean_q: 0.010626
 5359/10000: episode: 569, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000251, mae: 0.013788, mean_q: 0.009500
 5369/10000: episode: 570, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000236, mae: 0.013370, mean_q: 0.011341
 5379/10000: episode: 571, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000355, mae: 0.016294, mean_q: 0.007630
 5389/10000: episode: 572, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000562, mae: 0.018632, mean_q: 0.012241
 5399/10000: episode: 573, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000148, mae: 0.009290, mean_q: 0.010044
 5409/10000: episode: 574, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000095, mae: 0.007479, mean_q: 0.005616
 5419/10000: episode: 575, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000192, mae: 0.008005, mean_q: 0.005483
 5429/10000: episode: 576, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000253, mae: 0.010602, mean_q: 0.008569
 5439/10000: episode: 577, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000154, mae: 0.010476, mean_q: 0.008381
 5449/10000: episode: 578, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000186, mae: 0.010457, mean_q: 0.007473
 5459/10000: episode: 579, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000225, mae: 0.009136, mean_q: 0.008099
 5469/10000: episode: 580, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000579, mae: 0.007553, mean_q: 0.009261
 5479/10000: episode: 581, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000208, mae: 0.013383, mean_q: 0.009392
 5489/10000: episode: 582, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000319, mae: 0.010227, mean_q: 0.012807
 5499/10000: episode: 583, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000473, mae: 0.012605, mean_q: 0.007005
 5509/10000: episode: 584, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000159, mae: 0.009153, mean_q: 0.009418
 5519/10000: episode: 585, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000253, mae: 0.010702, mean_q: 0.011255
 5529/10000: episode: 586, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000651, mae: 0.016468, mean_q: 0.012576
 5539/10000: episode: 587, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000248, mae: 0.010205, mean_q: 0.004987
 5549/10000: episode: 588, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000248, mae: 0.011996, mean_q: 0.008065
 5559/10000: episode: 589, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000054, mae: 0.005706, mean_q: 0.007538
 5569/10000: episode: 590, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000117, mae: 0.006644, mean_q: 0.006809
 5579/10000: episode: 591, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000138, mae: 0.008518, mean_q: 0.008261
 5589/10000: episode: 592, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000302, mae: 0.014014, mean_q: 0.009568
 5599/10000: episode: 593, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000223, mae: 0.012805, mean_q: 0.009428
 5609/10000: episode: 594, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001154, mae: 0.021342, mean_q: 0.016596
 5619/10000: episode: 595, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001536, mae: 0.033769, mean_q: 0.011540
 5629/10000: episode: 596, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000709, mae: 0.025565, mean_q: 0.015565
 5639/10000: episode: 597, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000533, mae: 0.020303, mean_q: 0.008782
 5649/10000: episode: 598, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000327, mae: 0.015168, mean_q: 0.006679
 5659/10000: episode: 599, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000193, mae: 0.009300, mean_q: 0.007895
 5669/10000: episode: 600, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000127, mae: 0.007949, mean_q: 0.008846
 5679/10000: episode: 601, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000189, mae: 0.007981, mean_q: 0.010325
 5689/10000: episode: 602, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000077, mae: 0.007049, mean_q: 0.006432
 5699/10000: episode: 603, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000199, mae: 0.007950, mean_q: 0.010073
 5709/10000: episode: 604, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000244, mae: 0.008319, mean_q: 0.005147
 5719/10000: episode: 605, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000277, mae: 0.011685, mean_q: 0.007524
 5729/10000: episode: 606, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000260, mae: 0.008198, mean_q: 0.008970
 5739/10000: episode: 607, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000238, mae: 0.009266, mean_q: 0.011103
 5749/10000: episode: 608, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000186, mae: 0.011451, mean_q: 0.009043
 5759/10000: episode: 609, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000505, mae: 0.018893, mean_q: 0.012209
 5769/10000: episode: 610, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000222, mae: 0.012156, mean_q: 0.011468
 5779/10000: episode: 611, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000206, mae: 0.008524, mean_q: 0.006310
 5789/10000: episode: 612, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000422, mae: 0.009713, mean_q: 0.012466
 5799/10000: episode: 613, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000305, mae: 0.008192, mean_q: 0.011850
 5809/10000: episode: 614, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000393, mae: 0.009715, mean_q: 0.008257
 5819/10000: episode: 615, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000388, mae: 0.012999, mean_q: 0.009800
 5829/10000: episode: 616, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000193, mae: 0.009264, mean_q: 0.007873
 5839/10000: episode: 617, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000873, mae: 0.013543, mean_q: 0.013843
 5849/10000: episode: 618, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000364, mae: 0.018106, mean_q: 0.006959
 5859/10000: episode: 619, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000320, mae: 0.013348, mean_q: 0.008246
 5869/10000: episode: 620, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000214, mae: 0.013461, mean_q: 0.008139
 5879/10000: episode: 621, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000110, mae: 0.008645, mean_q: 0.006539
 5889/10000: episode: 622, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000813, mae: 0.018043, mean_q: 0.016358
 5899/10000: episode: 623, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000573, mae: 0.017038, mean_q: 0.014050
 5909/10000: episode: 624, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000338, mae: 0.014088, mean_q: 0.008635
 5919/10000: episode: 625, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000232, mae: 0.012439, mean_q: 0.009232
 5929/10000: episode: 626, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000233, mae: 0.009982, mean_q: 0.010225
 5939/10000: episode: 627, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000245, mae: 0.008761, mean_q: 0.009678
 5949/10000: episode: 628, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000555, mae: 0.011864, mean_q: 0.015563
 5959/10000: episode: 629, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000190, mae: 0.011021, mean_q: 0.008436
 5969/10000: episode: 630, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000190, mae: 0.011869, mean_q: 0.010236
 5979/10000: episode: 631, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000162, mae: 0.007327, mean_q: 0.007406
 5989/10000: episode: 632, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000062, mae: 0.005803, mean_q: 0.005592
 5999/10000: episode: 633, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000193, mae: 0.009972, mean_q: 0.011065
 6009/10000: episode: 634, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000245, mae: 0.010616, mean_q: 0.007656
 6019/10000: episode: 635, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000246, mae: 0.009649, mean_q: 0.007682
 6029/10000: episode: 636, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000197, mae: 0.008137, mean_q: 0.008757
 6039/10000: episode: 637, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000119, mae: 0.008019, mean_q: 0.008721
 6049/10000: episode: 638, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000241, mae: 0.015809, mean_q: 0.008068
 6059/10000: episode: 639, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000416, mae: 0.013409, mean_q: 0.012806
 6069/10000: episode: 640, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000559, mae: 0.013635, mean_q: 0.011464
 6079/10000: episode: 641, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000113, mae: 0.009778, mean_q: 0.008526
 6089/10000: episode: 642, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000259, mae: 0.008307, mean_q: 0.011728
 6099/10000: episode: 643, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000403, mae: 0.009398, mean_q: 0.013556
 6109/10000: episode: 644, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000566, mae: 0.014171, mean_q: 0.015781
[Info] 1-TH LEVEL FOUND: 0.0252262894064188, Considering 10/100 traces
 6119/10000: episode: 645, duration: 0.763s, episode steps: 10, steps per second: 13, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000677, mae: 0.015058, mean_q: 0.010122
 6123/10000: episode: 646, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000418, mae: 0.014714, mean_q: 0.016408
 6127/10000: episode: 647, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000385, mae: 0.015149, mean_q: 0.010222
 6131/10000: episode: 648, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000227, mae: 0.013109, mean_q: 0.012495
 6137/10000: episode: 649, duration: 0.028s, episode steps: 6, steps per second: 211, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000159, mae: 0.009474, mean_q: 0.001815
 6141/10000: episode: 650, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000079, mae: 0.007196, mean_q: 0.010275
 6145/10000: episode: 651, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000055, mae: 0.005627, mean_q: 0.002942
 6149/10000: episode: 652, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000140, mae: 0.007295, mean_q: 0.009295
 6153/10000: episode: 653, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000477, mae: 0.011244, mean_q: 0.016145
 6157/10000: episode: 654, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000129, mae: 0.011125, mean_q: 0.007247
 6161/10000: episode: 655, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000191, mae: 0.010404, mean_q: 0.012081
 6165/10000: episode: 656, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000158, mae: 0.008979, mean_q: 0.011472
 6171/10000: episode: 657, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000070, mae: 0.007108, mean_q: 0.005611
 6175/10000: episode: 658, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000116, mae: 0.008600, mean_q: 0.008156
 6181/10000: episode: 659, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000130, mae: 0.007103, mean_q: 0.008185
 6185/10000: episode: 660, duration: 0.020s, episode steps: 4, steps per second: 200, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000394, mae: 0.011619, mean_q: 0.005672
 6189/10000: episode: 661, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000113, mae: 0.008826, mean_q: 0.007132
 6195/10000: episode: 662, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000373, mae: 0.010500, mean_q: 0.011183
 6199/10000: episode: 663, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000650, mae: 0.013072, mean_q: 0.018881
 6203/10000: episode: 664, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000125, mae: 0.010112, mean_q: 0.004029
 6207/10000: episode: 665, duration: 0.020s, episode steps: 4, steps per second: 198, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000255, mae: 0.010511, mean_q: 0.013987
 6211/10000: episode: 666, duration: 0.020s, episode steps: 4, steps per second: 204, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000482, mae: 0.012098, mean_q: 0.009989
 6215/10000: episode: 667, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000159, mae: 0.011128, mean_q: 0.013860
 6219/10000: episode: 668, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000376, mae: 0.010781, mean_q: 0.015651
 6225/10000: episode: 669, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000155, mae: 0.009507, mean_q: 0.003747
 6229/10000: episode: 670, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000345, mae: 0.009863, mean_q: 0.013732
 6233/10000: episode: 671, duration: 0.020s, episode steps: 4, steps per second: 199, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000239, mae: 0.010327, mean_q: 0.013431
 6239/10000: episode: 672, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001009, mae: 0.015810, mean_q: 0.021747
 6243/10000: episode: 673, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000282, mae: 0.015899, mean_q: 0.001452
 6247/10000: episode: 674, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000744, mae: 0.019744, mean_q: 0.012563
[Info] FALSIFICATION!
 6252/10000: episode: 675, duration: 0.165s, episode steps: 5, steps per second: 30, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000247, mae: 0.014116, mean_q: 0.013675
 6256/10000: episode: 676, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000126, mae: 0.008862, mean_q: 0.004711
 6260/10000: episode: 677, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000115, mae: 0.008653, mean_q: 0.011294
 6266/10000: episode: 678, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000108, mae: 0.007109, mean_q: 0.006062
 6270/10000: episode: 679, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000099, mae: 0.010331, mean_q: 0.016274
 6276/10000: episode: 680, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000694, mae: 0.011874, mean_q: 0.011182
 6280/10000: episode: 681, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000186, mae: 0.010721, mean_q: 0.002786
 6284/10000: episode: 682, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000047, mae: 0.005595, mean_q: 0.008520
 6288/10000: episode: 683, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000129, mae: 0.007966, mean_q: 0.007779
 6294/10000: episode: 684, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000488, mae: 0.010323, mean_q: 0.012509
 6298/10000: episode: 685, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000158, mae: 0.012326, mean_q: 0.014615
 6302/10000: episode: 686, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000161, mae: 0.012726, mean_q: -0.001577
 6306/10000: episode: 687, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000205, mae: 0.010773, mean_q: 0.016519
 6310/10000: episode: 688, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000134, mae: 0.011429, mean_q: -0.000857
 6314/10000: episode: 689, duration: 0.020s, episode steps: 4, steps per second: 198, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000142, mae: 0.010991, mean_q: 0.017417
 6318/10000: episode: 690, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000288, mae: 0.014234, mean_q: 0.006032
 6322/10000: episode: 691, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000163, mae: 0.010170, mean_q: 0.012028
 6326/10000: episode: 692, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000130, mae: 0.009233, mean_q: 0.006144
 6330/10000: episode: 693, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001725, mae: 0.015721, mean_q: 0.018073
 6334/10000: episode: 694, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000169, mae: 0.010691, mean_q: 0.014344
 6338/10000: episode: 695, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000945, mae: 0.016101, mean_q: 0.016808
 6342/10000: episode: 696, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000630, mae: 0.017390, mean_q: 0.014362
 6346/10000: episode: 697, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000284, mae: 0.016103, mean_q: 0.011884
 6350/10000: episode: 698, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000311, mae: 0.014018, mean_q: 0.003269
 6356/10000: episode: 699, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000136, mae: 0.007106, mean_q: 0.007931
 6360/10000: episode: 700, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000106, mae: 0.008382, mean_q: 0.009576
 6364/10000: episode: 701, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000075, mae: 0.006761, mean_q: 0.007003
 6368/10000: episode: 702, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000289, mae: 0.011377, mean_q: 0.013652
 6372/10000: episode: 703, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001379, mae: 0.018560, mean_q: 0.024176
 6378/10000: episode: 704, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000688, mae: 0.018972, mean_q: 0.017509
 6384/10000: episode: 705, duration: 0.028s, episode steps: 6, steps per second: 212, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000139, mae: 0.011122, mean_q: 0.004912
 6388/10000: episode: 706, duration: 0.020s, episode steps: 4, steps per second: 200, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000337, mae: 0.013563, mean_q: 0.018233
 6392/10000: episode: 707, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000386, mae: 0.010250, mean_q: 0.008061
 6398/10000: episode: 708, duration: 0.028s, episode steps: 6, steps per second: 211, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000167, mae: 0.009042, mean_q: 0.011889
 6402/10000: episode: 709, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000114, mae: 0.009516, mean_q: 0.011206
 6406/10000: episode: 710, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000996, mae: 0.015252, mean_q: 0.019322
 6410/10000: episode: 711, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000356, mae: 0.013141, mean_q: 0.010772
 6414/10000: episode: 712, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000442, mae: 0.014207, mean_q: 0.006789
 6418/10000: episode: 713, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000988, mae: 0.018130, mean_q: 0.017239
 6422/10000: episode: 714, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000452, mae: 0.018530, mean_q: 0.015764
 6426/10000: episode: 715, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000840, mae: 0.020767, mean_q: 0.017059
 6432/10000: episode: 716, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000950, mae: 0.023730, mean_q: 0.010137
 6436/10000: episode: 717, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000479, mae: 0.013577, mean_q: 0.023213
 6440/10000: episode: 718, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000376, mae: 0.012109, mean_q: 0.020589
 6444/10000: episode: 719, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000228, mae: 0.011077, mean_q: 0.009304
 6448/10000: episode: 720, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000175, mae: 0.011933, mean_q: 0.012511
 6454/10000: episode: 721, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000663, mae: 0.017349, mean_q: 0.007383
 6458/10000: episode: 722, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000800, mae: 0.016860, mean_q: 0.025752
 6462/10000: episode: 723, duration: 0.020s, episode steps: 4, steps per second: 199, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000326, mae: 0.012176, mean_q: 0.009208
 6466/10000: episode: 724, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000203, mae: 0.010265, mean_q: 0.015143
 6470/10000: episode: 725, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000376, mae: 0.012920, mean_q: 0.013502
 6474/10000: episode: 726, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000167, mae: 0.009638, mean_q: 0.014768
 6478/10000: episode: 727, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000950, mae: 0.017495, mean_q: 0.020951
 6482/10000: episode: 728, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000904, mae: 0.013301, mean_q: 0.018120
 6486/10000: episode: 729, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000460, mae: 0.013118, mean_q: 0.008170
 6490/10000: episode: 730, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000292, mae: 0.009777, mean_q: 0.015088
 6494/10000: episode: 731, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000339, mae: 0.012001, mean_q: 0.014414
 6498/10000: episode: 732, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000277, mae: 0.011465, mean_q: 0.008256
 6502/10000: episode: 733, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000750, mae: 0.015362, mean_q: 0.022463
 6508/10000: episode: 734, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001229, mae: 0.026525, mean_q: 0.004640
[Info] Complete ISplit Iteration
[Info] Levels: [0.02522629, 0.64762163]
[Info] Cond. Prob: [0.1, 0.01]
[Info] Error Prob: 0.001

 6512/10000: episode: 735, duration: 0.807s, episode steps: 4, steps per second: 5, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000428, mae: 0.022143, mean_q: 0.027339
 6522/10000: episode: 736, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000850, mae: 0.016903, mean_q: 0.011221
 6532/10000: episode: 737, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000592, mae: 0.018864, mean_q: 0.020622
 6542/10000: episode: 738, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000411, mae: 0.011639, mean_q: 0.015850
 6552/10000: episode: 739, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000494, mae: 0.013545, mean_q: 0.020149
 6562/10000: episode: 740, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000477, mae: 0.017745, mean_q: 0.017923
 6572/10000: episode: 741, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000219, mae: 0.009441, mean_q: 0.009681
 6582/10000: episode: 742, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000100, mae: 0.008058, mean_q: 0.011492
 6592/10000: episode: 743, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000248, mae: 0.009732, mean_q: 0.016193
 6602/10000: episode: 744, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000324, mae: 0.010235, mean_q: 0.010612
 6612/10000: episode: 745, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000284, mae: 0.010086, mean_q: 0.009183
 6622/10000: episode: 746, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000195, mae: 0.009362, mean_q: 0.010584
 6632/10000: episode: 747, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000208, mae: 0.011282, mean_q: 0.012831
 6642/10000: episode: 748, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000289, mae: 0.011455, mean_q: 0.010990
 6652/10000: episode: 749, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000276, mae: 0.010506, mean_q: 0.009913
 6662/10000: episode: 750, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000939, mae: 0.017630, mean_q: 0.015254
 6672/10000: episode: 751, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000731, mae: 0.013907, mean_q: 0.015157
 6682/10000: episode: 752, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000535, mae: 0.016725, mean_q: 0.015925
 6692/10000: episode: 753, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000493, mae: 0.012008, mean_q: 0.018030
 6702/10000: episode: 754, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000620, mae: 0.013737, mean_q: 0.015557
 6712/10000: episode: 755, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000354, mae: 0.012828, mean_q: 0.012587
 6722/10000: episode: 756, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000339, mae: 0.011795, mean_q: 0.011317
 6732/10000: episode: 757, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000181, mae: 0.010089, mean_q: 0.011479
 6742/10000: episode: 758, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000375, mae: 0.010585, mean_q: 0.010433
 6752/10000: episode: 759, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000339, mae: 0.012743, mean_q: 0.010953
 6762/10000: episode: 760, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000232, mae: 0.012287, mean_q: 0.009673
 6772/10000: episode: 761, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000091, mae: 0.007299, mean_q: 0.008188
 6782/10000: episode: 762, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000246, mae: 0.011730, mean_q: 0.013462
 6792/10000: episode: 763, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000259, mae: 0.010529, mean_q: 0.011344
 6802/10000: episode: 764, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000215, mae: 0.008403, mean_q: 0.011952
 6812/10000: episode: 765, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000540, mae: 0.019023, mean_q: 0.012539
 6822/10000: episode: 766, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000737, mae: 0.021911, mean_q: 0.013094
 6832/10000: episode: 767, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000251, mae: 0.013360, mean_q: 0.010597
 6842/10000: episode: 768, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000247, mae: 0.011031, mean_q: 0.012962
 6852/10000: episode: 769, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000592, mae: 0.014491, mean_q: 0.019259
 6862/10000: episode: 770, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000297, mae: 0.013717, mean_q: 0.009882
 6872/10000: episode: 771, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000263, mae: 0.010965, mean_q: 0.015566
 6882/10000: episode: 772, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000326, mae: 0.011940, mean_q: 0.011110
 6892/10000: episode: 773, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000592, mae: 0.015878, mean_q: 0.015744
 6902/10000: episode: 774, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000203, mae: 0.009412, mean_q: 0.012001
 6912/10000: episode: 775, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000205, mae: 0.009778, mean_q: 0.010605
 6922/10000: episode: 776, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000848, mae: 0.018338, mean_q: 0.014524
 6932/10000: episode: 777, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000742, mae: 0.017644, mean_q: 0.017254
 6942/10000: episode: 778, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000346, mae: 0.015030, mean_q: 0.014994
 6952/10000: episode: 779, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000791, mae: 0.017384, mean_q: 0.015354
 6962/10000: episode: 780, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000613, mae: 0.017271, mean_q: 0.017763
 6972/10000: episode: 781, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000243, mae: 0.010884, mean_q: 0.013911
 6982/10000: episode: 782, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000702, mae: 0.011477, mean_q: 0.012890
 6992/10000: episode: 783, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000620, mae: 0.017802, mean_q: 0.013747
 7002/10000: episode: 784, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000497, mae: 0.013816, mean_q: 0.016177
 7012/10000: episode: 785, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000422, mae: 0.014273, mean_q: 0.012558
 7022/10000: episode: 786, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000388, mae: 0.013776, mean_q: 0.009378
 7032/10000: episode: 787, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000398, mae: 0.010815, mean_q: 0.015720
 7042/10000: episode: 788, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000191, mae: 0.009053, mean_q: 0.010082
 7052/10000: episode: 789, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000248, mae: 0.012376, mean_q: 0.012492
 7062/10000: episode: 790, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000367, mae: 0.010154, mean_q: 0.010828
 7072/10000: episode: 791, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000552, mae: 0.014859, mean_q: 0.011227
 7082/10000: episode: 792, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000195, mae: 0.010816, mean_q: 0.011769
 7092/10000: episode: 793, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000483, mae: 0.011674, mean_q: 0.008257
 7102/10000: episode: 794, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000764, mae: 0.016569, mean_q: 0.018336
 7112/10000: episode: 795, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000399, mae: 0.018251, mean_q: 0.019995
 7122/10000: episode: 796, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000345, mae: 0.012711, mean_q: 0.025195
 7132/10000: episode: 797, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000573, mae: 0.013697, mean_q: 0.013127
 7142/10000: episode: 798, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000909, mae: 0.019155, mean_q: 0.013506
 7152/10000: episode: 799, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000441, mae: 0.017632, mean_q: 0.011361
 7162/10000: episode: 800, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000411, mae: 0.014186, mean_q: 0.012341
 7172/10000: episode: 801, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000361, mae: 0.010820, mean_q: 0.012744
 7182/10000: episode: 802, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000229, mae: 0.010595, mean_q: 0.012022
 7192/10000: episode: 803, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000349, mae: 0.014568, mean_q: 0.019651
 7202/10000: episode: 804, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000316, mae: 0.010270, mean_q: 0.008970
 7212/10000: episode: 805, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000240, mae: 0.010715, mean_q: 0.014120
 7222/10000: episode: 806, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000471, mae: 0.012344, mean_q: 0.012282
 7232/10000: episode: 807, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000498, mae: 0.013827, mean_q: 0.012432
 7242/10000: episode: 808, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000520, mae: 0.014585, mean_q: 0.012512
 7252/10000: episode: 809, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000384, mae: 0.014740, mean_q: 0.013752
 7262/10000: episode: 810, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000255, mae: 0.010604, mean_q: 0.012984
 7272/10000: episode: 811, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000454, mae: 0.010917, mean_q: 0.011615
 7282/10000: episode: 812, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000333, mae: 0.010654, mean_q: 0.011775
 7292/10000: episode: 813, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000918, mae: 0.018695, mean_q: 0.018822
 7302/10000: episode: 814, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000142, mae: 0.009364, mean_q: 0.008129
 7312/10000: episode: 815, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000628, mae: 0.015416, mean_q: 0.011542
 7322/10000: episode: 816, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000385, mae: 0.014685, mean_q: 0.010817
 7332/10000: episode: 817, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001021, mae: 0.015601, mean_q: 0.015464
 7342/10000: episode: 818, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000521, mae: 0.015547, mean_q: 0.016577
 7352/10000: episode: 819, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001147, mae: 0.017504, mean_q: 0.012595
 7362/10000: episode: 820, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000738, mae: 0.018054, mean_q: 0.018342
 7372/10000: episode: 821, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000661, mae: 0.013373, mean_q: 0.016392
 7382/10000: episode: 822, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000814, mae: 0.016673, mean_q: 0.020587
 7392/10000: episode: 823, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000783, mae: 0.021233, mean_q: 0.016325
 7402/10000: episode: 824, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000303, mae: 0.014662, mean_q: 0.009865
 7412/10000: episode: 825, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000526, mae: 0.014902, mean_q: 0.015685
 7422/10000: episode: 826, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000358, mae: 0.011940, mean_q: 0.015163
 7432/10000: episode: 827, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000677, mae: 0.013613, mean_q: 0.012800
 7442/10000: episode: 828, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000342, mae: 0.015277, mean_q: 0.013759
 7452/10000: episode: 829, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000443, mae: 0.014082, mean_q: 0.011845
 7462/10000: episode: 830, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000480, mae: 0.014045, mean_q: 0.017488
 7472/10000: episode: 831, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000234, mae: 0.011939, mean_q: 0.013379
 7482/10000: episode: 832, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000282, mae: 0.012825, mean_q: 0.013782
 7492/10000: episode: 833, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000510, mae: 0.010916, mean_q: 0.017259
 7502/10000: episode: 834, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000191, mae: 0.010614, mean_q: 0.009935
[Info] 1-TH LEVEL FOUND: 0.04186324030160904, Considering 14/100 traces
 7512/10000: episode: 835, duration: 0.704s, episode steps: 10, steps per second: 14, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000437, mae: 0.013109, mean_q: 0.020105
 7516/10000: episode: 836, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001399, mae: 0.021711, mean_q: 0.024685
 7523/10000: episode: 837, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000579, mae: 0.012824, mean_q: 0.018397
 7527/10000: episode: 838, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000248, mae: 0.013852, mean_q: 0.021331
 7534/10000: episode: 839, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000247, mae: 0.011795, mean_q: 0.006687
 7541/10000: episode: 840, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000272, mae: 0.008594, mean_q: 0.007426
 7543/10000: episode: 841, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000349, mae: 0.008695, mean_q: 0.010302
 7545/10000: episode: 842, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000412, mae: 0.014331, mean_q: 0.002846
 7549/10000: episode: 843, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000218, mae: 0.012117, mean_q: 0.015862
 7551/10000: episode: 844, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001057, mae: 0.019404, mean_q: 0.019892
 7553/10000: episode: 845, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000413, mae: 0.013759, mean_q: 0.006848
 7555/10000: episode: 846, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000300, mae: 0.013148, mean_q: 0.016901
 7562/10000: episode: 847, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000329, mae: 0.013545, mean_q: 0.013181
 7566/10000: episode: 848, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000778, mae: 0.017723, mean_q: 0.026436
 7570/10000: episode: 849, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000310, mae: 0.013933, mean_q: 0.015868
 7572/10000: episode: 850, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001147, mae: 0.014301, mean_q: 0.012143
 7574/10000: episode: 851, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001046, mae: 0.016997, mean_q: 0.041275
 7578/10000: episode: 852, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000743, mae: 0.018071, mean_q: 0.012188
 7585/10000: episode: 853, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000715, mae: 0.014796, mean_q: 0.011133
 7587/10000: episode: 854, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001099, mae: 0.023810, mean_q: 0.008928
 7594/10000: episode: 855, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000653, mae: 0.014666, mean_q: 0.015455
 7598/10000: episode: 856, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000521, mae: 0.018414, mean_q: 0.021137
 7602/10000: episode: 857, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001203, mae: 0.022726, mean_q: 0.023790
 7606/10000: episode: 858, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001567, mae: 0.020825, mean_q: 0.010492
 7608/10000: episode: 859, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001388, mae: 0.031694, mean_q: 0.043628
 7615/10000: episode: 860, duration: 0.032s, episode steps: 7, steps per second: 219, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000941, mae: 0.022767, mean_q: 0.014030
 7619/10000: episode: 861, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000418, mae: 0.013647, mean_q: 0.012107
 7626/10000: episode: 862, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000859, mae: 0.018379, mean_q: 0.019447
 7630/10000: episode: 863, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000705, mae: 0.022388, mean_q: 0.006322
 7632/10000: episode: 864, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001048, mae: 0.022572, mean_q: 0.032508
 7639/10000: episode: 865, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000718, mae: 0.013773, mean_q: 0.005700
 7643/10000: episode: 866, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000699, mae: 0.017996, mean_q: 0.022543
 7650/10000: episode: 867, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000538, mae: 0.016158, mean_q: 0.015711
 7652/10000: episode: 868, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000531, mae: 0.016439, mean_q: 0.006887
 7654/10000: episode: 869, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000361, mae: 0.013008, mean_q: 0.020362
 7656/10000: episode: 870, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000285, mae: 0.012809, mean_q: 0.018383
 7660/10000: episode: 871, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000181, mae: 0.011697, mean_q: 0.003551
 7662/10000: episode: 872, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000165, mae: 0.010867, mean_q: 0.019601
 7664/10000: episode: 873, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000134, mae: 0.010910, mean_q: 0.017618
 7671/10000: episode: 874, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000866, mae: 0.017178, mean_q: 0.008243
 7673/10000: episode: 875, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000077, mae: 0.008740, mean_q: 0.008493
 7677/10000: episode: 876, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000774, mae: 0.016014, mean_q: 0.016458
 7679/10000: episode: 877, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000203, mae: 0.014041, mean_q: 0.015298
 7683/10000: episode: 878, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000317, mae: 0.013262, mean_q: 0.005993
 7687/10000: episode: 879, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000280, mae: 0.012803, mean_q: 0.018457
 7689/10000: episode: 880, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000669, mae: 0.018176, mean_q: 0.003927
 7696/10000: episode: 881, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000376, mae: 0.014388, mean_q: 0.013587
 7700/10000: episode: 882, duration: 0.020s, episode steps: 4, steps per second: 198, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000467, mae: 0.016696, mean_q: 0.018661
 7702/10000: episode: 883, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000271, mae: 0.015371, mean_q: 0.025372
 7706/10000: episode: 884, duration: 0.020s, episode steps: 4, steps per second: 198, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000698, mae: 0.021047, mean_q: -0.000168
 7710/10000: episode: 885, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000685, mae: 0.017061, mean_q: 0.021180
 7712/10000: episode: 886, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000732, mae: 0.021380, mean_q: -0.006853
 7714/10000: episode: 887, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000221, mae: 0.016246, mean_q: 0.022622
 7718/10000: episode: 888, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000304, mae: 0.014072, mean_q: 0.009441
 7725/10000: episode: 889, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000134, mae: 0.009748, mean_q: 0.014630
 7727/10000: episode: 890, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000091, mae: 0.007588, mean_q: 0.008484
 7729/10000: episode: 891, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001542, mae: 0.020013, mean_q: 0.025964
 7733/10000: episode: 892, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000311, mae: 0.016051, mean_q: 0.014772
 7735/10000: episode: 893, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000383, mae: 0.018371, mean_q: 0.005757
 7739/10000: episode: 894, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000962, mae: 0.025064, mean_q: 0.034399
 7743/10000: episode: 895, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000576, mae: 0.019484, mean_q: 0.012043
 7745/10000: episode: 896, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001180, mae: 0.019122, mean_q: 0.039607
 7749/10000: episode: 897, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000161, mae: 0.010574, mean_q: 0.019265
 7753/10000: episode: 898, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000200, mae: 0.010740, mean_q: 0.015241
 7757/10000: episode: 899, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000187, mae: 0.010899, mean_q: 0.013852
 7764/10000: episode: 900, duration: 0.038s, episode steps: 7, steps per second: 184, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000643, mae: 0.014287, mean_q: 0.015508
 7768/10000: episode: 901, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001027, mae: 0.023069, mean_q: 0.026986
 7770/10000: episode: 902, duration: 0.015s, episode steps: 2, steps per second: 135, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000259, mae: 0.015655, mean_q: 0.032047
 7772/10000: episode: 903, duration: 0.015s, episode steps: 2, steps per second: 138, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000257, mae: 0.013084, mean_q: 0.001989
 7776/10000: episode: 904, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000893, mae: 0.018971, mean_q: 0.020728
 7778/10000: episode: 905, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000682, mae: 0.015422, mean_q: 0.009067
 7782/10000: episode: 906, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000592, mae: 0.019697, mean_q: 0.016304
 7786/10000: episode: 907, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000383, mae: 0.016348, mean_q: 0.019583
 7793/10000: episode: 908, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000397, mae: 0.017864, mean_q: 0.020427
 7795/10000: episode: 909, duration: 0.014s, episode steps: 2, steps per second: 140, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000301, mae: 0.014946, mean_q: 0.006829
 7802/10000: episode: 910, duration: 0.037s, episode steps: 7, steps per second: 189, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000220, mae: 0.011941, mean_q: 0.016019
 7806/10000: episode: 911, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001022, mae: 0.021146, mean_q: 0.003565
 7813/10000: episode: 912, duration: 0.038s, episode steps: 7, steps per second: 185, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000362, mae: 0.015643, mean_q: 0.015017
 7820/10000: episode: 913, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000478, mae: 0.013649, mean_q: 0.019091
 7822/10000: episode: 914, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000156, mae: 0.011770, mean_q: 0.004914
 7829/10000: episode: 915, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000681, mae: 0.019200, mean_q: 0.015928
 7836/10000: episode: 916, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000585, mae: 0.019910, mean_q: 0.018182
 7838/10000: episode: 917, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000393, mae: 0.013961, mean_q: 0.005549
 7842/10000: episode: 918, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000303, mae: 0.016836, mean_q: 0.021565
 7849/10000: episode: 919, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000906, mae: 0.015679, mean_q: 0.016752
 7853/10000: episode: 920, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000436, mae: 0.016737, mean_q: 0.013739
[Info] 2-TH LEVEL FOUND: 0.10880882292985916, Considering 14/100 traces
 7855/10000: episode: 921, duration: 0.749s, episode steps: 2, steps per second: 3, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000097, mae: 0.009180, mean_q: 0.017221
 7857/10000: episode: 922, duration: 0.017s, episode steps: 2, steps per second: 117, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000376, mae: 0.012262, mean_q: 0.013718
 7859/10000: episode: 923, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000153, mae: 0.010321, mean_q: 0.006990
 7861/10000: episode: 924, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000539, mae: 0.016965, mean_q: 0.019759
 7863/10000: episode: 925, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000229, mae: 0.010097, mean_q: 0.011881
 7865/10000: episode: 926, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001440, mae: 0.021211, mean_q: 0.031293
 7867/10000: episode: 927, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000354, mae: 0.016284, mean_q: 0.025110
 7869/10000: episode: 928, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000237, mae: 0.017291, mean_q: -0.004950
 7871/10000: episode: 929, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001752, mae: 0.019387, mean_q: 0.018828
 7873/10000: episode: 930, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000274, mae: 0.012097, mean_q: 0.004062
 7875/10000: episode: 931, duration: 0.016s, episode steps: 2, steps per second: 122, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001568, mae: 0.024338, mean_q: 0.035546
 7877/10000: episode: 932, duration: 0.017s, episode steps: 2, steps per second: 119, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000804, mae: 0.019436, mean_q: 0.024420
 7879/10000: episode: 933, duration: 0.016s, episode steps: 2, steps per second: 126, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000307, mae: 0.013619, mean_q: -0.000365
 7881/10000: episode: 934, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001056, mae: 0.019129, mean_q: 0.022185
 7883/10000: episode: 935, duration: 0.014s, episode steps: 2, steps per second: 139, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001319, mae: 0.021099, mean_q: 0.034315
 7885/10000: episode: 936, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000316, mae: 0.011922, mean_q: 0.011656
 7887/10000: episode: 937, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001189, mae: 0.020965, mean_q: 0.031927
 7889/10000: episode: 938, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000150, mae: 0.008961, mean_q: 0.012156
 7891/10000: episode: 939, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000340, mae: 0.014813, mean_q: 0.002538
 7893/10000: episode: 940, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000145, mae: 0.008536, mean_q: 0.012900
 7895/10000: episode: 941, duration: 0.017s, episode steps: 2, steps per second: 119, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000593, mae: 0.011715, mean_q: 0.014465
 7899/10000: episode: 942, duration: 0.027s, episode steps: 4, steps per second: 150, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000343, mae: 0.011713, mean_q: 0.016770
 7901/10000: episode: 943, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000169, mae: 0.009895, mean_q: 0.013965
 7903/10000: episode: 944, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001041, mae: 0.019975, mean_q: 0.018730
 7905/10000: episode: 945, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000707, mae: 0.018071, mean_q: 0.028662
 7907/10000: episode: 946, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000627, mae: 0.015011, mean_q: 0.019486
 7909/10000: episode: 947, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000203, mae: 0.011563, mean_q: 0.015686
 7911/10000: episode: 948, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000377, mae: 0.012464, mean_q: 0.013579
 7913/10000: episode: 949, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000062, mae: 0.007859, mean_q: 0.001883
 7915/10000: episode: 950, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001195, mae: 0.018445, mean_q: 0.033789
 7917/10000: episode: 951, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000377, mae: 0.012078, mean_q: 0.016527
 7919/10000: episode: 952, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000328, mae: 0.013820, mean_q: 0.007227
 7923/10000: episode: 953, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000272, mae: 0.011711, mean_q: 0.019835
 7925/10000: episode: 954, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000206, mae: 0.013069, mean_q: 0.003596
 7927/10000: episode: 955, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000753, mae: 0.011599, mean_q: 0.010167
 7929/10000: episode: 956, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000302, mae: 0.014157, mean_q: 0.010001
 7933/10000: episode: 957, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000180, mae: 0.011849, mean_q: 0.011731
 7935/10000: episode: 958, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000492, mae: 0.012339, mean_q: 0.010168
 7937/10000: episode: 959, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000217, mae: 0.015152, mean_q: -0.005245
 7939/10000: episode: 960, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000970, mae: 0.021218, mean_q: 0.027127
 7941/10000: episode: 961, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000977, mae: 0.025059, mean_q: 0.033360
 7943/10000: episode: 962, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000373, mae: 0.013770, mean_q: 0.004575
 7945/10000: episode: 963, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000416, mae: 0.018457, mean_q: 0.001313
 7947/10000: episode: 964, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000180, mae: 0.014870, mean_q: 0.020905
 7949/10000: episode: 965, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000240, mae: 0.010029, mean_q: 0.008020
 7951/10000: episode: 966, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000844, mae: 0.018013, mean_q: 0.018568
 7953/10000: episode: 967, duration: 0.025s, episode steps: 2, steps per second: 80, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000276, mae: 0.011347, mean_q: 0.016100
 7957/10000: episode: 968, duration: 0.037s, episode steps: 4, steps per second: 107, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000721, mae: 0.014094, mean_q: 0.013628
 7959/10000: episode: 969, duration: 0.021s, episode steps: 2, steps per second: 94, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000103, mae: 0.008636, mean_q: 0.004144
 7961/10000: episode: 970, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000497, mae: 0.018445, mean_q: 0.025839
 7963/10000: episode: 971, duration: 0.017s, episode steps: 2, steps per second: 116, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000356, mae: 0.013976, mean_q: 0.014752
 7967/10000: episode: 972, duration: 0.032s, episode steps: 4, steps per second: 126, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000709, mae: 0.017149, mean_q: 0.015095
 7969/10000: episode: 973, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001933, mae: 0.022931, mean_q: 0.028090
[Info] FALSIFICATION!
 7972/10000: episode: 974, duration: 0.262s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000751, mae: 0.016530, mean_q: 0.013993
 7974/10000: episode: 975, duration: 0.034s, episode steps: 2, steps per second: 58, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001274, mae: 0.024910, mean_q: 0.030980
 7976/10000: episode: 976, duration: 0.039s, episode steps: 2, steps per second: 51, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001182, mae: 0.016989, mean_q: 0.025837
 7978/10000: episode: 977, duration: 0.038s, episode steps: 2, steps per second: 52, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000381, mae: 0.016736, mean_q: 0.008394
 7980/10000: episode: 978, duration: 0.023s, episode steps: 2, steps per second: 86, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000485, mae: 0.016764, mean_q: 0.029092
 7982/10000: episode: 979, duration: 0.022s, episode steps: 2, steps per second: 91, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000083, mae: 0.006792, mean_q: 0.007466
 7984/10000: episode: 980, duration: 0.021s, episode steps: 2, steps per second: 93, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000279, mae: 0.011158, mean_q: 0.009692
 7986/10000: episode: 981, duration: 0.018s, episode steps: 2, steps per second: 110, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000228, mae: 0.012197, mean_q: 0.019962
 7988/10000: episode: 982, duration: 0.025s, episode steps: 2, steps per second: 81, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001035, mae: 0.023830, mean_q: 0.006365
 7990/10000: episode: 983, duration: 0.035s, episode steps: 2, steps per second: 58, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000360, mae: 0.013664, mean_q: 0.011905
 7994/10000: episode: 984, duration: 0.042s, episode steps: 4, steps per second: 95, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001000, mae: 0.022787, mean_q: 0.027243
 7996/10000: episode: 985, duration: 0.029s, episode steps: 2, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000362, mae: 0.022577, mean_q: -0.015202
 7998/10000: episode: 986, duration: 0.027s, episode steps: 2, steps per second: 73, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000911, mae: 0.030796, mean_q: 0.038399
 8000/10000: episode: 987, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000463, mae: 0.019356, mean_q: 0.021049
 8002/10000: episode: 988, duration: 0.028s, episode steps: 2, steps per second: 73, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000492, mae: 0.024751, mean_q: -0.014132
 8004/10000: episode: 989, duration: 0.032s, episode steps: 2, steps per second: 63, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000225, mae: 0.013804, mean_q: 0.019345
 8006/10000: episode: 990, duration: 0.022s, episode steps: 2, steps per second: 90, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000256, mae: 0.015246, mean_q: 0.021233
 8008/10000: episode: 991, duration: 0.023s, episode steps: 2, steps per second: 85, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000801, mae: 0.017631, mean_q: 0.011583
 8010/10000: episode: 992, duration: 0.024s, episode steps: 2, steps per second: 84, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000435, mae: 0.015331, mean_q: 0.018408
 8012/10000: episode: 993, duration: 0.026s, episode steps: 2, steps per second: 78, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001151, mae: 0.020221, mean_q: 0.029922
 8014/10000: episode: 994, duration: 0.025s, episode steps: 2, steps per second: 79, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001022, mae: 0.024163, mean_q: 0.014990
 8016/10000: episode: 995, duration: 0.019s, episode steps: 2, steps per second: 108, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000748, mae: 0.017753, mean_q: 0.017547
 8018/10000: episode: 996, duration: 0.029s, episode steps: 2, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000223, mae: 0.012748, mean_q: 0.010657
 8020/10000: episode: 997, duration: 0.040s, episode steps: 2, steps per second: 50, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000345, mae: 0.017278, mean_q: 0.003378
 8024/10000: episode: 998, duration: 0.052s, episode steps: 4, steps per second: 77, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000767, mae: 0.021847, mean_q: 0.034241
 8026/10000: episode: 999, duration: 0.029s, episode steps: 2, steps per second: 69, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000340, mae: 0.018082, mean_q: -0.002332
 8028/10000: episode: 1000, duration: 0.031s, episode steps: 2, steps per second: 64, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000497, mae: 0.021283, mean_q: 0.024778
 8030/10000: episode: 1001, duration: 0.024s, episode steps: 2, steps per second: 82, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000444, mae: 0.017842, mean_q: 0.022193
 8032/10000: episode: 1002, duration: 0.026s, episode steps: 2, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000440, mae: 0.024159, mean_q: -0.011570
 8034/10000: episode: 1003, duration: 0.025s, episode steps: 2, steps per second: 80, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000384, mae: 0.018615, mean_q: 0.022683
 8036/10000: episode: 1004, duration: 0.027s, episode steps: 2, steps per second: 74, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000884, mae: 0.021981, mean_q: 0.031293
 8038/10000: episode: 1005, duration: 0.034s, episode steps: 2, steps per second: 59, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001442, mae: 0.034196, mean_q: 0.008806
 8040/10000: episode: 1006, duration: 0.031s, episode steps: 2, steps per second: 65, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000823, mae: 0.029113, mean_q: 0.053320
[Info] Complete ISplit Iteration
[Info] Levels: [0.04186324, 0.10880882, 0.8760797]
[Info] Cond. Prob: [0.14, 0.14, 0.01]
[Info] Error Prob: 0.00019600000000000002

 8042/10000: episode: 1007, duration: 1.829s, episode steps: 2, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000303, mae: 0.016037, mean_q: 0.001833
 8052/10000: episode: 1008, duration: 0.101s, episode steps: 10, steps per second: 99, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000693, mae: 0.023519, mean_q: 0.014593
 8062/10000: episode: 1009, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000505, mae: 0.019342, mean_q: 0.009925
 8072/10000: episode: 1010, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000708, mae: 0.021791, mean_q: 0.014436
 8082/10000: episode: 1011, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000562, mae: 0.019281, mean_q: 0.014250
 8092/10000: episode: 1012, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001077, mae: 0.019791, mean_q: 0.025225
 8102/10000: episode: 1013, duration: 0.095s, episode steps: 10, steps per second: 106, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000635, mae: 0.015462, mean_q: 0.015799
 8112/10000: episode: 1014, duration: 0.095s, episode steps: 10, steps per second: 106, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000736, mae: 0.015663, mean_q: 0.012389
 8122/10000: episode: 1015, duration: 0.107s, episode steps: 10, steps per second: 94, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000307, mae: 0.014501, mean_q: 0.013242
 8132/10000: episode: 1016, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000382, mae: 0.013865, mean_q: 0.012412
 8142/10000: episode: 1017, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000429, mae: 0.013983, mean_q: 0.014422
 8152/10000: episode: 1018, duration: 0.083s, episode steps: 10, steps per second: 120, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000821, mae: 0.016674, mean_q: 0.015176
 8162/10000: episode: 1019, duration: 0.080s, episode steps: 10, steps per second: 126, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000552, mae: 0.017891, mean_q: 0.019364
 8172/10000: episode: 1020, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000841, mae: 0.024064, mean_q: 0.013860
 8182/10000: episode: 1021, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000460, mae: 0.018970, mean_q: 0.017869
 8192/10000: episode: 1022, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000432, mae: 0.012439, mean_q: 0.013123
 8202/10000: episode: 1023, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000407, mae: 0.012157, mean_q: 0.010756
 8212/10000: episode: 1024, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000513, mae: 0.016520, mean_q: 0.012027
 8222/10000: episode: 1025, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000727, mae: 0.021779, mean_q: 0.019726
 8232/10000: episode: 1026, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000718, mae: 0.018478, mean_q: 0.022248
 8242/10000: episode: 1027, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001100, mae: 0.028004, mean_q: 0.016152
 8252/10000: episode: 1028, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000805, mae: 0.018510, mean_q: 0.011534
 8262/10000: episode: 1029, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000905, mae: 0.019970, mean_q: 0.019729
 8272/10000: episode: 1030, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000565, mae: 0.018338, mean_q: 0.010569
 8282/10000: episode: 1031, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000496, mae: 0.015400, mean_q: 0.018759
 8292/10000: episode: 1032, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001320, mae: 0.024941, mean_q: 0.019370
 8302/10000: episode: 1033, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001169, mae: 0.024960, mean_q: 0.019475
 8312/10000: episode: 1034, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000775, mae: 0.023252, mean_q: 0.012633
 8322/10000: episode: 1035, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000253, mae: 0.012034, mean_q: 0.006844
 8332/10000: episode: 1036, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001850, mae: 0.023818, mean_q: 0.035007
 8342/10000: episode: 1037, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000793, mae: 0.016974, mean_q: 0.016551
 8352/10000: episode: 1038, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000641, mae: 0.016594, mean_q: 0.011867
 8362/10000: episode: 1039, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000279, mae: 0.012381, mean_q: 0.009609
 8372/10000: episode: 1040, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000494, mae: 0.014427, mean_q: 0.013123
 8382/10000: episode: 1041, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000489, mae: 0.013926, mean_q: 0.012517
 8392/10000: episode: 1042, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000413, mae: 0.011867, mean_q: 0.009995
 8402/10000: episode: 1043, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000564, mae: 0.017128, mean_q: 0.017639
 8412/10000: episode: 1044, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000489, mae: 0.015498, mean_q: 0.011327
 8422/10000: episode: 1045, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000290, mae: 0.014155, mean_q: 0.007270
 8432/10000: episode: 1046, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000542, mae: 0.016724, mean_q: 0.009963
 8442/10000: episode: 1047, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001005, mae: 0.019681, mean_q: 0.014155
 8452/10000: episode: 1048, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000267, mae: 0.015151, mean_q: 0.012620
 8462/10000: episode: 1049, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000529, mae: 0.015680, mean_q: 0.013184
 8472/10000: episode: 1050, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000849, mae: 0.018629, mean_q: 0.018495
 8482/10000: episode: 1051, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000630, mae: 0.017131, mean_q: 0.018385
 8492/10000: episode: 1052, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000796, mae: 0.018473, mean_q: 0.017201
 8502/10000: episode: 1053, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000736, mae: 0.016702, mean_q: 0.008627
 8512/10000: episode: 1054, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000224, mae: 0.013158, mean_q: 0.010726
 8522/10000: episode: 1055, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000605, mae: 0.014652, mean_q: 0.015258
 8532/10000: episode: 1056, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000567, mae: 0.011786, mean_q: 0.013984
 8542/10000: episode: 1057, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000222, mae: 0.011483, mean_q: 0.009018
 8552/10000: episode: 1058, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000298, mae: 0.010194, mean_q: 0.010598
 8562/10000: episode: 1059, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000571, mae: 0.018263, mean_q: 0.016877
 8572/10000: episode: 1060, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000409, mae: 0.011936, mean_q: 0.014134
 8582/10000: episode: 1061, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000597, mae: 0.017162, mean_q: 0.015135
 8592/10000: episode: 1062, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000707, mae: 0.019621, mean_q: 0.018861
 8602/10000: episode: 1063, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000483, mae: 0.019645, mean_q: 0.011484
 8612/10000: episode: 1064, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000674, mae: 0.020821, mean_q: 0.015490
 8622/10000: episode: 1065, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000440, mae: 0.016592, mean_q: 0.014509
 8632/10000: episode: 1066, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000838, mae: 0.016496, mean_q: 0.017519
 8642/10000: episode: 1067, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000625, mae: 0.020028, mean_q: 0.012634
 8652/10000: episode: 1068, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000466, mae: 0.017527, mean_q: 0.011101
 8662/10000: episode: 1069, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000673, mae: 0.014648, mean_q: 0.013434
 8672/10000: episode: 1070, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000572, mae: 0.014574, mean_q: 0.012376
 8682/10000: episode: 1071, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000320, mae: 0.014845, mean_q: 0.014974
 8692/10000: episode: 1072, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000412, mae: 0.015423, mean_q: 0.013053
 8702/10000: episode: 1073, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000986, mae: 0.019456, mean_q: 0.020448
 8712/10000: episode: 1074, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000289, mae: 0.012900, mean_q: 0.011369
 8722/10000: episode: 1075, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000317, mae: 0.012612, mean_q: 0.012256
 8732/10000: episode: 1076, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000543, mae: 0.014680, mean_q: 0.016785
 8742/10000: episode: 1077, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000316, mae: 0.011691, mean_q: 0.012273
 8752/10000: episode: 1078, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000541, mae: 0.014325, mean_q: 0.009691
 8762/10000: episode: 1079, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000489, mae: 0.020174, mean_q: 0.019381
 8772/10000: episode: 1080, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000672, mae: 0.017564, mean_q: 0.017644
 8782/10000: episode: 1081, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000448, mae: 0.015777, mean_q: 0.015328
 8792/10000: episode: 1082, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000295, mae: 0.011973, mean_q: 0.012378
 8802/10000: episode: 1083, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000478, mae: 0.013222, mean_q: 0.015539
 8812/10000: episode: 1084, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000952, mae: 0.019588, mean_q: 0.023239
 8822/10000: episode: 1085, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000281, mae: 0.012595, mean_q: 0.012044
 8832/10000: episode: 1086, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000368, mae: 0.012537, mean_q: 0.013095
 8842/10000: episode: 1087, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000492, mae: 0.013440, mean_q: 0.015986
 8852/10000: episode: 1088, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000262, mae: 0.011984, mean_q: 0.009161
 8862/10000: episode: 1089, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000646, mae: 0.015364, mean_q: 0.018596
 8872/10000: episode: 1090, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000503, mae: 0.013846, mean_q: 0.015859
 8882/10000: episode: 1091, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000623, mae: 0.014884, mean_q: 0.019849
 8892/10000: episode: 1092, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000597, mae: 0.017962, mean_q: 0.014678
 8902/10000: episode: 1093, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000722, mae: 0.017511, mean_q: 0.011806
 8912/10000: episode: 1094, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000518, mae: 0.014793, mean_q: 0.015662
 8922/10000: episode: 1095, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000702, mae: 0.013734, mean_q: 0.015524
 8932/10000: episode: 1096, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000373, mae: 0.016298, mean_q: 0.011604
 8942/10000: episode: 1097, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000434, mae: 0.016686, mean_q: 0.010157
 8952/10000: episode: 1098, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000454, mae: 0.016780, mean_q: 0.017484
 8962/10000: episode: 1099, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000375, mae: 0.016056, mean_q: 0.009422
 8972/10000: episode: 1100, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000384, mae: 0.011791, mean_q: 0.011199
 8982/10000: episode: 1101, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000459, mae: 0.012266, mean_q: 0.014035
 8992/10000: episode: 1102, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000511, mae: 0.017812, mean_q: 0.016671
 9002/10000: episode: 1103, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000433, mae: 0.015439, mean_q: 0.018064
 9012/10000: episode: 1104, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000173, mae: 0.010298, mean_q: 0.007586
 9022/10000: episode: 1105, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000426, mae: 0.011998, mean_q: 0.016695
 9032/10000: episode: 1106, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000356, mae: 0.014235, mean_q: 0.011727
[Info] 1-TH LEVEL FOUND: 0.01838795095682144, Considering 100/100 traces
 9042/10000: episode: 1107, duration: 0.700s, episode steps: 10, steps per second: 14, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000736, mae: 0.013772, mean_q: 0.013607
[Info] 2-TH LEVEL FOUND: 0.02020818367600441, Considering 100/100 traces
 9043/10000: episode: 1108, duration: 0.700s, episode steps: 1, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000086, mae: 0.007810, mean_q: 0.007181
[Info] 3-TH LEVEL FOUND: 0.02727314829826355, Considering 10/100 traces
 9044/10000: episode: 1109, duration: 0.676s, episode steps: 1, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.001934, mae: 0.018758, mean_q: 0.018507
 9048/10000: episode: 1110, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000412, mae: 0.016291, mean_q: 0.021868
 9050/10000: episode: 1111, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000202, mae: 0.013173, mean_q: 0.002714
 9052/10000: episode: 1112, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000341, mae: 0.011903, mean_q: 0.013432
 9054/10000: episode: 1113, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001134, mae: 0.021703, mean_q: 0.026267
 9056/10000: episode: 1114, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001191, mae: 0.015207, mean_q: 0.025618
 9058/10000: episode: 1115, duration: 0.017s, episode steps: 2, steps per second: 117, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001223, mae: 0.019482, mean_q: 0.019659
 9060/10000: episode: 1116, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000821, mae: 0.015314, mean_q: 0.018548
 9062/10000: episode: 1117, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000800, mae: 0.017393, mean_q: 0.020329
 9064/10000: episode: 1118, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000839, mae: 0.018649, mean_q: 0.027311
 9070/10000: episode: 1119, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000259, mae: 0.012183, mean_q: 0.007227
 9072/10000: episode: 1120, duration: 0.017s, episode steps: 2, steps per second: 121, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000367, mae: 0.015603, mean_q: 0.020026
 9074/10000: episode: 1121, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000125, mae: 0.010933, mean_q: -0.000123
 9076/10000: episode: 1122, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000181, mae: 0.009549, mean_q: 0.007309
 9078/10000: episode: 1123, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001560, mae: 0.013947, mean_q: 0.017804
 9080/10000: episode: 1124, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000215, mae: 0.011666, mean_q: 0.000181
 9082/10000: episode: 1125, duration: 0.014s, episode steps: 2, steps per second: 144, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000264, mae: 0.013267, mean_q: 0.017533
 9084/10000: episode: 1126, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000270, mae: 0.012886, mean_q: 0.012933
 9086/10000: episode: 1127, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000288, mae: 0.011989, mean_q: 0.011765
 9088/10000: episode: 1128, duration: 0.017s, episode steps: 2, steps per second: 120, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000119, mae: 0.010197, mean_q: 0.000973
 9092/10000: episode: 1129, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000549, mae: 0.013979, mean_q: 0.016656
 9094/10000: episode: 1130, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000171, mae: 0.009514, mean_q: 0.000523
 9096/10000: episode: 1131, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000093, mae: 0.006978, mean_q: 0.006863
 9098/10000: episode: 1132, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000301, mae: 0.014126, mean_q: 0.017661
 9102/10000: episode: 1133, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000225, mae: 0.009627, mean_q: 0.006179
 9104/10000: episode: 1134, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000278, mae: 0.010126, mean_q: 0.011979
 9106/10000: episode: 1135, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000414, mae: 0.011459, mean_q: 0.013262
 9108/10000: episode: 1136, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000697, mae: 0.013598, mean_q: 0.010268
 9110/10000: episode: 1137, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000154, mae: 0.012874, mean_q: 0.018323
 9114/10000: episode: 1138, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000335, mae: 0.015169, mean_q: 0.001205
 9116/10000: episode: 1139, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000364, mae: 0.016314, mean_q: 0.019853
 9122/10000: episode: 1140, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000263, mae: 0.013901, mean_q: 0.004158
 9128/10000: episode: 1141, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001057, mae: 0.016218, mean_q: 0.019670
 9130/10000: episode: 1142, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000264, mae: 0.013719, mean_q: 0.016693
 9136/10000: episode: 1143, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000284, mae: 0.014082, mean_q: 0.012014
 9138/10000: episode: 1144, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000074, mae: 0.007011, mean_q: 0.009443
 9140/10000: episode: 1145, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000481, mae: 0.016868, mean_q: 0.015846
 9142/10000: episode: 1146, duration: 0.015s, episode steps: 2, steps per second: 136, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000534, mae: 0.017386, mean_q: 0.001349
 9144/10000: episode: 1147, duration: 0.015s, episode steps: 2, steps per second: 134, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001440, mae: 0.017620, mean_q: 0.027931
 9150/10000: episode: 1148, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000646, mae: 0.020922, mean_q: 0.009327
 9152/10000: episode: 1149, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000439, mae: 0.016935, mean_q: 0.021967
 9154/10000: episode: 1150, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000086, mae: 0.007956, mean_q: 0.010020
 9158/10000: episode: 1151, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000616, mae: 0.015377, mean_q: 0.011975
 9160/10000: episode: 1152, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000321, mae: 0.013242, mean_q: 0.012770
 9162/10000: episode: 1153, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000052, mae: 0.005626, mean_q: 0.007187
 9164/10000: episode: 1154, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000214, mae: 0.009962, mean_q: 0.012138
 9166/10000: episode: 1155, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000166, mae: 0.009095, mean_q: 0.010660
 9172/10000: episode: 1156, duration: 0.032s, episode steps: 6, steps per second: 187, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000286, mae: 0.010076, mean_q: 0.009716
 9174/10000: episode: 1157, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000094, mae: 0.006231, mean_q: 0.007704
 9180/10000: episode: 1158, duration: 0.034s, episode steps: 6, steps per second: 176, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000711, mae: 0.014880, mean_q: 0.021846
 9186/10000: episode: 1159, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000139, mae: 0.009964, mean_q: 0.003153
 9188/10000: episode: 1160, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000416, mae: 0.008988, mean_q: 0.012646
 9190/10000: episode: 1161, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000279, mae: 0.011747, mean_q: 0.011187
 9192/10000: episode: 1162, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000035, mae: 0.005232, mean_q: 0.005765
 9198/10000: episode: 1163, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000769, mae: 0.017756, mean_q: 0.005626
 9200/10000: episode: 1164, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000438, mae: 0.016890, mean_q: 0.014035
 9202/10000: episode: 1165, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000180, mae: 0.014637, mean_q: 0.016176
 9208/10000: episode: 1166, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000261, mae: 0.012496, mean_q: 0.007920
 9210/10000: episode: 1167, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000226, mae: 0.011468, mean_q: 0.012923
 9212/10000: episode: 1168, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000139, mae: 0.007499, mean_q: 0.003351
 9214/10000: episode: 1169, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000124, mae: 0.013086, mean_q: 0.018990
[Info] FALSIFICATION!
 9219/10000: episode: 1170, duration: 0.187s, episode steps: 5, steps per second: 27, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000391, mae: 0.015969, mean_q: 0.013122
 9221/10000: episode: 1171, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000165, mae: 0.011047, mean_q: 0.010630
 9223/10000: episode: 1172, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000356, mae: 0.015434, mean_q: 0.020827
 9225/10000: episode: 1173, duration: 0.019s, episode steps: 2, steps per second: 103, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000376, mae: 0.018835, mean_q: -0.005569
 9227/10000: episode: 1174, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000096, mae: 0.008676, mean_q: 0.009053
 9229/10000: episode: 1175, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000382, mae: 0.016014, mean_q: 0.020825
 9231/10000: episode: 1176, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000316, mae: 0.015237, mean_q: 0.007838
 9233/10000: episode: 1177, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000784, mae: 0.016948, mean_q: 0.013198
 9239/10000: episode: 1178, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000233, mae: 0.013356, mean_q: 0.010488
 9241/10000: episode: 1179, duration: 0.020s, episode steps: 2, steps per second: 99, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000311, mae: 0.012826, mean_q: 0.015084
 9247/10000: episode: 1180, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000454, mae: 0.012336, mean_q: 0.011462
 9251/10000: episode: 1181, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000474, mae: 0.015391, mean_q: 0.017200
 9253/10000: episode: 1182, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000917, mae: 0.014624, mean_q: 0.013610
 9257/10000: episode: 1183, duration: 0.023s, episode steps: 4, steps per second: 178, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000329, mae: 0.014764, mean_q: 0.013205
 9259/10000: episode: 1184, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000167, mae: 0.010879, mean_q: 0.012255
 9265/10000: episode: 1185, duration: 0.032s, episode steps: 6, steps per second: 187, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000709, mae: 0.018802, mean_q: 0.014437
 9271/10000: episode: 1186, duration: 0.034s, episode steps: 6, steps per second: 179, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000398, mae: 0.016320, mean_q: 0.002012
 9273/10000: episode: 1187, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000352, mae: 0.019406, mean_q: 0.023968
 9279/10000: episode: 1188, duration: 0.032s, episode steps: 6, steps per second: 187, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000291, mae: 0.015240, mean_q: 0.001095
 9281/10000: episode: 1189, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000301, mae: 0.018230, mean_q: 0.027193
 9283/10000: episode: 1190, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000340, mae: 0.014007, mean_q: 0.014227
 9285/10000: episode: 1191, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000416, mae: 0.012905, mean_q: 0.007475
 9287/10000: episode: 1192, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000194, mae: 0.010446, mean_q: 0.026498
 9293/10000: episode: 1193, duration: 0.033s, episode steps: 6, steps per second: 181, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000167, mae: 0.010766, mean_q: 0.006126
 9295/10000: episode: 1194, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000273, mae: 0.016035, mean_q: 0.018907
 9297/10000: episode: 1195, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000257, mae: 0.016779, mean_q: -0.003989
 9303/10000: episode: 1196, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000925, mae: 0.016928, mean_q: 0.018041
 9305/10000: episode: 1197, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001757, mae: 0.025862, mean_q: 0.015228
 9309/10000: episode: 1198, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001411, mae: 0.027994, mean_q: 0.039993
[Info] Complete ISplit Iteration
[Info] Levels: [0.018387951, 0.020208184, 0.027273148, 0.9395114]
[Info] Cond. Prob: [1.0, 1.0, 0.1, 0.01]
[Info] Error Prob: 0.001

 9311/10000: episode: 1199, duration: 0.881s, episode steps: 2, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001113, mae: 0.028595, mean_q: -0.007877
 9321/10000: episode: 1200, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000517, mae: 0.016152, mean_q: 0.013444
 9331/10000: episode: 1201, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000600, mae: 0.016040, mean_q: 0.017819
 9341/10000: episode: 1202, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000357, mae: 0.011130, mean_q: 0.011899
 9351/10000: episode: 1203, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000341, mae: 0.010354, mean_q: 0.014733
 9361/10000: episode: 1204, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000228, mae: 0.011912, mean_q: 0.009990
 9371/10000: episode: 1205, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000294, mae: 0.012485, mean_q: 0.011622
 9381/10000: episode: 1206, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000330, mae: 0.014692, mean_q: 0.009088
 9391/10000: episode: 1207, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001278, mae: 0.022548, mean_q: 0.012665
 9401/10000: episode: 1208, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001008, mae: 0.022761, mean_q: 0.019626
 9411/10000: episode: 1209, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000591, mae: 0.013196, mean_q: 0.011156
 9421/10000: episode: 1210, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000504, mae: 0.013353, mean_q: 0.008798
 9431/10000: episode: 1211, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000259, mae: 0.011895, mean_q: 0.012784
 9441/10000: episode: 1212, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000206, mae: 0.010145, mean_q: 0.010621
 9451/10000: episode: 1213, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000275, mae: 0.009838, mean_q: 0.009050
 9461/10000: episode: 1214, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000248, mae: 0.009833, mean_q: 0.006656
 9471/10000: episode: 1215, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000333, mae: 0.011890, mean_q: 0.010567
 9481/10000: episode: 1216, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000675, mae: 0.011177, mean_q: 0.009273
 9491/10000: episode: 1217, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000349, mae: 0.015371, mean_q: 0.014391
 9501/10000: episode: 1218, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000628, mae: 0.016680, mean_q: 0.012588
 9511/10000: episode: 1219, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000518, mae: 0.019930, mean_q: 0.010858
 9521/10000: episode: 1220, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000695, mae: 0.021420, mean_q: 0.011552
 9531/10000: episode: 1221, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000400, mae: 0.017280, mean_q: 0.009610
 9541/10000: episode: 1222, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000743, mae: 0.019347, mean_q: 0.017759
 9551/10000: episode: 1223, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000422, mae: 0.017980, mean_q: 0.007673
 9561/10000: episode: 1224, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000532, mae: 0.016910, mean_q: 0.014900
 9571/10000: episode: 1225, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001268, mae: 0.023889, mean_q: 0.020263
 9581/10000: episode: 1226, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000453, mae: 0.016998, mean_q: 0.013239
 9591/10000: episode: 1227, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000229, mae: 0.010129, mean_q: 0.014650
 9601/10000: episode: 1228, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000919, mae: 0.011466, mean_q: 0.015305
 9611/10000: episode: 1229, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000689, mae: 0.019170, mean_q: 0.008192
 9621/10000: episode: 1230, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000550, mae: 0.013518, mean_q: 0.009244
 9631/10000: episode: 1231, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000622, mae: 0.021362, mean_q: 0.014767
 9641/10000: episode: 1232, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000385, mae: 0.014323, mean_q: 0.011957
 9651/10000: episode: 1233, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000609, mae: 0.013809, mean_q: 0.015490
 9661/10000: episode: 1234, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000328, mae: 0.012388, mean_q: 0.011350
 9671/10000: episode: 1235, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000309, mae: 0.011191, mean_q: 0.009291
 9681/10000: episode: 1236, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000605, mae: 0.017311, mean_q: 0.013728
 9691/10000: episode: 1237, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000278, mae: 0.011869, mean_q: 0.008434
 9701/10000: episode: 1238, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000386, mae: 0.013609, mean_q: 0.011000
 9711/10000: episode: 1239, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000421, mae: 0.012647, mean_q: 0.013949
 9721/10000: episode: 1240, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000512, mae: 0.017055, mean_q: 0.013325
 9731/10000: episode: 1241, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000470, mae: 0.015265, mean_q: 0.009958
 9741/10000: episode: 1242, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000229, mae: 0.011810, mean_q: 0.011044
 9751/10000: episode: 1243, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000768, mae: 0.016270, mean_q: 0.013322
 9761/10000: episode: 1244, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000617, mae: 0.023469, mean_q: 0.010358
 9771/10000: episode: 1245, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000449, mae: 0.018049, mean_q: 0.010197
 9781/10000: episode: 1246, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000341, mae: 0.014964, mean_q: 0.007125
 9791/10000: episode: 1247, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000550, mae: 0.018155, mean_q: 0.009878
 9801/10000: episode: 1248, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000507, mae: 0.013175, mean_q: 0.014099
 9811/10000: episode: 1249, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000493, mae: 0.012496, mean_q: 0.007588
 9821/10000: episode: 1250, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000701, mae: 0.016577, mean_q: 0.017033
 9831/10000: episode: 1251, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000254, mae: 0.010152, mean_q: 0.009379
 9841/10000: episode: 1252, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000612, mae: 0.015659, mean_q: 0.015050
 9851/10000: episode: 1253, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000399, mae: 0.014918, mean_q: 0.007806
 9861/10000: episode: 1254, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000371, mae: 0.012702, mean_q: 0.011765
 9871/10000: episode: 1255, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000168, mae: 0.008765, mean_q: 0.006401
 9881/10000: episode: 1256, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000368, mae: 0.013319, mean_q: 0.008631
 9891/10000: episode: 1257, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000498, mae: 0.016561, mean_q: 0.012188
 9901/10000: episode: 1258, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000251, mae: 0.014529, mean_q: 0.008617
 9911/10000: episode: 1259, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000350, mae: 0.013534, mean_q: 0.012928
 9921/10000: episode: 1260, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000276, mae: 0.011085, mean_q: 0.008810
 9931/10000: episode: 1261, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000308, mae: 0.012625, mean_q: 0.010471
 9941/10000: episode: 1262, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000303, mae: 0.010538, mean_q: 0.005461
 9951/10000: episode: 1263, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000759, mae: 0.019744, mean_q: 0.015667
 9961/10000: episode: 1264, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000755, mae: 0.019944, mean_q: 0.013097
 9971/10000: episode: 1265, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000337, mae: 0.016521, mean_q: 0.009475
 9981/10000: episode: 1266, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000810, mae: 0.020577, mean_q: 0.012609
 9991/10000: episode: 1267, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000581, mae: 0.015972, mean_q: 0.010192
done, took 64.581 seconds
[Info] End Importance Splitting. Falsification occurred 8 times.
