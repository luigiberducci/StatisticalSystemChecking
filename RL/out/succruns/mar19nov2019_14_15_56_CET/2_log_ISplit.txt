Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          (None, 2)                 0         
_________________________________________________________________
dense_1 (Dense)              (None, 16)                48        
_________________________________________________________________
dense_2 (Dense)              (None, 8)                 136       
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 9         
=================================================================
Total params: 193
Trainable params: 193
Non-trainable params: 0
_________________________________________________________________
None
[Info] Start Importance Splitting on succruns-v1.
Training for 10000 steps ...
   10/10000: episode: 1, duration: 0.083s, episode steps: 10, steps per second: 121, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   20/10000: episode: 2, duration: 0.009s, episode steps: 10, steps per second: 1056, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   30/10000: episode: 3, duration: 0.011s, episode steps: 10, steps per second: 936, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   40/10000: episode: 4, duration: 0.013s, episode steps: 10, steps per second: 777, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   50/10000: episode: 5, duration: 0.007s, episode steps: 10, steps per second: 1480, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   60/10000: episode: 6, duration: 0.007s, episode steps: 10, steps per second: 1417, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   70/10000: episode: 7, duration: 0.009s, episode steps: 10, steps per second: 1089, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   80/10000: episode: 8, duration: 0.007s, episode steps: 10, steps per second: 1450, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   90/10000: episode: 9, duration: 0.006s, episode steps: 10, steps per second: 1579, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  100/10000: episode: 10, duration: 0.011s, episode steps: 10, steps per second: 920, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  110/10000: episode: 11, duration: 0.006s, episode steps: 10, steps per second: 1623, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  120/10000: episode: 12, duration: 0.006s, episode steps: 10, steps per second: 1640, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  130/10000: episode: 13, duration: 0.006s, episode steps: 10, steps per second: 1609, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  140/10000: episode: 14, duration: 0.006s, episode steps: 10, steps per second: 1584, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  150/10000: episode: 15, duration: 0.006s, episode steps: 10, steps per second: 1608, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  160/10000: episode: 16, duration: 0.012s, episode steps: 10, steps per second: 869, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  170/10000: episode: 17, duration: 0.006s, episode steps: 10, steps per second: 1615, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  180/10000: episode: 18, duration: 0.006s, episode steps: 10, steps per second: 1642, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  190/10000: episode: 19, duration: 0.008s, episode steps: 10, steps per second: 1279, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  200/10000: episode: 20, duration: 0.014s, episode steps: 10, steps per second: 704, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  210/10000: episode: 21, duration: 0.010s, episode steps: 10, steps per second: 977, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  220/10000: episode: 22, duration: 0.008s, episode steps: 10, steps per second: 1329, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  230/10000: episode: 23, duration: 0.007s, episode steps: 10, steps per second: 1355, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  240/10000: episode: 24, duration: 0.007s, episode steps: 10, steps per second: 1400, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  250/10000: episode: 25, duration: 0.007s, episode steps: 10, steps per second: 1382, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  260/10000: episode: 26, duration: 0.007s, episode steps: 10, steps per second: 1386, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  270/10000: episode: 27, duration: 0.007s, episode steps: 10, steps per second: 1392, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  280/10000: episode: 28, duration: 0.007s, episode steps: 10, steps per second: 1411, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  290/10000: episode: 29, duration: 0.007s, episode steps: 10, steps per second: 1343, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  300/10000: episode: 30, duration: 0.007s, episode steps: 10, steps per second: 1415, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  310/10000: episode: 31, duration: 0.007s, episode steps: 10, steps per second: 1422, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  320/10000: episode: 32, duration: 0.007s, episode steps: 10, steps per second: 1369, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  330/10000: episode: 33, duration: 0.009s, episode steps: 10, steps per second: 1143, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  340/10000: episode: 34, duration: 0.007s, episode steps: 10, steps per second: 1339, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  350/10000: episode: 35, duration: 0.011s, episode steps: 10, steps per second: 943, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  360/10000: episode: 36, duration: 0.006s, episode steps: 10, steps per second: 1639, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  370/10000: episode: 37, duration: 0.008s, episode steps: 10, steps per second: 1232, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  380/10000: episode: 38, duration: 0.008s, episode steps: 10, steps per second: 1252, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  390/10000: episode: 39, duration: 0.009s, episode steps: 10, steps per second: 1087, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  400/10000: episode: 40, duration: 0.006s, episode steps: 10, steps per second: 1547, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  410/10000: episode: 41, duration: 0.006s, episode steps: 10, steps per second: 1643, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  420/10000: episode: 42, duration: 0.005s, episode steps: 10, steps per second: 2182, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  430/10000: episode: 43, duration: 0.004s, episode steps: 10, steps per second: 2246, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  440/10000: episode: 44, duration: 0.005s, episode steps: 10, steps per second: 2216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  450/10000: episode: 45, duration: 0.004s, episode steps: 10, steps per second: 2241, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  460/10000: episode: 46, duration: 0.009s, episode steps: 10, steps per second: 1136, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  470/10000: episode: 47, duration: 0.006s, episode steps: 10, steps per second: 1551, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  480/10000: episode: 48, duration: 0.006s, episode steps: 10, steps per second: 1628, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  490/10000: episode: 49, duration: 0.005s, episode steps: 10, steps per second: 1903, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  500/10000: episode: 50, duration: 0.005s, episode steps: 10, steps per second: 2038, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  510/10000: episode: 51, duration: 0.634s, episode steps: 10, steps per second: 16, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.035455, mae: 0.168778, mean_q: 0.331370
  520/10000: episode: 52, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.010755, mae: 0.079717, mean_q: 0.213214
  530/10000: episode: 53, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.008290, mae: 0.086551, mean_q: 0.151568
  540/10000: episode: 54, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.007325, mae: 0.087866, mean_q: 0.131594
  550/10000: episode: 55, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.006907, mae: 0.081390, mean_q: 0.136497
  560/10000: episode: 56, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.006142, mae: 0.076831, mean_q: 0.127990
  570/10000: episode: 57, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.004154, mae: 0.065464, mean_q: 0.122226
  580/10000: episode: 58, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.003695, mae: 0.053793, mean_q: 0.118485
  590/10000: episode: 59, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003860, mae: 0.053196, mean_q: 0.121646
  600/10000: episode: 60, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.003198, mae: 0.053347, mean_q: 0.104412
  610/10000: episode: 61, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002225, mae: 0.046057, mean_q: 0.087698
  620/10000: episode: 62, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001941, mae: 0.041805, mean_q: 0.091150
  630/10000: episode: 63, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.002008, mae: 0.037349, mean_q: 0.097036
  640/10000: episode: 64, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002049, mae: 0.038422, mean_q: 0.091196
  650/10000: episode: 65, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001941, mae: 0.040567, mean_q: 0.084200
  660/10000: episode: 66, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001629, mae: 0.036528, mean_q: 0.075325
  670/10000: episode: 67, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001296, mae: 0.032654, mean_q: 0.074410
  680/10000: episode: 68, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001206, mae: 0.032265, mean_q: 0.065662
  690/10000: episode: 69, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001143, mae: 0.029588, mean_q: 0.065991
  700/10000: episode: 70, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001316, mae: 0.031729, mean_q: 0.062165
  710/10000: episode: 71, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000867, mae: 0.026544, mean_q: 0.052994
  720/10000: episode: 72, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000740, mae: 0.024397, mean_q: 0.051800
  730/10000: episode: 73, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000727, mae: 0.023667, mean_q: 0.052389
  740/10000: episode: 74, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000505, mae: 0.019871, mean_q: 0.046692
  750/10000: episode: 75, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000658, mae: 0.021541, mean_q: 0.048051
  760/10000: episode: 76, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000514, mae: 0.020418, mean_q: 0.040912
  770/10000: episode: 77, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000416, mae: 0.017980, mean_q: 0.039135
  780/10000: episode: 78, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000451, mae: 0.018317, mean_q: 0.037497
  790/10000: episode: 79, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000370, mae: 0.016251, mean_q: 0.033770
  800/10000: episode: 80, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000309, mae: 0.014825, mean_q: 0.032949
  810/10000: episode: 81, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000347, mae: 0.015178, mean_q: 0.031998
  820/10000: episode: 82, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000311, mae: 0.014766, mean_q: 0.030289
  830/10000: episode: 83, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000353, mae: 0.015339, mean_q: 0.029288
  840/10000: episode: 84, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000240, mae: 0.012862, mean_q: 0.025037
  850/10000: episode: 85, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000223, mae: 0.013376, mean_q: 0.023880
  860/10000: episode: 86, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000158, mae: 0.011228, mean_q: 0.022600
  870/10000: episode: 87, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000247, mae: 0.012943, mean_q: 0.022539
  880/10000: episode: 88, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000233, mae: 0.011949, mean_q: 0.021601
  890/10000: episode: 89, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000143, mae: 0.010389, mean_q: 0.018268
  900/10000: episode: 90, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000118, mae: 0.009915, mean_q: 0.016021
  910/10000: episode: 91, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000123, mae: 0.009397, mean_q: 0.016312
  920/10000: episode: 92, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000164, mae: 0.009931, mean_q: 0.018449
  930/10000: episode: 93, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000184, mae: 0.011079, mean_q: 0.017252
  940/10000: episode: 94, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000093, mae: 0.008860, mean_q: 0.013908
  950/10000: episode: 95, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000102, mae: 0.008614, mean_q: 0.014639
  960/10000: episode: 96, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000157, mae: 0.010339, mean_q: 0.015250
  970/10000: episode: 97, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000113, mae: 0.009484, mean_q: 0.014073
  980/10000: episode: 98, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000134, mae: 0.009242, mean_q: 0.012696
  990/10000: episode: 99, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000080, mae: 0.007555, mean_q: 0.011965
 1000/10000: episode: 100, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000104, mae: 0.009017, mean_q: 0.013909
 1010/10000: episode: 101, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000115, mae: 0.007677, mean_q: 0.010848
 1020/10000: episode: 102, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000107, mae: 0.008622, mean_q: 0.010645
 1030/10000: episode: 103, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000147, mae: 0.009422, mean_q: 0.011327
 1040/10000: episode: 104, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000081, mae: 0.007299, mean_q: 0.010373
 1050/10000: episode: 105, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000079, mae: 0.007656, mean_q: 0.011010
 1060/10000: episode: 106, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000087, mae: 0.008174, mean_q: 0.010421
 1070/10000: episode: 107, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000059, mae: 0.007165, mean_q: 0.009344
 1080/10000: episode: 108, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000126, mae: 0.008856, mean_q: 0.010565
 1090/10000: episode: 109, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000103, mae: 0.008247, mean_q: 0.008255
 1100/10000: episode: 110, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000079, mae: 0.007583, mean_q: 0.009012
 1110/10000: episode: 111, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000101, mae: 0.008218, mean_q: 0.008354
 1120/10000: episode: 112, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000092, mae: 0.007709, mean_q: 0.008942
 1130/10000: episode: 113, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000074, mae: 0.007467, mean_q: 0.007610
 1140/10000: episode: 114, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000094, mae: 0.007593, mean_q: 0.008073
 1150/10000: episode: 115, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000074, mae: 0.006664, mean_q: 0.007832
 1160/10000: episode: 116, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000084, mae: 0.007690, mean_q: 0.008082
 1170/10000: episode: 117, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000103, mae: 0.007593, mean_q: 0.008141
 1180/10000: episode: 118, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000071, mae: 0.006865, mean_q: 0.006228
 1190/10000: episode: 119, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000035, mae: 0.005459, mean_q: 0.005244
 1200/10000: episode: 120, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000098, mae: 0.007967, mean_q: 0.007574
 1210/10000: episode: 121, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000077, mae: 0.007034, mean_q: 0.007308
 1220/10000: episode: 122, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000060, mae: 0.006452, mean_q: 0.005736
 1230/10000: episode: 123, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000076, mae: 0.007120, mean_q: 0.006294
 1240/10000: episode: 124, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000063, mae: 0.006580, mean_q: 0.007485
 1250/10000: episode: 125, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000077, mae: 0.006738, mean_q: 0.008146
 1260/10000: episode: 126, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000066, mae: 0.005930, mean_q: 0.007525
 1270/10000: episode: 127, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000050, mae: 0.006037, mean_q: 0.005701
 1280/10000: episode: 128, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000053, mae: 0.005849, mean_q: 0.005512
 1290/10000: episode: 129, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000052, mae: 0.005797, mean_q: 0.005702
 1300/10000: episode: 130, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000063, mae: 0.006436, mean_q: 0.006062
 1310/10000: episode: 131, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000032, mae: 0.005107, mean_q: 0.005020
 1320/10000: episode: 132, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000072, mae: 0.006748, mean_q: 0.007507
 1330/10000: episode: 133, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000055, mae: 0.006014, mean_q: 0.005834
 1340/10000: episode: 134, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000039, mae: 0.005457, mean_q: 0.005069
 1350/10000: episode: 135, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000069, mae: 0.006584, mean_q: 0.005340
 1360/10000: episode: 136, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000051, mae: 0.005642, mean_q: 0.005414
 1370/10000: episode: 137, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000044, mae: 0.005567, mean_q: 0.004780
 1380/10000: episode: 138, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000052, mae: 0.005497, mean_q: 0.005433
 1390/10000: episode: 139, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000037, mae: 0.004964, mean_q: 0.004971
 1400/10000: episode: 140, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000046, mae: 0.005222, mean_q: 0.005072
 1410/10000: episode: 141, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000045, mae: 0.005465, mean_q: 0.003902
 1420/10000: episode: 142, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000037, mae: 0.004813, mean_q: 0.003722
 1430/10000: episode: 143, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000037, mae: 0.004787, mean_q: 0.004919
 1440/10000: episode: 144, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000038, mae: 0.004854, mean_q: 0.005388
 1450/10000: episode: 145, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000053, mae: 0.005803, mean_q: 0.004460
 1460/10000: episode: 146, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000034, mae: 0.004927, mean_q: 0.004209
 1470/10000: episode: 147, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000044, mae: 0.005096, mean_q: 0.004969
 1480/10000: episode: 148, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000053, mae: 0.005589, mean_q: 0.005948
 1490/10000: episode: 149, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000046, mae: 0.005374, mean_q: 0.004309
[Info] 1-TH LEVEL FOUND: 0.042868755757808685, Considering 10/100 traces
 1500/10000: episode: 150, duration: 1.080s, episode steps: 10, steps per second: 9, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000034, mae: 0.005045, mean_q: 0.005543
[Info] FALSIFICATION!
 1504/10000: episode: 151, duration: 0.673s, episode steps: 4, steps per second: 6, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000038, mae: 0.005213, mean_q: 0.005945
 1508/10000: episode: 152, duration: 0.064s, episode steps: 4, steps per second: 62, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000031, mae: 0.004573, mean_q: 0.004827
 1512/10000: episode: 153, duration: 0.059s, episode steps: 4, steps per second: 68, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000055, mae: 0.005782, mean_q: 0.006623
 1514/10000: episode: 154, duration: 0.026s, episode steps: 2, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000036, mae: 0.005546, mean_q: 0.005793
 1516/10000: episode: 155, duration: 0.039s, episode steps: 2, steps per second: 52, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000050, mae: 0.005222, mean_q: 0.003829
 1518/10000: episode: 156, duration: 0.024s, episode steps: 2, steps per second: 83, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000039, mae: 0.004786, mean_q: 0.004039
 1520/10000: episode: 157, duration: 0.026s, episode steps: 2, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000094, mae: 0.008415, mean_q: 0.008012
 1522/10000: episode: 158, duration: 0.025s, episode steps: 2, steps per second: 79, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000044, mae: 0.004809, mean_q: 0.005406
 1526/10000: episode: 159, duration: 0.041s, episode steps: 4, steps per second: 98, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000038, mae: 0.005000, mean_q: 0.003625
 1528/10000: episode: 160, duration: 0.024s, episode steps: 2, steps per second: 84, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000127, mae: 0.006306, mean_q: 0.005589
 1530/10000: episode: 161, duration: 0.024s, episode steps: 2, steps per second: 82, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000079, mae: 0.006851, mean_q: 0.005489
 1532/10000: episode: 162, duration: 0.024s, episode steps: 2, steps per second: 82, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000188, mae: 0.009424, mean_q: 0.007983
 1534/10000: episode: 163, duration: 0.025s, episode steps: 2, steps per second: 79, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000178, mae: 0.008485, mean_q: 0.008062
 1536/10000: episode: 164, duration: 0.018s, episode steps: 2, steps per second: 112, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000156, mae: 0.007816, mean_q: 0.008467
 1538/10000: episode: 165, duration: 0.037s, episode steps: 2, steps per second: 53, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000792, mae: 0.011623, mean_q: 0.009349
 1543/10000: episode: 166, duration: 0.063s, episode steps: 5, steps per second: 80, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000047, mae: 0.005460, mean_q: 0.005411
 1547/10000: episode: 167, duration: 0.048s, episode steps: 4, steps per second: 83, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000069, mae: 0.006008, mean_q: 0.006418
 1551/10000: episode: 168, duration: 0.045s, episode steps: 4, steps per second: 88, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002573, mae: 0.012418, mean_q: 0.007580
 1555/10000: episode: 169, duration: 0.041s, episode steps: 4, steps per second: 98, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000293, mae: 0.011899, mean_q: 0.009265
 1557/10000: episode: 170, duration: 0.026s, episode steps: 2, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000165, mae: 0.007085, mean_q: 0.008141
 1559/10000: episode: 171, duration: 0.023s, episode steps: 2, steps per second: 88, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000128, mae: 0.008584, mean_q: 0.005667
 1561/10000: episode: 172, duration: 0.030s, episode steps: 2, steps per second: 66, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000097, mae: 0.008342, mean_q: 0.005674
 1563/10000: episode: 173, duration: 0.023s, episode steps: 2, steps per second: 87, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000080, mae: 0.007431, mean_q: 0.006688
 1565/10000: episode: 174, duration: 0.022s, episode steps: 2, steps per second: 92, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000557, mae: 0.009983, mean_q: 0.008292
 1569/10000: episode: 175, duration: 0.035s, episode steps: 4, steps per second: 116, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002478, mae: 0.012840, mean_q: 0.008890
 1571/10000: episode: 176, duration: 0.019s, episode steps: 2, steps per second: 103, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000306, mae: 0.012548, mean_q: 0.020344
 1573/10000: episode: 177, duration: 0.018s, episode steps: 2, steps per second: 114, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000208, mae: 0.010461, mean_q: 0.015102
 1575/10000: episode: 178, duration: 0.019s, episode steps: 2, steps per second: 106, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000098, mae: 0.006713, mean_q: 0.007301
 1577/10000: episode: 179, duration: 0.028s, episode steps: 2, steps per second: 72, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000244, mae: 0.011020, mean_q: 0.012892
 1579/10000: episode: 180, duration: 0.023s, episode steps: 2, steps per second: 85, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000095, mae: 0.007609, mean_q: 0.007181
 1583/10000: episode: 181, duration: 0.041s, episode steps: 4, steps per second: 97, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000143, mae: 0.009332, mean_q: 0.007501
 1585/10000: episode: 182, duration: 0.017s, episode steps: 2, steps per second: 115, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004260, mae: 0.019087, mean_q: 0.008819
 1587/10000: episode: 183, duration: 0.037s, episode steps: 2, steps per second: 54, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000181, mae: 0.009065, mean_q: 0.011457
 1589/10000: episode: 184, duration: 0.029s, episode steps: 2, steps per second: 68, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000051, mae: 0.004984, mean_q: 0.004683
 1591/10000: episode: 185, duration: 0.017s, episode steps: 2, steps per second: 118, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000074, mae: 0.007759, mean_q: 0.007663
 1596/10000: episode: 186, duration: 0.032s, episode steps: 5, steps per second: 155, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000139, mae: 0.007975, mean_q: 0.007787
 1598/10000: episode: 187, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000125, mae: 0.008108, mean_q: 0.007128
 1600/10000: episode: 188, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003795, mae: 0.015665, mean_q: 0.010151
 1602/10000: episode: 189, duration: 0.014s, episode steps: 2, steps per second: 138, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000223, mae: 0.008365, mean_q: 0.009549
 1606/10000: episode: 190, duration: 0.042s, episode steps: 4, steps per second: 94, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000284, mae: 0.010802, mean_q: 0.011573
 1608/10000: episode: 191, duration: 0.031s, episode steps: 2, steps per second: 65, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000094, mae: 0.008492, mean_q: 0.006613
 1610/10000: episode: 192, duration: 0.032s, episode steps: 2, steps per second: 62, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000078, mae: 0.006574, mean_q: 0.006280
 1612/10000: episode: 193, duration: 0.022s, episode steps: 2, steps per second: 91, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000162, mae: 0.010228, mean_q: 0.005502
 1614/10000: episode: 194, duration: 0.027s, episode steps: 2, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000089, mae: 0.007208, mean_q: 0.006813
 1619/10000: episode: 195, duration: 0.056s, episode steps: 5, steps per second: 89, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001741, mae: 0.013407, mean_q: 0.009549
 1621/10000: episode: 196, duration: 0.027s, episode steps: 2, steps per second: 74, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000283, mae: 0.012055, mean_q: 0.012043
 1625/10000: episode: 197, duration: 0.045s, episode steps: 4, steps per second: 89, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000473, mae: 0.011942, mean_q: 0.010808
 1629/10000: episode: 198, duration: 0.051s, episode steps: 4, steps per second: 79, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000133, mae: 0.009015, mean_q: 0.008048
 1634/10000: episode: 199, duration: 0.047s, episode steps: 5, steps per second: 106, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000339, mae: 0.009844, mean_q: 0.008940
 1636/10000: episode: 200, duration: 0.026s, episode steps: 2, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004324, mae: 0.023029, mean_q: 0.014430
 1638/10000: episode: 201, duration: 0.032s, episode steps: 2, steps per second: 62, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000337, mae: 0.013414, mean_q: 0.012685
 1640/10000: episode: 202, duration: 0.023s, episode steps: 2, steps per second: 87, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000161, mae: 0.007785, mean_q: 0.007592
[Info] FALSIFICATION!
 1644/10000: episode: 203, duration: 0.374s, episode steps: 4, steps per second: 11, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000288, mae: 0.009747, mean_q: 0.009365
 1648/10000: episode: 204, duration: 0.041s, episode steps: 4, steps per second: 96, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000211, mae: 0.009148, mean_q: 0.009259
 1650/10000: episode: 205, duration: 0.025s, episode steps: 2, steps per second: 81, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000187, mae: 0.009868, mean_q: 0.007536
 1652/10000: episode: 206, duration: 0.023s, episode steps: 2, steps per second: 88, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000245, mae: 0.009078, mean_q: 0.006894
 1654/10000: episode: 207, duration: 0.024s, episode steps: 2, steps per second: 84, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000040, mae: 0.005653, mean_q: 0.004240
 1656/10000: episode: 208, duration: 0.024s, episode steps: 2, steps per second: 84, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000252, mae: 0.010217, mean_q: 0.006195
 1658/10000: episode: 209, duration: 0.023s, episode steps: 2, steps per second: 88, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000857, mae: 0.016775, mean_q: 0.014173
 1662/10000: episode: 210, duration: 0.045s, episode steps: 4, steps per second: 88, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000091, mae: 0.006813, mean_q: 0.004308
 1667/10000: episode: 211, duration: 0.048s, episode steps: 5, steps per second: 105, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001747, mae: 0.013044, mean_q: 0.009437
 1671/10000: episode: 212, duration: 0.035s, episode steps: 4, steps per second: 115, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001870, mae: 0.012352, mean_q: 0.010381
 1675/10000: episode: 213, duration: 0.038s, episode steps: 4, steps per second: 105, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000384, mae: 0.011893, mean_q: 0.016867
 1680/10000: episode: 214, duration: 0.052s, episode steps: 5, steps per second: 95, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000558, mae: 0.014142, mean_q: 0.014072
 1682/10000: episode: 215, duration: 0.034s, episode steps: 2, steps per second: 59, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000520, mae: 0.012319, mean_q: 0.012096
 1686/10000: episode: 216, duration: 0.035s, episode steps: 4, steps per second: 113, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000178, mae: 0.008797, mean_q: 0.005557
 1688/10000: episode: 217, duration: 0.017s, episode steps: 2, steps per second: 118, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000239, mae: 0.008805, mean_q: 0.005888
 1690/10000: episode: 218, duration: 0.030s, episode steps: 2, steps per second: 68, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000311, mae: 0.010528, mean_q: 0.009427
 1692/10000: episode: 219, duration: 0.025s, episode steps: 2, steps per second: 80, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000041, mae: 0.006233, mean_q: 0.001681
 1694/10000: episode: 220, duration: 0.022s, episode steps: 2, steps per second: 91, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000263, mae: 0.009937, mean_q: 0.008642
 1696/10000: episode: 221, duration: 0.023s, episode steps: 2, steps per second: 87, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000230, mae: 0.009423, mean_q: 0.006109
 1698/10000: episode: 222, duration: 0.025s, episode steps: 2, steps per second: 80, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000288, mae: 0.011093, mean_q: 0.007631
 1700/10000: episode: 223, duration: 0.022s, episode steps: 2, steps per second: 92, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000216, mae: 0.011469, mean_q: 0.008299
 1702/10000: episode: 224, duration: 0.026s, episode steps: 2, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000201, mae: 0.009379, mean_q: 0.014229
 1706/10000: episode: 225, duration: 0.041s, episode steps: 4, steps per second: 99, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000119, mae: 0.007221, mean_q: 0.008785
 1708/10000: episode: 226, duration: 0.024s, episode steps: 2, steps per second: 82, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000178, mae: 0.010287, mean_q: 0.009539
 1710/10000: episode: 227, duration: 0.024s, episode steps: 2, steps per second: 84, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000508, mae: 0.012260, mean_q: 0.008075
 1712/10000: episode: 228, duration: 0.027s, episode steps: 2, steps per second: 74, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005118, mae: 0.022940, mean_q: 0.012216
 1716/10000: episode: 229, duration: 0.035s, episode steps: 4, steps per second: 115, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000076, mae: 0.007116, mean_q: 0.011261
 1718/10000: episode: 230, duration: 0.026s, episode steps: 2, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000339, mae: 0.011882, mean_q: 0.011538
 1720/10000: episode: 231, duration: 0.022s, episode steps: 2, steps per second: 89, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004273, mae: 0.023630, mean_q: 0.020322
 1722/10000: episode: 232, duration: 0.021s, episode steps: 2, steps per second: 97, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000324, mae: 0.010936, mean_q: 0.013602
 1726/10000: episode: 233, duration: 0.025s, episode steps: 4, steps per second: 160, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000197, mae: 0.008364, mean_q: 0.008167
 1728/10000: episode: 234, duration: 0.021s, episode steps: 2, steps per second: 95, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000307, mae: 0.009618, mean_q: 0.014779
 1730/10000: episode: 235, duration: 0.016s, episode steps: 2, steps per second: 125, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003941, mae: 0.024304, mean_q: 0.015121
 1732/10000: episode: 236, duration: 0.015s, episode steps: 2, steps per second: 132, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000269, mae: 0.008331, mean_q: 0.005349
 1734/10000: episode: 237, duration: 0.016s, episode steps: 2, steps per second: 125, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000162, mae: 0.010168, mean_q: 0.009305
 1738/10000: episode: 238, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000140, mae: 0.008423, mean_q: 0.006247
 1743/10000: episode: 239, duration: 0.034s, episode steps: 5, steps per second: 145, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001676, mae: 0.013805, mean_q: 0.012006
[Info] Complete ISplit Iteration
[Info] Levels: [0.042868756, 0.3828008]
[Info] Cond. Prob: [0.1, 0.02]
[Info] Error Prob: 0.002

 1745/10000: episode: 240, duration: 1.113s, episode steps: 2, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000057, mae: 0.006303, mean_q: 0.005463
 1755/10000: episode: 241, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000233, mae: 0.008897, mean_q: 0.009309
 1765/10000: episode: 242, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000261, mae: 0.009727, mean_q: 0.007291
 1775/10000: episode: 243, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000202, mae: 0.009485, mean_q: 0.008238
 1785/10000: episode: 244, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000169, mae: 0.008361, mean_q: 0.006551
 1795/10000: episode: 245, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001167, mae: 0.013187, mean_q: 0.012207
 1805/10000: episode: 246, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000458, mae: 0.011093, mean_q: 0.012850
 1815/10000: episode: 247, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000178, mae: 0.009238, mean_q: 0.007326
 1825/10000: episode: 248, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000352, mae: 0.011771, mean_q: 0.011197
 1835/10000: episode: 249, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000098, mae: 0.006442, mean_q: 0.005244
 1845/10000: episode: 250, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000086, mae: 0.006698, mean_q: 0.006240
 1855/10000: episode: 251, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000113, mae: 0.006569, mean_q: 0.007491
 1865/10000: episode: 252, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000096, mae: 0.005719, mean_q: 0.007103
 1875/10000: episode: 253, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001067, mae: 0.010041, mean_q: 0.010476
 1885/10000: episode: 254, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001018, mae: 0.010901, mean_q: 0.011793
 1895/10000: episode: 255, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000272, mae: 0.009326, mean_q: 0.009260
 1905/10000: episode: 256, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000229, mae: 0.008500, mean_q: 0.007247
 1915/10000: episode: 257, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000149, mae: 0.007430, mean_q: 0.008323
 1925/10000: episode: 258, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000166, mae: 0.006954, mean_q: 0.006007
 1935/10000: episode: 259, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000159, mae: 0.007534, mean_q: 0.007343
 1945/10000: episode: 260, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000520, mae: 0.011397, mean_q: 0.012530
 1955/10000: episode: 261, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001579, mae: 0.013975, mean_q: 0.014645
 1965/10000: episode: 262, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002062, mae: 0.017030, mean_q: 0.018135
 1975/10000: episode: 263, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000738, mae: 0.015115, mean_q: 0.016337
 1985/10000: episode: 264, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000231, mae: 0.008864, mean_q: 0.006816
 1995/10000: episode: 265, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001018, mae: 0.009879, mean_q: 0.007556
 2005/10000: episode: 266, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001685, mae: 0.012211, mean_q: 0.010378
 2015/10000: episode: 267, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000934, mae: 0.012307, mean_q: 0.013884
 2025/10000: episode: 268, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000226, mae: 0.007364, mean_q: 0.006699
 2035/10000: episode: 269, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000249, mae: 0.008037, mean_q: 0.008642
 2045/10000: episode: 270, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000106, mae: 0.005876, mean_q: 0.006385
 2055/10000: episode: 271, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000156, mae: 0.006835, mean_q: 0.006029
 2065/10000: episode: 272, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000321, mae: 0.008754, mean_q: 0.008331
 2075/10000: episode: 273, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000281, mae: 0.007715, mean_q: 0.007125
 2085/10000: episode: 274, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000977, mae: 0.009709, mean_q: 0.008974
 2095/10000: episode: 275, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000190, mae: 0.006787, mean_q: 0.008811
 2105/10000: episode: 276, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000256, mae: 0.008151, mean_q: 0.008489
 2115/10000: episode: 277, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000275, mae: 0.008640, mean_q: 0.012040
 2125/10000: episode: 278, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000404, mae: 0.009971, mean_q: 0.009923
 2135/10000: episode: 279, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000211, mae: 0.007535, mean_q: 0.009518
 2145/10000: episode: 280, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000925, mae: 0.008977, mean_q: 0.008215
 2155/10000: episode: 281, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000289, mae: 0.008369, mean_q: 0.008675
 2165/10000: episode: 282, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000935, mae: 0.010079, mean_q: 0.013615
 2175/10000: episode: 283, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000192, mae: 0.007382, mean_q: 0.008918
 2185/10000: episode: 284, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000251, mae: 0.007915, mean_q: 0.009023
 2195/10000: episode: 285, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000821, mae: 0.008288, mean_q: 0.007168
 2205/10000: episode: 286, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000262, mae: 0.007859, mean_q: 0.009421
 2215/10000: episode: 287, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000269, mae: 0.008596, mean_q: 0.009335
 2225/10000: episode: 288, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000238, mae: 0.008196, mean_q: 0.009417
 2235/10000: episode: 289, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000128, mae: 0.006038, mean_q: 0.006453
 2245/10000: episode: 290, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000183, mae: 0.007339, mean_q: 0.007775
 2255/10000: episode: 291, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000159, mae: 0.006818, mean_q: 0.006935
 2265/10000: episode: 292, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000301, mae: 0.007627, mean_q: 0.006651
 2275/10000: episode: 293, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000869, mae: 0.007393, mean_q: 0.009031
 2285/10000: episode: 294, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000145, mae: 0.006741, mean_q: 0.006557
 2295/10000: episode: 295, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000157, mae: 0.006623, mean_q: 0.010986
 2305/10000: episode: 296, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000874, mae: 0.008393, mean_q: 0.007657
 2315/10000: episode: 297, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001345, mae: 0.008720, mean_q: 0.007826
 2325/10000: episode: 298, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000352, mae: 0.009355, mean_q: 0.012582
 2335/10000: episode: 299, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000245, mae: 0.007820, mean_q: 0.006833
 2345/10000: episode: 300, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000122, mae: 0.006312, mean_q: 0.008134
 2355/10000: episode: 301, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000982, mae: 0.008937, mean_q: 0.008463
 2365/10000: episode: 302, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000400, mae: 0.008871, mean_q: 0.011208
 2375/10000: episode: 303, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000184, mae: 0.006394, mean_q: 0.008539
 2385/10000: episode: 304, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000095, mae: 0.005655, mean_q: 0.007516
 2395/10000: episode: 305, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000852, mae: 0.008837, mean_q: 0.010702
 2405/10000: episode: 306, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000111, mae: 0.005330, mean_q: 0.009098
 2415/10000: episode: 307, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000123, mae: 0.005329, mean_q: 0.007972
 2425/10000: episode: 308, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000214, mae: 0.007567, mean_q: 0.006943
 2435/10000: episode: 309, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000831, mae: 0.009047, mean_q: 0.011632
 2445/10000: episode: 310, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000169, mae: 0.006529, mean_q: 0.007523
 2455/10000: episode: 311, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000103, mae: 0.005504, mean_q: 0.005770
 2465/10000: episode: 312, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000125, mae: 0.005348, mean_q: 0.006311
 2475/10000: episode: 313, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000106, mae: 0.005215, mean_q: 0.006801
 2485/10000: episode: 314, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000174, mae: 0.006590, mean_q: 0.006954
 2495/10000: episode: 315, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000935, mae: 0.008391, mean_q: 0.008510
 2505/10000: episode: 316, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001493, mae: 0.010794, mean_q: 0.009738
 2515/10000: episode: 317, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000254, mae: 0.007828, mean_q: 0.011022
 2525/10000: episode: 318, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001241, mae: 0.009931, mean_q: 0.009843
 2535/10000: episode: 319, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000229, mae: 0.007634, mean_q: 0.010515
 2545/10000: episode: 320, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000179, mae: 0.006254, mean_q: 0.008154
 2555/10000: episode: 321, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000055, mae: 0.004824, mean_q: 0.005730
 2565/10000: episode: 322, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000101, mae: 0.005344, mean_q: 0.004865
 2575/10000: episode: 323, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000876, mae: 0.008893, mean_q: 0.009699
 2585/10000: episode: 324, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000071, mae: 0.004782, mean_q: 0.005894
 2595/10000: episode: 325, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000899, mae: 0.008635, mean_q: 0.007675
 2605/10000: episode: 326, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000140, mae: 0.006486, mean_q: 0.006463
 2615/10000: episode: 327, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000746, mae: 0.008104, mean_q: 0.009599
 2625/10000: episode: 328, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000270, mae: 0.008012, mean_q: 0.010080
 2635/10000: episode: 329, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001371, mae: 0.010517, mean_q: 0.010702
 2645/10000: episode: 330, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000191, mae: 0.006317, mean_q: 0.007507
 2655/10000: episode: 331, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000567, mae: 0.005999, mean_q: 0.006522
 2665/10000: episode: 332, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000237, mae: 0.006887, mean_q: 0.007999
 2675/10000: episode: 333, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000746, mae: 0.008933, mean_q: 0.010155
 2685/10000: episode: 334, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000196, mae: 0.006218, mean_q: 0.006327
 2695/10000: episode: 335, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000150, mae: 0.005712, mean_q: 0.008156
 2705/10000: episode: 336, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000984, mae: 0.009280, mean_q: 0.008052
 2715/10000: episode: 337, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000670, mae: 0.007761, mean_q: 0.008132
 2725/10000: episode: 338, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000130, mae: 0.005739, mean_q: 0.005067
 2735/10000: episode: 339, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000283, mae: 0.007078, mean_q: 0.009047
[Info] 1-TH LEVEL FOUND: 0.02772379107773304, Considering 13/100 traces
 2745/10000: episode: 340, duration: 0.778s, episode steps: 10, steps per second: 13, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000772, mae: 0.007979, mean_q: 0.008418
 2753/10000: episode: 341, duration: 0.043s, episode steps: 8, steps per second: 185, episode reward: 0.032, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000117, mae: 0.005671, mean_q: 0.005256
 2761/10000: episode: 342, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.067, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000056, mae: 0.004824, mean_q: 0.007230
 2769/10000: episode: 343, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.263, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.938 [-1.000, 11.000], loss: 0.000597, mae: 0.009133, mean_q: 0.011720
 2777/10000: episode: 344, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000631, mae: 0.011003, mean_q: 0.010416
 2785/10000: episode: 345, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.812 [-1.000, 11.000], loss: 0.000087, mae: 0.005823, mean_q: 0.006988
 2793/10000: episode: 346, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.081, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000203, mae: 0.006519, mean_q: 0.007730
 2801/10000: episode: 347, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.082, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000422, mae: 0.009581, mean_q: 0.008410
 2809/10000: episode: 348, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000175, mae: 0.006876, mean_q: 0.011314
 2817/10000: episode: 349, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.035, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001041, mae: 0.012179, mean_q: 0.015349
 2825/10000: episode: 350, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.071, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000779, mae: 0.008959, mean_q: 0.008535
 2833/10000: episode: 351, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000386, mae: 0.008075, mean_q: 0.010623
 2841/10000: episode: 352, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.079, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001010, mae: 0.008804, mean_q: 0.007819
 2849/10000: episode: 353, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.102, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000090, mae: 0.005079, mean_q: 0.006933
 2857/10000: episode: 354, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.023, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000799, mae: 0.007632, mean_q: 0.007688
 2865/10000: episode: 355, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000204, mae: 0.006357, mean_q: 0.006862
 2873/10000: episode: 356, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.039, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000411, mae: 0.008179, mean_q: 0.009639
 2881/10000: episode: 357, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000808, mae: 0.009111, mean_q: 0.009771
 2889/10000: episode: 358, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.036, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000199, mae: 0.006294, mean_q: 0.007433
 2897/10000: episode: 359, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.038, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000739, mae: 0.007757, mean_q: 0.008585
 2905/10000: episode: 360, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.044, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000329, mae: 0.008009, mean_q: 0.009442
 2913/10000: episode: 361, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.079, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000178, mae: 0.007058, mean_q: 0.011359
 2921/10000: episode: 362, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000147, mae: 0.006186, mean_q: 0.005683
 2929/10000: episode: 363, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.098, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000094, mae: 0.005192, mean_q: 0.004393
 2937/10000: episode: 364, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.020, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000140, mae: 0.005987, mean_q: 0.006996
 2945/10000: episode: 365, duration: 0.043s, episode steps: 8, steps per second: 187, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.812 [-1.000, 11.000], loss: 0.000169, mae: 0.006371, mean_q: 0.006757
 2953/10000: episode: 366, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.081, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000129, mae: 0.006590, mean_q: 0.007047
 2961/10000: episode: 367, duration: 0.039s, episode steps: 8, steps per second: 208, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000143, mae: 0.006571, mean_q: 0.005513
 2969/10000: episode: 368, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.875 [-1.000, 11.000], loss: 0.000058, mae: 0.004483, mean_q: 0.006496
 2977/10000: episode: 369, duration: 0.037s, episode steps: 8, steps per second: 213, episode reward: 0.215, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000124, mae: 0.005614, mean_q: 0.006506
 2985/10000: episode: 370, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.097, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000105, mae: 0.005256, mean_q: 0.006214
 2993/10000: episode: 371, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001013, mae: 0.009054, mean_q: 0.008680
 3001/10000: episode: 372, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.036, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000085, mae: 0.005262, mean_q: 0.005702
 3009/10000: episode: 373, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.044, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.001020, mae: 0.012166, mean_q: 0.015554
 3017/10000: episode: 374, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.049, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000214, mae: 0.007617, mean_q: 0.007110
 3025/10000: episode: 375, duration: 0.039s, episode steps: 8, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000155, mae: 0.006663, mean_q: 0.007347
 3033/10000: episode: 376, duration: 0.039s, episode steps: 8, steps per second: 208, episode reward: 0.023, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000249, mae: 0.007319, mean_q: 0.007782
 3041/10000: episode: 377, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000187, mae: 0.007632, mean_q: 0.007297
 3049/10000: episode: 378, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000112, mae: 0.006663, mean_q: 0.008720
 3057/10000: episode: 379, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000223, mae: 0.008487, mean_q: 0.008046
 3065/10000: episode: 380, duration: 0.039s, episode steps: 8, steps per second: 208, episode reward: 0.114, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000315, mae: 0.008667, mean_q: 0.009404
 3073/10000: episode: 381, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000132, mae: 0.006196, mean_q: 0.007010
 3081/10000: episode: 382, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000125, mae: 0.006311, mean_q: 0.007633
 3089/10000: episode: 383, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.134, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.002092, mae: 0.012611, mean_q: 0.010749
 3097/10000: episode: 384, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.013, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000694, mae: 0.008623, mean_q: 0.009016
 3105/10000: episode: 385, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.102, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000252, mae: 0.008893, mean_q: 0.012536
 3113/10000: episode: 386, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000386, mae: 0.009789, mean_q: 0.012958
 3121/10000: episode: 387, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.036, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000194, mae: 0.007120, mean_q: 0.006111
 3129/10000: episode: 388, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000144, mae: 0.007737, mean_q: 0.006911
 3137/10000: episode: 389, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.130, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.001298, mae: 0.011924, mean_q: 0.009071
 3145/10000: episode: 390, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.015, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000091, mae: 0.006730, mean_q: 0.009061
 3153/10000: episode: 391, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.130, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000088, mae: 0.006123, mean_q: 0.005482
[Info] FALSIFICATION!
 3160/10000: episode: 392, duration: 0.269s, episode steps: 7, steps per second: 26, episode reward: 1.581, mean reward: 0.226 [0.002, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.000 [4.000, 10.000], loss: 0.000162, mae: 0.007335, mean_q: 0.008798
 3168/10000: episode: 393, duration: 0.042s, episode steps: 8, steps per second: 191, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000091, mae: 0.006615, mean_q: 0.008064
 3176/10000: episode: 394, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.015, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000168, mae: 0.006443, mean_q: 0.006333
 3184/10000: episode: 395, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000101, mae: 0.007573, mean_q: 0.009818
 3192/10000: episode: 396, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.023, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000127, mae: 0.007333, mean_q: 0.006580
 3200/10000: episode: 397, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.039, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000118, mae: 0.006030, mean_q: 0.007706
 3208/10000: episode: 398, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.049, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000490, mae: 0.009035, mean_q: 0.007572
 3216/10000: episode: 399, duration: 0.037s, episode steps: 8, steps per second: 216, episode reward: 0.231, mean reward: 0.029 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.000194, mae: 0.007669, mean_q: 0.009584
 3224/10000: episode: 400, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000412, mae: 0.008720, mean_q: 0.010817
 3232/10000: episode: 401, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000252, mae: 0.007771, mean_q: 0.013710
 3240/10000: episode: 402, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000134, mae: 0.006717, mean_q: 0.008350
 3248/10000: episode: 403, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000166, mae: 0.006754, mean_q: 0.008245
 3256/10000: episode: 404, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.114, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000887, mae: 0.008079, mean_q: 0.006516
 3264/10000: episode: 405, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.044, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000099, mae: 0.006147, mean_q: 0.008902
 3272/10000: episode: 406, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.036, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000233, mae: 0.007810, mean_q: 0.007932
 3280/10000: episode: 407, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.348, mean reward: 0.044 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000810, mae: 0.008079, mean_q: 0.009653
 3288/10000: episode: 408, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.065, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000992, mae: 0.010435, mean_q: 0.012645
 3296/10000: episode: 409, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000209, mae: 0.007491, mean_q: 0.011296
 3304/10000: episode: 410, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000883, mae: 0.009816, mean_q: 0.011769
 3312/10000: episode: 411, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.059, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000247, mae: 0.008224, mean_q: 0.009143
 3320/10000: episode: 412, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000361, mae: 0.008845, mean_q: 0.009438
 3328/10000: episode: 413, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.044, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000264, mae: 0.009025, mean_q: 0.009900
 3336/10000: episode: 414, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.177, mean reward: 0.022 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.001149, mae: 0.010200, mean_q: 0.009584
 3344/10000: episode: 415, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.023, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000196, mae: 0.006821, mean_q: 0.009645
 3352/10000: episode: 416, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.033, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000317, mae: 0.007553, mean_q: 0.009887
 3360/10000: episode: 417, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.263, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.938 [-1.000, 11.000], loss: 0.000257, mae: 0.007821, mean_q: 0.010173
 3368/10000: episode: 418, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.030, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000920, mae: 0.008924, mean_q: 0.010356
 3376/10000: episode: 419, duration: 0.037s, episode steps: 8, steps per second: 216, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000249, mae: 0.007807, mean_q: 0.012612
 3384/10000: episode: 420, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.102, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000327, mae: 0.009377, mean_q: 0.012240
 3392/10000: episode: 421, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.102, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000304, mae: 0.010213, mean_q: 0.009807
 3400/10000: episode: 422, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.214, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000212, mae: 0.009262, mean_q: 0.010956
 3408/10000: episode: 423, duration: 0.039s, episode steps: 8, steps per second: 208, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000242, mae: 0.009377, mean_q: 0.012512
 3416/10000: episode: 424, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.032, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000215, mae: 0.008305, mean_q: 0.010699
 3424/10000: episode: 425, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.036, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000905, mae: 0.008903, mean_q: 0.009135
 3432/10000: episode: 426, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.022, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000292, mae: 0.009419, mean_q: 0.011052
[Info] Complete ISplit Iteration
[Info] Levels: [0.027723791, 0.48729765]
[Info] Cond. Prob: [0.13, 0.01]
[Info] Error Prob: 0.0013000000000000002

 3440/10000: episode: 427, duration: 0.827s, episode steps: 8, steps per second: 10, episode reward: 0.033, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000345, mae: 0.009219, mean_q: 0.012351
 3450/10000: episode: 428, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000787, mae: 0.010321, mean_q: 0.012414
 3460/10000: episode: 429, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000316, mae: 0.008888, mean_q: 0.011611
 3470/10000: episode: 430, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000239, mae: 0.007608, mean_q: 0.009870
 3480/10000: episode: 431, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000545, mae: 0.007371, mean_q: 0.010619
 3490/10000: episode: 432, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000481, mae: 0.010748, mean_q: 0.013508
 3500/10000: episode: 433, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000171, mae: 0.007809, mean_q: 0.009123
 3510/10000: episode: 434, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000142, mae: 0.007375, mean_q: 0.009287
 3520/10000: episode: 435, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000902, mae: 0.010230, mean_q: 0.009926
 3530/10000: episode: 436, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000214, mae: 0.008850, mean_q: 0.009313
 3540/10000: episode: 437, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000680, mae: 0.008875, mean_q: 0.009831
 3550/10000: episode: 438, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000535, mae: 0.009052, mean_q: 0.013585
 3560/10000: episode: 439, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000320, mae: 0.008636, mean_q: 0.011947
 3570/10000: episode: 440, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000735, mae: 0.010209, mean_q: 0.011434
 3580/10000: episode: 441, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000196, mae: 0.007864, mean_q: 0.010394
 3590/10000: episode: 442, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000189, mae: 0.007627, mean_q: 0.008044
 3600/10000: episode: 443, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000137, mae: 0.007439, mean_q: 0.006925
 3610/10000: episode: 444, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000158, mae: 0.006773, mean_q: 0.006623
 3620/10000: episode: 445, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000224, mae: 0.008368, mean_q: 0.007747
 3630/10000: episode: 446, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000122, mae: 0.007611, mean_q: 0.009020
 3640/10000: episode: 447, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000192, mae: 0.009199, mean_q: 0.010180
 3650/10000: episode: 448, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000951, mae: 0.011728, mean_q: 0.009118
 3660/10000: episode: 449, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000203, mae: 0.008217, mean_q: 0.010419
 3670/10000: episode: 450, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000170, mae: 0.007366, mean_q: 0.008685
 3680/10000: episode: 451, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000100, mae: 0.005781, mean_q: 0.006477
 3690/10000: episode: 452, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000452, mae: 0.008907, mean_q: 0.009120
 3700/10000: episode: 453, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000143, mae: 0.007196, mean_q: 0.008460
 3710/10000: episode: 454, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000088, mae: 0.005998, mean_q: 0.008038
 3720/10000: episode: 455, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000265, mae: 0.008855, mean_q: 0.013185
 3730/10000: episode: 456, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000151, mae: 0.007512, mean_q: 0.008618
 3740/10000: episode: 457, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000274, mae: 0.008166, mean_q: 0.009599
 3750/10000: episode: 458, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000156, mae: 0.007708, mean_q: 0.008816
 3760/10000: episode: 459, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000119, mae: 0.007028, mean_q: 0.007180
 3770/10000: episode: 460, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001602, mae: 0.011999, mean_q: 0.011026
 3780/10000: episode: 461, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000358, mae: 0.010052, mean_q: 0.012168
 3790/10000: episode: 462, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000206, mae: 0.008069, mean_q: 0.008575
 3800/10000: episode: 463, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000176, mae: 0.006403, mean_q: 0.009397
 3810/10000: episode: 464, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000765, mae: 0.009416, mean_q: 0.010819
 3820/10000: episode: 465, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000236, mae: 0.007742, mean_q: 0.012148
 3830/10000: episode: 466, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000257, mae: 0.009551, mean_q: 0.011811
 3840/10000: episode: 467, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000100, mae: 0.006964, mean_q: 0.007662
 3850/10000: episode: 468, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000113, mae: 0.007224, mean_q: 0.009635
 3860/10000: episode: 469, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000147, mae: 0.007211, mean_q: 0.008969
 3870/10000: episode: 470, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000049, mae: 0.004627, mean_q: 0.006332
 3880/10000: episode: 471, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000266, mae: 0.006459, mean_q: 0.008772
 3890/10000: episode: 472, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000145, mae: 0.005923, mean_q: 0.009124
 3900/10000: episode: 473, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000171, mae: 0.006250, mean_q: 0.009378
 3910/10000: episode: 474, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000225, mae: 0.006478, mean_q: 0.009912
 3920/10000: episode: 475, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000129, mae: 0.006449, mean_q: 0.008207
 3930/10000: episode: 476, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000106, mae: 0.005786, mean_q: 0.007424
 3940/10000: episode: 477, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000127, mae: 0.006761, mean_q: 0.006173
 3950/10000: episode: 478, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000116, mae: 0.006362, mean_q: 0.006773
 3960/10000: episode: 479, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000721, mae: 0.008069, mean_q: 0.007895
 3970/10000: episode: 480, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000198, mae: 0.007340, mean_q: 0.008830
 3980/10000: episode: 481, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000618, mae: 0.009095, mean_q: 0.012112
 3990/10000: episode: 482, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000207, mae: 0.007028, mean_q: 0.009207
 4000/10000: episode: 483, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000094, mae: 0.006413, mean_q: 0.007710
 4010/10000: episode: 484, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000148, mae: 0.007318, mean_q: 0.008375
 4020/10000: episode: 485, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000333, mae: 0.008151, mean_q: 0.009642
 4030/10000: episode: 486, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000842, mae: 0.008577, mean_q: 0.009740
 4040/10000: episode: 487, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000207, mae: 0.007453, mean_q: 0.008686
 4050/10000: episode: 488, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000139, mae: 0.005975, mean_q: 0.007110
 4060/10000: episode: 489, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000143, mae: 0.007724, mean_q: 0.010248
 4070/10000: episode: 490, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000205, mae: 0.007690, mean_q: 0.010619
 4080/10000: episode: 491, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000083, mae: 0.005872, mean_q: 0.005147
 4090/10000: episode: 492, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000283, mae: 0.008205, mean_q: 0.009667
 4100/10000: episode: 493, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000273, mae: 0.008753, mean_q: 0.011421
 4110/10000: episode: 494, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000110, mae: 0.006973, mean_q: 0.009483
 4120/10000: episode: 495, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000149, mae: 0.006862, mean_q: 0.005785
 4130/10000: episode: 496, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000159, mae: 0.007093, mean_q: 0.007207
 4140/10000: episode: 497, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000093, mae: 0.007816, mean_q: 0.010566
 4150/10000: episode: 498, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000393, mae: 0.011738, mean_q: 0.014752
 4160/10000: episode: 499, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000102, mae: 0.007032, mean_q: 0.007086
 4170/10000: episode: 500, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001313, mae: 0.011382, mean_q: 0.010263
 4180/10000: episode: 501, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000604, mae: 0.009559, mean_q: 0.013104
 4190/10000: episode: 502, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000638, mae: 0.009559, mean_q: 0.011834
 4200/10000: episode: 503, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000071, mae: 0.006087, mean_q: 0.005875
 4210/10000: episode: 504, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000653, mae: 0.009235, mean_q: 0.010950
 4220/10000: episode: 505, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000123, mae: 0.006283, mean_q: 0.007498
 4230/10000: episode: 506, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000084, mae: 0.005356, mean_q: 0.007071
 4240/10000: episode: 507, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000182, mae: 0.008149, mean_q: 0.010061
 4250/10000: episode: 508, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000260, mae: 0.008652, mean_q: 0.009327
 4260/10000: episode: 509, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000676, mae: 0.009396, mean_q: 0.008050
 4270/10000: episode: 510, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000140, mae: 0.008318, mean_q: 0.008422
 4280/10000: episode: 511, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000056, mae: 0.005694, mean_q: 0.007029
 4290/10000: episode: 512, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000120, mae: 0.007725, mean_q: 0.007003
 4300/10000: episode: 513, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000670, mae: 0.009529, mean_q: 0.010730
 4310/10000: episode: 514, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000295, mae: 0.007617, mean_q: 0.012304
 4320/10000: episode: 515, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000162, mae: 0.007198, mean_q: 0.009615
 4330/10000: episode: 516, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000226, mae: 0.006670, mean_q: 0.009526
 4340/10000: episode: 517, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000101, mae: 0.007116, mean_q: 0.007676
 4350/10000: episode: 518, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000130, mae: 0.007538, mean_q: 0.007687
 4360/10000: episode: 519, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000985, mae: 0.009606, mean_q: 0.009886
 4370/10000: episode: 520, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000695, mae: 0.012072, mean_q: 0.013478
 4380/10000: episode: 521, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000356, mae: 0.009846, mean_q: 0.014499
 4390/10000: episode: 522, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000132, mae: 0.007751, mean_q: 0.007013
 4400/10000: episode: 523, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000246, mae: 0.008874, mean_q: 0.010592
 4410/10000: episode: 524, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000144, mae: 0.006614, mean_q: 0.006652
 4420/10000: episode: 525, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000796, mae: 0.008439, mean_q: 0.008314
 4430/10000: episode: 526, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000664, mae: 0.009987, mean_q: 0.013152
[Info] 1-TH LEVEL FOUND: 0.04179500788450241, Considering 10/100 traces
 4440/10000: episode: 527, duration: 0.649s, episode steps: 10, steps per second: 15, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000158, mae: 0.006563, mean_q: 0.009069
 4444/10000: episode: 528, duration: 0.032s, episode steps: 4, steps per second: 125, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000046, mae: 0.005120, mean_q: 0.005842
 4448/10000: episode: 529, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000305, mae: 0.008820, mean_q: 0.011710
 4455/10000: episode: 530, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000055, mae: 0.005522, mean_q: 0.007636
 4459/10000: episode: 531, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001273, mae: 0.011606, mean_q: 0.011962
 4463/10000: episode: 532, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000051, mae: 0.005860, mean_q: 0.009307
 4470/10000: episode: 533, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000289, mae: 0.008188, mean_q: 0.012502
 4477/10000: episode: 534, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000272, mae: 0.008047, mean_q: 0.011370
 4484/10000: episode: 535, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000059, mae: 0.005025, mean_q: 0.006036
 4488/10000: episode: 536, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000092, mae: 0.005992, mean_q: 0.007607
 4492/10000: episode: 537, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000346, mae: 0.009672, mean_q: 0.011739
 4496/10000: episode: 538, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000238, mae: 0.008037, mean_q: 0.009991
 4503/10000: episode: 539, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000161, mae: 0.006452, mean_q: 0.009118
 4510/10000: episode: 540, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.001396, mae: 0.012980, mean_q: 0.016702
 4517/10000: episode: 541, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000180, mae: 0.008368, mean_q: 0.014518
 4521/10000: episode: 542, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000328, mae: 0.008515, mean_q: 0.012720
 4525/10000: episode: 543, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000394, mae: 0.010301, mean_q: 0.011577
 4532/10000: episode: 544, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000304, mae: 0.009314, mean_q: 0.014885
 4539/10000: episode: 545, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000313, mae: 0.010049, mean_q: 0.011359
 4546/10000: episode: 546, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000135, mae: 0.008265, mean_q: 0.009588
 4553/10000: episode: 547, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000405, mae: 0.008983, mean_q: 0.009169
 4557/10000: episode: 548, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000126, mae: 0.007819, mean_q: 0.004716
 4564/10000: episode: 549, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000174, mae: 0.009617, mean_q: 0.009918
 4568/10000: episode: 550, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000370, mae: 0.010399, mean_q: 0.014720
 4575/10000: episode: 551, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000095, mae: 0.006666, mean_q: 0.009460
 4582/10000: episode: 552, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000285, mae: 0.007347, mean_q: 0.009812
 4586/10000: episode: 553, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001174, mae: 0.011993, mean_q: 0.012055
 4593/10000: episode: 554, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000377, mae: 0.010280, mean_q: 0.013751
 4597/10000: episode: 555, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000226, mae: 0.008689, mean_q: 0.010197
 4604/10000: episode: 556, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000183, mae: 0.008129, mean_q: 0.007478
 4608/10000: episode: 557, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000268, mae: 0.010142, mean_q: 0.011213
 4612/10000: episode: 558, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000105, mae: 0.006779, mean_q: 0.008309
 4616/10000: episode: 559, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000204, mae: 0.008730, mean_q: 0.009571
 4623/10000: episode: 560, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000352, mae: 0.010356, mean_q: 0.012416
 4627/10000: episode: 561, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000137, mae: 0.009539, mean_q: 0.008391
 4631/10000: episode: 562, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000071, mae: 0.006058, mean_q: 0.007393
 4638/10000: episode: 563, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000298, mae: 0.009563, mean_q: 0.011252
 4642/10000: episode: 564, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000149, mae: 0.007646, mean_q: 0.010496
 4649/10000: episode: 565, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000218, mae: 0.008722, mean_q: 0.012104
 4653/10000: episode: 566, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000205, mae: 0.007518, mean_q: 0.009573
 4657/10000: episode: 567, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001554, mae: 0.013723, mean_q: 0.013912
 4664/10000: episode: 568, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000171, mae: 0.008399, mean_q: 0.009257
 4668/10000: episode: 569, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000422, mae: 0.010706, mean_q: 0.010156
 4672/10000: episode: 570, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001584, mae: 0.017165, mean_q: 0.020038
 4676/10000: episode: 571, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000047, mae: 0.006856, mean_q: 0.016368
 4680/10000: episode: 572, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000293, mae: 0.010903, mean_q: 0.010384
 4687/10000: episode: 573, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000215, mae: 0.008106, mean_q: 0.010762
 4691/10000: episode: 574, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000126, mae: 0.006909, mean_q: 0.009930
 4695/10000: episode: 575, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000286, mae: 0.010304, mean_q: 0.014599
 4702/10000: episode: 576, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000335, mae: 0.009482, mean_q: 0.013987
 4706/10000: episode: 577, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000285, mae: 0.010525, mean_q: 0.014194
 4713/10000: episode: 578, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000180, mae: 0.008327, mean_q: 0.009324
 4720/10000: episode: 579, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000224, mae: 0.009809, mean_q: 0.011445
 4727/10000: episode: 580, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000310, mae: 0.010747, mean_q: 0.011812
 4731/10000: episode: 581, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000281, mae: 0.010536, mean_q: 0.014095
 4738/10000: episode: 582, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000255, mae: 0.009041, mean_q: 0.009806
 4745/10000: episode: 583, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000316, mae: 0.008568, mean_q: 0.011702
 4749/10000: episode: 584, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000073, mae: 0.006829, mean_q: 0.010053
 4753/10000: episode: 585, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000319, mae: 0.011414, mean_q: 0.017824
 4760/10000: episode: 586, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000238, mae: 0.009704, mean_q: 0.013897
 4764/10000: episode: 587, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000383, mae: 0.010147, mean_q: 0.013976
 4771/10000: episode: 588, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000757, mae: 0.009151, mean_q: 0.011093
 4778/10000: episode: 589, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000227, mae: 0.010105, mean_q: 0.018858
 4782/10000: episode: 590, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000283, mae: 0.010939, mean_q: 0.010568
 4786/10000: episode: 591, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000632, mae: 0.014363, mean_q: 0.019513
 4790/10000: episode: 592, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000156, mae: 0.009580, mean_q: 0.016483
 4794/10000: episode: 593, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000166, mae: 0.009685, mean_q: 0.007518
 4801/10000: episode: 594, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000298, mae: 0.011254, mean_q: 0.016516
 4808/10000: episode: 595, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000462, mae: 0.011380, mean_q: 0.010597
 4815/10000: episode: 596, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000247, mae: 0.008939, mean_q: 0.013106
 4819/10000: episode: 597, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000309, mae: 0.010347, mean_q: 0.014797
 4823/10000: episode: 598, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000116, mae: 0.008483, mean_q: 0.013382
 4827/10000: episode: 599, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000145, mae: 0.007909, mean_q: 0.010276
 4834/10000: episode: 600, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000264, mae: 0.009086, mean_q: 0.010842
 4838/10000: episode: 601, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001367, mae: 0.010986, mean_q: 0.013021
 4845/10000: episode: 602, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000926, mae: 0.013197, mean_q: 0.017229
 4849/10000: episode: 603, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000168, mae: 0.008505, mean_q: 0.016261
 4853/10000: episode: 604, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001787, mae: 0.019515, mean_q: 0.021620
 4860/10000: episode: 605, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000678, mae: 0.016304, mean_q: 0.022973
 4864/10000: episode: 606, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000152, mae: 0.009598, mean_q: 0.007088
 4868/10000: episode: 607, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000308, mae: 0.010508, mean_q: 0.012628
 4875/10000: episode: 608, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000220, mae: 0.009337, mean_q: 0.012543
 4882/10000: episode: 609, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000294, mae: 0.008726, mean_q: 0.011327
 4886/10000: episode: 610, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002172, mae: 0.015588, mean_q: 0.013424
 4893/10000: episode: 611, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000847, mae: 0.010082, mean_q: 0.013987
 4897/10000: episode: 612, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000826, mae: 0.017631, mean_q: 0.018671
 4904/10000: episode: 613, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000951, mae: 0.013658, mean_q: 0.017971
 4908/10000: episode: 614, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000453, mae: 0.010192, mean_q: 0.011558
 4912/10000: episode: 615, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000355, mae: 0.009829, mean_q: 0.015442
 4919/10000: episode: 616, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000934, mae: 0.010450, mean_q: 0.013376
[Info] 2-TH LEVEL FOUND: 0.35143402218818665, Considering 10/100 traces
 4926/10000: episode: 617, duration: 0.661s, episode steps: 7, steps per second: 11, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001744, mae: 0.016097, mean_q: 0.018826
 4930/10000: episode: 618, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001092, mae: 0.014681, mean_q: 0.020334
 4934/10000: episode: 619, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000678, mae: 0.014189, mean_q: 0.025704
 4938/10000: episode: 620, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001685, mae: 0.017795, mean_q: 0.026516
[Info] FALSIFICATION!
 4941/10000: episode: 621, duration: 0.167s, episode steps: 3, steps per second: 18, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000257, mae: 0.010583, mean_q: 0.012401
 4945/10000: episode: 622, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000530, mae: 0.012646, mean_q: 0.017199
 4949/10000: episode: 623, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000403, mae: 0.012151, mean_q: 0.014634
 4953/10000: episode: 624, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000081, mae: 0.006467, mean_q: 0.006442
 4957/10000: episode: 625, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000238, mae: 0.011038, mean_q: 0.013250
 4961/10000: episode: 626, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000231, mae: 0.009237, mean_q: 0.010401
 4965/10000: episode: 627, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000129, mae: 0.008388, mean_q: 0.009445
 4969/10000: episode: 628, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000154, mae: 0.008021, mean_q: 0.010043
 4973/10000: episode: 629, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000227, mae: 0.008393, mean_q: 0.012829
 4977/10000: episode: 630, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000489, mae: 0.009440, mean_q: 0.012554
 4981/10000: episode: 631, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000945, mae: 0.016036, mean_q: 0.018609
 4985/10000: episode: 632, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000312, mae: 0.009702, mean_q: 0.016237
 4989/10000: episode: 633, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000097, mae: 0.007597, mean_q: 0.010523
 4993/10000: episode: 634, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000382, mae: 0.010228, mean_q: 0.013554
 4997/10000: episode: 635, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000827, mae: 0.016591, mean_q: 0.023677
 5001/10000: episode: 636, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000314, mae: 0.011081, mean_q: 0.015246
 5005/10000: episode: 637, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000403, mae: 0.009655, mean_q: 0.013448
[Info] FALSIFICATION!
 5008/10000: episode: 638, duration: 0.256s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000593, mae: 0.015071, mean_q: 0.024422
 5012/10000: episode: 639, duration: 0.026s, episode steps: 4, steps per second: 156, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000338, mae: 0.011489, mean_q: 0.018075
 5016/10000: episode: 640, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000185, mae: 0.007182, mean_q: 0.012166
 5020/10000: episode: 641, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000200, mae: 0.008208, mean_q: 0.014711
 5024/10000: episode: 642, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000356, mae: 0.012101, mean_q: 0.014433
 5028/10000: episode: 643, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000402, mae: 0.012863, mean_q: 0.018224
 5032/10000: episode: 644, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000660, mae: 0.012297, mean_q: 0.015617
 5036/10000: episode: 645, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000450, mae: 0.011021, mean_q: 0.013944
 5040/10000: episode: 646, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000186, mae: 0.009822, mean_q: 0.014603
 5044/10000: episode: 647, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000287, mae: 0.010203, mean_q: 0.012727
[Info] FALSIFICATION!
 5047/10000: episode: 648, duration: 0.258s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000227, mae: 0.010412, mean_q: 0.018905
 5051/10000: episode: 649, duration: 0.025s, episode steps: 4, steps per second: 158, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000407, mae: 0.011594, mean_q: 0.015184
 5055/10000: episode: 650, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001205, mae: 0.019165, mean_q: 0.025428
 5059/10000: episode: 651, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.004350, mae: 0.025296, mean_q: 0.027148
 5063/10000: episode: 652, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001357, mae: 0.021788, mean_q: 0.035746
 5067/10000: episode: 653, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000417, mae: 0.012736, mean_q: 0.026377
 5071/10000: episode: 654, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001645, mae: 0.016613, mean_q: 0.017990
 5075/10000: episode: 655, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000261, mae: 0.008036, mean_q: 0.010144
 5079/10000: episode: 656, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000644, mae: 0.013604, mean_q: 0.016361
 5083/10000: episode: 657, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000588, mae: 0.013730, mean_q: 0.019063
 5087/10000: episode: 658, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000553, mae: 0.015227, mean_q: 0.020131
 5091/10000: episode: 659, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000619, mae: 0.015116, mean_q: 0.022275
 5095/10000: episode: 660, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000151, mae: 0.008484, mean_q: 0.013878
 5099/10000: episode: 661, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000509, mae: 0.012424, mean_q: 0.018012
 5103/10000: episode: 662, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001542, mae: 0.018069, mean_q: 0.022116
 5107/10000: episode: 663, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000787, mae: 0.015788, mean_q: 0.024901
 5111/10000: episode: 664, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000341, mae: 0.009723, mean_q: 0.017367
 5115/10000: episode: 665, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000562, mae: 0.015389, mean_q: 0.021796
 5119/10000: episode: 666, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000410, mae: 0.012176, mean_q: 0.019899
 5123/10000: episode: 667, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000748, mae: 0.018189, mean_q: 0.013878
 5127/10000: episode: 668, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001266, mae: 0.019561, mean_q: 0.024493
 5131/10000: episode: 669, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001729, mae: 0.018206, mean_q: 0.012713
 5135/10000: episode: 670, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000765, mae: 0.018372, mean_q: 0.030557
 5139/10000: episode: 671, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001393, mae: 0.024685, mean_q: 0.033530
 5143/10000: episode: 672, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000447, mae: 0.016004, mean_q: 0.028043
 5147/10000: episode: 673, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000717, mae: 0.017309, mean_q: 0.017626
 5151/10000: episode: 674, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001085, mae: 0.018452, mean_q: 0.021850
 5155/10000: episode: 675, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000819, mae: 0.015761, mean_q: 0.027850
[Info] FALSIFICATION!
 5158/10000: episode: 676, duration: 0.255s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000807, mae: 0.018563, mean_q: 0.034050
 5162/10000: episode: 677, duration: 0.025s, episode steps: 4, steps per second: 158, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001053, mae: 0.017554, mean_q: 0.026357
 5166/10000: episode: 678, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000796, mae: 0.016547, mean_q: 0.019416
 5170/10000: episode: 679, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000938, mae: 0.016709, mean_q: 0.022273
 5174/10000: episode: 680, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000231, mae: 0.009762, mean_q: 0.015625
 5178/10000: episode: 681, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000542, mae: 0.013006, mean_q: 0.019134
[Info] FALSIFICATION!
 5181/10000: episode: 682, duration: 0.254s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000369, mae: 0.011039, mean_q: 0.021119
 5185/10000: episode: 683, duration: 0.026s, episode steps: 4, steps per second: 156, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000418, mae: 0.012916, mean_q: 0.019718
 5189/10000: episode: 684, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000501, mae: 0.013680, mean_q: 0.022867
 5193/10000: episode: 685, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001340, mae: 0.022351, mean_q: 0.027623
 5197/10000: episode: 686, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000665, mae: 0.015836, mean_q: 0.019546
 5201/10000: episode: 687, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000407, mae: 0.011824, mean_q: 0.019369
 5205/10000: episode: 688, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.006414, mae: 0.028987, mean_q: 0.021536
 5209/10000: episode: 689, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000640, mae: 0.015957, mean_q: 0.026227
 5213/10000: episode: 690, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000508, mae: 0.014674, mean_q: 0.026998
 5217/10000: episode: 691, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000458, mae: 0.014126, mean_q: 0.019456
 5221/10000: episode: 692, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000738, mae: 0.018277, mean_q: 0.017000
 5225/10000: episode: 693, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.004849, mae: 0.033717, mean_q: 0.033922
 5229/10000: episode: 694, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000792, mae: 0.021037, mean_q: 0.025897
 5233/10000: episode: 695, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002729, mae: 0.024226, mean_q: 0.027077
 5237/10000: episode: 696, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000676, mae: 0.015586, mean_q: 0.023209
 5241/10000: episode: 697, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000553, mae: 0.016076, mean_q: 0.027158
 5245/10000: episode: 698, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001070, mae: 0.021885, mean_q: 0.024102
 5249/10000: episode: 699, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002267, mae: 0.022079, mean_q: 0.027517
 5253/10000: episode: 700, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002370, mae: 0.024429, mean_q: 0.034081
 5257/10000: episode: 701, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000597, mae: 0.012756, mean_q: 0.019548
 5261/10000: episode: 702, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001871, mae: 0.016884, mean_q: 0.024983
 5265/10000: episode: 703, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000831, mae: 0.015341, mean_q: 0.030368
 5269/10000: episode: 704, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000935, mae: 0.017137, mean_q: 0.026036
 5273/10000: episode: 705, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000903, mae: 0.015766, mean_q: 0.023171
 5277/10000: episode: 706, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002914, mae: 0.024440, mean_q: 0.029521
[Info] Complete ISplit Iteration
[Info] Levels: [0.041795008, 0.35143402, 0.6164019]
[Info] Cond. Prob: [0.1, 0.1, 0.05]
[Info] Error Prob: 0.0005000000000000001

 5281/10000: episode: 707, duration: 0.867s, episode steps: 4, steps per second: 5, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000513, mae: 0.013437, mean_q: 0.021944
 5291/10000: episode: 708, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000739, mae: 0.016257, mean_q: 0.021329
 5301/10000: episode: 709, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000446, mae: 0.013613, mean_q: 0.016446
 5311/10000: episode: 710, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.003213, mae: 0.023875, mean_q: 0.023905
 5321/10000: episode: 711, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001431, mae: 0.019723, mean_q: 0.028787
 5331/10000: episode: 712, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000789, mae: 0.017385, mean_q: 0.024994
 5341/10000: episode: 713, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002549, mae: 0.022447, mean_q: 0.026898
 5351/10000: episode: 714, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000654, mae: 0.014828, mean_q: 0.024204
 5361/10000: episode: 715, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000717, mae: 0.016786, mean_q: 0.028692
 5371/10000: episode: 716, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002497, mae: 0.025026, mean_q: 0.031863
 5381/10000: episode: 717, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002922, mae: 0.024498, mean_q: 0.032422
 5391/10000: episode: 718, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001514, mae: 0.022642, mean_q: 0.027783
 5401/10000: episode: 719, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002013, mae: 0.020882, mean_q: 0.021449
 5411/10000: episode: 720, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002837, mae: 0.021996, mean_q: 0.023565
 5421/10000: episode: 721, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000608, mae: 0.016723, mean_q: 0.024734
 5431/10000: episode: 722, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.003320, mae: 0.022829, mean_q: 0.024786
 5441/10000: episode: 723, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000919, mae: 0.018137, mean_q: 0.027706
 5451/10000: episode: 724, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001636, mae: 0.019095, mean_q: 0.023388
 5461/10000: episode: 725, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001653, mae: 0.017766, mean_q: 0.020844
 5471/10000: episode: 726, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000499, mae: 0.013775, mean_q: 0.017401
 5481/10000: episode: 727, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000773, mae: 0.016610, mean_q: 0.021110
 5491/10000: episode: 728, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001152, mae: 0.015794, mean_q: 0.022473
 5501/10000: episode: 729, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000788, mae: 0.017247, mean_q: 0.026404
 5511/10000: episode: 730, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001129, mae: 0.017523, mean_q: 0.024481
 5521/10000: episode: 731, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000529, mae: 0.013253, mean_q: 0.023111
 5531/10000: episode: 732, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000894, mae: 0.016806, mean_q: 0.024299
 5541/10000: episode: 733, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002403, mae: 0.020087, mean_q: 0.021983
 5551/10000: episode: 734, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001883, mae: 0.020882, mean_q: 0.027560
 5561/10000: episode: 735, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001140, mae: 0.015385, mean_q: 0.023680
 5571/10000: episode: 736, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000408, mae: 0.011964, mean_q: 0.017611
 5581/10000: episode: 737, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000939, mae: 0.016539, mean_q: 0.024064
 5591/10000: episode: 738, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000910, mae: 0.015267, mean_q: 0.020792
 5601/10000: episode: 739, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001804, mae: 0.019514, mean_q: 0.030654
 5611/10000: episode: 740, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001387, mae: 0.022342, mean_q: 0.033235
 5621/10000: episode: 741, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001838, mae: 0.018741, mean_q: 0.015215
 5631/10000: episode: 742, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000569, mae: 0.017772, mean_q: 0.018803
 5641/10000: episode: 743, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.004176, mae: 0.023441, mean_q: 0.020844
 5651/10000: episode: 744, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001642, mae: 0.021798, mean_q: 0.030286
 5661/10000: episode: 745, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.001288, mae: 0.020428, mean_q: 0.024484
 5671/10000: episode: 746, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000793, mae: 0.016600, mean_q: 0.019760
 5681/10000: episode: 747, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.003070, mae: 0.026202, mean_q: 0.030256
 5691/10000: episode: 748, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001440, mae: 0.020548, mean_q: 0.033742
 5701/10000: episode: 749, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001564, mae: 0.019397, mean_q: 0.019015
 5711/10000: episode: 750, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001464, mae: 0.018305, mean_q: 0.022758
 5721/10000: episode: 751, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002401, mae: 0.024642, mean_q: 0.035532
 5731/10000: episode: 752, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001163, mae: 0.019858, mean_q: 0.029094
 5741/10000: episode: 753, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000965, mae: 0.013944, mean_q: 0.017496
 5751/10000: episode: 754, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000951, mae: 0.016597, mean_q: 0.020240
 5761/10000: episode: 755, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000529, mae: 0.015341, mean_q: 0.017969
 5771/10000: episode: 756, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002067, mae: 0.019684, mean_q: 0.021000
 5781/10000: episode: 757, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001969, mae: 0.021640, mean_q: 0.028492
 5791/10000: episode: 758, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001892, mae: 0.019802, mean_q: 0.030383
 5801/10000: episode: 759, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002007, mae: 0.021465, mean_q: 0.025496
 5811/10000: episode: 760, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000644, mae: 0.014048, mean_q: 0.018907
 5821/10000: episode: 761, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001028, mae: 0.016151, mean_q: 0.022121
 5831/10000: episode: 762, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001363, mae: 0.018834, mean_q: 0.027773
 5841/10000: episode: 763, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001011, mae: 0.015137, mean_q: 0.020997
 5851/10000: episode: 764, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000606, mae: 0.013470, mean_q: 0.018022
 5861/10000: episode: 765, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.003381, mae: 0.022787, mean_q: 0.025971
 5871/10000: episode: 766, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000694, mae: 0.013483, mean_q: 0.022359
 5881/10000: episode: 767, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000674, mae: 0.015427, mean_q: 0.021413
 5891/10000: episode: 768, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000497, mae: 0.012687, mean_q: 0.013605
 5901/10000: episode: 769, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001906, mae: 0.017416, mean_q: 0.017471
 5911/10000: episode: 770, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000745, mae: 0.014972, mean_q: 0.022643
 5921/10000: episode: 771, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002295, mae: 0.019731, mean_q: 0.026422
 5931/10000: episode: 772, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000787, mae: 0.015768, mean_q: 0.026849
 5941/10000: episode: 773, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001632, mae: 0.015835, mean_q: 0.018790
 5951/10000: episode: 774, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.001633, mae: 0.014862, mean_q: 0.021272
 5961/10000: episode: 775, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000497, mae: 0.012990, mean_q: 0.019044
 5971/10000: episode: 776, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000376, mae: 0.012309, mean_q: 0.017810
 5981/10000: episode: 777, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001291, mae: 0.016379, mean_q: 0.018529
 5991/10000: episode: 778, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.003025, mae: 0.021973, mean_q: 0.031906
 6001/10000: episode: 779, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001247, mae: 0.019210, mean_q: 0.027146
 6011/10000: episode: 780, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001056, mae: 0.016870, mean_q: 0.023561
 6021/10000: episode: 781, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002057, mae: 0.020434, mean_q: 0.026213
 6031/10000: episode: 782, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.002425, mae: 0.021895, mean_q: 0.032728
 6041/10000: episode: 783, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001388, mae: 0.012883, mean_q: 0.014397
[Info] FALSIFICATION!
 6051/10000: episode: 784, duration: 0.275s, episode steps: 10, steps per second: 36, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.001014, mae: 0.015024, mean_q: 0.025204
 6061/10000: episode: 785, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001425, mae: 0.013253, mean_q: 0.018433
 6071/10000: episode: 786, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.003725, mae: 0.023354, mean_q: 0.026389
 6081/10000: episode: 787, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001448, mae: 0.018250, mean_q: 0.028013
 6091/10000: episode: 788, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001104, mae: 0.017456, mean_q: 0.029292
 6101/10000: episode: 789, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001858, mae: 0.018020, mean_q: 0.023328
 6111/10000: episode: 790, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001578, mae: 0.019816, mean_q: 0.029858
 6121/10000: episode: 791, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000715, mae: 0.014838, mean_q: 0.021861
 6131/10000: episode: 792, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001167, mae: 0.020452, mean_q: 0.031761
 6141/10000: episode: 793, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000556, mae: 0.015627, mean_q: 0.019393
 6151/10000: episode: 794, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000772, mae: 0.014831, mean_q: 0.017991
 6161/10000: episode: 795, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001507, mae: 0.012811, mean_q: 0.018764
 6171/10000: episode: 796, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001436, mae: 0.021804, mean_q: 0.036312
 6181/10000: episode: 797, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000830, mae: 0.018243, mean_q: 0.029994
 6191/10000: episode: 798, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000409, mae: 0.013966, mean_q: 0.013884
 6201/10000: episode: 799, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002271, mae: 0.020922, mean_q: 0.018765
 6211/10000: episode: 800, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001169, mae: 0.018198, mean_q: 0.018867
 6221/10000: episode: 801, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000787, mae: 0.017824, mean_q: 0.026199
 6231/10000: episode: 802, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000906, mae: 0.013844, mean_q: 0.022057
 6241/10000: episode: 803, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002064, mae: 0.018857, mean_q: 0.026874
 6251/10000: episode: 804, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001852, mae: 0.018593, mean_q: 0.025282
 6261/10000: episode: 805, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000535, mae: 0.013340, mean_q: 0.021625
 6271/10000: episode: 806, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.001651, mae: 0.016162, mean_q: 0.020064
[Info] Complete ISplit Iteration
[Info] Levels: [0.594844]
[Info] Cond. Prob: [0.01]
[Info] Error Prob: 0.01

 6281/10000: episode: 807, duration: 0.814s, episode steps: 10, steps per second: 12, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001616, mae: 0.015778, mean_q: 0.020685
 6291/10000: episode: 808, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.003317, mae: 0.027560, mean_q: 0.034555
 6301/10000: episode: 809, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000823, mae: 0.013846, mean_q: 0.024898
 6311/10000: episode: 810, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000569, mae: 0.012185, mean_q: 0.026126
 6321/10000: episode: 811, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001288, mae: 0.016868, mean_q: 0.027280
 6331/10000: episode: 812, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.000996, mae: 0.019866, mean_q: 0.030712
 6341/10000: episode: 813, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000535, mae: 0.013427, mean_q: 0.018348
 6351/10000: episode: 814, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002986, mae: 0.018708, mean_q: 0.016842
 6361/10000: episode: 815, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001614, mae: 0.019108, mean_q: 0.029628
 6371/10000: episode: 816, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001054, mae: 0.020030, mean_q: 0.028465
 6381/10000: episode: 817, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000711, mae: 0.013686, mean_q: 0.020225
 6391/10000: episode: 818, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001715, mae: 0.015317, mean_q: 0.015766
 6401/10000: episode: 819, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001203, mae: 0.018055, mean_q: 0.027842
 6411/10000: episode: 820, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001402, mae: 0.016597, mean_q: 0.025113
 6421/10000: episode: 821, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001112, mae: 0.015829, mean_q: 0.030290
 6431/10000: episode: 822, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000803, mae: 0.013380, mean_q: 0.023173
 6441/10000: episode: 823, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001793, mae: 0.018661, mean_q: 0.028488
 6451/10000: episode: 824, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001225, mae: 0.017797, mean_q: 0.026539
 6461/10000: episode: 825, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001288, mae: 0.015945, mean_q: 0.022147
 6471/10000: episode: 826, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001943, mae: 0.023261, mean_q: 0.036830
 6481/10000: episode: 827, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001278, mae: 0.019636, mean_q: 0.028294
 6491/10000: episode: 828, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000547, mae: 0.013162, mean_q: 0.019082
 6501/10000: episode: 829, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001806, mae: 0.016682, mean_q: 0.018671
 6511/10000: episode: 830, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000535, mae: 0.012286, mean_q: 0.015971
 6521/10000: episode: 831, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000552, mae: 0.014073, mean_q: 0.022515
 6531/10000: episode: 832, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000407, mae: 0.011113, mean_q: 0.015734
 6541/10000: episode: 833, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002746, mae: 0.021064, mean_q: 0.025484
 6551/10000: episode: 834, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000493, mae: 0.012041, mean_q: 0.021270
 6561/10000: episode: 835, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001165, mae: 0.017200, mean_q: 0.024599
 6571/10000: episode: 836, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002103, mae: 0.022377, mean_q: 0.034235
 6581/10000: episode: 837, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000799, mae: 0.015072, mean_q: 0.022038
 6591/10000: episode: 838, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000823, mae: 0.014961, mean_q: 0.022867
 6601/10000: episode: 839, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.002202, mae: 0.018572, mean_q: 0.023635
 6611/10000: episode: 840, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000820, mae: 0.017171, mean_q: 0.025926
 6621/10000: episode: 841, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000673, mae: 0.013017, mean_q: 0.016961
 6631/10000: episode: 842, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.003034, mae: 0.020137, mean_q: 0.018507
 6641/10000: episode: 843, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001153, mae: 0.016557, mean_q: 0.022268
 6651/10000: episode: 844, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001439, mae: 0.019486, mean_q: 0.031916
 6661/10000: episode: 845, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000686, mae: 0.014255, mean_q: 0.020254
 6671/10000: episode: 846, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.002202, mae: 0.019341, mean_q: 0.024561
 6681/10000: episode: 847, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001510, mae: 0.014788, mean_q: 0.019937
 6691/10000: episode: 848, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001349, mae: 0.018426, mean_q: 0.026769
 6701/10000: episode: 849, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000708, mae: 0.013348, mean_q: 0.020587
 6711/10000: episode: 850, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.003192, mae: 0.023712, mean_q: 0.030310
 6721/10000: episode: 851, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002049, mae: 0.017581, mean_q: 0.022599
 6731/10000: episode: 852, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001747, mae: 0.019644, mean_q: 0.028605
 6741/10000: episode: 853, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000375, mae: 0.010698, mean_q: 0.018456
 6751/10000: episode: 854, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001754, mae: 0.014394, mean_q: 0.017016
 6761/10000: episode: 855, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002012, mae: 0.018763, mean_q: 0.026800
 6771/10000: episode: 856, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000907, mae: 0.015039, mean_q: 0.024931
 6781/10000: episode: 857, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000351, mae: 0.010513, mean_q: 0.015161
 6791/10000: episode: 858, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000787, mae: 0.016590, mean_q: 0.020491
 6801/10000: episode: 859, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000916, mae: 0.015553, mean_q: 0.021736
 6811/10000: episode: 860, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001940, mae: 0.017845, mean_q: 0.021456
 6821/10000: episode: 861, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000594, mae: 0.013064, mean_q: 0.019719
 6831/10000: episode: 862, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001776, mae: 0.020826, mean_q: 0.033678
 6841/10000: episode: 863, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000953, mae: 0.018195, mean_q: 0.021369
 6851/10000: episode: 864, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000664, mae: 0.013851, mean_q: 0.016882
 6861/10000: episode: 865, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001191, mae: 0.017470, mean_q: 0.021727
 6871/10000: episode: 866, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001718, mae: 0.014550, mean_q: 0.019559
 6881/10000: episode: 867, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001685, mae: 0.015927, mean_q: 0.023703
 6891/10000: episode: 868, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001451, mae: 0.014983, mean_q: 0.018275
 6901/10000: episode: 869, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000988, mae: 0.017015, mean_q: 0.023784
 6911/10000: episode: 870, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001117, mae: 0.016275, mean_q: 0.022040
 6921/10000: episode: 871, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000517, mae: 0.013656, mean_q: 0.018389
 6931/10000: episode: 872, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002961, mae: 0.020324, mean_q: 0.020293
 6941/10000: episode: 873, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000856, mae: 0.014548, mean_q: 0.022650
 6951/10000: episode: 874, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001333, mae: 0.018791, mean_q: 0.028391
 6961/10000: episode: 875, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001248, mae: 0.020904, mean_q: 0.034181
 6971/10000: episode: 876, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000515, mae: 0.012925, mean_q: 0.018815
 6981/10000: episode: 877, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000822, mae: 0.017021, mean_q: 0.028641
 6991/10000: episode: 878, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000599, mae: 0.012553, mean_q: 0.017670
 7001/10000: episode: 879, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000803, mae: 0.012880, mean_q: 0.018423
 7011/10000: episode: 880, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000928, mae: 0.017905, mean_q: 0.028608
 7021/10000: episode: 881, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000730, mae: 0.016514, mean_q: 0.025658
 7031/10000: episode: 882, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001750, mae: 0.018693, mean_q: 0.025865
 7041/10000: episode: 883, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000379, mae: 0.011827, mean_q: 0.016794
 7051/10000: episode: 884, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000601, mae: 0.012355, mean_q: 0.015853
 7061/10000: episode: 885, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000930, mae: 0.014018, mean_q: 0.018780
 7071/10000: episode: 886, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000609, mae: 0.014830, mean_q: 0.020683
 7081/10000: episode: 887, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001083, mae: 0.017428, mean_q: 0.024675
 7091/10000: episode: 888, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002047, mae: 0.017465, mean_q: 0.018747
 7101/10000: episode: 889, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000690, mae: 0.016668, mean_q: 0.023561
 7111/10000: episode: 890, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000742, mae: 0.015242, mean_q: 0.022864
 7121/10000: episode: 891, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001632, mae: 0.017213, mean_q: 0.021043
 7131/10000: episode: 892, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.003017, mae: 0.026147, mean_q: 0.035468
 7141/10000: episode: 893, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001949, mae: 0.021335, mean_q: 0.037574
 7151/10000: episode: 894, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000899, mae: 0.015269, mean_q: 0.022650
 7161/10000: episode: 895, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001022, mae: 0.016492, mean_q: 0.024651
 7171/10000: episode: 896, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001199, mae: 0.011934, mean_q: 0.016472
 7181/10000: episode: 897, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.002384, mae: 0.021524, mean_q: 0.029874
 7191/10000: episode: 898, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001905, mae: 0.018650, mean_q: 0.023030
 7201/10000: episode: 899, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000696, mae: 0.014755, mean_q: 0.024402
 7211/10000: episode: 900, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001584, mae: 0.017203, mean_q: 0.023928
 7221/10000: episode: 901, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001700, mae: 0.018530, mean_q: 0.023889
 7231/10000: episode: 902, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001366, mae: 0.015521, mean_q: 0.018026
 7241/10000: episode: 903, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000694, mae: 0.015810, mean_q: 0.025678
 7251/10000: episode: 904, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000688, mae: 0.015910, mean_q: 0.021392
 7261/10000: episode: 905, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000674, mae: 0.013214, mean_q: 0.017797
 7271/10000: episode: 906, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001629, mae: 0.019454, mean_q: 0.026884
[Info] 1-TH LEVEL FOUND: 0.02144607901573181, Considering 15/100 traces
 7281/10000: episode: 907, duration: 0.658s, episode steps: 10, steps per second: 15, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002438, mae: 0.020082, mean_q: 0.024391
 7287/10000: episode: 908, duration: 0.032s, episode steps: 6, steps per second: 186, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.002140, mae: 0.019219, mean_q: 0.024017
 7293/10000: episode: 909, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.018, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.583 [-1.000, 11.000], loss: 0.000606, mae: 0.014429, mean_q: 0.025085
 7299/10000: episode: 910, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000616, mae: 0.012542, mean_q: 0.022271
 7305/10000: episode: 911, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001052, mae: 0.017864, mean_q: 0.022318
 7311/10000: episode: 912, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001249, mae: 0.016578, mean_q: 0.023972
 7317/10000: episode: 913, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.030, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000774, mae: 0.016137, mean_q: 0.023125
 7323/10000: episode: 914, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.010, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.417 [-1.000, 11.000], loss: 0.002175, mae: 0.020467, mean_q: 0.021136
 7329/10000: episode: 915, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000625, mae: 0.015786, mean_q: 0.026485
 7335/10000: episode: 916, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.046, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001514, mae: 0.020208, mean_q: 0.026465
 7341/10000: episode: 917, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.010, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.417 [-1.000, 11.000], loss: 0.000528, mae: 0.012071, mean_q: 0.017030
 7347/10000: episode: 918, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000563, mae: 0.012873, mean_q: 0.019333
 7353/10000: episode: 919, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000639, mae: 0.012933, mean_q: 0.017335
 7359/10000: episode: 920, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.002092, mae: 0.021475, mean_q: 0.025271
 7365/10000: episode: 921, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000594, mae: 0.013350, mean_q: 0.013884
 7371/10000: episode: 922, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000532, mae: 0.014278, mean_q: 0.021437
 7377/10000: episode: 923, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.018, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.583 [-1.000, 11.000], loss: 0.001188, mae: 0.020215, mean_q: 0.029765
 7383/10000: episode: 924, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.002486, mae: 0.019205, mean_q: 0.029070
 7389/10000: episode: 925, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000526, mae: 0.012150, mean_q: 0.014738
 7395/10000: episode: 926, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000962, mae: 0.015014, mean_q: 0.020553
 7401/10000: episode: 927, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000679, mae: 0.014022, mean_q: 0.022056
 7407/10000: episode: 928, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.018, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.583 [-1.000, 11.000], loss: 0.000795, mae: 0.017279, mean_q: 0.026868
 7413/10000: episode: 929, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.002548, mae: 0.020304, mean_q: 0.020454
 7419/10000: episode: 930, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001784, mae: 0.024703, mean_q: 0.038994
 7425/10000: episode: 931, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000643, mae: 0.012758, mean_q: 0.010955
 7431/10000: episode: 932, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.030, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001164, mae: 0.018067, mean_q: 0.022662
 7437/10000: episode: 933, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.002379, mae: 0.018599, mean_q: 0.017883
 7443/10000: episode: 934, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000503, mae: 0.013418, mean_q: 0.025226
 7449/10000: episode: 935, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001300, mae: 0.019210, mean_q: 0.026526
 7455/10000: episode: 936, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.018, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.583 [-1.000, 11.000], loss: 0.000911, mae: 0.016810, mean_q: 0.019953
 7461/10000: episode: 937, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003052, mae: 0.022408, mean_q: 0.028226
 7467/10000: episode: 938, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.077, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000666, mae: 0.013640, mean_q: 0.024353
 7473/10000: episode: 939, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000561, mae: 0.013277, mean_q: 0.021681
 7479/10000: episode: 940, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.023, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000674, mae: 0.015179, mean_q: 0.019903
 7485/10000: episode: 941, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.023, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001188, mae: 0.015832, mean_q: 0.021642
 7491/10000: episode: 942, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000966, mae: 0.015199, mean_q: 0.023742
 7497/10000: episode: 943, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.034, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001507, mae: 0.017952, mean_q: 0.026698
 7503/10000: episode: 944, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001214, mae: 0.015515, mean_q: 0.019191
 7509/10000: episode: 945, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000522, mae: 0.011652, mean_q: 0.018565
 7515/10000: episode: 946, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000618, mae: 0.014430, mean_q: 0.022074
 7521/10000: episode: 947, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000700, mae: 0.014002, mean_q: 0.025042
 7527/10000: episode: 948, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000686, mae: 0.016842, mean_q: 0.025815
 7533/10000: episode: 949, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000583, mae: 0.014603, mean_q: 0.015833
 7539/10000: episode: 950, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002263, mae: 0.016166, mean_q: 0.018729
 7545/10000: episode: 951, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000718, mae: 0.013128, mean_q: 0.012585
 7551/10000: episode: 952, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000265, mae: 0.010187, mean_q: 0.015583
 7557/10000: episode: 953, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.010, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.417 [-1.000, 11.000], loss: 0.002746, mae: 0.024050, mean_q: 0.033615
 7563/10000: episode: 954, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000773, mae: 0.014890, mean_q: 0.022659
 7569/10000: episode: 955, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.018, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.583 [-1.000, 11.000], loss: 0.000424, mae: 0.011988, mean_q: 0.019968
 7575/10000: episode: 956, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.002039, mae: 0.020697, mean_q: 0.022186
 7581/10000: episode: 957, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001275, mae: 0.019032, mean_q: 0.035043
 7587/10000: episode: 958, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000470, mae: 0.011171, mean_q: 0.018353
 7593/10000: episode: 959, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001225, mae: 0.016487, mean_q: 0.024354
 7599/10000: episode: 960, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002250, mae: 0.017047, mean_q: 0.022310
 7605/10000: episode: 961, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001445, mae: 0.020611, mean_q: 0.032344
 7611/10000: episode: 962, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000409, mae: 0.011760, mean_q: 0.020191
 7617/10000: episode: 963, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000655, mae: 0.013781, mean_q: 0.020281
 7623/10000: episode: 964, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001290, mae: 0.017373, mean_q: 0.020474
 7629/10000: episode: 965, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.023, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000998, mae: 0.015997, mean_q: 0.024738
 7635/10000: episode: 966, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.018, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.583 [-1.000, 11.000], loss: 0.001015, mae: 0.016779, mean_q: 0.026655
 7641/10000: episode: 967, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001194, mae: 0.019114, mean_q: 0.034884
 7647/10000: episode: 968, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.034, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001554, mae: 0.019329, mean_q: 0.030901
 7653/10000: episode: 969, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001349, mae: 0.017557, mean_q: 0.025414
 7659/10000: episode: 970, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.077, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000791, mae: 0.015077, mean_q: 0.025520
 7665/10000: episode: 971, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000821, mae: 0.014753, mean_q: 0.020511
 7671/10000: episode: 972, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.077, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000499, mae: 0.012221, mean_q: 0.015522
 7677/10000: episode: 973, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000420, mae: 0.010777, mean_q: 0.016040
 7683/10000: episode: 974, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000587, mae: 0.015199, mean_q: 0.021299
 7689/10000: episode: 975, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.002455, mae: 0.018770, mean_q: 0.022065
 7695/10000: episode: 976, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000775, mae: 0.013233, mean_q: 0.016810
 7701/10000: episode: 977, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002500, mae: 0.020283, mean_q: 0.025443
 7707/10000: episode: 978, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.002102, mae: 0.020875, mean_q: 0.030092
 7713/10000: episode: 979, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002001, mae: 0.019377, mean_q: 0.027926
 7719/10000: episode: 980, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.077, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000948, mae: 0.015894, mean_q: 0.026950
 7725/10000: episode: 981, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001223, mae: 0.016835, mean_q: 0.019880
 7731/10000: episode: 982, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000888, mae: 0.016923, mean_q: 0.024989
 7737/10000: episode: 983, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000706, mae: 0.014757, mean_q: 0.027638
 7743/10000: episode: 984, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001031, mae: 0.013018, mean_q: 0.015544
 7749/10000: episode: 985, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.077, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000973, mae: 0.014994, mean_q: 0.018060
 7755/10000: episode: 986, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001440, mae: 0.016488, mean_q: 0.018866
 7761/10000: episode: 987, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.077, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000622, mae: 0.014105, mean_q: 0.022628
 7767/10000: episode: 988, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.077, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000714, mae: 0.014835, mean_q: 0.024386
 7773/10000: episode: 989, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000503, mae: 0.012117, mean_q: 0.014422
 7779/10000: episode: 990, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001463, mae: 0.018512, mean_q: 0.024151
 7785/10000: episode: 991, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000747, mae: 0.016419, mean_q: 0.026154
[Info] 2-TH LEVEL FOUND: 0.10430514812469482, Considering 10/100 traces
 7791/10000: episode: 992, duration: 0.727s, episode steps: 6, steps per second: 8, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000689, mae: 0.016471, mean_q: 0.029430
 7796/10000: episode: 993, duration: 0.028s, episode steps: 5, steps per second: 179, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000778, mae: 0.015131, mean_q: 0.026932
 7801/10000: episode: 994, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000637, mae: 0.015150, mean_q: 0.019996
 7806/10000: episode: 995, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000549, mae: 0.016133, mean_q: 0.017718
 7811/10000: episode: 996, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000273, mae: 0.012553, mean_q: 0.017317
 7816/10000: episode: 997, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000701, mae: 0.016437, mean_q: 0.016233
 7821/10000: episode: 998, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000745, mae: 0.015763, mean_q: 0.022061
 7826/10000: episode: 999, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000763, mae: 0.015008, mean_q: 0.017345
 7831/10000: episode: 1000, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.004941, mae: 0.027368, mean_q: 0.024674
 7836/10000: episode: 1001, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002407, mae: 0.021583, mean_q: 0.024550
 7841/10000: episode: 1002, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002151, mae: 0.023912, mean_q: 0.036988
 7846/10000: episode: 1003, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001208, mae: 0.020034, mean_q: 0.029513
 7851/10000: episode: 1004, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001113, mae: 0.018361, mean_q: 0.028250
 7856/10000: episode: 1005, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000483, mae: 0.014273, mean_q: 0.025246
 7861/10000: episode: 1006, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000328, mae: 0.010998, mean_q: 0.013488
[Info] FALSIFICATION!
 7865/10000: episode: 1007, duration: 0.172s, episode steps: 4, steps per second: 23, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000553, mae: 0.013962, mean_q: 0.021117
 7870/10000: episode: 1008, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000812, mae: 0.013092, mean_q: 0.013827
 7875/10000: episode: 1009, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001397, mae: 0.012911, mean_q: 0.014878
 7880/10000: episode: 1010, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001725, mae: 0.015971, mean_q: 0.018115
 7885/10000: episode: 1011, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000492, mae: 0.012581, mean_q: 0.026665
 7890/10000: episode: 1012, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002634, mae: 0.021510, mean_q: 0.031239
 7895/10000: episode: 1013, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001056, mae: 0.018398, mean_q: 0.029935
 7900/10000: episode: 1014, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000838, mae: 0.010743, mean_q: 0.013330
 7905/10000: episode: 1015, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000995, mae: 0.012718, mean_q: 0.019689
 7910/10000: episode: 1016, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000798, mae: 0.015901, mean_q: 0.025454
 7915/10000: episode: 1017, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000769, mae: 0.015676, mean_q: 0.032946
 7920/10000: episode: 1018, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001038, mae: 0.016680, mean_q: 0.022507
 7925/10000: episode: 1019, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000993, mae: 0.017669, mean_q: 0.031867
 7930/10000: episode: 1020, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000514, mae: 0.013734, mean_q: 0.020144
 7935/10000: episode: 1021, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001099, mae: 0.016769, mean_q: 0.029624
 7940/10000: episode: 1022, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.003189, mae: 0.024478, mean_q: 0.033458
 7945/10000: episode: 1023, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000953, mae: 0.016549, mean_q: 0.030456
 7950/10000: episode: 1024, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002170, mae: 0.016186, mean_q: 0.025117
 7955/10000: episode: 1025, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000793, mae: 0.014269, mean_q: 0.021148
 7960/10000: episode: 1026, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000571, mae: 0.014615, mean_q: 0.025756
 7965/10000: episode: 1027, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000886, mae: 0.014713, mean_q: 0.019759
 7970/10000: episode: 1028, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001068, mae: 0.014833, mean_q: 0.026291
 7975/10000: episode: 1029, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000734, mae: 0.015901, mean_q: 0.020544
 7980/10000: episode: 1030, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001675, mae: 0.020483, mean_q: 0.036642
 7985/10000: episode: 1031, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001676, mae: 0.021250, mean_q: 0.035135
 7990/10000: episode: 1032, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001066, mae: 0.019555, mean_q: 0.029407
[Info] FALSIFICATION!
 7994/10000: episode: 1033, duration: 0.173s, episode steps: 4, steps per second: 23, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000371, mae: 0.012464, mean_q: 0.017577
 7999/10000: episode: 1034, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000827, mae: 0.015977, mean_q: 0.027527
 8004/10000: episode: 1035, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001668, mae: 0.019637, mean_q: 0.020451
 8009/10000: episode: 1036, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000976, mae: 0.020329, mean_q: 0.032397
 8014/10000: episode: 1037, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.004235, mae: 0.029621, mean_q: 0.037419
 8019/10000: episode: 1038, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001465, mae: 0.024901, mean_q: 0.038783
 8024/10000: episode: 1039, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001381, mae: 0.021835, mean_q: 0.041983
 8029/10000: episode: 1040, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000699, mae: 0.019922, mean_q: 0.026257
 8034/10000: episode: 1041, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000979, mae: 0.016852, mean_q: 0.024979
 8039/10000: episode: 1042, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000700, mae: 0.016567, mean_q: 0.020327
 8044/10000: episode: 1043, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001316, mae: 0.019474, mean_q: 0.023664
 8049/10000: episode: 1044, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001184, mae: 0.016146, mean_q: 0.026610
 8054/10000: episode: 1045, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000733, mae: 0.015873, mean_q: 0.026649
 8059/10000: episode: 1046, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000814, mae: 0.016548, mean_q: 0.028970
 8064/10000: episode: 1047, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000773, mae: 0.015629, mean_q: 0.023119
 8069/10000: episode: 1048, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003161, mae: 0.021631, mean_q: 0.023401
 8074/10000: episode: 1049, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000816, mae: 0.017967, mean_q: 0.027411
[Info] FALSIFICATION!
 8078/10000: episode: 1050, duration: 0.261s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000569, mae: 0.016169, mean_q: 0.020220
 8083/10000: episode: 1051, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001068, mae: 0.018522, mean_q: 0.024713
 8088/10000: episode: 1052, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002800, mae: 0.022107, mean_q: 0.023571
 8093/10000: episode: 1053, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001433, mae: 0.024167, mean_q: 0.046635
 8098/10000: episode: 1054, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000704, mae: 0.017750, mean_q: 0.023536
 8103/10000: episode: 1055, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000539, mae: 0.014281, mean_q: 0.015470
 8108/10000: episode: 1056, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002197, mae: 0.023942, mean_q: 0.030056
 8113/10000: episode: 1057, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002938, mae: 0.023187, mean_q: 0.028273
 8118/10000: episode: 1058, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000890, mae: 0.017380, mean_q: 0.025575
[Info] FALSIFICATION!
 8122/10000: episode: 1059, duration: 0.259s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000528, mae: 0.015160, mean_q: 0.026161
 8127/10000: episode: 1060, duration: 0.030s, episode steps: 5, steps per second: 166, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002073, mae: 0.023704, mean_q: 0.030329
 8132/10000: episode: 1061, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000840, mae: 0.017711, mean_q: 0.014578
 8137/10000: episode: 1062, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000995, mae: 0.020419, mean_q: 0.025381
 8142/10000: episode: 1063, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.001202, mae: 0.021468, mean_q: 0.035247
 8147/10000: episode: 1064, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.004696, mae: 0.029187, mean_q: 0.034380
 8152/10000: episode: 1065, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001228, mae: 0.023310, mean_q: 0.032285
[Info] FALSIFICATION!
 8156/10000: episode: 1066, duration: 0.260s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000376, mae: 0.014067, mean_q: 0.020516
 8161/10000: episode: 1067, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001283, mae: 0.017367, mean_q: 0.024192
 8166/10000: episode: 1068, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000768, mae: 0.016362, mean_q: 0.021432
[Info] FALSIFICATION!
 8170/10000: episode: 1069, duration: 0.262s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000652, mae: 0.016381, mean_q: 0.022585
 8175/10000: episode: 1070, duration: 0.029s, episode steps: 5, steps per second: 170, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000852, mae: 0.018121, mean_q: 0.027893
 8180/10000: episode: 1071, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000692, mae: 0.015169, mean_q: 0.025865
 8185/10000: episode: 1072, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000949, mae: 0.018204, mean_q: 0.030133
 8190/10000: episode: 1073, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.004597, mae: 0.031390, mean_q: 0.047823
 8195/10000: episode: 1074, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001853, mae: 0.022946, mean_q: 0.027545
 8200/10000: episode: 1075, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001259, mae: 0.020037, mean_q: 0.033537
 8205/10000: episode: 1076, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002681, mae: 0.022464, mean_q: 0.023029
 8210/10000: episode: 1077, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001828, mae: 0.025592, mean_q: 0.041766
 8215/10000: episode: 1078, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001861, mae: 0.026004, mean_q: 0.034599
 8220/10000: episode: 1079, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002716, mae: 0.024738, mean_q: 0.031387
 8225/10000: episode: 1080, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001335, mae: 0.021899, mean_q: 0.032140
 8230/10000: episode: 1081, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001789, mae: 0.026819, mean_q: 0.036410
[Info] Complete ISplit Iteration
[Info] Levels: [0.021446079, 0.10430515, 0.6429571]
[Info] Cond. Prob: [0.15, 0.1, 0.06]
[Info] Error Prob: 0.0009

 8235/10000: episode: 1082, duration: 0.876s, episode steps: 5, steps per second: 6, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001334, mae: 0.019299, mean_q: 0.026702
 8245/10000: episode: 1083, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001209, mae: 0.021105, mean_q: 0.025479
 8255/10000: episode: 1084, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002118, mae: 0.026637, mean_q: 0.039552
 8265/10000: episode: 1085, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002084, mae: 0.025506, mean_q: 0.035282
 8275/10000: episode: 1086, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001236, mae: 0.020971, mean_q: 0.026427
 8285/10000: episode: 1087, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001615, mae: 0.025027, mean_q: 0.034155
 8295/10000: episode: 1088, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000998, mae: 0.019905, mean_q: 0.028105
 8305/10000: episode: 1089, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002050, mae: 0.024622, mean_q: 0.036156
 8315/10000: episode: 1090, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002574, mae: 0.023969, mean_q: 0.037970
 8325/10000: episode: 1091, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001379, mae: 0.022207, mean_q: 0.035692
 8335/10000: episode: 1092, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001659, mae: 0.022656, mean_q: 0.031170
 8345/10000: episode: 1093, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001385, mae: 0.021234, mean_q: 0.035696
 8355/10000: episode: 1094, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001211, mae: 0.020714, mean_q: 0.033790
 8365/10000: episode: 1095, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002365, mae: 0.024690, mean_q: 0.032421
 8375/10000: episode: 1096, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.002113, mae: 0.024398, mean_q: 0.033552
 8385/10000: episode: 1097, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002212, mae: 0.024638, mean_q: 0.037080
 8395/10000: episode: 1098, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001735, mae: 0.025066, mean_q: 0.042343
 8405/10000: episode: 1099, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002285, mae: 0.024064, mean_q: 0.032615
 8415/10000: episode: 1100, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001157, mae: 0.019291, mean_q: 0.026006
 8425/10000: episode: 1101, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002565, mae: 0.030817, mean_q: 0.046276
 8435/10000: episode: 1102, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001185, mae: 0.024194, mean_q: 0.034138
 8445/10000: episode: 1103, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.003677, mae: 0.033400, mean_q: 0.038332
 8455/10000: episode: 1104, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002228, mae: 0.027664, mean_q: 0.034119
 8465/10000: episode: 1105, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001005, mae: 0.022525, mean_q: 0.027797
 8475/10000: episode: 1106, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001913, mae: 0.024140, mean_q: 0.033819
 8485/10000: episode: 1107, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001528, mae: 0.020303, mean_q: 0.027941
 8495/10000: episode: 1108, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002529, mae: 0.024452, mean_q: 0.031850
 8505/10000: episode: 1109, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.003853, mae: 0.030524, mean_q: 0.040717
 8515/10000: episode: 1110, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001918, mae: 0.023282, mean_q: 0.038347
 8525/10000: episode: 1111, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002295, mae: 0.026038, mean_q: 0.041790
 8535/10000: episode: 1112, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001944, mae: 0.026816, mean_q: 0.040878
 8545/10000: episode: 1113, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002138, mae: 0.023581, mean_q: 0.034342
 8555/10000: episode: 1114, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.002883, mae: 0.023756, mean_q: 0.031246
 8565/10000: episode: 1115, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001310, mae: 0.019781, mean_q: 0.030814
 8575/10000: episode: 1116, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002749, mae: 0.025348, mean_q: 0.032777
 8585/10000: episode: 1117, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002881, mae: 0.029526, mean_q: 0.047422
 8595/10000: episode: 1118, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.002890, mae: 0.029019, mean_q: 0.040173
 8605/10000: episode: 1119, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002721, mae: 0.027199, mean_q: 0.038292
 8615/10000: episode: 1120, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001792, mae: 0.026178, mean_q: 0.033426
 8625/10000: episode: 1121, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001399, mae: 0.022538, mean_q: 0.029860
 8635/10000: episode: 1122, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001065, mae: 0.017863, mean_q: 0.028997
 8645/10000: episode: 1123, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001249, mae: 0.020703, mean_q: 0.033484
 8655/10000: episode: 1124, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002013, mae: 0.023804, mean_q: 0.028809
 8665/10000: episode: 1125, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001011, mae: 0.020506, mean_q: 0.031676
 8675/10000: episode: 1126, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002780, mae: 0.025303, mean_q: 0.031721
 8685/10000: episode: 1127, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002790, mae: 0.028345, mean_q: 0.045357
 8695/10000: episode: 1128, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002440, mae: 0.028504, mean_q: 0.040736
 8705/10000: episode: 1129, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001322, mae: 0.023193, mean_q: 0.035294
 8715/10000: episode: 1130, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002464, mae: 0.019968, mean_q: 0.023489
 8725/10000: episode: 1131, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002206, mae: 0.026639, mean_q: 0.038645
 8735/10000: episode: 1132, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001738, mae: 0.021234, mean_q: 0.030996
 8745/10000: episode: 1133, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001169, mae: 0.022852, mean_q: 0.037171
 8755/10000: episode: 1134, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001776, mae: 0.022430, mean_q: 0.032556
 8765/10000: episode: 1135, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002524, mae: 0.027946, mean_q: 0.036126
 8775/10000: episode: 1136, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001250, mae: 0.022875, mean_q: 0.032425
 8785/10000: episode: 1137, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002895, mae: 0.025340, mean_q: 0.032701
 8795/10000: episode: 1138, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001948, mae: 0.026017, mean_q: 0.041490
 8805/10000: episode: 1139, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002181, mae: 0.024006, mean_q: 0.028793
 8815/10000: episode: 1140, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.002106, mae: 0.022464, mean_q: 0.028367
 8825/10000: episode: 1141, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001910, mae: 0.025935, mean_q: 0.038217
 8835/10000: episode: 1142, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001156, mae: 0.022977, mean_q: 0.033925
 8845/10000: episode: 1143, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001652, mae: 0.021667, mean_q: 0.030618
 8855/10000: episode: 1144, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001501, mae: 0.022514, mean_q: 0.032837
 8865/10000: episode: 1145, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001911, mae: 0.022282, mean_q: 0.033989
 8875/10000: episode: 1146, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001712, mae: 0.025960, mean_q: 0.035348
 8885/10000: episode: 1147, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001273, mae: 0.021177, mean_q: 0.032103
 8895/10000: episode: 1148, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000889, mae: 0.016708, mean_q: 0.025507
 8905/10000: episode: 1149, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001128, mae: 0.018235, mean_q: 0.027870
 8915/10000: episode: 1150, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001122, mae: 0.019158, mean_q: 0.029723
 8925/10000: episode: 1151, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001288, mae: 0.021476, mean_q: 0.029564
 8935/10000: episode: 1152, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000975, mae: 0.019772, mean_q: 0.032361
 8945/10000: episode: 1153, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.003245, mae: 0.028013, mean_q: 0.038238
 8955/10000: episode: 1154, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001595, mae: 0.024204, mean_q: 0.041607
 8965/10000: episode: 1155, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001285, mae: 0.025165, mean_q: 0.033789
 8975/10000: episode: 1156, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001695, mae: 0.023109, mean_q: 0.027776
 8985/10000: episode: 1157, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001096, mae: 0.017621, mean_q: 0.022861
 8995/10000: episode: 1158, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002221, mae: 0.023635, mean_q: 0.028900
 9005/10000: episode: 1159, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001221, mae: 0.022313, mean_q: 0.037303
 9015/10000: episode: 1160, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000827, mae: 0.019556, mean_q: 0.030319
 9025/10000: episode: 1161, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001625, mae: 0.021613, mean_q: 0.031762
 9035/10000: episode: 1162, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001339, mae: 0.020642, mean_q: 0.035618
 9045/10000: episode: 1163, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001355, mae: 0.022500, mean_q: 0.034033
 9055/10000: episode: 1164, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001361, mae: 0.019023, mean_q: 0.028247
 9065/10000: episode: 1165, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001329, mae: 0.019687, mean_q: 0.035334
 9075/10000: episode: 1166, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001089, mae: 0.017366, mean_q: 0.026597
 9085/10000: episode: 1167, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001203, mae: 0.018595, mean_q: 0.031067
 9095/10000: episode: 1168, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002120, mae: 0.022713, mean_q: 0.030439
 9105/10000: episode: 1169, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.002424, mae: 0.025443, mean_q: 0.037543
 9115/10000: episode: 1170, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001359, mae: 0.020868, mean_q: 0.028999
 9125/10000: episode: 1171, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002002, mae: 0.023869, mean_q: 0.036887
 9135/10000: episode: 1172, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.002693, mae: 0.023202, mean_q: 0.027316
 9145/10000: episode: 1173, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001067, mae: 0.020124, mean_q: 0.032876
 9155/10000: episode: 1174, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000781, mae: 0.017832, mean_q: 0.033779
 9165/10000: episode: 1175, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002228, mae: 0.021138, mean_q: 0.027109
 9175/10000: episode: 1176, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001011, mae: 0.019471, mean_q: 0.023797
 9185/10000: episode: 1177, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001293, mae: 0.021447, mean_q: 0.032747
 9195/10000: episode: 1178, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001174, mae: 0.020468, mean_q: 0.029670
 9205/10000: episode: 1179, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001267, mae: 0.018851, mean_q: 0.026154
 9215/10000: episode: 1180, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001174, mae: 0.018184, mean_q: 0.029256
 9225/10000: episode: 1181, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001822, mae: 0.021281, mean_q: 0.029270
[Info] 1-TH LEVEL FOUND: 0.03488074243068695, Considering 10/100 traces
 9235/10000: episode: 1182, duration: 0.694s, episode steps: 10, steps per second: 14, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000940, mae: 0.017600, mean_q: 0.028446
 9242/10000: episode: 1183, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001272, mae: 0.020492, mean_q: 0.034035
 9249/10000: episode: 1184, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001969, mae: 0.023841, mean_q: 0.036304
 9253/10000: episode: 1185, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000707, mae: 0.016998, mean_q: 0.023581
 9257/10000: episode: 1186, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000818, mae: 0.016352, mean_q: 0.024043
[Info] FALSIFICATION!
 9263/10000: episode: 1187, duration: 0.173s, episode steps: 6, steps per second: 35, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.003555, mae: 0.027266, mean_q: 0.031369
 9270/10000: episode: 1188, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001189, mae: 0.018061, mean_q: 0.030327
 9277/10000: episode: 1189, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001265, mae: 0.020068, mean_q: 0.028325
 9284/10000: episode: 1190, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001337, mae: 0.021868, mean_q: 0.043205
 9291/10000: episode: 1191, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.003164, mae: 0.029020, mean_q: 0.038725
 9295/10000: episode: 1192, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001009, mae: 0.016815, mean_q: 0.024824
[Info] FALSIFICATION!
 9301/10000: episode: 1193, duration: 0.176s, episode steps: 6, steps per second: 34, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000952, mae: 0.019855, mean_q: 0.032227
 9308/10000: episode: 1194, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.002123, mae: 0.024742, mean_q: 0.042322
 9312/10000: episode: 1195, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001454, mae: 0.021122, mean_q: 0.035779
 9316/10000: episode: 1196, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001602, mae: 0.023296, mean_q: 0.041509
 9320/10000: episode: 1197, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001645, mae: 0.022756, mean_q: 0.038187
 9327/10000: episode: 1198, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000638, mae: 0.016907, mean_q: 0.029485
 9331/10000: episode: 1199, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000622, mae: 0.012748, mean_q: 0.018229
 9338/10000: episode: 1200, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.001383, mae: 0.018815, mean_q: 0.030732
 9345/10000: episode: 1201, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001167, mae: 0.020524, mean_q: 0.038361
 9352/10000: episode: 1202, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001085, mae: 0.021359, mean_q: 0.032793
 9359/10000: episode: 1203, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000884, mae: 0.016553, mean_q: 0.024075
 9366/10000: episode: 1204, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.003749, mae: 0.021877, mean_q: 0.020852
 9370/10000: episode: 1205, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000799, mae: 0.015784, mean_q: 0.024292
 9374/10000: episode: 1206, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000620, mae: 0.017150, mean_q: 0.030373
 9381/10000: episode: 1207, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001250, mae: 0.019919, mean_q: 0.035350
 9388/10000: episode: 1208, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000826, mae: 0.017187, mean_q: 0.026884
 9392/10000: episode: 1209, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002878, mae: 0.024313, mean_q: 0.030319
 9396/10000: episode: 1210, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004302, mae: 0.032810, mean_q: 0.043831
 9403/10000: episode: 1211, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000962, mae: 0.015674, mean_q: 0.026539
 9410/10000: episode: 1212, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.002013, mae: 0.025765, mean_q: 0.046637
 9417/10000: episode: 1213, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000710, mae: 0.017261, mean_q: 0.027766
 9424/10000: episode: 1214, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001223, mae: 0.017420, mean_q: 0.020841
 9431/10000: episode: 1215, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.004238, mae: 0.028431, mean_q: 0.031357
 9438/10000: episode: 1216, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001932, mae: 0.017798, mean_q: 0.026211
 9445/10000: episode: 1217, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.002608, mae: 0.024910, mean_q: 0.040578
 9449/10000: episode: 1218, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001459, mae: 0.023034, mean_q: 0.033387
 9456/10000: episode: 1219, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001020, mae: 0.019504, mean_q: 0.020942
 9463/10000: episode: 1220, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002752, mae: 0.018624, mean_q: 0.019668
 9467/10000: episode: 1221, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002840, mae: 0.023711, mean_q: 0.034541
 9474/10000: episode: 1222, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000825, mae: 0.017557, mean_q: 0.030536
 9478/10000: episode: 1223, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001639, mae: 0.022522, mean_q: 0.041060
 9482/10000: episode: 1224, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003084, mae: 0.025051, mean_q: 0.032576
 9489/10000: episode: 1225, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001771, mae: 0.018826, mean_q: 0.027784
 9496/10000: episode: 1226, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001113, mae: 0.017716, mean_q: 0.032589
 9500/10000: episode: 1227, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001313, mae: 0.017233, mean_q: 0.029916
 9507/10000: episode: 1228, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001758, mae: 0.023009, mean_q: 0.033719
 9514/10000: episode: 1229, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001076, mae: 0.019929, mean_q: 0.030367
 9518/10000: episode: 1230, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000559, mae: 0.014099, mean_q: 0.021906
 9522/10000: episode: 1231, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001139, mae: 0.019452, mean_q: 0.027206
 9529/10000: episode: 1232, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.001684, mae: 0.022442, mean_q: 0.046210
 9536/10000: episode: 1233, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000970, mae: 0.016213, mean_q: 0.029324
 9543/10000: episode: 1234, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.002673, mae: 0.024917, mean_q: 0.035058
 9550/10000: episode: 1235, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.003772, mae: 0.025545, mean_q: 0.033053
 9554/10000: episode: 1236, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000801, mae: 0.014275, mean_q: 0.025851
 9561/10000: episode: 1237, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001195, mae: 0.019297, mean_q: 0.034919
 9568/10000: episode: 1238, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000952, mae: 0.016876, mean_q: 0.019486
 9575/10000: episode: 1239, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001916, mae: 0.016428, mean_q: 0.022484
 9582/10000: episode: 1240, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001439, mae: 0.020920, mean_q: 0.037941
 9589/10000: episode: 1241, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001435, mae: 0.020599, mean_q: 0.033766
 9596/10000: episode: 1242, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.001770, mae: 0.018803, mean_q: 0.024508
 9600/10000: episode: 1243, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000913, mae: 0.019768, mean_q: 0.023957
 9607/10000: episode: 1244, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000853, mae: 0.018533, mean_q: 0.027757
 9614/10000: episode: 1245, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002069, mae: 0.021459, mean_q: 0.027199
 9621/10000: episode: 1246, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001047, mae: 0.018888, mean_q: 0.030626
 9625/10000: episode: 1247, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000554, mae: 0.011489, mean_q: 0.018127
 9632/10000: episode: 1248, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001358, mae: 0.015239, mean_q: 0.023056
 9636/10000: episode: 1249, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.004075, mae: 0.034940, mean_q: 0.048423
 9640/10000: episode: 1250, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000536, mae: 0.014612, mean_q: 0.023456
 9644/10000: episode: 1251, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000884, mae: 0.017813, mean_q: 0.027236
 9648/10000: episode: 1252, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000432, mae: 0.012348, mean_q: 0.015045
 9652/10000: episode: 1253, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001419, mae: 0.018503, mean_q: 0.021341
 9659/10000: episode: 1254, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.002138, mae: 0.017692, mean_q: 0.022541
 9663/10000: episode: 1255, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000418, mae: 0.013012, mean_q: 0.020222
 9667/10000: episode: 1256, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000572, mae: 0.012009, mean_q: 0.022335
 9674/10000: episode: 1257, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000579, mae: 0.013084, mean_q: 0.020035
 9681/10000: episode: 1258, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000852, mae: 0.013807, mean_q: 0.020757
 9685/10000: episode: 1259, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000561, mae: 0.013190, mean_q: 0.021905
 9689/10000: episode: 1260, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000690, mae: 0.014362, mean_q: 0.024039
 9696/10000: episode: 1261, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000843, mae: 0.015248, mean_q: 0.019656
 9703/10000: episode: 1262, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000258, mae: 0.009983, mean_q: 0.016568
 9707/10000: episode: 1263, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003460, mae: 0.023925, mean_q: 0.028216
 9711/10000: episode: 1264, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000650, mae: 0.013528, mean_q: 0.017949
 9715/10000: episode: 1265, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001349, mae: 0.017900, mean_q: 0.024283
 9719/10000: episode: 1266, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000832, mae: 0.016214, mean_q: 0.033301
 9726/10000: episode: 1267, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000630, mae: 0.013723, mean_q: 0.024643
 9733/10000: episode: 1268, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000493, mae: 0.013190, mean_q: 0.020614
 9737/10000: episode: 1269, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000986, mae: 0.019331, mean_q: 0.030599
 9741/10000: episode: 1270, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000362, mae: 0.011650, mean_q: 0.016186
 9748/10000: episode: 1271, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001716, mae: 0.014743, mean_q: 0.011281
[Info] Complete ISplit Iteration
[Info] Levels: [0.034880742, 0.9622665]
[Info] Cond. Prob: [0.1, 0.02]
[Info] Error Prob: 0.002

 9755/10000: episode: 1272, duration: 0.834s, episode steps: 7, steps per second: 8, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001737, mae: 0.017663, mean_q: 0.021230
 9765/10000: episode: 1273, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001300, mae: 0.020873, mean_q: 0.034538
 9775/10000: episode: 1274, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000379, mae: 0.013500, mean_q: 0.018054
 9785/10000: episode: 1275, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000713, mae: 0.014386, mean_q: 0.017341
 9795/10000: episode: 1276, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001317, mae: 0.016172, mean_q: 0.020061
 9805/10000: episode: 1277, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000835, mae: 0.016183, mean_q: 0.026322
 9815/10000: episode: 1278, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000751, mae: 0.015717, mean_q: 0.021644
 9825/10000: episode: 1279, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001473, mae: 0.015117, mean_q: 0.012941
 9835/10000: episode: 1280, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001098, mae: 0.020511, mean_q: 0.035689
 9845/10000: episode: 1281, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000531, mae: 0.012832, mean_q: 0.019595
 9855/10000: episode: 1282, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000825, mae: 0.015934, mean_q: 0.024069
 9865/10000: episode: 1283, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002067, mae: 0.022551, mean_q: 0.028567
 9875/10000: episode: 1284, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000541, mae: 0.013368, mean_q: 0.018362
 9885/10000: episode: 1285, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000604, mae: 0.013199, mean_q: 0.016457
 9895/10000: episode: 1286, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000562, mae: 0.015413, mean_q: 0.017586
 9905/10000: episode: 1287, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000940, mae: 0.016408, mean_q: 0.024643
 9915/10000: episode: 1288, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001581, mae: 0.018926, mean_q: 0.019922
 9925/10000: episode: 1289, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001164, mae: 0.018764, mean_q: 0.030663
 9935/10000: episode: 1290, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000938, mae: 0.017566, mean_q: 0.028972
 9945/10000: episode: 1291, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001529, mae: 0.018103, mean_q: 0.020304
 9955/10000: episode: 1292, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001172, mae: 0.018799, mean_q: 0.028147
 9965/10000: episode: 1293, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000557, mae: 0.014057, mean_q: 0.021432
 9975/10000: episode: 1294, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000413, mae: 0.013696, mean_q: 0.016243
 9985/10000: episode: 1295, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000868, mae: 0.016371, mean_q: 0.027701
 9995/10000: episode: 1296, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001730, mae: 0.018007, mean_q: 0.018872
done, took 62.859 seconds
[Info] End Importance Splitting. Falsification occurred 17 times.
