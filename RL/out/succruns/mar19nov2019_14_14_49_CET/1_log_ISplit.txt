Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          (None, 2)                 0         
_________________________________________________________________
dense_1 (Dense)              (None, 16)                48        
_________________________________________________________________
dense_2 (Dense)              (None, 8)                 136       
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 9         
=================================================================
Total params: 193
Trainable params: 193
Non-trainable params: 0
_________________________________________________________________
None
[Info] Start Importance Splitting on succruns-v1.
Training for 10000 steps ...
   10/10000: episode: 1, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   20/10000: episode: 2, duration: 0.005s, episode steps: 10, steps per second: 1954, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   30/10000: episode: 3, duration: 0.005s, episode steps: 10, steps per second: 2024, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   40/10000: episode: 4, duration: 0.005s, episode steps: 10, steps per second: 1912, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   50/10000: episode: 5, duration: 0.005s, episode steps: 10, steps per second: 1949, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   60/10000: episode: 6, duration: 0.005s, episode steps: 10, steps per second: 2060, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   70/10000: episode: 7, duration: 0.005s, episode steps: 10, steps per second: 1902, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   80/10000: episode: 8, duration: 0.005s, episode steps: 10, steps per second: 1894, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   90/10000: episode: 9, duration: 0.005s, episode steps: 10, steps per second: 2037, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  100/10000: episode: 10, duration: 0.008s, episode steps: 10, steps per second: 1252, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  110/10000: episode: 11, duration: 0.005s, episode steps: 10, steps per second: 2032, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  120/10000: episode: 12, duration: 0.005s, episode steps: 10, steps per second: 1824, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  130/10000: episode: 13, duration: 0.005s, episode steps: 10, steps per second: 1956, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  140/10000: episode: 14, duration: 0.005s, episode steps: 10, steps per second: 2028, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  150/10000: episode: 15, duration: 0.005s, episode steps: 10, steps per second: 1946, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  160/10000: episode: 16, duration: 0.005s, episode steps: 10, steps per second: 1907, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  170/10000: episode: 17, duration: 0.005s, episode steps: 10, steps per second: 2041, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  180/10000: episode: 18, duration: 0.005s, episode steps: 10, steps per second: 2077, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  190/10000: episode: 19, duration: 0.005s, episode steps: 10, steps per second: 1931, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  200/10000: episode: 20, duration: 0.005s, episode steps: 10, steps per second: 2063, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  210/10000: episode: 21, duration: 0.005s, episode steps: 10, steps per second: 2086, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  220/10000: episode: 22, duration: 0.005s, episode steps: 10, steps per second: 1970, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  230/10000: episode: 23, duration: 0.005s, episode steps: 10, steps per second: 2129, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  240/10000: episode: 24, duration: 0.005s, episode steps: 10, steps per second: 2104, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  250/10000: episode: 25, duration: 0.005s, episode steps: 10, steps per second: 2025, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  260/10000: episode: 26, duration: 0.005s, episode steps: 10, steps per second: 2094, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  270/10000: episode: 27, duration: 0.005s, episode steps: 10, steps per second: 2167, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  280/10000: episode: 28, duration: 0.005s, episode steps: 10, steps per second: 2187, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  290/10000: episode: 29, duration: 0.005s, episode steps: 10, steps per second: 2194, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  300/10000: episode: 30, duration: 0.005s, episode steps: 10, steps per second: 2126, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  310/10000: episode: 31, duration: 0.005s, episode steps: 10, steps per second: 2188, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  320/10000: episode: 32, duration: 0.005s, episode steps: 10, steps per second: 2167, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  330/10000: episode: 33, duration: 0.005s, episode steps: 10, steps per second: 2203, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  340/10000: episode: 34, duration: 0.005s, episode steps: 10, steps per second: 2154, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  350/10000: episode: 35, duration: 0.005s, episode steps: 10, steps per second: 2117, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  360/10000: episode: 36, duration: 0.005s, episode steps: 10, steps per second: 2137, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  370/10000: episode: 37, duration: 0.005s, episode steps: 10, steps per second: 2178, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  380/10000: episode: 38, duration: 0.005s, episode steps: 10, steps per second: 2062, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  390/10000: episode: 39, duration: 0.005s, episode steps: 10, steps per second: 2200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  400/10000: episode: 40, duration: 0.004s, episode steps: 10, steps per second: 2247, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  410/10000: episode: 41, duration: 0.005s, episode steps: 10, steps per second: 2088, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  420/10000: episode: 42, duration: 0.005s, episode steps: 10, steps per second: 2116, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  430/10000: episode: 43, duration: 0.005s, episode steps: 10, steps per second: 2097, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  440/10000: episode: 44, duration: 0.005s, episode steps: 10, steps per second: 2199, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  450/10000: episode: 45, duration: 0.005s, episode steps: 10, steps per second: 2163, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  460/10000: episode: 46, duration: 0.005s, episode steps: 10, steps per second: 2179, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  470/10000: episode: 47, duration: 0.005s, episode steps: 10, steps per second: 2184, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  480/10000: episode: 48, duration: 0.005s, episode steps: 10, steps per second: 2207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  490/10000: episode: 49, duration: 0.004s, episode steps: 10, steps per second: 2229, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  500/10000: episode: 50, duration: 0.005s, episode steps: 10, steps per second: 2154, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  510/10000: episode: 51, duration: 0.945s, episode steps: 10, steps per second: 11, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.019446, mae: 0.126531, mean_q: -0.280995
  520/10000: episode: 52, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.009854, mae: 0.110660, mean_q: -0.114119
  530/10000: episode: 53, duration: 0.121s, episode steps: 10, steps per second: 83, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.007246, mae: 0.093115, mean_q: -0.113468
  540/10000: episode: 54, duration: 0.118s, episode steps: 10, steps per second: 85, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.006043, mae: 0.073067, mean_q: -0.135547
  550/10000: episode: 55, duration: 0.113s, episode steps: 10, steps per second: 89, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.004876, mae: 0.065772, mean_q: -0.121640
  560/10000: episode: 56, duration: 0.140s, episode steps: 10, steps per second: 72, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.003389, mae: 0.053965, mean_q: -0.114815
  570/10000: episode: 57, duration: 0.113s, episode steps: 10, steps per second: 89, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.003202, mae: 0.046862, mean_q: -0.137739
  580/10000: episode: 58, duration: 0.109s, episode steps: 10, steps per second: 92, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002984, mae: 0.053921, mean_q: -0.104073
  590/10000: episode: 59, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001897, mae: 0.044357, mean_q: -0.107753
  600/10000: episode: 60, duration: 0.093s, episode steps: 10, steps per second: 108, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001865, mae: 0.040504, mean_q: -0.108970
  610/10000: episode: 61, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001638, mae: 0.042886, mean_q: -0.089109
  620/10000: episode: 62, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001210, mae: 0.034705, mean_q: -0.091348
  630/10000: episode: 63, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000885, mae: 0.029573, mean_q: -0.091191
  640/10000: episode: 64, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001099, mae: 0.033037, mean_q: -0.079889
  650/10000: episode: 65, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000787, mae: 0.028543, mean_q: -0.077299
  660/10000: episode: 66, duration: 0.073s, episode steps: 10, steps per second: 138, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000679, mae: 0.025917, mean_q: -0.076517
  670/10000: episode: 67, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000551, mae: 0.024889, mean_q: -0.067790
  680/10000: episode: 68, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000566, mae: 0.024143, mean_q: -0.068642
  690/10000: episode: 69, duration: 0.074s, episode steps: 10, steps per second: 136, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000598, mae: 0.025961, mean_q: -0.057458
  700/10000: episode: 70, duration: 0.067s, episode steps: 10, steps per second: 148, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000432, mae: 0.020496, mean_q: -0.063498
  710/10000: episode: 71, duration: 0.074s, episode steps: 10, steps per second: 136, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000368, mae: 0.018927, mean_q: -0.057059
  720/10000: episode: 72, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000356, mae: 0.019728, mean_q: -0.048867
  730/10000: episode: 73, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000238, mae: 0.016174, mean_q: -0.046388
  740/10000: episode: 74, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000276, mae: 0.016790, mean_q: -0.043311
  750/10000: episode: 75, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000193, mae: 0.014413, mean_q: -0.045492
  760/10000: episode: 76, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000187, mae: 0.013860, mean_q: -0.041560
  770/10000: episode: 77, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000156, mae: 0.012810, mean_q: -0.039051
  780/10000: episode: 78, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000150, mae: 0.012439, mean_q: -0.035368
  790/10000: episode: 79, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000165, mae: 0.013333, mean_q: -0.034359
  800/10000: episode: 80, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000095, mae: 0.010415, mean_q: -0.031378
  810/10000: episode: 81, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000095, mae: 0.009708, mean_q: -0.030450
  820/10000: episode: 82, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000090, mae: 0.009395, mean_q: -0.028084
  830/10000: episode: 83, duration: 0.103s, episode steps: 10, steps per second: 97, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000125, mae: 0.011281, mean_q: -0.025895
  840/10000: episode: 84, duration: 0.071s, episode steps: 10, steps per second: 140, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000090, mae: 0.009606, mean_q: -0.023951
  850/10000: episode: 85, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000075, mae: 0.009156, mean_q: -0.021086
  860/10000: episode: 86, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000068, mae: 0.007613, mean_q: -0.023470
  870/10000: episode: 87, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000071, mae: 0.008392, mean_q: -0.018738
  880/10000: episode: 88, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000061, mae: 0.007213, mean_q: -0.018315
  890/10000: episode: 89, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000064, mae: 0.007900, mean_q: -0.016091
  900/10000: episode: 90, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000060, mae: 0.006760, mean_q: -0.018059
  910/10000: episode: 91, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000046, mae: 0.006702, mean_q: -0.013394
  920/10000: episode: 92, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000052, mae: 0.006538, mean_q: -0.014530
  930/10000: episode: 93, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000048, mae: 0.006600, mean_q: -0.012531
  940/10000: episode: 94, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000038, mae: 0.005746, mean_q: -0.011941
  950/10000: episode: 95, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000095, mae: 0.007060, mean_q: -0.011574
  960/10000: episode: 96, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000043, mae: 0.006432, mean_q: -0.008753
  970/10000: episode: 97, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000051, mae: 0.006457, mean_q: -0.008725
  980/10000: episode: 98, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000036, mae: 0.005403, mean_q: -0.009746
  990/10000: episode: 99, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000048, mae: 0.006644, mean_q: -0.007649
 1000/10000: episode: 100, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000057, mae: 0.005673, mean_q: -0.006726
 1010/10000: episode: 101, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000044, mae: 0.006042, mean_q: -0.006528
 1020/10000: episode: 102, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000027, mae: 0.005027, mean_q: -0.005506
 1030/10000: episode: 103, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000037, mae: 0.005380, mean_q: -0.005083
 1040/10000: episode: 104, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000034, mae: 0.005251, mean_q: -0.003721
 1050/10000: episode: 105, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000038, mae: 0.005306, mean_q: -0.003746
 1060/10000: episode: 106, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000029, mae: 0.004641, mean_q: -0.004870
 1070/10000: episode: 107, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000054, mae: 0.005886, mean_q: -0.000921
 1080/10000: episode: 108, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000036, mae: 0.005675, mean_q: -0.004027
 1090/10000: episode: 109, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000087, mae: 0.006180, mean_q: -0.001113
 1100/10000: episode: 110, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000074, mae: 0.006557, mean_q: -0.002097
 1110/10000: episode: 111, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000054, mae: 0.005890, mean_q: 0.000000
 1120/10000: episode: 112, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000042, mae: 0.005430, mean_q: -0.001600
 1130/10000: episode: 113, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000042, mae: 0.005861, mean_q: -0.000417
 1140/10000: episode: 114, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000054, mae: 0.005397, mean_q: -0.000118
 1150/10000: episode: 115, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000061, mae: 0.006197, mean_q: 0.000588
 1160/10000: episode: 116, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000053, mae: 0.005956, mean_q: 0.001939
 1170/10000: episode: 117, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000062, mae: 0.005930, mean_q: 0.000526
 1180/10000: episode: 118, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000046, mae: 0.006006, mean_q: -0.000756
 1190/10000: episode: 119, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000076, mae: 0.007077, mean_q: 0.003065
 1200/10000: episode: 120, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000104, mae: 0.007117, mean_q: 0.003138
 1210/10000: episode: 121, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000046, mae: 0.005661, mean_q: 0.000187
 1220/10000: episode: 122, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000060, mae: 0.006679, mean_q: 0.002630
 1230/10000: episode: 123, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000090, mae: 0.007118, mean_q: 0.003672
 1240/10000: episode: 124, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000093, mae: 0.007137, mean_q: 0.001291
 1250/10000: episode: 125, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000040, mae: 0.006000, mean_q: 0.003717
 1260/10000: episode: 126, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000041, mae: 0.005672, mean_q: 0.002502
 1270/10000: episode: 127, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000061, mae: 0.006465, mean_q: 0.001354
 1280/10000: episode: 128, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000034, mae: 0.005119, mean_q: 0.001574
 1290/10000: episode: 129, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000083, mae: 0.006445, mean_q: 0.005831
 1300/10000: episode: 130, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000098, mae: 0.007086, mean_q: 0.002451
 1310/10000: episode: 131, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000069, mae: 0.007097, mean_q: 0.005259
 1320/10000: episode: 132, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000059, mae: 0.006470, mean_q: 0.004866
 1330/10000: episode: 133, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000048, mae: 0.006014, mean_q: 0.001676
 1340/10000: episode: 134, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000037, mae: 0.005393, mean_q: 0.003804
 1350/10000: episode: 135, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000065, mae: 0.005776, mean_q: 0.003428
 1360/10000: episode: 136, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000067, mae: 0.006715, mean_q: 0.004313
 1370/10000: episode: 137, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000086, mae: 0.007160, mean_q: 0.004060
 1380/10000: episode: 138, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000075, mae: 0.006773, mean_q: 0.004988
 1390/10000: episode: 139, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000055, mae: 0.005647, mean_q: 0.004099
 1400/10000: episode: 140, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000099, mae: 0.006528, mean_q: 0.004512
 1410/10000: episode: 141, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000077, mae: 0.007336, mean_q: 0.002584
 1420/10000: episode: 142, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000096, mae: 0.007575, mean_q: 0.006110
 1430/10000: episode: 143, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000067, mae: 0.006333, mean_q: 0.004472
 1440/10000: episode: 144, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000043, mae: 0.005674, mean_q: 0.004721
 1450/10000: episode: 145, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000038, mae: 0.005557, mean_q: 0.004837
 1460/10000: episode: 146, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000088, mae: 0.006439, mean_q: 0.005693
 1470/10000: episode: 147, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000067, mae: 0.006048, mean_q: 0.004823
 1480/10000: episode: 148, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000072, mae: 0.006576, mean_q: 0.005312
 1490/10000: episode: 149, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000047, mae: 0.006162, mean_q: 0.004648
[Info] 1-TH LEVEL FOUND: 0.04354080185294151, Considering 11/100 traces
 1500/10000: episode: 150, duration: 1.085s, episode steps: 10, steps per second: 9, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000046, mae: 0.005652, mean_q: 0.002088
 1502/10000: episode: 151, duration: 0.018s, episode steps: 2, steps per second: 109, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000073, mae: 0.007359, mean_q: 0.007409
 1505/10000: episode: 152, duration: 0.022s, episode steps: 3, steps per second: 137, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000052, mae: 0.005535, mean_q: 0.002461
 1510/10000: episode: 153, duration: 0.030s, episode steps: 5, steps per second: 167, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000098, mae: 0.006733, mean_q: 0.003603
 1513/10000: episode: 154, duration: 0.022s, episode steps: 3, steps per second: 139, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000256, mae: 0.008933, mean_q: 0.005641
 1518/10000: episode: 155, duration: 0.032s, episode steps: 5, steps per second: 154, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000098, mae: 0.007831, mean_q: 0.007606
 1520/10000: episode: 156, duration: 0.033s, episode steps: 2, steps per second: 61, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000054, mae: 0.006421, mean_q: 0.005516
 1523/10000: episode: 157, duration: 0.036s, episode steps: 3, steps per second: 83, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000060, mae: 0.007968, mean_q: 0.008888
 1528/10000: episode: 158, duration: 0.059s, episode steps: 5, steps per second: 84, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000182, mae: 0.009354, mean_q: 0.002667
 1533/10000: episode: 159, duration: 0.047s, episode steps: 5, steps per second: 106, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000112, mae: 0.008557, mean_q: 0.004479
 1535/10000: episode: 160, duration: 0.018s, episode steps: 2, steps per second: 109, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000249, mae: 0.010792, mean_q: 0.008228
 1537/10000: episode: 161, duration: 0.018s, episode steps: 2, steps per second: 109, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000209, mae: 0.010406, mean_q: 0.007104
 1540/10000: episode: 162, duration: 0.034s, episode steps: 3, steps per second: 89, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000282, mae: 0.012308, mean_q: -0.001407
 1545/10000: episode: 163, duration: 0.053s, episode steps: 5, steps per second: 95, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000146, mae: 0.009657, mean_q: 0.009099
 1547/10000: episode: 164, duration: 0.028s, episode steps: 2, steps per second: 72, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000238, mae: 0.010307, mean_q: 0.008338
 1549/10000: episode: 165, duration: 0.027s, episode steps: 2, steps per second: 73, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000293, mae: 0.012546, mean_q: -0.005050
 1551/10000: episode: 166, duration: 0.028s, episode steps: 2, steps per second: 71, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000181, mae: 0.008305, mean_q: 0.002460
 1553/10000: episode: 167, duration: 0.042s, episode steps: 2, steps per second: 48, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000295, mae: 0.014454, mean_q: 0.016423
 1556/10000: episode: 168, duration: 0.039s, episode steps: 3, steps per second: 77, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000343, mae: 0.013865, mean_q: 0.004592
 1558/10000: episode: 169, duration: 0.036s, episode steps: 2, steps per second: 56, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000555, mae: 0.019673, mean_q: -0.005543
 1560/10000: episode: 170, duration: 0.026s, episode steps: 2, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000482, mae: 0.015302, mean_q: 0.007842
 1565/10000: episode: 171, duration: 0.054s, episode steps: 5, steps per second: 93, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000338, mae: 0.012431, mean_q: 0.007375
[Info] FALSIFICATION!
 1569/10000: episode: 172, duration: 0.591s, episode steps: 4, steps per second: 7, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000508, mae: 0.018114, mean_q: -0.003454
 1572/10000: episode: 173, duration: 0.046s, episode steps: 3, steps per second: 65, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000359, mae: 0.013029, mean_q: 0.001450
 1575/10000: episode: 174, duration: 0.038s, episode steps: 3, steps per second: 79, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001287, mae: 0.027324, mean_q: 0.022946
 1577/10000: episode: 175, duration: 0.023s, episode steps: 2, steps per second: 87, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000805, mae: 0.024903, mean_q: 0.028287
 1580/10000: episode: 176, duration: 0.033s, episode steps: 3, steps per second: 90, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000601, mae: 0.019299, mean_q: 0.001633
 1583/10000: episode: 177, duration: 0.034s, episode steps: 3, steps per second: 88, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000608, mae: 0.022755, mean_q: -0.017474
 1588/10000: episode: 178, duration: 0.050s, episode steps: 5, steps per second: 99, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000717, mae: 0.022436, mean_q: 0.020261
 1591/10000: episode: 179, duration: 0.038s, episode steps: 3, steps per second: 78, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000192, mae: 0.012085, mean_q: 0.005024
 1593/10000: episode: 180, duration: 0.025s, episode steps: 2, steps per second: 80, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000490, mae: 0.020991, mean_q: -0.002364
 1598/10000: episode: 181, duration: 0.059s, episode steps: 5, steps per second: 85, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000294, mae: 0.013667, mean_q: 0.007254
 1601/10000: episode: 182, duration: 0.034s, episode steps: 3, steps per second: 89, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000202, mae: 0.011759, mean_q: 0.007131
 1604/10000: episode: 183, duration: 0.054s, episode steps: 3, steps per second: 56, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000300, mae: 0.014064, mean_q: 0.006057
 1606/10000: episode: 184, duration: 0.029s, episode steps: 2, steps per second: 68, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000258, mae: 0.017067, mean_q: 0.002032
 1611/10000: episode: 185, duration: 0.050s, episode steps: 5, steps per second: 101, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000373, mae: 0.014133, mean_q: 0.007728
 1613/10000: episode: 186, duration: 0.026s, episode steps: 2, steps per second: 78, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000332, mae: 0.014199, mean_q: 0.007143
 1618/10000: episode: 187, duration: 0.061s, episode steps: 5, steps per second: 81, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000654, mae: 0.015699, mean_q: 0.007885
 1620/10000: episode: 188, duration: 0.031s, episode steps: 2, steps per second: 65, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000391, mae: 0.015080, mean_q: 0.011540
 1625/10000: episode: 189, duration: 0.065s, episode steps: 5, steps per second: 77, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.003196, mae: 0.022712, mean_q: 0.013264
 1628/10000: episode: 190, duration: 0.034s, episode steps: 3, steps per second: 87, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000459, mae: 0.019128, mean_q: 0.015236
 1630/10000: episode: 191, duration: 0.027s, episode steps: 2, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000585, mae: 0.023387, mean_q: -0.007526
[Info] FALSIFICATION!
 1634/10000: episode: 192, duration: 0.355s, episode steps: 4, steps per second: 11, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000263, mae: 0.013619, mean_q: 0.008507
 1636/10000: episode: 193, duration: 0.039s, episode steps: 2, steps per second: 51, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000397, mae: 0.018141, mean_q: 0.019530
 1639/10000: episode: 194, duration: 0.052s, episode steps: 3, steps per second: 57, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000211, mae: 0.014834, mean_q: 0.001344
 1641/10000: episode: 195, duration: 0.033s, episode steps: 2, steps per second: 61, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.007309, mae: 0.034124, mean_q: -0.006613
 1644/10000: episode: 196, duration: 0.033s, episode steps: 3, steps per second: 90, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000628, mae: 0.020302, mean_q: 0.024084
 1646/10000: episode: 197, duration: 0.026s, episode steps: 2, steps per second: 78, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000463, mae: 0.019722, mean_q: 0.023541
 1648/10000: episode: 198, duration: 0.033s, episode steps: 2, steps per second: 61, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005756, mae: 0.029586, mean_q: 0.009831
 1650/10000: episode: 199, duration: 0.032s, episode steps: 2, steps per second: 62, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000726, mae: 0.024586, mean_q: 0.012266
 1653/10000: episode: 200, duration: 0.037s, episode steps: 3, steps per second: 81, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000815, mae: 0.023330, mean_q: 0.007769
 1655/10000: episode: 201, duration: 0.029s, episode steps: 2, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000356, mae: 0.017277, mean_q: 0.009184
 1658/10000: episode: 202, duration: 0.037s, episode steps: 3, steps per second: 82, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000378, mae: 0.015850, mean_q: 0.014713
 1661/10000: episode: 203, duration: 0.039s, episode steps: 3, steps per second: 76, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000117, mae: 0.011591, mean_q: 0.005471
 1663/10000: episode: 204, duration: 0.024s, episode steps: 2, steps per second: 85, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000239, mae: 0.014195, mean_q: 0.002107
 1666/10000: episode: 205, duration: 0.027s, episode steps: 3, steps per second: 111, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001148, mae: 0.021418, mean_q: 0.006474
 1668/10000: episode: 206, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000422, mae: 0.017045, mean_q: 0.014821
 1671/10000: episode: 207, duration: 0.022s, episode steps: 3, steps per second: 134, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000309, mae: 0.015787, mean_q: 0.002195
 1674/10000: episode: 208, duration: 0.023s, episode steps: 3, steps per second: 132, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000381, mae: 0.019175, mean_q: -0.001565
 1676/10000: episode: 209, duration: 0.018s, episode steps: 2, steps per second: 109, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000317, mae: 0.015996, mean_q: 0.013650
 1681/10000: episode: 210, duration: 0.049s, episode steps: 5, steps per second: 102, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000277, mae: 0.015675, mean_q: 0.008618
 1683/10000: episode: 211, duration: 0.027s, episode steps: 2, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000483, mae: 0.020808, mean_q: -0.002107
 1686/10000: episode: 212, duration: 0.047s, episode steps: 3, steps per second: 64, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000416, mae: 0.019086, mean_q: 0.009601
 1691/10000: episode: 213, duration: 0.042s, episode steps: 5, steps per second: 120, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000317, mae: 0.016592, mean_q: 0.008682
 1694/10000: episode: 214, duration: 0.032s, episode steps: 3, steps per second: 94, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000363, mae: 0.015558, mean_q: 0.010624
 1699/10000: episode: 215, duration: 0.048s, episode steps: 5, steps per second: 103, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.002947, mae: 0.025623, mean_q: 0.019240
 1702/10000: episode: 216, duration: 0.032s, episode steps: 3, steps per second: 95, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000662, mae: 0.017830, mean_q: -0.001128
 1705/10000: episode: 217, duration: 0.036s, episode steps: 3, steps per second: 84, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003828, mae: 0.025685, mean_q: 0.020197
[Info] FALSIFICATION!
 1709/10000: episode: 218, duration: 0.335s, episode steps: 4, steps per second: 12, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000585, mae: 0.020468, mean_q: 0.023382
 1712/10000: episode: 219, duration: 0.034s, episode steps: 3, steps per second: 88, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001013, mae: 0.029078, mean_q: -0.004352
 1715/10000: episode: 220, duration: 0.038s, episode steps: 3, steps per second: 78, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000518, mae: 0.014833, mean_q: 0.014948
 1720/10000: episode: 221, duration: 0.042s, episode steps: 5, steps per second: 120, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.002553, mae: 0.028267, mean_q: 0.035698
 1723/10000: episode: 222, duration: 0.029s, episode steps: 3, steps per second: 102, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000764, mae: 0.023747, mean_q: -0.002378
 1726/10000: episode: 223, duration: 0.030s, episode steps: 3, steps per second: 100, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004180, mae: 0.031756, mean_q: 0.020037
 1731/10000: episode: 224, duration: 0.041s, episode steps: 5, steps per second: 121, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002982, mae: 0.035797, mean_q: 0.043883
 1736/10000: episode: 225, duration: 0.042s, episode steps: 5, steps per second: 120, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.003635, mae: 0.038333, mean_q: -0.006416
 1738/10000: episode: 226, duration: 0.028s, episode steps: 2, steps per second: 73, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001035, mae: 0.026598, mean_q: 0.033558
 1740/10000: episode: 227, duration: 0.018s, episode steps: 2, steps per second: 109, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001101, mae: 0.028316, mean_q: 0.033093
 1743/10000: episode: 228, duration: 0.027s, episode steps: 3, steps per second: 112, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001176, mae: 0.033497, mean_q: -0.012880
 1745/10000: episode: 229, duration: 0.019s, episode steps: 2, steps per second: 104, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000381, mae: 0.017986, mean_q: 0.014521
 1747/10000: episode: 230, duration: 0.025s, episode steps: 2, steps per second: 79, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000804, mae: 0.028418, mean_q: 0.041665
 1749/10000: episode: 231, duration: 0.022s, episode steps: 2, steps per second: 92, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000913, mae: 0.020353, mean_q: 0.018095
 1752/10000: episode: 232, duration: 0.032s, episode steps: 3, steps per second: 93, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000510, mae: 0.024252, mean_q: -0.005775
 1757/10000: episode: 233, duration: 0.044s, episode steps: 5, steps per second: 114, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000328, mae: 0.016081, mean_q: 0.013036
 1759/10000: episode: 234, duration: 0.022s, episode steps: 2, steps per second: 90, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000405, mae: 0.016134, mean_q: 0.021949
 1762/10000: episode: 235, duration: 0.033s, episode steps: 3, steps per second: 92, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000694, mae: 0.017995, mean_q: 0.014124
 1765/10000: episode: 236, duration: 0.029s, episode steps: 3, steps per second: 103, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000250, mae: 0.015071, mean_q: 0.005198
 1767/10000: episode: 237, duration: 0.022s, episode steps: 2, steps per second: 90, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000179, mae: 0.012860, mean_q: 0.006341
 1770/10000: episode: 238, duration: 0.030s, episode steps: 3, steps per second: 99, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000450, mae: 0.016415, mean_q: 0.008779
[Info] Complete ISplit Iteration
[Info] Levels: [0.0435408, 0.2721142]
[Info] Cond. Prob: [0.11, 0.03]
[Info] Error Prob: 0.0033

 1775/10000: episode: 239, duration: 0.977s, episode steps: 5, steps per second: 5, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.004402, mae: 0.025997, mean_q: 0.016352
 1785/10000: episode: 240, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001512, mae: 0.024617, mean_q: 0.017074
 1795/10000: episode: 241, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001488, mae: 0.020395, mean_q: 0.014001
 1805/10000: episode: 242, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000620, mae: 0.020885, mean_q: 0.009424
 1815/10000: episode: 243, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000395, mae: 0.017073, mean_q: 0.016414
 1825/10000: episode: 244, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000814, mae: 0.019454, mean_q: 0.015110
 1835/10000: episode: 245, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001647, mae: 0.020603, mean_q: 0.018153
 1845/10000: episode: 246, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002596, mae: 0.024646, mean_q: 0.018390
 1855/10000: episode: 247, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001638, mae: 0.023214, mean_q: 0.016930
 1865/10000: episode: 248, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000589, mae: 0.016852, mean_q: 0.009361
 1875/10000: episode: 249, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000352, mae: 0.016285, mean_q: 0.005869
 1885/10000: episode: 250, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000598, mae: 0.019251, mean_q: 0.018080
 1895/10000: episode: 251, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000661, mae: 0.018790, mean_q: 0.011869
 1905/10000: episode: 252, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001617, mae: 0.020657, mean_q: 0.013279
 1915/10000: episode: 253, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000669, mae: 0.020320, mean_q: 0.009490
 1925/10000: episode: 254, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001706, mae: 0.020904, mean_q: 0.017409
 1935/10000: episode: 255, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000548, mae: 0.017346, mean_q: 0.013260
 1945/10000: episode: 256, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001232, mae: 0.015497, mean_q: 0.007528
 1955/10000: episode: 257, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000748, mae: 0.022995, mean_q: 0.014127
 1965/10000: episode: 258, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001557, mae: 0.022552, mean_q: 0.025917
 1975/10000: episode: 259, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.000585, mae: 0.018544, mean_q: 0.007850
 1985/10000: episode: 260, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000498, mae: 0.017213, mean_q: 0.011547
 1995/10000: episode: 261, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001477, mae: 0.019225, mean_q: 0.016828
 2005/10000: episode: 262, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001543, mae: 0.020830, mean_q: 0.021233
 2015/10000: episode: 263, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001507, mae: 0.020130, mean_q: 0.008453
 2025/10000: episode: 264, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002248, mae: 0.020893, mean_q: 0.018195
 2035/10000: episode: 265, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001781, mae: 0.024976, mean_q: 0.014595
 2045/10000: episode: 266, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001303, mae: 0.019018, mean_q: 0.010713
 2055/10000: episode: 267, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001378, mae: 0.020530, mean_q: 0.016466
 2065/10000: episode: 268, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000532, mae: 0.017421, mean_q: 0.011338
 2075/10000: episode: 269, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.003041, mae: 0.026120, mean_q: 0.025373
 2085/10000: episode: 270, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001606, mae: 0.026233, mean_q: 0.013246
 2095/10000: episode: 271, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001578, mae: 0.023038, mean_q: 0.018714
 2105/10000: episode: 272, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000349, mae: 0.018573, mean_q: 0.000962
 2115/10000: episode: 273, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000507, mae: 0.019403, mean_q: 0.011228
 2125/10000: episode: 274, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002645, mae: 0.028061, mean_q: 0.029249
 2135/10000: episode: 275, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000707, mae: 0.024303, mean_q: 0.006892
 2145/10000: episode: 276, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001387, mae: 0.020145, mean_q: 0.010454
 2155/10000: episode: 277, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000407, mae: 0.014821, mean_q: 0.014816
 2165/10000: episode: 278, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000595, mae: 0.016595, mean_q: 0.011101
 2175/10000: episode: 279, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001457, mae: 0.018813, mean_q: 0.016352
 2185/10000: episode: 280, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000464, mae: 0.014879, mean_q: 0.013237
 2195/10000: episode: 281, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000670, mae: 0.018529, mean_q: 0.015978
 2205/10000: episode: 282, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001921, mae: 0.023211, mean_q: 0.026666
 2215/10000: episode: 283, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000829, mae: 0.023735, mean_q: 0.012669
 2225/10000: episode: 284, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001727, mae: 0.022969, mean_q: 0.020493
 2235/10000: episode: 285, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001567, mae: 0.023956, mean_q: 0.013258
 2245/10000: episode: 286, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000438, mae: 0.018287, mean_q: 0.005240
 2255/10000: episode: 287, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001472, mae: 0.019520, mean_q: 0.018818
 2265/10000: episode: 288, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000468, mae: 0.015244, mean_q: 0.020991
 2275/10000: episode: 289, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000466, mae: 0.017630, mean_q: 0.006922
 2285/10000: episode: 290, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002523, mae: 0.024886, mean_q: 0.024178
 2295/10000: episode: 291, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001531, mae: 0.024065, mean_q: 0.016372
 2305/10000: episode: 292, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000387, mae: 0.017405, mean_q: 0.004626
 2315/10000: episode: 293, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001390, mae: 0.018105, mean_q: 0.011862
 2325/10000: episode: 294, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002059, mae: 0.022534, mean_q: 0.024191
 2335/10000: episode: 295, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001620, mae: 0.026947, mean_q: 0.020005
 2345/10000: episode: 296, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001005, mae: 0.026151, mean_q: 0.016777
 2355/10000: episode: 297, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000392, mae: 0.017000, mean_q: 0.007380
 2365/10000: episode: 298, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001454, mae: 0.018211, mean_q: 0.018436
 2375/10000: episode: 299, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000641, mae: 0.015332, mean_q: 0.012694
 2385/10000: episode: 300, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001919, mae: 0.024272, mean_q: 0.027395
 2395/10000: episode: 301, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000543, mae: 0.017264, mean_q: 0.014584
 2405/10000: episode: 302, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000455, mae: 0.017826, mean_q: 0.008323
 2415/10000: episode: 303, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000275, mae: 0.014610, mean_q: 0.006089
 2425/10000: episode: 304, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000468, mae: 0.016109, mean_q: 0.013255
 2435/10000: episode: 305, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001471, mae: 0.020663, mean_q: 0.017946
 2445/10000: episode: 306, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001489, mae: 0.019787, mean_q: 0.015424
 2455/10000: episode: 307, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000635, mae: 0.016800, mean_q: 0.007422
 2465/10000: episode: 308, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000448, mae: 0.017793, mean_q: 0.011721
 2475/10000: episode: 309, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001789, mae: 0.019937, mean_q: 0.018151
 2485/10000: episode: 310, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000800, mae: 0.017744, mean_q: 0.015775
 2495/10000: episode: 311, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000814, mae: 0.019891, mean_q: 0.015199
 2505/10000: episode: 312, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000499, mae: 0.016155, mean_q: 0.013715
 2515/10000: episode: 313, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002437, mae: 0.024311, mean_q: 0.021979
 2525/10000: episode: 314, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000641, mae: 0.019060, mean_q: 0.012922
 2535/10000: episode: 315, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000664, mae: 0.017214, mean_q: 0.013297
 2545/10000: episode: 316, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000330, mae: 0.013215, mean_q: 0.012203
 2555/10000: episode: 317, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000296, mae: 0.011882, mean_q: 0.008714
 2565/10000: episode: 318, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000581, mae: 0.016313, mean_q: 0.007869
 2575/10000: episode: 319, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002489, mae: 0.021020, mean_q: 0.020291
 2585/10000: episode: 320, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000708, mae: 0.020744, mean_q: 0.010247
 2595/10000: episode: 321, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001505, mae: 0.021827, mean_q: 0.012696
 2605/10000: episode: 322, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000360, mae: 0.012379, mean_q: 0.008056
 2615/10000: episode: 323, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000452, mae: 0.013004, mean_q: 0.008567
 2625/10000: episode: 324, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002737, mae: 0.025862, mean_q: 0.024639
 2635/10000: episode: 325, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000647, mae: 0.018169, mean_q: 0.015954
 2645/10000: episode: 326, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000411, mae: 0.015801, mean_q: 0.006542
 2655/10000: episode: 327, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000401, mae: 0.015013, mean_q: 0.015432
 2665/10000: episode: 328, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000705, mae: 0.016248, mean_q: 0.014393
 2675/10000: episode: 329, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000429, mae: 0.012828, mean_q: 0.013156
 2685/10000: episode: 330, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001498, mae: 0.018214, mean_q: 0.018083
 2695/10000: episode: 331, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000454, mae: 0.016507, mean_q: 0.009081
 2705/10000: episode: 332, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000380, mae: 0.012366, mean_q: 0.013272
 2715/10000: episode: 333, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000801, mae: 0.016978, mean_q: 0.017588
 2725/10000: episode: 334, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000738, mae: 0.016864, mean_q: 0.014050
 2735/10000: episode: 335, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001443, mae: 0.016186, mean_q: 0.011310
 2745/10000: episode: 336, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000454, mae: 0.013442, mean_q: 0.013512
 2755/10000: episode: 337, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000474, mae: 0.014352, mean_q: 0.012181
 2765/10000: episode: 338, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001338, mae: 0.017510, mean_q: 0.018412
[Info] 1-TH LEVEL FOUND: 0.0649290457367897, Considering 18/100 traces
 2775/10000: episode: 339, duration: 0.748s, episode steps: 10, steps per second: 13, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002118, mae: 0.019634, mean_q: 0.017620
 2783/10000: episode: 340, duration: 0.040s, episode steps: 8, steps per second: 202, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.001386, mae: 0.018835, mean_q: 0.014855
 2791/10000: episode: 341, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.071, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.001641, mae: 0.019178, mean_q: 0.013142
 2795/10000: episode: 342, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000302, mae: 0.008805, mean_q: 0.008129
 2803/10000: episode: 343, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.023, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000364, mae: 0.015155, mean_q: 0.005136
 2807/10000: episode: 344, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003065, mae: 0.026194, mean_q: 0.027695
 2815/10000: episode: 345, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.263, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.938 [-1.000, 11.000], loss: 0.000586, mae: 0.021560, mean_q: 0.008868
 2823/10000: episode: 346, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000520, mae: 0.015532, mean_q: 0.016334
 2831/10000: episode: 347, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.001535, mae: 0.018947, mean_q: 0.016745
 2839/10000: episode: 348, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000666, mae: 0.021888, mean_q: 0.004649
 2847/10000: episode: 349, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.812 [-1.000, 11.000], loss: 0.000607, mae: 0.018453, mean_q: 0.016402
 2851/10000: episode: 350, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000207, mae: 0.010484, mean_q: 0.000926
 2859/10000: episode: 351, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.146, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000422, mae: 0.011912, mean_q: 0.013028
 2863/10000: episode: 352, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002499, mae: 0.018528, mean_q: 0.018335
 2871/10000: episode: 353, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000334, mae: 0.015404, mean_q: 0.011860
 2875/10000: episode: 354, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000264, mae: 0.013086, mean_q: 0.011451
 2883/10000: episode: 355, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.030, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000209, mae: 0.012213, mean_q: 0.008654
 2891/10000: episode: 356, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.081, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000378, mae: 0.013443, mean_q: 0.012623
 2899/10000: episode: 357, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.001611, mae: 0.019341, mean_q: 0.017515
 2907/10000: episode: 358, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000575, mae: 0.016043, mean_q: 0.005793
 2915/10000: episode: 359, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000531, mae: 0.020377, mean_q: 0.024425
 2923/10000: episode: 360, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000471, mae: 0.017763, mean_q: 0.008323
 2931/10000: episode: 361, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.035, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.003920, mae: 0.022757, mean_q: 0.017416
 2939/10000: episode: 362, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.028, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000468, mae: 0.020111, mean_q: 0.012666
 2947/10000: episode: 363, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.044, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000438, mae: 0.016365, mean_q: 0.016310
 2955/10000: episode: 364, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.022, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000367, mae: 0.015189, mean_q: 0.011684
 2963/10000: episode: 365, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.812 [-1.000, 11.000], loss: 0.001431, mae: 0.016378, mean_q: 0.009427
 2971/10000: episode: 366, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.059, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000384, mae: 0.015631, mean_q: 0.013505
 2979/10000: episode: 367, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.028, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000352, mae: 0.013892, mean_q: 0.008688
 2987/10000: episode: 368, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.001685, mae: 0.022800, mean_q: 0.024741
 2995/10000: episode: 369, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.102, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000557, mae: 0.019242, mean_q: 0.005980
 3003/10000: episode: 370, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.097, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.001604, mae: 0.018689, mean_q: 0.014747
 3011/10000: episode: 371, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.348, mean reward: 0.044 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000413, mae: 0.014163, mean_q: 0.012661
 3019/10000: episode: 372, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.032, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000309, mae: 0.014642, mean_q: 0.003841
 3023/10000: episode: 373, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000367, mae: 0.016943, mean_q: 0.019201
 3031/10000: episode: 374, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.102, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000458, mae: 0.015907, mean_q: 0.013645
 3039/10000: episode: 375, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.134, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000253, mae: 0.011766, mean_q: 0.009221
 3047/10000: episode: 376, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.067, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000327, mae: 0.011528, mean_q: 0.005636
 3055/10000: episode: 377, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.231, mean reward: 0.029 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.002800, mae: 0.021658, mean_q: 0.022417
 3063/10000: episode: 378, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.177, mean reward: 0.022 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.000681, mae: 0.020417, mean_q: 0.016320
 3067/10000: episode: 379, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000231, mae: 0.011818, mean_q: 0.012953
 3075/10000: episode: 380, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.071, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.001347, mae: 0.015327, mean_q: 0.011370
 3083/10000: episode: 381, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.130, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000534, mae: 0.017327, mean_q: 0.016573
 3091/10000: episode: 382, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.081, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000317, mae: 0.012854, mean_q: 0.017351
 3095/10000: episode: 383, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000326, mae: 0.017675, mean_q: 0.000276
 3103/10000: episode: 384, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.032, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000409, mae: 0.015103, mean_q: 0.013878
 3111/10000: episode: 385, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000163, mae: 0.010241, mean_q: 0.005357
 3119/10000: episode: 386, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.231, mean reward: 0.029 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.000464, mae: 0.012784, mean_q: 0.014479
 3127/10000: episode: 387, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.059, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000869, mae: 0.016078, mean_q: 0.017027
 3135/10000: episode: 388, duration: 0.037s, episode steps: 8, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000486, mae: 0.012205, mean_q: 0.009895
 3143/10000: episode: 389, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.079, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000314, mae: 0.013660, mean_q: 0.014381
 3151/10000: episode: 390, duration: 0.037s, episode steps: 8, steps per second: 216, episode reward: 0.087, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000409, mae: 0.012377, mean_q: 0.013027
 3159/10000: episode: 391, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000420, mae: 0.012193, mean_q: 0.009578
 3167/10000: episode: 392, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000493, mae: 0.012340, mean_q: 0.012559
 3171/10000: episode: 393, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000185, mae: 0.010687, mean_q: 0.011243
 3179/10000: episode: 394, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.082, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000254, mae: 0.012437, mean_q: 0.006282
 3187/10000: episode: 395, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.081, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000690, mae: 0.021002, mean_q: 0.024748
 3195/10000: episode: 396, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.079, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001670, mae: 0.023466, mean_q: 0.013840
 3203/10000: episode: 397, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.130, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000562, mae: 0.022389, mean_q: 0.005766
 3207/10000: episode: 398, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000556, mae: 0.018235, mean_q: 0.021320
 3215/10000: episode: 399, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.030, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.001555, mae: 0.019689, mean_q: 0.011230
 3223/10000: episode: 400, duration: 0.037s, episode steps: 8, steps per second: 213, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000574, mae: 0.015160, mean_q: 0.016970
 3231/10000: episode: 401, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.177, mean reward: 0.022 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.001390, mae: 0.015743, mean_q: 0.013715
 3239/10000: episode: 402, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.215, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000658, mae: 0.018075, mean_q: 0.014812
 3247/10000: episode: 403, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.059, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000437, mae: 0.013103, mean_q: 0.009760
 3255/10000: episode: 404, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.013, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000497, mae: 0.015449, mean_q: 0.021068
 3263/10000: episode: 405, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.102, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.001593, mae: 0.018325, mean_q: 0.012662
 3271/10000: episode: 406, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000733, mae: 0.023844, mean_q: 0.013423
 3279/10000: episode: 407, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.044, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000397, mae: 0.017812, mean_q: 0.019086
 3287/10000: episode: 408, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.128, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.001399, mae: 0.019433, mean_q: 0.019334
 3295/10000: episode: 409, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.134, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001481, mae: 0.022003, mean_q: 0.010066
 3303/10000: episode: 410, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.059, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.001692, mae: 0.021041, mean_q: 0.020917
 3311/10000: episode: 411, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.001795, mae: 0.023373, mean_q: 0.021350
 3319/10000: episode: 412, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000631, mae: 0.022337, mean_q: 0.003558
 3327/10000: episode: 413, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.231, mean reward: 0.029 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.000468, mae: 0.018599, mean_q: 0.015707
 3335/10000: episode: 414, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.214, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000818, mae: 0.020168, mean_q: 0.020563
 3343/10000: episode: 415, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.001611, mae: 0.018147, mean_q: 0.016482
 3347/10000: episode: 416, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002453, mae: 0.019827, mean_q: 0.019262
 3355/10000: episode: 417, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.231, mean reward: 0.029 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.000574, mae: 0.017399, mean_q: 0.011831
 3363/10000: episode: 418, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.015, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.003045, mae: 0.020995, mean_q: 0.019917
 3371/10000: episode: 419, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000408, mae: 0.016730, mean_q: 0.011533
 3379/10000: episode: 420, duration: 0.037s, episode steps: 8, steps per second: 217, episode reward: 0.082, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001624, mae: 0.022537, mean_q: 0.028035
[Info] 2-TH LEVEL FOUND: 0.16529588401317596, Considering 10/100 traces
 3387/10000: episode: 421, duration: 0.687s, episode steps: 8, steps per second: 12, episode reward: 0.036, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000967, mae: 0.026376, mean_q: 0.005476
 3392/10000: episode: 422, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000530, mae: 0.018757, mean_q: 0.018688
 3397/10000: episode: 423, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000369, mae: 0.019575, mean_q: -0.000026
[Info] FALSIFICATION!
 3401/10000: episode: 424, duration: 0.261s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000466, mae: 0.019344, mean_q: 0.019352
 3406/10000: episode: 425, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002580, mae: 0.020621, mean_q: 0.019409
 3411/10000: episode: 426, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002098, mae: 0.026113, mean_q: 0.013303
 3416/10000: episode: 427, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000251, mae: 0.013649, mean_q: 0.008448
 3421/10000: episode: 428, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002288, mae: 0.023365, mean_q: 0.018001
 3426/10000: episode: 429, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000724, mae: 0.018374, mean_q: 0.019130
 3431/10000: episode: 430, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000326, mae: 0.015094, mean_q: 0.010761
 3436/10000: episode: 431, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000333, mae: 0.013341, mean_q: 0.013620
 3441/10000: episode: 432, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000232, mae: 0.012426, mean_q: 0.010865
 3446/10000: episode: 433, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000413, mae: 0.014464, mean_q: 0.010622
 3451/10000: episode: 434, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000301, mae: 0.013008, mean_q: 0.014494
 3456/10000: episode: 435, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000647, mae: 0.014536, mean_q: 0.014592
 3461/10000: episode: 436, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000414, mae: 0.014956, mean_q: 0.012443
 3466/10000: episode: 437, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000296, mae: 0.011014, mean_q: 0.014329
 3471/10000: episode: 438, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000688, mae: 0.015522, mean_q: 0.012204
 3476/10000: episode: 439, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000231, mae: 0.011647, mean_q: 0.016466
 3481/10000: episode: 440, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000886, mae: 0.019599, mean_q: 0.016755
 3486/10000: episode: 441, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000446, mae: 0.014451, mean_q: 0.019538
 3491/10000: episode: 442, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001059, mae: 0.021269, mean_q: 0.014742
 3496/10000: episode: 443, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000640, mae: 0.016886, mean_q: 0.023664
 3501/10000: episode: 444, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000363, mae: 0.017331, mean_q: 0.005559
 3506/10000: episode: 445, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001010, mae: 0.023642, mean_q: 0.025848
 3511/10000: episode: 446, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000591, mae: 0.015596, mean_q: 0.009753
 3516/10000: episode: 447, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000726, mae: 0.018282, mean_q: 0.022871
 3521/10000: episode: 448, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000893, mae: 0.016892, mean_q: 0.019634
 3526/10000: episode: 449, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000335, mae: 0.014083, mean_q: 0.005709
 3531/10000: episode: 450, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000593, mae: 0.017394, mean_q: 0.022276
 3536/10000: episode: 451, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000735, mae: 0.016938, mean_q: 0.013978
 3541/10000: episode: 452, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002440, mae: 0.024377, mean_q: 0.029800
 3546/10000: episode: 453, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000429, mae: 0.019132, mean_q: 0.006120
 3551/10000: episode: 454, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000454, mae: 0.015192, mean_q: 0.011856
 3556/10000: episode: 455, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000748, mae: 0.020584, mean_q: 0.027902
 3561/10000: episode: 456, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000409, mae: 0.015972, mean_q: 0.010176
 3566/10000: episode: 457, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.004491, mae: 0.030598, mean_q: 0.030948
 3571/10000: episode: 458, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002408, mae: 0.023719, mean_q: 0.017264
 3576/10000: episode: 459, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000598, mae: 0.017187, mean_q: 0.023434
 3581/10000: episode: 460, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000693, mae: 0.017118, mean_q: 0.006925
 3586/10000: episode: 461, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002825, mae: 0.025398, mean_q: 0.028305
 3591/10000: episode: 462, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000387, mae: 0.016423, mean_q: 0.019388
 3596/10000: episode: 463, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000588, mae: 0.021210, mean_q: 0.008929
 3601/10000: episode: 464, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002606, mae: 0.026805, mean_q: 0.035780
 3606/10000: episode: 465, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002890, mae: 0.025946, mean_q: 0.024980
 3611/10000: episode: 466, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000478, mae: 0.015586, mean_q: 0.017059
 3616/10000: episode: 467, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003008, mae: 0.024408, mean_q: 0.016833
 3621/10000: episode: 468, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000768, mae: 0.021893, mean_q: 0.026410
 3626/10000: episode: 469, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002861, mae: 0.025728, mean_q: 0.026335
 3631/10000: episode: 470, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001158, mae: 0.029486, mean_q: 0.021574
 3636/10000: episode: 471, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000786, mae: 0.025151, mean_q: 0.007857
 3641/10000: episode: 472, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000895, mae: 0.024224, mean_q: 0.024895
 3646/10000: episode: 473, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000849, mae: 0.023658, mean_q: 0.011826
 3651/10000: episode: 474, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000716, mae: 0.019266, mean_q: 0.020899
 3656/10000: episode: 475, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001012, mae: 0.019993, mean_q: 0.023260
 3661/10000: episode: 476, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000783, mae: 0.019176, mean_q: 0.018207
 3666/10000: episode: 477, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000719, mae: 0.019542, mean_q: 0.019433
 3671/10000: episode: 478, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001277, mae: 0.027070, mean_q: 0.034515
 3676/10000: episode: 479, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002407, mae: 0.026188, mean_q: 0.019771
 3681/10000: episode: 480, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002548, mae: 0.030750, mean_q: 0.028394
 3686/10000: episode: 481, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.002395, mae: 0.026855, mean_q: 0.014130
 3691/10000: episode: 482, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.006149, mae: 0.043459, mean_q: 0.050977
 3696/10000: episode: 483, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001232, mae: 0.029063, mean_q: 0.026111
[Info] FALSIFICATION!
 3700/10000: episode: 484, duration: 0.261s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.003483, mae: 0.048551, mean_q: 0.012545
 3705/10000: episode: 485, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.004490, mae: 0.036236, mean_q: 0.036691
 3710/10000: episode: 486, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001071, mae: 0.027049, mean_q: 0.032111
 3715/10000: episode: 487, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002594, mae: 0.031337, mean_q: 0.019877
 3720/10000: episode: 488, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002989, mae: 0.033709, mean_q: 0.046809
 3725/10000: episode: 489, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001093, mae: 0.033099, mean_q: 0.006905
 3730/10000: episode: 490, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001276, mae: 0.030533, mean_q: 0.035524
 3735/10000: episode: 491, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.003138, mae: 0.033231, mean_q: 0.016082
[Info] FALSIFICATION!
 3739/10000: episode: 492, duration: 0.261s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001447, mae: 0.032259, mean_q: 0.042941
 3744/10000: episode: 493, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002959, mae: 0.036471, mean_q: 0.008698
 3749/10000: episode: 494, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001019, mae: 0.027153, mean_q: 0.039026
 3754/10000: episode: 495, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001260, mae: 0.033189, mean_q: 0.006036
 3759/10000: episode: 496, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.004487, mae: 0.036887, mean_q: 0.044426
 3764/10000: episode: 497, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.004265, mae: 0.035138, mean_q: 0.043721
 3769/10000: episode: 498, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001205, mae: 0.026195, mean_q: 0.026279
 3774/10000: episode: 499, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.003425, mae: 0.028588, mean_q: 0.021370
 3779/10000: episode: 500, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000736, mae: 0.023158, mean_q: 0.027966
 3784/10000: episode: 501, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000542, mae: 0.021927, mean_q: 0.011081
 3789/10000: episode: 502, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000805, mae: 0.021003, mean_q: 0.024719
 3794/10000: episode: 503, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001765, mae: 0.017424, mean_q: 0.016719
 3799/10000: episode: 504, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001213, mae: 0.026468, mean_q: 0.043259
 3804/10000: episode: 505, duration: 0.025s, episode steps: 5, steps per second: 204, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000683, mae: 0.024400, mean_q: 0.017344
 3809/10000: episode: 506, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001021, mae: 0.024803, mean_q: 0.036277
 3814/10000: episode: 507, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000780, mae: 0.023321, mean_q: 0.011387
 3819/10000: episode: 508, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000748, mae: 0.021777, mean_q: 0.032670
 3824/10000: episode: 509, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002927, mae: 0.028159, mean_q: 0.027755
 3829/10000: episode: 510, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.002039, mae: 0.022556, mean_q: 0.027856
[Info] Complete ISplit Iteration
[Info] Levels: [0.064929046, 0.16529588, 0.31773436]
[Info] Cond. Prob: [0.18, 0.1, 0.03]
[Info] Error Prob: 0.0005399999999999999

 3834/10000: episode: 511, duration: 0.874s, episode steps: 5, steps per second: 6, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000953, mae: 0.024018, mean_q: 0.024509
 3844/10000: episode: 512, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.003182, mae: 0.028356, mean_q: 0.028250
 3854/10000: episode: 513, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000675, mae: 0.024445, mean_q: 0.019573
 3864/10000: episode: 514, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000743, mae: 0.020784, mean_q: 0.020194
 3874/10000: episode: 515, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001956, mae: 0.025357, mean_q: 0.027131
 3884/10000: episode: 516, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001773, mae: 0.021933, mean_q: 0.016937
 3894/10000: episode: 517, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001073, mae: 0.030843, mean_q: 0.019466
 3904/10000: episode: 518, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001065, mae: 0.029616, mean_q: 0.032252
 3914/10000: episode: 519, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000941, mae: 0.025274, mean_q: 0.030265
 3924/10000: episode: 520, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001571, mae: 0.026656, mean_q: 0.020449
 3934/10000: episode: 521, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000719, mae: 0.020490, mean_q: 0.015940
 3944/10000: episode: 522, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000817, mae: 0.020480, mean_q: 0.024308
 3954/10000: episode: 523, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.002756, mae: 0.024376, mean_q: 0.025119
 3964/10000: episode: 524, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001776, mae: 0.033720, mean_q: 0.018833
 3974/10000: episode: 525, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002484, mae: 0.033996, mean_q: 0.039739
 3984/10000: episode: 526, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001123, mae: 0.026434, mean_q: 0.022312
 3994/10000: episode: 527, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002095, mae: 0.028616, mean_q: 0.034906
 4004/10000: episode: 528, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002049, mae: 0.031880, mean_q: 0.024417
 4014/10000: episode: 529, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001741, mae: 0.023634, mean_q: 0.013411
 4024/10000: episode: 530, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001221, mae: 0.027499, mean_q: 0.025156
 4034/10000: episode: 531, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001098, mae: 0.030065, mean_q: 0.024373
 4044/10000: episode: 532, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001247, mae: 0.030331, mean_q: 0.037543
 4054/10000: episode: 533, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.002219, mae: 0.025558, mean_q: 0.021553
 4064/10000: episode: 534, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002661, mae: 0.032332, mean_q: 0.034894
 4074/10000: episode: 535, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000910, mae: 0.024972, mean_q: 0.018462
 4084/10000: episode: 536, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001903, mae: 0.024949, mean_q: 0.027201
 4094/10000: episode: 537, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001682, mae: 0.021884, mean_q: 0.019176
 4104/10000: episode: 538, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001086, mae: 0.023302, mean_q: 0.021794
 4114/10000: episode: 539, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002230, mae: 0.028041, mean_q: 0.030299
 4124/10000: episode: 540, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002033, mae: 0.025964, mean_q: 0.024418
 4134/10000: episode: 541, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000939, mae: 0.023697, mean_q: 0.025071
 4144/10000: episode: 542, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000648, mae: 0.019164, mean_q: 0.014695
 4154/10000: episode: 543, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001727, mae: 0.020340, mean_q: 0.022356
 4164/10000: episode: 544, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.002680, mae: 0.024075, mean_q: 0.028079
 4174/10000: episode: 545, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002054, mae: 0.028730, mean_q: 0.027941
 4184/10000: episode: 546, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000784, mae: 0.020617, mean_q: 0.023947
 4194/10000: episode: 547, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000657, mae: 0.019825, mean_q: 0.015003
 4204/10000: episode: 548, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001648, mae: 0.022432, mean_q: 0.020056
 4214/10000: episode: 549, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001714, mae: 0.025018, mean_q: 0.029867
 4224/10000: episode: 550, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002856, mae: 0.024145, mean_q: 0.022194
 4234/10000: episode: 551, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000774, mae: 0.023544, mean_q: 0.014742
 4244/10000: episode: 552, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001967, mae: 0.028709, mean_q: 0.023584
 4254/10000: episode: 553, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001073, mae: 0.027016, mean_q: 0.028304
 4264/10000: episode: 554, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000507, mae: 0.015488, mean_q: 0.012225
 4274/10000: episode: 555, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001712, mae: 0.021382, mean_q: 0.023530
 4284/10000: episode: 556, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001803, mae: 0.023756, mean_q: 0.021678
 4294/10000: episode: 557, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000866, mae: 0.023986, mean_q: 0.010722
 4304/10000: episode: 558, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002746, mae: 0.026109, mean_q: 0.027305
 4314/10000: episode: 559, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.003276, mae: 0.041361, mean_q: 0.038403
 4324/10000: episode: 560, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.004033, mae: 0.038102, mean_q: 0.037729
 4334/10000: episode: 561, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001773, mae: 0.025768, mean_q: 0.020290
 4344/10000: episode: 562, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001757, mae: 0.023385, mean_q: 0.026585
 4354/10000: episode: 563, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001091, mae: 0.025244, mean_q: 0.026473
 4364/10000: episode: 564, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.002728, mae: 0.029515, mean_q: 0.027992
 4374/10000: episode: 565, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.002163, mae: 0.029208, mean_q: 0.032833
 4384/10000: episode: 566, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000551, mae: 0.018674, mean_q: 0.015867
 4394/10000: episode: 567, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000942, mae: 0.022206, mean_q: 0.021771
 4404/10000: episode: 568, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000735, mae: 0.018698, mean_q: 0.023275
 4414/10000: episode: 569, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002483, mae: 0.022648, mean_q: 0.022507
 4424/10000: episode: 570, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001066, mae: 0.023088, mean_q: 0.023736
 4434/10000: episode: 571, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001555, mae: 0.020034, mean_q: 0.022451
 4444/10000: episode: 572, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.001822, mae: 0.022012, mean_q: 0.021930
 4454/10000: episode: 573, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001267, mae: 0.017761, mean_q: 0.017301
 4464/10000: episode: 574, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000706, mae: 0.021495, mean_q: 0.013022
 4474/10000: episode: 575, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000527, mae: 0.017448, mean_q: 0.017080
 4484/10000: episode: 576, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001069, mae: 0.022116, mean_q: 0.026415
 4494/10000: episode: 577, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002574, mae: 0.027165, mean_q: 0.020171
 4504/10000: episode: 578, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000478, mae: 0.017028, mean_q: 0.009350
 4514/10000: episode: 579, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000785, mae: 0.017995, mean_q: 0.017806
 4524/10000: episode: 580, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001577, mae: 0.017305, mean_q: 0.022779
 4534/10000: episode: 581, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001029, mae: 0.022317, mean_q: 0.023095
 4544/10000: episode: 582, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000485, mae: 0.016923, mean_q: 0.014315
 4554/10000: episode: 583, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000839, mae: 0.019396, mean_q: 0.022298
 4564/10000: episode: 584, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000629, mae: 0.017861, mean_q: 0.017391
 4574/10000: episode: 585, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002414, mae: 0.024267, mean_q: 0.023001
 4584/10000: episode: 586, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001855, mae: 0.028275, mean_q: 0.026083
 4594/10000: episode: 587, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001924, mae: 0.025154, mean_q: 0.026301
 4604/10000: episode: 588, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001133, mae: 0.025067, mean_q: 0.020061
 4614/10000: episode: 589, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002797, mae: 0.025286, mean_q: 0.024103
 4624/10000: episode: 590, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.003544, mae: 0.032068, mean_q: 0.024836
 4634/10000: episode: 591, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000711, mae: 0.021750, mean_q: 0.019625
 4644/10000: episode: 592, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000730, mae: 0.020068, mean_q: 0.027275
 4654/10000: episode: 593, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001320, mae: 0.020369, mean_q: 0.026274
 4664/10000: episode: 594, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002668, mae: 0.026787, mean_q: 0.026608
 4674/10000: episode: 595, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001598, mae: 0.025663, mean_q: 0.017214
 4684/10000: episode: 596, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001496, mae: 0.020815, mean_q: 0.022086
 4694/10000: episode: 597, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000488, mae: 0.018284, mean_q: 0.011694
 4704/10000: episode: 598, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001062, mae: 0.022117, mean_q: 0.024042
 4714/10000: episode: 599, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000908, mae: 0.023785, mean_q: 0.020354
 4724/10000: episode: 600, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000588, mae: 0.017525, mean_q: 0.016907
 4734/10000: episode: 601, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001697, mae: 0.024130, mean_q: 0.026565
 4744/10000: episode: 602, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000515, mae: 0.019220, mean_q: 0.007908
 4754/10000: episode: 603, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000546, mae: 0.016519, mean_q: 0.017648
 4764/10000: episode: 604, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.004709, mae: 0.031991, mean_q: 0.030582
 4774/10000: episode: 605, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001055, mae: 0.026083, mean_q: 0.031078
 4784/10000: episode: 606, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001752, mae: 0.023722, mean_q: 0.030115
 4794/10000: episode: 607, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001848, mae: 0.023911, mean_q: 0.025290
 4804/10000: episode: 608, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001581, mae: 0.022078, mean_q: 0.017991
 4814/10000: episode: 609, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001895, mae: 0.029534, mean_q: 0.021971
 4824/10000: episode: 610, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000975, mae: 0.023899, mean_q: 0.021148
[Info] 1-TH LEVEL FOUND: 0.04517733305692673, Considering 11/100 traces
 4834/10000: episode: 611, duration: 0.695s, episode steps: 10, steps per second: 14, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001521, mae: 0.020667, mean_q: 0.019225
 4841/10000: episode: 612, duration: 0.050s, episode steps: 7, steps per second: 141, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002149, mae: 0.023552, mean_q: 0.026844
 4843/10000: episode: 613, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005458, mae: 0.031673, mean_q: 0.016390
 4847/10000: episode: 614, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002453, mae: 0.022932, mean_q: 0.021501
 4851/10000: episode: 615, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003363, mae: 0.029451, mean_q: 0.031913
 4858/10000: episode: 616, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000570, mae: 0.018420, mean_q: 0.020254
 4860/10000: episode: 617, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001008, mae: 0.022857, mean_q: 0.023168
 4864/10000: episode: 618, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002712, mae: 0.026064, mean_q: 0.039168
 4871/10000: episode: 619, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000780, mae: 0.019064, mean_q: 0.019311
 4875/10000: episode: 620, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001248, mae: 0.024226, mean_q: 0.023603
 4877/10000: episode: 621, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000532, mae: 0.018200, mean_q: 0.026420
 4884/10000: episode: 622, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.002078, mae: 0.021518, mean_q: 0.027670
 4888/10000: episode: 623, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002840, mae: 0.023102, mean_q: 0.019414
 4890/10000: episode: 624, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001062, mae: 0.026466, mean_q: 0.016242
 4897/10000: episode: 625, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.003628, mae: 0.031813, mean_q: 0.025709
 4899/10000: episode: 626, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000334, mae: 0.015745, mean_q: 0.026213
 4906/10000: episode: 627, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.003384, mae: 0.030204, mean_q: 0.030566
 4913/10000: episode: 628, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001152, mae: 0.025642, mean_q: 0.018984
 4920/10000: episode: 629, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001739, mae: 0.024167, mean_q: 0.022094
 4927/10000: episode: 630, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000836, mae: 0.022620, mean_q: 0.022273
 4931/10000: episode: 631, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001050, mae: 0.022411, mean_q: 0.028625
 4933/10000: episode: 632, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005183, mae: 0.025769, mean_q: 0.017912
 4935/10000: episode: 633, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000795, mae: 0.021099, mean_q: 0.022203
 4942/10000: episode: 634, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.003851, mae: 0.031849, mean_q: 0.043375
 4949/10000: episode: 635, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001761, mae: 0.026723, mean_q: 0.013110
 4956/10000: episode: 636, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000818, mae: 0.021022, mean_q: 0.026923
 4960/10000: episode: 637, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000459, mae: 0.015800, mean_q: 0.012287
 4964/10000: episode: 638, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001340, mae: 0.024071, mean_q: 0.024251
 4968/10000: episode: 639, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000575, mae: 0.016157, mean_q: 0.011192
 4972/10000: episode: 640, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000581, mae: 0.016894, mean_q: 0.016222
 4974/10000: episode: 641, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000412, mae: 0.015337, mean_q: 0.020113
 4976/10000: episode: 642, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000409, mae: 0.014966, mean_q: 0.013297
 4983/10000: episode: 643, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000578, mae: 0.015036, mean_q: 0.015606
 4990/10000: episode: 644, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000644, mae: 0.016165, mean_q: 0.015008
 4992/10000: episode: 645, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005826, mae: 0.028378, mean_q: 0.024088
 4996/10000: episode: 646, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001021, mae: 0.023645, mean_q: 0.030029
 5000/10000: episode: 647, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001101, mae: 0.023767, mean_q: 0.018241
 5004/10000: episode: 648, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001137, mae: 0.024906, mean_q: 0.016421
 5011/10000: episode: 649, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.002510, mae: 0.030045, mean_q: 0.040501
 5015/10000: episode: 650, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003889, mae: 0.034684, mean_q: 0.022701
 5017/10000: episode: 651, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000568, mae: 0.020820, mean_q: 0.026570
 5019/10000: episode: 652, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005823, mae: 0.032893, mean_q: 0.031602
 5023/10000: episode: 653, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001311, mae: 0.026964, mean_q: 0.036651
 5025/10000: episode: 654, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000210, mae: 0.014120, mean_q: 0.010080
 5032/10000: episode: 655, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.003600, mae: 0.031824, mean_q: 0.031496
 5034/10000: episode: 656, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000820, mae: 0.019666, mean_q: 0.022181
 5041/10000: episode: 657, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001777, mae: 0.025570, mean_q: 0.015437
 5045/10000: episode: 658, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001423, mae: 0.026208, mean_q: 0.039519
 5052/10000: episode: 659, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001623, mae: 0.022639, mean_q: 0.017201
 5059/10000: episode: 660, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000642, mae: 0.020809, mean_q: 0.020934
 5066/10000: episode: 661, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000817, mae: 0.018917, mean_q: 0.022025
 5073/10000: episode: 662, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001996, mae: 0.022216, mean_q: 0.021204
 5075/10000: episode: 663, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000280, mae: 0.012810, mean_q: 0.014911
[Info] FALSIFICATION!
 5081/10000: episode: 664, duration: 0.177s, episode steps: 6, steps per second: 34, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000718, mae: 0.019066, mean_q: 0.019667
 5088/10000: episode: 665, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000839, mae: 0.020576, mean_q: 0.024679
 5095/10000: episode: 666, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000851, mae: 0.020431, mean_q: 0.022472
 5102/10000: episode: 667, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000783, mae: 0.018499, mean_q: 0.017941
 5109/10000: episode: 668, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.002256, mae: 0.020406, mean_q: 0.017821
 5113/10000: episode: 669, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003313, mae: 0.034113, mean_q: 0.046881
 5120/10000: episode: 670, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002716, mae: 0.034888, mean_q: 0.023529
 5122/10000: episode: 671, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001363, mae: 0.030298, mean_q: 0.044220
 5124/10000: episode: 672, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000724, mae: 0.022791, mean_q: 0.024690
 5126/10000: episode: 673, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000790, mae: 0.023614, mean_q: 0.009357
 5130/10000: episode: 674, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002460, mae: 0.028332, mean_q: 0.027279
 5137/10000: episode: 675, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.002572, mae: 0.034574, mean_q: 0.035064
 5139/10000: episode: 676, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000957, mae: 0.032069, mean_q: 0.003849
 5143/10000: episode: 677, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002753, mae: 0.034340, mean_q: 0.047399
 5150/10000: episode: 678, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001079, mae: 0.025132, mean_q: 0.012759
 5152/10000: episode: 679, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004498, mae: 0.033233, mean_q: 0.036580
 5154/10000: episode: 680, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004944, mae: 0.039528, mean_q: 0.048877
 5156/10000: episode: 681, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000381, mae: 0.016081, mean_q: 0.012708
 5160/10000: episode: 682, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000705, mae: 0.021548, mean_q: 0.016169
 5167/10000: episode: 683, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000806, mae: 0.021925, mean_q: 0.025254
 5169/10000: episode: 684, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005171, mae: 0.035050, mean_q: 0.021413
 5171/10000: episode: 685, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000108, mae: 0.010010, mean_q: 0.017716
 5175/10000: episode: 686, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001128, mae: 0.024669, mean_q: 0.033893
 5177/10000: episode: 687, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001017, mae: 0.025440, mean_q: 0.024011
 5184/10000: episode: 688, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000829, mae: 0.020013, mean_q: 0.025483
 5191/10000: episode: 689, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000974, mae: 0.020801, mean_q: 0.022891
 5193/10000: episode: 690, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001165, mae: 0.019737, mean_q: 0.014011
 5195/10000: episode: 691, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001236, mae: 0.024232, mean_q: 0.032168
 5202/10000: episode: 692, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000604, mae: 0.018798, mean_q: 0.013711
 5204/10000: episode: 693, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001100, mae: 0.023895, mean_q: 0.029538
 5208/10000: episode: 694, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003192, mae: 0.026531, mean_q: 0.032899
 5215/10000: episode: 695, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001180, mae: 0.023806, mean_q: 0.026206
 5222/10000: episode: 696, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000987, mae: 0.029254, mean_q: 0.004615
 5224/10000: episode: 697, duration: 0.012s, episode steps: 2, steps per second: 166, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001433, mae: 0.031982, mean_q: 0.043291
 5228/10000: episode: 698, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000701, mae: 0.024488, mean_q: 0.031624
 5230/10000: episode: 699, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000854, mae: 0.029962, mean_q: 0.002689
[Info] Complete ISplit Iteration
[Info] Levels: [0.045177333, 0.3040274]
[Info] Cond. Prob: [0.11, 0.01]
[Info] Error Prob: 0.0011

 5237/10000: episode: 700, duration: 0.734s, episode steps: 7, steps per second: 10, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001281, mae: 0.029386, mean_q: 0.034895
 5247/10000: episode: 701, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002169, mae: 0.031530, mean_q: 0.024696
 5257/10000: episode: 702, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001473, mae: 0.024277, mean_q: 0.014902
 5267/10000: episode: 703, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002654, mae: 0.024406, mean_q: 0.017168
 5277/10000: episode: 704, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.003044, mae: 0.024574, mean_q: 0.025449
 5287/10000: episode: 705, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001938, mae: 0.028944, mean_q: 0.023994
 5297/10000: episode: 706, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001386, mae: 0.021891, mean_q: 0.029935
 5307/10000: episode: 707, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000831, mae: 0.019601, mean_q: 0.024430
 5317/10000: episode: 708, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001324, mae: 0.021201, mean_q: 0.023601
 5327/10000: episode: 709, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002582, mae: 0.027096, mean_q: 0.032852
 5337/10000: episode: 710, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000933, mae: 0.025190, mean_q: 0.022920
 5347/10000: episode: 711, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000920, mae: 0.020565, mean_q: 0.026510
 5357/10000: episode: 712, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000781, mae: 0.019019, mean_q: 0.017664
 5367/10000: episode: 713, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000789, mae: 0.021974, mean_q: 0.026496
 5377/10000: episode: 714, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000827, mae: 0.022713, mean_q: 0.022434
 5387/10000: episode: 715, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001876, mae: 0.023345, mean_q: 0.027047
 5397/10000: episode: 716, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001993, mae: 0.024668, mean_q: 0.028768
 5407/10000: episode: 717, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001006, mae: 0.023934, mean_q: 0.026752
 5417/10000: episode: 718, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001636, mae: 0.025128, mean_q: 0.030181
 5427/10000: episode: 719, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000865, mae: 0.019432, mean_q: 0.025480
 5437/10000: episode: 720, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000807, mae: 0.021715, mean_q: 0.021025
 5447/10000: episode: 721, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001777, mae: 0.021796, mean_q: 0.023950
 5457/10000: episode: 722, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000693, mae: 0.021026, mean_q: 0.017686
 5467/10000: episode: 723, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002144, mae: 0.025203, mean_q: 0.024858
 5477/10000: episode: 724, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000586, mae: 0.017989, mean_q: 0.018273
 5487/10000: episode: 725, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000865, mae: 0.020407, mean_q: 0.028553
 5497/10000: episode: 726, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000811, mae: 0.020425, mean_q: 0.024112
 5507/10000: episode: 727, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002747, mae: 0.024139, mean_q: 0.026026
 5517/10000: episode: 728, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000564, mae: 0.019443, mean_q: 0.018430
 5527/10000: episode: 729, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000808, mae: 0.022322, mean_q: 0.022952
 5537/10000: episode: 730, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001310, mae: 0.019800, mean_q: 0.019122
 5547/10000: episode: 731, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.003889, mae: 0.034115, mean_q: 0.027054
 5557/10000: episode: 732, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002523, mae: 0.040588, mean_q: 0.033313
 5567/10000: episode: 733, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001873, mae: 0.031665, mean_q: 0.030757
 5577/10000: episode: 734, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002344, mae: 0.034007, mean_q: 0.035987
 5587/10000: episode: 735, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.004004, mae: 0.035404, mean_q: 0.037250
 5597/10000: episode: 736, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000804, mae: 0.023043, mean_q: 0.020046
 5607/10000: episode: 737, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000954, mae: 0.022777, mean_q: 0.024636
 5617/10000: episode: 738, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002958, mae: 0.027872, mean_q: 0.027348
 5627/10000: episode: 739, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001367, mae: 0.021951, mean_q: 0.029767
 5637/10000: episode: 740, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000574, mae: 0.019018, mean_q: 0.013088
 5647/10000: episode: 741, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001268, mae: 0.026998, mean_q: 0.032341
 5657/10000: episode: 742, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000581, mae: 0.020983, mean_q: 0.015446
 5667/10000: episode: 743, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000648, mae: 0.019609, mean_q: 0.017599
 5677/10000: episode: 744, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002649, mae: 0.029858, mean_q: 0.029935
 5687/10000: episode: 745, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001181, mae: 0.025031, mean_q: 0.027243
 5697/10000: episode: 746, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001038, mae: 0.026770, mean_q: 0.025382
 5707/10000: episode: 747, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002598, mae: 0.027766, mean_q: 0.026887
 5717/10000: episode: 748, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001019, mae: 0.025398, mean_q: 0.016112
 5727/10000: episode: 749, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.003339, mae: 0.027378, mean_q: 0.026812
 5737/10000: episode: 750, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002893, mae: 0.034436, mean_q: 0.026339
 5747/10000: episode: 751, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002362, mae: 0.030647, mean_q: 0.025018
 5757/10000: episode: 752, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001030, mae: 0.023979, mean_q: 0.025144
 5767/10000: episode: 753, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002685, mae: 0.029619, mean_q: 0.032573
 5777/10000: episode: 754, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000775, mae: 0.022157, mean_q: 0.016312
 5787/10000: episode: 755, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001218, mae: 0.031463, mean_q: 0.022994
 5797/10000: episode: 756, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000568, mae: 0.021050, mean_q: 0.019967
 5807/10000: episode: 757, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000846, mae: 0.024850, mean_q: 0.029932
 5817/10000: episode: 758, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000494, mae: 0.016223, mean_q: 0.020892
 5827/10000: episode: 759, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000851, mae: 0.020998, mean_q: 0.025693
 5837/10000: episode: 760, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001664, mae: 0.021307, mean_q: 0.018548
 5847/10000: episode: 761, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.001960, mae: 0.024586, mean_q: 0.027406
 5857/10000: episode: 762, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000933, mae: 0.024404, mean_q: 0.024020
 5867/10000: episode: 763, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000521, mae: 0.017611, mean_q: 0.013450
 5877/10000: episode: 764, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000743, mae: 0.019662, mean_q: 0.019612
 5887/10000: episode: 765, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001595, mae: 0.020092, mean_q: 0.017523
 5897/10000: episode: 766, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002569, mae: 0.026673, mean_q: 0.029047
 5907/10000: episode: 767, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000640, mae: 0.018220, mean_q: 0.017559
 5917/10000: episode: 768, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.003343, mae: 0.024929, mean_q: 0.022281
 5927/10000: episode: 769, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001613, mae: 0.028637, mean_q: 0.031384
 5937/10000: episode: 770, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000821, mae: 0.019841, mean_q: 0.022816
 5947/10000: episode: 771, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001642, mae: 0.023171, mean_q: 0.022203
 5957/10000: episode: 772, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002079, mae: 0.024480, mean_q: 0.029103
 5967/10000: episode: 773, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000840, mae: 0.023074, mean_q: 0.019968
 5977/10000: episode: 774, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000771, mae: 0.020117, mean_q: 0.024491
 5987/10000: episode: 775, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000788, mae: 0.019624, mean_q: 0.023529
 5997/10000: episode: 776, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001124, mae: 0.024050, mean_q: 0.024787
 6007/10000: episode: 777, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000763, mae: 0.019793, mean_q: 0.015879
 6017/10000: episode: 778, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002699, mae: 0.027531, mean_q: 0.028360
 6027/10000: episode: 779, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000736, mae: 0.020687, mean_q: 0.019241
 6037/10000: episode: 780, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001670, mae: 0.019194, mean_q: 0.022954
 6047/10000: episode: 781, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000873, mae: 0.019991, mean_q: 0.021904
 6057/10000: episode: 782, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000916, mae: 0.020425, mean_q: 0.019566
 6067/10000: episode: 783, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001499, mae: 0.022872, mean_q: 0.025585
 6077/10000: episode: 784, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001212, mae: 0.019361, mean_q: 0.025689
 6087/10000: episode: 785, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001406, mae: 0.021149, mean_q: 0.018147
 6097/10000: episode: 786, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000500, mae: 0.020409, mean_q: 0.015559
 6107/10000: episode: 787, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000885, mae: 0.021451, mean_q: 0.024404
 6117/10000: episode: 788, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000805, mae: 0.018463, mean_q: 0.020839
 6127/10000: episode: 789, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001410, mae: 0.021442, mean_q: 0.032079
 6137/10000: episode: 790, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000655, mae: 0.018966, mean_q: 0.019269
 6147/10000: episode: 791, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000899, mae: 0.020165, mean_q: 0.022608
 6157/10000: episode: 792, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001162, mae: 0.018389, mean_q: 0.021938
 6167/10000: episode: 793, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000497, mae: 0.014734, mean_q: 0.017931
 6177/10000: episode: 794, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000665, mae: 0.017922, mean_q: 0.017217
 6187/10000: episode: 795, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002732, mae: 0.026025, mean_q: 0.027362
 6197/10000: episode: 796, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002143, mae: 0.031295, mean_q: 0.018475
 6207/10000: episode: 797, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000947, mae: 0.027525, mean_q: 0.013626
 6217/10000: episode: 798, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001902, mae: 0.023911, mean_q: 0.028231
 6227/10000: episode: 799, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001782, mae: 0.020696, mean_q: 0.023657
[Info] 1-TH LEVEL FOUND: 0.027991939336061478, Considering 12/100 traces
 6237/10000: episode: 800, duration: 0.707s, episode steps: 10, steps per second: 14, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000576, mae: 0.019969, mean_q: 0.014971
 6239/10000: episode: 801, duration: 0.014s, episode steps: 2, steps per second: 144, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000730, mae: 0.019079, mean_q: 0.022353
 6243/10000: episode: 802, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000431, mae: 0.015997, mean_q: 0.023902
 6247/10000: episode: 803, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000529, mae: 0.018449, mean_q: 0.020707
 6251/10000: episode: 804, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000940, mae: 0.022642, mean_q: 0.040784
 6255/10000: episode: 805, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002015, mae: 0.017151, mean_q: 0.018130
 6259/10000: episode: 806, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000933, mae: 0.017805, mean_q: 0.021653
 6261/10000: episode: 807, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000232, mae: 0.012371, mean_q: 0.005616
 6265/10000: episode: 808, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000584, mae: 0.016445, mean_q: 0.026104
 6267/10000: episode: 809, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001495, mae: 0.025727, mean_q: 0.032153
 6271/10000: episode: 810, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000546, mae: 0.013887, mean_q: 0.015283
 6278/10000: episode: 811, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000362, mae: 0.013869, mean_q: 0.021392
 6285/10000: episode: 812, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.002281, mae: 0.022813, mean_q: 0.025164
 6289/10000: episode: 813, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000364, mae: 0.013692, mean_q: 0.022013
 6296/10000: episode: 814, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001793, mae: 0.022876, mean_q: 0.024386
 6298/10000: episode: 815, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000616, mae: 0.015981, mean_q: 0.030286
 6300/10000: episode: 816, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000850, mae: 0.018436, mean_q: 0.023582
 6302/10000: episode: 817, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000541, mae: 0.017160, mean_q: 0.029548
 6304/10000: episode: 818, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000186, mae: 0.011037, mean_q: 0.010759
 6306/10000: episode: 819, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000696, mae: 0.018843, mean_q: 0.025115
 6310/10000: episode: 820, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002231, mae: 0.020316, mean_q: 0.021768
 6314/10000: episode: 821, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000990, mae: 0.016772, mean_q: 0.014629
 6321/10000: episode: 822, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000718, mae: 0.018514, mean_q: 0.025580
 6325/10000: episode: 823, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.003378, mae: 0.029712, mean_q: 0.022738
 6327/10000: episode: 824, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001132, mae: 0.024793, mean_q: 0.034018
 6334/10000: episode: 825, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000584, mae: 0.020507, mean_q: 0.019740
 6338/10000: episode: 826, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000666, mae: 0.018763, mean_q: 0.014413
 6340/10000: episode: 827, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001069, mae: 0.026946, mean_q: 0.045454
 6342/10000: episode: 828, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004172, mae: 0.030627, mean_q: 0.034842
 6346/10000: episode: 829, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003694, mae: 0.027106, mean_q: 0.029030
 6348/10000: episode: 830, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000436, mae: 0.015681, mean_q: 0.030750
 6350/10000: episode: 831, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000599, mae: 0.017925, mean_q: 0.020014
 6352/10000: episode: 832, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005068, mae: 0.033727, mean_q: 0.021238
 6359/10000: episode: 833, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000642, mae: 0.015830, mean_q: 0.016378
 6363/10000: episode: 834, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000361, mae: 0.013178, mean_q: 0.017759
 6365/10000: episode: 835, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000384, mae: 0.014045, mean_q: 0.013377
 6367/10000: episode: 836, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000337, mae: 0.015847, mean_q: 0.011038
 6369/10000: episode: 837, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001251, mae: 0.022590, mean_q: 0.020112
 6371/10000: episode: 838, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000770, mae: 0.019922, mean_q: 0.020467
 6373/10000: episode: 839, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000496, mae: 0.018800, mean_q: 0.026238
 6377/10000: episode: 840, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001112, mae: 0.019091, mean_q: 0.021651
 6384/10000: episode: 841, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.002719, mae: 0.023972, mean_q: 0.029603
 6391/10000: episode: 842, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001007, mae: 0.028387, mean_q: 0.013973
 6398/10000: episode: 843, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001016, mae: 0.023553, mean_q: 0.031290
 6402/10000: episode: 844, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000824, mae: 0.023991, mean_q: 0.017388
 6406/10000: episode: 845, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000706, mae: 0.025563, mean_q: 0.037453
 6410/10000: episode: 846, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001213, mae: 0.025601, mean_q: 0.009684
 6412/10000: episode: 847, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000433, mae: 0.019543, mean_q: 0.025623
 6419/10000: episode: 848, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000395, mae: 0.017428, mean_q: 0.015907
 6426/10000: episode: 849, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000560, mae: 0.018590, mean_q: 0.025757
 6430/10000: episode: 850, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002562, mae: 0.032871, mean_q: 0.005778
 6432/10000: episode: 851, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001399, mae: 0.031723, mean_q: 0.041683
 6439/10000: episode: 852, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000344, mae: 0.015158, mean_q: 0.012321
 6446/10000: episode: 853, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.002370, mae: 0.027782, mean_q: 0.037682
 6448/10000: episode: 854, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000783, mae: 0.024344, mean_q: 0.009470
 6455/10000: episode: 855, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000784, mae: 0.018428, mean_q: 0.023842
 6459/10000: episode: 856, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001103, mae: 0.024092, mean_q: 0.019511
 6461/10000: episode: 857, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005559, mae: 0.032163, mean_q: 0.022232
 6468/10000: episode: 858, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000428, mae: 0.017961, mean_q: 0.022885
 6475/10000: episode: 859, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.003044, mae: 0.026163, mean_q: 0.027261
 6479/10000: episode: 860, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000667, mae: 0.019019, mean_q: 0.033640
 6481/10000: episode: 861, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000552, mae: 0.018517, mean_q: 0.007131
 6485/10000: episode: 862, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000393, mae: 0.016490, mean_q: 0.013047
 6487/10000: episode: 863, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000645, mae: 0.021864, mean_q: 0.034210
 6491/10000: episode: 864, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000404, mae: 0.020721, mean_q: 0.004521
 6498/10000: episode: 865, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000381, mae: 0.015663, mean_q: 0.019507
 6500/10000: episode: 866, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000170, mae: 0.010322, mean_q: 0.010990
 6502/10000: episode: 867, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000376, mae: 0.015687, mean_q: 0.020321
 6509/10000: episode: 868, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000506, mae: 0.017030, mean_q: 0.016273
 6516/10000: episode: 869, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.002120, mae: 0.020764, mean_q: 0.021792
 6520/10000: episode: 870, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000595, mae: 0.018011, mean_q: 0.020960
 6524/10000: episode: 871, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003304, mae: 0.027050, mean_q: 0.026387
 6526/10000: episode: 872, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000352, mae: 0.014468, mean_q: 0.014951
 6533/10000: episode: 873, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.001444, mae: 0.018789, mean_q: 0.019496
 6537/10000: episode: 874, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000397, mae: 0.014057, mean_q: 0.016385
 6539/10000: episode: 875, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005183, mae: 0.031575, mean_q: 0.037902
 6543/10000: episode: 876, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000316, mae: 0.016517, mean_q: 0.018429
 6545/10000: episode: 877, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000733, mae: 0.024480, mean_q: 0.014187
 6552/10000: episode: 878, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.002149, mae: 0.026801, mean_q: 0.029245
 6554/10000: episode: 879, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005328, mae: 0.023172, mean_q: 0.014642
 6556/10000: episode: 880, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001136, mae: 0.025102, mean_q: 0.016138
 6560/10000: episode: 881, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001312, mae: 0.026266, mean_q: 0.037942
 6564/10000: episode: 882, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000980, mae: 0.025152, mean_q: 0.024352
 6571/10000: episode: 883, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.002950, mae: 0.028786, mean_q: 0.028013
 6575/10000: episode: 884, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002624, mae: 0.025044, mean_q: 0.017088
 6579/10000: episode: 885, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000649, mae: 0.018793, mean_q: 0.023579
 6581/10000: episode: 886, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000351, mae: 0.014001, mean_q: 0.014114
 6585/10000: episode: 887, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000649, mae: 0.019812, mean_q: 0.017253
[Info] 2-TH LEVEL FOUND: 0.14721092581748962, Considering 13/100 traces
 6592/10000: episode: 888, duration: 0.698s, episode steps: 7, steps per second: 10, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001429, mae: 0.021873, mean_q: 0.030714
 6596/10000: episode: 889, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000450, mae: 0.016553, mean_q: 0.012493
 6598/10000: episode: 890, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000350, mae: 0.016745, mean_q: 0.027924
 6600/10000: episode: 891, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000355, mae: 0.014900, mean_q: 0.016046
 6602/10000: episode: 892, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000965, mae: 0.022947, mean_q: 0.016189
 6606/10000: episode: 893, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000264, mae: 0.013520, mean_q: 0.010038
 6608/10000: episode: 894, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000457, mae: 0.016039, mean_q: 0.021877
 6610/10000: episode: 895, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000828, mae: 0.020122, mean_q: 0.022074
 6612/10000: episode: 896, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005711, mae: 0.028179, mean_q: 0.019833
 6614/10000: episode: 897, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000658, mae: 0.023550, mean_q: 0.041896
 6616/10000: episode: 898, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000698, mae: 0.020540, mean_q: 0.027172
 6618/10000: episode: 899, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000198, mae: 0.012157, mean_q: 0.006840
 6620/10000: episode: 900, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000428, mae: 0.016205, mean_q: 0.014649
 6622/10000: episode: 901, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001547, mae: 0.030005, mean_q: 0.041747
 6624/10000: episode: 902, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000972, mae: 0.028266, mean_q: 0.028487
 6628/10000: episode: 903, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001219, mae: 0.023409, mean_q: 0.030872
 6632/10000: episode: 904, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000371, mae: 0.015965, mean_q: 0.021332
 6634/10000: episode: 905, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000463, mae: 0.016278, mean_q: 0.016412
 6636/10000: episode: 906, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000812, mae: 0.021990, mean_q: 0.028846
 6638/10000: episode: 907, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001710, mae: 0.024533, mean_q: 0.025196
 6640/10000: episode: 908, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000290, mae: 0.012117, mean_q: 0.013237
 6642/10000: episode: 909, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000744, mae: 0.015404, mean_q: 0.022525
 6644/10000: episode: 910, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000122, mae: 0.010131, mean_q: 0.013617
 6646/10000: episode: 911, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000801, mae: 0.017512, mean_q: 0.035025
 6648/10000: episode: 912, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005339, mae: 0.031072, mean_q: 0.024069
 6650/10000: episode: 913, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000688, mae: 0.017723, mean_q: 0.019408
 6652/10000: episode: 914, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004682, mae: 0.025322, mean_q: 0.024364
 6654/10000: episode: 915, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000405, mae: 0.016056, mean_q: 0.032933
 6656/10000: episode: 916, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000668, mae: 0.018727, mean_q: 0.029943
 6658/10000: episode: 917, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000659, mae: 0.018616, mean_q: 0.015237
 6660/10000: episode: 918, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001262, mae: 0.020844, mean_q: 0.024727
 6662/10000: episode: 919, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000690, mae: 0.016865, mean_q: 0.020393
 6664/10000: episode: 920, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000804, mae: 0.018694, mean_q: 0.008650
 6668/10000: episode: 921, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.003856, mae: 0.033282, mean_q: 0.019204
 6670/10000: episode: 922, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000717, mae: 0.027948, mean_q: 0.035193
 6674/10000: episode: 923, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000621, mae: 0.021057, mean_q: 0.013543
 6676/10000: episode: 924, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001255, mae: 0.020727, mean_q: 0.021718
 6678/10000: episode: 925, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000397, mae: 0.018922, mean_q: 0.025299
 6680/10000: episode: 926, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005685, mae: 0.023644, mean_q: 0.011331
 6682/10000: episode: 927, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000669, mae: 0.020397, mean_q: 0.027810
 6684/10000: episode: 928, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000655, mae: 0.018639, mean_q: 0.029275
 6686/10000: episode: 929, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001368, mae: 0.027818, mean_q: 0.024359
 6688/10000: episode: 930, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003602, mae: 0.025677, mean_q: 0.018701
 6690/10000: episode: 931, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001091, mae: 0.021122, mean_q: 0.025957
 6692/10000: episode: 932, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000781, mae: 0.023588, mean_q: 0.031691
 6694/10000: episode: 933, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000791, mae: 0.022561, mean_q: 0.023022
 6696/10000: episode: 934, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000687, mae: 0.020503, mean_q: 0.005157
 6698/10000: episode: 935, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000774, mae: 0.022684, mean_q: 0.031936
 6700/10000: episode: 936, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000509, mae: 0.019678, mean_q: 0.024091
[Info] FALSIFICATION!
 6703/10000: episode: 937, duration: 0.255s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000928, mae: 0.022531, mean_q: 0.013381
 6705/10000: episode: 938, duration: 0.017s, episode steps: 2, steps per second: 116, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000509, mae: 0.021105, mean_q: 0.033580
 6707/10000: episode: 939, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001289, mae: 0.020951, mean_q: 0.030487
 6711/10000: episode: 940, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000749, mae: 0.022170, mean_q: 0.019035
 6713/10000: episode: 941, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000751, mae: 0.021634, mean_q: 0.031832
 6715/10000: episode: 942, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000563, mae: 0.016688, mean_q: 0.024148
 6717/10000: episode: 943, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001618, mae: 0.027689, mean_q: 0.021572
 6719/10000: episode: 944, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000346, mae: 0.013108, mean_q: 0.013178
 6721/10000: episode: 945, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001305, mae: 0.021170, mean_q: 0.020536
 6725/10000: episode: 946, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000210, mae: 0.011205, mean_q: 0.014445
 6727/10000: episode: 947, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000116, mae: 0.008966, mean_q: 0.006358
 6729/10000: episode: 948, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005862, mae: 0.027990, mean_q: 0.024200
 6731/10000: episode: 949, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000404, mae: 0.016577, mean_q: 0.023312
 6733/10000: episode: 950, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000390, mae: 0.014345, mean_q: 0.009716
 6735/10000: episode: 951, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006123, mae: 0.032491, mean_q: 0.017829
 6739/10000: episode: 952, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000630, mae: 0.020028, mean_q: 0.027475
 6741/10000: episode: 953, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000807, mae: 0.024247, mean_q: 0.012544
 6743/10000: episode: 954, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000585, mae: 0.019130, mean_q: 0.020967
 6745/10000: episode: 955, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000873, mae: 0.023561, mean_q: 0.032078
 6747/10000: episode: 956, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000391, mae: 0.016386, mean_q: 0.020635
 6749/10000: episode: 957, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000548, mae: 0.016298, mean_q: 0.011472
 6751/10000: episode: 958, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001259, mae: 0.022649, mean_q: 0.018648
 6753/10000: episode: 959, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000589, mae: 0.019399, mean_q: 0.023255
 6755/10000: episode: 960, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000240, mae: 0.012520, mean_q: 0.020508
 6757/10000: episode: 961, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000427, mae: 0.015244, mean_q: 0.006041
 6759/10000: episode: 962, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000639, mae: 0.022012, mean_q: 0.033431
 6761/10000: episode: 963, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000743, mae: 0.026041, mean_q: 0.044320
 6763/10000: episode: 964, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000273, mae: 0.015289, mean_q: 0.008228
[Info] FALSIFICATION!
 6766/10000: episode: 965, duration: 0.168s, episode steps: 3, steps per second: 18, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000752, mae: 0.023260, mean_q: 0.014861
 6768/10000: episode: 966, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001844, mae: 0.033551, mean_q: 0.037563
 6770/10000: episode: 967, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000556, mae: 0.018017, mean_q: 0.020833
 6772/10000: episode: 968, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.007059, mae: 0.034495, mean_q: 0.020584
 6774/10000: episode: 969, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001078, mae: 0.024189, mean_q: 0.032857
 6776/10000: episode: 970, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001057, mae: 0.021756, mean_q: 0.026616
 6778/10000: episode: 971, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000328, mae: 0.014076, mean_q: 0.013678
 6780/10000: episode: 972, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000602, mae: 0.018183, mean_q: 0.012759
 6782/10000: episode: 973, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000948, mae: 0.019594, mean_q: 0.027977
 6784/10000: episode: 974, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001096, mae: 0.024011, mean_q: 0.026440
[Info] Complete ISplit Iteration
[Info] Levels: [0.02799194, 0.14721093, 0.37979788]
[Info] Cond. Prob: [0.12, 0.13, 0.02]
[Info] Error Prob: 0.000312

 6786/10000: episode: 975, duration: 0.815s, episode steps: 2, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001237, mae: 0.026623, mean_q: 0.019522
 6796/10000: episode: 976, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000782, mae: 0.021368, mean_q: 0.017578
 6806/10000: episode: 977, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.004063, mae: 0.033942, mean_q: 0.032958
 6816/10000: episode: 978, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.004241, mae: 0.035459, mean_q: 0.033224
 6826/10000: episode: 979, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.002033, mae: 0.029321, mean_q: 0.018875
 6836/10000: episode: 980, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001091, mae: 0.024228, mean_q: 0.024005
 6846/10000: episode: 981, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001491, mae: 0.024383, mean_q: 0.025367
 6856/10000: episode: 982, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000730, mae: 0.020687, mean_q: 0.021268
 6866/10000: episode: 983, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000665, mae: 0.020359, mean_q: 0.020006
 6876/10000: episode: 984, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001760, mae: 0.019999, mean_q: 0.024759
 6886/10000: episode: 985, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000513, mae: 0.016483, mean_q: 0.017098
 6896/10000: episode: 986, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001758, mae: 0.024494, mean_q: 0.021341
 6906/10000: episode: 987, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000726, mae: 0.020158, mean_q: 0.020106
 6916/10000: episode: 988, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002016, mae: 0.025676, mean_q: 0.025072
 6926/10000: episode: 989, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001592, mae: 0.023807, mean_q: 0.025118
 6936/10000: episode: 990, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000698, mae: 0.016754, mean_q: 0.017458
 6946/10000: episode: 991, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001946, mae: 0.023357, mean_q: 0.021191
 6956/10000: episode: 992, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001699, mae: 0.028067, mean_q: 0.017321
 6966/10000: episode: 993, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000760, mae: 0.020885, mean_q: 0.015823
 6976/10000: episode: 994, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001339, mae: 0.020199, mean_q: 0.021680
 6986/10000: episode: 995, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000925, mae: 0.020357, mean_q: 0.022489
 6996/10000: episode: 996, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000729, mae: 0.018297, mean_q: 0.016230
 7006/10000: episode: 997, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000659, mae: 0.018825, mean_q: 0.020100
 7016/10000: episode: 998, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001548, mae: 0.025582, mean_q: 0.027827
 7026/10000: episode: 999, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001972, mae: 0.027379, mean_q: 0.025985
 7036/10000: episode: 1000, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000877, mae: 0.024135, mean_q: 0.015670
 7046/10000: episode: 1001, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000559, mae: 0.019317, mean_q: 0.016973
 7056/10000: episode: 1002, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000673, mae: 0.019876, mean_q: 0.021655
 7066/10000: episode: 1003, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002664, mae: 0.027455, mean_q: 0.022598
 7076/10000: episode: 1004, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.001921, mae: 0.025862, mean_q: 0.022663
 7086/10000: episode: 1005, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001800, mae: 0.024805, mean_q: 0.021701
 7096/10000: episode: 1006, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001513, mae: 0.023639, mean_q: 0.022946
 7106/10000: episode: 1007, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001934, mae: 0.025335, mean_q: 0.026299
 7116/10000: episode: 1008, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002499, mae: 0.026840, mean_q: 0.034183
 7126/10000: episode: 1009, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000441, mae: 0.015895, mean_q: 0.017566
 7136/10000: episode: 1010, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001776, mae: 0.024401, mean_q: 0.029548
 7146/10000: episode: 1011, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000833, mae: 0.021465, mean_q: 0.023730
 7156/10000: episode: 1012, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001581, mae: 0.018884, mean_q: 0.020185
 7166/10000: episode: 1013, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000542, mae: 0.017090, mean_q: 0.018032
 7176/10000: episode: 1014, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000869, mae: 0.020170, mean_q: 0.020989
 7186/10000: episode: 1015, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000800, mae: 0.020443, mean_q: 0.020370
 7196/10000: episode: 1016, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001501, mae: 0.023940, mean_q: 0.028235
 7206/10000: episode: 1017, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000690, mae: 0.020983, mean_q: 0.024231
 7216/10000: episode: 1018, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000594, mae: 0.017597, mean_q: 0.018395
 7226/10000: episode: 1019, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001382, mae: 0.017595, mean_q: 0.020837
 7236/10000: episode: 1020, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000910, mae: 0.021455, mean_q: 0.020892
 7246/10000: episode: 1021, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001320, mae: 0.024162, mean_q: 0.027098
 7256/10000: episode: 1022, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002347, mae: 0.025534, mean_q: 0.029917
 7266/10000: episode: 1023, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000698, mae: 0.019380, mean_q: 0.023068
 7276/10000: episode: 1024, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001822, mae: 0.020696, mean_q: 0.023648
 7286/10000: episode: 1025, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001499, mae: 0.022234, mean_q: 0.023400
 7296/10000: episode: 1026, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001855, mae: 0.024951, mean_q: 0.024818
 7306/10000: episode: 1027, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002909, mae: 0.027261, mean_q: 0.020945
 7316/10000: episode: 1028, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002256, mae: 0.030469, mean_q: 0.026900
 7326/10000: episode: 1029, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001492, mae: 0.022278, mean_q: 0.031073
 7336/10000: episode: 1030, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001552, mae: 0.022637, mean_q: 0.023797
 7346/10000: episode: 1031, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001344, mae: 0.019427, mean_q: 0.021085
 7356/10000: episode: 1032, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000420, mae: 0.015160, mean_q: 0.016722
 7366/10000: episode: 1033, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002020, mae: 0.024393, mean_q: 0.027939
 7376/10000: episode: 1034, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000920, mae: 0.021129, mean_q: 0.025878
 7386/10000: episode: 1035, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000786, mae: 0.020429, mean_q: 0.019372
 7396/10000: episode: 1036, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001000, mae: 0.020585, mean_q: 0.020560
 7406/10000: episode: 1037, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000816, mae: 0.024034, mean_q: 0.019612
 7416/10000: episode: 1038, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002330, mae: 0.021021, mean_q: 0.018066
 7426/10000: episode: 1039, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002355, mae: 0.024051, mean_q: 0.029729
 7436/10000: episode: 1040, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001281, mae: 0.022126, mean_q: 0.018827
 7446/10000: episode: 1041, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002207, mae: 0.025441, mean_q: 0.030010
 7456/10000: episode: 1042, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001249, mae: 0.024075, mean_q: 0.023604
 7466/10000: episode: 1043, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000911, mae: 0.022255, mean_q: 0.025959
 7476/10000: episode: 1044, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.003507, mae: 0.030067, mean_q: 0.030134
 7486/10000: episode: 1045, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001228, mae: 0.025566, mean_q: 0.023723
 7496/10000: episode: 1046, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001430, mae: 0.022347, mean_q: 0.020760
 7506/10000: episode: 1047, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000969, mae: 0.022609, mean_q: 0.024468
 7516/10000: episode: 1048, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001429, mae: 0.019746, mean_q: 0.025137
 7526/10000: episode: 1049, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.001756, mae: 0.024348, mean_q: 0.021272
 7536/10000: episode: 1050, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001219, mae: 0.021926, mean_q: 0.020538
 7546/10000: episode: 1051, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.003895, mae: 0.033647, mean_q: 0.033989
 7556/10000: episode: 1052, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002478, mae: 0.027058, mean_q: 0.030926
 7566/10000: episode: 1053, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001188, mae: 0.026135, mean_q: 0.018796
 7576/10000: episode: 1054, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000817, mae: 0.022775, mean_q: 0.021230
 7586/10000: episode: 1055, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000598, mae: 0.017429, mean_q: 0.018274
 7596/10000: episode: 1056, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000608, mae: 0.019266, mean_q: 0.021746
 7606/10000: episode: 1057, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000403, mae: 0.015895, mean_q: 0.019170
 7616/10000: episode: 1058, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002338, mae: 0.021001, mean_q: 0.023174
 7626/10000: episode: 1059, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001329, mae: 0.020471, mean_q: 0.015984
 7636/10000: episode: 1060, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001734, mae: 0.020508, mean_q: 0.023460
 7646/10000: episode: 1061, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000976, mae: 0.020371, mean_q: 0.018307
 7656/10000: episode: 1062, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000556, mae: 0.016204, mean_q: 0.019841
 7666/10000: episode: 1063, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000722, mae: 0.014999, mean_q: 0.016937
 7676/10000: episode: 1064, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001785, mae: 0.023397, mean_q: 0.021722
 7686/10000: episode: 1065, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.002702, mae: 0.029047, mean_q: 0.033551
 7696/10000: episode: 1066, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001034, mae: 0.021146, mean_q: 0.023159
 7706/10000: episode: 1067, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001225, mae: 0.019109, mean_q: 0.015923
 7716/10000: episode: 1068, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001424, mae: 0.019191, mean_q: 0.019516
 7726/10000: episode: 1069, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002280, mae: 0.021016, mean_q: 0.021369
 7736/10000: episode: 1070, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000572, mae: 0.017208, mean_q: 0.017572
 7746/10000: episode: 1071, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.001872, mae: 0.021439, mean_q: 0.022604
 7756/10000: episode: 1072, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001666, mae: 0.017869, mean_q: 0.020124
 7766/10000: episode: 1073, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001929, mae: 0.024928, mean_q: 0.023452
 7776/10000: episode: 1074, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.002690, mae: 0.021965, mean_q: 0.017851
[Info] 1-TH LEVEL FOUND: 0.025332026183605194, Considering 10/100 traces
 7786/10000: episode: 1075, duration: 0.657s, episode steps: 10, steps per second: 15, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000587, mae: 0.015489, mean_q: 0.015607
 7790/10000: episode: 1076, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000454, mae: 0.013998, mean_q: 0.017144
 7794/10000: episode: 1077, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000498, mae: 0.017153, mean_q: 0.008413
 7801/10000: episode: 1078, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.002506, mae: 0.021470, mean_q: 0.022164
 7805/10000: episode: 1079, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000557, mae: 0.017978, mean_q: 0.026812
 7807/10000: episode: 1080, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000449, mae: 0.021403, mean_q: -0.000305
 7814/10000: episode: 1081, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000846, mae: 0.024128, mean_q: 0.028162
 7821/10000: episode: 1082, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000550, mae: 0.019755, mean_q: 0.017017
 7828/10000: episode: 1083, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000898, mae: 0.019610, mean_q: 0.016652
 7835/10000: episode: 1084, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001401, mae: 0.019098, mean_q: 0.021390
 7839/10000: episode: 1085, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000451, mae: 0.014606, mean_q: 0.016690
 7846/10000: episode: 1086, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000630, mae: 0.017033, mean_q: 0.017372
 7848/10000: episode: 1087, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000370, mae: 0.015494, mean_q: 0.008620
 7852/10000: episode: 1088, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000833, mae: 0.016506, mean_q: 0.017001
 7859/10000: episode: 1089, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000695, mae: 0.019235, mean_q: 0.015643
 7866/10000: episode: 1090, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000483, mae: 0.016934, mean_q: 0.022006
 7873/10000: episode: 1091, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000551, mae: 0.016383, mean_q: 0.022026
 7875/10000: episode: 1092, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000396, mae: 0.017325, mean_q: 0.023211
 7882/10000: episode: 1093, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.003195, mae: 0.026322, mean_q: 0.025611
 7889/10000: episode: 1094, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001557, mae: 0.022210, mean_q: 0.016450
 7896/10000: episode: 1095, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000682, mae: 0.015470, mean_q: 0.019478
 7898/10000: episode: 1096, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001027, mae: 0.021867, mean_q: 0.012416
 7905/10000: episode: 1097, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 1.947, mean reward: 0.278 [0.007, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 7.857 [5.000, 11.000], loss: 0.001587, mae: 0.022255, mean_q: 0.027050
 7907/10000: episode: 1098, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000374, mae: 0.012086, mean_q: 0.014366
 7914/10000: episode: 1099, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000348, mae: 0.014043, mean_q: 0.017214
 7921/10000: episode: 1100, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001460, mae: 0.019527, mean_q: 0.019017
 7928/10000: episode: 1101, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000436, mae: 0.014172, mean_q: 0.008621
 7935/10000: episode: 1102, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001399, mae: 0.020677, mean_q: 0.021263
 7937/10000: episode: 1103, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001197, mae: 0.025816, mean_q: 0.018128
 7944/10000: episode: 1104, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.001986, mae: 0.021396, mean_q: 0.021935
 7948/10000: episode: 1105, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000563, mae: 0.016596, mean_q: 0.021041
 7955/10000: episode: 1106, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001587, mae: 0.018552, mean_q: 0.019011
 7957/10000: episode: 1107, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000376, mae: 0.019125, mean_q: 0.033236
 7961/10000: episode: 1108, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000636, mae: 0.017867, mean_q: 0.009399
 7963/10000: episode: 1109, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003082, mae: 0.031069, mean_q: 0.012102
 7970/10000: episode: 1110, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000725, mae: 0.018378, mean_q: 0.024561
 7972/10000: episode: 1111, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000754, mae: 0.026010, mean_q: -0.003468
 7976/10000: episode: 1112, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000693, mae: 0.018472, mean_q: 0.016298
 7983/10000: episode: 1113, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.002311, mae: 0.020916, mean_q: 0.008559
 7987/10000: episode: 1114, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.004048, mae: 0.034582, mean_q: 0.035479
 7989/10000: episode: 1115, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000279, mae: 0.012615, mean_q: 0.010981
 7993/10000: episode: 1116, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000537, mae: 0.015451, mean_q: 0.010507
 8000/10000: episode: 1117, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000818, mae: 0.017623, mean_q: 0.019079
 8007/10000: episode: 1118, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001257, mae: 0.018809, mean_q: 0.018330
 8014/10000: episode: 1119, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000401, mae: 0.014922, mean_q: 0.010011
 8021/10000: episode: 1120, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001548, mae: 0.018881, mean_q: 0.010754
[Info] FALSIFICATION!
 8027/10000: episode: 1121, duration: 0.257s, episode steps: 6, steps per second: 23, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.004609, mae: 0.031151, mean_q: 0.028364
 8034/10000: episode: 1122, duration: 0.039s, episode steps: 7, steps per second: 180, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.001768, mae: 0.024885, mean_q: 0.026504
 8036/10000: episode: 1123, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001000, mae: 0.023731, mean_q: 0.014723
 8043/10000: episode: 1124, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000843, mae: 0.018702, mean_q: 0.012344
 8050/10000: episode: 1125, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.001365, mae: 0.019945, mean_q: 0.017412
 8057/10000: episode: 1126, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000751, mae: 0.018597, mean_q: 0.017826
 8064/10000: episode: 1127, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000616, mae: 0.018082, mean_q: 0.012692
 8071/10000: episode: 1128, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000351, mae: 0.014999, mean_q: 0.011320
 8078/10000: episode: 1129, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000194, mae: 0.010857, mean_q: 0.004878
 8085/10000: episode: 1130, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000429, mae: 0.015314, mean_q: 0.017773
 8092/10000: episode: 1131, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000588, mae: 0.013858, mean_q: 0.016472
 8096/10000: episode: 1132, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003402, mae: 0.023379, mean_q: 0.018718
 8103/10000: episode: 1133, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000429, mae: 0.015489, mean_q: 0.011813
 8110/10000: episode: 1134, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000268, mae: 0.012601, mean_q: 0.015242
 8114/10000: episode: 1135, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000584, mae: 0.013660, mean_q: 0.008554
 8116/10000: episode: 1136, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000304, mae: 0.012197, mean_q: 0.013696
 8123/10000: episode: 1137, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001287, mae: 0.015160, mean_q: 0.016818
 8130/10000: episode: 1138, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000372, mae: 0.014610, mean_q: 0.014300
 8132/10000: episode: 1139, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000187, mae: 0.010725, mean_q: 0.010613
 8134/10000: episode: 1140, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000300, mae: 0.019627, mean_q: -0.005115
 8138/10000: episode: 1141, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000439, mae: 0.017746, mean_q: 0.017305
 8145/10000: episode: 1142, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000277, mae: 0.014618, mean_q: 0.001745
 8147/10000: episode: 1143, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001033, mae: 0.022673, mean_q: 0.027053
 8151/10000: episode: 1144, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002110, mae: 0.018406, mean_q: 0.016564
 8158/10000: episode: 1145, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001151, mae: 0.015103, mean_q: 0.017234
 8162/10000: episode: 1146, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.005290, mae: 0.026678, mean_q: 0.021620
 8166/10000: episode: 1147, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000821, mae: 0.019614, mean_q: 0.014511
 8173/10000: episode: 1148, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000512, mae: 0.016953, mean_q: 0.015860
 8180/10000: episode: 1149, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000250, mae: 0.012396, mean_q: 0.008248
 8187/10000: episode: 1150, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000482, mae: 0.013729, mean_q: 0.012486
 8189/10000: episode: 1151, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000403, mae: 0.013321, mean_q: 0.010327
 8193/10000: episode: 1152, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000647, mae: 0.015029, mean_q: 0.009067
 8197/10000: episode: 1153, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000181, mae: 0.013127, mean_q: 0.016024
 8204/10000: episode: 1154, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000561, mae: 0.017891, mean_q: 0.013460
 8208/10000: episode: 1155, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000422, mae: 0.016929, mean_q: 0.009797
 8215/10000: episode: 1156, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000477, mae: 0.015203, mean_q: 0.018312
 8222/10000: episode: 1157, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 1.947, mean reward: 0.278 [0.007, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 7.857 [5.000, 11.000], loss: 0.000229, mae: 0.011682, mean_q: 0.007829
 8224/10000: episode: 1158, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000441, mae: 0.016334, mean_q: 0.018279
 8228/10000: episode: 1159, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000238, mae: 0.011071, mean_q: 0.004896
 8232/10000: episode: 1160, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000240, mae: 0.010735, mean_q: 0.013297
 8239/10000: episode: 1161, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000504, mae: 0.011979, mean_q: 0.010258
 8246/10000: episode: 1162, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000283, mae: 0.011646, mean_q: 0.011887
 8248/10000: episode: 1163, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000920, mae: 0.015151, mean_q: 0.013718
 8252/10000: episode: 1164, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000968, mae: 0.019566, mean_q: 0.022605
[Info] Complete ISplit Iteration
[Info] Levels: [0.025332026, 0.4766175]
[Info] Cond. Prob: [0.1, 0.01]
[Info] Error Prob: 0.001

 8259/10000: episode: 1165, duration: 0.826s, episode steps: 7, steps per second: 8, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000689, mae: 0.018701, mean_q: 0.014446
 8269/10000: episode: 1166, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001508, mae: 0.016965, mean_q: 0.018962
 8279/10000: episode: 1167, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001496, mae: 0.017076, mean_q: 0.016172
 8289/10000: episode: 1168, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001162, mae: 0.019647, mean_q: 0.014790
 8299/10000: episode: 1169, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000378, mae: 0.011501, mean_q: 0.013415
 8309/10000: episode: 1170, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000294, mae: 0.014557, mean_q: 0.009436
 8319/10000: episode: 1171, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000294, mae: 0.013670, mean_q: 0.009102
 8329/10000: episode: 1172, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000232, mae: 0.010748, mean_q: 0.009904
 8339/10000: episode: 1173, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000341, mae: 0.011538, mean_q: 0.010726
 8349/10000: episode: 1174, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000709, mae: 0.020038, mean_q: 0.014739
 8359/10000: episode: 1175, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000344, mae: 0.014143, mean_q: 0.012942
 8369/10000: episode: 1176, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001163, mae: 0.015954, mean_q: 0.016056
 8379/10000: episode: 1177, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000328, mae: 0.012500, mean_q: 0.012315
 8389/10000: episode: 1178, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000924, mae: 0.013437, mean_q: 0.014277
 8399/10000: episode: 1179, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002108, mae: 0.019726, mean_q: 0.019627
 8409/10000: episode: 1180, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000592, mae: 0.016802, mean_q: 0.013021
 8419/10000: episode: 1181, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000892, mae: 0.013243, mean_q: 0.014010
 8429/10000: episode: 1182, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000298, mae: 0.011253, mean_q: 0.012240
 8439/10000: episode: 1183, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000368, mae: 0.011534, mean_q: 0.011337
 8449/10000: episode: 1184, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002261, mae: 0.019804, mean_q: 0.018008
 8459/10000: episode: 1185, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000394, mae: 0.013700, mean_q: 0.011329
 8469/10000: episode: 1186, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000365, mae: 0.014065, mean_q: 0.014083
 8479/10000: episode: 1187, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001593, mae: 0.016910, mean_q: 0.018436
 8489/10000: episode: 1188, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001081, mae: 0.017764, mean_q: 0.014289
 8499/10000: episode: 1189, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000568, mae: 0.020664, mean_q: 0.014100
 8509/10000: episode: 1190, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000271, mae: 0.012999, mean_q: 0.014339
 8519/10000: episode: 1191, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000634, mae: 0.015896, mean_q: 0.012309
 8529/10000: episode: 1192, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000287, mae: 0.013302, mean_q: 0.013300
 8539/10000: episode: 1193, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001625, mae: 0.018627, mean_q: 0.015069
 8549/10000: episode: 1194, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000547, mae: 0.017232, mean_q: 0.011561
 8559/10000: episode: 1195, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000899, mae: 0.016385, mean_q: 0.012820
 8569/10000: episode: 1196, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000259, mae: 0.013263, mean_q: 0.011841
 8579/10000: episode: 1197, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001010, mae: 0.015661, mean_q: 0.014612
 8589/10000: episode: 1198, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000448, mae: 0.015699, mean_q: 0.014109
 8599/10000: episode: 1199, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001412, mae: 0.015038, mean_q: 0.007108
 8609/10000: episode: 1200, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000419, mae: 0.018177, mean_q: 0.011115
 8619/10000: episode: 1201, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002140, mae: 0.019685, mean_q: 0.021170
 8629/10000: episode: 1202, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000914, mae: 0.015486, mean_q: 0.011969
 8639/10000: episode: 1203, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001241, mae: 0.019470, mean_q: 0.014833
 8649/10000: episode: 1204, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001095, mae: 0.021464, mean_q: 0.018702
 8659/10000: episode: 1205, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002119, mae: 0.022247, mean_q: 0.017722
 8669/10000: episode: 1206, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000333, mae: 0.014289, mean_q: 0.016285
 8679/10000: episode: 1207, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000628, mae: 0.017379, mean_q: 0.017424
 8689/10000: episode: 1208, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001530, mae: 0.018022, mean_q: 0.015221
 8699/10000: episode: 1209, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000417, mae: 0.012631, mean_q: 0.015154
 8709/10000: episode: 1210, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000345, mae: 0.012964, mean_q: 0.015496
 8719/10000: episode: 1211, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000312, mae: 0.012148, mean_q: 0.012412
 8729/10000: episode: 1212, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001037, mae: 0.017372, mean_q: 0.012363
 8739/10000: episode: 1213, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000926, mae: 0.016204, mean_q: 0.014893
 8749/10000: episode: 1214, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000983, mae: 0.014832, mean_q: 0.014323
 8759/10000: episode: 1215, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001428, mae: 0.013923, mean_q: 0.012157
 8769/10000: episode: 1216, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000504, mae: 0.014921, mean_q: 0.014079
 8779/10000: episode: 1217, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000265, mae: 0.012482, mean_q: 0.012102
 8789/10000: episode: 1218, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000516, mae: 0.013969, mean_q: 0.016316
 8799/10000: episode: 1219, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001408, mae: 0.016721, mean_q: 0.016203
 8809/10000: episode: 1220, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001157, mae: 0.022031, mean_q: 0.020169
 8819/10000: episode: 1221, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000626, mae: 0.018110, mean_q: 0.014611
 8829/10000: episode: 1222, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001438, mae: 0.015266, mean_q: 0.011442
 8839/10000: episode: 1223, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001180, mae: 0.016984, mean_q: 0.017652
 8849/10000: episode: 1224, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000421, mae: 0.014083, mean_q: 0.016440
 8859/10000: episode: 1225, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000310, mae: 0.013671, mean_q: 0.009991
 8869/10000: episode: 1226, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000544, mae: 0.015591, mean_q: 0.014596
 8879/10000: episode: 1227, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000301, mae: 0.012555, mean_q: 0.009477
 8889/10000: episode: 1228, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000138, mae: 0.008921, mean_q: 0.008463
 8899/10000: episode: 1229, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001010, mae: 0.017159, mean_q: 0.012767
 8909/10000: episode: 1230, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000371, mae: 0.013556, mean_q: 0.016000
 8919/10000: episode: 1231, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000236, mae: 0.011148, mean_q: 0.009769
 8929/10000: episode: 1232, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000462, mae: 0.012477, mean_q: 0.013549
 8939/10000: episode: 1233, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000193, mae: 0.009311, mean_q: 0.009356
 8949/10000: episode: 1234, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001434, mae: 0.014682, mean_q: 0.016179
 8959/10000: episode: 1235, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001022, mae: 0.016291, mean_q: 0.015663
 8969/10000: episode: 1236, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000604, mae: 0.016730, mean_q: 0.015679
 8979/10000: episode: 1237, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001590, mae: 0.017518, mean_q: 0.018724
 8989/10000: episode: 1238, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.004211, mae: 0.025117, mean_q: 0.023735
 8999/10000: episode: 1239, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001190, mae: 0.026101, mean_q: 0.015576
 9009/10000: episode: 1240, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000932, mae: 0.023842, mean_q: 0.015935
 9019/10000: episode: 1241, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002914, mae: 0.023375, mean_q: 0.014109
 9029/10000: episode: 1242, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000566, mae: 0.018179, mean_q: 0.013337
 9039/10000: episode: 1243, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001670, mae: 0.020916, mean_q: 0.014297
 9049/10000: episode: 1244, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000384, mae: 0.015539, mean_q: 0.012850
 9059/10000: episode: 1245, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001970, mae: 0.017393, mean_q: 0.019899
 9069/10000: episode: 1246, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000487, mae: 0.014760, mean_q: 0.011982
 9079/10000: episode: 1247, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000219, mae: 0.010863, mean_q: 0.009529
 9089/10000: episode: 1248, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000452, mae: 0.013960, mean_q: 0.014042
 9099/10000: episode: 1249, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001815, mae: 0.018229, mean_q: 0.014357
 9109/10000: episode: 1250, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001695, mae: 0.021424, mean_q: 0.013964
 9119/10000: episode: 1251, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002142, mae: 0.024484, mean_q: 0.019012
 9129/10000: episode: 1252, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000601, mae: 0.016396, mean_q: 0.015093
 9139/10000: episode: 1253, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001482, mae: 0.018332, mean_q: 0.016814
 9149/10000: episode: 1254, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000318, mae: 0.013532, mean_q: 0.011397
 9159/10000: episode: 1255, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001546, mae: 0.015873, mean_q: 0.015601
 9169/10000: episode: 1256, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000383, mae: 0.012799, mean_q: 0.011621
 9179/10000: episode: 1257, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000502, mae: 0.014892, mean_q: 0.013439
 9189/10000: episode: 1258, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002855, mae: 0.025652, mean_q: 0.022293
 9199/10000: episode: 1259, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000715, mae: 0.021151, mean_q: 0.016551
 9209/10000: episode: 1260, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000412, mae: 0.015167, mean_q: 0.010491
 9219/10000: episode: 1261, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000489, mae: 0.015902, mean_q: 0.014850
 9229/10000: episode: 1262, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000337, mae: 0.012143, mean_q: 0.013674
 9239/10000: episode: 1263, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001566, mae: 0.014703, mean_q: 0.013465
 9249/10000: episode: 1264, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001392, mae: 0.017639, mean_q: 0.015444
[Info] 1-TH LEVEL FOUND: 0.006566919386386871, Considering 10/100 traces
 9259/10000: episode: 1265, duration: 0.706s, episode steps: 10, steps per second: 14, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000310, mae: 0.014363, mean_q: 0.010502
 9266/10000: episode: 1266, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000252, mae: 0.012888, mean_q: 0.005574
 9270/10000: episode: 1267, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000129, mae: 0.008998, mean_q: 0.009426
 9272/10000: episode: 1268, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000461, mae: 0.014973, mean_q: 0.003147
 9279/10000: episode: 1269, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000218, mae: 0.011113, mean_q: 0.014888
 9286/10000: episode: 1270, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000250, mae: 0.010906, mean_q: 0.009073
 9293/10000: episode: 1271, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000286, mae: 0.012081, mean_q: 0.009385
 9300/10000: episode: 1272, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000300, mae: 0.012039, mean_q: 0.013788
 9307/10000: episode: 1273, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.002217, mae: 0.019384, mean_q: 0.018393
 9314/10000: episode: 1274, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000570, mae: 0.016972, mean_q: 0.017989
 9321/10000: episode: 1275, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000346, mae: 0.015017, mean_q: 0.010569
 9328/10000: episode: 1276, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000353, mae: 0.012952, mean_q: 0.008116
 9335/10000: episode: 1277, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000245, mae: 0.012705, mean_q: 0.010294
 9342/10000: episode: 1278, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000189, mae: 0.010025, mean_q: 0.008798
 9349/10000: episode: 1279, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000350, mae: 0.011837, mean_q: 0.012363
 9353/10000: episode: 1280, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000162, mae: 0.008249, mean_q: 0.010511
 9357/10000: episode: 1281, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000273, mae: 0.011407, mean_q: 0.012075
 9364/10000: episode: 1282, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.003775, mae: 0.017847, mean_q: 0.011876
 9371/10000: episode: 1283, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000529, mae: 0.017715, mean_q: 0.017508
 9375/10000: episode: 1284, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001233, mae: 0.023688, mean_q: 0.021133
 9382/10000: episode: 1285, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000552, mae: 0.015665, mean_q: 0.014866
 9386/10000: episode: 1286, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001944, mae: 0.019989, mean_q: 0.018634
 9390/10000: episode: 1287, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000552, mae: 0.014034, mean_q: 0.014815
 9394/10000: episode: 1288, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001837, mae: 0.016118, mean_q: 0.018546
 9398/10000: episode: 1289, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000289, mae: 0.010968, mean_q: 0.009183
 9405/10000: episode: 1290, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000298, mae: 0.010922, mean_q: 0.013546
 9412/10000: episode: 1291, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000487, mae: 0.013064, mean_q: 0.014599
 9419/10000: episode: 1292, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001970, mae: 0.017060, mean_q: 0.014773
 9423/10000: episode: 1293, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000295, mae: 0.013024, mean_q: 0.004859
 9430/10000: episode: 1294, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000254, mae: 0.010903, mean_q: 0.013255
 9434/10000: episode: 1295, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000469, mae: 0.014982, mean_q: 0.014815
 9438/10000: episode: 1296, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000374, mae: 0.013783, mean_q: 0.016204
 9445/10000: episode: 1297, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000266, mae: 0.012887, mean_q: 0.005809
 9452/10000: episode: 1298, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000201, mae: 0.009841, mean_q: 0.008624
 9459/10000: episode: 1299, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000258, mae: 0.012537, mean_q: 0.014668
 9466/10000: episode: 1300, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000566, mae: 0.014345, mean_q: 0.013864
 9473/10000: episode: 1301, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001185, mae: 0.015548, mean_q: 0.006835
 9480/10000: episode: 1302, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000413, mae: 0.015229, mean_q: 0.014590
 9484/10000: episode: 1303, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000738, mae: 0.016037, mean_q: 0.019132
 9491/10000: episode: 1304, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000327, mae: 0.012958, mean_q: 0.007534
 9498/10000: episode: 1305, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.002826, mae: 0.025618, mean_q: 0.025693
 9505/10000: episode: 1306, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000278, mae: 0.016707, mean_q: 0.010237
 9512/10000: episode: 1307, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000202, mae: 0.013969, mean_q: 0.001350
 9519/10000: episode: 1308, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000523, mae: 0.013783, mean_q: 0.013153
 9526/10000: episode: 1309, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000320, mae: 0.012052, mean_q: 0.015569
 9533/10000: episode: 1310, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000221, mae: 0.011361, mean_q: 0.008495
 9540/10000: episode: 1311, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000275, mae: 0.011300, mean_q: 0.009703
 9547/10000: episode: 1312, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000628, mae: 0.013469, mean_q: 0.014919
[Info] FALSIFICATION!
 9553/10000: episode: 1313, duration: 0.262s, episode steps: 6, steps per second: 23, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.001281, mae: 0.015367, mean_q: 0.018440
 9560/10000: episode: 1314, duration: 0.039s, episode steps: 7, steps per second: 182, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.000242, mae: 0.013001, mean_q: 0.007708
 9564/10000: episode: 1315, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000717, mae: 0.019150, mean_q: 0.025890
 9571/10000: episode: 1316, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000334, mae: 0.012845, mean_q: 0.007424
 9578/10000: episode: 1317, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000367, mae: 0.011775, mean_q: 0.008850
 9585/10000: episode: 1318, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001968, mae: 0.015051, mean_q: 0.012382
 9589/10000: episode: 1319, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000563, mae: 0.020075, mean_q: 0.027697
 9596/10000: episode: 1320, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000418, mae: 0.014968, mean_q: 0.010430
 9603/10000: episode: 1321, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000218, mae: 0.012015, mean_q: 0.005181
 9610/10000: episode: 1322, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000150, mae: 0.008815, mean_q: 0.009077
[Info] FALSIFICATION!
 9616/10000: episode: 1323, duration: 0.261s, episode steps: 6, steps per second: 23, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000498, mae: 0.017895, mean_q: 0.023012
 9623/10000: episode: 1324, duration: 0.037s, episode steps: 7, steps per second: 187, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000343, mae: 0.017016, mean_q: 0.005371
 9630/10000: episode: 1325, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000410, mae: 0.016760, mean_q: 0.011106
 9634/10000: episode: 1326, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000524, mae: 0.020870, mean_q: 0.026928
 9638/10000: episode: 1327, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000418, mae: 0.014467, mean_q: 0.003676
 9645/10000: episode: 1328, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000549, mae: 0.015207, mean_q: 0.015714
 9649/10000: episode: 1329, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000372, mae: 0.014564, mean_q: 0.020008
 9656/10000: episode: 1330, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001130, mae: 0.013677, mean_q: 0.010520
 9660/10000: episode: 1331, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000535, mae: 0.015576, mean_q: 0.020331
 9667/10000: episode: 1332, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000571, mae: 0.015129, mean_q: 0.018424
 9671/10000: episode: 1333, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000530, mae: 0.015896, mean_q: 0.006322
 9678/10000: episode: 1334, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001022, mae: 0.013994, mean_q: 0.018405
 9685/10000: episode: 1335, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001251, mae: 0.019059, mean_q: 0.016713
 9692/10000: episode: 1336, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000564, mae: 0.016254, mean_q: 0.018195
 9696/10000: episode: 1337, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000288, mae: 0.013374, mean_q: 0.006549
 9700/10000: episode: 1338, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000326, mae: 0.017606, mean_q: 0.024080
 9707/10000: episode: 1339, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001029, mae: 0.013304, mean_q: 0.011266
 9714/10000: episode: 1340, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000327, mae: 0.011617, mean_q: 0.010932
 9721/10000: episode: 1341, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.002318, mae: 0.020160, mean_q: 0.014645
 9728/10000: episode: 1342, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.000337, mae: 0.015359, mean_q: 0.013325
 9730/10000: episode: 1343, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000890, mae: 0.018666, mean_q: 0.022531
 9737/10000: episode: 1344, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000401, mae: 0.016846, mean_q: 0.011519
 9744/10000: episode: 1345, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000266, mae: 0.011823, mean_q: 0.015490
 9751/10000: episode: 1346, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000310, mae: 0.012011, mean_q: 0.015014
 9758/10000: episode: 1347, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000518, mae: 0.014707, mean_q: 0.016926
 9765/10000: episode: 1348, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000279, mae: 0.011886, mean_q: 0.012172
 9772/10000: episode: 1349, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001910, mae: 0.015129, mean_q: 0.012081
 9779/10000: episode: 1350, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000820, mae: 0.020777, mean_q: 0.019995
 9786/10000: episode: 1351, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000425, mae: 0.013410, mean_q: 0.013457
 9793/10000: episode: 1352, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.002034, mae: 0.016359, mean_q: 0.011468
 9797/10000: episode: 1353, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000301, mae: 0.013678, mean_q: 0.014282
 9804/10000: episode: 1354, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000477, mae: 0.020938, mean_q: 0.014599
[Info] Complete ISplit Iteration
[Info] Levels: [0.0065669194, 0.5470495]
[Info] Cond. Prob: [0.1, 0.02]
[Info] Error Prob: 0.002

 9811/10000: episode: 1355, duration: 0.824s, episode steps: 7, steps per second: 8, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001636, mae: 0.019620, mean_q: 0.014928
 9821/10000: episode: 1356, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000566, mae: 0.017578, mean_q: 0.022182
 9831/10000: episode: 1357, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001457, mae: 0.015637, mean_q: 0.019412
 9841/10000: episode: 1358, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001987, mae: 0.019438, mean_q: 0.021054
 9851/10000: episode: 1359, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001189, mae: 0.018354, mean_q: 0.018853
 9861/10000: episode: 1360, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001594, mae: 0.021928, mean_q: 0.019239
 9871/10000: episode: 1361, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001472, mae: 0.018563, mean_q: 0.017311
 9881/10000: episode: 1362, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000503, mae: 0.018105, mean_q: 0.013665
 9891/10000: episode: 1363, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000763, mae: 0.014041, mean_q: 0.015877
 9901/10000: episode: 1364, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001024, mae: 0.017739, mean_q: 0.016552
 9911/10000: episode: 1365, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000416, mae: 0.013570, mean_q: 0.016662
 9921/10000: episode: 1366, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001542, mae: 0.023422, mean_q: 0.018438
 9931/10000: episode: 1367, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000668, mae: 0.019654, mean_q: 0.017932
 9941/10000: episode: 1368, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000406, mae: 0.016578, mean_q: 0.014024
 9951/10000: episode: 1369, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000272, mae: 0.013922, mean_q: 0.010843
 9961/10000: episode: 1370, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000432, mae: 0.012751, mean_q: 0.012649
 9971/10000: episode: 1371, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001404, mae: 0.015873, mean_q: 0.012202
 9981/10000: episode: 1372, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000386, mae: 0.015342, mean_q: 0.012789
 9991/10000: episode: 1373, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000560, mae: 0.016887, mean_q: 0.014704
done, took 64.197 seconds
[Info] End Importance Splitting. Falsification occurred 12 times.
