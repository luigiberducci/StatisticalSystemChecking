Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          (None, 2)                 0         
_________________________________________________________________
dense_1 (Dense)              (None, 16)                48        
_________________________________________________________________
dense_2 (Dense)              (None, 8)                 136       
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 9         
=================================================================
Total params: 193
Trainable params: 193
Non-trainable params: 0
_________________________________________________________________
None
[Info] Start Importance Splitting on succruns-v1.
Training for 10000 steps ...
   10/10000: episode: 1, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   20/10000: episode: 2, duration: 0.005s, episode steps: 10, steps per second: 1830, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   30/10000: episode: 3, duration: 0.005s, episode steps: 10, steps per second: 1888, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   40/10000: episode: 4, duration: 0.005s, episode steps: 10, steps per second: 2013, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   50/10000: episode: 5, duration: 0.005s, episode steps: 10, steps per second: 1842, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   60/10000: episode: 6, duration: 0.006s, episode steps: 10, steps per second: 1630, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   70/10000: episode: 7, duration: 0.006s, episode steps: 10, steps per second: 1781, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   80/10000: episode: 8, duration: 0.005s, episode steps: 10, steps per second: 2037, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   90/10000: episode: 9, duration: 0.005s, episode steps: 10, steps per second: 1867, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  100/10000: episode: 10, duration: 0.006s, episode steps: 10, steps per second: 1795, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  110/10000: episode: 11, duration: 0.005s, episode steps: 10, steps per second: 2113, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  120/10000: episode: 12, duration: 0.005s, episode steps: 10, steps per second: 2073, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  130/10000: episode: 13, duration: 0.005s, episode steps: 10, steps per second: 1969, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  140/10000: episode: 14, duration: 0.005s, episode steps: 10, steps per second: 1901, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  150/10000: episode: 15, duration: 0.005s, episode steps: 10, steps per second: 2138, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  160/10000: episode: 16, duration: 0.005s, episode steps: 10, steps per second: 1921, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  170/10000: episode: 17, duration: 0.006s, episode steps: 10, steps per second: 1786, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  180/10000: episode: 18, duration: 0.006s, episode steps: 10, steps per second: 1744, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  190/10000: episode: 19, duration: 0.005s, episode steps: 10, steps per second: 2031, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  200/10000: episode: 20, duration: 0.005s, episode steps: 10, steps per second: 1904, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  210/10000: episode: 21, duration: 0.005s, episode steps: 10, steps per second: 1984, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  220/10000: episode: 22, duration: 0.005s, episode steps: 10, steps per second: 1955, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  230/10000: episode: 23, duration: 0.005s, episode steps: 10, steps per second: 1911, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  240/10000: episode: 24, duration: 0.006s, episode steps: 10, steps per second: 1648, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  250/10000: episode: 25, duration: 0.006s, episode steps: 10, steps per second: 1688, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  260/10000: episode: 26, duration: 0.005s, episode steps: 10, steps per second: 2082, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  270/10000: episode: 27, duration: 0.007s, episode steps: 10, steps per second: 1413, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  280/10000: episode: 28, duration: 0.005s, episode steps: 10, steps per second: 1895, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  290/10000: episode: 29, duration: 0.006s, episode steps: 10, steps per second: 1767, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  300/10000: episode: 30, duration: 0.008s, episode steps: 10, steps per second: 1280, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  310/10000: episode: 31, duration: 0.005s, episode steps: 10, steps per second: 1952, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  320/10000: episode: 32, duration: 0.005s, episode steps: 10, steps per second: 2187, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  330/10000: episode: 33, duration: 0.006s, episode steps: 10, steps per second: 1730, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  340/10000: episode: 34, duration: 0.005s, episode steps: 10, steps per second: 2009, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  350/10000: episode: 35, duration: 0.005s, episode steps: 10, steps per second: 2029, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  360/10000: episode: 36, duration: 0.006s, episode steps: 10, steps per second: 1792, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  370/10000: episode: 37, duration: 0.005s, episode steps: 10, steps per second: 1901, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  380/10000: episode: 38, duration: 0.005s, episode steps: 10, steps per second: 1970, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  390/10000: episode: 39, duration: 0.006s, episode steps: 10, steps per second: 1709, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  400/10000: episode: 40, duration: 0.005s, episode steps: 10, steps per second: 2083, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  410/10000: episode: 41, duration: 0.005s, episode steps: 10, steps per second: 1922, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  420/10000: episode: 42, duration: 0.007s, episode steps: 10, steps per second: 1475, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  430/10000: episode: 43, duration: 0.005s, episode steps: 10, steps per second: 2147, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  440/10000: episode: 44, duration: 0.005s, episode steps: 10, steps per second: 1958, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  450/10000: episode: 45, duration: 0.005s, episode steps: 10, steps per second: 1877, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  460/10000: episode: 46, duration: 0.005s, episode steps: 10, steps per second: 2049, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  470/10000: episode: 47, duration: 0.005s, episode steps: 10, steps per second: 2086, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  480/10000: episode: 48, duration: 0.005s, episode steps: 10, steps per second: 1947, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  490/10000: episode: 49, duration: 0.005s, episode steps: 10, steps per second: 1938, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  500/10000: episode: 50, duration: 0.005s, episode steps: 10, steps per second: 2086, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  510/10000: episode: 51, duration: 0.676s, episode steps: 10, steps per second: 15, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.004215, mae: 0.066022, mean_q: -0.056555
  520/10000: episode: 52, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002344, mae: 0.043234, mean_q: -0.069082
  530/10000: episode: 53, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001380, mae: 0.037250, mean_q: -0.054353
  540/10000: episode: 54, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001149, mae: 0.032859, mean_q: -0.052039
  550/10000: episode: 55, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000653, mae: 0.027323, mean_q: -0.055129
  560/10000: episode: 56, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000729, mae: 0.027237, mean_q: -0.051199
  570/10000: episode: 57, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000641, mae: 0.026177, mean_q: -0.047007
  580/10000: episode: 58, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000717, mae: 0.028126, mean_q: -0.037756
  590/10000: episode: 59, duration: 0.073s, episode steps: 10, steps per second: 138, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000701, mae: 0.025594, mean_q: -0.038161
  600/10000: episode: 60, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000599, mae: 0.023784, mean_q: -0.037926
  610/10000: episode: 61, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000517, mae: 0.023411, mean_q: -0.030722
  620/10000: episode: 62, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000480, mae: 0.021476, mean_q: -0.032987
  630/10000: episode: 63, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000422, mae: 0.020425, mean_q: -0.036252
  640/10000: episode: 64, duration: 0.118s, episode steps: 10, steps per second: 85, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000381, mae: 0.020594, mean_q: -0.027645
  650/10000: episode: 65, duration: 0.085s, episode steps: 10, steps per second: 117, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000359, mae: 0.019428, mean_q: -0.026153
  660/10000: episode: 66, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000269, mae: 0.017576, mean_q: -0.027115
  670/10000: episode: 67, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000253, mae: 0.017077, mean_q: -0.023751
  680/10000: episode: 68, duration: 0.136s, episode steps: 10, steps per second: 73, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000223, mae: 0.016684, mean_q: -0.019765
  690/10000: episode: 69, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000252, mae: 0.016248, mean_q: -0.018779
  700/10000: episode: 70, duration: 0.157s, episode steps: 10, steps per second: 64, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000231, mae: 0.015263, mean_q: -0.016071
  710/10000: episode: 71, duration: 0.101s, episode steps: 10, steps per second: 99, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000192, mae: 0.014837, mean_q: -0.017680
  720/10000: episode: 72, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000149, mae: 0.013384, mean_q: -0.018820
  730/10000: episode: 73, duration: 0.095s, episode steps: 10, steps per second: 106, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000140, mae: 0.013157, mean_q: -0.016108
  740/10000: episode: 74, duration: 0.101s, episode steps: 10, steps per second: 99, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000165, mae: 0.012237, mean_q: -0.012064
  750/10000: episode: 75, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000174, mae: 0.013080, mean_q: -0.014845
  760/10000: episode: 76, duration: 0.117s, episode steps: 10, steps per second: 85, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000143, mae: 0.012235, mean_q: -0.010230
  770/10000: episode: 77, duration: 0.108s, episode steps: 10, steps per second: 92, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000173, mae: 0.012608, mean_q: -0.008334
  780/10000: episode: 78, duration: 0.119s, episode steps: 10, steps per second: 84, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000095, mae: 0.010496, mean_q: -0.009834
  790/10000: episode: 79, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000221, mae: 0.013234, mean_q: -0.006641
  800/10000: episode: 80, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000081, mae: 0.009884, mean_q: -0.007807
  810/10000: episode: 81, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000068, mae: 0.008537, mean_q: -0.008200
  820/10000: episode: 82, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000132, mae: 0.009775, mean_q: -0.007251
  830/10000: episode: 83, duration: 0.060s, episode steps: 10, steps per second: 165, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000056, mae: 0.008451, mean_q: -0.006855
  840/10000: episode: 84, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000110, mae: 0.008910, mean_q: -0.004764
  850/10000: episode: 85, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000070, mae: 0.007692, mean_q: -0.005081
  860/10000: episode: 86, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000051, mae: 0.007418, mean_q: -0.005528
  870/10000: episode: 87, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000037, mae: 0.006683, mean_q: -0.006268
  880/10000: episode: 88, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000114, mae: 0.007976, mean_q: -0.002357
  890/10000: episode: 89, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000057, mae: 0.007716, mean_q: -0.003391
  900/10000: episode: 90, duration: 0.093s, episode steps: 10, steps per second: 107, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000043, mae: 0.006526, mean_q: -0.002675
  910/10000: episode: 91, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000096, mae: 0.007651, mean_q: -0.000579
  920/10000: episode: 92, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000073, mae: 0.007448, mean_q: -0.002410
  930/10000: episode: 93, duration: 0.079s, episode steps: 10, steps per second: 126, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000042, mae: 0.006563, mean_q: -0.002488
  940/10000: episode: 94, duration: 0.088s, episode steps: 10, steps per second: 114, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000070, mae: 0.006229, mean_q: -0.001599
  950/10000: episode: 95, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000050, mae: 0.005777, mean_q: -0.000263
  960/10000: episode: 96, duration: 0.076s, episode steps: 10, steps per second: 131, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000073, mae: 0.006400, mean_q: -0.000739
  970/10000: episode: 97, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000068, mae: 0.005557, mean_q: 0.001063
  980/10000: episode: 98, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000086, mae: 0.006121, mean_q: 0.000144
  990/10000: episode: 99, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000098, mae: 0.006966, mean_q: 0.001555
 1000/10000: episode: 100, duration: 0.092s, episode steps: 10, steps per second: 108, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000036, mae: 0.004306, mean_q: 0.000199
 1010/10000: episode: 101, duration: 0.083s, episode steps: 10, steps per second: 121, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000131, mae: 0.008999, mean_q: 0.002195
 1020/10000: episode: 102, duration: 0.083s, episode steps: 10, steps per second: 120, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000070, mae: 0.005570, mean_q: 0.002292
 1030/10000: episode: 103, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000059, mae: 0.004894, mean_q: 0.001613
 1040/10000: episode: 104, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000036, mae: 0.003764, mean_q: 0.000899
 1050/10000: episode: 105, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000046, mae: 0.004686, mean_q: 0.000550
 1060/10000: episode: 106, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000022, mae: 0.004186, mean_q: 0.000512
 1070/10000: episode: 107, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000030, mae: 0.004845, mean_q: 0.001596
 1080/10000: episode: 108, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000042, mae: 0.004310, mean_q: 0.002570
 1090/10000: episode: 109, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000022, mae: 0.003773, mean_q: 0.002260
 1100/10000: episode: 110, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000059, mae: 0.004061, mean_q: 0.002905
 1110/10000: episode: 111, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000025, mae: 0.004282, mean_q: 0.001918
 1120/10000: episode: 112, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000107, mae: 0.005607, mean_q: 0.004553
 1130/10000: episode: 113, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000057, mae: 0.005812, mean_q: 0.002455
 1140/10000: episode: 114, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000071, mae: 0.005566, mean_q: 0.005679
 1150/10000: episode: 115, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000074, mae: 0.005712, mean_q: 0.003386
 1160/10000: episode: 116, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000024, mae: 0.004433, mean_q: 0.002542
 1170/10000: episode: 117, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000029, mae: 0.004233, mean_q: 0.001876
 1180/10000: episode: 118, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000054, mae: 0.004780, mean_q: 0.004313
 1190/10000: episode: 119, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000074, mae: 0.005858, mean_q: 0.003992
 1200/10000: episode: 120, duration: 0.067s, episode steps: 10, steps per second: 148, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000063, mae: 0.006330, mean_q: 0.003858
 1210/10000: episode: 121, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000048, mae: 0.004082, mean_q: 0.003478
 1220/10000: episode: 122, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000058, mae: 0.005475, mean_q: 0.002472
 1230/10000: episode: 123, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000057, mae: 0.005515, mean_q: 0.004992
 1240/10000: episode: 124, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000055, mae: 0.004877, mean_q: 0.001973
 1250/10000: episode: 125, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000069, mae: 0.005447, mean_q: 0.003809
 1260/10000: episode: 126, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000041, mae: 0.004057, mean_q: 0.004243
 1270/10000: episode: 127, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000026, mae: 0.003911, mean_q: 0.003470
 1280/10000: episode: 128, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000035, mae: 0.003728, mean_q: 0.005107
 1290/10000: episode: 129, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000064, mae: 0.004207, mean_q: 0.003127
 1300/10000: episode: 130, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000061, mae: 0.006056, mean_q: 0.004739
 1310/10000: episode: 131, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000155, mae: 0.008791, mean_q: 0.004811
 1320/10000: episode: 132, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000083, mae: 0.007565, mean_q: 0.005939
 1330/10000: episode: 133, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000127, mae: 0.009111, mean_q: 0.002994
 1340/10000: episode: 134, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000062, mae: 0.006078, mean_q: 0.005376
 1350/10000: episode: 135, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000018, mae: 0.003405, mean_q: 0.003757
 1360/10000: episode: 136, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000017, mae: 0.003344, mean_q: 0.004127
 1370/10000: episode: 137, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000075, mae: 0.004974, mean_q: 0.004680
 1380/10000: episode: 138, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000070, mae: 0.006543, mean_q: 0.003297
 1390/10000: episode: 139, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000035, mae: 0.004759, mean_q: 0.004036
 1400/10000: episode: 140, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000031, mae: 0.004827, mean_q: 0.003261
 1410/10000: episode: 141, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000082, mae: 0.007188, mean_q: 0.005619
 1420/10000: episode: 142, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000031, mae: 0.004974, mean_q: 0.003314
 1430/10000: episode: 143, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000076, mae: 0.005211, mean_q: 0.004722
 1440/10000: episode: 144, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000022, mae: 0.003799, mean_q: 0.004344
 1450/10000: episode: 145, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000038, mae: 0.003701, mean_q: 0.003211
 1460/10000: episode: 146, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000025, mae: 0.003949, mean_q: 0.003739
 1470/10000: episode: 147, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000052, mae: 0.004222, mean_q: 0.004839
 1480/10000: episode: 148, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000033, mae: 0.004040, mean_q: 0.003432
 1490/10000: episode: 149, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000019, mae: 0.003070, mean_q: 0.003739
[Info] 1-TH LEVEL FOUND: 0.027385706081986427, Considering 12/100 traces
 1500/10000: episode: 150, duration: 1.109s, episode steps: 10, steps per second: 9, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000050, mae: 0.004541, mean_q: 0.004935
 1506/10000: episode: 151, duration: 0.037s, episode steps: 6, steps per second: 162, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000090, mae: 0.004780, mean_q: 0.003801
 1511/10000: episode: 152, duration: 0.031s, episode steps: 5, steps per second: 159, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000018, mae: 0.003511, mean_q: 0.004153
 1516/10000: episode: 153, duration: 0.032s, episode steps: 5, steps per second: 155, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000024, mae: 0.003916, mean_q: 0.003277
 1522/10000: episode: 154, duration: 0.040s, episode steps: 6, steps per second: 150, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000124, mae: 0.006637, mean_q: 0.007412
 1527/10000: episode: 155, duration: 0.039s, episode steps: 5, steps per second: 128, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000467, mae: 0.011261, mean_q: 0.006546
 1532/10000: episode: 156, duration: 0.067s, episode steps: 5, steps per second: 75, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000111, mae: 0.010195, mean_q: -0.002299
 1535/10000: episode: 157, duration: 0.039s, episode steps: 3, steps per second: 77, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000149, mae: 0.009568, mean_q: 0.010225
 1540/10000: episode: 158, duration: 0.062s, episode steps: 5, steps per second: 81, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000434, mae: 0.009683, mean_q: 0.010228
 1545/10000: episode: 159, duration: 0.064s, episode steps: 5, steps per second: 79, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000048, mae: 0.007789, mean_q: -0.000178
 1550/10000: episode: 160, duration: 0.055s, episode steps: 5, steps per second: 92, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000046, mae: 0.006532, mean_q: 0.004299
 1555/10000: episode: 161, duration: 0.064s, episode steps: 5, steps per second: 78, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000161, mae: 0.010647, mean_q: 0.010528
 1560/10000: episode: 162, duration: 0.063s, episode steps: 5, steps per second: 79, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000091, mae: 0.009799, mean_q: -0.002294
 1565/10000: episode: 163, duration: 0.035s, episode steps: 5, steps per second: 144, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000394, mae: 0.009719, mean_q: 0.009324
 1570/10000: episode: 164, duration: 0.033s, episode steps: 5, steps per second: 154, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000134, mae: 0.010769, mean_q: 0.015168
 1575/10000: episode: 165, duration: 0.045s, episode steps: 5, steps per second: 112, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000496, mae: 0.014417, mean_q: 0.011205
 1578/10000: episode: 166, duration: 0.038s, episode steps: 3, steps per second: 80, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001475, mae: 0.017129, mean_q: 0.005364
 1581/10000: episode: 167, duration: 0.031s, episode steps: 3, steps per second: 98, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000198, mae: 0.012483, mean_q: 0.015476
 1586/10000: episode: 168, duration: 0.050s, episode steps: 5, steps per second: 101, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000149, mae: 0.012747, mean_q: -0.002453
 1591/10000: episode: 169, duration: 0.052s, episode steps: 5, steps per second: 95, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000175, mae: 0.012357, mean_q: 0.001728
 1597/10000: episode: 170, duration: 0.058s, episode steps: 6, steps per second: 103, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000107, mae: 0.009085, mean_q: 0.012065
 1602/10000: episode: 171, duration: 0.052s, episode steps: 5, steps per second: 95, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000047, mae: 0.006592, mean_q: 0.005221
 1607/10000: episode: 172, duration: 0.041s, episode steps: 5, steps per second: 122, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000683, mae: 0.013381, mean_q: 0.011276
 1612/10000: episode: 173, duration: 0.051s, episode steps: 5, steps per second: 99, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000181, mae: 0.013531, mean_q: -0.001661
 1617/10000: episode: 174, duration: 0.046s, episode steps: 5, steps per second: 108, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000141, mae: 0.010798, mean_q: 0.016379
 1622/10000: episode: 175, duration: 0.044s, episode steps: 5, steps per second: 113, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000096, mae: 0.007140, mean_q: 0.006094
 1627/10000: episode: 176, duration: 0.045s, episode steps: 5, steps per second: 112, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000153, mae: 0.008156, mean_q: 0.008111
 1632/10000: episode: 177, duration: 0.039s, episode steps: 5, steps per second: 127, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000364, mae: 0.007768, mean_q: 0.010308
 1635/10000: episode: 178, duration: 0.022s, episode steps: 3, steps per second: 138, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000159, mae: 0.010912, mean_q: 0.001669
 1640/10000: episode: 179, duration: 0.034s, episode steps: 5, steps per second: 148, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000130, mae: 0.009010, mean_q: 0.012384
 1643/10000: episode: 180, duration: 0.022s, episode steps: 3, steps per second: 138, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000134, mae: 0.012462, mean_q: -0.005242
 1648/10000: episode: 181, duration: 0.043s, episode steps: 5, steps per second: 115, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000184, mae: 0.011243, mean_q: 0.012944
 1653/10000: episode: 182, duration: 0.040s, episode steps: 5, steps per second: 125, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000093, mae: 0.007985, mean_q: 0.007160
 1656/10000: episode: 183, duration: 0.032s, episode steps: 3, steps per second: 93, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000082, mae: 0.007465, mean_q: 0.003117
 1662/10000: episode: 184, duration: 0.049s, episode steps: 6, steps per second: 122, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000344, mae: 0.008830, mean_q: 0.009063
 1667/10000: episode: 185, duration: 0.051s, episode steps: 5, steps per second: 99, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000405, mae: 0.012154, mean_q: 0.012505
 1670/10000: episode: 186, duration: 0.031s, episode steps: 3, steps per second: 97, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000161, mae: 0.011519, mean_q: 0.005199
 1675/10000: episode: 187, duration: 0.043s, episode steps: 5, steps per second: 116, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000116, mae: 0.009299, mean_q: 0.001729
 1680/10000: episode: 188, duration: 0.037s, episode steps: 5, steps per second: 137, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000203, mae: 0.011674, mean_q: 0.012265
 1686/10000: episode: 189, duration: 0.038s, episode steps: 6, steps per second: 156, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000121, mae: 0.008984, mean_q: 0.004512
 1691/10000: episode: 190, duration: 0.031s, episode steps: 5, steps per second: 164, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000075, mae: 0.005449, mean_q: 0.005340
 1696/10000: episode: 191, duration: 0.034s, episode steps: 5, steps per second: 147, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000125, mae: 0.006388, mean_q: 0.007841
 1701/10000: episode: 192, duration: 0.032s, episode steps: 5, steps per second: 158, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000094, mae: 0.008327, mean_q: 0.007128
 1706/10000: episode: 193, duration: 0.029s, episode steps: 5, steps per second: 173, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000133, mae: 0.008638, mean_q: 0.009017
 1711/10000: episode: 194, duration: 0.033s, episode steps: 5, steps per second: 151, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000101, mae: 0.006648, mean_q: 0.006765
 1716/10000: episode: 195, duration: 0.033s, episode steps: 5, steps per second: 152, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000039, mae: 0.004832, mean_q: 0.008063
 1719/10000: episode: 196, duration: 0.029s, episode steps: 3, steps per second: 103, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000080, mae: 0.007039, mean_q: 0.007209
 1724/10000: episode: 197, duration: 0.047s, episode steps: 5, steps per second: 107, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000051, mae: 0.006306, mean_q: 0.006208
 1729/10000: episode: 198, duration: 0.039s, episode steps: 5, steps per second: 129, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000106, mae: 0.006466, mean_q: 0.006839
 1734/10000: episode: 199, duration: 0.059s, episode steps: 5, steps per second: 85, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000334, mae: 0.009087, mean_q: 0.012106
 1739/10000: episode: 200, duration: 0.050s, episode steps: 5, steps per second: 101, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000128, mae: 0.009284, mean_q: 0.005458
 1744/10000: episode: 201, duration: 0.052s, episode steps: 5, steps per second: 97, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000178, mae: 0.012826, mean_q: 0.011906
 1749/10000: episode: 202, duration: 0.055s, episode steps: 5, steps per second: 90, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000087, mae: 0.009236, mean_q: 0.008499
 1752/10000: episode: 203, duration: 0.031s, episode steps: 3, steps per second: 96, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000121, mae: 0.008745, mean_q: 0.006697
 1758/10000: episode: 204, duration: 0.037s, episode steps: 6, steps per second: 160, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000085, mae: 0.007339, mean_q: 0.004659
 1763/10000: episode: 205, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000316, mae: 0.008523, mean_q: 0.010242
 1768/10000: episode: 206, duration: 0.038s, episode steps: 5, steps per second: 131, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000100, mae: 0.006502, mean_q: 0.007680
 1773/10000: episode: 207, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000064, mae: 0.006368, mean_q: 0.006750
 1778/10000: episode: 208, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000142, mae: 0.006341, mean_q: 0.004231
 1783/10000: episode: 209, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000097, mae: 0.009028, mean_q: 0.008415
 1788/10000: episode: 210, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000101, mae: 0.008156, mean_q: 0.009444
 1791/10000: episode: 211, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000047, mae: 0.005916, mean_q: 0.005204
 1797/10000: episode: 212, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000148, mae: 0.009058, mean_q: 0.009003
 1802/10000: episode: 213, duration: 0.030s, episode steps: 5, steps per second: 168, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000153, mae: 0.009804, mean_q: 0.012205
 1805/10000: episode: 214, duration: 0.020s, episode steps: 3, steps per second: 152, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000068, mae: 0.008135, mean_q: 0.001851
 1810/10000: episode: 215, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000098, mae: 0.007792, mean_q: 0.010416
 1815/10000: episode: 216, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000420, mae: 0.012308, mean_q: 0.018649
 1820/10000: episode: 217, duration: 0.046s, episode steps: 5, steps per second: 108, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000168, mae: 0.011650, mean_q: -0.000671
 1825/10000: episode: 218, duration: 0.058s, episode steps: 5, steps per second: 86, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000220, mae: 0.012067, mean_q: 0.012344
 1830/10000: episode: 219, duration: 0.058s, episode steps: 5, steps per second: 86, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000232, mae: 0.010772, mean_q: 0.013686
 1835/10000: episode: 220, duration: 0.054s, episode steps: 5, steps per second: 93, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000110, mae: 0.008017, mean_q: 0.012284
 1840/10000: episode: 221, duration: 0.072s, episode steps: 5, steps per second: 69, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000411, mae: 0.009739, mean_q: 0.009709
 1843/10000: episode: 222, duration: 0.037s, episode steps: 3, steps per second: 81, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000256, mae: 0.011835, mean_q: 0.015943
 1848/10000: episode: 223, duration: 0.063s, episode steps: 5, steps per second: 79, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000172, mae: 0.009693, mean_q: 0.010235
 1854/10000: episode: 224, duration: 0.072s, episode steps: 6, steps per second: 83, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000171, mae: 0.007861, mean_q: 0.011366
 1859/10000: episode: 225, duration: 0.057s, episode steps: 5, steps per second: 88, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000202, mae: 0.012521, mean_q: 0.005031
 1865/10000: episode: 226, duration: 0.058s, episode steps: 6, steps per second: 104, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000133, mae: 0.010545, mean_q: 0.007629
 1870/10000: episode: 227, duration: 0.047s, episode steps: 5, steps per second: 107, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000268, mae: 0.013048, mean_q: 0.015571
 1876/10000: episode: 228, duration: 0.057s, episode steps: 6, steps per second: 106, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000386, mae: 0.011039, mean_q: 0.013401
 1881/10000: episode: 229, duration: 0.053s, episode steps: 5, steps per second: 94, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000467, mae: 0.012846, mean_q: 0.016099
 1886/10000: episode: 230, duration: 0.056s, episode steps: 5, steps per second: 89, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000284, mae: 0.013545, mean_q: 0.006840
 1891/10000: episode: 231, duration: 0.053s, episode steps: 5, steps per second: 95, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000218, mae: 0.012403, mean_q: 0.012177
 1896/10000: episode: 232, duration: 0.051s, episode steps: 5, steps per second: 99, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000073, mae: 0.008266, mean_q: 0.005061
 1901/10000: episode: 233, duration: 0.053s, episode steps: 5, steps per second: 93, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000495, mae: 0.016705, mean_q: 0.017986
 1906/10000: episode: 234, duration: 0.057s, episode steps: 5, steps per second: 88, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000158, mae: 0.010939, mean_q: 0.012738
 1912/10000: episode: 235, duration: 0.080s, episode steps: 6, steps per second: 75, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000091, mae: 0.009396, mean_q: 0.007308
 1915/10000: episode: 236, duration: 0.031s, episode steps: 3, steps per second: 96, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000204, mae: 0.011400, mean_q: 0.003446
 1920/10000: episode: 237, duration: 0.047s, episode steps: 5, steps per second: 106, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000126, mae: 0.008936, mean_q: 0.011449
[Info] 2-TH LEVEL FOUND: 0.05789539963006973, Considering 12/100 traces
 1925/10000: episode: 238, duration: 0.890s, episode steps: 5, steps per second: 6, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000196, mae: 0.011840, mean_q: 0.011508
 1927/10000: episode: 239, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000206, mae: 0.009817, mean_q: 0.003354
 1929/10000: episode: 240, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000084, mae: 0.007875, mean_q: 0.010505
 1933/10000: episode: 241, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000502, mae: 0.010888, mean_q: 0.014418
 1935/10000: episode: 242, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000162, mae: 0.009035, mean_q: 0.009215
 1937/10000: episode: 243, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000288, mae: 0.012963, mean_q: 0.014559
 1941/10000: episode: 244, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000201, mae: 0.011341, mean_q: 0.014442
 1945/10000: episode: 245, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000298, mae: 0.012935, mean_q: 0.009824
 1947/10000: episode: 246, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000148, mae: 0.013102, mean_q: 0.019308
 1949/10000: episode: 247, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000225, mae: 0.017312, mean_q: -0.006716
[Info] FALSIFICATION!
 1952/10000: episode: 248, duration: 0.423s, episode steps: 3, steps per second: 7, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000203, mae: 0.012956, mean_q: 0.016550
 1954/10000: episode: 249, duration: 0.016s, episode steps: 2, steps per second: 121, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006397, mae: 0.023931, mean_q: 0.013808
 1956/10000: episode: 250, duration: 0.017s, episode steps: 2, steps per second: 120, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000190, mae: 0.012688, mean_q: 0.020730
 1958/10000: episode: 251, duration: 0.024s, episode steps: 2, steps per second: 84, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000862, mae: 0.017748, mean_q: 0.012894
 1960/10000: episode: 252, duration: 0.032s, episode steps: 2, steps per second: 62, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000874, mae: 0.016429, mean_q: 0.007184
 1962/10000: episode: 253, duration: 0.032s, episode steps: 2, steps per second: 63, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000087, mae: 0.009903, mean_q: 0.020244
 1966/10000: episode: 254, duration: 0.049s, episode steps: 4, steps per second: 82, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000254, mae: 0.013768, mean_q: 0.002082
 1968/10000: episode: 255, duration: 0.027s, episode steps: 2, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000372, mae: 0.018858, mean_q: 0.028669
 1970/10000: episode: 256, duration: 0.028s, episode steps: 2, steps per second: 71, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000377, mae: 0.016425, mean_q: 0.000976
 1974/10000: episode: 257, duration: 0.061s, episode steps: 4, steps per second: 66, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000416, mae: 0.012286, mean_q: 0.014827
 1976/10000: episode: 258, duration: 0.040s, episode steps: 2, steps per second: 50, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000195, mae: 0.011866, mean_q: 0.010255
 1978/10000: episode: 259, duration: 0.031s, episode steps: 2, steps per second: 64, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000994, mae: 0.019674, mean_q: 0.008384
 1980/10000: episode: 260, duration: 0.024s, episode steps: 2, steps per second: 84, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000431, mae: 0.020872, mean_q: 0.029718
 1982/10000: episode: 261, duration: 0.033s, episode steps: 2, steps per second: 61, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000318, mae: 0.015301, mean_q: 0.011330
 1984/10000: episode: 262, duration: 0.029s, episode steps: 2, steps per second: 69, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000589, mae: 0.023475, mean_q: -0.005410
 1986/10000: episode: 263, duration: 0.034s, episode steps: 2, steps per second: 58, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001327, mae: 0.035447, mean_q: 0.040333
 1988/10000: episode: 264, duration: 0.032s, episode steps: 2, steps per second: 63, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000202, mae: 0.016271, mean_q: -0.007198
 1990/10000: episode: 265, duration: 0.024s, episode steps: 2, steps per second: 82, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000427, mae: 0.020310, mean_q: -0.005326
 1992/10000: episode: 266, duration: 0.037s, episode steps: 2, steps per second: 55, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000513, mae: 0.025586, mean_q: 0.035422
[Info] FALSIFICATION!
 1995/10000: episode: 267, duration: 0.300s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000217, mae: 0.014424, mean_q: 0.001016
 1997/10000: episode: 268, duration: 0.022s, episode steps: 2, steps per second: 89, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.007647, mae: 0.038867, mean_q: 0.022931
 1999/10000: episode: 269, duration: 0.022s, episode steps: 2, steps per second: 92, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001686, mae: 0.045435, mean_q: 0.055903
 2003/10000: episode: 270, duration: 0.042s, episode steps: 4, steps per second: 95, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001278, mae: 0.031760, mean_q: -0.008360
 2005/10000: episode: 271, duration: 0.025s, episode steps: 2, steps per second: 81, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000447, mae: 0.017548, mean_q: 0.025354
 2009/10000: episode: 272, duration: 0.041s, episode steps: 4, steps per second: 99, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000480, mae: 0.023476, mean_q: -0.006542
 2011/10000: episode: 273, duration: 0.022s, episode steps: 2, steps per second: 90, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001642, mae: 0.030098, mean_q: 0.015053
 2013/10000: episode: 274, duration: 0.024s, episode steps: 2, steps per second: 83, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001028, mae: 0.035435, mean_q: 0.046077
 2015/10000: episode: 275, duration: 0.028s, episode steps: 2, steps per second: 72, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001432, mae: 0.036714, mean_q: -0.014874
 2017/10000: episode: 276, duration: 0.022s, episode steps: 2, steps per second: 92, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000322, mae: 0.015834, mean_q: 0.007547
 2019/10000: episode: 277, duration: 0.024s, episode steps: 2, steps per second: 83, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001078, mae: 0.027307, mean_q: 0.034539
 2021/10000: episode: 278, duration: 0.018s, episode steps: 2, steps per second: 114, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000895, mae: 0.017029, mean_q: 0.018342
 2023/10000: episode: 279, duration: 0.018s, episode steps: 2, steps per second: 113, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001237, mae: 0.028219, mean_q: -0.002446
 2025/10000: episode: 280, duration: 0.017s, episode steps: 2, steps per second: 120, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001657, mae: 0.028090, mean_q: 0.029857
 2027/10000: episode: 281, duration: 0.016s, episode steps: 2, steps per second: 122, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000569, mae: 0.016653, mean_q: 0.022390
 2029/10000: episode: 282, duration: 0.018s, episode steps: 2, steps per second: 112, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000391, mae: 0.023669, mean_q: -0.012605
 2031/10000: episode: 283, duration: 0.020s, episode steps: 2, steps per second: 102, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000177, mae: 0.012183, mean_q: 0.015628
 2033/10000: episode: 284, duration: 0.014s, episode steps: 2, steps per second: 139, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000937, mae: 0.024901, mean_q: 0.028925
 2035/10000: episode: 285, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000550, mae: 0.022120, mean_q: -0.007283
 2037/10000: episode: 286, duration: 0.014s, episode steps: 2, steps per second: 139, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000438, mae: 0.015021, mean_q: 0.010311
 2041/10000: episode: 287, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000340, mae: 0.015271, mean_q: 0.021954
 2043/10000: episode: 288, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000357, mae: 0.012638, mean_q: 0.010857
 2047/10000: episode: 289, duration: 0.032s, episode steps: 4, steps per second: 127, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000836, mae: 0.027367, mean_q: 0.039730
 2049/10000: episode: 290, duration: 0.018s, episode steps: 2, steps per second: 111, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001402, mae: 0.035624, mean_q: -0.018134
 2051/10000: episode: 291, duration: 0.018s, episode steps: 2, steps per second: 110, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000811, mae: 0.017673, mean_q: 0.014794
 2055/10000: episode: 292, duration: 0.026s, episode steps: 4, steps per second: 153, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001309, mae: 0.030029, mean_q: 0.030807
 2059/10000: episode: 293, duration: 0.043s, episode steps: 4, steps per second: 93, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002245, mae: 0.033189, mean_q: 0.012165
 2061/10000: episode: 294, duration: 0.025s, episode steps: 2, steps per second: 81, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001075, mae: 0.030920, mean_q: 0.040620
 2063/10000: episode: 295, duration: 0.017s, episode steps: 2, steps per second: 116, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000462, mae: 0.025533, mean_q: -0.012252
 2065/10000: episode: 296, duration: 0.018s, episode steps: 2, steps per second: 110, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000176, mae: 0.014514, mean_q: -0.004623
 2067/10000: episode: 297, duration: 0.017s, episode steps: 2, steps per second: 120, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001488, mae: 0.035301, mean_q: 0.039661
 2069/10000: episode: 298, duration: 0.016s, episode steps: 2, steps per second: 127, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000299, mae: 0.017162, mean_q: 0.003904
 2073/10000: episode: 299, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003227, mae: 0.022232, mean_q: 0.008450
 2075/10000: episode: 300, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001247, mae: 0.039992, mean_q: 0.047248
 2077/10000: episode: 301, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000832, mae: 0.026789, mean_q: 0.003073
 2079/10000: episode: 302, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000338, mae: 0.019442, mean_q: -0.005161
 2081/10000: episode: 303, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006197, mae: 0.028951, mean_q: 0.018350
 2085/10000: episode: 304, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001269, mae: 0.026056, mean_q: 0.029460
 2087/10000: episode: 305, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000269, mae: 0.014768, mean_q: 0.003724
 2089/10000: episode: 306, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001059, mae: 0.024400, mean_q: 0.015997
 2091/10000: episode: 307, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001229, mae: 0.023283, mean_q: 0.023115
 2093/10000: episode: 308, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001097, mae: 0.023163, mean_q: 0.012747
 2095/10000: episode: 309, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000123, mae: 0.010423, mean_q: 0.013007
 2097/10000: episode: 310, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000598, mae: 0.021848, mean_q: 0.026285
 2099/10000: episode: 311, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001082, mae: 0.021897, mean_q: 0.007744
 2101/10000: episode: 312, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000316, mae: 0.016224, mean_q: 0.005103
 2105/10000: episode: 313, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000308, mae: 0.013401, mean_q: 0.018340
 2107/10000: episode: 314, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000269, mae: 0.012639, mean_q: 0.002703
 2109/10000: episode: 315, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000902, mae: 0.014900, mean_q: 0.012258
 2111/10000: episode: 316, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000227, mae: 0.012665, mean_q: 0.015632
 2113/10000: episode: 317, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000528, mae: 0.016300, mean_q: 0.016679
 2117/10000: episode: 318, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.004280, mae: 0.034131, mean_q: 0.030273
 2119/10000: episode: 319, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000514, mae: 0.019371, mean_q: 0.006294
 2121/10000: episode: 320, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000500, mae: 0.025658, mean_q: -0.007823
 2125/10000: episode: 321, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000747, mae: 0.019503, mean_q: 0.014705
 2127/10000: episode: 322, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006061, mae: 0.030243, mean_q: 0.023340
 2131/10000: episode: 323, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000460, mae: 0.018552, mean_q: 0.015181
 2135/10000: episode: 324, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000754, mae: 0.021008, mean_q: 0.009804
 2137/10000: episode: 325, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000670, mae: 0.023838, mean_q: 0.033093
[Info] Complete ISplit Iteration
[Info] Levels: [0.027385706, 0.0578954, 0.14420503]
[Info] Cond. Prob: [0.12, 0.12, 0.02]
[Info] Error Prob: 0.000288

 2141/10000: episode: 326, duration: 0.996s, episode steps: 4, steps per second: 4, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000445, mae: 0.017987, mean_q: -0.001241
 2151/10000: episode: 327, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000996, mae: 0.022099, mean_q: 0.023050
 2161/10000: episode: 328, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001907, mae: 0.021449, mean_q: 0.012472
 2171/10000: episode: 329, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000876, mae: 0.021371, mean_q: 0.018387
 2181/10000: episode: 330, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001020, mae: 0.020299, mean_q: 0.016060
 2191/10000: episode: 331, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000632, mae: 0.018021, mean_q: 0.013401
 2201/10000: episode: 332, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000549, mae: 0.016321, mean_q: 0.014663
 2211/10000: episode: 333, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001611, mae: 0.016682, mean_q: 0.015118
 2221/10000: episode: 334, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.001932, mae: 0.023935, mean_q: 0.022489
 2231/10000: episode: 335, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002702, mae: 0.032429, mean_q: 0.027800
 2241/10000: episode: 336, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000633, mae: 0.024599, mean_q: 0.004688
 2251/10000: episode: 337, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001789, mae: 0.022361, mean_q: 0.011764
 2261/10000: episode: 338, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000939, mae: 0.026706, mean_q: 0.011651
 2271/10000: episode: 339, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000298, mae: 0.015013, mean_q: 0.005737
 2281/10000: episode: 340, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001959, mae: 0.025703, mean_q: 0.023843
 2291/10000: episode: 341, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000408, mae: 0.017707, mean_q: 0.011478
 2301/10000: episode: 342, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000667, mae: 0.019922, mean_q: 0.015356
 2311/10000: episode: 343, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000913, mae: 0.023078, mean_q: 0.017571
 2321/10000: episode: 344, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000449, mae: 0.016184, mean_q: 0.011371
 2331/10000: episode: 345, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000580, mae: 0.017698, mean_q: 0.010594
 2341/10000: episode: 346, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000469, mae: 0.015861, mean_q: 0.008550
 2351/10000: episode: 347, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000757, mae: 0.016676, mean_q: 0.012378
 2361/10000: episode: 348, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001732, mae: 0.020185, mean_q: 0.024820
 2371/10000: episode: 349, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002111, mae: 0.030347, mean_q: 0.017791
 2381/10000: episode: 350, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002824, mae: 0.025499, mean_q: 0.023242
 2391/10000: episode: 351, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000771, mae: 0.028353, mean_q: 0.009407
 2401/10000: episode: 352, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000834, mae: 0.018677, mean_q: 0.013133
 2411/10000: episode: 353, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001862, mae: 0.021735, mean_q: 0.017728
 2421/10000: episode: 354, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000534, mae: 0.014343, mean_q: 0.011871
 2431/10000: episode: 355, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.002208, mae: 0.029228, mean_q: 0.028720
 2441/10000: episode: 356, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001926, mae: 0.029197, mean_q: 0.018786
 2451/10000: episode: 357, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001056, mae: 0.029789, mean_q: 0.015008
 2461/10000: episode: 358, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000972, mae: 0.027269, mean_q: 0.012746
 2471/10000: episode: 359, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000455, mae: 0.015738, mean_q: 0.010461
 2481/10000: episode: 360, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000491, mae: 0.014189, mean_q: 0.013442
 2491/10000: episode: 361, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000185, mae: 0.013261, mean_q: 0.005429
 2501/10000: episode: 362, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000226, mae: 0.012008, mean_q: 0.008868
 2511/10000: episode: 363, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000896, mae: 0.018079, mean_q: 0.019122
 2521/10000: episode: 364, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000368, mae: 0.016117, mean_q: 0.010009
 2531/10000: episode: 365, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000484, mae: 0.013353, mean_q: 0.009366
 2541/10000: episode: 366, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000209, mae: 0.011964, mean_q: 0.012729
 2551/10000: episode: 367, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000336, mae: 0.012853, mean_q: 0.010019
 2561/10000: episode: 368, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000407, mae: 0.012326, mean_q: 0.012958
 2571/10000: episode: 369, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001704, mae: 0.018193, mean_q: 0.012289
 2581/10000: episode: 370, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000618, mae: 0.024152, mean_q: 0.010995
 2591/10000: episode: 371, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000615, mae: 0.019976, mean_q: 0.016151
 2601/10000: episode: 372, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001665, mae: 0.024640, mean_q: 0.017489
 2611/10000: episode: 373, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000428, mae: 0.014975, mean_q: 0.010235
 2621/10000: episode: 374, duration: 0.112s, episode steps: 10, steps per second: 89, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000635, mae: 0.017379, mean_q: 0.009581
 2631/10000: episode: 375, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000732, mae: 0.023168, mean_q: 0.006297
 2641/10000: episode: 376, duration: 0.109s, episode steps: 10, steps per second: 92, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001531, mae: 0.022225, mean_q: 0.021124
 2651/10000: episode: 377, duration: 0.123s, episode steps: 10, steps per second: 81, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000370, mae: 0.012265, mean_q: 0.009591
 2661/10000: episode: 378, duration: 0.112s, episode steps: 10, steps per second: 89, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000591, mae: 0.016415, mean_q: 0.011053
 2671/10000: episode: 379, duration: 0.094s, episode steps: 10, steps per second: 106, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001294, mae: 0.013591, mean_q: 0.013206
 2681/10000: episode: 380, duration: 0.118s, episode steps: 10, steps per second: 85, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000306, mae: 0.011501, mean_q: 0.009617
 2691/10000: episode: 381, duration: 0.108s, episode steps: 10, steps per second: 92, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000549, mae: 0.015038, mean_q: 0.015033
 2701/10000: episode: 382, duration: 0.106s, episode steps: 10, steps per second: 94, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000976, mae: 0.018922, mean_q: 0.016209
 2711/10000: episode: 383, duration: 0.085s, episode steps: 10, steps per second: 117, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000686, mae: 0.017237, mean_q: 0.013183
 2721/10000: episode: 384, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001743, mae: 0.020267, mean_q: 0.014996
 2731/10000: episode: 385, duration: 0.085s, episode steps: 10, steps per second: 117, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000584, mae: 0.018017, mean_q: 0.011512
 2741/10000: episode: 386, duration: 0.094s, episode steps: 10, steps per second: 106, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000447, mae: 0.012954, mean_q: 0.009200
 2751/10000: episode: 387, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000366, mae: 0.010914, mean_q: 0.010378
 2761/10000: episode: 388, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001575, mae: 0.019492, mean_q: 0.020178
 2771/10000: episode: 389, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000853, mae: 0.023718, mean_q: 0.015175
 2781/10000: episode: 390, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.003224, mae: 0.029778, mean_q: 0.023381
 2791/10000: episode: 391, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000906, mae: 0.026000, mean_q: 0.007450
 2801/10000: episode: 392, duration: 0.072s, episode steps: 10, steps per second: 138, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000631, mae: 0.019190, mean_q: 0.011473
 2811/10000: episode: 393, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000314, mae: 0.015055, mean_q: 0.015169
 2821/10000: episode: 394, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000381, mae: 0.013133, mean_q: 0.012384
 2831/10000: episode: 395, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001488, mae: 0.017508, mean_q: 0.014929
 2841/10000: episode: 396, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000591, mae: 0.015305, mean_q: 0.010363
 2851/10000: episode: 397, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000396, mae: 0.012815, mean_q: 0.009731
 2861/10000: episode: 398, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001205, mae: 0.015682, mean_q: 0.017427
 2871/10000: episode: 399, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000387, mae: 0.012601, mean_q: 0.010992
 2881/10000: episode: 400, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001567, mae: 0.020650, mean_q: 0.012215
 2891/10000: episode: 401, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000451, mae: 0.019323, mean_q: 0.004100
 2901/10000: episode: 402, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000187, mae: 0.013543, mean_q: 0.004136
 2911/10000: episode: 403, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000627, mae: 0.019471, mean_q: 0.015621
 2921/10000: episode: 404, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000456, mae: 0.016926, mean_q: 0.015751
 2931/10000: episode: 405, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000298, mae: 0.015784, mean_q: 0.011678
 2941/10000: episode: 406, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000499, mae: 0.011746, mean_q: 0.008668
 2951/10000: episode: 407, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000310, mae: 0.010560, mean_q: 0.008200
 2961/10000: episode: 408, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001500, mae: 0.015728, mean_q: 0.014150
 2971/10000: episode: 409, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000691, mae: 0.016055, mean_q: 0.015745
 2981/10000: episode: 410, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001563, mae: 0.016278, mean_q: 0.017550
 2991/10000: episode: 411, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001512, mae: 0.019656, mean_q: 0.016458
 3001/10000: episode: 412, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000529, mae: 0.016097, mean_q: 0.016027
 3011/10000: episode: 413, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000663, mae: 0.017236, mean_q: 0.007050
 3021/10000: episode: 414, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001602, mae: 0.018549, mean_q: 0.020661
 3031/10000: episode: 415, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000381, mae: 0.015636, mean_q: 0.007810
 3041/10000: episode: 416, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000530, mae: 0.017169, mean_q: 0.005552
 3051/10000: episode: 417, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000627, mae: 0.023342, mean_q: 0.012733
 3061/10000: episode: 418, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000416, mae: 0.013365, mean_q: 0.012479
 3071/10000: episode: 419, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000582, mae: 0.016625, mean_q: 0.019233
 3081/10000: episode: 420, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000367, mae: 0.012491, mean_q: 0.011043
 3091/10000: episode: 421, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000183, mae: 0.010369, mean_q: 0.008136
 3101/10000: episode: 422, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000516, mae: 0.011668, mean_q: 0.010731
 3111/10000: episode: 423, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001235, mae: 0.017252, mean_q: 0.013786
 3121/10000: episode: 424, duration: 0.055s, episode steps: 10, steps per second: 180, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000456, mae: 0.014854, mean_q: 0.010932
 3131/10000: episode: 425, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000663, mae: 0.015723, mean_q: 0.013294
[Info] 1-TH LEVEL FOUND: 0.015160750597715378, Considering 13/100 traces
 3141/10000: episode: 426, duration: 0.708s, episode steps: 10, steps per second: 14, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001250, mae: 0.015890, mean_q: 0.015853
 3149/10000: episode: 427, duration: 0.040s, episode steps: 8, steps per second: 201, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000650, mae: 0.018943, mean_q: 0.012428
 3157/10000: episode: 428, duration: 0.043s, episode steps: 8, steps per second: 187, episode reward: 0.036, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000263, mae: 0.011167, mean_q: 0.007188
 3165/10000: episode: 429, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.038, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000296, mae: 0.012929, mean_q: 0.009817
 3173/10000: episode: 430, duration: 0.037s, episode steps: 8, steps per second: 218, episode reward: 0.055, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001364, mae: 0.017005, mean_q: 0.019877
 3181/10000: episode: 431, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000295, mae: 0.013646, mean_q: 0.004560
 3189/10000: episode: 432, duration: 0.037s, episode steps: 8, steps per second: 213, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000355, mae: 0.011735, mean_q: 0.012972
 3193/10000: episode: 433, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000286, mae: 0.011210, mean_q: 0.002108
 3201/10000: episode: 434, duration: 0.041s, episode steps: 8, steps per second: 193, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.001363, mae: 0.013173, mean_q: 0.016533
 3209/10000: episode: 435, duration: 0.037s, episode steps: 8, steps per second: 216, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000191, mae: 0.012130, mean_q: 0.005200
 3217/10000: episode: 436, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.023, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000469, mae: 0.012804, mean_q: 0.013834
 3225/10000: episode: 437, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.812 [-1.000, 11.000], loss: 0.000293, mae: 0.008993, mean_q: 0.007822
 3233/10000: episode: 438, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.071, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000134, mae: 0.007907, mean_q: 0.006968
 3241/10000: episode: 439, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.044, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000167, mae: 0.010313, mean_q: 0.003902
 3249/10000: episode: 440, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.087, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000137, mae: 0.011044, mean_q: 0.013836
 3257/10000: episode: 441, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.215, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000103, mae: 0.009199, mean_q: 0.008046
 3261/10000: episode: 442, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000193, mae: 0.008057, mean_q: 0.005121
 3269/10000: episode: 443, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.130, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.002513, mae: 0.019155, mean_q: 0.018784
 3277/10000: episode: 444, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000668, mae: 0.021975, mean_q: 0.009567
 3285/10000: episode: 445, duration: 0.041s, episode steps: 8, steps per second: 193, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000428, mae: 0.015295, mean_q: 0.015110
 3293/10000: episode: 446, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.087, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000456, mae: 0.013389, mean_q: 0.014019
 3297/10000: episode: 447, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000107, mae: 0.008488, mean_q: 0.007979
 3305/10000: episode: 448, duration: 0.037s, episode steps: 8, steps per second: 213, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000093, mae: 0.006741, mean_q: 0.007743
 3309/10000: episode: 449, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000333, mae: 0.016037, mean_q: 0.019819
 3313/10000: episode: 450, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000196, mae: 0.012019, mean_q: 0.002533
 3321/10000: episode: 451, duration: 0.037s, episode steps: 8, steps per second: 213, episode reward: 0.032, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000308, mae: 0.013797, mean_q: 0.012877
 3329/10000: episode: 452, duration: 0.042s, episode steps: 8, steps per second: 193, episode reward: 0.022, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000232, mae: 0.012116, mean_q: 0.006190
 3337/10000: episode: 453, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.082, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000457, mae: 0.011507, mean_q: 0.011423
 3345/10000: episode: 454, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.130, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000197, mae: 0.010793, mean_q: 0.004334
 3353/10000: episode: 455, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.001537, mae: 0.016747, mean_q: 0.019711
 3361/10000: episode: 456, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.097, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.001570, mae: 0.018807, mean_q: 0.017362
 3365/10000: episode: 457, duration: 0.027s, episode steps: 4, steps per second: 151, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000401, mae: 0.019674, mean_q: 0.005204
 3373/10000: episode: 458, duration: 0.040s, episode steps: 8, steps per second: 199, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000224, mae: 0.011887, mean_q: 0.010657
 3381/10000: episode: 459, duration: 0.040s, episode steps: 8, steps per second: 202, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000504, mae: 0.013861, mean_q: 0.013495
 3389/10000: episode: 460, duration: 0.045s, episode steps: 8, steps per second: 178, episode reward: 0.032, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000603, mae: 0.015282, mean_q: 0.014724
 3397/10000: episode: 461, duration: 0.041s, episode steps: 8, steps per second: 197, episode reward: 0.102, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000340, mae: 0.011314, mean_q: 0.010977
 3401/10000: episode: 462, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000226, mae: 0.012572, mean_q: -0.000005
 3409/10000: episode: 463, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.039, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000194, mae: 0.011593, mean_q: 0.011446
 3417/10000: episode: 464, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.022, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000185, mae: 0.010870, mean_q: 0.008836
 3425/10000: episode: 465, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.215, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000431, mae: 0.010281, mean_q: 0.010444
 3429/10000: episode: 466, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000461, mae: 0.010055, mean_q: 0.008050
 3437/10000: episode: 467, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000294, mae: 0.014383, mean_q: 0.011398
 3441/10000: episode: 468, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000405, mae: 0.016429, mean_q: 0.011184
 3449/10000: episode: 469, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.055, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000481, mae: 0.013842, mean_q: 0.010815
 3453/10000: episode: 470, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000156, mae: 0.011266, mean_q: 0.014726
 3461/10000: episode: 471, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.038, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000297, mae: 0.012566, mean_q: 0.016636
 3469/10000: episode: 472, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.023, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.001438, mae: 0.022864, mean_q: 0.009920
 3477/10000: episode: 473, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000492, mae: 0.022828, mean_q: -0.000923
 3485/10000: episode: 474, duration: 0.042s, episode steps: 8, steps per second: 190, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.002762, mae: 0.029939, mean_q: 0.032029
 3493/10000: episode: 475, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.036, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000499, mae: 0.016295, mean_q: 0.011653
 3501/10000: episode: 476, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.085, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000204, mae: 0.010855, mean_q: 0.008807
 3509/10000: episode: 477, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.051, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000607, mae: 0.012831, mean_q: 0.012013
 3517/10000: episode: 478, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.875 [-1.000, 11.000], loss: 0.000833, mae: 0.024610, mean_q: 0.014346
 3525/10000: episode: 479, duration: 0.037s, episode steps: 8, steps per second: 216, episode reward: 0.214, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000573, mae: 0.015929, mean_q: 0.019331
 3533/10000: episode: 480, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000348, mae: 0.015240, mean_q: 0.010544
 3541/10000: episode: 481, duration: 0.040s, episode steps: 8, steps per second: 202, episode reward: 0.035, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000140, mae: 0.009128, mean_q: 0.011045
 3545/10000: episode: 482, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000365, mae: 0.013578, mean_q: 0.015715
 3553/10000: episode: 483, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.059, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000327, mae: 0.011807, mean_q: 0.011599
 3561/10000: episode: 484, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.214, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000586, mae: 0.013208, mean_q: 0.017305
 3569/10000: episode: 485, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000483, mae: 0.012115, mean_q: 0.012519
 3577/10000: episode: 486, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000545, mae: 0.015763, mean_q: 0.010481
 3585/10000: episode: 487, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000544, mae: 0.015874, mean_q: 0.012757
 3589/10000: episode: 488, duration: 0.031s, episode steps: 4, steps per second: 128, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000211, mae: 0.010320, mean_q: 0.016243
 3597/10000: episode: 489, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.079, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000715, mae: 0.015417, mean_q: 0.015986
 3605/10000: episode: 490, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.146, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000518, mae: 0.013458, mean_q: 0.010794
 3613/10000: episode: 491, duration: 0.041s, episode steps: 8, steps per second: 193, episode reward: 0.231, mean reward: 0.029 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.000350, mae: 0.009883, mean_q: 0.006884
 3621/10000: episode: 492, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.114, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000246, mae: 0.011185, mean_q: 0.009792
 3629/10000: episode: 493, duration: 0.044s, episode steps: 8, steps per second: 182, episode reward: 0.032, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000462, mae: 0.015395, mean_q: 0.017571
 3637/10000: episode: 494, duration: 0.051s, episode steps: 8, steps per second: 158, episode reward: 0.348, mean reward: 0.044 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001413, mae: 0.019396, mean_q: 0.015343
 3641/10000: episode: 495, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000751, mae: 0.024210, mean_q: 0.031905
 3649/10000: episode: 496, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000428, mae: 0.019564, mean_q: 0.003449
 3657/10000: episode: 497, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.059, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.001527, mae: 0.018126, mean_q: 0.017278
 3661/10000: episode: 498, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000171, mae: 0.013125, mean_q: 0.002252
 3669/10000: episode: 499, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000470, mae: 0.014968, mean_q: 0.013643
 3677/10000: episode: 500, duration: 0.043s, episode steps: 8, steps per second: 186, episode reward: 0.215, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000203, mae: 0.009733, mean_q: 0.011978
 3685/10000: episode: 501, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.013, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000253, mae: 0.010505, mean_q: 0.011155
 3693/10000: episode: 502, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.875 [-1.000, 11.000], loss: 0.000483, mae: 0.014905, mean_q: 0.012660
 3701/10000: episode: 503, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000568, mae: 0.013042, mean_q: 0.015117
 3709/10000: episode: 504, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.215, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000372, mae: 0.013257, mean_q: 0.010953
 3717/10000: episode: 505, duration: 0.040s, episode steps: 8, steps per second: 200, episode reward: 0.036, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000627, mae: 0.013614, mean_q: 0.010842
 3725/10000: episode: 506, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.038, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001325, mae: 0.020034, mean_q: 0.017616
 3729/10000: episode: 507, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000293, mae: 0.014713, mean_q: 0.004511
 3737/10000: episode: 508, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.812 [-1.000, 11.000], loss: 0.001594, mae: 0.016361, mean_q: 0.014078
 3745/10000: episode: 509, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000473, mae: 0.021359, mean_q: 0.013863
 3753/10000: episode: 510, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000461, mae: 0.015108, mean_q: 0.017044
 3761/10000: episode: 511, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.044, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000362, mae: 0.012877, mean_q: 0.010839
 3769/10000: episode: 512, duration: 0.037s, episode steps: 8, steps per second: 213, episode reward: 0.015, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000520, mae: 0.014114, mean_q: 0.012007
[Info] 2-TH LEVEL FOUND: 0.051190927624702454, Considering 23/100 traces
 3777/10000: episode: 513, duration: 0.760s, episode steps: 8, steps per second: 11, episode reward: 0.023, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000198, mae: 0.009629, mean_q: 0.010441
[Info] FALSIFICATION!
 3781/10000: episode: 514, duration: 0.265s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000352, mae: 0.012333, mean_q: 0.011145
 3786/10000: episode: 515, duration: 0.032s, episode steps: 5, steps per second: 156, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000247, mae: 0.011348, mean_q: 0.016717
 3788/10000: episode: 516, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000599, mae: 0.020280, mean_q: 0.014322
 3793/10000: episode: 517, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000242, mae: 0.011379, mean_q: 0.014983
 3795/10000: episode: 518, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000181, mae: 0.009993, mean_q: 0.005667
 3797/10000: episode: 519, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000187, mae: 0.010994, mean_q: 0.005270
 3799/10000: episode: 520, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000144, mae: 0.008399, mean_q: 0.011550
 3804/10000: episode: 521, duration: 0.024s, episode steps: 5, steps per second: 204, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000488, mae: 0.011918, mean_q: 0.014091
 3806/10000: episode: 522, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000188, mae: 0.009794, mean_q: 0.015113
 3811/10000: episode: 523, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000633, mae: 0.015969, mean_q: 0.018153
 3813/10000: episode: 524, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000744, mae: 0.014867, mean_q: 0.017150
 3818/10000: episode: 525, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000668, mae: 0.017379, mean_q: 0.021542
 3820/10000: episode: 526, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000198, mae: 0.014533, mean_q: -0.002783
 3822/10000: episode: 527, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000269, mae: 0.011514, mean_q: 0.014594
 3824/10000: episode: 528, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000230, mae: 0.012550, mean_q: 0.013993
 3826/10000: episode: 529, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000186, mae: 0.011802, mean_q: 0.012446
[Info] FALSIFICATION!
 3830/10000: episode: 530, duration: 0.264s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000529, mae: 0.013149, mean_q: 0.010201
 3835/10000: episode: 531, duration: 0.029s, episode steps: 5, steps per second: 170, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000675, mae: 0.015483, mean_q: 0.017141
 3837/10000: episode: 532, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000514, mae: 0.019187, mean_q: 0.027486
 3839/10000: episode: 533, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000428, mae: 0.016966, mean_q: 0.011589
 3841/10000: episode: 534, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000281, mae: 0.011788, mean_q: 0.005905
 3843/10000: episode: 535, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004309, mae: 0.025923, mean_q: 0.017368
 3845/10000: episode: 536, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003926, mae: 0.029530, mean_q: 0.029820
 3847/10000: episode: 537, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000561, mae: 0.017722, mean_q: 0.027415
 3852/10000: episode: 538, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000593, mae: 0.021135, mean_q: 0.000834
 3854/10000: episode: 539, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004101, mae: 0.022905, mean_q: 0.021969
 3856/10000: episode: 540, duration: 0.012s, episode steps: 2, steps per second: 167, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000467, mae: 0.020161, mean_q: 0.028490
 3861/10000: episode: 541, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001749, mae: 0.017799, mean_q: 0.005102
 3863/10000: episode: 542, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001001, mae: 0.018342, mean_q: 0.025067
 3865/10000: episode: 543, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000377, mae: 0.010810, mean_q: 0.014578
 3867/10000: episode: 544, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000155, mae: 0.013615, mean_q: -0.001140
 3872/10000: episode: 545, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002078, mae: 0.023059, mean_q: 0.021751
 3874/10000: episode: 546, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000865, mae: 0.025214, mean_q: 0.035180
 3876/10000: episode: 547, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000747, mae: 0.018623, mean_q: 0.009928
 3878/10000: episode: 548, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003669, mae: 0.027036, mean_q: 0.003954
 3880/10000: episode: 549, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000876, mae: 0.022443, mean_q: 0.034883
 3882/10000: episode: 550, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000874, mae: 0.023432, mean_q: 0.011731
 3884/10000: episode: 551, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000630, mae: 0.028340, mean_q: -0.004608
 3886/10000: episode: 552, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000412, mae: 0.017671, mean_q: 0.006472
 3888/10000: episode: 553, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000443, mae: 0.019729, mean_q: 0.017994
 3893/10000: episode: 554, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000268, mae: 0.014889, mean_q: 0.001096
 3898/10000: episode: 555, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.004607, mae: 0.041105, mean_q: 0.041836
 3900/10000: episode: 556, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000664, mae: 0.023036, mean_q: 0.019976
 3902/10000: episode: 557, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000752, mae: 0.025929, mean_q: -0.003338
 3904/10000: episode: 558, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001134, mae: 0.026509, mean_q: 0.005429
 3906/10000: episode: 559, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001371, mae: 0.029741, mean_q: 0.037226
 3908/10000: episode: 560, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000375, mae: 0.019107, mean_q: 0.020596
 3910/10000: episode: 561, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000449, mae: 0.021413, mean_q: -0.006594
 3912/10000: episode: 562, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001082, mae: 0.018829, mean_q: 0.012110
 3914/10000: episode: 563, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004540, mae: 0.039821, mean_q: 0.043892
 3916/10000: episode: 564, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000263, mae: 0.015383, mean_q: 0.018166
 3918/10000: episode: 565, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000610, mae: 0.024307, mean_q: -0.001521
 3920/10000: episode: 566, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000312, mae: 0.015361, mean_q: 0.010992
 3922/10000: episode: 567, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000908, mae: 0.027751, mean_q: 0.035730
 3924/10000: episode: 568, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000941, mae: 0.025446, mean_q: 0.031284
 3926/10000: episode: 569, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000450, mae: 0.023558, mean_q: -0.006673
 3928/10000: episode: 570, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004298, mae: 0.031986, mean_q: -0.007782
 3933/10000: episode: 571, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000778, mae: 0.027556, mean_q: 0.042610
 3935/10000: episode: 572, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000698, mae: 0.030773, mean_q: -0.008852
 3937/10000: episode: 573, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000440, mae: 0.023000, mean_q: -0.005369
 3942/10000: episode: 574, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000431, mae: 0.019649, mean_q: 0.028894
 3944/10000: episode: 575, duration: 0.016s, episode steps: 2, steps per second: 128, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000179, mae: 0.013063, mean_q: -0.005424
 3946/10000: episode: 576, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000160, mae: 0.011430, mean_q: 0.003593
 3948/10000: episode: 577, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000683, mae: 0.026823, mean_q: 0.034167
 3950/10000: episode: 578, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001323, mae: 0.026148, mean_q: 0.030848
 3955/10000: episode: 579, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002114, mae: 0.019178, mean_q: 0.009659
 3960/10000: episode: 580, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001890, mae: 0.020217, mean_q: 0.025447
 3965/10000: episode: 581, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000384, mae: 0.016892, mean_q: 0.001163
 3970/10000: episode: 582, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001004, mae: 0.023068, mean_q: 0.025942
 3972/10000: episode: 583, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000461, mae: 0.017360, mean_q: 0.008708
 3974/10000: episode: 584, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000657, mae: 0.016309, mean_q: 0.016022
 3979/10000: episode: 585, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000366, mae: 0.014231, mean_q: 0.022175
 3981/10000: episode: 586, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000494, mae: 0.019471, mean_q: 0.005942
 3983/10000: episode: 587, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000847, mae: 0.014982, mean_q: 0.013002
 3988/10000: episode: 588, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000970, mae: 0.028921, mean_q: 0.035521
 3990/10000: episode: 589, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.007175, mae: 0.041063, mean_q: -0.008042
[Info] Complete ISplit Iteration
[Info] Levels: [0.015160751, 0.051190928, 0.46377409]
[Info] Cond. Prob: [0.13, 0.23, 0.02]
[Info] Error Prob: 0.0005980000000000001

 3992/10000: episode: 590, duration: 0.783s, episode steps: 2, steps per second: 3, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000721, mae: 0.018221, mean_q: 0.026447
 4002/10000: episode: 591, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000641, mae: 0.016788, mean_q: 0.015539
 4012/10000: episode: 592, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000580, mae: 0.016652, mean_q: 0.016878
 4022/10000: episode: 593, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000427, mae: 0.017018, mean_q: 0.009268
 4032/10000: episode: 594, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000398, mae: 0.012251, mean_q: 0.012936
 4042/10000: episode: 595, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000388, mae: 0.014761, mean_q: 0.011618
 4052/10000: episode: 596, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000433, mae: 0.015400, mean_q: 0.013119
 4062/10000: episode: 597, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000607, mae: 0.015490, mean_q: 0.014824
 4072/10000: episode: 598, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002779, mae: 0.031599, mean_q: 0.019438
 4082/10000: episode: 599, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000591, mae: 0.021959, mean_q: 0.012654
 4092/10000: episode: 600, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001299, mae: 0.021866, mean_q: 0.021045
 4102/10000: episode: 601, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000793, mae: 0.024327, mean_q: 0.020492
 4112/10000: episode: 602, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.000635, mae: 0.017661, mean_q: 0.016340
 4122/10000: episode: 603, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000604, mae: 0.017059, mean_q: 0.017701
 4132/10000: episode: 604, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000523, mae: 0.014827, mean_q: 0.016776
 4142/10000: episode: 605, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002153, mae: 0.024227, mean_q: 0.023742
 4152/10000: episode: 606, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000791, mae: 0.025138, mean_q: 0.012504
 4162/10000: episode: 607, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000653, mae: 0.021003, mean_q: 0.015585
 4172/10000: episode: 608, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000234, mae: 0.014444, mean_q: 0.011312
 4182/10000: episode: 609, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001395, mae: 0.022550, mean_q: 0.023204
 4192/10000: episode: 610, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000573, mae: 0.017348, mean_q: 0.017031
 4202/10000: episode: 611, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000354, mae: 0.012010, mean_q: 0.011387
 4212/10000: episode: 612, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000317, mae: 0.012316, mean_q: 0.012370
 4222/10000: episode: 613, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000286, mae: 0.014866, mean_q: 0.004625
 4232/10000: episode: 614, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000604, mae: 0.016981, mean_q: 0.015468
 4242/10000: episode: 615, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000698, mae: 0.017718, mean_q: 0.019383
 4252/10000: episode: 616, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000439, mae: 0.013798, mean_q: 0.012509
 4262/10000: episode: 617, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000373, mae: 0.013686, mean_q: 0.011414
 4272/10000: episode: 618, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000545, mae: 0.014042, mean_q: 0.015127
 4282/10000: episode: 619, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000428, mae: 0.015605, mean_q: 0.010699
 4292/10000: episode: 620, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000420, mae: 0.013469, mean_q: 0.012892
 4302/10000: episode: 621, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001212, mae: 0.017864, mean_q: 0.015999
 4312/10000: episode: 622, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000764, mae: 0.021939, mean_q: 0.013703
 4322/10000: episode: 623, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001116, mae: 0.019413, mean_q: 0.010862
 4332/10000: episode: 624, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000337, mae: 0.011678, mean_q: 0.012003
 4342/10000: episode: 625, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000710, mae: 0.017171, mean_q: 0.023716
 4352/10000: episode: 626, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000391, mae: 0.018521, mean_q: 0.007176
 4362/10000: episode: 627, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002806, mae: 0.025064, mean_q: 0.020457
 4372/10000: episode: 628, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001915, mae: 0.027867, mean_q: 0.012362
 4382/10000: episode: 629, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000919, mae: 0.029748, mean_q: 0.000848
 4392/10000: episode: 630, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000447, mae: 0.021495, mean_q: 0.009068
 4402/10000: episode: 631, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001176, mae: 0.020805, mean_q: 0.021198
 4412/10000: episode: 632, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000561, mae: 0.016722, mean_q: 0.018253
 4422/10000: episode: 633, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001461, mae: 0.020670, mean_q: 0.022023
 4432/10000: episode: 634, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001547, mae: 0.018742, mean_q: 0.006853
 4442/10000: episode: 635, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.001754, mae: 0.021582, mean_q: 0.019567
 4452/10000: episode: 636, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000604, mae: 0.014891, mean_q: 0.010466
 4462/10000: episode: 637, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001180, mae: 0.018220, mean_q: 0.014601
 4472/10000: episode: 638, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000601, mae: 0.016353, mean_q: 0.019206
 4482/10000: episode: 639, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000652, mae: 0.020008, mean_q: 0.017309
 4492/10000: episode: 640, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000449, mae: 0.017139, mean_q: 0.014755
 4502/10000: episode: 641, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000452, mae: 0.013087, mean_q: 0.013079
 4512/10000: episode: 642, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000361, mae: 0.012600, mean_q: 0.011386
 4522/10000: episode: 643, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000593, mae: 0.013239, mean_q: 0.015329
 4532/10000: episode: 644, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000453, mae: 0.013232, mean_q: 0.015173
 4542/10000: episode: 645, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000308, mae: 0.012910, mean_q: 0.009237
 4552/10000: episode: 646, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000457, mae: 0.014636, mean_q: 0.014527
 4562/10000: episode: 647, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001934, mae: 0.027657, mean_q: 0.023501
 4572/10000: episode: 648, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000421, mae: 0.018645, mean_q: 0.011569
 4582/10000: episode: 649, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000778, mae: 0.016555, mean_q: 0.014776
 4592/10000: episode: 650, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000298, mae: 0.014516, mean_q: 0.010233
 4602/10000: episode: 651, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000472, mae: 0.015511, mean_q: 0.013695
 4612/10000: episode: 652, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000321, mae: 0.012341, mean_q: 0.011353
 4622/10000: episode: 653, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000645, mae: 0.016640, mean_q: 0.020062
 4632/10000: episode: 654, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000230, mae: 0.010328, mean_q: 0.013139
 4642/10000: episode: 655, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000396, mae: 0.013623, mean_q: 0.016903
 4652/10000: episode: 656, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001696, mae: 0.016694, mean_q: 0.009110
 4662/10000: episode: 657, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000706, mae: 0.026795, mean_q: 0.008895
 4672/10000: episode: 658, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000599, mae: 0.019231, mean_q: 0.016095
 4682/10000: episode: 659, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000341, mae: 0.016032, mean_q: 0.014852
 4692/10000: episode: 660, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000314, mae: 0.011924, mean_q: 0.011408
 4702/10000: episode: 661, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000662, mae: 0.017423, mean_q: 0.020706
 4712/10000: episode: 662, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000597, mae: 0.017658, mean_q: 0.016246
 4722/10000: episode: 663, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000524, mae: 0.016772, mean_q: 0.012527
 4732/10000: episode: 664, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000443, mae: 0.013426, mean_q: 0.012025
 4742/10000: episode: 665, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000249, mae: 0.010891, mean_q: 0.006452
 4752/10000: episode: 666, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000248, mae: 0.010574, mean_q: 0.011206
 4762/10000: episode: 667, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000466, mae: 0.012213, mean_q: 0.013900
 4772/10000: episode: 668, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000439, mae: 0.011571, mean_q: 0.014707
 4782/10000: episode: 669, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000347, mae: 0.011333, mean_q: 0.014288
 4792/10000: episode: 670, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000472, mae: 0.014679, mean_q: 0.010313
 4802/10000: episode: 671, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000911, mae: 0.014006, mean_q: 0.012655
 4812/10000: episode: 672, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000432, mae: 0.017779, mean_q: 0.019452
 4822/10000: episode: 673, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000494, mae: 0.015471, mean_q: 0.015076
 4832/10000: episode: 674, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001721, mae: 0.020108, mean_q: 0.013345
 4842/10000: episode: 675, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000621, mae: 0.015239, mean_q: 0.015404
 4852/10000: episode: 676, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000960, mae: 0.012529, mean_q: 0.010314
 4862/10000: episode: 677, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000471, mae: 0.016511, mean_q: 0.008337
 4872/10000: episode: 678, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000402, mae: 0.013269, mean_q: 0.017868
 4882/10000: episode: 679, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001585, mae: 0.015082, mean_q: 0.016100
 4892/10000: episode: 680, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000601, mae: 0.016054, mean_q: 0.014172
 4902/10000: episode: 681, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000379, mae: 0.014720, mean_q: 0.009339
 4912/10000: episode: 682, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000581, mae: 0.020092, mean_q: 0.021045
 4922/10000: episode: 683, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000375, mae: 0.012650, mean_q: 0.011480
 4932/10000: episode: 684, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000303, mae: 0.012920, mean_q: 0.015850
 4942/10000: episode: 685, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000217, mae: 0.011077, mean_q: 0.008452
 4952/10000: episode: 686, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000612, mae: 0.016416, mean_q: 0.017276
 4962/10000: episode: 687, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001170, mae: 0.020569, mean_q: 0.016195
 4972/10000: episode: 688, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000461, mae: 0.014110, mean_q: 0.005633
 4982/10000: episode: 689, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000503, mae: 0.017314, mean_q: 0.014451
[Info] 1-TH LEVEL FOUND: 0.01797499507665634, Considering 11/100 traces
 4992/10000: episode: 690, duration: 0.674s, episode steps: 10, steps per second: 15, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000453, mae: 0.019713, mean_q: 0.017709
 4996/10000: episode: 691, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000453, mae: 0.014480, mean_q: 0.010690
 5003/10000: episode: 692, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000820, mae: 0.023447, mean_q: 0.014363
 5007/10000: episode: 693, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000776, mae: 0.021728, mean_q: 0.017498
 5011/10000: episode: 694, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003066, mae: 0.024396, mean_q: 0.020852
 5018/10000: episode: 695, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000588, mae: 0.017938, mean_q: 0.022897
 5025/10000: episode: 696, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000363, mae: 0.013940, mean_q: 0.010716
 5029/10000: episode: 697, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000164, mae: 0.011422, mean_q: 0.007319
 5036/10000: episode: 698, duration: 0.061s, episode steps: 7, steps per second: 115, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000480, mae: 0.014831, mean_q: 0.016603
 5040/10000: episode: 699, duration: 0.031s, episode steps: 4, steps per second: 131, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002043, mae: 0.018666, mean_q: 0.021936
 5044/10000: episode: 700, duration: 0.029s, episode steps: 4, steps per second: 138, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000253, mae: 0.010796, mean_q: 0.007805
 5051/10000: episode: 701, duration: 0.048s, episode steps: 7, steps per second: 146, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001340, mae: 0.019256, mean_q: 0.022417
 5055/10000: episode: 702, duration: 0.039s, episode steps: 4, steps per second: 103, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000324, mae: 0.011819, mean_q: 0.018745
 5062/10000: episode: 703, duration: 0.046s, episode steps: 7, steps per second: 151, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002089, mae: 0.019442, mean_q: 0.024075
 5069/10000: episode: 704, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000599, mae: 0.022914, mean_q: 0.000085
 5076/10000: episode: 705, duration: 0.037s, episode steps: 7, steps per second: 189, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000429, mae: 0.020283, mean_q: 0.031143
 5083/10000: episode: 706, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000328, mae: 0.019242, mean_q: -0.002725
 5090/10000: episode: 707, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000309, mae: 0.017844, mean_q: 0.021877
 5097/10000: episode: 708, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000494, mae: 0.017865, mean_q: 0.015908
 5101/10000: episode: 709, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000324, mae: 0.017662, mean_q: 0.003860
 5105/10000: episode: 710, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000585, mae: 0.014936, mean_q: 0.004295
 5109/10000: episode: 711, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001859, mae: 0.023462, mean_q: 0.029581
 5116/10000: episode: 712, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000315, mae: 0.015153, mean_q: 0.002485
 5120/10000: episode: 713, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000500, mae: 0.016110, mean_q: 0.022080
 5124/10000: episode: 714, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000647, mae: 0.017411, mean_q: 0.003646
 5131/10000: episode: 715, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000512, mae: 0.014942, mean_q: 0.013345
 5138/10000: episode: 716, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000245, mae: 0.012714, mean_q: 0.017012
 5145/10000: episode: 717, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000210, mae: 0.011630, mean_q: 0.007587
 5152/10000: episode: 718, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000236, mae: 0.011475, mean_q: 0.010546
 5159/10000: episode: 719, duration: 0.048s, episode steps: 7, steps per second: 144, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000187, mae: 0.009180, mean_q: 0.011132
 5163/10000: episode: 720, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000897, mae: 0.014232, mean_q: 0.016187
 5167/10000: episode: 721, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000427, mae: 0.021801, mean_q: 0.028489
 5171/10000: episode: 722, duration: 0.026s, episode steps: 4, steps per second: 153, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000583, mae: 0.020870, mean_q: 0.008068
 5178/10000: episode: 723, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000340, mae: 0.016688, mean_q: 0.012887
 5185/10000: episode: 724, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001297, mae: 0.016662, mean_q: 0.005445
 5192/10000: episode: 725, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001329, mae: 0.033938, mean_q: 0.024921
 5196/10000: episode: 726, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000565, mae: 0.024227, mean_q: -0.005079
 5200/10000: episode: 727, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000674, mae: 0.026868, mean_q: 0.032441
 5204/10000: episode: 728, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000662, mae: 0.019801, mean_q: 0.001516
 5211/10000: episode: 729, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000557, mae: 0.020620, mean_q: 0.024683
 5218/10000: episode: 730, duration: 0.038s, episode steps: 7, steps per second: 184, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000767, mae: 0.021040, mean_q: 0.010875
 5225/10000: episode: 731, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000566, mae: 0.015411, mean_q: 0.010418
 5229/10000: episode: 732, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000219, mae: 0.010180, mean_q: 0.014244
 5233/10000: episode: 733, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000672, mae: 0.016631, mean_q: 0.024405
 5237/10000: episode: 734, duration: 0.025s, episode steps: 4, steps per second: 161, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001559, mae: 0.013045, mean_q: 0.012541
 5244/10000: episode: 735, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001199, mae: 0.019872, mean_q: 0.020858
 5251/10000: episode: 736, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001405, mae: 0.025168, mean_q: 0.017133
 5258/10000: episode: 737, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000915, mae: 0.024795, mean_q: 0.009390
 5265/10000: episode: 738, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000400, mae: 0.018001, mean_q: 0.025576
 5272/10000: episode: 739, duration: 0.037s, episode steps: 7, steps per second: 189, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.002628, mae: 0.024854, mean_q: 0.021929
 5276/10000: episode: 740, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000636, mae: 0.019794, mean_q: 0.007760
 5280/10000: episode: 741, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000575, mae: 0.015387, mean_q: 0.020906
 5287/10000: episode: 742, duration: 0.039s, episode steps: 7, steps per second: 181, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.003254, mae: 0.028201, mean_q: 0.035182
 5294/10000: episode: 743, duration: 0.042s, episode steps: 7, steps per second: 168, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000727, mae: 0.024291, mean_q: 0.006512
 5301/10000: episode: 744, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000650, mae: 0.015332, mean_q: 0.016846
 5308/10000: episode: 745, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000409, mae: 0.014873, mean_q: 0.012553
 5312/10000: episode: 746, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000357, mae: 0.013480, mean_q: 0.014851
 5319/10000: episode: 747, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000598, mae: 0.019729, mean_q: 0.023258
 5326/10000: episode: 748, duration: 0.037s, episode steps: 7, steps per second: 187, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000361, mae: 0.018274, mean_q: 0.003216
 5330/10000: episode: 749, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000508, mae: 0.013779, mean_q: 0.013903
 5334/10000: episode: 750, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000100, mae: 0.007935, mean_q: 0.007166
 5338/10000: episode: 751, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.003638, mae: 0.024655, mean_q: 0.027235
 5342/10000: episode: 752, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002253, mae: 0.030117, mean_q: 0.033006
 5349/10000: episode: 753, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000772, mae: 0.023921, mean_q: 0.014494
 5356/10000: episode: 754, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001450, mae: 0.021898, mean_q: 0.019528
 5363/10000: episode: 755, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000380, mae: 0.013100, mean_q: 0.016076
 5367/10000: episode: 756, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000240, mae: 0.010553, mean_q: 0.011812
 5374/10000: episode: 757, duration: 0.038s, episode steps: 7, steps per second: 183, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000752, mae: 0.015648, mean_q: 0.017726
 5381/10000: episode: 758, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000441, mae: 0.018315, mean_q: 0.013223
 5388/10000: episode: 759, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000363, mae: 0.016043, mean_q: 0.013899
 5395/10000: episode: 760, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000335, mae: 0.012738, mean_q: 0.012483
 5399/10000: episode: 761, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000336, mae: 0.012594, mean_q: 0.015043
 5406/10000: episode: 762, duration: 0.035s, episode steps: 7, steps per second: 197, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000512, mae: 0.017280, mean_q: 0.020001
 5410/10000: episode: 763, duration: 0.026s, episode steps: 4, steps per second: 156, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000767, mae: 0.016988, mean_q: 0.014821
 5417/10000: episode: 764, duration: 0.035s, episode steps: 7, steps per second: 197, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000628, mae: 0.015402, mean_q: 0.015719
 5424/10000: episode: 765, duration: 0.040s, episode steps: 7, steps per second: 174, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000273, mae: 0.010754, mean_q: 0.013024
 5431/10000: episode: 766, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000458, mae: 0.015546, mean_q: 0.020090
 5435/10000: episode: 767, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000505, mae: 0.016543, mean_q: 0.023124
 5439/10000: episode: 768, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001090, mae: 0.020998, mean_q: 0.014658
 5443/10000: episode: 769, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000295, mae: 0.014023, mean_q: 0.021744
 5450/10000: episode: 770, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000503, mae: 0.013912, mean_q: 0.017698
 5454/10000: episode: 771, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000582, mae: 0.017535, mean_q: 0.008616
 5458/10000: episode: 772, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000464, mae: 0.017886, mean_q: 0.021610
 5465/10000: episode: 773, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000552, mae: 0.013840, mean_q: 0.012614
 5472/10000: episode: 774, duration: 0.037s, episode steps: 7, steps per second: 189, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002172, mae: 0.020042, mean_q: 0.025326
 5476/10000: episode: 775, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000893, mae: 0.021124, mean_q: 0.022280
 5483/10000: episode: 776, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000790, mae: 0.020317, mean_q: 0.022521
 5487/10000: episode: 777, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000468, mae: 0.017509, mean_q: 0.006800
 5491/10000: episode: 778, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000328, mae: 0.014684, mean_q: 0.008230
[Info] 2-TH LEVEL FOUND: 0.051628969609737396, Considering 10/100 traces
 5495/10000: episode: 779, duration: 0.735s, episode steps: 4, steps per second: 5, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000318, mae: 0.015131, mean_q: 0.020552
[Info] FALSIFICATION!
 5499/10000: episode: 780, duration: 0.224s, episode steps: 4, steps per second: 18, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000206, mae: 0.012391, mean_q: 0.003915
 5504/10000: episode: 781, duration: 0.029s, episode steps: 5, steps per second: 170, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000596, mae: 0.019713, mean_q: 0.019259
 5509/10000: episode: 782, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000425, mae: 0.017841, mean_q: 0.012300
 5514/10000: episode: 783, duration: 0.025s, episode steps: 5, steps per second: 204, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000347, mae: 0.016518, mean_q: 0.020674
 5519/10000: episode: 784, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000468, mae: 0.017441, mean_q: 0.022155
 5524/10000: episode: 785, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000362, mae: 0.016285, mean_q: 0.007087
 5529/10000: episode: 786, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000282, mae: 0.014972, mean_q: 0.020342
 5534/10000: episode: 787, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000688, mae: 0.016147, mean_q: 0.010001
 5539/10000: episode: 788, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000464, mae: 0.016106, mean_q: 0.026509
 5544/10000: episode: 789, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000762, mae: 0.020984, mean_q: 0.000450
 5549/10000: episode: 790, duration: 0.029s, episode steps: 5, steps per second: 173, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000326, mae: 0.017205, mean_q: 0.021235
 5554/10000: episode: 791, duration: 0.032s, episode steps: 5, steps per second: 154, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000553, mae: 0.019038, mean_q: 0.001588
 5559/10000: episode: 792, duration: 0.059s, episode steps: 5, steps per second: 85, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000713, mae: 0.023327, mean_q: 0.029037
 5564/10000: episode: 793, duration: 0.038s, episode steps: 5, steps per second: 130, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002741, mae: 0.033474, mean_q: 0.033153
 5569/10000: episode: 794, duration: 0.042s, episode steps: 5, steps per second: 118, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000809, mae: 0.023592, mean_q: 0.016192
 5574/10000: episode: 795, duration: 0.042s, episode steps: 5, steps per second: 119, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002488, mae: 0.033698, mean_q: 0.029090
[Info] FALSIFICATION!
 5578/10000: episode: 796, duration: 0.179s, episode steps: 4, steps per second: 22, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000436, mae: 0.019093, mean_q: 0.021475
 5583/10000: episode: 797, duration: 0.046s, episode steps: 5, steps per second: 109, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000523, mae: 0.020278, mean_q: 0.002906
 5588/10000: episode: 798, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000399, mae: 0.017516, mean_q: 0.021205
 5593/10000: episode: 799, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000379, mae: 0.016634, mean_q: 0.010540
 5598/10000: episode: 800, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000590, mae: 0.017080, mean_q: 0.022787
 5603/10000: episode: 801, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000666, mae: 0.017126, mean_q: 0.016826
 5608/10000: episode: 802, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000482, mae: 0.014215, mean_q: 0.018964
 5613/10000: episode: 803, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000345, mae: 0.015242, mean_q: 0.009233
 5618/10000: episode: 804, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000587, mae: 0.018470, mean_q: 0.028325
 5623/10000: episode: 805, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000832, mae: 0.020079, mean_q: 0.016783
 5628/10000: episode: 806, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001352, mae: 0.019411, mean_q: 0.024566
[Info] FALSIFICATION!
 5632/10000: episode: 807, duration: 0.253s, episode steps: 4, steps per second: 16, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000880, mae: 0.019848, mean_q: 0.026473
 5637/10000: episode: 808, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.003071, mae: 0.026534, mean_q: 0.006388
 5642/10000: episode: 809, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001568, mae: 0.024773, mean_q: 0.035628
 5647/10000: episode: 810, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002887, mae: 0.025329, mean_q: 0.023233
 5652/10000: episode: 811, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000894, mae: 0.023190, mean_q: 0.033268
 5657/10000: episode: 812, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000560, mae: 0.021056, mean_q: 0.007044
 5662/10000: episode: 813, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000552, mae: 0.022392, mean_q: 0.032021
 5667/10000: episode: 814, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.003490, mae: 0.025344, mean_q: 0.016367
 5672/10000: episode: 815, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000757, mae: 0.020960, mean_q: 0.022025
 5677/10000: episode: 816, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001589, mae: 0.023009, mean_q: 0.010366
 5682/10000: episode: 817, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000764, mae: 0.020219, mean_q: 0.026919
 5687/10000: episode: 818, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000393, mae: 0.015017, mean_q: 0.014933
 5692/10000: episode: 819, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001634, mae: 0.022843, mean_q: 0.025369
 5697/10000: episode: 820, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000611, mae: 0.018229, mean_q: 0.030713
 5702/10000: episode: 821, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000905, mae: 0.022594, mean_q: 0.016534
 5707/10000: episode: 822, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000929, mae: 0.022798, mean_q: 0.034046
 5712/10000: episode: 823, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000364, mae: 0.015599, mean_q: 0.015459
 5717/10000: episode: 824, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000392, mae: 0.014208, mean_q: 0.023931
[Info] FALSIFICATION!
 5721/10000: episode: 825, duration: 0.268s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000357, mae: 0.015010, mean_q: 0.012276
 5726/10000: episode: 826, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.003356, mae: 0.028460, mean_q: 0.021792
 5731/10000: episode: 827, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001074, mae: 0.027855, mean_q: 0.027228
 5736/10000: episode: 828, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000943, mae: 0.022242, mean_q: 0.032807
 5741/10000: episode: 829, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.003922, mae: 0.031254, mean_q: 0.011550
 5746/10000: episode: 830, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001422, mae: 0.035756, mean_q: 0.051190
 5751/10000: episode: 831, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002820, mae: 0.038964, mean_q: 0.007420
 5756/10000: episode: 832, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001364, mae: 0.033218, mean_q: 0.043234
 5761/10000: episode: 833, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.004554, mae: 0.043708, mean_q: 0.004380
 5766/10000: episode: 834, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001619, mae: 0.036647, mean_q: 0.045180
 5771/10000: episode: 835, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000916, mae: 0.032234, mean_q: -0.001226
 5776/10000: episode: 836, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002207, mae: 0.033910, mean_q: 0.045251
 5781/10000: episode: 837, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001518, mae: 0.023130, mean_q: 0.014740
 5786/10000: episode: 838, duration: 0.030s, episode steps: 5, steps per second: 167, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000689, mae: 0.019435, mean_q: 0.028102
 5791/10000: episode: 839, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001708, mae: 0.023852, mean_q: 0.029506
 5796/10000: episode: 840, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000792, mae: 0.021267, mean_q: 0.013627
 5801/10000: episode: 841, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000520, mae: 0.017208, mean_q: 0.025689
 5806/10000: episode: 842, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002829, mae: 0.028736, mean_q: 0.037915
 5811/10000: episode: 843, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001178, mae: 0.022700, mean_q: 0.025421
 5816/10000: episode: 844, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000689, mae: 0.019125, mean_q: 0.022772
 5821/10000: episode: 845, duration: 0.031s, episode steps: 5, steps per second: 159, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001055, mae: 0.022226, mean_q: 0.032606
 5826/10000: episode: 846, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000956, mae: 0.022039, mean_q: 0.035177
 5831/10000: episode: 847, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001785, mae: 0.024527, mean_q: 0.011426
 5836/10000: episode: 848, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001753, mae: 0.029932, mean_q: 0.043768
 5841/10000: episode: 849, duration: 0.028s, episode steps: 5, steps per second: 179, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000668, mae: 0.025576, mean_q: -0.002859
[Info] FALSIFICATION!
 5845/10000: episode: 850, duration: 0.183s, episode steps: 4, steps per second: 22, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.002068, mae: 0.027369, mean_q: 0.038348
 5850/10000: episode: 851, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001213, mae: 0.030159, mean_q: 0.025832
 5855/10000: episode: 852, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003283, mae: 0.030390, mean_q: 0.021450
[Info] FALSIFICATION!
 5859/10000: episode: 853, duration: 0.263s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001593, mae: 0.040207, mean_q: 0.063020
 5864/10000: episode: 854, duration: 0.029s, episode steps: 5, steps per second: 171, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001296, mae: 0.037258, mean_q: -0.000940
 5869/10000: episode: 855, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000987, mae: 0.029976, mean_q: 0.048922
 5874/10000: episode: 856, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001689, mae: 0.022365, mean_q: 0.015201
 5879/10000: episode: 857, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000764, mae: 0.018948, mean_q: 0.021341
 5884/10000: episode: 858, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000518, mae: 0.016774, mean_q: 0.022674
 5889/10000: episode: 859, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001402, mae: 0.020475, mean_q: 0.021165
 5894/10000: episode: 860, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000585, mae: 0.017649, mean_q: 0.033624
 5899/10000: episode: 861, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000772, mae: 0.021421, mean_q: 0.013615
 5904/10000: episode: 862, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001864, mae: 0.028182, mean_q: 0.043348
[Info] FALSIFICATION!
 5908/10000: episode: 863, duration: 0.263s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000502, mae: 0.017473, mean_q: 0.008049
 5913/10000: episode: 864, duration: 0.030s, episode steps: 5, steps per second: 166, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000558, mae: 0.019439, mean_q: 0.030889
 5918/10000: episode: 865, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000759, mae: 0.022075, mean_q: 0.015430
 5923/10000: episode: 866, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001432, mae: 0.022859, mean_q: 0.032332
 5928/10000: episode: 867, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001611, mae: 0.021942, mean_q: 0.015539
 5933/10000: episode: 868, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001772, mae: 0.027140, mean_q: 0.039023
[Info] Complete ISplit Iteration
[Info] Levels: [0.017974995, 0.05162897, 0.61601365]
[Info] Cond. Prob: [0.11, 0.1, 0.07]
[Info] Error Prob: 0.0007700000000000002

 5938/10000: episode: 869, duration: 0.890s, episode steps: 5, steps per second: 6, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000934, mae: 0.021877, mean_q: 0.033649
 5948/10000: episode: 870, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001349, mae: 0.028001, mean_q: 0.027098
 5958/10000: episode: 871, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001979, mae: 0.031266, mean_q: 0.033572
 5968/10000: episode: 872, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000850, mae: 0.022910, mean_q: 0.027104
 5978/10000: episode: 873, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.003281, mae: 0.032314, mean_q: 0.036390
 5988/10000: episode: 874, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001896, mae: 0.033557, mean_q: 0.022989
 5998/10000: episode: 875, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000875, mae: 0.022566, mean_q: 0.019436
 6008/10000: episode: 876, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002718, mae: 0.027849, mean_q: 0.032956
 6018/10000: episode: 877, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001623, mae: 0.030817, mean_q: 0.033411
 6028/10000: episode: 878, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.003465, mae: 0.036593, mean_q: 0.034836
 6038/10000: episode: 879, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001689, mae: 0.031975, mean_q: 0.024763
 6048/10000: episode: 880, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002237, mae: 0.030674, mean_q: 0.021132
 6058/10000: episode: 881, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001859, mae: 0.030013, mean_q: 0.030821
 6068/10000: episode: 882, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001167, mae: 0.024033, mean_q: 0.025070
 6078/10000: episode: 883, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002661, mae: 0.032158, mean_q: 0.040863
 6088/10000: episode: 884, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001450, mae: 0.029426, mean_q: 0.011278
 6098/10000: episode: 885, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.002248, mae: 0.031098, mean_q: 0.029376
 6108/10000: episode: 886, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002234, mae: 0.029603, mean_q: 0.030245
 6118/10000: episode: 887, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001149, mae: 0.025308, mean_q: 0.032632
 6128/10000: episode: 888, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002542, mae: 0.031771, mean_q: 0.032201
 6138/10000: episode: 889, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.003368, mae: 0.039610, mean_q: 0.032880
 6148/10000: episode: 890, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001963, mae: 0.030218, mean_q: 0.021948
 6158/10000: episode: 891, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000999, mae: 0.025802, mean_q: 0.017377
 6168/10000: episode: 892, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002405, mae: 0.030919, mean_q: 0.033570
 6178/10000: episode: 893, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001953, mae: 0.031800, mean_q: 0.032139
 6188/10000: episode: 894, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001230, mae: 0.029545, mean_q: 0.031120
 6198/10000: episode: 895, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002735, mae: 0.031330, mean_q: 0.033217
 6208/10000: episode: 896, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001741, mae: 0.032711, mean_q: 0.021676
 6218/10000: episode: 897, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.003125, mae: 0.036400, mean_q: 0.042391
 6228/10000: episode: 898, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001424, mae: 0.025238, mean_q: 0.031125
 6238/10000: episode: 899, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001034, mae: 0.029069, mean_q: 0.018966
 6248/10000: episode: 900, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001009, mae: 0.021459, mean_q: 0.014700
 6258/10000: episode: 901, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000879, mae: 0.021928, mean_q: 0.028675
 6268/10000: episode: 902, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001422, mae: 0.025137, mean_q: 0.031290
 6278/10000: episode: 903, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001378, mae: 0.024611, mean_q: 0.029602
 6288/10000: episode: 904, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001033, mae: 0.029802, mean_q: 0.018318
 6298/10000: episode: 905, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001234, mae: 0.024324, mean_q: 0.024658
 6308/10000: episode: 906, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002448, mae: 0.032164, mean_q: 0.037511
 6318/10000: episode: 907, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.001050, mae: 0.021745, mean_q: 0.017298
 6328/10000: episode: 908, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001115, mae: 0.021512, mean_q: 0.020297
 6338/10000: episode: 909, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000962, mae: 0.022786, mean_q: 0.028350
 6348/10000: episode: 910, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.003456, mae: 0.034804, mean_q: 0.037748
 6358/10000: episode: 911, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001067, mae: 0.029369, mean_q: 0.012653
 6368/10000: episode: 912, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000931, mae: 0.023975, mean_q: 0.024366
 6378/10000: episode: 913, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001971, mae: 0.022308, mean_q: 0.027915
 6388/10000: episode: 914, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000807, mae: 0.020440, mean_q: 0.013680
 6398/10000: episode: 915, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001383, mae: 0.026683, mean_q: 0.031115
 6408/10000: episode: 916, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001211, mae: 0.025888, mean_q: 0.030222
 6418/10000: episode: 917, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001265, mae: 0.022444, mean_q: 0.020151
 6428/10000: episode: 918, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000897, mae: 0.019903, mean_q: 0.027755
 6438/10000: episode: 919, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.002009, mae: 0.026786, mean_q: 0.034186
 6448/10000: episode: 920, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000828, mae: 0.022342, mean_q: 0.016796
 6458/10000: episode: 921, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.001223, mae: 0.022715, mean_q: 0.026392
 6468/10000: episode: 922, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000942, mae: 0.020403, mean_q: 0.029050
 6478/10000: episode: 923, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001390, mae: 0.025584, mean_q: 0.031763
 6488/10000: episode: 924, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001166, mae: 0.026151, mean_q: 0.012442
 6498/10000: episode: 925, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001520, mae: 0.023634, mean_q: 0.030447
 6508/10000: episode: 926, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.003847, mae: 0.034787, mean_q: 0.040241
 6518/10000: episode: 927, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002421, mae: 0.046950, mean_q: 0.010615
 6528/10000: episode: 928, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000890, mae: 0.030644, mean_q: 0.006183
 6538/10000: episode: 929, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000678, mae: 0.023012, mean_q: 0.026684
 6548/10000: episode: 930, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001708, mae: 0.025557, mean_q: 0.037200
 6558/10000: episode: 931, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000615, mae: 0.022277, mean_q: 0.018255
 6568/10000: episode: 932, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000607, mae: 0.017480, mean_q: 0.013119
 6578/10000: episode: 933, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001172, mae: 0.021361, mean_q: 0.028503
 6588/10000: episode: 934, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.004003, mae: 0.031234, mean_q: 0.036459
 6598/10000: episode: 935, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001880, mae: 0.030246, mean_q: 0.020106
 6608/10000: episode: 936, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001402, mae: 0.025794, mean_q: 0.033649
 6618/10000: episode: 937, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000885, mae: 0.025524, mean_q: 0.018218
 6628/10000: episode: 938, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000581, mae: 0.017250, mean_q: 0.017077
 6638/10000: episode: 939, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001427, mae: 0.017950, mean_q: 0.024649
 6648/10000: episode: 940, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002738, mae: 0.034724, mean_q: 0.031769
 6658/10000: episode: 941, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001536, mae: 0.024566, mean_q: 0.019723
 6668/10000: episode: 942, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002604, mae: 0.033237, mean_q: 0.026372
 6678/10000: episode: 943, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001476, mae: 0.023585, mean_q: 0.028665
 6688/10000: episode: 944, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002167, mae: 0.025542, mean_q: 0.031220
 6698/10000: episode: 945, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001911, mae: 0.023980, mean_q: 0.024119
 6708/10000: episode: 946, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000728, mae: 0.020895, mean_q: 0.010880
 6718/10000: episode: 947, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001477, mae: 0.027168, mean_q: 0.036461
 6728/10000: episode: 948, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000676, mae: 0.021590, mean_q: 0.018747
 6738/10000: episode: 949, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000741, mae: 0.018871, mean_q: 0.026646
 6748/10000: episode: 950, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000931, mae: 0.019047, mean_q: 0.020649
 6758/10000: episode: 951, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.003145, mae: 0.030376, mean_q: 0.038065
 6768/10000: episode: 952, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001374, mae: 0.026590, mean_q: 0.012413
 6778/10000: episode: 953, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002072, mae: 0.025479, mean_q: 0.022145
 6788/10000: episode: 954, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001955, mae: 0.029338, mean_q: 0.044714
 6798/10000: episode: 955, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001901, mae: 0.027587, mean_q: 0.021890
 6808/10000: episode: 956, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001429, mae: 0.023633, mean_q: 0.025935
 6818/10000: episode: 957, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.003865, mae: 0.031255, mean_q: 0.028391
 6828/10000: episode: 958, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002219, mae: 0.025113, mean_q: 0.040450
 6838/10000: episode: 959, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001885, mae: 0.023119, mean_q: 0.024590
 6848/10000: episode: 960, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000796, mae: 0.019705, mean_q: 0.019119
 6858/10000: episode: 961, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002045, mae: 0.021419, mean_q: 0.027177
 6868/10000: episode: 962, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000802, mae: 0.019552, mean_q: 0.016904
 6878/10000: episode: 963, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001086, mae: 0.019032, mean_q: 0.023031
 6888/10000: episode: 964, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000735, mae: 0.016364, mean_q: 0.023857
 6898/10000: episode: 965, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000502, mae: 0.015624, mean_q: 0.018148
 6908/10000: episode: 966, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001519, mae: 0.021891, mean_q: 0.028143
 6918/10000: episode: 967, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001182, mae: 0.021108, mean_q: 0.025617
 6928/10000: episode: 968, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000655, mae: 0.017947, mean_q: 0.020945
[Info] 1-TH LEVEL FOUND: 0.08535738289356232, Considering 11/100 traces
 6938/10000: episode: 969, duration: 0.739s, episode steps: 10, steps per second: 14, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002232, mae: 0.022472, mean_q: 0.021719
 6940/10000: episode: 970, duration: 0.021s, episode steps: 2, steps per second: 97, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001241, mae: 0.038984, mean_q: 0.052708
 6943/10000: episode: 971, duration: 0.025s, episode steps: 3, steps per second: 120, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000786, mae: 0.021587, mean_q: 0.037754
 6946/10000: episode: 972, duration: 0.020s, episode steps: 3, steps per second: 149, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.004096, mae: 0.038107, mean_q: 0.027235
 6948/10000: episode: 973, duration: 0.018s, episode steps: 2, steps per second: 109, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002068, mae: 0.042401, mean_q: 0.016861
 6950/10000: episode: 974, duration: 0.016s, episode steps: 2, steps per second: 122, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001943, mae: 0.033064, mean_q: 0.025413
 6953/10000: episode: 975, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000809, mae: 0.020539, mean_q: 0.011355
 6955/10000: episode: 976, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001757, mae: 0.028290, mean_q: 0.031157
 6957/10000: episode: 977, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002750, mae: 0.031623, mean_q: 0.037820
 6959/10000: episode: 978, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000921, mae: 0.030045, mean_q: 0.040313
 6961/10000: episode: 979, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001167, mae: 0.026210, mean_q: 0.038187
 6963/10000: episode: 980, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000855, mae: 0.026457, mean_q: 0.003042
 6965/10000: episode: 981, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001404, mae: 0.038786, mean_q: -0.001967
 6968/10000: episode: 982, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000550, mae: 0.018734, mean_q: 0.013930
 6970/10000: episode: 983, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000704, mae: 0.027941, mean_q: 0.042526
 6972/10000: episode: 984, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000730, mae: 0.021161, mean_q: 0.027863
 6975/10000: episode: 985, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000771, mae: 0.026271, mean_q: 0.000538
 6977/10000: episode: 986, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000332, mae: 0.018977, mean_q: 0.000606
 6980/10000: episode: 987, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000991, mae: 0.020916, mean_q: 0.026255
 6982/10000: episode: 988, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000865, mae: 0.025780, mean_q: 0.037087
 6984/10000: episode: 989, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000452, mae: 0.013827, mean_q: 0.022137
 6987/10000: episode: 990, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001101, mae: 0.023729, mean_q: 0.009533
 6989/10000: episode: 991, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001380, mae: 0.019856, mean_q: 0.024394
 6991/10000: episode: 992, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000502, mae: 0.023634, mean_q: 0.033487
 6993/10000: episode: 993, duration: 0.015s, episode steps: 2, steps per second: 130, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005163, mae: 0.037074, mean_q: 0.038004
 6996/10000: episode: 994, duration: 0.020s, episode steps: 3, steps per second: 149, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000648, mae: 0.018806, mean_q: 0.015108
 6998/10000: episode: 995, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000842, mae: 0.026450, mean_q: 0.003754
 7003/10000: episode: 996, duration: 0.050s, episode steps: 5, steps per second: 100, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000746, mae: 0.019701, mean_q: 0.011060
 7005/10000: episode: 997, duration: 0.018s, episode steps: 2, steps per second: 110, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000630, mae: 0.020716, mean_q: 0.019102
 7008/10000: episode: 998, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001100, mae: 0.023028, mean_q: 0.023026
 7010/10000: episode: 999, duration: 0.017s, episode steps: 2, steps per second: 115, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000320, mae: 0.017709, mean_q: 0.023817
 7013/10000: episode: 1000, duration: 0.024s, episode steps: 3, steps per second: 126, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000897, mae: 0.021392, mean_q: 0.023720
 7015/10000: episode: 1001, duration: 0.016s, episode steps: 2, steps per second: 129, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000994, mae: 0.025466, mean_q: 0.021569
 7017/10000: episode: 1002, duration: 0.018s, episode steps: 2, steps per second: 111, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006625, mae: 0.026177, mean_q: 0.015215
 7019/10000: episode: 1003, duration: 0.017s, episode steps: 2, steps per second: 116, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001466, mae: 0.036417, mean_q: 0.048140
 7021/10000: episode: 1004, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001290, mae: 0.027928, mean_q: 0.057028
 7024/10000: episode: 1005, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002079, mae: 0.030538, mean_q: 0.035766
 7027/10000: episode: 1006, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001184, mae: 0.033655, mean_q: 0.000554
 7030/10000: episode: 1007, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000666, mae: 0.021792, mean_q: 0.010417
 7033/10000: episode: 1008, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000549, mae: 0.020851, mean_q: 0.026456
 7036/10000: episode: 1009, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001312, mae: 0.029515, mean_q: 0.038114
 7038/10000: episode: 1010, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000493, mae: 0.020413, mean_q: 0.036199
 7043/10000: episode: 1011, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001394, mae: 0.026315, mean_q: 0.029297
 7045/10000: episode: 1012, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000525, mae: 0.019893, mean_q: 0.015989
 7048/10000: episode: 1013, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001213, mae: 0.025149, mean_q: 0.036678
 7050/10000: episode: 1014, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000565, mae: 0.014393, mean_q: 0.018512
 7052/10000: episode: 1015, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000426, mae: 0.016328, mean_q: 0.024641
 7054/10000: episode: 1016, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000389, mae: 0.018618, mean_q: 0.025196
 7057/10000: episode: 1017, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001908, mae: 0.024748, mean_q: 0.026731
 7059/10000: episode: 1018, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002811, mae: 0.031758, mean_q: 0.028762
 7062/10000: episode: 1019, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000865, mae: 0.020048, mean_q: 0.022389
 7065/10000: episode: 1020, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000561, mae: 0.016659, mean_q: 0.021637
 7068/10000: episode: 1021, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001209, mae: 0.025336, mean_q: 0.039720
 7070/10000: episode: 1022, duration: 0.016s, episode steps: 2, steps per second: 122, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000380, mae: 0.014144, mean_q: 0.020222
 7073/10000: episode: 1023, duration: 0.019s, episode steps: 3, steps per second: 154, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000921, mae: 0.022495, mean_q: 0.017520
 7075/10000: episode: 1024, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001375, mae: 0.021030, mean_q: 0.027402
 7077/10000: episode: 1025, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000514, mae: 0.020908, mean_q: 0.031888
 7079/10000: episode: 1026, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000825, mae: 0.020756, mean_q: 0.036769
 7082/10000: episode: 1027, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001138, mae: 0.023232, mean_q: 0.029515
 7084/10000: episode: 1028, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000672, mae: 0.022481, mean_q: 0.006514
 7086/10000: episode: 1029, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000468, mae: 0.016873, mean_q: 0.019072
 7088/10000: episode: 1030, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000777, mae: 0.024191, mean_q: 0.030920
 7090/10000: episode: 1031, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000781, mae: 0.018864, mean_q: 0.027614
 7092/10000: episode: 1032, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000894, mae: 0.020717, mean_q: 0.014231
 7095/10000: episode: 1033, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000786, mae: 0.025187, mean_q: 0.001172
 7097/10000: episode: 1034, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000730, mae: 0.022051, mean_q: 0.038218
 7099/10000: episode: 1035, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000758, mae: 0.026368, mean_q: 0.030980
 7101/10000: episode: 1036, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005731, mae: 0.037647, mean_q: 0.035640
 7104/10000: episode: 1037, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003595, mae: 0.030103, mean_q: 0.032841
 7107/10000: episode: 1038, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001523, mae: 0.026628, mean_q: 0.024832
 7112/10000: episode: 1039, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001435, mae: 0.028875, mean_q: 0.015245
 7114/10000: episode: 1040, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001654, mae: 0.027414, mean_q: 0.037638
 7117/10000: episode: 1041, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000919, mae: 0.028372, mean_q: 0.046527
 7122/10000: episode: 1042, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001529, mae: 0.023012, mean_q: 0.028644
 7125/10000: episode: 1043, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001148, mae: 0.025532, mean_q: 0.027838
 7127/10000: episode: 1044, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001818, mae: 0.023719, mean_q: 0.035535
 7130/10000: episode: 1045, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000871, mae: 0.018158, mean_q: 0.024854
 7133/10000: episode: 1046, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000817, mae: 0.022012, mean_q: 0.014574
 7136/10000: episode: 1047, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000835, mae: 0.022738, mean_q: 0.012550
 7138/10000: episode: 1048, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006012, mae: 0.030368, mean_q: 0.019541
 7140/10000: episode: 1049, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001237, mae: 0.031070, mean_q: 0.053576
 7142/10000: episode: 1050, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001027, mae: 0.020208, mean_q: 0.031187
 7145/10000: episode: 1051, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.004245, mae: 0.038089, mean_q: 0.027323
 7150/10000: episode: 1052, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001762, mae: 0.027339, mean_q: 0.040477
 7152/10000: episode: 1053, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001268, mae: 0.030923, mean_q: 0.054355
 7155/10000: episode: 1054, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000757, mae: 0.024543, mean_q: 0.016189
 7157/10000: episode: 1055, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000672, mae: 0.020822, mean_q: 0.007249
 7159/10000: episode: 1056, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000707, mae: 0.020729, mean_q: 0.021476
 7162/10000: episode: 1057, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000724, mae: 0.024839, mean_q: 0.032265
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.08535738289356232
 7164/10000: episode: 1058, duration: 0.497s, episode steps: 2, steps per second: 4, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000627, mae: 0.020835, mean_q: 0.032463
 7174/10000: episode: 1059, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001173, mae: 0.023306, mean_q: 0.028654
 7184/10000: episode: 1060, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001383, mae: 0.023072, mean_q: 0.027173
 7194/10000: episode: 1061, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000791, mae: 0.019474, mean_q: 0.023434
 7204/10000: episode: 1062, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000690, mae: 0.016156, mean_q: 0.022924
 7214/10000: episode: 1063, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000827, mae: 0.021276, mean_q: 0.019006
 7224/10000: episode: 1064, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000745, mae: 0.020296, mean_q: 0.024660
 7234/10000: episode: 1065, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000732, mae: 0.020514, mean_q: 0.019807
 7244/10000: episode: 1066, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001655, mae: 0.019455, mean_q: 0.021343
 7254/10000: episode: 1067, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000674, mae: 0.017280, mean_q: 0.021407
 7264/10000: episode: 1068, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001071, mae: 0.020753, mean_q: 0.027758
 7274/10000: episode: 1069, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001316, mae: 0.024940, mean_q: 0.034287
 7284/10000: episode: 1070, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001024, mae: 0.023203, mean_q: 0.017724
 7294/10000: episode: 1071, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001295, mae: 0.022615, mean_q: 0.032016
 7304/10000: episode: 1072, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.001878, mae: 0.024831, mean_q: 0.024808
 7314/10000: episode: 1073, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000733, mae: 0.020377, mean_q: 0.017797
 7324/10000: episode: 1074, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001299, mae: 0.020540, mean_q: 0.021578
 7334/10000: episode: 1075, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001036, mae: 0.023710, mean_q: 0.029717
 7344/10000: episode: 1076, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000947, mae: 0.020546, mean_q: 0.019940
 7354/10000: episode: 1077, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000767, mae: 0.016884, mean_q: 0.022267
 7364/10000: episode: 1078, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000552, mae: 0.017465, mean_q: 0.010510
 7374/10000: episode: 1079, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000697, mae: 0.021199, mean_q: 0.026743
 7384/10000: episode: 1080, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000965, mae: 0.020725, mean_q: 0.025226
 7394/10000: episode: 1081, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001110, mae: 0.020461, mean_q: 0.026351
 7404/10000: episode: 1082, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001160, mae: 0.023855, mean_q: 0.030845
 7414/10000: episode: 1083, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000805, mae: 0.022910, mean_q: 0.019622
 7424/10000: episode: 1084, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001433, mae: 0.022828, mean_q: 0.020785
 7434/10000: episode: 1085, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001344, mae: 0.026306, mean_q: 0.030419
 7444/10000: episode: 1086, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001916, mae: 0.023719, mean_q: 0.033292
 7454/10000: episode: 1087, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000851, mae: 0.020057, mean_q: 0.019941
 7464/10000: episode: 1088, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001173, mae: 0.020033, mean_q: 0.029616
 7474/10000: episode: 1089, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001323, mae: 0.020262, mean_q: 0.025108
 7484/10000: episode: 1090, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002348, mae: 0.031268, mean_q: 0.025797
 7494/10000: episode: 1091, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002411, mae: 0.026579, mean_q: 0.029309
 7504/10000: episode: 1092, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001563, mae: 0.035246, mean_q: 0.014648
 7514/10000: episode: 1093, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001979, mae: 0.027193, mean_q: 0.031330
 7524/10000: episode: 1094, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.003948, mae: 0.035976, mean_q: 0.043589
 7534/10000: episode: 1095, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001125, mae: 0.030844, mean_q: 0.015510
 7544/10000: episode: 1096, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000748, mae: 0.020740, mean_q: 0.019190
 7554/10000: episode: 1097, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002269, mae: 0.024269, mean_q: 0.034922
 7564/10000: episode: 1098, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001280, mae: 0.029713, mean_q: 0.009858
 7574/10000: episode: 1099, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.001427, mae: 0.027361, mean_q: 0.031382
 7584/10000: episode: 1100, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000844, mae: 0.021849, mean_q: 0.023796
 7594/10000: episode: 1101, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001154, mae: 0.022638, mean_q: 0.022307
 7604/10000: episode: 1102, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001266, mae: 0.023341, mean_q: 0.026155
 7614/10000: episode: 1103, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000745, mae: 0.019476, mean_q: 0.012826
 7624/10000: episode: 1104, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001757, mae: 0.021826, mean_q: 0.024082
 7634/10000: episode: 1105, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001245, mae: 0.025095, mean_q: 0.026016
 7644/10000: episode: 1106, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000943, mae: 0.019827, mean_q: 0.023685
 7654/10000: episode: 1107, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001181, mae: 0.018860, mean_q: 0.023766
 7664/10000: episode: 1108, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001497, mae: 0.025102, mean_q: 0.027739
 7674/10000: episode: 1109, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001113, mae: 0.023371, mean_q: 0.015416
 7684/10000: episode: 1110, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001366, mae: 0.024379, mean_q: 0.027886
 7694/10000: episode: 1111, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002742, mae: 0.036265, mean_q: 0.031892
 7704/10000: episode: 1112, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002398, mae: 0.028636, mean_q: 0.032226
 7714/10000: episode: 1113, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002891, mae: 0.033453, mean_q: 0.027624
 7724/10000: episode: 1114, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001364, mae: 0.031084, mean_q: 0.015027
 7734/10000: episode: 1115, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000792, mae: 0.021180, mean_q: 0.023703
 7744/10000: episode: 1116, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001228, mae: 0.026464, mean_q: 0.029587
 7754/10000: episode: 1117, duration: 0.073s, episode steps: 10, steps per second: 136, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000852, mae: 0.021944, mean_q: 0.017185
 7764/10000: episode: 1118, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001418, mae: 0.032179, mean_q: 0.039264
 7774/10000: episode: 1119, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001832, mae: 0.030822, mean_q: 0.029806
 7784/10000: episode: 1120, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000832, mae: 0.022615, mean_q: 0.022607
 7794/10000: episode: 1121, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000835, mae: 0.019902, mean_q: 0.024548
 7804/10000: episode: 1122, duration: 0.077s, episode steps: 10, steps per second: 129, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000847, mae: 0.018329, mean_q: 0.020011
 7814/10000: episode: 1123, duration: 0.067s, episode steps: 10, steps per second: 148, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000858, mae: 0.019112, mean_q: 0.023636
 7824/10000: episode: 1124, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001248, mae: 0.020997, mean_q: 0.031168
 7834/10000: episode: 1125, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002429, mae: 0.031964, mean_q: 0.048086
 7844/10000: episode: 1126, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002388, mae: 0.032335, mean_q: 0.019571
 7854/10000: episode: 1127, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.002708, mae: 0.025427, mean_q: 0.022615
 7864/10000: episode: 1128, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001441, mae: 0.027383, mean_q: 0.027925
 7874/10000: episode: 1129, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000997, mae: 0.023290, mean_q: 0.026426
 7884/10000: episode: 1130, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001275, mae: 0.024014, mean_q: 0.028463
 7894/10000: episode: 1131, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000633, mae: 0.019558, mean_q: 0.028418
 7904/10000: episode: 1132, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000941, mae: 0.019476, mean_q: 0.024531
 7914/10000: episode: 1133, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001057, mae: 0.022115, mean_q: 0.020147
 7924/10000: episode: 1134, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000964, mae: 0.024454, mean_q: 0.032251
 7934/10000: episode: 1135, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000685, mae: 0.020780, mean_q: 0.011724
 7944/10000: episode: 1136, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001006, mae: 0.021875, mean_q: 0.026080
 7954/10000: episode: 1137, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001341, mae: 0.021032, mean_q: 0.027576
 7964/10000: episode: 1138, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001811, mae: 0.019268, mean_q: 0.014228
 7974/10000: episode: 1139, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001600, mae: 0.024163, mean_q: 0.030262
 7984/10000: episode: 1140, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000930, mae: 0.019177, mean_q: 0.022342
 7994/10000: episode: 1141, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000834, mae: 0.019443, mean_q: 0.015995
 8004/10000: episode: 1142, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000728, mae: 0.016203, mean_q: 0.019541
 8014/10000: episode: 1143, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001186, mae: 0.023271, mean_q: 0.029674
 8024/10000: episode: 1144, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001411, mae: 0.023034, mean_q: 0.031437
 8034/10000: episode: 1145, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000695, mae: 0.017403, mean_q: 0.019223
 8044/10000: episode: 1146, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000727, mae: 0.017418, mean_q: 0.021646
 8054/10000: episode: 1147, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002840, mae: 0.024754, mean_q: 0.020629
 8064/10000: episode: 1148, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001080, mae: 0.024061, mean_q: 0.030716
 8074/10000: episode: 1149, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002376, mae: 0.033305, mean_q: 0.035994
 8084/10000: episode: 1150, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002819, mae: 0.029874, mean_q: 0.005916
 8094/10000: episode: 1151, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000942, mae: 0.025858, mean_q: 0.029333
 8104/10000: episode: 1152, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000619, mae: 0.018484, mean_q: 0.018710
 8114/10000: episode: 1153, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000828, mae: 0.018127, mean_q: 0.024742
 8124/10000: episode: 1154, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001146, mae: 0.021683, mean_q: 0.017664
 8134/10000: episode: 1155, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001885, mae: 0.023946, mean_q: 0.027416
 8144/10000: episode: 1156, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002129, mae: 0.024075, mean_q: 0.022533
 8154/10000: episode: 1157, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000512, mae: 0.015536, mean_q: 0.017611
[Info] 1-TH LEVEL FOUND: 0.03296130895614624, Considering 11/100 traces
 8164/10000: episode: 1158, duration: 0.756s, episode steps: 10, steps per second: 13, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000923, mae: 0.017967, mean_q: 0.024343
 8171/10000: episode: 1159, duration: 0.039s, episode steps: 7, steps per second: 178, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.003272, mae: 0.024998, mean_q: 0.030988
 8178/10000: episode: 1160, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.002115, mae: 0.023031, mean_q: 0.019598
 8185/10000: episode: 1161, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000817, mae: 0.018595, mean_q: 0.019696
 8192/10000: episode: 1162, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.003070, mae: 0.021173, mean_q: 0.017098
 8199/10000: episode: 1163, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001315, mae: 0.033262, mean_q: 0.046469
 8206/10000: episode: 1164, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001012, mae: 0.031042, mean_q: 0.003067
 8213/10000: episode: 1165, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000831, mae: 0.019482, mean_q: 0.020312
 8220/10000: episode: 1166, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001029, mae: 0.018744, mean_q: 0.019020
 8227/10000: episode: 1167, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.002228, mae: 0.022695, mean_q: 0.026419
 8234/10000: episode: 1168, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.002881, mae: 0.027897, mean_q: 0.036973
 8241/10000: episode: 1169, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.002158, mae: 0.036090, mean_q: 0.017327
 8248/10000: episode: 1170, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000807, mae: 0.022887, mean_q: 0.024618
 8255/10000: episode: 1171, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000548, mae: 0.016507, mean_q: 0.005451
 8262/10000: episode: 1172, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000875, mae: 0.021275, mean_q: 0.028275
 8269/10000: episode: 1173, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002483, mae: 0.023669, mean_q: 0.023559
 8276/10000: episode: 1174, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000794, mae: 0.019485, mean_q: 0.027401
 8283/10000: episode: 1175, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001583, mae: 0.025823, mean_q: 0.025513
 8290/10000: episode: 1176, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001234, mae: 0.023709, mean_q: 0.020462
 8297/10000: episode: 1177, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000757, mae: 0.023487, mean_q: 0.031462
 8304/10000: episode: 1178, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.002335, mae: 0.019359, mean_q: 0.018633
 8311/10000: episode: 1179, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.002011, mae: 0.020616, mean_q: 0.018374
 8318/10000: episode: 1180, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000773, mae: 0.017759, mean_q: 0.029978
 8325/10000: episode: 1181, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000340, mae: 0.015324, mean_q: 0.011045
 8332/10000: episode: 1182, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000828, mae: 0.021067, mean_q: 0.022662
 8339/10000: episode: 1183, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.002067, mae: 0.019338, mean_q: 0.021436
 8346/10000: episode: 1184, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001508, mae: 0.024015, mean_q: 0.027232
 8353/10000: episode: 1185, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000541, mae: 0.014341, mean_q: 0.015045
 8360/10000: episode: 1186, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000536, mae: 0.014515, mean_q: 0.017946
 8367/10000: episode: 1187, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000474, mae: 0.013440, mean_q: 0.018231
 8374/10000: episode: 1188, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000549, mae: 0.014823, mean_q: 0.023308
 8381/10000: episode: 1189, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000791, mae: 0.017129, mean_q: 0.018091
 8388/10000: episode: 1190, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000568, mae: 0.014986, mean_q: 0.018809
 8395/10000: episode: 1191, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000417, mae: 0.012061, mean_q: 0.012124
 8402/10000: episode: 1192, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000559, mae: 0.014418, mean_q: 0.018830
 8409/10000: episode: 1193, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000763, mae: 0.021623, mean_q: 0.030665
 8416/10000: episode: 1194, duration: 0.038s, episode steps: 7, steps per second: 183, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.001156, mae: 0.024762, mean_q: 0.011901
 8423/10000: episode: 1195, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000949, mae: 0.019868, mean_q: 0.023422
 8430/10000: episode: 1196, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000392, mae: 0.015195, mean_q: 0.013602
 8437/10000: episode: 1197, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000519, mae: 0.015097, mean_q: 0.021738
 8444/10000: episode: 1198, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000870, mae: 0.018338, mean_q: 0.012910
 8451/10000: episode: 1199, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000835, mae: 0.023586, mean_q: 0.028988
 8458/10000: episode: 1200, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002822, mae: 0.026932, mean_q: 0.028387
 8465/10000: episode: 1201, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.001396, mae: 0.027541, mean_q: 0.033583
 8472/10000: episode: 1202, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.002625, mae: 0.030687, mean_q: 0.016522
 8479/10000: episode: 1203, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.002888, mae: 0.025743, mean_q: 0.024587
 8486/10000: episode: 1204, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002784, mae: 0.034909, mean_q: 0.043507
 8493/10000: episode: 1205, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001535, mae: 0.031918, mean_q: 0.011043
 8500/10000: episode: 1206, duration: 0.037s, episode steps: 7, steps per second: 187, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000685, mae: 0.019615, mean_q: 0.020199
 8507/10000: episode: 1207, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000683, mae: 0.015852, mean_q: 0.017722
 8514/10000: episode: 1208, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001554, mae: 0.023450, mean_q: 0.029973
 8521/10000: episode: 1209, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001967, mae: 0.023700, mean_q: 0.029851
 8528/10000: episode: 1210, duration: 0.035s, episode steps: 7, steps per second: 197, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001275, mae: 0.027728, mean_q: 0.014650
 8535/10000: episode: 1211, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.002062, mae: 0.030351, mean_q: 0.033892
 8542/10000: episode: 1212, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001775, mae: 0.024567, mean_q: 0.008068
 8549/10000: episode: 1213, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000513, mae: 0.013863, mean_q: 0.022131
 8556/10000: episode: 1214, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000724, mae: 0.017919, mean_q: 0.014806
 8563/10000: episode: 1215, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000815, mae: 0.027980, mean_q: 0.036385
 8570/10000: episode: 1216, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000944, mae: 0.026237, mean_q: 0.008908
 8577/10000: episode: 1217, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001046, mae: 0.022877, mean_q: 0.036726
 8584/10000: episode: 1218, duration: 0.033s, episode steps: 7, steps per second: 215, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.002655, mae: 0.028448, mean_q: 0.020810
 8591/10000: episode: 1219, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000621, mae: 0.019490, mean_q: 0.028407
 8598/10000: episode: 1220, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.001674, mae: 0.029552, mean_q: 0.025129
 8605/10000: episode: 1221, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.002408, mae: 0.023694, mean_q: 0.026999
 8612/10000: episode: 1222, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000860, mae: 0.020813, mean_q: 0.033122
 8619/10000: episode: 1223, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001007, mae: 0.024952, mean_q: 0.020555
 8626/10000: episode: 1224, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000582, mae: 0.019031, mean_q: 0.030184
 8633/10000: episode: 1225, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000954, mae: 0.021661, mean_q: 0.012989
 8640/10000: episode: 1226, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000795, mae: 0.017860, mean_q: 0.022476
 8647/10000: episode: 1227, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.002369, mae: 0.024749, mean_q: 0.035438
 8654/10000: episode: 1228, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000474, mae: 0.021564, mean_q: 0.008640
 8661/10000: episode: 1229, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002311, mae: 0.021672, mean_q: 0.026082
 8668/10000: episode: 1230, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001843, mae: 0.017974, mean_q: 0.020423
 8675/10000: episode: 1231, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001019, mae: 0.020616, mean_q: 0.026660
 8682/10000: episode: 1232, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000737, mae: 0.018745, mean_q: 0.017360
[Info] FALSIFICATION!
 8688/10000: episode: 1233, duration: 0.194s, episode steps: 6, steps per second: 31, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.004232, mae: 0.030201, mean_q: 0.033777
 8695/10000: episode: 1234, duration: 0.036s, episode steps: 7, steps per second: 192, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001649, mae: 0.027669, mean_q: 0.025273
[Info] FALSIFICATION!
 8701/10000: episode: 1235, duration: 0.260s, episode steps: 6, steps per second: 23, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.002321, mae: 0.031152, mean_q: 0.038969
 8708/10000: episode: 1236, duration: 0.038s, episode steps: 7, steps per second: 183, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000902, mae: 0.023630, mean_q: 0.029191
 8715/10000: episode: 1237, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.002561, mae: 0.029188, mean_q: 0.032658
 8722/10000: episode: 1238, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001722, mae: 0.020873, mean_q: 0.021352
 8729/10000: episode: 1239, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001778, mae: 0.023935, mean_q: 0.033921
 8736/10000: episode: 1240, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001255, mae: 0.023875, mean_q: 0.025317
 8743/10000: episode: 1241, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001777, mae: 0.025252, mean_q: 0.040041
 8750/10000: episode: 1242, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000946, mae: 0.019821, mean_q: 0.032870
 8757/10000: episode: 1243, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000613, mae: 0.021069, mean_q: 0.019382
 8764/10000: episode: 1244, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.002358, mae: 0.026558, mean_q: 0.027877
 8771/10000: episode: 1245, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001381, mae: 0.022605, mean_q: 0.027549
 8778/10000: episode: 1246, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.002198, mae: 0.030382, mean_q: 0.045902
[Info] Complete ISplit Iteration
[Info] Levels: [0.03296131, 0.8632551]
[Info] Cond. Prob: [0.11, 0.02]
[Info] Error Prob: 0.0022

 8785/10000: episode: 1247, duration: 0.850s, episode steps: 7, steps per second: 8, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.002010, mae: 0.027538, mean_q: 0.016459
 8795/10000: episode: 1248, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001065, mae: 0.022332, mean_q: 0.028823
 8805/10000: episode: 1249, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001079, mae: 0.021666, mean_q: 0.025261
 8815/10000: episode: 1250, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001156, mae: 0.020409, mean_q: 0.025989
 8825/10000: episode: 1251, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001030, mae: 0.019432, mean_q: 0.021847
 8835/10000: episode: 1252, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001089, mae: 0.022609, mean_q: 0.031362
 8845/10000: episode: 1253, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000680, mae: 0.019403, mean_q: 0.015633
 8855/10000: episode: 1254, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000607, mae: 0.017525, mean_q: 0.025143
 8865/10000: episode: 1255, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001572, mae: 0.020230, mean_q: 0.016733
 8875/10000: episode: 1256, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001688, mae: 0.026083, mean_q: 0.035602
 8885/10000: episode: 1257, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001648, mae: 0.026674, mean_q: 0.020631
 8895/10000: episode: 1258, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000975, mae: 0.020795, mean_q: 0.024192
 8905/10000: episode: 1259, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001176, mae: 0.024890, mean_q: 0.031220
 8915/10000: episode: 1260, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000483, mae: 0.018394, mean_q: 0.011465
 8925/10000: episode: 1261, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.001717, mae: 0.022080, mean_q: 0.025504
 8935/10000: episode: 1262, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000979, mae: 0.022636, mean_q: 0.028912
 8945/10000: episode: 1263, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.002088, mae: 0.022775, mean_q: 0.026010
 8955/10000: episode: 1264, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001646, mae: 0.029574, mean_q: 0.036593
 8965/10000: episode: 1265, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001331, mae: 0.025976, mean_q: 0.031199
 8975/10000: episode: 1266, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000566, mae: 0.017148, mean_q: 0.013020
 8985/10000: episode: 1267, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001823, mae: 0.022388, mean_q: 0.028999
 8995/10000: episode: 1268, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001071, mae: 0.019443, mean_q: 0.024440
 9005/10000: episode: 1269, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000924, mae: 0.020813, mean_q: 0.019925
 9015/10000: episode: 1270, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000553, mae: 0.016760, mean_q: 0.021775
 9025/10000: episode: 1271, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000833, mae: 0.019653, mean_q: 0.027357
 9035/10000: episode: 1272, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001816, mae: 0.019059, mean_q: 0.025143
 9045/10000: episode: 1273, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001417, mae: 0.030035, mean_q: 0.030494
 9055/10000: episode: 1274, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002023, mae: 0.021366, mean_q: 0.020981
 9065/10000: episode: 1275, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000874, mae: 0.020559, mean_q: 0.015623
 9075/10000: episode: 1276, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001054, mae: 0.024440, mean_q: 0.033233
 9085/10000: episode: 1277, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001292, mae: 0.023715, mean_q: 0.027818
 9095/10000: episode: 1278, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001011, mae: 0.026627, mean_q: 0.018061
 9105/10000: episode: 1279, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000596, mae: 0.019642, mean_q: 0.012353
 9115/10000: episode: 1280, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001718, mae: 0.023397, mean_q: 0.030810
 9125/10000: episode: 1281, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001785, mae: 0.023511, mean_q: 0.029706
 9135/10000: episode: 1282, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000825, mae: 0.017909, mean_q: 0.019949
 9145/10000: episode: 1283, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001369, mae: 0.023288, mean_q: 0.024654
 9155/10000: episode: 1284, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.001957, mae: 0.026010, mean_q: 0.033608
 9165/10000: episode: 1285, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000645, mae: 0.019402, mean_q: 0.020424
 9175/10000: episode: 1286, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001952, mae: 0.026568, mean_q: 0.026380
 9185/10000: episode: 1287, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001248, mae: 0.018100, mean_q: 0.013525
 9195/10000: episode: 1288, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002071, mae: 0.028015, mean_q: 0.031057
 9205/10000: episode: 1289, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000883, mae: 0.019420, mean_q: 0.027307
 9215/10000: episode: 1290, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001957, mae: 0.023639, mean_q: 0.033356
 9225/10000: episode: 1291, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000801, mae: 0.019922, mean_q: 0.025962
 9235/10000: episode: 1292, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000724, mae: 0.020266, mean_q: 0.019525
 9245/10000: episode: 1293, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000848, mae: 0.021449, mean_q: 0.023235
 9255/10000: episode: 1294, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001078, mae: 0.021994, mean_q: 0.030862
 9265/10000: episode: 1295, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001654, mae: 0.027803, mean_q: 0.022252
 9275/10000: episode: 1296, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000952, mae: 0.022894, mean_q: 0.027089
 9285/10000: episode: 1297, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001316, mae: 0.024562, mean_q: 0.026520
 9295/10000: episode: 1298, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002470, mae: 0.031319, mean_q: 0.028142
 9305/10000: episode: 1299, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000720, mae: 0.020105, mean_q: 0.015070
 9315/10000: episode: 1300, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001003, mae: 0.020970, mean_q: 0.028435
 9325/10000: episode: 1301, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001700, mae: 0.023002, mean_q: 0.035091
 9335/10000: episode: 1302, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001666, mae: 0.027388, mean_q: 0.022667
 9345/10000: episode: 1303, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000966, mae: 0.021361, mean_q: 0.026813
 9355/10000: episode: 1304, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002600, mae: 0.027440, mean_q: 0.037309
 9365/10000: episode: 1305, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001672, mae: 0.025838, mean_q: 0.016496
 9375/10000: episode: 1306, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000801, mae: 0.022463, mean_q: 0.018750
 9385/10000: episode: 1307, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001245, mae: 0.021978, mean_q: 0.022598
 9395/10000: episode: 1308, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000882, mae: 0.018748, mean_q: 0.016439
 9405/10000: episode: 1309, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001442, mae: 0.030636, mean_q: 0.038534
 9415/10000: episode: 1310, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000981, mae: 0.023011, mean_q: 0.026816
 9425/10000: episode: 1311, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000918, mae: 0.022609, mean_q: 0.014608
 9435/10000: episode: 1312, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001336, mae: 0.024421, mean_q: 0.032408
 9445/10000: episode: 1313, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000856, mae: 0.018966, mean_q: 0.025494
 9455/10000: episode: 1314, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001160, mae: 0.019292, mean_q: 0.028201
 9465/10000: episode: 1315, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002177, mae: 0.021971, mean_q: 0.028667
 9475/10000: episode: 1316, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001144, mae: 0.024497, mean_q: 0.013849
 9485/10000: episode: 1317, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000519, mae: 0.016345, mean_q: 0.021805
 9495/10000: episode: 1318, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002626, mae: 0.029080, mean_q: 0.031759
 9505/10000: episode: 1319, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001314, mae: 0.030839, mean_q: 0.020102
 9515/10000: episode: 1320, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001050, mae: 0.023467, mean_q: 0.028661
 9525/10000: episode: 1321, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000716, mae: 0.018507, mean_q: 0.021212
 9535/10000: episode: 1322, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002383, mae: 0.024550, mean_q: 0.029264
 9545/10000: episode: 1323, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000880, mae: 0.020190, mean_q: 0.021935
 9555/10000: episode: 1324, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001303, mae: 0.022463, mean_q: 0.028435
 9565/10000: episode: 1325, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000714, mae: 0.018099, mean_q: 0.025592
 9575/10000: episode: 1326, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001061, mae: 0.020264, mean_q: 0.027195
 9585/10000: episode: 1327, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000555, mae: 0.014019, mean_q: 0.014106
 9595/10000: episode: 1328, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001860, mae: 0.022863, mean_q: 0.023511
 9605/10000: episode: 1329, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001274, mae: 0.024731, mean_q: 0.031726
 9615/10000: episode: 1330, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000973, mae: 0.021763, mean_q: 0.022136
 9625/10000: episode: 1331, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001093, mae: 0.021446, mean_q: 0.031014
 9635/10000: episode: 1332, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001051, mae: 0.020432, mean_q: 0.027521
 9645/10000: episode: 1333, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000596, mae: 0.013790, mean_q: 0.020249
 9655/10000: episode: 1334, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000715, mae: 0.016269, mean_q: 0.019232
 9665/10000: episode: 1335, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001842, mae: 0.020209, mean_q: 0.020294
 9675/10000: episode: 1336, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000624, mae: 0.013936, mean_q: 0.019981
 9685/10000: episode: 1337, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000603, mae: 0.016244, mean_q: 0.019795
 9695/10000: episode: 1338, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.003314, mae: 0.033798, mean_q: 0.037218
 9705/10000: episode: 1339, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000906, mae: 0.027706, mean_q: 0.006395
 9715/10000: episode: 1340, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001051, mae: 0.023698, mean_q: 0.025215
 9725/10000: episode: 1341, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001217, mae: 0.023257, mean_q: 0.030514
 9735/10000: episode: 1342, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001044, mae: 0.023820, mean_q: 0.022849
 9745/10000: episode: 1343, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000893, mae: 0.018573, mean_q: 0.026382
 9755/10000: episode: 1344, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000884, mae: 0.016786, mean_q: 0.023702
 9765/10000: episode: 1345, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000843, mae: 0.017759, mean_q: 0.016367
 9775/10000: episode: 1346, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001519, mae: 0.026808, mean_q: 0.036682
[Info] 1-TH LEVEL FOUND: 0.03963050991296768, Considering 15/100 traces
 9785/10000: episode: 1347, duration: 0.727s, episode steps: 10, steps per second: 14, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000822, mae: 0.020476, mean_q: 0.017814
 9789/10000: episode: 1348, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000976, mae: 0.017766, mean_q: 0.034354
 9791/10000: episode: 1349, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000505, mae: 0.016751, mean_q: 0.014094
 9793/10000: episode: 1350, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000868, mae: 0.023025, mean_q: 0.019476
 9797/10000: episode: 1351, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001401, mae: 0.024906, mean_q: 0.035523
 9801/10000: episode: 1352, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000536, mae: 0.015874, mean_q: 0.018979
 9805/10000: episode: 1353, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001192, mae: 0.022624, mean_q: 0.020746
 9809/10000: episode: 1354, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000736, mae: 0.017546, mean_q: 0.025148
 9811/10000: episode: 1355, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001831, mae: 0.027132, mean_q: 0.024027
 9815/10000: episode: 1356, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000393, mae: 0.012432, mean_q: 0.013683
 9821/10000: episode: 1357, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000567, mae: 0.015109, mean_q: 0.020338
 9823/10000: episode: 1358, duration: 0.016s, episode steps: 2, steps per second: 127, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000703, mae: 0.015621, mean_q: 0.022108
 9827/10000: episode: 1359, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000725, mae: 0.017153, mean_q: 0.020265
 9829/10000: episode: 1360, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004617, mae: 0.023274, mean_q: 0.012819
 9833/10000: episode: 1361, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001007, mae: 0.022659, mean_q: 0.034436
 9837/10000: episode: 1362, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001019, mae: 0.021941, mean_q: 0.013186
 9839/10000: episode: 1363, duration: 0.016s, episode steps: 2, steps per second: 128, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001416, mae: 0.020358, mean_q: 0.013464
 9845/10000: episode: 1364, duration: 0.031s, episode steps: 6, steps per second: 197, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000469, mae: 0.016149, mean_q: 0.014974
 9847/10000: episode: 1365, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000730, mae: 0.017661, mean_q: 0.019248
 9851/10000: episode: 1366, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000915, mae: 0.017363, mean_q: 0.019788
 9853/10000: episode: 1367, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000805, mae: 0.015421, mean_q: 0.014402
 9855/10000: episode: 1368, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006107, mae: 0.031567, mean_q: 0.026713
 9859/10000: episode: 1369, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001089, mae: 0.025792, mean_q: 0.038488
 9863/10000: episode: 1370, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000852, mae: 0.024981, mean_q: -0.002845
 9865/10000: episode: 1371, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000143, mae: 0.010779, mean_q: 0.006148
 9869/10000: episode: 1372, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001306, mae: 0.025713, mean_q: 0.035508
 9873/10000: episode: 1373, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001081, mae: 0.020113, mean_q: 0.017118
 9877/10000: episode: 1374, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000467, mae: 0.016896, mean_q: 0.006541
 9879/10000: episode: 1375, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000543, mae: 0.016163, mean_q: 0.022367
 9883/10000: episode: 1376, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001015, mae: 0.020367, mean_q: 0.021099
 9887/10000: episode: 1377, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000764, mae: 0.018803, mean_q: 0.023262
 9893/10000: episode: 1378, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001192, mae: 0.016382, mean_q: 0.014105
 9897/10000: episode: 1379, duration: 0.020s, episode steps: 4, steps per second: 198, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000997, mae: 0.019942, mean_q: 0.025159
 9899/10000: episode: 1380, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000583, mae: 0.017693, mean_q: 0.025173
 9903/10000: episode: 1381, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000779, mae: 0.018199, mean_q: 0.016215
 9905/10000: episode: 1382, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001506, mae: 0.019555, mean_q: 0.017196
 9909/10000: episode: 1383, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000295, mae: 0.014979, mean_q: 0.022149
 9913/10000: episode: 1384, duration: 0.025s, episode steps: 4, steps per second: 163, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000543, mae: 0.016241, mean_q: 0.026308
 9917/10000: episode: 1385, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001570, mae: 0.030249, mean_q: 0.017762
 9921/10000: episode: 1386, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001374, mae: 0.028581, mean_q: 0.014038
 9925/10000: episode: 1387, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002832, mae: 0.028957, mean_q: 0.034719
 9929/10000: episode: 1388, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000935, mae: 0.022846, mean_q: 0.037966
 9931/10000: episode: 1389, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004484, mae: 0.033545, mean_q: 0.009311
 9935/10000: episode: 1390, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000708, mae: 0.017495, mean_q: 0.016637
 9939/10000: episode: 1391, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000707, mae: 0.017400, mean_q: 0.027069
 9943/10000: episode: 1392, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001089, mae: 0.020512, mean_q: 0.023039
 9947/10000: episode: 1393, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001585, mae: 0.023404, mean_q: 0.031807
 9951/10000: episode: 1394, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000759, mae: 0.020602, mean_q: 0.036651
 9955/10000: episode: 1395, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000847, mae: 0.022527, mean_q: 0.012157
 9957/10000: episode: 1396, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001090, mae: 0.025533, mean_q: 0.015923
 9959/10000: episode: 1397, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001737, mae: 0.026924, mean_q: 0.053127
 9963/10000: episode: 1398, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001086, mae: 0.021953, mean_q: 0.031072
 9967/10000: episode: 1399, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003712, mae: 0.031968, mean_q: 0.017685
 9973/10000: episode: 1400, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000689, mae: 0.014719, mean_q: 0.023180
 9975/10000: episode: 1401, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000251, mae: 0.011539, mean_q: 0.014705
 9979/10000: episode: 1402, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000512, mae: 0.017479, mean_q: 0.027401
 9983/10000: episode: 1403, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002796, mae: 0.026186, mean_q: 0.037510
 9985/10000: episode: 1404, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000457, mae: 0.017945, mean_q: 0.026741
 9989/10000: episode: 1405, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000614, mae: 0.017165, mean_q: 0.013847
 9993/10000: episode: 1406, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001089, mae: 0.023743, mean_q: 0.017310
 9995/10000: episode: 1407, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001224, mae: 0.020682, mean_q: 0.019976
 9999/10000: episode: 1408, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000528, mae: 0.018910, mean_q: 0.022135
done, took 68.195 seconds
[Info] End Importance Splitting. Falsification occurred 13 times.
