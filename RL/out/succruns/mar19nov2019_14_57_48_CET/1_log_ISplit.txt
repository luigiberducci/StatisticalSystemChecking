Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          (None, 2)                 0         
_________________________________________________________________
dense_1 (Dense)              (None, 16)                48        
_________________________________________________________________
dense_2 (Dense)              (None, 8)                 136       
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 9         
=================================================================
Total params: 193
Trainable params: 193
Non-trainable params: 0
_________________________________________________________________
None
[Info] Start Importance Splitting on succruns-v1.
Training for 100000 steps ...
    10/100000: episode: 1, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    20/100000: episode: 2, duration: 0.005s, episode steps: 10, steps per second: 2040, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    30/100000: episode: 3, duration: 0.005s, episode steps: 10, steps per second: 2092, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    40/100000: episode: 4, duration: 0.005s, episode steps: 10, steps per second: 2101, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    50/100000: episode: 5, duration: 0.005s, episode steps: 10, steps per second: 2134, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    60/100000: episode: 6, duration: 0.006s, episode steps: 10, steps per second: 1723, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    70/100000: episode: 7, duration: 0.006s, episode steps: 10, steps per second: 1706, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    80/100000: episode: 8, duration: 0.005s, episode steps: 10, steps per second: 2054, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    90/100000: episode: 9, duration: 0.005s, episode steps: 10, steps per second: 1996, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   100/100000: episode: 10, duration: 0.005s, episode steps: 10, steps per second: 2057, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   110/100000: episode: 11, duration: 0.005s, episode steps: 10, steps per second: 1922, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   120/100000: episode: 12, duration: 0.005s, episode steps: 10, steps per second: 2038, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   130/100000: episode: 13, duration: 0.005s, episode steps: 10, steps per second: 2215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   140/100000: episode: 14, duration: 0.005s, episode steps: 10, steps per second: 2094, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   150/100000: episode: 15, duration: 0.005s, episode steps: 10, steps per second: 2111, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   160/100000: episode: 16, duration: 0.005s, episode steps: 10, steps per second: 2106, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   170/100000: episode: 17, duration: 0.005s, episode steps: 10, steps per second: 2182, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   180/100000: episode: 18, duration: 0.005s, episode steps: 10, steps per second: 2099, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   190/100000: episode: 19, duration: 0.005s, episode steps: 10, steps per second: 2113, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   200/100000: episode: 20, duration: 0.005s, episode steps: 10, steps per second: 2115, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   210/100000: episode: 21, duration: 0.005s, episode steps: 10, steps per second: 2172, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   220/100000: episode: 22, duration: 0.005s, episode steps: 10, steps per second: 2077, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   230/100000: episode: 23, duration: 0.005s, episode steps: 10, steps per second: 2091, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   240/100000: episode: 24, duration: 0.005s, episode steps: 10, steps per second: 2102, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   250/100000: episode: 25, duration: 0.005s, episode steps: 10, steps per second: 2110, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   260/100000: episode: 26, duration: 0.006s, episode steps: 10, steps per second: 1768, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   270/100000: episode: 27, duration: 0.005s, episode steps: 10, steps per second: 2030, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   280/100000: episode: 28, duration: 0.005s, episode steps: 10, steps per second: 2074, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   290/100000: episode: 29, duration: 0.005s, episode steps: 10, steps per second: 2063, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   300/100000: episode: 30, duration: 0.006s, episode steps: 10, steps per second: 1700, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   310/100000: episode: 31, duration: 0.005s, episode steps: 10, steps per second: 2119, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   320/100000: episode: 32, duration: 0.005s, episode steps: 10, steps per second: 2112, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   330/100000: episode: 33, duration: 0.005s, episode steps: 10, steps per second: 2065, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   340/100000: episode: 34, duration: 0.005s, episode steps: 10, steps per second: 2020, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   350/100000: episode: 35, duration: 0.005s, episode steps: 10, steps per second: 2092, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   360/100000: episode: 36, duration: 0.005s, episode steps: 10, steps per second: 2134, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   370/100000: episode: 37, duration: 0.005s, episode steps: 10, steps per second: 2069, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   380/100000: episode: 38, duration: 0.005s, episode steps: 10, steps per second: 2148, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   390/100000: episode: 39, duration: 0.005s, episode steps: 10, steps per second: 2096, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   400/100000: episode: 40, duration: 0.005s, episode steps: 10, steps per second: 2131, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   410/100000: episode: 41, duration: 0.005s, episode steps: 10, steps per second: 2092, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   420/100000: episode: 42, duration: 0.005s, episode steps: 10, steps per second: 2128, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   430/100000: episode: 43, duration: 0.005s, episode steps: 10, steps per second: 2110, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   440/100000: episode: 44, duration: 0.005s, episode steps: 10, steps per second: 2063, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   450/100000: episode: 45, duration: 0.005s, episode steps: 10, steps per second: 2049, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   460/100000: episode: 46, duration: 0.006s, episode steps: 10, steps per second: 1787, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   470/100000: episode: 47, duration: 0.005s, episode steps: 10, steps per second: 2086, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   480/100000: episode: 48, duration: 0.005s, episode steps: 10, steps per second: 2069, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   490/100000: episode: 49, duration: 0.005s, episode steps: 10, steps per second: 2078, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   500/100000: episode: 50, duration: 0.005s, episode steps: 10, steps per second: 2075, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   510/100000: episode: 51, duration: 0.614s, episode steps: 10, steps per second: 16, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.003276, mae: 0.047630, mean_q: 0.106021
   520/100000: episode: 52, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001822, mae: 0.050174, mean_q: 0.043204
   530/100000: episode: 53, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001175, mae: 0.031400, mean_q: 0.060699
   540/100000: episode: 54, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001035, mae: 0.026956, mean_q: 0.067208
   550/100000: episode: 55, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000824, mae: 0.030103, mean_q: 0.055706
   560/100000: episode: 56, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000790, mae: 0.025006, mean_q: 0.050723
   570/100000: episode: 57, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000768, mae: 0.023600, mean_q: 0.054059
   580/100000: episode: 58, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000601, mae: 0.023084, mean_q: 0.047183
   590/100000: episode: 59, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000510, mae: 0.021293, mean_q: 0.044628
   600/100000: episode: 60, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000489, mae: 0.020601, mean_q: 0.045645
   610/100000: episode: 61, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000365, mae: 0.018054, mean_q: 0.042744
   620/100000: episode: 62, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000463, mae: 0.019261, mean_q: 0.038673
   630/100000: episode: 63, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000307, mae: 0.015340, mean_q: 0.043210
   640/100000: episode: 64, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000269, mae: 0.015294, mean_q: 0.034614
   650/100000: episode: 65, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000212, mae: 0.013790, mean_q: 0.033902
   660/100000: episode: 66, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000194, mae: 0.012129, mean_q: 0.034837
   670/100000: episode: 67, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000206, mae: 0.013186, mean_q: 0.028626
   680/100000: episode: 68, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000140, mae: 0.010755, mean_q: 0.027240
   690/100000: episode: 69, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000176, mae: 0.010494, mean_q: 0.028089
   700/100000: episode: 70, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000184, mae: 0.010741, mean_q: 0.026911
   710/100000: episode: 71, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000156, mae: 0.010137, mean_q: 0.023886
   720/100000: episode: 72, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000114, mae: 0.008893, mean_q: 0.022657
   730/100000: episode: 73, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000142, mae: 0.009670, mean_q: 0.021912
   740/100000: episode: 74, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000119, mae: 0.007362, mean_q: 0.018591
   750/100000: episode: 75, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000085, mae: 0.007070, mean_q: 0.019716
   760/100000: episode: 76, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000160, mae: 0.009212, mean_q: 0.019114
   770/100000: episode: 77, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000153, mae: 0.009248, mean_q: 0.017057
   780/100000: episode: 78, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000072, mae: 0.006574, mean_q: 0.014847
   790/100000: episode: 79, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000075, mae: 0.006590, mean_q: 0.014369
   800/100000: episode: 80, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000065, mae: 0.006748, mean_q: 0.014478
   810/100000: episode: 81, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000099, mae: 0.007020, mean_q: 0.014367
   820/100000: episode: 82, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000133, mae: 0.007655, mean_q: 0.013491
   830/100000: episode: 83, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000078, mae: 0.006475, mean_q: 0.014264
   840/100000: episode: 84, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000092, mae: 0.006411, mean_q: 0.012268
   850/100000: episode: 85, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000057, mae: 0.005524, mean_q: 0.011645
   860/100000: episode: 86, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000096, mae: 0.006457, mean_q: 0.011142
   870/100000: episode: 87, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000092, mae: 0.006384, mean_q: 0.012998
   880/100000: episode: 88, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000072, mae: 0.005316, mean_q: 0.011761
   890/100000: episode: 89, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000078, mae: 0.005786, mean_q: 0.009853
   900/100000: episode: 90, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000095, mae: 0.005784, mean_q: 0.010441
   910/100000: episode: 91, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000054, mae: 0.005816, mean_q: 0.011195
   920/100000: episode: 92, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000060, mae: 0.005231, mean_q: 0.008778
   930/100000: episode: 93, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000049, mae: 0.004517, mean_q: 0.009374
   940/100000: episode: 94, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000063, mae: 0.005349, mean_q: 0.010459
   950/100000: episode: 95, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000058, mae: 0.005313, mean_q: 0.009551
   960/100000: episode: 96, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000055, mae: 0.004935, mean_q: 0.008565
   970/100000: episode: 97, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000076, mae: 0.005043, mean_q: 0.007929
   980/100000: episode: 98, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000044, mae: 0.004452, mean_q: 0.008649
   990/100000: episode: 99, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000033, mae: 0.004634, mean_q: 0.007839
  1000/100000: episode: 100, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000109, mae: 0.005401, mean_q: 0.008482
  1010/100000: episode: 101, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000074, mae: 0.005589, mean_q: 0.010603
  1020/100000: episode: 102, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000063, mae: 0.004942, mean_q: 0.008938
  1030/100000: episode: 103, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000027, mae: 0.004421, mean_q: 0.007392
  1040/100000: episode: 104, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000091, mae: 0.005518, mean_q: 0.007339
  1050/100000: episode: 105, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000100, mae: 0.005759, mean_q: 0.009446
  1060/100000: episode: 106, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000081, mae: 0.005558, mean_q: 0.009810
  1070/100000: episode: 107, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000076, mae: 0.005601, mean_q: 0.007939
  1080/100000: episode: 108, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000093, mae: 0.005826, mean_q: 0.007693
  1090/100000: episode: 109, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000068, mae: 0.005498, mean_q: 0.008111
  1100/100000: episode: 110, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000073, mae: 0.005027, mean_q: 0.004785
  1110/100000: episode: 111, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000055, mae: 0.004779, mean_q: 0.005814
  1120/100000: episode: 112, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000075, mae: 0.005093, mean_q: 0.006544
  1130/100000: episode: 113, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000040, mae: 0.004866, mean_q: 0.008267
  1140/100000: episode: 114, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000087, mae: 0.005673, mean_q: 0.009625
  1150/100000: episode: 115, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000084, mae: 0.005750, mean_q: 0.006262
  1160/100000: episode: 116, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000069, mae: 0.004588, mean_q: 0.005063
  1170/100000: episode: 117, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000067, mae: 0.004237, mean_q: 0.005681
  1180/100000: episode: 118, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000043, mae: 0.004990, mean_q: 0.007708
  1190/100000: episode: 119, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000090, mae: 0.005671, mean_q: 0.007943
  1200/100000: episode: 120, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000078, mae: 0.005003, mean_q: 0.007182
  1210/100000: episode: 121, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000088, mae: 0.005260, mean_q: 0.007609
  1220/100000: episode: 122, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000175, mae: 0.007712, mean_q: 0.010656
  1230/100000: episode: 123, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000053, mae: 0.004952, mean_q: 0.007613
  1240/100000: episode: 124, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000034, mae: 0.004902, mean_q: 0.004340
  1250/100000: episode: 125, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000033, mae: 0.003847, mean_q: 0.005084
  1260/100000: episode: 126, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000050, mae: 0.004356, mean_q: 0.006757
  1270/100000: episode: 127, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000093, mae: 0.004904, mean_q: 0.006807
  1280/100000: episode: 128, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000067, mae: 0.004654, mean_q: 0.007415
  1290/100000: episode: 129, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000041, mae: 0.004561, mean_q: 0.005815
  1300/100000: episode: 130, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000067, mae: 0.004455, mean_q: 0.004416
  1310/100000: episode: 131, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000055, mae: 0.004326, mean_q: 0.006470
  1320/100000: episode: 132, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000072, mae: 0.005156, mean_q: 0.007679
  1330/100000: episode: 133, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000080, mae: 0.005070, mean_q: 0.006120
  1340/100000: episode: 134, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000058, mae: 0.004295, mean_q: 0.005657
  1350/100000: episode: 135, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000044, mae: 0.003126, mean_q: 0.004809
  1360/100000: episode: 136, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000063, mae: 0.004812, mean_q: 0.006450
  1370/100000: episode: 137, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000028, mae: 0.003708, mean_q: 0.004342
  1380/100000: episode: 138, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000060, mae: 0.004205, mean_q: 0.006317
  1390/100000: episode: 139, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000090, mae: 0.005702, mean_q: 0.009679
  1400/100000: episode: 140, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000105, mae: 0.006198, mean_q: 0.008394
  1410/100000: episode: 141, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000099, mae: 0.005922, mean_q: 0.006559
  1420/100000: episode: 142, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000055, mae: 0.004616, mean_q: 0.005199
  1430/100000: episode: 143, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000054, mae: 0.004334, mean_q: 0.005652
  1440/100000: episode: 144, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000044, mae: 0.003855, mean_q: 0.006512
  1450/100000: episode: 145, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000028, mae: 0.003710, mean_q: 0.005148
  1460/100000: episode: 146, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000055, mae: 0.004199, mean_q: 0.004718
  1470/100000: episode: 147, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000117, mae: 0.005354, mean_q: 0.006718
  1480/100000: episode: 148, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000048, mae: 0.004831, mean_q: 0.007959
  1490/100000: episode: 149, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000046, mae: 0.003940, mean_q: 0.004186
[Info] 1-TH LEVEL FOUND: 0.04402521252632141, Considering 100/100 traces
  1500/100000: episode: 150, duration: 1.097s, episode steps: 10, steps per second: 9, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000062, mae: 0.003809, mean_q: 0.004430
[Info] 2-TH LEVEL FOUND: 0.04425809159874916, Considering 100/100 traces
  1501/100000: episode: 151, duration: 0.642s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000018, mae: 0.003888, mean_q: 0.005065
[Info] 3-TH LEVEL FOUND: 0.04472091421484947, Considering 10/100 traces
  1502/100000: episode: 152, duration: 0.653s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000009, mae: 0.002802, mean_q: 0.008620
  1504/100000: episode: 153, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000031, mae: 0.004184, mean_q: 0.006755
  1506/100000: episode: 154, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000123, mae: 0.006604, mean_q: 0.008422
  1510/100000: episode: 155, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000086, mae: 0.005046, mean_q: 0.006284
  1512/100000: episode: 156, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000033, mae: 0.003743, mean_q: 0.006069
  1518/100000: episode: 157, duration: 0.028s, episode steps: 6, steps per second: 212, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000020, mae: 0.003004, mean_q: 0.003932
  1520/100000: episode: 158, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000016, mae: 0.003102, mean_q: 0.002693
  1526/100000: episode: 159, duration: 0.028s, episode steps: 6, steps per second: 214, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000069, mae: 0.004823, mean_q: 0.005958
  1528/100000: episode: 160, duration: 0.014s, episode steps: 2, steps per second: 139, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000046, mae: 0.004938, mean_q: 0.008393
  1534/100000: episode: 161, duration: 0.028s, episode steps: 6, steps per second: 214, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000089, mae: 0.005987, mean_q: 0.008863
  1536/100000: episode: 162, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000050, mae: 0.005028, mean_q: 0.005290
  1540/100000: episode: 163, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000045, mae: 0.004557, mean_q: 0.004942
  1546/100000: episode: 164, duration: 0.028s, episode steps: 6, steps per second: 215, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000029, mae: 0.003487, mean_q: 0.004107
  1552/100000: episode: 165, duration: 0.032s, episode steps: 6, steps per second: 189, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000099, mae: 0.005820, mean_q: 0.007495
  1556/100000: episode: 166, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000057, mae: 0.005180, mean_q: 0.007235
  1558/100000: episode: 167, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000218, mae: 0.007512, mean_q: 0.008222
  1562/100000: episode: 168, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000106, mae: 0.005430, mean_q: 0.007474
  1568/100000: episode: 169, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000046, mae: 0.004487, mean_q: 0.005019
  1574/100000: episode: 170, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000101, mae: 0.005351, mean_q: 0.006061
  1576/100000: episode: 171, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000062, mae: 0.005388, mean_q: 0.006591
  1580/100000: episode: 172, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000099, mae: 0.005266, mean_q: 0.006745
  1582/100000: episode: 173, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000029, mae: 0.003972, mean_q: 0.007876
  1584/100000: episode: 174, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000047, mae: 0.003971, mean_q: 0.005224
  1586/100000: episode: 175, duration: 0.015s, episode steps: 2, steps per second: 133, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000046, mae: 0.004377, mean_q: 0.006144
  1590/100000: episode: 176, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000026, mae: 0.003662, mean_q: 0.006899
  1594/100000: episode: 177, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000067, mae: 0.004543, mean_q: 0.006373
  1596/100000: episode: 178, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000025, mae: 0.003939, mean_q: 0.008452
  1600/100000: episode: 179, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000083, mae: 0.005859, mean_q: 0.010023
  1606/100000: episode: 180, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000064, mae: 0.005446, mean_q: 0.008771
  1608/100000: episode: 181, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000026, mae: 0.004218, mean_q: 0.000736
  1610/100000: episode: 182, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000042, mae: 0.005058, mean_q: 0.003984
  1614/100000: episode: 183, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000098, mae: 0.006654, mean_q: 0.006010
  1616/100000: episode: 184, duration: 0.012s, episode steps: 2, steps per second: 168, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000149, mae: 0.005897, mean_q: 0.006738
  1618/100000: episode: 185, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000148, mae: 0.006782, mean_q: 0.010379
  1624/100000: episode: 186, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000141, mae: 0.007289, mean_q: 0.011204
  1626/100000: episode: 187, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000052, mae: 0.004268, mean_q: 0.007244
  1628/100000: episode: 188, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000069, mae: 0.006110, mean_q: 0.006590
  1634/100000: episode: 189, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000150, mae: 0.006468, mean_q: 0.006635
  1638/100000: episode: 190, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000086, mae: 0.005779, mean_q: 0.007948
  1642/100000: episode: 191, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000111, mae: 0.006757, mean_q: 0.009655
  1644/100000: episode: 192, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000131, mae: 0.006582, mean_q: 0.007541
  1648/100000: episode: 193, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000043, mae: 0.004450, mean_q: 0.006038
  1654/100000: episode: 194, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000051, mae: 0.004991, mean_q: 0.007117
  1660/100000: episode: 195, duration: 0.028s, episode steps: 6, steps per second: 211, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000086, mae: 0.005390, mean_q: 0.007281
  1664/100000: episode: 196, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000096, mae: 0.005216, mean_q: 0.006902
  1668/100000: episode: 197, duration: 0.020s, episode steps: 4, steps per second: 198, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000096, mae: 0.005678, mean_q: 0.006315
  1670/100000: episode: 198, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000083, mae: 0.005172, mean_q: 0.007474
  1676/100000: episode: 199, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000062, mae: 0.005434, mean_q: 0.007993
  1680/100000: episode: 200, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000116, mae: 0.006063, mean_q: 0.006861
  1684/100000: episode: 201, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000196, mae: 0.007539, mean_q: 0.008696
  1686/100000: episode: 202, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000135, mae: 0.006945, mean_q: 0.009002
  1688/100000: episode: 203, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000036, mae: 0.005537, mean_q: 0.009719
  1690/100000: episode: 204, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000095, mae: 0.008224, mean_q: 0.014303
  1696/100000: episode: 205, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000112, mae: 0.006690, mean_q: 0.010363
  1698/100000: episode: 206, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000065, mae: 0.005100, mean_q: 0.008998
  1704/100000: episode: 207, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000128, mae: 0.006569, mean_q: 0.007842
  1706/100000: episode: 208, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000083, mae: 0.005926, mean_q: 0.008031
  1708/100000: episode: 209, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000125, mae: 0.008020, mean_q: 0.009829
  1712/100000: episode: 210, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000083, mae: 0.004312, mean_q: 0.005781
  1716/100000: episode: 211, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000174, mae: 0.006154, mean_q: 0.007353
  1720/100000: episode: 212, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000050, mae: 0.005357, mean_q: 0.010401
  1722/100000: episode: 213, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000127, mae: 0.007085, mean_q: 0.012504
  1724/100000: episode: 214, duration: 0.014s, episode steps: 2, steps per second: 140, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000189, mae: 0.009658, mean_q: 0.013602
  1728/100000: episode: 215, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000188, mae: 0.006967, mean_q: 0.008462
  1730/100000: episode: 216, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000155, mae: 0.008499, mean_q: 0.012186
  1732/100000: episode: 217, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000115, mae: 0.007658, mean_q: 0.011445
  1734/100000: episode: 218, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000094, mae: 0.006734, mean_q: 0.007481
  1736/100000: episode: 219, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000049, mae: 0.005389, mean_q: 0.004729
  1742/100000: episode: 220, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000097, mae: 0.005750, mean_q: 0.005515
  1744/100000: episode: 221, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000088, mae: 0.006662, mean_q: 0.007363
  1746/100000: episode: 222, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000041, mae: 0.004496, mean_q: 0.004911
  1748/100000: episode: 223, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000096, mae: 0.006265, mean_q: 0.006536
  1752/100000: episode: 224, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000165, mae: 0.007770, mean_q: 0.008965
  1754/100000: episode: 225, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000190, mae: 0.009021, mean_q: 0.009382
  1758/100000: episode: 226, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000131, mae: 0.008127, mean_q: 0.011708
  1762/100000: episode: 227, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000212, mae: 0.007999, mean_q: 0.007797
  1766/100000: episode: 228, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000061, mae: 0.005739, mean_q: 0.007325
  1770/100000: episode: 229, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000194, mae: 0.007280, mean_q: 0.008999
  1772/100000: episode: 230, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000066, mae: 0.005471, mean_q: 0.007942
  1776/100000: episode: 231, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000139, mae: 0.007117, mean_q: 0.010686
  1782/100000: episode: 232, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000102, mae: 0.005486, mean_q: 0.009058
  1784/100000: episode: 233, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000085, mae: 0.005718, mean_q: 0.009119
  1788/100000: episode: 234, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000095, mae: 0.007188, mean_q: 0.009352
  1794/100000: episode: 235, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000159, mae: 0.007148, mean_q: 0.006765
  1796/100000: episode: 236, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000715, mae: 0.015938, mean_q: 0.007668
  1798/100000: episode: 237, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000175, mae: 0.008301, mean_q: 0.010784
  1802/100000: episode: 238, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000174, mae: 0.011319, mean_q: 0.017247
  1804/100000: episode: 239, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000065, mae: 0.007410, mean_q: 0.012348
  1810/100000: episode: 240, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000189, mae: 0.008732, mean_q: 0.010811
  1814/100000: episode: 241, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000119, mae: 0.006881, mean_q: 0.005233
[Info] 4-TH LEVEL FOUND: 0.0568939745426178, Considering 14/100 traces
  1818/100000: episode: 242, duration: 0.768s, episode steps: 4, steps per second: 5, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000213, mae: 0.007134, mean_q: 0.004384
  1820/100000: episode: 243, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000103, mae: 0.006401, mean_q: 0.008436
  1824/100000: episode: 244, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000120, mae: 0.006864, mean_q: 0.008492
  1828/100000: episode: 245, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000081, mae: 0.007236, mean_q: 0.010633
  1832/100000: episode: 246, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000085, mae: 0.006283, mean_q: 0.009791
  1834/100000: episode: 247, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000044, mae: 0.005125, mean_q: 0.006494
  1838/100000: episode: 248, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000141, mae: 0.007740, mean_q: 0.006538
  1840/100000: episode: 249, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000062, mae: 0.005428, mean_q: 0.005753
  1842/100000: episode: 250, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000041, mae: 0.004619, mean_q: 0.009221
  1846/100000: episode: 251, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000161, mae: 0.008819, mean_q: 0.013447
  1848/100000: episode: 252, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000121, mae: 0.007796, mean_q: 0.014607
  1852/100000: episode: 253, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000165, mae: 0.009459, mean_q: 0.012995
  1854/100000: episode: 254, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000388, mae: 0.011232, mean_q: 0.004739
  1856/100000: episode: 255, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000142, mae: 0.006587, mean_q: 0.002054
  1858/100000: episode: 256, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000413, mae: 0.011181, mean_q: 0.005093
  1860/100000: episode: 257, duration: 0.015s, episode steps: 2, steps per second: 132, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000197, mae: 0.008179, mean_q: 0.007919
  1862/100000: episode: 258, duration: 0.014s, episode steps: 2, steps per second: 142, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000136, mae: 0.008981, mean_q: 0.012882
  1864/100000: episode: 259, duration: 0.014s, episode steps: 2, steps per second: 140, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000272, mae: 0.012458, mean_q: 0.017182
[Info] FALSIFICATION!
  1867/100000: episode: 260, duration: 0.414s, episode steps: 3, steps per second: 7, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000153, mae: 0.009270, mean_q: 0.013219
  1869/100000: episode: 261, duration: 0.018s, episode steps: 2, steps per second: 111, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000053, mae: 0.005877, mean_q: 0.011001
  1873/100000: episode: 262, duration: 0.028s, episode steps: 4, steps per second: 140, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000115, mae: 0.006737, mean_q: 0.008891
  1875/100000: episode: 263, duration: 0.015s, episode steps: 2, steps per second: 131, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000323, mae: 0.010837, mean_q: 0.007405
  1877/100000: episode: 264, duration: 0.016s, episode steps: 2, steps per second: 122, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000167, mae: 0.006673, mean_q: 0.007433
  1879/100000: episode: 265, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000390, mae: 0.016250, mean_q: 0.023545
  1881/100000: episode: 266, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000293, mae: 0.012263, mean_q: 0.014988
  1883/100000: episode: 267, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000212, mae: 0.012218, mean_q: 0.022050
  1887/100000: episode: 268, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000193, mae: 0.008563, mean_q: 0.010792
  1889/100000: episode: 269, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000379, mae: 0.012579, mean_q: 0.009107
  1891/100000: episode: 270, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000126, mae: 0.009466, mean_q: 0.008018
  1895/100000: episode: 271, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000274, mae: 0.009924, mean_q: 0.009187
  1897/100000: episode: 272, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000148, mae: 0.007888, mean_q: 0.010246
  1899/100000: episode: 273, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000133, mae: 0.008268, mean_q: 0.012463
  1901/100000: episode: 274, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000102, mae: 0.006817, mean_q: 0.008328
  1905/100000: episode: 275, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000120, mae: 0.007247, mean_q: 0.009632
  1907/100000: episode: 276, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000119, mae: 0.007070, mean_q: 0.007945
  1911/100000: episode: 277, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000361, mae: 0.011103, mean_q: 0.007332
  1913/100000: episode: 278, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000217, mae: 0.008306, mean_q: 0.009308
  1915/100000: episode: 279, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000311, mae: 0.013144, mean_q: 0.014402
  1919/100000: episode: 280, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000244, mae: 0.011438, mean_q: 0.017192
  1923/100000: episode: 281, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000276, mae: 0.011761, mean_q: 0.016890
  1927/100000: episode: 282, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000148, mae: 0.007428, mean_q: 0.011028
  1929/100000: episode: 283, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000295, mae: 0.012650, mean_q: 0.014068
  1931/100000: episode: 284, duration: 0.014s, episode steps: 2, steps per second: 143, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000403, mae: 0.011099, mean_q: 0.008189
  1933/100000: episode: 285, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000069, mae: 0.005623, mean_q: 0.007724
[Info] FALSIFICATION!
  1936/100000: episode: 286, duration: 0.288s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000286, mae: 0.009503, mean_q: 0.010775
  1938/100000: episode: 287, duration: 0.016s, episode steps: 2, steps per second: 124, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000248, mae: 0.010034, mean_q: 0.012841
  1942/100000: episode: 288, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000418, mae: 0.008539, mean_q: 0.011241
  1944/100000: episode: 289, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000177, mae: 0.008368, mean_q: 0.013354
  1946/100000: episode: 290, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000100, mae: 0.006249, mean_q: 0.007552
  1948/100000: episode: 291, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000625, mae: 0.016792, mean_q: 0.009461
  1952/100000: episode: 292, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000163, mae: 0.007036, mean_q: 0.006943
  1954/100000: episode: 293, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000174, mae: 0.006849, mean_q: 0.007020
  1958/100000: episode: 294, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000355, mae: 0.013524, mean_q: 0.015707
  1962/100000: episode: 295, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000661, mae: 0.015595, mean_q: 0.020969
  1964/100000: episode: 296, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000278, mae: 0.012811, mean_q: 0.017209
  1966/100000: episode: 297, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001025, mae: 0.015883, mean_q: 0.012572
  1970/100000: episode: 298, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000661, mae: 0.013111, mean_q: 0.014643
  1972/100000: episode: 299, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000111, mae: 0.006009, mean_q: 0.011504
  1976/100000: episode: 300, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003484, mae: 0.019090, mean_q: 0.017102
  1978/100000: episode: 301, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000250, mae: 0.012166, mean_q: 0.019783
  1980/100000: episode: 302, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000329, mae: 0.010883, mean_q: 0.014372
  1982/100000: episode: 303, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000137, mae: 0.006193, mean_q: 0.009568
  1986/100000: episode: 304, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.010179, mae: 0.036758, mean_q: 0.022232
  1988/100000: episode: 305, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000622, mae: 0.016468, mean_q: 0.024303
  1990/100000: episode: 306, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000863, mae: 0.019911, mean_q: 0.030515
  1992/100000: episode: 307, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000712, mae: 0.019500, mean_q: 0.027338
  1994/100000: episode: 308, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000302, mae: 0.012829, mean_q: 0.015678
  1998/100000: episode: 309, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000420, mae: 0.015797, mean_q: 0.003900
  2002/100000: episode: 310, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000584, mae: 0.012249, mean_q: 0.004514
  2006/100000: episode: 311, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.004072, mae: 0.025697, mean_q: 0.018252
[Info] FALSIFICATION!
  2009/100000: episode: 312, duration: 0.205s, episode steps: 3, steps per second: 15, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000489, mae: 0.018751, mean_q: 0.026099
  2011/100000: episode: 313, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000518, mae: 0.018045, mean_q: 0.021543
  2015/100000: episode: 314, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003481, mae: 0.022799, mean_q: 0.021748
  2017/100000: episode: 315, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000415, mae: 0.014323, mean_q: 0.016715
  2021/100000: episode: 316, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001211, mae: 0.020442, mean_q: 0.020397
  2023/100000: episode: 317, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.012366, mae: 0.041470, mean_q: 0.025779
  2027/100000: episode: 318, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000584, mae: 0.017613, mean_q: 0.023849
  2029/100000: episode: 319, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000759, mae: 0.013839, mean_q: 0.020656
  2031/100000: episode: 320, duration: 0.012s, episode steps: 2, steps per second: 166, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001204, mae: 0.019974, mean_q: 0.020187
  2033/100000: episode: 321, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006576, mae: 0.024986, mean_q: 0.012948
  2035/100000: episode: 322, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000974, mae: 0.015577, mean_q: 0.017750
  2037/100000: episode: 323, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000221, mae: 0.010699, mean_q: 0.010812
  2039/100000: episode: 324, duration: 0.014s, episode steps: 2, steps per second: 140, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000374, mae: 0.012317, mean_q: 0.013075
  2041/100000: episode: 325, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000356, mae: 0.012084, mean_q: 0.015136
  2043/100000: episode: 326, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006265, mae: 0.025578, mean_q: 0.017333
  2045/100000: episode: 327, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000510, mae: 0.015941, mean_q: 0.021826
[Info] Complete ISplit Iteration
[Info] Levels: [0.044025213, 0.04425809, 0.044720914, 0.056893975, 0.15914303]
[Info] Cond. Prob: [1.0, 1.0, 0.1, 0.14, 0.03]
[Info] Error Prob: 0.00042000000000000007

  2047/100000: episode: 328, duration: 1.067s, episode steps: 2, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001918, mae: 0.024334, mean_q: 0.023668
  2057/100000: episode: 329, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000442, mae: 0.011813, mean_q: 0.012196
  2067/100000: episode: 330, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002911, mae: 0.017519, mean_q: 0.014152
  2077/100000: episode: 331, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000423, mae: 0.014593, mean_q: 0.022809
  2087/100000: episode: 332, duration: 0.073s, episode steps: 10, steps per second: 138, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001736, mae: 0.013919, mean_q: 0.012649
  2097/100000: episode: 333, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000521, mae: 0.010545, mean_q: 0.012363
  2107/100000: episode: 334, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001552, mae: 0.014766, mean_q: 0.018699
  2117/100000: episode: 335, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000561, mae: 0.013107, mean_q: 0.015221
  2127/100000: episode: 336, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001515, mae: 0.012495, mean_q: 0.011959
  2137/100000: episode: 337, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000460, mae: 0.013759, mean_q: 0.018192
  2147/100000: episode: 338, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000371, mae: 0.012325, mean_q: 0.013435
  2157/100000: episode: 339, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001708, mae: 0.012370, mean_q: 0.011491
  2167/100000: episode: 340, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000614, mae: 0.013618, mean_q: 0.015612
  2177/100000: episode: 341, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000666, mae: 0.013819, mean_q: 0.017878
  2187/100000: episode: 342, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001557, mae: 0.012032, mean_q: 0.012890
  2197/100000: episode: 343, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001653, mae: 0.016485, mean_q: 0.019895
  2207/100000: episode: 344, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001396, mae: 0.013761, mean_q: 0.014141
  2217/100000: episode: 345, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000582, mae: 0.011642, mean_q: 0.012892
  2227/100000: episode: 346, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001344, mae: 0.011689, mean_q: 0.013741
  2237/100000: episode: 347, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001758, mae: 0.015233, mean_q: 0.017188
  2247/100000: episode: 348, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001560, mae: 0.016661, mean_q: 0.020853
  2257/100000: episode: 349, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002614, mae: 0.018359, mean_q: 0.020995
  2267/100000: episode: 350, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001576, mae: 0.012760, mean_q: 0.014169
  2277/100000: episode: 351, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001687, mae: 0.013329, mean_q: 0.013203
  2287/100000: episode: 352, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001521, mae: 0.014538, mean_q: 0.017931
  2297/100000: episode: 353, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000431, mae: 0.012365, mean_q: 0.013426
  2307/100000: episode: 354, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000542, mae: 0.012772, mean_q: 0.010747
  2317/100000: episode: 355, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001578, mae: 0.016778, mean_q: 0.018187
  2327/100000: episode: 356, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000382, mae: 0.011209, mean_q: 0.013871
  2337/100000: episode: 357, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001841, mae: 0.014633, mean_q: 0.015077
  2347/100000: episode: 358, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001398, mae: 0.012397, mean_q: 0.013530
  2357/100000: episode: 359, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000419, mae: 0.010952, mean_q: 0.015874
  2367/100000: episode: 360, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.003480, mae: 0.017464, mean_q: 0.012401
  2377/100000: episode: 361, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000347, mae: 0.011078, mean_q: 0.016452
  2387/100000: episode: 362, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000284, mae: 0.010623, mean_q: 0.013420
  2397/100000: episode: 363, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001569, mae: 0.011482, mean_q: 0.011416
  2407/100000: episode: 364, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002343, mae: 0.015380, mean_q: 0.014622
  2417/100000: episode: 365, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000291, mae: 0.009715, mean_q: 0.015723
  2427/100000: episode: 366, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001630, mae: 0.010854, mean_q: 0.009297
  2437/100000: episode: 367, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001612, mae: 0.013163, mean_q: 0.014811
  2447/100000: episode: 368, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000464, mae: 0.011541, mean_q: 0.016135
  2457/100000: episode: 369, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001869, mae: 0.013969, mean_q: 0.011530
  2467/100000: episode: 370, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000391, mae: 0.011899, mean_q: 0.018189
  2477/100000: episode: 371, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001497, mae: 0.012959, mean_q: 0.013176
  2487/100000: episode: 372, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001421, mae: 0.011614, mean_q: 0.010502
  2497/100000: episode: 373, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000490, mae: 0.013519, mean_q: 0.020570
  2507/100000: episode: 374, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001457, mae: 0.012624, mean_q: 0.012796
  2517/100000: episode: 375, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001423, mae: 0.014642, mean_q: 0.019009
  2527/100000: episode: 376, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000252, mae: 0.009074, mean_q: 0.008237
  2537/100000: episode: 377, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000498, mae: 0.011463, mean_q: 0.007260
  2547/100000: episode: 378, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002899, mae: 0.018887, mean_q: 0.018663
  2557/100000: episode: 379, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000467, mae: 0.013518, mean_q: 0.021622
  2567/100000: episode: 380, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001663, mae: 0.012590, mean_q: 0.005979
  2577/100000: episode: 381, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001545, mae: 0.012606, mean_q: 0.019217
  2587/100000: episode: 382, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000415, mae: 0.010739, mean_q: 0.016362
  2597/100000: episode: 383, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000631, mae: 0.013063, mean_q: 0.007044
  2607/100000: episode: 384, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002135, mae: 0.018573, mean_q: 0.019290
  2617/100000: episode: 385, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000632, mae: 0.015324, mean_q: 0.021719
  2627/100000: episode: 386, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000307, mae: 0.007699, mean_q: 0.007331
  2637/100000: episode: 387, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.004230, mae: 0.019942, mean_q: 0.013878
  2647/100000: episode: 388, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001497, mae: 0.014463, mean_q: 0.017210
  2657/100000: episode: 389, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001432, mae: 0.010978, mean_q: 0.011517
  2667/100000: episode: 390, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001600, mae: 0.012185, mean_q: 0.011268
  2677/100000: episode: 391, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000472, mae: 0.010182, mean_q: 0.011751
  2687/100000: episode: 392, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000421, mae: 0.010214, mean_q: 0.012059
  2697/100000: episode: 393, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000481, mae: 0.011895, mean_q: 0.014740
  2707/100000: episode: 394, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001212, mae: 0.011171, mean_q: 0.012734
  2717/100000: episode: 395, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.002503, mae: 0.015908, mean_q: 0.016144
  2727/100000: episode: 396, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001450, mae: 0.012971, mean_q: 0.015147
  2737/100000: episode: 397, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000533, mae: 0.011547, mean_q: 0.015778
  2747/100000: episode: 398, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000389, mae: 0.008287, mean_q: 0.009023
  2757/100000: episode: 399, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001334, mae: 0.013589, mean_q: 0.015181
  2767/100000: episode: 400, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001323, mae: 0.013204, mean_q: 0.015195
  2777/100000: episode: 401, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000253, mae: 0.008238, mean_q: 0.010161
  2787/100000: episode: 402, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000442, mae: 0.009757, mean_q: 0.010058
  2797/100000: episode: 403, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000272, mae: 0.010223, mean_q: 0.011893
  2807/100000: episode: 404, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001716, mae: 0.013130, mean_q: 0.011519
  2817/100000: episode: 405, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000449, mae: 0.010206, mean_q: 0.016067
  2827/100000: episode: 406, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000290, mae: 0.007718, mean_q: 0.007865
  2837/100000: episode: 407, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000623, mae: 0.010602, mean_q: 0.009902
  2847/100000: episode: 408, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000209, mae: 0.007858, mean_q: 0.010872
  2857/100000: episode: 409, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002585, mae: 0.015091, mean_q: 0.013975
  2867/100000: episode: 410, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000507, mae: 0.012124, mean_q: 0.015734
  2877/100000: episode: 411, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000402, mae: 0.011342, mean_q: 0.010715
  2887/100000: episode: 412, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000263, mae: 0.007421, mean_q: 0.005059
  2897/100000: episode: 413, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001433, mae: 0.014335, mean_q: 0.016941
  2907/100000: episode: 414, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002262, mae: 0.016283, mean_q: 0.020240
  2917/100000: episode: 415, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000626, mae: 0.013340, mean_q: 0.015823
  2927/100000: episode: 416, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001333, mae: 0.010895, mean_q: 0.004674
  2937/100000: episode: 417, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001305, mae: 0.011166, mean_q: 0.008705
  2947/100000: episode: 418, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001631, mae: 0.014063, mean_q: 0.015589
  2957/100000: episode: 419, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001215, mae: 0.012633, mean_q: 0.013880
  2967/100000: episode: 420, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000563, mae: 0.009161, mean_q: 0.011269
  2977/100000: episode: 421, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000291, mae: 0.009291, mean_q: 0.010607
  2987/100000: episode: 422, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000267, mae: 0.007554, mean_q: 0.006227
  2997/100000: episode: 423, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000341, mae: 0.009427, mean_q: 0.011977
  3007/100000: episode: 424, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001529, mae: 0.012234, mean_q: 0.012727
  3017/100000: episode: 425, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000271, mae: 0.009404, mean_q: 0.013053
  3027/100000: episode: 426, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000316, mae: 0.008001, mean_q: 0.008266
  3037/100000: episode: 427, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001511, mae: 0.013550, mean_q: 0.015358
[Info] 1-TH LEVEL FOUND: 0.04291306808590889, Considering 12/100 traces
  3047/100000: episode: 428, duration: 0.732s, episode steps: 10, steps per second: 14, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001169, mae: 0.011869, mean_q: 0.015784
  3055/100000: episode: 429, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.054, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000624, mae: 0.011052, mean_q: 0.013023
  3063/100000: episode: 430, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.044, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000633, mae: 0.011025, mean_q: 0.014506
  3071/100000: episode: 431, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000406, mae: 0.008837, mean_q: 0.011872
  3079/100000: episode: 432, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.263, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.938 [-1.000, 11.000], loss: 0.001811, mae: 0.011971, mean_q: 0.011866
  3087/100000: episode: 433, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.128, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.001380, mae: 0.011574, mean_q: 0.013058
  3095/100000: episode: 434, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.128, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.001430, mae: 0.013125, mean_q: 0.014796
  3103/100000: episode: 435, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.049, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000607, mae: 0.012786, mean_q: 0.017305
  3111/100000: episode: 436, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.130, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.001806, mae: 0.011031, mean_q: 0.006116
  3119/100000: episode: 437, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.081, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.002127, mae: 0.016078, mean_q: 0.014377
  3127/100000: episode: 438, duration: 0.041s, episode steps: 8, steps per second: 197, episode reward: 0.013, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.001710, mae: 0.017155, mean_q: 0.020610
  3135/100000: episode: 439, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.215, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000493, mae: 0.011486, mean_q: 0.015771
  3143/100000: episode: 440, duration: 0.037s, episode steps: 8, steps per second: 218, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000318, mae: 0.008308, mean_q: 0.014743
  3151/100000: episode: 441, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.013, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000459, mae: 0.010883, mean_q: 0.014024
  3159/100000: episode: 442, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.039, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000295, mae: 0.009434, mean_q: 0.005264
  3167/100000: episode: 443, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000426, mae: 0.008431, mean_q: 0.008243
  3175/100000: episode: 444, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.102, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000146, mae: 0.006873, mean_q: 0.008540
  3183/100000: episode: 445, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.082, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000410, mae: 0.011371, mean_q: 0.009924
  3191/100000: episode: 446, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.146, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000172, mae: 0.008602, mean_q: 0.012436
  3199/100000: episode: 447, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000558, mae: 0.011925, mean_q: 0.009209
  3207/100000: episode: 448, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000547, mae: 0.011689, mean_q: 0.014777
  3215/100000: episode: 449, duration: 0.040s, episode steps: 8, steps per second: 201, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000366, mae: 0.010836, mean_q: 0.015387
  3223/100000: episode: 450, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000366, mae: 0.010326, mean_q: 0.010930
  3231/100000: episode: 451, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000438, mae: 0.010366, mean_q: 0.009374
  3239/100000: episode: 452, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.033, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000117, mae: 0.006250, mean_q: 0.006610
  3247/100000: episode: 453, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.002152, mae: 0.014098, mean_q: 0.011732
  3255/100000: episode: 454, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.028, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000350, mae: 0.011463, mean_q: 0.014070
  3263/100000: episode: 455, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000147, mae: 0.007275, mean_q: 0.009332
  3271/100000: episode: 456, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.114, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000406, mae: 0.010897, mean_q: 0.011105
  3279/100000: episode: 457, duration: 0.040s, episode steps: 8, steps per second: 198, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002930, mae: 0.013874, mean_q: 0.012392
  3287/100000: episode: 458, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.128, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000390, mae: 0.011893, mean_q: 0.018548
  3295/100000: episode: 459, duration: 0.037s, episode steps: 8, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000385, mae: 0.009257, mean_q: 0.015570
  3303/100000: episode: 460, duration: 0.039s, episode steps: 8, steps per second: 208, episode reward: 0.051, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.002079, mae: 0.013806, mean_q: 0.008715
  3311/100000: episode: 461, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000316, mae: 0.009553, mean_q: 0.011681
  3319/100000: episode: 462, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000527, mae: 0.010625, mean_q: 0.012625
  3327/100000: episode: 463, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.130, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000440, mae: 0.010020, mean_q: 0.012048
  3335/100000: episode: 464, duration: 0.037s, episode steps: 8, steps per second: 216, episode reward: 0.067, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000273, mae: 0.007706, mean_q: 0.011336
  3343/100000: episode: 465, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.001673, mae: 0.013497, mean_q: 0.012603
  3351/100000: episode: 466, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001904, mae: 0.013629, mean_q: 0.014541
  3359/100000: episode: 467, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000354, mae: 0.010212, mean_q: 0.014886
  3367/100000: episode: 468, duration: 0.041s, episode steps: 8, steps per second: 197, episode reward: 0.128, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.001887, mae: 0.012745, mean_q: 0.014351
  3375/100000: episode: 469, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.059, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.001497, mae: 0.013247, mean_q: 0.013035
  3383/100000: episode: 470, duration: 0.039s, episode steps: 8, steps per second: 208, episode reward: 0.032, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001453, mae: 0.012571, mean_q: 0.013133
  3391/100000: episode: 471, duration: 0.037s, episode steps: 8, steps per second: 217, episode reward: 0.348, mean reward: 0.044 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000314, mae: 0.009897, mean_q: 0.011983
  3399/100000: episode: 472, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000403, mae: 0.009179, mean_q: 0.010076
  3407/100000: episode: 473, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000268, mae: 0.009865, mean_q: 0.010908
  3415/100000: episode: 474, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.036, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.001727, mae: 0.012961, mean_q: 0.010703
  3423/100000: episode: 475, duration: 0.037s, episode steps: 8, steps per second: 213, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000222, mae: 0.011040, mean_q: 0.014657
  3431/100000: episode: 476, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.036, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000370, mae: 0.010547, mean_q: 0.010568
  3439/100000: episode: 477, duration: 0.037s, episode steps: 8, steps per second: 218, episode reward: 0.067, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000246, mae: 0.009238, mean_q: 0.009481
  3447/100000: episode: 478, duration: 0.040s, episode steps: 8, steps per second: 200, episode reward: 0.215, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000273, mae: 0.007989, mean_q: 0.007260
  3455/100000: episode: 479, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001870, mae: 0.016046, mean_q: 0.012210
  3463/100000: episode: 480, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.035, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000245, mae: 0.011455, mean_q: 0.016492
  3471/100000: episode: 481, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.114, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.002768, mae: 0.020597, mean_q: 0.019626
  3479/100000: episode: 482, duration: 0.037s, episode steps: 8, steps per second: 216, episode reward: 0.059, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000552, mae: 0.012551, mean_q: 0.017794
  3487/100000: episode: 483, duration: 0.037s, episode steps: 8, steps per second: 216, episode reward: 0.263, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.938 [-1.000, 11.000], loss: 0.000369, mae: 0.011396, mean_q: 0.012841
  3495/100000: episode: 484, duration: 0.040s, episode steps: 8, steps per second: 198, episode reward: 0.102, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000208, mae: 0.009616, mean_q: 0.008913
  3503/100000: episode: 485, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000466, mae: 0.009518, mean_q: 0.006271
  3511/100000: episode: 486, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.032, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000341, mae: 0.010991, mean_q: 0.008931
  3519/100000: episode: 487, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.214, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000263, mae: 0.010480, mean_q: 0.010772
  3527/100000: episode: 488, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.134, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000331, mae: 0.012280, mean_q: 0.011306
  3535/100000: episode: 489, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.022, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000201, mae: 0.010130, mean_q: 0.011327
  3543/100000: episode: 490, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000487, mae: 0.012119, mean_q: 0.011965
  3551/100000: episode: 491, duration: 0.037s, episode steps: 8, steps per second: 219, episode reward: 0.177, mean reward: 0.022 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.001624, mae: 0.014425, mean_q: 0.014867
  3559/100000: episode: 492, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000212, mae: 0.011731, mean_q: 0.017394
  3567/100000: episode: 493, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.098, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000465, mae: 0.011861, mean_q: 0.013189
  3575/100000: episode: 494, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.263, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.938 [-1.000, 11.000], loss: 0.000291, mae: 0.010800, mean_q: 0.013830
  3583/100000: episode: 495, duration: 0.040s, episode steps: 8, steps per second: 201, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000142, mae: 0.006745, mean_q: 0.009662
  3591/100000: episode: 496, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000354, mae: 0.009214, mean_q: 0.009306
  3599/100000: episode: 497, duration: 0.052s, episode steps: 8, steps per second: 155, episode reward: 0.065, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000537, mae: 0.010060, mean_q: 0.009303
  3607/100000: episode: 498, duration: 0.042s, episode steps: 8, steps per second: 189, episode reward: 0.028, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000338, mae: 0.009408, mean_q: 0.012178
  3615/100000: episode: 499, duration: 0.045s, episode steps: 8, steps per second: 180, episode reward: 0.032, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000680, mae: 0.014630, mean_q: 0.015420
  3623/100000: episode: 500, duration: 0.043s, episode steps: 8, steps per second: 186, episode reward: 0.263, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.938 [-1.000, 11.000], loss: 0.000437, mae: 0.013220, mean_q: 0.015473
  3631/100000: episode: 501, duration: 0.037s, episode steps: 8, steps per second: 216, episode reward: 0.082, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000298, mae: 0.010061, mean_q: 0.013235
  3639/100000: episode: 502, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.055, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000377, mae: 0.010679, mean_q: 0.014461
  3647/100000: episode: 503, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.033, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000221, mae: 0.009063, mean_q: 0.013425
  3655/100000: episode: 504, duration: 0.036s, episode steps: 8, steps per second: 220, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000501, mae: 0.009966, mean_q: 0.008359
  3663/100000: episode: 505, duration: 0.040s, episode steps: 8, steps per second: 202, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000201, mae: 0.008524, mean_q: 0.010483
  3671/100000: episode: 506, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.055, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000318, mae: 0.011127, mean_q: 0.014288
  3679/100000: episode: 507, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.214, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000385, mae: 0.011182, mean_q: 0.015208
  3687/100000: episode: 508, duration: 0.041s, episode steps: 8, steps per second: 195, episode reward: 0.035, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001650, mae: 0.014905, mean_q: 0.015855
  3695/100000: episode: 509, duration: 0.037s, episode steps: 8, steps per second: 216, episode reward: 0.032, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000183, mae: 0.010128, mean_q: 0.013257
  3703/100000: episode: 510, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000446, mae: 0.011784, mean_q: 0.014914
  3711/100000: episode: 511, duration: 0.042s, episode steps: 8, steps per second: 189, episode reward: 0.081, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000385, mae: 0.008509, mean_q: 0.009650
  3719/100000: episode: 512, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000129, mae: 0.006584, mean_q: 0.006828
  3727/100000: episode: 513, duration: 0.041s, episode steps: 8, steps per second: 196, episode reward: 0.146, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000105, mae: 0.006699, mean_q: 0.009054
  3735/100000: episode: 514, duration: 0.037s, episode steps: 8, steps per second: 217, episode reward: 0.059, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.002141, mae: 0.012842, mean_q: 0.008749
  3743/100000: episode: 515, duration: 0.037s, episode steps: 8, steps per second: 216, episode reward: 0.085, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000189, mae: 0.010729, mean_q: 0.013451
[Info] 2-TH LEVEL FOUND: 0.13766755163669586, Considering 11/100 traces
  3751/100000: episode: 516, duration: 0.718s, episode steps: 8, steps per second: 11, episode reward: 0.214, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.001964, mae: 0.014920, mean_q: 0.017762
  3756/100000: episode: 517, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000380, mae: 0.014695, mean_q: 0.020895
  3761/100000: episode: 518, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000165, mae: 0.009194, mean_q: 0.014469
  3766/100000: episode: 519, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000183, mae: 0.007306, mean_q: 0.008402
  3771/100000: episode: 520, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000302, mae: 0.008692, mean_q: 0.012001
  3776/100000: episode: 521, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000647, mae: 0.011187, mean_q: 0.007300
  3781/100000: episode: 522, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000114, mae: 0.006667, mean_q: 0.009031
  3786/100000: episode: 523, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000294, mae: 0.011965, mean_q: 0.014704
  3791/100000: episode: 524, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002800, mae: 0.014880, mean_q: 0.014165
  3796/100000: episode: 525, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000558, mae: 0.014842, mean_q: 0.017686
  3801/100000: episode: 526, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000194, mae: 0.009481, mean_q: 0.014778
  3806/100000: episode: 527, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000269, mae: 0.008797, mean_q: 0.015260
[Info] FALSIFICATION!
  3810/100000: episode: 528, duration: 0.263s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000427, mae: 0.009634, mean_q: 0.013206
  3815/100000: episode: 529, duration: 0.031s, episode steps: 5, steps per second: 162, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000455, mae: 0.011665, mean_q: 0.012177
  3820/100000: episode: 530, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000307, mae: 0.008160, mean_q: 0.010064
  3825/100000: episode: 531, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002166, mae: 0.014551, mean_q: 0.013428
  3830/100000: episode: 532, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000262, mae: 0.009410, mean_q: 0.010839
  3835/100000: episode: 533, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000468, mae: 0.010727, mean_q: 0.011915
  3840/100000: episode: 534, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000369, mae: 0.010995, mean_q: 0.013628
  3845/100000: episode: 535, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000264, mae: 0.010942, mean_q: 0.015028
  3850/100000: episode: 536, duration: 0.024s, episode steps: 5, steps per second: 205, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000340, mae: 0.011117, mean_q: 0.016565
  3855/100000: episode: 537, duration: 0.024s, episode steps: 5, steps per second: 208, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002223, mae: 0.014449, mean_q: 0.014549
  3860/100000: episode: 538, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000188, mae: 0.008374, mean_q: 0.009435
  3865/100000: episode: 539, duration: 0.024s, episode steps: 5, steps per second: 204, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000274, mae: 0.009561, mean_q: 0.009999
  3870/100000: episode: 540, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002280, mae: 0.014978, mean_q: 0.013080
  3875/100000: episode: 541, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002827, mae: 0.017088, mean_q: 0.016904
  3880/100000: episode: 542, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000500, mae: 0.014270, mean_q: 0.021200
[Info] FALSIFICATION!
  3884/100000: episode: 543, duration: 0.175s, episode steps: 4, steps per second: 23, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000451, mae: 0.013378, mean_q: 0.020626
  3889/100000: episode: 544, duration: 0.032s, episode steps: 5, steps per second: 155, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000715, mae: 0.016737, mean_q: 0.019381
  3894/100000: episode: 545, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.004839, mae: 0.022995, mean_q: 0.011152
  3899/100000: episode: 546, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000301, mae: 0.011339, mean_q: 0.014666
  3904/100000: episode: 547, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000477, mae: 0.014394, mean_q: 0.019464
[Info] FALSIFICATION!
  3908/100000: episode: 548, duration: 0.173s, episode steps: 4, steps per second: 23, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000512, mae: 0.016033, mean_q: 0.018136
  3913/100000: episode: 549, duration: 0.028s, episode steps: 5, steps per second: 179, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000600, mae: 0.011128, mean_q: 0.010607
  3918/100000: episode: 550, duration: 0.029s, episode steps: 5, steps per second: 173, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.006739, mae: 0.027780, mean_q: 0.020135
  3923/100000: episode: 551, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.004007, mae: 0.036391, mean_q: 0.044792
  3928/100000: episode: 552, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000265, mae: 0.010148, mean_q: 0.019570
  3933/100000: episode: 553, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000657, mae: 0.014706, mean_q: 0.019805
  3938/100000: episode: 554, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000650, mae: 0.013966, mean_q: 0.009088
  3943/100000: episode: 555, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000336, mae: 0.011471, mean_q: 0.004129
  3948/100000: episode: 556, duration: 0.025s, episode steps: 5, steps per second: 204, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000736, mae: 0.014207, mean_q: 0.009897
  3953/100000: episode: 557, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000367, mae: 0.012764, mean_q: 0.014251
  3958/100000: episode: 558, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000231, mae: 0.011262, mean_q: 0.014203
  3963/100000: episode: 559, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000537, mae: 0.016060, mean_q: 0.016100
[Info] FALSIFICATION!
  3967/100000: episode: 560, duration: 0.175s, episode steps: 4, steps per second: 23, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000437, mae: 0.015628, mean_q: 0.015829
  3972/100000: episode: 561, duration: 0.028s, episode steps: 5, steps per second: 179, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000958, mae: 0.019556, mean_q: 0.023095
  3977/100000: episode: 562, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000333, mae: 0.016537, mean_q: 0.023137
  3982/100000: episode: 563, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000773, mae: 0.014460, mean_q: 0.015613
  3987/100000: episode: 564, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000536, mae: 0.014201, mean_q: 0.019370
  3992/100000: episode: 565, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000463, mae: 0.011157, mean_q: 0.012551
  3997/100000: episode: 566, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001140, mae: 0.017421, mean_q: 0.016522
  4002/100000: episode: 567, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000423, mae: 0.013172, mean_q: 0.018720
  4007/100000: episode: 568, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000542, mae: 0.012699, mean_q: 0.017439
  4012/100000: episode: 569, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000750, mae: 0.013248, mean_q: 0.018816
  4017/100000: episode: 570, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000724, mae: 0.014732, mean_q: 0.014947
  4022/100000: episode: 571, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000341, mae: 0.010495, mean_q: 0.016971
  4027/100000: episode: 572, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.003132, mae: 0.020467, mean_q: 0.017618
  4032/100000: episode: 573, duration: 0.024s, episode steps: 5, steps per second: 205, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002221, mae: 0.020330, mean_q: 0.025215
  4037/100000: episode: 574, duration: 0.024s, episode steps: 5, steps per second: 205, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002195, mae: 0.020435, mean_q: 0.028203
  4042/100000: episode: 575, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000475, mae: 0.012878, mean_q: 0.018495
[Info] FALSIFICATION!
  4046/100000: episode: 576, duration: 0.264s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000607, mae: 0.011652, mean_q: 0.012096
  4051/100000: episode: 577, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.002629, mae: 0.018352, mean_q: 0.016171
  4056/100000: episode: 578, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000448, mae: 0.012782, mean_q: 0.013678
  4061/100000: episode: 579, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000751, mae: 0.014652, mean_q: 0.020758
  4066/100000: episode: 580, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000471, mae: 0.013928, mean_q: 0.018658
  4071/100000: episode: 581, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000652, mae: 0.014699, mean_q: 0.022753
  4076/100000: episode: 582, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000589, mae: 0.012020, mean_q: 0.008943
  4081/100000: episode: 583, duration: 0.035s, episode steps: 5, steps per second: 141, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.003488, mae: 0.019360, mean_q: 0.012454
  4086/100000: episode: 584, duration: 0.035s, episode steps: 5, steps per second: 143, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002520, mae: 0.022269, mean_q: 0.021104
  4091/100000: episode: 585, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000854, mae: 0.021603, mean_q: 0.029562
  4096/100000: episode: 586, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000630, mae: 0.017248, mean_q: 0.028000
  4101/100000: episode: 587, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000526, mae: 0.015043, mean_q: 0.022934
  4106/100000: episode: 588, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000518, mae: 0.013810, mean_q: 0.013875
[Info] FALSIFICATION!
  4110/100000: episode: 589, duration: 0.231s, episode steps: 4, steps per second: 17, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000903, mae: 0.015688, mean_q: 0.010926
  4115/100000: episode: 590, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.003935, mae: 0.021122, mean_q: 0.010816
  4120/100000: episode: 591, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000433, mae: 0.014339, mean_q: 0.019767
  4125/100000: episode: 592, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000863, mae: 0.018772, mean_q: 0.021066
[Info] FALSIFICATION!
  4129/100000: episode: 593, duration: 0.200s, episode steps: 4, steps per second: 20, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000620, mae: 0.017459, mean_q: 0.021346
  4134/100000: episode: 594, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000867, mae: 0.017934, mean_q: 0.023829
  4139/100000: episode: 595, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002467, mae: 0.020259, mean_q: 0.020165
  4144/100000: episode: 596, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.004953, mae: 0.026895, mean_q: 0.024975
  4149/100000: episode: 597, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.001056, mae: 0.019934, mean_q: 0.032137
  4154/100000: episode: 598, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000625, mae: 0.013067, mean_q: 0.020669
  4159/100000: episode: 599, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002245, mae: 0.018145, mean_q: 0.015210
  4164/100000: episode: 600, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002793, mae: 0.017184, mean_q: 0.018239
  4169/100000: episode: 601, duration: 0.029s, episode steps: 5, steps per second: 173, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001335, mae: 0.021591, mean_q: 0.031031
  4174/100000: episode: 602, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002124, mae: 0.020124, mean_q: 0.023675
  4179/100000: episode: 603, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000908, mae: 0.017736, mean_q: 0.027426
  4184/100000: episode: 604, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002215, mae: 0.020088, mean_q: 0.024601
[Info] Complete ISplit Iteration
[Info] Levels: [0.042913068, 0.13766755, 0.27529913]
[Info] Cond. Prob: [0.12, 0.11, 0.07]
[Info] Error Prob: 0.0009240000000000001

  4189/100000: episode: 605, duration: 0.908s, episode steps: 5, steps per second: 6, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000590, mae: 0.015975, mean_q: 0.019938
  4199/100000: episode: 606, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002832, mae: 0.018311, mean_q: 0.013097
  4209/100000: episode: 607, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002052, mae: 0.022052, mean_q: 0.024433
  4219/100000: episode: 608, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001139, mae: 0.023030, mean_q: 0.029087
  4229/100000: episode: 609, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000532, mae: 0.012584, mean_q: 0.012438
  4239/100000: episode: 610, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001471, mae: 0.015591, mean_q: 0.012729
  4249/100000: episode: 611, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002593, mae: 0.022420, mean_q: 0.025437
  4259/100000: episode: 612, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001761, mae: 0.020122, mean_q: 0.030118
  4269/100000: episode: 613, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001822, mae: 0.018311, mean_q: 0.020735
  4279/100000: episode: 614, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000822, mae: 0.016358, mean_q: 0.015785
  4289/100000: episode: 615, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000730, mae: 0.015330, mean_q: 0.018126
  4299/100000: episode: 616, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002366, mae: 0.018923, mean_q: 0.016379
  4309/100000: episode: 617, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002370, mae: 0.023975, mean_q: 0.033344
  4319/100000: episode: 618, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002661, mae: 0.022660, mean_q: 0.032164
  4329/100000: episode: 619, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002685, mae: 0.021061, mean_q: 0.019905
  4339/100000: episode: 620, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001493, mae: 0.018325, mean_q: 0.021206
  4349/100000: episode: 621, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000914, mae: 0.017753, mean_q: 0.020866
  4359/100000: episode: 622, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001369, mae: 0.018109, mean_q: 0.021376
  4369/100000: episode: 623, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002955, mae: 0.022872, mean_q: 0.021790
  4379/100000: episode: 624, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001542, mae: 0.015309, mean_q: 0.022527
  4389/100000: episode: 625, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003455, mae: 0.028030, mean_q: 0.038043
  4399/100000: episode: 626, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.003875, mae: 0.028384, mean_q: 0.032495
  4409/100000: episode: 627, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002229, mae: 0.022273, mean_q: 0.027578
  4419/100000: episode: 628, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001534, mae: 0.012390, mean_q: 0.016329
  4429/100000: episode: 629, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000733, mae: 0.016164, mean_q: 0.020129
  4439/100000: episode: 630, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001782, mae: 0.019523, mean_q: 0.017288
  4449/100000: episode: 631, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002529, mae: 0.022256, mean_q: 0.023566
  4459/100000: episode: 632, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000815, mae: 0.019642, mean_q: 0.030481
  4469/100000: episode: 633, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002341, mae: 0.023727, mean_q: 0.028309
  4479/100000: episode: 634, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.003140, mae: 0.024149, mean_q: 0.027110
  4489/100000: episode: 635, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002645, mae: 0.023485, mean_q: 0.030929
  4499/100000: episode: 636, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002357, mae: 0.017648, mean_q: 0.022385
  4509/100000: episode: 637, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001479, mae: 0.018596, mean_q: 0.021687
  4519/100000: episode: 638, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001887, mae: 0.018678, mean_q: 0.025553
  4529/100000: episode: 639, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002309, mae: 0.019000, mean_q: 0.026655
  4539/100000: episode: 640, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001812, mae: 0.020078, mean_q: 0.027580
  4549/100000: episode: 641, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.003357, mae: 0.018660, mean_q: 0.017038
  4559/100000: episode: 642, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.004529, mae: 0.028666, mean_q: 0.034268
  4569/100000: episode: 643, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001673, mae: 0.019411, mean_q: 0.028436
  4579/100000: episode: 644, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002440, mae: 0.023540, mean_q: 0.020146
  4589/100000: episode: 645, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002007, mae: 0.019492, mean_q: 0.022178
  4599/100000: episode: 646, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001960, mae: 0.022147, mean_q: 0.029340
  4609/100000: episode: 647, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.004201, mae: 0.029609, mean_q: 0.033226
  4619/100000: episode: 648, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001909, mae: 0.024381, mean_q: 0.032326
  4629/100000: episode: 649, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.003142, mae: 0.021338, mean_q: 0.014851
  4639/100000: episode: 650, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000735, mae: 0.016210, mean_q: 0.019870
  4649/100000: episode: 651, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002257, mae: 0.020562, mean_q: 0.019956
  4659/100000: episode: 652, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001000, mae: 0.019754, mean_q: 0.028448
  4669/100000: episode: 653, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002687, mae: 0.022181, mean_q: 0.022313
  4679/100000: episode: 654, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001185, mae: 0.014396, mean_q: 0.017681
  4689/100000: episode: 655, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001672, mae: 0.017584, mean_q: 0.023435
  4699/100000: episode: 656, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001288, mae: 0.015330, mean_q: 0.016599
  4709/100000: episode: 657, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000519, mae: 0.014855, mean_q: 0.017643
  4719/100000: episode: 658, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001031, mae: 0.016852, mean_q: 0.014293
  4729/100000: episode: 659, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002169, mae: 0.019164, mean_q: 0.019015
  4739/100000: episode: 660, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002670, mae: 0.028290, mean_q: 0.038813
  4749/100000: episode: 661, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002398, mae: 0.023074, mean_q: 0.029992
  4759/100000: episode: 662, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001432, mae: 0.018300, mean_q: 0.026716
  4769/100000: episode: 663, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.003457, mae: 0.023266, mean_q: 0.016091
  4779/100000: episode: 664, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002056, mae: 0.021959, mean_q: 0.027475
  4789/100000: episode: 665, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001052, mae: 0.020012, mean_q: 0.028183
  4799/100000: episode: 666, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.003216, mae: 0.019691, mean_q: 0.015513
  4809/100000: episode: 667, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000591, mae: 0.015227, mean_q: 0.020033
  4819/100000: episode: 668, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000540, mae: 0.015848, mean_q: 0.021009
  4829/100000: episode: 669, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000840, mae: 0.014552, mean_q: 0.012429
  4839/100000: episode: 670, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001562, mae: 0.017714, mean_q: 0.018449
  4849/100000: episode: 671, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001865, mae: 0.020980, mean_q: 0.025090
  4859/100000: episode: 672, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001282, mae: 0.024316, mean_q: 0.031687
  4869/100000: episode: 673, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001774, mae: 0.020473, mean_q: 0.020988
  4879/100000: episode: 674, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001465, mae: 0.016646, mean_q: 0.015590
  4889/100000: episode: 675, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001607, mae: 0.021129, mean_q: 0.027929
  4899/100000: episode: 676, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000718, mae: 0.017302, mean_q: 0.023726
  4909/100000: episode: 677, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000655, mae: 0.017864, mean_q: 0.024003
  4919/100000: episode: 678, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.004198, mae: 0.026939, mean_q: 0.026503
  4929/100000: episode: 679, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001097, mae: 0.018659, mean_q: 0.030742
  4939/100000: episode: 680, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.003247, mae: 0.023212, mean_q: 0.021126
  4949/100000: episode: 681, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001912, mae: 0.019126, mean_q: 0.024394
  4959/100000: episode: 682, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001919, mae: 0.018195, mean_q: 0.018693
  4969/100000: episode: 683, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002108, mae: 0.018473, mean_q: 0.016738
  4979/100000: episode: 684, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001507, mae: 0.021483, mean_q: 0.023783
  4989/100000: episode: 685, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002000, mae: 0.020676, mean_q: 0.022160
  4999/100000: episode: 686, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000538, mae: 0.014410, mean_q: 0.016718
  5009/100000: episode: 687, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001676, mae: 0.019004, mean_q: 0.019857
  5019/100000: episode: 688, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001801, mae: 0.017835, mean_q: 0.017829
  5029/100000: episode: 689, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001837, mae: 0.022428, mean_q: 0.029312
  5039/100000: episode: 690, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.005187, mae: 0.029774, mean_q: 0.030003
  5049/100000: episode: 691, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002106, mae: 0.023292, mean_q: 0.035930
  5059/100000: episode: 692, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001046, mae: 0.017572, mean_q: 0.022276
  5069/100000: episode: 693, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000893, mae: 0.014082, mean_q: 0.009026
  5079/100000: episode: 694, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.004017, mae: 0.023443, mean_q: 0.017121
  5089/100000: episode: 695, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002167, mae: 0.026228, mean_q: 0.035989
  5099/100000: episode: 696, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001956, mae: 0.023823, mean_q: 0.028578
  5109/100000: episode: 697, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001920, mae: 0.014598, mean_q: 0.011761
  5119/100000: episode: 698, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002740, mae: 0.021403, mean_q: 0.023160
  5129/100000: episode: 699, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000826, mae: 0.017725, mean_q: 0.024636
  5139/100000: episode: 700, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000961, mae: 0.018798, mean_q: 0.021369
  5149/100000: episode: 701, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002512, mae: 0.018550, mean_q: 0.019034
  5159/100000: episode: 702, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002353, mae: 0.021020, mean_q: 0.029374
  5169/100000: episode: 703, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001028, mae: 0.018893, mean_q: 0.025907
  5179/100000: episode: 704, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001838, mae: 0.017815, mean_q: 0.020650
[Info] 1-TH LEVEL FOUND: 0.0063184755854308605, Considering 100/100 traces
  5189/100000: episode: 705, duration: 0.684s, episode steps: 10, steps per second: 15, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002853, mae: 0.018999, mean_q: 0.019755
[Info] 2-TH LEVEL FOUND: 0.007637710310518742, Considering 100/100 traces
  5199/100000: episode: 706, duration: 0.697s, episode steps: 10, steps per second: 14, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002858, mae: 0.023638, mean_q: 0.034087
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.007637710310518742
  5209/100000: episode: 707, duration: 0.508s, episode steps: 10, steps per second: 20, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001358, mae: 0.020597, mean_q: 0.031270
  5219/100000: episode: 708, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002031, mae: 0.017914, mean_q: 0.011815
  5229/100000: episode: 709, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.003749, mae: 0.023699, mean_q: 0.021174
  5239/100000: episode: 710, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001837, mae: 0.019307, mean_q: 0.025513
  5249/100000: episode: 711, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000656, mae: 0.013900, mean_q: 0.020608
  5259/100000: episode: 712, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001176, mae: 0.015694, mean_q: 0.020255
  5269/100000: episode: 713, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002561, mae: 0.021815, mean_q: 0.022838
  5279/100000: episode: 714, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001747, mae: 0.020479, mean_q: 0.030087
  5289/100000: episode: 715, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000986, mae: 0.018621, mean_q: 0.025773
  5299/100000: episode: 716, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002103, mae: 0.019687, mean_q: 0.016497
  5309/100000: episode: 717, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.003829, mae: 0.027968, mean_q: 0.030441
  5319/100000: episode: 718, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002143, mae: 0.022199, mean_q: 0.026481
  5329/100000: episode: 719, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001107, mae: 0.015704, mean_q: 0.021603
  5339/100000: episode: 720, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002254, mae: 0.024194, mean_q: 0.030392
  5349/100000: episode: 721, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001976, mae: 0.018735, mean_q: 0.019221
  5359/100000: episode: 722, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000849, mae: 0.015858, mean_q: 0.015999
  5369/100000: episode: 723, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001838, mae: 0.018948, mean_q: 0.020272
  5379/100000: episode: 724, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001883, mae: 0.020925, mean_q: 0.021072
  5389/100000: episode: 725, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002158, mae: 0.019041, mean_q: 0.020298
  5399/100000: episode: 726, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002636, mae: 0.024027, mean_q: 0.025298
  5409/100000: episode: 727, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001324, mae: 0.020027, mean_q: 0.029626
  5419/100000: episode: 728, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.003436, mae: 0.024174, mean_q: 0.030501
  5429/100000: episode: 729, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002303, mae: 0.024330, mean_q: 0.033932
  5439/100000: episode: 730, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001459, mae: 0.017175, mean_q: 0.025465
  5449/100000: episode: 731, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001993, mae: 0.020980, mean_q: 0.025660
  5459/100000: episode: 732, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002446, mae: 0.021279, mean_q: 0.024933
  5469/100000: episode: 733, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000820, mae: 0.015965, mean_q: 0.018562
  5479/100000: episode: 734, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002354, mae: 0.019214, mean_q: 0.018053
  5489/100000: episode: 735, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.003179, mae: 0.025993, mean_q: 0.028195
  5499/100000: episode: 736, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000804, mae: 0.017741, mean_q: 0.021853
  5509/100000: episode: 737, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000748, mae: 0.014960, mean_q: 0.016788
  5519/100000: episode: 738, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001225, mae: 0.016392, mean_q: 0.014146
  5529/100000: episode: 739, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000617, mae: 0.017410, mean_q: 0.021759
  5539/100000: episode: 740, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001705, mae: 0.017833, mean_q: 0.020075
  5549/100000: episode: 741, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000835, mae: 0.020171, mean_q: 0.025131
  5559/100000: episode: 742, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001492, mae: 0.018681, mean_q: 0.021497
  5569/100000: episode: 743, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000671, mae: 0.017951, mean_q: 0.025567
  5579/100000: episode: 744, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001725, mae: 0.016748, mean_q: 0.019048
  5589/100000: episode: 745, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000490, mae: 0.014426, mean_q: 0.020503
  5599/100000: episode: 746, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001463, mae: 0.019126, mean_q: 0.022341
  5609/100000: episode: 747, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002944, mae: 0.023422, mean_q: 0.027572
  5619/100000: episode: 748, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001355, mae: 0.020147, mean_q: 0.023833
  5629/100000: episode: 749, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000619, mae: 0.013672, mean_q: 0.015470
  5639/100000: episode: 750, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001931, mae: 0.016348, mean_q: 0.014681
  5649/100000: episode: 751, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001222, mae: 0.019021, mean_q: 0.023151
  5659/100000: episode: 752, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001314, mae: 0.018732, mean_q: 0.027303
  5669/100000: episode: 753, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001070, mae: 0.020510, mean_q: 0.029674
  5679/100000: episode: 754, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001962, mae: 0.014424, mean_q: 0.011465
  5689/100000: episode: 755, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001661, mae: 0.018504, mean_q: 0.023300
  5699/100000: episode: 756, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000764, mae: 0.017156, mean_q: 0.027051
  5709/100000: episode: 757, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001900, mae: 0.016605, mean_q: 0.016289
  5719/100000: episode: 758, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001797, mae: 0.015915, mean_q: 0.016216
  5729/100000: episode: 759, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000809, mae: 0.017598, mean_q: 0.025552
  5739/100000: episode: 760, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001359, mae: 0.019606, mean_q: 0.028709
  5749/100000: episode: 761, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001974, mae: 0.022411, mean_q: 0.025594
  5759/100000: episode: 762, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001273, mae: 0.015869, mean_q: 0.016751
  5769/100000: episode: 763, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001025, mae: 0.015313, mean_q: 0.018558
  5779/100000: episode: 764, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000534, mae: 0.014546, mean_q: 0.017868
  5789/100000: episode: 765, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000467, mae: 0.014523, mean_q: 0.018982
  5799/100000: episode: 766, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.004019, mae: 0.026094, mean_q: 0.028206
  5809/100000: episode: 767, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002059, mae: 0.023363, mean_q: 0.033080
  5819/100000: episode: 768, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000328, mae: 0.009636, mean_q: 0.011071
  5829/100000: episode: 769, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002030, mae: 0.015599, mean_q: 0.010506
  5839/100000: episode: 770, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001141, mae: 0.017624, mean_q: 0.022826
  5849/100000: episode: 771, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001968, mae: 0.017835, mean_q: 0.021479
  5859/100000: episode: 772, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001892, mae: 0.022586, mean_q: 0.028679
  5869/100000: episode: 773, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001278, mae: 0.018463, mean_q: 0.026324
  5879/100000: episode: 774, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000931, mae: 0.013713, mean_q: 0.018796
  5889/100000: episode: 775, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001507, mae: 0.020169, mean_q: 0.026274
  5899/100000: episode: 776, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003547, mae: 0.027765, mean_q: 0.032015
  5909/100000: episode: 777, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001174, mae: 0.017057, mean_q: 0.030182
  5919/100000: episode: 778, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000642, mae: 0.012484, mean_q: 0.015013
  5929/100000: episode: 779, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002057, mae: 0.017152, mean_q: 0.016988
  5939/100000: episode: 780, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001209, mae: 0.019517, mean_q: 0.026102
  5949/100000: episode: 781, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000697, mae: 0.015387, mean_q: 0.023254
  5959/100000: episode: 782, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001322, mae: 0.016619, mean_q: 0.018998
  5969/100000: episode: 783, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.003042, mae: 0.020593, mean_q: 0.023142
  5979/100000: episode: 784, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002258, mae: 0.022143, mean_q: 0.034176
  5989/100000: episode: 785, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001312, mae: 0.020585, mean_q: 0.023787
  5999/100000: episode: 786, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000938, mae: 0.012689, mean_q: 0.016898
  6009/100000: episode: 787, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002420, mae: 0.018274, mean_q: 0.018101
  6019/100000: episode: 788, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001813, mae: 0.018617, mean_q: 0.021155
  6029/100000: episode: 789, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.004643, mae: 0.027460, mean_q: 0.027725
  6039/100000: episode: 790, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002670, mae: 0.030283, mean_q: 0.042651
  6049/100000: episode: 791, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.003242, mae: 0.021711, mean_q: 0.018019
  6059/100000: episode: 792, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.003446, mae: 0.024584, mean_q: 0.023237
  6069/100000: episode: 793, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001835, mae: 0.021802, mean_q: 0.027203
  6079/100000: episode: 794, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002478, mae: 0.023115, mean_q: 0.024634
  6089/100000: episode: 795, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002244, mae: 0.021458, mean_q: 0.023498
  6099/100000: episode: 796, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000602, mae: 0.014916, mean_q: 0.025071
  6109/100000: episode: 797, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002067, mae: 0.022816, mean_q: 0.030826
  6119/100000: episode: 798, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001901, mae: 0.017817, mean_q: 0.017699
  6129/100000: episode: 799, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000816, mae: 0.015360, mean_q: 0.019085
  6139/100000: episode: 800, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002387, mae: 0.021102, mean_q: 0.023877
  6149/100000: episode: 801, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001398, mae: 0.020608, mean_q: 0.036075
  6159/100000: episode: 802, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000846, mae: 0.013905, mean_q: 0.013398
  6169/100000: episode: 803, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001276, mae: 0.013147, mean_q: 0.011102
  6179/100000: episode: 804, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000577, mae: 0.014321, mean_q: 0.019972
  6189/100000: episode: 805, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001714, mae: 0.018783, mean_q: 0.021889
  6199/100000: episode: 806, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001503, mae: 0.012624, mean_q: 0.012291
[Info] 1-TH LEVEL FOUND: 0.009375366382300854, Considering 100/100 traces
  6209/100000: episode: 807, duration: 0.725s, episode steps: 10, steps per second: 14, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002752, mae: 0.021321, mean_q: 0.025475
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.009375366382300854
  6219/100000: episode: 808, duration: 0.587s, episode steps: 10, steps per second: 17, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001119, mae: 0.016273, mean_q: 0.026807
  6229/100000: episode: 809, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002276, mae: 0.018116, mean_q: 0.019231
  6239/100000: episode: 810, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001022, mae: 0.013699, mean_q: 0.017056
  6249/100000: episode: 811, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001932, mae: 0.017394, mean_q: 0.021580
  6259/100000: episode: 812, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000816, mae: 0.015025, mean_q: 0.025818
  6269/100000: episode: 813, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001312, mae: 0.018013, mean_q: 0.024430
  6279/100000: episode: 814, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000701, mae: 0.014360, mean_q: 0.017860
  6289/100000: episode: 815, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.003727, mae: 0.021634, mean_q: 0.018580
  6299/100000: episode: 816, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001520, mae: 0.021248, mean_q: 0.032591
  6309/100000: episode: 817, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000704, mae: 0.013435, mean_q: 0.020756
  6319/100000: episode: 818, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001711, mae: 0.016675, mean_q: 0.018595
  6329/100000: episode: 819, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001556, mae: 0.012905, mean_q: 0.013927
  6339/100000: episode: 820, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001110, mae: 0.014231, mean_q: 0.020477
  6349/100000: episode: 821, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001594, mae: 0.015494, mean_q: 0.019206
  6359/100000: episode: 822, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001121, mae: 0.015711, mean_q: 0.023736
  6369/100000: episode: 823, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000439, mae: 0.012179, mean_q: 0.018661
  6379/100000: episode: 824, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001041, mae: 0.014540, mean_q: 0.020820
  6389/100000: episode: 825, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001707, mae: 0.016556, mean_q: 0.022695
  6399/100000: episode: 826, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001707, mae: 0.018983, mean_q: 0.020017
  6409/100000: episode: 827, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001079, mae: 0.015022, mean_q: 0.020667
  6419/100000: episode: 828, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001187, mae: 0.016820, mean_q: 0.026570
  6429/100000: episode: 829, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000509, mae: 0.011348, mean_q: 0.012228
  6439/100000: episode: 830, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000816, mae: 0.012904, mean_q: 0.013398
  6449/100000: episode: 831, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001997, mae: 0.019568, mean_q: 0.024151
  6459/100000: episode: 832, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000805, mae: 0.016557, mean_q: 0.024916
  6469/100000: episode: 833, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000303, mae: 0.009204, mean_q: 0.012844
  6479/100000: episode: 834, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002266, mae: 0.014298, mean_q: 0.015071
  6489/100000: episode: 835, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001404, mae: 0.012297, mean_q: 0.015950
  6499/100000: episode: 836, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000572, mae: 0.012053, mean_q: 0.015208
  6509/100000: episode: 837, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000327, mae: 0.009212, mean_q: 0.011564
  6519/100000: episode: 838, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000337, mae: 0.009078, mean_q: 0.013056
  6529/100000: episode: 839, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000519, mae: 0.011226, mean_q: 0.015519
  6539/100000: episode: 840, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000883, mae: 0.011706, mean_q: 0.015643
  6549/100000: episode: 841, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000725, mae: 0.011655, mean_q: 0.013324
  6559/100000: episode: 842, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002742, mae: 0.016002, mean_q: 0.015669
  6569/100000: episode: 843, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001805, mae: 0.016650, mean_q: 0.020441
  6579/100000: episode: 844, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001091, mae: 0.014637, mean_q: 0.023792
  6589/100000: episode: 845, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000820, mae: 0.011362, mean_q: 0.014382
  6599/100000: episode: 846, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001066, mae: 0.012810, mean_q: 0.014792
  6609/100000: episode: 847, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001439, mae: 0.009400, mean_q: 0.010893
  6619/100000: episode: 848, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000788, mae: 0.012447, mean_q: 0.017819
  6629/100000: episode: 849, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000837, mae: 0.013094, mean_q: 0.017800
  6639/100000: episode: 850, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000564, mae: 0.012710, mean_q: 0.017301
  6649/100000: episode: 851, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000414, mae: 0.010819, mean_q: 0.016677
  6659/100000: episode: 852, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000404, mae: 0.010954, mean_q: 0.011975
  6669/100000: episode: 853, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000584, mae: 0.011280, mean_q: 0.014231
  6679/100000: episode: 854, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001800, mae: 0.016532, mean_q: 0.017927
  6689/100000: episode: 855, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001502, mae: 0.014564, mean_q: 0.016627
  6699/100000: episode: 856, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000571, mae: 0.012810, mean_q: 0.018431
  6709/100000: episode: 857, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000856, mae: 0.015174, mean_q: 0.019578
  6719/100000: episode: 858, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002109, mae: 0.015167, mean_q: 0.012232
  6729/100000: episode: 859, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000978, mae: 0.013192, mean_q: 0.016917
  6739/100000: episode: 860, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000510, mae: 0.012083, mean_q: 0.016926
  6749/100000: episode: 861, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002156, mae: 0.014896, mean_q: 0.015197
  6759/100000: episode: 862, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000318, mae: 0.011432, mean_q: 0.019545
  6769/100000: episode: 863, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000152, mae: 0.007144, mean_q: 0.010323
  6779/100000: episode: 864, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000851, mae: 0.011106, mean_q: 0.014982
  6789/100000: episode: 865, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001665, mae: 0.012859, mean_q: 0.011961
  6799/100000: episode: 866, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000684, mae: 0.011506, mean_q: 0.013665
  6809/100000: episode: 867, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001460, mae: 0.016899, mean_q: 0.021944
  6819/100000: episode: 868, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000712, mae: 0.013961, mean_q: 0.024127
  6829/100000: episode: 869, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000617, mae: 0.009395, mean_q: 0.013253
  6839/100000: episode: 870, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001316, mae: 0.013501, mean_q: 0.015845
  6849/100000: episode: 871, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001300, mae: 0.017761, mean_q: 0.022141
  6859/100000: episode: 872, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002524, mae: 0.021582, mean_q: 0.026185
  6869/100000: episode: 873, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000952, mae: 0.014820, mean_q: 0.024632
  6879/100000: episode: 874, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000405, mae: 0.009066, mean_q: 0.007870
  6889/100000: episode: 875, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000543, mae: 0.010993, mean_q: 0.012717
  6899/100000: episode: 876, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000428, mae: 0.010177, mean_q: 0.011527
  6909/100000: episode: 877, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001023, mae: 0.014374, mean_q: 0.015922
  6919/100000: episode: 878, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000534, mae: 0.011613, mean_q: 0.015688
  6929/100000: episode: 879, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000663, mae: 0.013419, mean_q: 0.022535
  6939/100000: episode: 880, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002521, mae: 0.015793, mean_q: 0.017963
  6949/100000: episode: 881, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002242, mae: 0.016424, mean_q: 0.024751
  6959/100000: episode: 882, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000830, mae: 0.012338, mean_q: 0.021422
  6969/100000: episode: 883, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000766, mae: 0.009674, mean_q: 0.014422
  6979/100000: episode: 884, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000652, mae: 0.012309, mean_q: 0.013702
  6989/100000: episode: 885, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000613, mae: 0.012326, mean_q: 0.011399
  6999/100000: episode: 886, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001248, mae: 0.014687, mean_q: 0.017074
  7009/100000: episode: 887, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001104, mae: 0.016760, mean_q: 0.020726
  7019/100000: episode: 888, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000865, mae: 0.013816, mean_q: 0.020599
  7029/100000: episode: 889, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002345, mae: 0.017482, mean_q: 0.018677
  7039/100000: episode: 890, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001692, mae: 0.015702, mean_q: 0.020791
  7049/100000: episode: 891, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000339, mae: 0.008532, mean_q: 0.012418
  7059/100000: episode: 892, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.001050, mae: 0.013880, mean_q: 0.017906
  7069/100000: episode: 893, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000904, mae: 0.013427, mean_q: 0.015870
  7079/100000: episode: 894, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.002903, mae: 0.019342, mean_q: 0.017082
  7089/100000: episode: 895, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000918, mae: 0.014475, mean_q: 0.021838
  7099/100000: episode: 896, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000819, mae: 0.011287, mean_q: 0.013182
  7109/100000: episode: 897, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000514, mae: 0.011117, mean_q: 0.010733
  7119/100000: episode: 898, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.002525, mae: 0.023460, mean_q: 0.025019
  7129/100000: episode: 899, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000691, mae: 0.013873, mean_q: 0.019865
  7139/100000: episode: 900, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001523, mae: 0.014604, mean_q: 0.019477
  7149/100000: episode: 901, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000772, mae: 0.009713, mean_q: 0.012314
  7159/100000: episode: 902, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000593, mae: 0.011549, mean_q: 0.013018
  7169/100000: episode: 903, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000394, mae: 0.011376, mean_q: 0.018003
  7179/100000: episode: 904, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000218, mae: 0.008293, mean_q: 0.009925
  7189/100000: episode: 905, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000268, mae: 0.009452, mean_q: 0.012412
  7199/100000: episode: 906, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000881, mae: 0.013609, mean_q: 0.019185
  7209/100000: episode: 907, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000882, mae: 0.014118, mean_q: 0.017858
[Info] 1-TH LEVEL FOUND: 0.007436021231114864, Considering 100/100 traces
  7219/100000: episode: 908, duration: 0.680s, episode steps: 10, steps per second: 15, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000769, mae: 0.013666, mean_q: 0.020768
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.007436021231114864
  7229/100000: episode: 909, duration: 0.493s, episode steps: 10, steps per second: 20, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000614, mae: 0.010841, mean_q: 0.013793
  7239/100000: episode: 910, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001102, mae: 0.014250, mean_q: 0.015804
  7249/100000: episode: 911, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001853, mae: 0.016243, mean_q: 0.019086
  7259/100000: episode: 912, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000958, mae: 0.013681, mean_q: 0.020916
  7269/100000: episode: 913, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000571, mae: 0.011903, mean_q: 0.014649
  7279/100000: episode: 914, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000897, mae: 0.012315, mean_q: 0.015232
  7289/100000: episode: 915, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001577, mae: 0.015430, mean_q: 0.017966
  7299/100000: episode: 916, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000720, mae: 0.014610, mean_q: 0.020028
  7309/100000: episode: 917, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000461, mae: 0.010727, mean_q: 0.013571
  7319/100000: episode: 918, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000334, mae: 0.008322, mean_q: 0.010612
  7329/100000: episode: 919, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000209, mae: 0.006895, mean_q: 0.008796
  7339/100000: episode: 920, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.001937, mae: 0.016520, mean_q: 0.016945
  7349/100000: episode: 921, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001682, mae: 0.018091, mean_q: 0.020152
  7359/100000: episode: 922, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001687, mae: 0.015524, mean_q: 0.022698
  7369/100000: episode: 923, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000539, mae: 0.009471, mean_q: 0.015535
  7379/100000: episode: 924, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000412, mae: 0.009527, mean_q: 0.009885
  7389/100000: episode: 925, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000430, mae: 0.009909, mean_q: 0.009904
  7399/100000: episode: 926, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000693, mae: 0.014557, mean_q: 0.020725
  7409/100000: episode: 927, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000596, mae: 0.013455, mean_q: 0.020671
  7419/100000: episode: 928, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000470, mae: 0.010956, mean_q: 0.015557
  7429/100000: episode: 929, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000695, mae: 0.012220, mean_q: 0.017110
  7439/100000: episode: 930, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001559, mae: 0.014577, mean_q: 0.015786
  7449/100000: episode: 931, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000393, mae: 0.011291, mean_q: 0.014789
  7459/100000: episode: 932, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001121, mae: 0.014749, mean_q: 0.019641
  7469/100000: episode: 933, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001525, mae: 0.015182, mean_q: 0.018750
  7479/100000: episode: 934, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001316, mae: 0.017150, mean_q: 0.027652
  7489/100000: episode: 935, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000789, mae: 0.011704, mean_q: 0.015203
  7499/100000: episode: 936, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000645, mae: 0.008739, mean_q: 0.013376
  7509/100000: episode: 937, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000184, mae: 0.007410, mean_q: 0.008436
  7519/100000: episode: 938, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002541, mae: 0.017065, mean_q: 0.020993
  7529/100000: episode: 939, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002999, mae: 0.025168, mean_q: 0.033777
  7539/100000: episode: 940, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000858, mae: 0.012045, mean_q: 0.014631
  7549/100000: episode: 941, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001080, mae: 0.014253, mean_q: 0.010307
  7559/100000: episode: 942, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000658, mae: 0.012466, mean_q: 0.021046
  7569/100000: episode: 943, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001786, mae: 0.017826, mean_q: 0.020603
  7579/100000: episode: 944, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001164, mae: 0.015587, mean_q: 0.021721
  7589/100000: episode: 945, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002069, mae: 0.018228, mean_q: 0.019753
  7599/100000: episode: 946, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000757, mae: 0.013024, mean_q: 0.016239
  7609/100000: episode: 947, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000717, mae: 0.014875, mean_q: 0.016656
  7619/100000: episode: 948, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000400, mae: 0.010571, mean_q: 0.013251
  7629/100000: episode: 949, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002010, mae: 0.019591, mean_q: 0.023776
  7639/100000: episode: 950, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000612, mae: 0.011967, mean_q: 0.021468
  7649/100000: episode: 951, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001271, mae: 0.012544, mean_q: 0.011792
  7659/100000: episode: 952, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001907, mae: 0.018907, mean_q: 0.024591
  7669/100000: episode: 953, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001016, mae: 0.015614, mean_q: 0.018962
  7679/100000: episode: 954, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001979, mae: 0.017345, mean_q: 0.019258
  7689/100000: episode: 955, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000508, mae: 0.011405, mean_q: 0.016839
  7699/100000: episode: 956, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000633, mae: 0.012449, mean_q: 0.016674
  7709/100000: episode: 957, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.003348, mae: 0.016524, mean_q: 0.015644
  7719/100000: episode: 958, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001658, mae: 0.019306, mean_q: 0.024733
  7729/100000: episode: 959, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000959, mae: 0.013768, mean_q: 0.013923
  7739/100000: episode: 960, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001683, mae: 0.016141, mean_q: 0.012438
  7749/100000: episode: 961, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002286, mae: 0.021033, mean_q: 0.027710
  7759/100000: episode: 962, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001130, mae: 0.015513, mean_q: 0.021666
  7769/100000: episode: 963, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002097, mae: 0.017255, mean_q: 0.018668
  7779/100000: episode: 964, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000592, mae: 0.012110, mean_q: 0.016573
  7789/100000: episode: 965, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000326, mae: 0.008699, mean_q: 0.011158
  7799/100000: episode: 966, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002907, mae: 0.017746, mean_q: 0.015870
  7809/100000: episode: 967, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001760, mae: 0.019149, mean_q: 0.032885
  7819/100000: episode: 968, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001077, mae: 0.012803, mean_q: 0.023039
  7829/100000: episode: 969, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001668, mae: 0.017533, mean_q: 0.016272
  7839/100000: episode: 970, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000613, mae: 0.011525, mean_q: 0.013276
  7849/100000: episode: 971, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001530, mae: 0.012566, mean_q: 0.014073
  7859/100000: episode: 972, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000493, mae: 0.011263, mean_q: 0.014029
  7869/100000: episode: 973, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000861, mae: 0.015033, mean_q: 0.016552
  7879/100000: episode: 974, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000580, mae: 0.012360, mean_q: 0.015868
  7889/100000: episode: 975, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000568, mae: 0.012859, mean_q: 0.014212
  7899/100000: episode: 976, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001615, mae: 0.014408, mean_q: 0.013871
  7909/100000: episode: 977, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000888, mae: 0.014827, mean_q: 0.020499
  7919/100000: episode: 978, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000306, mae: 0.008565, mean_q: 0.014068
  7929/100000: episode: 979, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000566, mae: 0.011407, mean_q: 0.014360
  7939/100000: episode: 980, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000803, mae: 0.012808, mean_q: 0.015005
  7949/100000: episode: 981, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000605, mae: 0.012721, mean_q: 0.016666
  7959/100000: episode: 982, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000529, mae: 0.011698, mean_q: 0.014634
  7969/100000: episode: 983, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000912, mae: 0.012978, mean_q: 0.015516
  7979/100000: episode: 984, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000752, mae: 0.012412, mean_q: 0.014757
  7989/100000: episode: 985, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000489, mae: 0.010984, mean_q: 0.013522
  7999/100000: episode: 986, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002023, mae: 0.015357, mean_q: 0.015509
  8009/100000: episode: 987, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001471, mae: 0.013599, mean_q: 0.015463
  8019/100000: episode: 988, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000777, mae: 0.013659, mean_q: 0.022421
  8029/100000: episode: 989, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.003310, mae: 0.016027, mean_q: 0.012309
  8039/100000: episode: 990, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001237, mae: 0.016064, mean_q: 0.023405
  8049/100000: episode: 991, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000907, mae: 0.012166, mean_q: 0.019120
  8059/100000: episode: 992, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000745, mae: 0.011541, mean_q: 0.013671
  8069/100000: episode: 993, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001880, mae: 0.014834, mean_q: 0.018425
  8079/100000: episode: 994, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001210, mae: 0.013054, mean_q: 0.019571
  8089/100000: episode: 995, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000715, mae: 0.011639, mean_q: 0.017724
  8099/100000: episode: 996, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001740, mae: 0.012341, mean_q: 0.016726
  8109/100000: episode: 997, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001294, mae: 0.016283, mean_q: 0.023645
  8119/100000: episode: 998, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001660, mae: 0.015340, mean_q: 0.018361
  8129/100000: episode: 999, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000499, mae: 0.009959, mean_q: 0.024232
  8139/100000: episode: 1000, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.001631, mae: 0.017592, mean_q: 0.025832
  8149/100000: episode: 1001, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000646, mae: 0.010619, mean_q: 0.010705
  8159/100000: episode: 1002, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000813, mae: 0.011665, mean_q: 0.013605
  8169/100000: episode: 1003, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001695, mae: 0.017131, mean_q: 0.024092
  8179/100000: episode: 1004, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000920, mae: 0.013973, mean_q: 0.018979
  8189/100000: episode: 1005, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001813, mae: 0.014024, mean_q: 0.017029
  8199/100000: episode: 1006, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001320, mae: 0.016223, mean_q: 0.025893
  8209/100000: episode: 1007, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000391, mae: 0.008405, mean_q: 0.012910
  8219/100000: episode: 1008, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000728, mae: 0.010526, mean_q: 0.014589
[Info] 1-TH LEVEL FOUND: 0.006940700579434633, Considering 100/100 traces
  8229/100000: episode: 1009, duration: 0.732s, episode steps: 10, steps per second: 14, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001503, mae: 0.012429, mean_q: 0.014686
[Info] 2-TH LEVEL FOUND: 0.007266896776854992, Considering 100/100 traces
  8238/100000: episode: 1010, duration: 0.653s, episode steps: 9, steps per second: 14, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.444 [-1.000, 11.000], loss: 0.000610, mae: 0.009945, mean_q: 0.012404
[Info] 3-TH LEVEL FOUND: 0.00763574568554759, Considering 100/100 traces
  8247/100000: episode: 1011, duration: 0.672s, episode steps: 9, steps per second: 13, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.222 [-1.000, 11.000], loss: 0.001440, mae: 0.013174, mean_q: 0.015546
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.00763574568554759
  8257/100000: episode: 1012, duration: 0.492s, episode steps: 10, steps per second: 20, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 11.000], loss: 0.000422, mae: 0.008981, mean_q: 0.014460
  8267/100000: episode: 1013, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000878, mae: 0.011414, mean_q: 0.014972
  8277/100000: episode: 1014, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000600, mae: 0.009937, mean_q: 0.013481
  8287/100000: episode: 1015, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000576, mae: 0.011416, mean_q: 0.015208
  8297/100000: episode: 1016, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000877, mae: 0.013325, mean_q: 0.013082
  8307/100000: episode: 1017, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001514, mae: 0.014439, mean_q: 0.017415
  8317/100000: episode: 1018, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000881, mae: 0.013516, mean_q: 0.020546
  8327/100000: episode: 1019, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000239, mae: 0.007138, mean_q: 0.010863
  8337/100000: episode: 1020, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000433, mae: 0.008225, mean_q: 0.010811
  8347/100000: episode: 1021, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000468, mae: 0.009221, mean_q: 0.013525
  8357/100000: episode: 1022, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000490, mae: 0.009346, mean_q: 0.012626
  8367/100000: episode: 1023, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000300, mae: 0.007440, mean_q: 0.014378
  8377/100000: episode: 1024, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000601, mae: 0.009477, mean_q: 0.014968
  8387/100000: episode: 1025, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000946, mae: 0.011253, mean_q: 0.012063
  8397/100000: episode: 1026, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000356, mae: 0.008755, mean_q: 0.013354
  8407/100000: episode: 1027, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000645, mae: 0.011446, mean_q: 0.019083
  8417/100000: episode: 1028, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000504, mae: 0.008715, mean_q: 0.013318
  8427/100000: episode: 1029, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000317, mae: 0.006878, mean_q: 0.008819
  8437/100000: episode: 1030, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001157, mae: 0.009297, mean_q: 0.007304
  8447/100000: episode: 1031, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000379, mae: 0.010776, mean_q: 0.011804
  8457/100000: episode: 1032, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001151, mae: 0.012395, mean_q: 0.014365
  8467/100000: episode: 1033, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000348, mae: 0.008547, mean_q: 0.017707
  8477/100000: episode: 1034, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000589, mae: 0.008982, mean_q: 0.010501
  8487/100000: episode: 1035, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000520, mae: 0.007103, mean_q: 0.010009
  8497/100000: episode: 1036, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000323, mae: 0.006811, mean_q: 0.008110
  8507/100000: episode: 1037, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001877, mae: 0.011434, mean_q: 0.012058
  8517/100000: episode: 1038, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000579, mae: 0.010334, mean_q: 0.016086
  8527/100000: episode: 1039, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000666, mae: 0.006679, mean_q: 0.010685
  8537/100000: episode: 1040, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000695, mae: 0.008194, mean_q: 0.012090
  8547/100000: episode: 1041, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001689, mae: 0.010692, mean_q: 0.013882
  8557/100000: episode: 1042, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000678, mae: 0.008782, mean_q: 0.013157
  8567/100000: episode: 1043, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000366, mae: 0.007297, mean_q: 0.009545
  8577/100000: episode: 1044, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000368, mae: 0.007298, mean_q: 0.010856
  8587/100000: episode: 1045, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000810, mae: 0.008008, mean_q: 0.011171
  8597/100000: episode: 1046, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001119, mae: 0.009429, mean_q: 0.008598
  8607/100000: episode: 1047, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000302, mae: 0.006924, mean_q: 0.010374
  8617/100000: episode: 1048, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000497, mae: 0.007571, mean_q: 0.009963
  8627/100000: episode: 1049, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000106, mae: 0.004125, mean_q: 0.004136
  8637/100000: episode: 1050, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000200, mae: 0.005475, mean_q: 0.004499
  8647/100000: episode: 1051, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000147, mae: 0.005822, mean_q: 0.006181
  8657/100000: episode: 1052, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000126, mae: 0.005613, mean_q: 0.008044
  8667/100000: episode: 1053, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000122, mae: 0.004186, mean_q: 0.004922
  8677/100000: episode: 1054, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000102, mae: 0.003645, mean_q: 0.005878
  8687/100000: episode: 1055, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000115, mae: 0.004125, mean_q: 0.005489
  8697/100000: episode: 1056, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000141, mae: 0.005013, mean_q: 0.006773
  8707/100000: episode: 1057, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000300, mae: 0.006832, mean_q: 0.007222
  8717/100000: episode: 1058, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000130, mae: 0.004816, mean_q: 0.005969
  8727/100000: episode: 1059, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000086, mae: 0.004285, mean_q: 0.005571
  8737/100000: episode: 1060, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000016, mae: 0.002990, mean_q: 0.004821
  8747/100000: episode: 1061, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000011, mae: 0.002459, mean_q: 0.004381
  8757/100000: episode: 1062, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000071, mae: 0.003506, mean_q: 0.004986
  8767/100000: episode: 1063, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000071, mae: 0.003381, mean_q: 0.005571
  8777/100000: episode: 1064, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000062, mae: 0.003444, mean_q: 0.004453
  8787/100000: episode: 1065, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000115, mae: 0.004786, mean_q: 0.005731
  8797/100000: episode: 1066, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000026, mae: 0.003835, mean_q: 0.005588
  8807/100000: episode: 1067, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000016, mae: 0.003080, mean_q: 0.004826
  8817/100000: episode: 1068, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000049, mae: 0.002792, mean_q: 0.004275
  8827/100000: episode: 1069, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000023, mae: 0.003002, mean_q: 0.004496
  8837/100000: episode: 1070, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000016, mae: 0.002835, mean_q: 0.004471
  8847/100000: episode: 1071, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000089, mae: 0.003804, mean_q: 0.005216
  8857/100000: episode: 1072, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000060, mae: 0.003643, mean_q: 0.004433
  8867/100000: episode: 1073, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000058, mae: 0.003729, mean_q: 0.004604
  8877/100000: episode: 1074, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000067, mae: 0.003920, mean_q: 0.005518
  8887/100000: episode: 1075, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000134, mae: 0.005176, mean_q: 0.005203
  8897/100000: episode: 1076, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000024, mae: 0.004037, mean_q: 0.005736
  8907/100000: episode: 1077, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000029, mae: 0.003832, mean_q: 0.005353
  8917/100000: episode: 1078, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000007, mae: 0.002419, mean_q: 0.004631
  8927/100000: episode: 1079, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000055, mae: 0.003613, mean_q: 0.004548
  8937/100000: episode: 1080, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000014, mae: 0.002748, mean_q: 0.004755
  8947/100000: episode: 1081, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000115, mae: 0.004428, mean_q: 0.005372
  8957/100000: episode: 1082, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000098, mae: 0.003833, mean_q: 0.005777
  8967/100000: episode: 1083, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000017, mae: 0.002400, mean_q: 0.003674
  8977/100000: episode: 1084, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000019, mae: 0.002379, mean_q: 0.003669
  8987/100000: episode: 1085, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000070, mae: 0.003159, mean_q: 0.004207
  8997/100000: episode: 1086, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000019, mae: 0.002988, mean_q: 0.004703
  9007/100000: episode: 1087, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000073, mae: 0.003710, mean_q: 0.004464
  9017/100000: episode: 1088, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000006, mae: 0.002244, mean_q: 0.004452
  9027/100000: episode: 1089, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000094, mae: 0.004566, mean_q: 0.005426
  9037/100000: episode: 1090, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000116, mae: 0.004191, mean_q: 0.005439
  9047/100000: episode: 1091, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000017, mae: 0.003037, mean_q: 0.004955
  9057/100000: episode: 1092, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000018, mae: 0.002951, mean_q: 0.004503
  9067/100000: episode: 1093, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000039, mae: 0.003403, mean_q: 0.004965
  9077/100000: episode: 1094, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000087, mae: 0.004229, mean_q: 0.004241
  9087/100000: episode: 1095, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000047, mae: 0.004071, mean_q: 0.005465
  9097/100000: episode: 1096, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000006, mae: 0.002651, mean_q: 0.005034
  9107/100000: episode: 1097, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000102, mae: 0.003817, mean_q: 0.005171
  9117/100000: episode: 1098, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000046, mae: 0.003144, mean_q: 0.004011
  9127/100000: episode: 1099, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000119, mae: 0.004366, mean_q: 0.005503
  9137/100000: episode: 1100, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000054, mae: 0.003259, mean_q: 0.005184
  9147/100000: episode: 1101, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000043, mae: 0.003352, mean_q: 0.004352
  9157/100000: episode: 1102, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000042, mae: 0.003391, mean_q: 0.004783
  9167/100000: episode: 1103, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000034, mae: 0.003363, mean_q: 0.005074
  9177/100000: episode: 1104, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000009, mae: 0.002358, mean_q: 0.004135
  9187/100000: episode: 1105, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000020, mae: 0.002522, mean_q: 0.003885
  9197/100000: episode: 1106, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000014, mae: 0.002564, mean_q: 0.004010
  9207/100000: episode: 1107, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000024, mae: 0.003043, mean_q: 0.004255
  9217/100000: episode: 1108, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000020, mae: 0.002949, mean_q: 0.004618
  9227/100000: episode: 1109, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000037, mae: 0.003213, mean_q: 0.004385
  9237/100000: episode: 1110, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000032, mae: 0.003077, mean_q: 0.004671
  9247/100000: episode: 1111, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000135, mae: 0.005123, mean_q: 0.006165
[Info] 1-TH LEVEL FOUND: 0.0045881918631494045, Considering 100/100 traces
  9257/100000: episode: 1112, duration: 0.714s, episode steps: 10, steps per second: 14, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000020, mae: 0.003041, mean_q: 0.004587
[Info] 2-TH LEVEL FOUND: 0.004652414470911026, Considering 100/100 traces
  9266/100000: episode: 1113, duration: 0.673s, episode steps: 9, steps per second: 13, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.444 [-1.000, 11.000], loss: 0.000054, mae: 0.003336, mean_q: 0.004079
[Info] 3-TH LEVEL FOUND: 0.005111367907375097, Considering 100/100 traces
  9276/100000: episode: 1114, duration: 0.676s, episode steps: 10, steps per second: 15, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 11.000], loss: 0.000014, mae: 0.002756, mean_q: 0.004645
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005111367907375097
  9285/100000: episode: 1115, duration: 0.490s, episode steps: 9, steps per second: 18, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000042, mae: 0.003460, mean_q: 0.004732
  9295/100000: episode: 1116, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000035, mae: 0.003269, mean_q: 0.004533
  9305/100000: episode: 1117, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000023, mae: 0.003230, mean_q: 0.004442
  9315/100000: episode: 1118, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000020, mae: 0.002860, mean_q: 0.004381
  9325/100000: episode: 1119, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000021, mae: 0.002880, mean_q: 0.004969
  9335/100000: episode: 1120, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000067, mae: 0.003150, mean_q: 0.004154
  9345/100000: episode: 1121, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000010, mae: 0.002356, mean_q: 0.003961
  9355/100000: episode: 1122, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000017, mae: 0.002639, mean_q: 0.003921
  9365/100000: episode: 1123, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000030, mae: 0.003011, mean_q: 0.004062
  9375/100000: episode: 1124, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000019, mae: 0.003076, mean_q: 0.004407
  9385/100000: episode: 1125, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000043, mae: 0.003294, mean_q: 0.004667
  9395/100000: episode: 1126, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000086, mae: 0.004469, mean_q: 0.005192
  9405/100000: episode: 1127, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000010, mae: 0.003032, mean_q: 0.005560
  9415/100000: episode: 1128, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000008, mae: 0.002691, mean_q: 0.004345
  9425/100000: episode: 1129, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000031, mae: 0.003120, mean_q: 0.004012
  9435/100000: episode: 1130, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000050, mae: 0.003790, mean_q: 0.004881
  9445/100000: episode: 1131, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000026, mae: 0.003433, mean_q: 0.004973
  9455/100000: episode: 1132, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000021, mae: 0.003278, mean_q: 0.004798
  9465/100000: episode: 1133, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000013, mae: 0.002614, mean_q: 0.004595
  9475/100000: episode: 1134, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000015, mae: 0.002245, mean_q: 0.003907
  9485/100000: episode: 1135, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000022, mae: 0.002956, mean_q: 0.003955
  9495/100000: episode: 1136, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000024, mae: 0.002778, mean_q: 0.004523
  9505/100000: episode: 1137, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000045, mae: 0.003328, mean_q: 0.004564
  9515/100000: episode: 1138, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000033, mae: 0.002853, mean_q: 0.004591
  9525/100000: episode: 1139, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000085, mae: 0.004045, mean_q: 0.004542
  9535/100000: episode: 1140, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000009, mae: 0.002586, mean_q: 0.004747
  9545/100000: episode: 1141, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000051, mae: 0.003274, mean_q: 0.004378
  9555/100000: episode: 1142, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000089, mae: 0.004417, mean_q: 0.004731
  9565/100000: episode: 1143, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000058, mae: 0.004244, mean_q: 0.005667
  9575/100000: episode: 1144, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000011, mae: 0.002807, mean_q: 0.004671
  9585/100000: episode: 1145, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000023, mae: 0.002932, mean_q: 0.004262
  9595/100000: episode: 1146, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000021, mae: 0.002838, mean_q: 0.004080
  9605/100000: episode: 1147, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000082, mae: 0.004201, mean_q: 0.005094
  9615/100000: episode: 1148, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000045, mae: 0.003393, mean_q: 0.004735
  9625/100000: episode: 1149, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000035, mae: 0.002962, mean_q: 0.004600
  9635/100000: episode: 1150, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000019, mae: 0.002981, mean_q: 0.004422
  9645/100000: episode: 1151, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000036, mae: 0.003483, mean_q: 0.005270
  9655/100000: episode: 1152, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000026, mae: 0.002954, mean_q: 0.004517
  9665/100000: episode: 1153, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000010, mae: 0.002627, mean_q: 0.004570
  9675/100000: episode: 1154, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000084, mae: 0.003968, mean_q: 0.004222
  9685/100000: episode: 1155, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000031, mae: 0.003832, mean_q: 0.005205
  9695/100000: episode: 1156, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000009, mae: 0.002908, mean_q: 0.004906
  9705/100000: episode: 1157, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000016, mae: 0.002839, mean_q: 0.004611
  9715/100000: episode: 1158, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000012, mae: 0.002517, mean_q: 0.004125
  9725/100000: episode: 1159, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000027, mae: 0.002948, mean_q: 0.004211
  9735/100000: episode: 1160, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000020, mae: 0.002877, mean_q: 0.004196
  9745/100000: episode: 1161, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000053, mae: 0.003553, mean_q: 0.004441
  9755/100000: episode: 1162, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000056, mae: 0.004258, mean_q: 0.005497
  9765/100000: episode: 1163, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000021, mae: 0.003325, mean_q: 0.005034
  9775/100000: episode: 1164, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000013, mae: 0.002964, mean_q: 0.004265
  9785/100000: episode: 1165, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000029, mae: 0.002980, mean_q: 0.004268
  9795/100000: episode: 1166, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000023, mae: 0.003039, mean_q: 0.004580
  9805/100000: episode: 1167, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000029, mae: 0.003356, mean_q: 0.004997
  9815/100000: episode: 1168, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000036, mae: 0.003409, mean_q: 0.004665
  9825/100000: episode: 1169, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000104, mae: 0.004021, mean_q: 0.004853
  9835/100000: episode: 1170, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000021, mae: 0.002942, mean_q: 0.004929
  9845/100000: episode: 1171, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000026, mae: 0.003230, mean_q: 0.004770
  9855/100000: episode: 1172, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000009, mae: 0.002344, mean_q: 0.004112
  9865/100000: episode: 1173, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000033, mae: 0.002306, mean_q: 0.003742
  9875/100000: episode: 1174, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000067, mae: 0.003830, mean_q: 0.004305
  9885/100000: episode: 1175, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000051, mae: 0.004321, mean_q: 0.005615
  9895/100000: episode: 1176, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000015, mae: 0.003267, mean_q: 0.005128
  9905/100000: episode: 1177, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000023, mae: 0.003133, mean_q: 0.004290
  9915/100000: episode: 1178, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000019, mae: 0.003063, mean_q: 0.004442
  9925/100000: episode: 1179, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000031, mae: 0.003300, mean_q: 0.004257
  9935/100000: episode: 1180, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000014, mae: 0.002769, mean_q: 0.004546
  9945/100000: episode: 1181, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000048, mae: 0.003182, mean_q: 0.004298
  9955/100000: episode: 1182, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000069, mae: 0.003940, mean_q: 0.005259
  9965/100000: episode: 1183, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000021, mae: 0.003334, mean_q: 0.005004
  9975/100000: episode: 1184, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000050, mae: 0.003300, mean_q: 0.004165
  9985/100000: episode: 1185, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000018, mae: 0.003247, mean_q: 0.005030
  9995/100000: episode: 1186, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000011, mae: 0.002753, mean_q: 0.004533
 10005/100000: episode: 1187, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000024, mae: 0.003174, mean_q: 0.003917
 10015/100000: episode: 1188, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000020, mae: 0.002896, mean_q: 0.004637
 10025/100000: episode: 1189, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000074, mae: 0.004002, mean_q: 0.004384
 10035/100000: episode: 1190, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000011, mae: 0.003021, mean_q: 0.005176
 10045/100000: episode: 1191, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000045, mae: 0.003453, mean_q: 0.004582
 10055/100000: episode: 1192, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000027, mae: 0.003148, mean_q: 0.004705
 10065/100000: episode: 1193, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000051, mae: 0.003536, mean_q: 0.005258
 10075/100000: episode: 1194, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000041, mae: 0.003275, mean_q: 0.004640
 10085/100000: episode: 1195, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000014, mae: 0.002600, mean_q: 0.004313
 10095/100000: episode: 1196, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000044, mae: 0.003782, mean_q: 0.005126
 10105/100000: episode: 1197, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000024, mae: 0.003420, mean_q: 0.005197
 10115/100000: episode: 1198, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000021, mae: 0.002895, mean_q: 0.004557
 10125/100000: episode: 1199, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000015, mae: 0.002860, mean_q: 0.004497
 10135/100000: episode: 1200, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000083, mae: 0.004057, mean_q: 0.004694
 10145/100000: episode: 1201, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000073, mae: 0.004157, mean_q: 0.005279
 10155/100000: episode: 1202, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000037, mae: 0.002895, mean_q: 0.004500
 10165/100000: episode: 1203, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000011, mae: 0.002450, mean_q: 0.004321
 10175/100000: episode: 1204, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000026, mae: 0.003088, mean_q: 0.004105
 10185/100000: episode: 1205, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000022, mae: 0.003131, mean_q: 0.004696
 10195/100000: episode: 1206, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000033, mae: 0.003943, mean_q: 0.005188
 10205/100000: episode: 1207, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000024, mae: 0.003487, mean_q: 0.005117
 10215/100000: episode: 1208, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000026, mae: 0.003100, mean_q: 0.004680
 10225/100000: episode: 1209, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000049, mae: 0.003591, mean_q: 0.005080
 10235/100000: episode: 1210, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000049, mae: 0.003603, mean_q: 0.004733
 10245/100000: episode: 1211, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000011, mae: 0.002826, mean_q: 0.005362
 10255/100000: episode: 1212, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000009, mae: 0.002340, mean_q: 0.004215
 10265/100000: episode: 1213, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000090, mae: 0.003668, mean_q: 0.004672
 10275/100000: episode: 1214, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000042, mae: 0.003175, mean_q: 0.004638
[Info] 1-TH LEVEL FOUND: 0.00587161211296916, Considering 100/100 traces
 10285/100000: episode: 1215, duration: 0.863s, episode steps: 10, steps per second: 12, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000066, mae: 0.003505, mean_q: 0.005008
[Info] 2-TH LEVEL FOUND: 0.006508078891783953, Considering 100/100 traces
 10295/100000: episode: 1216, duration: 0.893s, episode steps: 10, steps per second: 11, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 11.000], loss: 0.000063, mae: 0.004273, mean_q: 0.006066
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.006508078891783953
 10304/100000: episode: 1217, duration: 0.572s, episode steps: 9, steps per second: 16, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.389 [-1.000, 11.000], loss: 0.000032, mae: 0.003738, mean_q: 0.006006
 10314/100000: episode: 1218, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000039, mae: 0.002873, mean_q: 0.003915
 10324/100000: episode: 1219, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000078, mae: 0.004128, mean_q: 0.004622
 10334/100000: episode: 1220, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000014, mae: 0.003333, mean_q: 0.005622
 10344/100000: episode: 1221, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000045, mae: 0.003389, mean_q: 0.004567
 10354/100000: episode: 1222, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000160, mae: 0.005469, mean_q: 0.006770
 10364/100000: episode: 1223, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000039, mae: 0.003299, mean_q: 0.005139
 10374/100000: episode: 1224, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000036, mae: 0.003242, mean_q: 0.004687
 10384/100000: episode: 1225, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000057, mae: 0.003960, mean_q: 0.005335
 10394/100000: episode: 1226, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000079, mae: 0.004683, mean_q: 0.005928
 10404/100000: episode: 1227, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000014, mae: 0.003372, mean_q: 0.005751
 10414/100000: episode: 1228, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000103, mae: 0.004495, mean_q: 0.004851
 10424/100000: episode: 1229, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000015, mae: 0.003029, mean_q: 0.005200
 10434/100000: episode: 1230, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000033, mae: 0.003371, mean_q: 0.004735
 10444/100000: episode: 1231, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000026, mae: 0.003378, mean_q: 0.004817
 10454/100000: episode: 1232, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000034, mae: 0.003690, mean_q: 0.005360
 10464/100000: episode: 1233, duration: 0.071s, episode steps: 10, steps per second: 140, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000104, mae: 0.004728, mean_q: 0.005126
 10474/100000: episode: 1234, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000047, mae: 0.004297, mean_q: 0.006090
 10484/100000: episode: 1235, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000071, mae: 0.004236, mean_q: 0.005576
 10494/100000: episode: 1236, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000096, mae: 0.004972, mean_q: 0.006908
 10504/100000: episode: 1237, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000022, mae: 0.003157, mean_q: 0.004668
 10514/100000: episode: 1238, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000030, mae: 0.003342, mean_q: 0.004556
 10524/100000: episode: 1239, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000082, mae: 0.004299, mean_q: 0.005193
 10534/100000: episode: 1240, duration: 0.069s, episode steps: 10, steps per second: 146, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000084, mae: 0.005370, mean_q: 0.006541
 10544/100000: episode: 1241, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000030, mae: 0.003935, mean_q: 0.005817
 10554/100000: episode: 1242, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000030, mae: 0.003379, mean_q: 0.004552
 10564/100000: episode: 1243, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000019, mae: 0.003673, mean_q: 0.005872
 10574/100000: episode: 1244, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000039, mae: 0.003866, mean_q: 0.005258
 10584/100000: episode: 1245, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000052, mae: 0.003830, mean_q: 0.005454
 10594/100000: episode: 1246, duration: 0.067s, episode steps: 10, steps per second: 148, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000071, mae: 0.004434, mean_q: 0.005730
 10604/100000: episode: 1247, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000045, mae: 0.003756, mean_q: 0.005263
 10614/100000: episode: 1248, duration: 0.055s, episode steps: 10, steps per second: 180, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000016, mae: 0.002747, mean_q: 0.004818
 10624/100000: episode: 1249, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000050, mae: 0.003560, mean_q: 0.004469
 10634/100000: episode: 1250, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000096, mae: 0.004367, mean_q: 0.006863
 10644/100000: episode: 1251, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000023, mae: 0.003191, mean_q: 0.004466
 10654/100000: episode: 1252, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000060, mae: 0.004753, mean_q: 0.005843
 10664/100000: episode: 1253, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000088, mae: 0.004824, mean_q: 0.005828
 10674/100000: episode: 1254, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000014, mae: 0.003079, mean_q: 0.005467
 10684/100000: episode: 1255, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000026, mae: 0.003163, mean_q: 0.004610
 10694/100000: episode: 1256, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000084, mae: 0.004630, mean_q: 0.005767
 10704/100000: episode: 1257, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000046, mae: 0.004516, mean_q: 0.006612
 10714/100000: episode: 1258, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000135, mae: 0.005229, mean_q: 0.005166
 10724/100000: episode: 1259, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000069, mae: 0.004896, mean_q: 0.006724
 10734/100000: episode: 1260, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000076, mae: 0.005308, mean_q: 0.006138
 10744/100000: episode: 1261, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000124, mae: 0.005360, mean_q: 0.006439
 10754/100000: episode: 1262, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000063, mae: 0.005166, mean_q: 0.006639
 10764/100000: episode: 1263, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000026, mae: 0.003756, mean_q: 0.005913
 10774/100000: episode: 1264, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000038, mae: 0.003895, mean_q: 0.005456
 10784/100000: episode: 1265, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000058, mae: 0.004179, mean_q: 0.005887
 10794/100000: episode: 1266, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000049, mae: 0.003874, mean_q: 0.005735
 10804/100000: episode: 1267, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000097, mae: 0.003929, mean_q: 0.005010
 10814/100000: episode: 1268, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000027, mae: 0.003904, mean_q: 0.005809
 10824/100000: episode: 1269, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000055, mae: 0.003971, mean_q: 0.005242
 10834/100000: episode: 1270, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000091, mae: 0.004891, mean_q: 0.005447
 10844/100000: episode: 1271, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000059, mae: 0.004861, mean_q: 0.006879
 10854/100000: episode: 1272, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000038, mae: 0.004095, mean_q: 0.004999
 10864/100000: episode: 1273, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000073, mae: 0.005518, mean_q: 0.006643
 10874/100000: episode: 1274, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000032, mae: 0.004076, mean_q: 0.005937
 10884/100000: episode: 1275, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000032, mae: 0.003287, mean_q: 0.004995
 10894/100000: episode: 1276, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000037, mae: 0.003861, mean_q: 0.005572
 10904/100000: episode: 1277, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000044, mae: 0.003554, mean_q: 0.005239
 10914/100000: episode: 1278, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000022, mae: 0.003220, mean_q: 0.005254
 10924/100000: episode: 1279, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000026, mae: 0.003539, mean_q: 0.005182
 10934/100000: episode: 1280, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000035, mae: 0.003797, mean_q: 0.005513
 10944/100000: episode: 1281, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000050, mae: 0.003357, mean_q: 0.004848
 10954/100000: episode: 1282, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000026, mae: 0.003575, mean_q: 0.005581
 10964/100000: episode: 1283, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000031, mae: 0.003646, mean_q: 0.005882
 10974/100000: episode: 1284, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000052, mae: 0.003771, mean_q: 0.005329
 10984/100000: episode: 1285, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000030, mae: 0.004049, mean_q: 0.005792
 10994/100000: episode: 1286, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000030, mae: 0.003663, mean_q: 0.005537
 11004/100000: episode: 1287, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000050, mae: 0.003895, mean_q: 0.005497
 11014/100000: episode: 1288, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000094, mae: 0.004417, mean_q: 0.005656
 11024/100000: episode: 1289, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000036, mae: 0.004332, mean_q: 0.005991
 11034/100000: episode: 1290, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000083, mae: 0.004704, mean_q: 0.005915
 11044/100000: episode: 1291, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000056, mae: 0.004583, mean_q: 0.006429
 11054/100000: episode: 1292, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000029, mae: 0.003811, mean_q: 0.005369
 11064/100000: episode: 1293, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000013, mae: 0.002623, mean_q: 0.004533
 11074/100000: episode: 1294, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000020, mae: 0.003177, mean_q: 0.005063
 11084/100000: episode: 1295, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000124, mae: 0.005224, mean_q: 0.005414
 11094/100000: episode: 1296, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000021, mae: 0.004276, mean_q: 0.006651
 11104/100000: episode: 1297, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000032, mae: 0.003533, mean_q: 0.004565
 11114/100000: episode: 1298, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000025, mae: 0.003594, mean_q: 0.005083
 11124/100000: episode: 1299, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000017, mae: 0.003178, mean_q: 0.005141
 11134/100000: episode: 1300, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000055, mae: 0.004223, mean_q: 0.005751
 11144/100000: episode: 1301, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000030, mae: 0.003700, mean_q: 0.004813
 11154/100000: episode: 1302, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000037, mae: 0.002984, mean_q: 0.005047
 11164/100000: episode: 1303, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000028, mae: 0.003320, mean_q: 0.004628
 11174/100000: episode: 1304, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000048, mae: 0.004000, mean_q: 0.005880
 11184/100000: episode: 1305, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000024, mae: 0.003820, mean_q: 0.005668
 11194/100000: episode: 1306, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000073, mae: 0.004082, mean_q: 0.005510
 11204/100000: episode: 1307, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000051, mae: 0.003596, mean_q: 0.005465
 11214/100000: episode: 1308, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000036, mae: 0.003303, mean_q: 0.004429
 11224/100000: episode: 1309, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000012, mae: 0.002714, mean_q: 0.004647
 11234/100000: episode: 1310, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000037, mae: 0.003828, mean_q: 0.005400
 11244/100000: episode: 1311, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000021, mae: 0.003220, mean_q: 0.005220
 11254/100000: episode: 1312, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000022, mae: 0.003022, mean_q: 0.005743
 11264/100000: episode: 1313, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000036, mae: 0.003775, mean_q: 0.004545
 11274/100000: episode: 1314, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000020, mae: 0.003592, mean_q: 0.005493
 11284/100000: episode: 1315, duration: 0.072s, episode steps: 10, steps per second: 138, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000008, mae: 0.002471, mean_q: 0.004351
 11294/100000: episode: 1316, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000051, mae: 0.004753, mean_q: 0.005237
[Info] 1-TH LEVEL FOUND: 0.007172157987952232, Considering 100/100 traces
 11304/100000: episode: 1317, duration: 0.843s, episode steps: 10, steps per second: 12, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000188, mae: 0.006180, mean_q: 0.007039
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.007172157987952232
 11313/100000: episode: 1318, duration: 0.828s, episode steps: 9, steps per second: 11, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.778 [-1.000, 11.000], loss: 0.000021, mae: 0.004056, mean_q: 0.005851
 11323/100000: episode: 1319, duration: 0.105s, episode steps: 10, steps per second: 95, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000123, mae: 0.004515, mean_q: 0.004848
 11333/100000: episode: 1320, duration: 0.115s, episode steps: 10, steps per second: 87, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000129, mae: 0.005474, mean_q: 0.006734
 11343/100000: episode: 1321, duration: 0.112s, episode steps: 10, steps per second: 89, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000019, mae: 0.003898, mean_q: 0.006246
 11353/100000: episode: 1322, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000061, mae: 0.004232, mean_q: 0.005138
 11363/100000: episode: 1323, duration: 0.087s, episode steps: 10, steps per second: 114, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000024, mae: 0.003315, mean_q: 0.005390
 11373/100000: episode: 1324, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000119, mae: 0.005155, mean_q: 0.006183
 11383/100000: episode: 1325, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000083, mae: 0.004519, mean_q: 0.006046
 11393/100000: episode: 1326, duration: 0.052s, episode steps: 10, steps per second: 190, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000017, mae: 0.003197, mean_q: 0.005560
 11403/100000: episode: 1327, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000074, mae: 0.004433, mean_q: 0.005632
 11413/100000: episode: 1328, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000055, mae: 0.004488, mean_q: 0.007225
 11423/100000: episode: 1329, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000076, mae: 0.004048, mean_q: 0.004696
 11433/100000: episode: 1330, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000055, mae: 0.004163, mean_q: 0.006864
 11443/100000: episode: 1331, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000026, mae: 0.003395, mean_q: 0.004716
 11453/100000: episode: 1332, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000098, mae: 0.005372, mean_q: 0.005694
 11463/100000: episode: 1333, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000027, mae: 0.004302, mean_q: 0.006219
 11473/100000: episode: 1334, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000055, mae: 0.003859, mean_q: 0.004774
 11483/100000: episode: 1335, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000096, mae: 0.005088, mean_q: 0.006212
 11493/100000: episode: 1336, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000072, mae: 0.004883, mean_q: 0.006454
 11503/100000: episode: 1337, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000031, mae: 0.003980, mean_q: 0.005401
 11513/100000: episode: 1338, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000063, mae: 0.003770, mean_q: 0.005820
 11523/100000: episode: 1339, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000023, mae: 0.003306, mean_q: 0.005152
 11533/100000: episode: 1340, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000063, mae: 0.003840, mean_q: 0.005058
 11543/100000: episode: 1341, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000028, mae: 0.003378, mean_q: 0.005521
 11553/100000: episode: 1342, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000050, mae: 0.003575, mean_q: 0.004899
 11563/100000: episode: 1343, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000026, mae: 0.003666, mean_q: 0.005597
 11573/100000: episode: 1344, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000023, mae: 0.003336, mean_q: 0.005364
 11583/100000: episode: 1345, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000064, mae: 0.003799, mean_q: 0.004750
 11593/100000: episode: 1346, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000052, mae: 0.003990, mean_q: 0.005614
 11603/100000: episode: 1347, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000037, mae: 0.004312, mean_q: 0.005995
 11613/100000: episode: 1348, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000036, mae: 0.004234, mean_q: 0.005979
 11623/100000: episode: 1349, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000041, mae: 0.003573, mean_q: 0.005714
 11633/100000: episode: 1350, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000032, mae: 0.003291, mean_q: 0.004838
 11643/100000: episode: 1351, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000106, mae: 0.004456, mean_q: 0.005625
 11653/100000: episode: 1352, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000018, mae: 0.003557, mean_q: 0.006218
 11663/100000: episode: 1353, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000095, mae: 0.004985, mean_q: 0.005325
 11673/100000: episode: 1354, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000058, mae: 0.004627, mean_q: 0.006473
 11683/100000: episode: 1355, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000023, mae: 0.002912, mean_q: 0.004233
 11693/100000: episode: 1356, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000045, mae: 0.003176, mean_q: 0.004731
 11703/100000: episode: 1357, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000029, mae: 0.003519, mean_q: 0.005262
 11713/100000: episode: 1358, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000020, mae: 0.003168, mean_q: 0.004903
 11723/100000: episode: 1359, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000099, mae: 0.004135, mean_q: 0.005174
 11733/100000: episode: 1360, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000029, mae: 0.004002, mean_q: 0.006004
 11743/100000: episode: 1361, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000080, mae: 0.004835, mean_q: 0.005751
 11753/100000: episode: 1362, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000050, mae: 0.004343, mean_q: 0.006057
 11763/100000: episode: 1363, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000017, mae: 0.003282, mean_q: 0.005830
 11773/100000: episode: 1364, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000041, mae: 0.003015, mean_q: 0.004588
 11783/100000: episode: 1365, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000058, mae: 0.003930, mean_q: 0.005311
 11793/100000: episode: 1366, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000099, mae: 0.004872, mean_q: 0.005913
 11803/100000: episode: 1367, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000036, mae: 0.004389, mean_q: 0.006555
 11813/100000: episode: 1368, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000045, mae: 0.003720, mean_q: 0.004599
 11823/100000: episode: 1369, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000049, mae: 0.004029, mean_q: 0.005570
 11833/100000: episode: 1370, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000031, mae: 0.003921, mean_q: 0.005686
 11843/100000: episode: 1371, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000012, mae: 0.002820, mean_q: 0.004959
 11853/100000: episode: 1372, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000014, mae: 0.002635, mean_q: 0.004642
 11863/100000: episode: 1373, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000149, mae: 0.005625, mean_q: 0.006069
 11873/100000: episode: 1374, duration: 0.070s, episode steps: 10, steps per second: 144, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000047, mae: 0.004168, mean_q: 0.005844
 11883/100000: episode: 1375, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000036, mae: 0.004019, mean_q: 0.004575
 11893/100000: episode: 1376, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000054, mae: 0.004908, mean_q: 0.006538
 11903/100000: episode: 1377, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000052, mae: 0.003757, mean_q: 0.004667
 11913/100000: episode: 1378, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000056, mae: 0.003825, mean_q: 0.005860
 11923/100000: episode: 1379, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000050, mae: 0.003816, mean_q: 0.005295
 11933/100000: episode: 1380, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000048, mae: 0.003314, mean_q: 0.004738
 11943/100000: episode: 1381, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000076, mae: 0.004302, mean_q: 0.005637
 11953/100000: episode: 1382, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000068, mae: 0.005070, mean_q: 0.007050
 11963/100000: episode: 1383, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000026, mae: 0.003292, mean_q: 0.004825
 11973/100000: episode: 1384, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000030, mae: 0.003668, mean_q: 0.005161
 11983/100000: episode: 1385, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000093, mae: 0.005196, mean_q: 0.007200
 11993/100000: episode: 1386, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000046, mae: 0.003605, mean_q: 0.004915
 12003/100000: episode: 1387, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000050, mae: 0.003980, mean_q: 0.005145
 12013/100000: episode: 1388, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000039, mae: 0.003508, mean_q: 0.005388
 12023/100000: episode: 1389, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000039, mae: 0.003798, mean_q: 0.004991
 12033/100000: episode: 1390, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000017, mae: 0.003281, mean_q: 0.005487
 12043/100000: episode: 1391, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000032, mae: 0.003852, mean_q: 0.004859
 12053/100000: episode: 1392, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000074, mae: 0.005154, mean_q: 0.007939
 12063/100000: episode: 1393, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000009, mae: 0.002513, mean_q: 0.003657
 12073/100000: episode: 1394, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000070, mae: 0.004582, mean_q: 0.005512
 12083/100000: episode: 1395, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000108, mae: 0.006178, mean_q: 0.007085
 12093/100000: episode: 1396, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000083, mae: 0.004231, mean_q: 0.005075
 12103/100000: episode: 1397, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000068, mae: 0.004444, mean_q: 0.006143
 12113/100000: episode: 1398, duration: 0.073s, episode steps: 10, steps per second: 138, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000050, mae: 0.004347, mean_q: 0.006159
 12123/100000: episode: 1399, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000038, mae: 0.003581, mean_q: 0.005041
 12133/100000: episode: 1400, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000017, mae: 0.002731, mean_q: 0.004252
 12143/100000: episode: 1401, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000018, mae: 0.003252, mean_q: 0.005261
 12153/100000: episode: 1402, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000073, mae: 0.004346, mean_q: 0.005875
 12163/100000: episode: 1403, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000056, mae: 0.004669, mean_q: 0.006300
 12173/100000: episode: 1404, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000046, mae: 0.004248, mean_q: 0.005501
 12183/100000: episode: 1405, duration: 0.068s, episode steps: 10, steps per second: 146, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000043, mae: 0.003941, mean_q: 0.005102
 12193/100000: episode: 1406, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000043, mae: 0.004571, mean_q: 0.006121
 12203/100000: episode: 1407, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000021, mae: 0.003264, mean_q: 0.005773
 12213/100000: episode: 1408, duration: 0.088s, episode steps: 10, steps per second: 113, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000077, mae: 0.004196, mean_q: 0.005417
 12223/100000: episode: 1409, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000030, mae: 0.004254, mean_q: 0.006463
 12233/100000: episode: 1410, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000025, mae: 0.003110, mean_q: 0.004586
 12243/100000: episode: 1411, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000070, mae: 0.004668, mean_q: 0.005605
 12253/100000: episode: 1412, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000065, mae: 0.005330, mean_q: 0.006621
 12263/100000: episode: 1413, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000075, mae: 0.004693, mean_q: 0.006546
 12273/100000: episode: 1414, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000022, mae: 0.003866, mean_q: 0.005769
 12283/100000: episode: 1415, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000030, mae: 0.003333, mean_q: 0.005709
 12293/100000: episode: 1416, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000044, mae: 0.003225, mean_q: 0.004545
 12303/100000: episode: 1417, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000048, mae: 0.004755, mean_q: 0.006087
[Info] 1-TH LEVEL FOUND: 0.00533293467015028, Considering 100/100 traces
 12313/100000: episode: 1418, duration: 0.786s, episode steps: 10, steps per second: 13, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000026, mae: 0.003980, mean_q: 0.006437
[Info] 2-TH LEVEL FOUND: 0.006554965395480394, Considering 100/100 traces
 12322/100000: episode: 1419, duration: 0.825s, episode steps: 9, steps per second: 11, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.278 [-1.000, 11.000], loss: 0.000051, mae: 0.004338, mean_q: 0.005213
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.006554965395480394
 12332/100000: episode: 1420, duration: 0.524s, episode steps: 10, steps per second: 19, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 11.000], loss: 0.000027, mae: 0.003896, mean_q: 0.005976
 12342/100000: episode: 1421, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000087, mae: 0.005122, mean_q: 0.006384
 12352/100000: episode: 1422, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000107, mae: 0.005454, mean_q: 0.006644
 12362/100000: episode: 1423, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000054, mae: 0.004463, mean_q: 0.005990
 12372/100000: episode: 1424, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000064, mae: 0.004676, mean_q: 0.005889
 12382/100000: episode: 1425, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000032, mae: 0.004182, mean_q: 0.006111
 12392/100000: episode: 1426, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000023, mae: 0.003210, mean_q: 0.005465
 12402/100000: episode: 1427, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000021, mae: 0.002808, mean_q: 0.004502
 12412/100000: episode: 1428, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000078, mae: 0.004593, mean_q: 0.006165
 12422/100000: episode: 1429, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000054, mae: 0.004301, mean_q: 0.007230
 12432/100000: episode: 1430, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000040, mae: 0.002874, mean_q: 0.004165
 12442/100000: episode: 1431, duration: 0.074s, episode steps: 10, steps per second: 136, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000023, mae: 0.003506, mean_q: 0.005379
 12452/100000: episode: 1432, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000070, mae: 0.004222, mean_q: 0.006086
 12462/100000: episode: 1433, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000077, mae: 0.004836, mean_q: 0.005962
 12472/100000: episode: 1434, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000043, mae: 0.004658, mean_q: 0.006279
 12482/100000: episode: 1435, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000037, mae: 0.002859, mean_q: 0.004912
 12492/100000: episode: 1436, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000038, mae: 0.003664, mean_q: 0.004803
 12502/100000: episode: 1437, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000019, mae: 0.003644, mean_q: 0.006091
 12512/100000: episode: 1438, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000171, mae: 0.005625, mean_q: 0.005350
 12522/100000: episode: 1439, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000078, mae: 0.005457, mean_q: 0.007145
 12532/100000: episode: 1440, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000076, mae: 0.004261, mean_q: 0.004966
 12542/100000: episode: 1441, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000058, mae: 0.004844, mean_q: 0.006303
 12552/100000: episode: 1442, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000040, mae: 0.003242, mean_q: 0.005291
 12562/100000: episode: 1443, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000095, mae: 0.004485, mean_q: 0.005526
 12572/100000: episode: 1444, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000094, mae: 0.005920, mean_q: 0.007221
 12582/100000: episode: 1445, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000108, mae: 0.004993, mean_q: 0.005640
 12592/100000: episode: 1446, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000083, mae: 0.004727, mean_q: 0.006405
 12602/100000: episode: 1447, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000017, mae: 0.002959, mean_q: 0.005536
 12612/100000: episode: 1448, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000106, mae: 0.004840, mean_q: 0.005622
 12622/100000: episode: 1449, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000026, mae: 0.003727, mean_q: 0.005696
 12632/100000: episode: 1450, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000024, mae: 0.003211, mean_q: 0.005249
 12642/100000: episode: 1451, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000024, mae: 0.003538, mean_q: 0.005652
 12652/100000: episode: 1452, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000136, mae: 0.005111, mean_q: 0.006512
 12662/100000: episode: 1453, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000043, mae: 0.004158, mean_q: 0.005815
 12672/100000: episode: 1454, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000093, mae: 0.005036, mean_q: 0.006068
 12682/100000: episode: 1455, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000061, mae: 0.004868, mean_q: 0.006262
 12692/100000: episode: 1456, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000071, mae: 0.004137, mean_q: 0.005716
 12702/100000: episode: 1457, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000033, mae: 0.004500, mean_q: 0.006447
 12712/100000: episode: 1458, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000024, mae: 0.003430, mean_q: 0.005403
 12722/100000: episode: 1459, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000072, mae: 0.003968, mean_q: 0.005880
 12732/100000: episode: 1460, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000062, mae: 0.004066, mean_q: 0.005251
 12742/100000: episode: 1461, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000063, mae: 0.004757, mean_q: 0.006007
 12752/100000: episode: 1462, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000033, mae: 0.004230, mean_q: 0.005775
 12762/100000: episode: 1463, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000039, mae: 0.003604, mean_q: 0.004571
 12772/100000: episode: 1464, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000030, mae: 0.004263, mean_q: 0.005827
 12782/100000: episode: 1465, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000069, mae: 0.004187, mean_q: 0.005836
 12792/100000: episode: 1466, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000026, mae: 0.003587, mean_q: 0.005426
 12802/100000: episode: 1467, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000024, mae: 0.003461, mean_q: 0.005188
 12812/100000: episode: 1468, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000065, mae: 0.004087, mean_q: 0.005984
 12822/100000: episode: 1469, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000018, mae: 0.003179, mean_q: 0.005217
 12832/100000: episode: 1470, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000043, mae: 0.004016, mean_q: 0.004544
 12842/100000: episode: 1471, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000054, mae: 0.004606, mean_q: 0.006215
 12852/100000: episode: 1472, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000035, mae: 0.004253, mean_q: 0.006033
 12862/100000: episode: 1473, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000030, mae: 0.003742, mean_q: 0.005015
 12872/100000: episode: 1474, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000050, mae: 0.003851, mean_q: 0.005343
 12882/100000: episode: 1475, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000078, mae: 0.004994, mean_q: 0.006453
 12892/100000: episode: 1476, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000051, mae: 0.004308, mean_q: 0.005856
 12902/100000: episode: 1477, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000087, mae: 0.004808, mean_q: 0.005501
 12912/100000: episode: 1478, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000039, mae: 0.003649, mean_q: 0.005954
 12922/100000: episode: 1479, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000010, mae: 0.002262, mean_q: 0.004061
 12932/100000: episode: 1480, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000081, mae: 0.004605, mean_q: 0.005519
 12942/100000: episode: 1481, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000026, mae: 0.004320, mean_q: 0.006702
 12952/100000: episode: 1482, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000018, mae: 0.003098, mean_q: 0.004281
 12962/100000: episode: 1483, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000044, mae: 0.003583, mean_q: 0.004983
 12972/100000: episode: 1484, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000022, mae: 0.003991, mean_q: 0.005896
 12982/100000: episode: 1485, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000021, mae: 0.003104, mean_q: 0.005008
 12992/100000: episode: 1486, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000053, mae: 0.004141, mean_q: 0.005222
 13002/100000: episode: 1487, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000081, mae: 0.005174, mean_q: 0.006780
 13012/100000: episode: 1488, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000037, mae: 0.004187, mean_q: 0.005260
 13022/100000: episode: 1489, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000025, mae: 0.003770, mean_q: 0.005325
 13032/100000: episode: 1490, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000055, mae: 0.003887, mean_q: 0.005383
 13042/100000: episode: 1491, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000059, mae: 0.004650, mean_q: 0.006299
 13052/100000: episode: 1492, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000061, mae: 0.004421, mean_q: 0.005614
 13062/100000: episode: 1493, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000073, mae: 0.003935, mean_q: 0.005136
 13072/100000: episode: 1494, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000030, mae: 0.003767, mean_q: 0.005394
 13082/100000: episode: 1495, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000064, mae: 0.004907, mean_q: 0.006211
 13092/100000: episode: 1496, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000050, mae: 0.003591, mean_q: 0.004883
 13102/100000: episode: 1497, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000019, mae: 0.003380, mean_q: 0.005568
 13112/100000: episode: 1498, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000025, mae: 0.003284, mean_q: 0.004546
 13122/100000: episode: 1499, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000046, mae: 0.003615, mean_q: 0.005462
 13132/100000: episode: 1500, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000027, mae: 0.003578, mean_q: 0.005113
 13142/100000: episode: 1501, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000047, mae: 0.003562, mean_q: 0.004933
 13152/100000: episode: 1502, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000027, mae: 0.004001, mean_q: 0.005878
 13162/100000: episode: 1503, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000031, mae: 0.003446, mean_q: 0.004869
 13172/100000: episode: 1504, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000084, mae: 0.004833, mean_q: 0.005874
 13182/100000: episode: 1505, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000044, mae: 0.003695, mean_q: 0.005660
 13192/100000: episode: 1506, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000077, mae: 0.004863, mean_q: 0.004892
 13202/100000: episode: 1507, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000058, mae: 0.005116, mean_q: 0.006669
 13212/100000: episode: 1508, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000052, mae: 0.004273, mean_q: 0.005062
 13222/100000: episode: 1509, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000039, mae: 0.004428, mean_q: 0.006094
 13232/100000: episode: 1510, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000027, mae: 0.003968, mean_q: 0.005958
 13242/100000: episode: 1511, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000026, mae: 0.003592, mean_q: 0.005451
 13252/100000: episode: 1512, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000078, mae: 0.004811, mean_q: 0.006220
 13262/100000: episode: 1513, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000015, mae: 0.002871, mean_q: 0.004941
 13272/100000: episode: 1514, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000033, mae: 0.004217, mean_q: 0.006163
 13282/100000: episode: 1515, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000015, mae: 0.002987, mean_q: 0.005080
 13292/100000: episode: 1516, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000082, mae: 0.004435, mean_q: 0.005706
 13302/100000: episode: 1517, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000020, mae: 0.004004, mean_q: 0.006534
 13312/100000: episode: 1518, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000042, mae: 0.003244, mean_q: 0.004965
 13322/100000: episode: 1519, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000025, mae: 0.003210, mean_q: 0.004742
[Info] 1-TH LEVEL FOUND: 0.006612013094127178, Considering 100/100 traces
 13332/100000: episode: 1520, duration: 0.737s, episode steps: 10, steps per second: 14, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000077, mae: 0.004282, mean_q: 0.005797
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.006612013094127178
 13342/100000: episode: 1521, duration: 0.495s, episode steps: 10, steps per second: 20, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 11.000], loss: 0.000040, mae: 0.003695, mean_q: 0.006157
 13352/100000: episode: 1522, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000019, mae: 0.002823, mean_q: 0.003753
 13362/100000: episode: 1523, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000017, mae: 0.002915, mean_q: 0.005083
 13372/100000: episode: 1524, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000054, mae: 0.004115, mean_q: 0.005432
 13382/100000: episode: 1525, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000073, mae: 0.004237, mean_q: 0.006110
 13392/100000: episode: 1526, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000050, mae: 0.003657, mean_q: 0.004798
 13402/100000: episode: 1527, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000046, mae: 0.003761, mean_q: 0.005466
 13412/100000: episode: 1528, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000098, mae: 0.004229, mean_q: 0.005048
 13422/100000: episode: 1529, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000049, mae: 0.004297, mean_q: 0.006445
 13432/100000: episode: 1530, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000059, mae: 0.003794, mean_q: 0.004611
 13442/100000: episode: 1531, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000074, mae: 0.005144, mean_q: 0.006463
 13452/100000: episode: 1532, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000084, mae: 0.004588, mean_q: 0.005749
 13462/100000: episode: 1533, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000052, mae: 0.004872, mean_q: 0.006648
 13472/100000: episode: 1534, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000082, mae: 0.004757, mean_q: 0.005855
 13482/100000: episode: 1535, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000017, mae: 0.003264, mean_q: 0.004998
 13492/100000: episode: 1536, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000108, mae: 0.004592, mean_q: 0.005353
 13502/100000: episode: 1537, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000024, mae: 0.004303, mean_q: 0.006391
 13512/100000: episode: 1538, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000065, mae: 0.003508, mean_q: 0.004401
 13522/100000: episode: 1539, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000048, mae: 0.004479, mean_q: 0.006597
 13532/100000: episode: 1540, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000017, mae: 0.002979, mean_q: 0.005007
 13542/100000: episode: 1541, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000091, mae: 0.004584, mean_q: 0.004853
 13552/100000: episode: 1542, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000054, mae: 0.004687, mean_q: 0.006848
 13562/100000: episode: 1543, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000102, mae: 0.004993, mean_q: 0.006291
 13572/100000: episode: 1544, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000014, mae: 0.003513, mean_q: 0.005896
 13582/100000: episode: 1545, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000072, mae: 0.004478, mean_q: 0.004822
 13592/100000: episode: 1546, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000016, mae: 0.003549, mean_q: 0.005822
 13602/100000: episode: 1547, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000034, mae: 0.003748, mean_q: 0.004385
 13612/100000: episode: 1548, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000014, mae: 0.003843, mean_q: 0.006491
 13622/100000: episode: 1549, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000072, mae: 0.003834, mean_q: 0.005498
 13632/100000: episode: 1550, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000025, mae: 0.003364, mean_q: 0.005350
 13642/100000: episode: 1551, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000086, mae: 0.003956, mean_q: 0.005947
 13652/100000: episode: 1552, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000056, mae: 0.003661, mean_q: 0.004633
 13662/100000: episode: 1553, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000049, mae: 0.004464, mean_q: 0.006475
 13672/100000: episode: 1554, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000047, mae: 0.003941, mean_q: 0.005509
 13682/100000: episode: 1555, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000030, mae: 0.003717, mean_q: 0.005177
 13692/100000: episode: 1556, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000052, mae: 0.004201, mean_q: 0.005702
 13702/100000: episode: 1557, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000033, mae: 0.003933, mean_q: 0.005456
 13712/100000: episode: 1558, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000084, mae: 0.004927, mean_q: 0.005973
 13722/100000: episode: 1559, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000033, mae: 0.004226, mean_q: 0.006050
 13732/100000: episode: 1560, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000023, mae: 0.003118, mean_q: 0.004444
 13742/100000: episode: 1561, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000036, mae: 0.004067, mean_q: 0.005477
 13752/100000: episode: 1562, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000047, mae: 0.003744, mean_q: 0.005521
 13762/100000: episode: 1563, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000028, mae: 0.004169, mean_q: 0.005961
 13772/100000: episode: 1564, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000048, mae: 0.003584, mean_q: 0.004612
 13782/100000: episode: 1565, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000055, mae: 0.004488, mean_q: 0.006023
 13792/100000: episode: 1566, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000054, mae: 0.004170, mean_q: 0.005484
 13802/100000: episode: 1567, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000031, mae: 0.003898, mean_q: 0.005419
 13812/100000: episode: 1568, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000054, mae: 0.004117, mean_q: 0.005356
 13822/100000: episode: 1569, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000044, mae: 0.003625, mean_q: 0.005696
 13832/100000: episode: 1570, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000052, mae: 0.003300, mean_q: 0.004075
 13842/100000: episode: 1571, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000011, mae: 0.002935, mean_q: 0.005274
 13852/100000: episode: 1572, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000081, mae: 0.004109, mean_q: 0.004971
 13862/100000: episode: 1573, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000026, mae: 0.003764, mean_q: 0.005512
 13872/100000: episode: 1574, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000072, mae: 0.004245, mean_q: 0.005517
 13882/100000: episode: 1575, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000013, mae: 0.002966, mean_q: 0.005014
 13892/100000: episode: 1576, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000058, mae: 0.003609, mean_q: 0.004568
 13902/100000: episode: 1577, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000041, mae: 0.005191, mean_q: 0.006862
 13912/100000: episode: 1578, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000019, mae: 0.002951, mean_q: 0.004536
 13922/100000: episode: 1579, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000062, mae: 0.004309, mean_q: 0.005907
 13932/100000: episode: 1580, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000045, mae: 0.003558, mean_q: 0.005974
 13942/100000: episode: 1581, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000101, mae: 0.004640, mean_q: 0.005231
 13952/100000: episode: 1582, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000023, mae: 0.003831, mean_q: 0.005784
 13962/100000: episode: 1583, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000107, mae: 0.004703, mean_q: 0.005780
 13972/100000: episode: 1584, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000078, mae: 0.004124, mean_q: 0.005720
 13982/100000: episode: 1585, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000075, mae: 0.004727, mean_q: 0.006236
 13992/100000: episode: 1586, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000087, mae: 0.005037, mean_q: 0.005864
 14002/100000: episode: 1587, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000068, mae: 0.004930, mean_q: 0.006252
 14012/100000: episode: 1588, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000029, mae: 0.003306, mean_q: 0.005024
 14022/100000: episode: 1589, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000052, mae: 0.003651, mean_q: 0.005288
 14032/100000: episode: 1590, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000026, mae: 0.003506, mean_q: 0.005279
 14042/100000: episode: 1591, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000052, mae: 0.003690, mean_q: 0.005117
 14052/100000: episode: 1592, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000027, mae: 0.003888, mean_q: 0.005717
 14062/100000: episode: 1593, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000063, mae: 0.004020, mean_q: 0.004924
 14072/100000: episode: 1594, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000068, mae: 0.005011, mean_q: 0.007005
 14082/100000: episode: 1595, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000056, mae: 0.004432, mean_q: 0.005782
 14092/100000: episode: 1596, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000021, mae: 0.002905, mean_q: 0.004883
 14102/100000: episode: 1597, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000028, mae: 0.003058, mean_q: 0.004502
 14112/100000: episode: 1598, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000042, mae: 0.004498, mean_q: 0.006040
 14122/100000: episode: 1599, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000046, mae: 0.004201, mean_q: 0.006246
 14132/100000: episode: 1600, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000046, mae: 0.003480, mean_q: 0.004480
 14142/100000: episode: 1601, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000072, mae: 0.005230, mean_q: 0.006197
 14152/100000: episode: 1602, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000019, mae: 0.003647, mean_q: 0.005856
 14162/100000: episode: 1603, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000051, mae: 0.003810, mean_q: 0.004418
 14172/100000: episode: 1604, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000041, mae: 0.004014, mean_q: 0.006134
 14182/100000: episode: 1605, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000030, mae: 0.003272, mean_q: 0.004467
 14192/100000: episode: 1606, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000036, mae: 0.004184, mean_q: 0.005927
 14202/100000: episode: 1607, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000045, mae: 0.003443, mean_q: 0.005255
 14212/100000: episode: 1608, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000095, mae: 0.003542, mean_q: 0.004977
 14222/100000: episode: 1609, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000031, mae: 0.003877, mean_q: 0.005653
 14232/100000: episode: 1610, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000024, mae: 0.003060, mean_q: 0.004537
 14242/100000: episode: 1611, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000045, mae: 0.003674, mean_q: 0.005621
 14252/100000: episode: 1612, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000037, mae: 0.003944, mean_q: 0.005087
 14262/100000: episode: 1613, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000047, mae: 0.003735, mean_q: 0.005327
 14272/100000: episode: 1614, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000029, mae: 0.003628, mean_q: 0.005291
 14282/100000: episode: 1615, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000049, mae: 0.003625, mean_q: 0.005225
 14292/100000: episode: 1616, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000075, mae: 0.004067, mean_q: 0.005056
 14302/100000: episode: 1617, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000028, mae: 0.003436, mean_q: 0.005338
 14312/100000: episode: 1618, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000049, mae: 0.003440, mean_q: 0.005049
 14322/100000: episode: 1619, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000066, mae: 0.003351, mean_q: 0.004987
 14332/100000: episode: 1620, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000026, mae: 0.003914, mean_q: 0.005774
[Info] 1-TH LEVEL FOUND: 0.006223847158253193, Considering 100/100 traces
 14342/100000: episode: 1621, duration: 0.843s, episode steps: 10, steps per second: 12, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000048, mae: 0.003884, mean_q: 0.005473
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.006223847158253193
 14351/100000: episode: 1622, duration: 0.562s, episode steps: 9, steps per second: 16, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.278 [-1.000, 11.000], loss: 0.000014, mae: 0.002979, mean_q: 0.004975
 14361/100000: episode: 1623, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000046, mae: 0.003366, mean_q: 0.005023
 14371/100000: episode: 1624, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000059, mae: 0.004569, mean_q: 0.006466
 14381/100000: episode: 1625, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000055, mae: 0.004183, mean_q: 0.005689
 14391/100000: episode: 1626, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000023, mae: 0.003633, mean_q: 0.005310
 14401/100000: episode: 1627, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000043, mae: 0.003279, mean_q: 0.005211
 14411/100000: episode: 1628, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000023, mae: 0.003010, mean_q: 0.004589
 14421/100000: episode: 1629, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000059, mae: 0.003826, mean_q: 0.005607
 14431/100000: episode: 1630, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000118, mae: 0.004767, mean_q: 0.006039
 14441/100000: episode: 1631, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000040, mae: 0.003950, mean_q: 0.006301
 14451/100000: episode: 1632, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000026, mae: 0.003416, mean_q: 0.004474
 14461/100000: episode: 1633, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000044, mae: 0.004006, mean_q: 0.005759
 14471/100000: episode: 1634, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000049, mae: 0.003442, mean_q: 0.005233
 14481/100000: episode: 1635, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000015, mae: 0.003008, mean_q: 0.005096
 14491/100000: episode: 1636, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000036, mae: 0.002938, mean_q: 0.004382
 14501/100000: episode: 1637, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000019, mae: 0.003006, mean_q: 0.004861
 14511/100000: episode: 1638, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000055, mae: 0.003761, mean_q: 0.005028
 14521/100000: episode: 1639, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000056, mae: 0.003709, mean_q: 0.005317
 14531/100000: episode: 1640, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000022, mae: 0.003285, mean_q: 0.005092
 14541/100000: episode: 1641, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000035, mae: 0.003346, mean_q: 0.004902
 14551/100000: episode: 1642, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000057, mae: 0.004589, mean_q: 0.007786
 14561/100000: episode: 1643, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000112, mae: 0.004196, mean_q: 0.005448
 14571/100000: episode: 1644, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000029, mae: 0.003676, mean_q: 0.005345
 14581/100000: episode: 1645, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000047, mae: 0.003448, mean_q: 0.005076
 14591/100000: episode: 1646, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000083, mae: 0.004629, mean_q: 0.006178
 14601/100000: episode: 1647, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000094, mae: 0.004572, mean_q: 0.005400
 14611/100000: episode: 1648, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000050, mae: 0.004053, mean_q: 0.005608
 14621/100000: episode: 1649, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000044, mae: 0.003546, mean_q: 0.004760
 14631/100000: episode: 1650, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000042, mae: 0.003431, mean_q: 0.004763
 14641/100000: episode: 1651, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000115, mae: 0.004584, mean_q: 0.005657
 14651/100000: episode: 1652, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000054, mae: 0.004366, mean_q: 0.005908
 14661/100000: episode: 1653, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000030, mae: 0.003643, mean_q: 0.005620
 14671/100000: episode: 1654, duration: 0.110s, episode steps: 10, steps per second: 91, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000096, mae: 0.003770, mean_q: 0.004594
 14681/100000: episode: 1655, duration: 0.076s, episode steps: 10, steps per second: 131, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000030, mae: 0.004220, mean_q: 0.005836
 14691/100000: episode: 1656, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000068, mae: 0.003483, mean_q: 0.004393
 14701/100000: episode: 1657, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000041, mae: 0.003731, mean_q: 0.005731
 14711/100000: episode: 1658, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000197, mae: 0.005503, mean_q: 0.005495
 14721/100000: episode: 1659, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000017, mae: 0.004074, mean_q: 0.006619
 14731/100000: episode: 1660, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000044, mae: 0.003107, mean_q: 0.003516
 14741/100000: episode: 1661, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000025, mae: 0.003678, mean_q: 0.005749
 14751/100000: episode: 1662, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000068, mae: 0.003616, mean_q: 0.004939
 14761/100000: episode: 1663, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000011, mae: 0.002910, mean_q: 0.005243
 14771/100000: episode: 1664, duration: 0.125s, episode steps: 10, steps per second: 80, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000018, mae: 0.002883, mean_q: 0.004328
 14781/100000: episode: 1665, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000062, mae: 0.004526, mean_q: 0.005864
 14791/100000: episode: 1666, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000025, mae: 0.003541, mean_q: 0.005109
 14801/100000: episode: 1667, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000049, mae: 0.003374, mean_q: 0.004384
 14811/100000: episode: 1668, duration: 0.110s, episode steps: 10, steps per second: 91, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000026, mae: 0.003608, mean_q: 0.005340
 14821/100000: episode: 1669, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000025, mae: 0.003400, mean_q: 0.005240
 14831/100000: episode: 1670, duration: 0.072s, episode steps: 10, steps per second: 138, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000053, mae: 0.003922, mean_q: 0.005223
 14841/100000: episode: 1671, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000075, mae: 0.004052, mean_q: 0.005965
 14851/100000: episode: 1672, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000027, mae: 0.003649, mean_q: 0.004980
 14861/100000: episode: 1673, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000053, mae: 0.003863, mean_q: 0.005323
 14871/100000: episode: 1674, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000037, mae: 0.004562, mean_q: 0.006212
 14881/100000: episode: 1675, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000121, mae: 0.004468, mean_q: 0.005068
 14891/100000: episode: 1676, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000013, mae: 0.003386, mean_q: 0.005872
 14901/100000: episode: 1677, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000041, mae: 0.002825, mean_q: 0.003993
 14911/100000: episode: 1678, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000021, mae: 0.003344, mean_q: 0.005484
 14921/100000: episode: 1679, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000018, mae: 0.002781, mean_q: 0.003921
 14931/100000: episode: 1680, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000036, mae: 0.003181, mean_q: 0.005223
 14941/100000: episode: 1681, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000069, mae: 0.003856, mean_q: 0.005213
 14951/100000: episode: 1682, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000044, mae: 0.003657, mean_q: 0.005586
 14961/100000: episode: 1683, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000046, mae: 0.003371, mean_q: 0.004682
 14971/100000: episode: 1684, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000078, mae: 0.004301, mean_q: 0.005328
 14981/100000: episode: 1685, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000023, mae: 0.003588, mean_q: 0.005628
 14991/100000: episode: 1686, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000019, mae: 0.003083, mean_q: 0.004198
 15001/100000: episode: 1687, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000069, mae: 0.003963, mean_q: 0.005987
 15011/100000: episode: 1688, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000056, mae: 0.003830, mean_q: 0.005180
 15021/100000: episode: 1689, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000070, mae: 0.003631, mean_q: 0.005072
 15031/100000: episode: 1690, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000032, mae: 0.003580, mean_q: 0.005753
 15041/100000: episode: 1691, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000040, mae: 0.004467, mean_q: 0.006057
 15051/100000: episode: 1692, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000056, mae: 0.003400, mean_q: 0.004648
 15061/100000: episode: 1693, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000033, mae: 0.003414, mean_q: 0.005199
 15071/100000: episode: 1694, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000122, mae: 0.004810, mean_q: 0.005280
 15081/100000: episode: 1695, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000017, mae: 0.003545, mean_q: 0.006325
 15091/100000: episode: 1696, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000039, mae: 0.003038, mean_q: 0.004037
 15101/100000: episode: 1697, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000206, mae: 0.006631, mean_q: 0.007163
 15111/100000: episode: 1698, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000026, mae: 0.003884, mean_q: 0.005264
 15121/100000: episode: 1699, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000102, mae: 0.004836, mean_q: 0.005197
 15131/100000: episode: 1700, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000016, mae: 0.003858, mean_q: 0.006036
 15141/100000: episode: 1701, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000055, mae: 0.003221, mean_q: 0.004667
 15151/100000: episode: 1702, duration: 0.080s, episode steps: 10, steps per second: 126, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000042, mae: 0.003512, mean_q: 0.005680
 15161/100000: episode: 1703, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000072, mae: 0.003847, mean_q: 0.005228
 15171/100000: episode: 1704, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000025, mae: 0.003686, mean_q: 0.006022
 15181/100000: episode: 1705, duration: 0.104s, episode steps: 10, steps per second: 96, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000051, mae: 0.004139, mean_q: 0.005526
 15191/100000: episode: 1706, duration: 0.119s, episode steps: 10, steps per second: 84, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000027, mae: 0.003415, mean_q: 0.005018
 15201/100000: episode: 1707, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000007, mae: 0.002153, mean_q: 0.004067
 15211/100000: episode: 1708, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000012, mae: 0.002416, mean_q: 0.004107
 15221/100000: episode: 1709, duration: 0.105s, episode steps: 10, steps per second: 96, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000012, mae: 0.003018, mean_q: 0.005255
 15231/100000: episode: 1710, duration: 0.111s, episode steps: 10, steps per second: 90, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000024, mae: 0.003152, mean_q: 0.004465
 15241/100000: episode: 1711, duration: 0.103s, episode steps: 10, steps per second: 97, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000100, mae: 0.004388, mean_q: 0.005403
 15251/100000: episode: 1712, duration: 0.104s, episode steps: 10, steps per second: 96, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000018, mae: 0.003514, mean_q: 0.005518
 15261/100000: episode: 1713, duration: 0.093s, episode steps: 10, steps per second: 108, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000015, mae: 0.002672, mean_q: 0.003571
 15271/100000: episode: 1714, duration: 0.129s, episode steps: 10, steps per second: 78, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000014, mae: 0.002894, mean_q: 0.005075
 15281/100000: episode: 1715, duration: 0.107s, episode steps: 10, steps per second: 93, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000015, mae: 0.002427, mean_q: 0.003822
 15291/100000: episode: 1716, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000047, mae: 0.003431, mean_q: 0.004880
 15301/100000: episode: 1717, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000052, mae: 0.003984, mean_q: 0.005642
 15311/100000: episode: 1718, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000026, mae: 0.003311, mean_q: 0.004935
 15321/100000: episode: 1719, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000012, mae: 0.002267, mean_q: 0.004570
 15331/100000: episode: 1720, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000118, mae: 0.005524, mean_q: 0.006092
 15341/100000: episode: 1721, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000017, mae: 0.003618, mean_q: 0.006377
[Info] 1-TH LEVEL FOUND: 0.006347165908664465, Considering 100/100 traces
 15351/100000: episode: 1722, duration: 0.790s, episode steps: 10, steps per second: 13, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000042, mae: 0.003260, mean_q: 0.004537
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.006347165908664465
 15360/100000: episode: 1723, duration: 0.592s, episode steps: 9, steps per second: 15, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 11.000], loss: 0.000036, mae: 0.003129, mean_q: 0.005578
 15370/100000: episode: 1724, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000107, mae: 0.005369, mean_q: 0.005526
 15380/100000: episode: 1725, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000014, mae: 0.003483, mean_q: 0.005250
 15390/100000: episode: 1726, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000017, mae: 0.002902, mean_q: 0.004004
 15400/100000: episode: 1727, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000099, mae: 0.005288, mean_q: 0.006535
 15410/100000: episode: 1728, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000047, mae: 0.003737, mean_q: 0.005306
 15420/100000: episode: 1729, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000029, mae: 0.003394, mean_q: 0.004540
 15430/100000: episode: 1730, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000052, mae: 0.003968, mean_q: 0.005561
 15440/100000: episode: 1731, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000034, mae: 0.002834, mean_q: 0.004915
 15450/100000: episode: 1732, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000014, mae: 0.002458, mean_q: 0.004084
 15460/100000: episode: 1733, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000071, mae: 0.004532, mean_q: 0.006002
 15470/100000: episode: 1734, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000027, mae: 0.003202, mean_q: 0.005085
 15480/100000: episode: 1735, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000028, mae: 0.003583, mean_q: 0.004461
 15490/100000: episode: 1736, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000067, mae: 0.003893, mean_q: 0.005534
 15500/100000: episode: 1737, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000012, mae: 0.002710, mean_q: 0.004576
 15510/100000: episode: 1738, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000006, mae: 0.002145, mean_q: 0.004169
 15520/100000: episode: 1739, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000036, mae: 0.002695, mean_q: 0.004464
 15530/100000: episode: 1740, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000042, mae: 0.003460, mean_q: 0.005392
 15540/100000: episode: 1741, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000063, mae: 0.003033, mean_q: 0.004121
 15550/100000: episode: 1742, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000073, mae: 0.004502, mean_q: 0.005971
 15560/100000: episode: 1743, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000142, mae: 0.005331, mean_q: 0.005068
 15570/100000: episode: 1744, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000019, mae: 0.004044, mean_q: 0.006496
 15580/100000: episode: 1745, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000058, mae: 0.004114, mean_q: 0.004048
 15590/100000: episode: 1746, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000039, mae: 0.004029, mean_q: 0.006326
 15600/100000: episode: 1747, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000006, mae: 0.002170, mean_q: 0.003450
 15610/100000: episode: 1748, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000058, mae: 0.004470, mean_q: 0.005689
 15620/100000: episode: 1749, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000038, mae: 0.003516, mean_q: 0.005856
 15630/100000: episode: 1750, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000073, mae: 0.003753, mean_q: 0.004343
 15640/100000: episode: 1751, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000023, mae: 0.003687, mean_q: 0.005527
 15650/100000: episode: 1752, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000034, mae: 0.002608, mean_q: 0.004526
 15660/100000: episode: 1753, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000058, mae: 0.004481, mean_q: 0.005847
 15670/100000: episode: 1754, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000055, mae: 0.004474, mean_q: 0.005891
 15680/100000: episode: 1755, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000017, mae: 0.002715, mean_q: 0.004388
 15690/100000: episode: 1756, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000042, mae: 0.003572, mean_q: 0.005998
 15700/100000: episode: 1757, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000081, mae: 0.004585, mean_q: 0.005526
 15710/100000: episode: 1758, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000028, mae: 0.004042, mean_q: 0.006165
 15720/100000: episode: 1759, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000044, mae: 0.003442, mean_q: 0.004361
 15730/100000: episode: 1760, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000038, mae: 0.003464, mean_q: 0.005888
 15740/100000: episode: 1761, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000091, mae: 0.004842, mean_q: 0.005576
 15750/100000: episode: 1762, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000021, mae: 0.003520, mean_q: 0.005634
 15760/100000: episode: 1763, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000020, mae: 0.003186, mean_q: 0.004548
 15770/100000: episode: 1764, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000023, mae: 0.002896, mean_q: 0.005269
 15780/100000: episode: 1765, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000018, mae: 0.002681, mean_q: 0.004373
 15790/100000: episode: 1766, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000083, mae: 0.004346, mean_q: 0.005695
 15800/100000: episode: 1767, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000049, mae: 0.003881, mean_q: 0.005064
 15810/100000: episode: 1768, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000022, mae: 0.003595, mean_q: 0.006061
 15820/100000: episode: 1769, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000021, mae: 0.003389, mean_q: 0.005150
 15830/100000: episode: 1770, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000018, mae: 0.002873, mean_q: 0.005247
 15840/100000: episode: 1771, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000040, mae: 0.003123, mean_q: 0.004622
 15850/100000: episode: 1772, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000015, mae: 0.002674, mean_q: 0.004744
 15860/100000: episode: 1773, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000046, mae: 0.003528, mean_q: 0.005085
 15870/100000: episode: 1774, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000019, mae: 0.002744, mean_q: 0.004386
 15880/100000: episode: 1775, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000043, mae: 0.003221, mean_q: 0.005094
 15890/100000: episode: 1776, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000071, mae: 0.004151, mean_q: 0.005934
 15900/100000: episode: 1777, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000041, mae: 0.003088, mean_q: 0.004536
 15910/100000: episode: 1778, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000026, mae: 0.003211, mean_q: 0.004593
 15920/100000: episode: 1779, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000040, mae: 0.003448, mean_q: 0.005262
 15930/100000: episode: 1780, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000077, mae: 0.004226, mean_q: 0.005489
 15940/100000: episode: 1781, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000075, mae: 0.004765, mean_q: 0.006281
 15950/100000: episode: 1782, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000071, mae: 0.004238, mean_q: 0.005467
 15960/100000: episode: 1783, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000063, mae: 0.003688, mean_q: 0.005493
 15970/100000: episode: 1784, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000015, mae: 0.002596, mean_q: 0.004162
 15980/100000: episode: 1785, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000019, mae: 0.003264, mean_q: 0.005426
 15990/100000: episode: 1786, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000021, mae: 0.003261, mean_q: 0.004885
 16000/100000: episode: 1787, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000100, mae: 0.004556, mean_q: 0.005767
 16010/100000: episode: 1788, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000029, mae: 0.003972, mean_q: 0.005626
 16020/100000: episode: 1789, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000030, mae: 0.003459, mean_q: 0.004923
 16030/100000: episode: 1790, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000089, mae: 0.005257, mean_q: 0.006149
 16040/100000: episode: 1791, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000012, mae: 0.003113, mean_q: 0.005163
 16050/100000: episode: 1792, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000046, mae: 0.003490, mean_q: 0.004245
 16060/100000: episode: 1793, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000039, mae: 0.003743, mean_q: 0.005877
 16070/100000: episode: 1794, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000063, mae: 0.003115, mean_q: 0.004233
 16080/100000: episode: 1795, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000016, mae: 0.002883, mean_q: 0.005068
 16090/100000: episode: 1796, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000042, mae: 0.002826, mean_q: 0.004159
 16100/100000: episode: 1797, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000037, mae: 0.002881, mean_q: 0.005040
 16110/100000: episode: 1798, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000071, mae: 0.004313, mean_q: 0.005713
 16120/100000: episode: 1799, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000016, mae: 0.003164, mean_q: 0.004679
 16130/100000: episode: 1800, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000010, mae: 0.002536, mean_q: 0.004783
 16140/100000: episode: 1801, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000013, mae: 0.001929, mean_q: 0.003998
 16150/100000: episode: 1802, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000037, mae: 0.002656, mean_q: 0.004341
 16160/100000: episode: 1803, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000013, mae: 0.002770, mean_q: 0.005189
 16170/100000: episode: 1804, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000049, mae: 0.003701, mean_q: 0.004720
 16180/100000: episode: 1805, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000058, mae: 0.004758, mean_q: 0.005987
 16190/100000: episode: 1806, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000057, mae: 0.003935, mean_q: 0.005061
 16200/100000: episode: 1807, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000053, mae: 0.004021, mean_q: 0.005770
 16210/100000: episode: 1808, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000068, mae: 0.003771, mean_q: 0.005269
 16220/100000: episode: 1809, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000006, mae: 0.002437, mean_q: 0.004790
 16230/100000: episode: 1810, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000043, mae: 0.003253, mean_q: 0.003981
 16240/100000: episode: 1811, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000015, mae: 0.003340, mean_q: 0.005674
 16250/100000: episode: 1812, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000044, mae: 0.003216, mean_q: 0.004051
 16260/100000: episode: 1813, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000043, mae: 0.003831, mean_q: 0.005702
 16270/100000: episode: 1814, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000012, mae: 0.002684, mean_q: 0.003950
 16280/100000: episode: 1815, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000024, mae: 0.003214, mean_q: 0.004763
 16290/100000: episode: 1816, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000095, mae: 0.004387, mean_q: 0.005715
 16300/100000: episode: 1817, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000023, mae: 0.003861, mean_q: 0.005958
 16310/100000: episode: 1818, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000017, mae: 0.003138, mean_q: 0.004306
 16320/100000: episode: 1819, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000009, mae: 0.002529, mean_q: 0.004724
 16330/100000: episode: 1820, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000018, mae: 0.002694, mean_q: 0.004603
 16340/100000: episode: 1821, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000064, mae: 0.003263, mean_q: 0.004858
 16350/100000: episode: 1822, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000018, mae: 0.002790, mean_q: 0.004691
[Info] 1-TH LEVEL FOUND: 0.005149312783032656, Considering 100/100 traces
 16360/100000: episode: 1823, duration: 0.765s, episode steps: 10, steps per second: 13, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000039, mae: 0.003262, mean_q: 0.005177
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005149312783032656
 16369/100000: episode: 1824, duration: 0.503s, episode steps: 9, steps per second: 18, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.833 [-1.000, 11.000], loss: 0.000016, mae: 0.002502, mean_q: 0.003953
 16379/100000: episode: 1825, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000026, mae: 0.003629, mean_q: 0.004918
 16389/100000: episode: 1826, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000021, mae: 0.003454, mean_q: 0.005085
 16399/100000: episode: 1827, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000021, mae: 0.002981, mean_q: 0.004558
 16409/100000: episode: 1828, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000016, mae: 0.003106, mean_q: 0.005050
 16419/100000: episode: 1829, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000017, mae: 0.003053, mean_q: 0.004819
 16429/100000: episode: 1830, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000026, mae: 0.003387, mean_q: 0.004936
 16439/100000: episode: 1831, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000012, mae: 0.002524, mean_q: 0.004565
 16449/100000: episode: 1832, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000019, mae: 0.002970, mean_q: 0.004759
 16459/100000: episode: 1833, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000015, mae: 0.002811, mean_q: 0.004641
 16469/100000: episode: 1834, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000010, mae: 0.002340, mean_q: 0.004070
 16479/100000: episode: 1835, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000022, mae: 0.003191, mean_q: 0.004783
 16489/100000: episode: 1836, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000012, mae: 0.002576, mean_q: 0.004642
 16499/100000: episode: 1837, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000026, mae: 0.003457, mean_q: 0.004768
 16509/100000: episode: 1838, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000011, mae: 0.002703, mean_q: 0.004692
 16519/100000: episode: 1839, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000018, mae: 0.002771, mean_q: 0.003950
 16529/100000: episode: 1840, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000023, mae: 0.003334, mean_q: 0.004887
 16539/100000: episode: 1841, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000015, mae: 0.002608, mean_q: 0.003819
 16549/100000: episode: 1842, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000017, mae: 0.003270, mean_q: 0.005421
 16559/100000: episode: 1843, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000062, mae: 0.003128, mean_q: 0.004412
 16569/100000: episode: 1844, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000012, mae: 0.002814, mean_q: 0.004597
 16579/100000: episode: 1845, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000045, mae: 0.003088, mean_q: 0.004420
 16589/100000: episode: 1846, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000048, mae: 0.003960, mean_q: 0.005188
 16599/100000: episode: 1847, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000014, mae: 0.002683, mean_q: 0.004211
 16609/100000: episode: 1848, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000019, mae: 0.003173, mean_q: 0.004607
 16619/100000: episode: 1849, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000008, mae: 0.002466, mean_q: 0.004365
 16629/100000: episode: 1850, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000008, mae: 0.002351, mean_q: 0.003834
 16639/100000: episode: 1851, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000053, mae: 0.003655, mean_q: 0.004505
 16649/100000: episode: 1852, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000019, mae: 0.003560, mean_q: 0.005314
 16659/100000: episode: 1853, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000018, mae: 0.002906, mean_q: 0.004269
 16669/100000: episode: 1854, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000034, mae: 0.002601, mean_q: 0.004405
 16679/100000: episode: 1855, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000025, mae: 0.003081, mean_q: 0.004338
 16689/100000: episode: 1856, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000045, mae: 0.003254, mean_q: 0.004528
 16699/100000: episode: 1857, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000057, mae: 0.004537, mean_q: 0.005623
 16709/100000: episode: 1858, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000013, mae: 0.003040, mean_q: 0.004484
 16719/100000: episode: 1859, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000038, mae: 0.003038, mean_q: 0.004582
 16729/100000: episode: 1860, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000021, mae: 0.003067, mean_q: 0.004776
 16739/100000: episode: 1861, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000049, mae: 0.004000, mean_q: 0.005522
 16749/100000: episode: 1862, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000017, mae: 0.002873, mean_q: 0.004396
 16759/100000: episode: 1863, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000037, mae: 0.002811, mean_q: 0.004651
 16769/100000: episode: 1864, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000023, mae: 0.003364, mean_q: 0.004846
 16779/100000: episode: 1865, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000073, mae: 0.004083, mean_q: 0.005229
 16789/100000: episode: 1866, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000042, mae: 0.003242, mean_q: 0.004943
 16799/100000: episode: 1867, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000046, mae: 0.003693, mean_q: 0.005206
 16809/100000: episode: 1868, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000014, mae: 0.002558, mean_q: 0.004058
 16819/100000: episode: 1869, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000023, mae: 0.002990, mean_q: 0.004554
 16829/100000: episode: 1870, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000040, mae: 0.003168, mean_q: 0.004500
 16839/100000: episode: 1871, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000026, mae: 0.003592, mean_q: 0.005231
 16849/100000: episode: 1872, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000010, mae: 0.002490, mean_q: 0.004160
 16859/100000: episode: 1873, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000020, mae: 0.003033, mean_q: 0.004213
 16869/100000: episode: 1874, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000048, mae: 0.003890, mean_q: 0.005060
 16879/100000: episode: 1875, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000071, mae: 0.004269, mean_q: 0.005403
 16889/100000: episode: 1876, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000018, mae: 0.002892, mean_q: 0.004471
 16899/100000: episode: 1877, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000125, mae: 0.004861, mean_q: 0.005323
 16909/100000: episode: 1878, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000054, mae: 0.004447, mean_q: 0.005735
 16919/100000: episode: 1879, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000042, mae: 0.003443, mean_q: 0.005059
 16929/100000: episode: 1880, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000035, mae: 0.002815, mean_q: 0.004569
 16939/100000: episode: 1881, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000014, mae: 0.002658, mean_q: 0.004652
 16949/100000: episode: 1882, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000010, mae: 0.002661, mean_q: 0.004495
 16959/100000: episode: 1883, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000017, mae: 0.002526, mean_q: 0.004104
 16969/100000: episode: 1884, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000045, mae: 0.003474, mean_q: 0.005094
 16979/100000: episode: 1885, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000043, mae: 0.003181, mean_q: 0.004623
 16989/100000: episode: 1886, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000012, mae: 0.002740, mean_q: 0.004941
 16999/100000: episode: 1887, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000049, mae: 0.003318, mean_q: 0.004318
 17009/100000: episode: 1888, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000013, mae: 0.003213, mean_q: 0.005278
 17019/100000: episode: 1889, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000011, mae: 0.002494, mean_q: 0.004146
 17029/100000: episode: 1890, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000018, mae: 0.002703, mean_q: 0.004499
 17039/100000: episode: 1891, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000016, mae: 0.002461, mean_q: 0.004137
 17049/100000: episode: 1892, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000046, mae: 0.003365, mean_q: 0.004708
 17059/100000: episode: 1893, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000043, mae: 0.003430, mean_q: 0.004596
 17069/100000: episode: 1894, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000045, mae: 0.003237, mean_q: 0.004424
 17079/100000: episode: 1895, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000076, mae: 0.003933, mean_q: 0.004640
 17089/100000: episode: 1896, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000103, mae: 0.005769, mean_q: 0.006983
 17099/100000: episode: 1897, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000018, mae: 0.003359, mean_q: 0.004316
 17109/100000: episode: 1898, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000072, mae: 0.003543, mean_q: 0.004312
 17119/100000: episode: 1899, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000036, mae: 0.003448, mean_q: 0.005252
 17129/100000: episode: 1900, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000044, mae: 0.002894, mean_q: 0.003423
 17139/100000: episode: 1901, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000016, mae: 0.003828, mean_q: 0.006231
 17149/100000: episode: 1902, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000016, mae: 0.002694, mean_q: 0.003939
 17159/100000: episode: 1903, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000029, mae: 0.003577, mean_q: 0.005085
 17169/100000: episode: 1904, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000035, mae: 0.002716, mean_q: 0.004193
 17179/100000: episode: 1905, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000016, mae: 0.002987, mean_q: 0.004516
 17189/100000: episode: 1906, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000039, mae: 0.003369, mean_q: 0.005204
 17199/100000: episode: 1907, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000065, mae: 0.003412, mean_q: 0.003922
 17209/100000: episode: 1908, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000077, mae: 0.004911, mean_q: 0.006180
 17219/100000: episode: 1909, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000012, mae: 0.002600, mean_q: 0.003892
 17229/100000: episode: 1910, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000063, mae: 0.003416, mean_q: 0.004658
 17239/100000: episode: 1911, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000022, mae: 0.003263, mean_q: 0.005003
 17249/100000: episode: 1912, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000027, mae: 0.003509, mean_q: 0.005343
 17259/100000: episode: 1913, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000045, mae: 0.003468, mean_q: 0.004806
 17269/100000: episode: 1914, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000009, mae: 0.002470, mean_q: 0.004281
 17279/100000: episode: 1915, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000023, mae: 0.003247, mean_q: 0.004663
 17289/100000: episode: 1916, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000016, mae: 0.003425, mean_q: 0.005342
 17299/100000: episode: 1917, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000047, mae: 0.003228, mean_q: 0.004689
 17309/100000: episode: 1918, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000020, mae: 0.003024, mean_q: 0.004786
 17319/100000: episode: 1919, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000015, mae: 0.003054, mean_q: 0.004853
 17329/100000: episode: 1920, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000039, mae: 0.003210, mean_q: 0.004940
 17339/100000: episode: 1921, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000045, mae: 0.003450, mean_q: 0.004221
 17349/100000: episode: 1922, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000013, mae: 0.003447, mean_q: 0.005748
 17359/100000: episode: 1923, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000022, mae: 0.003175, mean_q: 0.004163
[Info] 1-TH LEVEL FOUND: 0.005006697494536638, Considering 100/100 traces
 17369/100000: episode: 1924, duration: 0.781s, episode steps: 10, steps per second: 13, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000015, mae: 0.002439, mean_q: 0.004446
[Info] 2-TH LEVEL FOUND: 0.005996264051645994, Considering 100/100 traces
 17378/100000: episode: 1925, duration: 0.700s, episode steps: 9, steps per second: 13, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.389 [-1.000, 11.000], loss: 0.000021, mae: 0.002782, mean_q: 0.004427
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005996264051645994
 17387/100000: episode: 1926, duration: 0.493s, episode steps: 9, steps per second: 18, episode reward: 0.014, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.778 [-1.000, 11.000], loss: 0.000010, mae: 0.003034, mean_q: 0.005684
 17397/100000: episode: 1927, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000026, mae: 0.003186, mean_q: 0.003753
 17407/100000: episode: 1928, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000011, mae: 0.002884, mean_q: 0.005015
 17417/100000: episode: 1929, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000016, mae: 0.002775, mean_q: 0.004009
 17427/100000: episode: 1930, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000021, mae: 0.003401, mean_q: 0.005034
 17437/100000: episode: 1931, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000016, mae: 0.003060, mean_q: 0.004882
 17447/100000: episode: 1932, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000018, mae: 0.002804, mean_q: 0.004381
 17457/100000: episode: 1933, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000020, mae: 0.003042, mean_q: 0.004580
 17467/100000: episode: 1934, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000011, mae: 0.002878, mean_q: 0.004950
 17477/100000: episode: 1935, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000014, mae: 0.002578, mean_q: 0.004007
 17487/100000: episode: 1936, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000012, mae: 0.002610, mean_q: 0.004358
 17497/100000: episode: 1937, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000018, mae: 0.002775, mean_q: 0.004439
 17507/100000: episode: 1938, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000043, mae: 0.003229, mean_q: 0.004480
 17517/100000: episode: 1939, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000010, mae: 0.002382, mean_q: 0.004298
 17527/100000: episode: 1940, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000045, mae: 0.003000, mean_q: 0.004047
 17537/100000: episode: 1941, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000071, mae: 0.003972, mean_q: 0.005041
 17547/100000: episode: 1942, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000019, mae: 0.003756, mean_q: 0.005941
 17557/100000: episode: 1943, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000046, mae: 0.003397, mean_q: 0.003922
 17567/100000: episode: 1944, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000050, mae: 0.004431, mean_q: 0.005909
 17577/100000: episode: 1945, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000041, mae: 0.003099, mean_q: 0.004009
 17587/100000: episode: 1946, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000041, mae: 0.003072, mean_q: 0.004586
 17597/100000: episode: 1947, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000010, mae: 0.002604, mean_q: 0.004755
 17607/100000: episode: 1948, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000025, mae: 0.003100, mean_q: 0.004338
 17617/100000: episode: 1949, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000040, mae: 0.003748, mean_q: 0.005599
 17627/100000: episode: 1950, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000015, mae: 0.002824, mean_q: 0.003964
 17637/100000: episode: 1951, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000007, mae: 0.002103, mean_q: 0.003912
 17647/100000: episode: 1952, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000008, mae: 0.002249, mean_q: 0.003967
 17657/100000: episode: 1953, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000009, mae: 0.002023, mean_q: 0.003704
 17667/100000: episode: 1954, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000014, mae: 0.002510, mean_q: 0.004312
 17677/100000: episode: 1955, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000015, mae: 0.002543, mean_q: 0.003661
 17687/100000: episode: 1956, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000011, mae: 0.002623, mean_q: 0.004387
 17697/100000: episode: 1957, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000020, mae: 0.002983, mean_q: 0.004104
 17707/100000: episode: 1958, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000046, mae: 0.004009, mean_q: 0.005130
 17717/100000: episode: 1959, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000051, mae: 0.003709, mean_q: 0.004789
 17727/100000: episode: 1960, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000048, mae: 0.003565, mean_q: 0.004991
 17737/100000: episode: 1961, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000039, mae: 0.003230, mean_q: 0.004958
 17747/100000: episode: 1962, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000009, mae: 0.002512, mean_q: 0.004034
 17757/100000: episode: 1963, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000016, mae: 0.002875, mean_q: 0.004416
 17767/100000: episode: 1964, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000020, mae: 0.002636, mean_q: 0.003944
 17777/100000: episode: 1965, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000016, mae: 0.003029, mean_q: 0.004668
 17787/100000: episode: 1966, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000017, mae: 0.003025, mean_q: 0.004884
 17797/100000: episode: 1967, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000010, mae: 0.002432, mean_q: 0.003731
 17807/100000: episode: 1968, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000015, mae: 0.003143, mean_q: 0.004944
 17817/100000: episode: 1969, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000019, mae: 0.003141, mean_q: 0.004684
[Info] FALSIFICATION!
 17827/100000: episode: 1970, duration: 0.203s, episode steps: 10, steps per second: 49, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.000014, mae: 0.002545, mean_q: 0.003673
 17837/100000: episode: 1971, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000011, mae: 0.002553, mean_q: 0.004269
 17847/100000: episode: 1972, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000018, mae: 0.003070, mean_q: 0.004381
 17857/100000: episode: 1973, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000016, mae: 0.003257, mean_q: 0.004979
 17867/100000: episode: 1974, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000022, mae: 0.003074, mean_q: 0.004396
 17877/100000: episode: 1975, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000851, mae: 0.006579, mean_q: 0.007523
 17887/100000: episode: 1976, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000205, mae: 0.006244, mean_q: 0.004826
 17897/100000: episode: 1977, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000011, mae: 0.003308, mean_q: 0.004636
 17907/100000: episode: 1978, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000084, mae: 0.004039, mean_q: 0.006200
 17917/100000: episode: 1979, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000340, mae: 0.004962, mean_q: 0.007999
 17927/100000: episode: 1980, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000131, mae: 0.004352, mean_q: 0.006488
 17937/100000: episode: 1981, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000078, mae: 0.003384, mean_q: 0.002959
 17947/100000: episode: 1982, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000014, mae: 0.002773, mean_q: 0.004286
 17957/100000: episode: 1983, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000009, mae: 0.003071, mean_q: 0.005047
 17967/100000: episode: 1984, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000057, mae: 0.003568, mean_q: 0.003918
 17977/100000: episode: 1985, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000267, mae: 0.005627, mean_q: 0.007275
 17987/100000: episode: 1986, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000014, mae: 0.003222, mean_q: 0.003818
 17997/100000: episode: 1987, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000048, mae: 0.004498, mean_q: 0.005367
 18007/100000: episode: 1988, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000047, mae: 0.004633, mean_q: 0.008248
 18017/100000: episode: 1989, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000017, mae: 0.002817, mean_q: 0.002216
 18027/100000: episode: 1990, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000121, mae: 0.004743, mean_q: 0.006011
 18037/100000: episode: 1991, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000011, mae: 0.002517, mean_q: 0.004408
 18047/100000: episode: 1992, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000018, mae: 0.002707, mean_q: 0.004064
 18057/100000: episode: 1993, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000051, mae: 0.003145, mean_q: 0.004890
 18067/100000: episode: 1994, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000077, mae: 0.003645, mean_q: 0.004396
 18077/100000: episode: 1995, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000018, mae: 0.003119, mean_q: 0.004746
 18087/100000: episode: 1996, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000015, mae: 0.002391, mean_q: 0.004072
 18097/100000: episode: 1997, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000066, mae: 0.003780, mean_q: 0.004597
 18107/100000: episode: 1998, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000032, mae: 0.004071, mean_q: 0.005654
 18117/100000: episode: 1999, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000019, mae: 0.003071, mean_q: 0.004011
 18127/100000: episode: 2000, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000015, mae: 0.002810, mean_q: 0.004688
 18137/100000: episode: 2001, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000052, mae: 0.003541, mean_q: 0.005235
 18147/100000: episode: 2002, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000021, mae: 0.002836, mean_q: 0.004272
 18157/100000: episode: 2003, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000088, mae: 0.003668, mean_q: 0.005818
 18167/100000: episode: 2004, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000023, mae: 0.003432, mean_q: 0.005574
 18177/100000: episode: 2005, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000282, mae: 0.004729, mean_q: 0.008583
 18187/100000: episode: 2006, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000022, mae: 0.002722, mean_q: 0.002599
 18197/100000: episode: 2007, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000012, mae: 0.002908, mean_q: 0.004767
 18207/100000: episode: 2008, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000075, mae: 0.003652, mean_q: 0.004587
 18217/100000: episode: 2009, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000010, mae: 0.002696, mean_q: 0.004961
 18227/100000: episode: 2010, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000238, mae: 0.004376, mean_q: 0.003866
 18237/100000: episode: 2011, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000070, mae: 0.003857, mean_q: 0.005629
 18247/100000: episode: 2012, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000070, mae: 0.004342, mean_q: 0.007133
 18257/100000: episode: 2013, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000035, mae: 0.003356, mean_q: 0.001869
 18267/100000: episode: 2014, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000240, mae: 0.004399, mean_q: 0.005837
 18277/100000: episode: 2015, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000617, mae: 0.005970, mean_q: 0.006243
 18287/100000: episode: 2016, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000017, mae: 0.003931, mean_q: 0.005872
 18297/100000: episode: 2017, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000031, mae: 0.002959, mean_q: 0.002931
 18307/100000: episode: 2018, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000159, mae: 0.005155, mean_q: 0.007952
 18317/100000: episode: 2019, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000011, mae: 0.002784, mean_q: 0.004715
 18327/100000: episode: 2020, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000030, mae: 0.003074, mean_q: 0.003748
 18337/100000: episode: 2021, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000012, mae: 0.002467, mean_q: 0.004036
 18347/100000: episode: 2022, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000140, mae: 0.003700, mean_q: 0.006639
 18357/100000: episode: 2023, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000032, mae: 0.003853, mean_q: 0.006309
 18367/100000: episode: 2024, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000388, mae: 0.004879, mean_q: 0.003901
 18377/100000: episode: 2025, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000023, mae: 0.002760, mean_q: 0.003937
[Info] Complete ISplit Iteration
[Info] Levels: [0.75355345]
[Info] Cond. Prob: [0.01]
[Info] Error Prob: 0.01

 18387/100000: episode: 2026, duration: 0.796s, episode steps: 10, steps per second: 13, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000045, mae: 0.003993, mean_q: 0.005049
 18397/100000: episode: 2027, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000054, mae: 0.003900, mean_q: 0.004639
 18407/100000: episode: 2028, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000521, mae: 0.009645, mean_q: 0.010684
 18417/100000: episode: 2029, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000051, mae: 0.004720, mean_q: 0.008013
 18427/100000: episode: 2030, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000065, mae: 0.004032, mean_q: 0.003375
 18437/100000: episode: 2031, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000041, mae: 0.004414, mean_q: 0.007250
 18447/100000: episode: 2032, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000047, mae: 0.003710, mean_q: 0.004982
 18457/100000: episode: 2033, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000048, mae: 0.003861, mean_q: 0.005474
 18467/100000: episode: 2034, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000115, mae: 0.004076, mean_q: 0.006746
 18477/100000: episode: 2035, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000018, mae: 0.002369, mean_q: 0.003666
 18487/100000: episode: 2036, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000054, mae: 0.003756, mean_q: 0.005665
 18497/100000: episode: 2037, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000017, mae: 0.002874, mean_q: 0.004704
 18507/100000: episode: 2038, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000174, mae: 0.004036, mean_q: 0.004352
 18517/100000: episode: 2039, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000120, mae: 0.003142, mean_q: 0.005209
 18527/100000: episode: 2040, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000016, mae: 0.002242, mean_q: 0.003011
 18537/100000: episode: 2041, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000034, mae: 0.003184, mean_q: 0.004400
 18547/100000: episode: 2042, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000013, mae: 0.003108, mean_q: 0.004777
 18557/100000: episode: 2043, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000503, mae: 0.005674, mean_q: 0.007256
 18567/100000: episode: 2044, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000025, mae: 0.003318, mean_q: 0.004470
 18577/100000: episode: 2045, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000211, mae: 0.003859, mean_q: 0.004052
 18587/100000: episode: 2046, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000064, mae: 0.003870, mean_q: 0.005702
 18597/100000: episode: 2047, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000200, mae: 0.005598, mean_q: 0.008821
 18607/100000: episode: 2048, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000066, mae: 0.003845, mean_q: 0.004977
 18617/100000: episode: 2049, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000411, mae: 0.004554, mean_q: 0.010265
 18627/100000: episode: 2050, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000016, mae: 0.002850, mean_q: 0.004004
 18637/100000: episode: 2051, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000012, mae: 0.003280, mean_q: 0.005055
 18647/100000: episode: 2052, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000037, mae: 0.002981, mean_q: 0.003852
 18657/100000: episode: 2053, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000010, mae: 0.002530, mean_q: 0.004278
 18667/100000: episode: 2054, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000010, mae: 0.002300, mean_q: 0.003673
 18677/100000: episode: 2055, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000016, mae: 0.002654, mean_q: 0.004626
 18687/100000: episode: 2056, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000027, mae: 0.003259, mean_q: 0.004958
 18697/100000: episode: 2057, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000034, mae: 0.003224, mean_q: 0.005782
 18707/100000: episode: 2058, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000209, mae: 0.004271, mean_q: 0.002851
 18717/100000: episode: 2059, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000007, mae: 0.002264, mean_q: 0.003223
 18727/100000: episode: 2060, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000021, mae: 0.003694, mean_q: 0.005052
 18737/100000: episode: 2061, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000017, mae: 0.002899, mean_q: 0.004619
 18747/100000: episode: 2062, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000015, mae: 0.002649, mean_q: 0.004110
 18757/100000: episode: 2063, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000013, mae: 0.002450, mean_q: 0.004495
 18767/100000: episode: 2064, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000105, mae: 0.003401, mean_q: 0.004893
 18777/100000: episode: 2065, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000037, mae: 0.003278, mean_q: 0.004516
 18787/100000: episode: 2066, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000015, mae: 0.002516, mean_q: 0.002233
 18797/100000: episode: 2067, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000055, mae: 0.003770, mean_q: 0.006022
 18807/100000: episode: 2068, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000026, mae: 0.002580, mean_q: 0.004145
 18817/100000: episode: 2069, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000026, mae: 0.002756, mean_q: 0.003294
 18827/100000: episode: 2070, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000016, mae: 0.002482, mean_q: 0.004173
 18837/100000: episode: 2071, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000009, mae: 0.002322, mean_q: 0.004277
 18847/100000: episode: 2072, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000094, mae: 0.002941, mean_q: 0.004958
 18857/100000: episode: 2073, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000080, mae: 0.005263, mean_q: 0.009571
 18867/100000: episode: 2074, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000025, mae: 0.003475, mean_q: 0.001898
 18877/100000: episode: 2075, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000038, mae: 0.003596, mean_q: 0.006528
 18887/100000: episode: 2076, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000019, mae: 0.002317, mean_q: 0.003330
 18897/100000: episode: 2077, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000014, mae: 0.002730, mean_q: 0.002766
 18907/100000: episode: 2078, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000075, mae: 0.003942, mean_q: 0.005299
 18917/100000: episode: 2079, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000009, mae: 0.002199, mean_q: 0.003622
 18927/100000: episode: 2080, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000028, mae: 0.002964, mean_q: 0.005456
 18937/100000: episode: 2081, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000077, mae: 0.003889, mean_q: 0.006289
 18947/100000: episode: 2082, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000017, mae: 0.003635, mean_q: 0.002185
 18957/100000: episode: 2083, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000051, mae: 0.004326, mean_q: 0.005073
 18967/100000: episode: 2084, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000036, mae: 0.003685, mean_q: 0.004577
 18977/100000: episode: 2085, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000023, mae: 0.002705, mean_q: 0.003271
 18987/100000: episode: 2086, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000083, mae: 0.003525, mean_q: 0.005140
 18997/100000: episode: 2087, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000009, mae: 0.002285, mean_q: 0.003903
 19007/100000: episode: 2088, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000024, mae: 0.002623, mean_q: 0.003103
 19017/100000: episode: 2089, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000345, mae: 0.006039, mean_q: 0.008326
 19027/100000: episode: 2090, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000017, mae: 0.003559, mean_q: 0.003319
 19037/100000: episode: 2091, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000078, mae: 0.003643, mean_q: 0.003213
 19047/100000: episode: 2092, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000046, mae: 0.003519, mean_q: 0.005380
 19057/100000: episode: 2093, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000028, mae: 0.003810, mean_q: 0.004126
 19067/100000: episode: 2094, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000016, mae: 0.003694, mean_q: 0.004953
 19077/100000: episode: 2095, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000015, mae: 0.002705, mean_q: 0.003874
 19087/100000: episode: 2096, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000246, mae: 0.005294, mean_q: 0.007859
 19097/100000: episode: 2097, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000019, mae: 0.003524, mean_q: 0.002576
 19107/100000: episode: 2098, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000015, mae: 0.002585, mean_q: 0.004028
 19117/100000: episode: 2099, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000070, mae: 0.003197, mean_q: 0.004768
 19127/100000: episode: 2100, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000046, mae: 0.002934, mean_q: 0.003376
 19137/100000: episode: 2101, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000031, mae: 0.004024, mean_q: 0.005813
 19147/100000: episode: 2102, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000014, mae: 0.002569, mean_q: 0.003671
 19157/100000: episode: 2103, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000019, mae: 0.002933, mean_q: 0.004151
 19167/100000: episode: 2104, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000018, mae: 0.002323, mean_q: 0.003936
 19177/100000: episode: 2105, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000048, mae: 0.003149, mean_q: 0.004546
 19187/100000: episode: 2106, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000687, mae: 0.005795, mean_q: 0.007513
 19197/100000: episode: 2107, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000082, mae: 0.005915, mean_q: 0.008604
 19207/100000: episode: 2108, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000097, mae: 0.006545, mean_q: 0.003712
 19217/100000: episode: 2109, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000514, mae: 0.005028, mean_q: 0.005093
 19227/100000: episode: 2110, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000030, mae: 0.003699, mean_q: 0.004039
 19237/100000: episode: 2111, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000026, mae: 0.003909, mean_q: 0.003967
 19247/100000: episode: 2112, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000020, mae: 0.003054, mean_q: 0.003262
 19257/100000: episode: 2113, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000032, mae: 0.003695, mean_q: 0.003840
 19267/100000: episode: 2114, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000015, mae: 0.002893, mean_q: 0.004050
 19277/100000: episode: 2115, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000009, mae: 0.002538, mean_q: 0.003015
 19287/100000: episode: 2116, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000007, mae: 0.002179, mean_q: 0.003419
 19297/100000: episode: 2117, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000051, mae: 0.003040, mean_q: 0.003433
 19307/100000: episode: 2118, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000042, mae: 0.003033, mean_q: 0.003746
 19317/100000: episode: 2119, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000015, mae: 0.002513, mean_q: 0.003517
 19327/100000: episode: 2120, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000225, mae: 0.004527, mean_q: 0.005459
 19337/100000: episode: 2121, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000014, mae: 0.003094, mean_q: 0.005046
 19347/100000: episode: 2122, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000013, mae: 0.002369, mean_q: 0.003110
 19357/100000: episode: 2123, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000009, mae: 0.001832, mean_q: 0.003305
 19367/100000: episode: 2124, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000045, mae: 0.002684, mean_q: 0.003838
 19377/100000: episode: 2125, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000096, mae: 0.003696, mean_q: 0.004767
[Info] 1-TH LEVEL FOUND: 0.01945725455880165, Considering 13/100 traces
 19387/100000: episode: 2126, duration: 0.669s, episode steps: 10, steps per second: 15, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000055, mae: 0.003266, mean_q: 0.003656
 19391/100000: episode: 2127, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000013, mae: 0.003367, mean_q: 0.005568
 19394/100000: episode: 2128, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000458, mae: 0.005669, mean_q: 0.009359
 19397/100000: episode: 2129, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000016, mae: 0.003496, mean_q: 0.006739
 19400/100000: episode: 2130, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000019, mae: 0.003293, mean_q: 0.006841
 19403/100000: episode: 2131, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000010, mae: 0.002565, mean_q: 0.002988
 19406/100000: episode: 2132, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000013, mae: 0.002951, mean_q: 0.001616
 19410/100000: episode: 2133, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000028, mae: 0.003620, mean_q: 0.003327
 19413/100000: episode: 2134, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000023, mae: 0.002927, mean_q: 0.004108
 19416/100000: episode: 2135, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000221, mae: 0.004717, mean_q: 0.006270
 19419/100000: episode: 2136, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000015, mae: 0.002354, mean_q: 0.002306
 19422/100000: episode: 2137, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000021, mae: 0.002470, mean_q: 0.002708
 19425/100000: episode: 2138, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000034, mae: 0.003673, mean_q: 0.003881
 19428/100000: episode: 2139, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000056, mae: 0.004905, mean_q: 0.006025
 19432/100000: episode: 2140, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000020, mae: 0.003336, mean_q: 0.004711
 19435/100000: episode: 2141, duration: 0.022s, episode steps: 3, steps per second: 139, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000017, mae: 0.002059, mean_q: 0.002747
 19438/100000: episode: 2142, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000010, mae: 0.001669, mean_q: 0.003109
 19441/100000: episode: 2143, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000034, mae: 0.003007, mean_q: 0.003266
 19444/100000: episode: 2144, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000032, mae: 0.003346, mean_q: 0.003910
 19448/100000: episode: 2145, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000112, mae: 0.004674, mean_q: 0.005005
 19452/100000: episode: 2146, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000082, mae: 0.004732, mean_q: 0.006158
 19456/100000: episode: 2147, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000009, mae: 0.002590, mean_q: 0.004808
 19459/100000: episode: 2148, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000016, mae: 0.002755, mean_q: 0.004572
 19462/100000: episode: 2149, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000019, mae: 0.002881, mean_q: 0.002934
 19465/100000: episode: 2150, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000026, mae: 0.003987, mean_q: 0.004307
 19468/100000: episode: 2151, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000012, mae: 0.002702, mean_q: 0.002345
 19471/100000: episode: 2152, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000017, mae: 0.003019, mean_q: 0.003636
 19475/100000: episode: 2153, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000083, mae: 0.003879, mean_q: 0.004600
 19479/100000: episode: 2154, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000020, mae: 0.003480, mean_q: 0.005204
 19482/100000: episode: 2155, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000113, mae: 0.005038, mean_q: 0.005797
 19486/100000: episode: 2156, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000008, mae: 0.002621, mean_q: 0.004715
 19489/100000: episode: 2157, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000012, mae: 0.002347, mean_q: 0.004656
 19493/100000: episode: 2158, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000014, mae: 0.002516, mean_q: 0.003876
 19497/100000: episode: 2159, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000030, mae: 0.003122, mean_q: 0.004135
 19500/100000: episode: 2160, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000007, mae: 0.001757, mean_q: 0.003434
 19503/100000: episode: 2161, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000015, mae: 0.002411, mean_q: 0.003880
 19507/100000: episode: 2162, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000022, mae: 0.002774, mean_q: 0.004579
 19510/100000: episode: 2163, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000016, mae: 0.002622, mean_q: 0.004630
 19514/100000: episode: 2164, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000034, mae: 0.003571, mean_q: 0.004915
 19518/100000: episode: 2165, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000010, mae: 0.001699, mean_q: 0.003125
 19521/100000: episode: 2166, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000019, mae: 0.002654, mean_q: 0.004927
 19525/100000: episode: 2167, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000073, mae: 0.003530, mean_q: 0.004666
 19529/100000: episode: 2168, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000425, mae: 0.006412, mean_q: 0.008489
 19532/100000: episode: 2169, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000083, mae: 0.004978, mean_q: 0.008189
 19535/100000: episode: 2170, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000138, mae: 0.006176, mean_q: 0.010145
 19538/100000: episode: 2171, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000043, mae: 0.004488, mean_q: 0.004279
 19541/100000: episode: 2172, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000103, mae: 0.005811, mean_q: 0.000508
 19545/100000: episode: 2173, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000013, mae: 0.002824, mean_q: 0.001782
 19548/100000: episode: 2174, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000039, mae: 0.004047, mean_q: 0.005540
 19551/100000: episode: 2175, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000094, mae: 0.005313, mean_q: 0.006419
 19554/100000: episode: 2176, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000102, mae: 0.006161, mean_q: 0.007667
 19557/100000: episode: 2177, duration: 0.016s, episode steps: 3, steps per second: 186, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000020, mae: 0.003639, mean_q: 0.006308
 19560/100000: episode: 2178, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000085, mae: 0.004475, mean_q: 0.006684
 19563/100000: episode: 2179, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000017, mae: 0.002774, mean_q: 0.003900
 19566/100000: episode: 2180, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000033, mae: 0.004147, mean_q: 0.004064
 19569/100000: episode: 2181, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000019, mae: 0.003590, mean_q: 0.002241
 19572/100000: episode: 2182, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000056, mae: 0.004783, mean_q: 0.003933
 19575/100000: episode: 2183, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000056, mae: 0.004622, mean_q: 0.005751
 19578/100000: episode: 2184, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000017, mae: 0.003684, mean_q: 0.006354
 19581/100000: episode: 2185, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000010, mae: 0.003206, mean_q: 0.006487
 19585/100000: episode: 2186, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000183, mae: 0.005627, mean_q: 0.006718
 19588/100000: episode: 2187, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000019, mae: 0.003331, mean_q: 0.006044
 19591/100000: episode: 2188, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000051, mae: 0.005050, mean_q: 0.008428
 19594/100000: episode: 2189, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000018, mae: 0.002714, mean_q: 0.003672
 19597/100000: episode: 2190, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000029, mae: 0.003634, mean_q: 0.002807
 19601/100000: episode: 2191, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000038, mae: 0.003814, mean_q: 0.005104
 19604/100000: episode: 2192, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000016, mae: 0.002662, mean_q: 0.005290
 19607/100000: episode: 2193, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000089, mae: 0.004147, mean_q: 0.005502
 19611/100000: episode: 2194, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000039, mae: 0.003929, mean_q: 0.005857
 19614/100000: episode: 2195, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000030, mae: 0.003425, mean_q: 0.005166
 19617/100000: episode: 2196, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000078, mae: 0.005857, mean_q: 0.007021
 19620/100000: episode: 2197, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000041, mae: 0.004158, mean_q: 0.006822
 19623/100000: episode: 2198, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000013, mae: 0.002154, mean_q: 0.003468
 19626/100000: episode: 2199, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000015, mae: 0.002778, mean_q: 0.002794
 19629/100000: episode: 2200, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000033, mae: 0.003652, mean_q: 0.003707
 19632/100000: episode: 2201, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000017, mae: 0.003095, mean_q: 0.004676
 19635/100000: episode: 2202, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000037, mae: 0.005140, mean_q: 0.008632
 19639/100000: episode: 2203, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000019, mae: 0.003721, mean_q: 0.005940
 19642/100000: episode: 2204, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000062, mae: 0.005045, mean_q: 0.005509
 19646/100000: episode: 2205, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000043, mae: 0.004013, mean_q: 0.004383
 19650/100000: episode: 2206, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000043, mae: 0.004220, mean_q: 0.004897
 19653/100000: episode: 2207, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000027, mae: 0.003214, mean_q: 0.004947
 19656/100000: episode: 2208, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000032, mae: 0.003714, mean_q: 0.005079
 19659/100000: episode: 2209, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000049, mae: 0.004591, mean_q: 0.006312
 19663/100000: episode: 2210, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000053, mae: 0.004518, mean_q: 0.005109
 19667/100000: episode: 2211, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000016, mae: 0.003058, mean_q: 0.004839
 19671/100000: episode: 2212, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000030, mae: 0.003044, mean_q: 0.004570
[Info] 2-TH LEVEL FOUND: 0.04761342331767082, Considering 10/100 traces
 19674/100000: episode: 2213, duration: 0.787s, episode steps: 3, steps per second: 4, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000042, mae: 0.004241, mean_q: 0.004943
 19676/100000: episode: 2214, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000025, mae: 0.003504, mean_q: 0.006427
 19678/100000: episode: 2215, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000147, mae: 0.005579, mean_q: 0.006355
 19680/100000: episode: 2216, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000070, mae: 0.005127, mean_q: 0.006457
 19682/100000: episode: 2217, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000023, mae: 0.003699, mean_q: 0.007309
 19684/100000: episode: 2218, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000041, mae: 0.004695, mean_q: 0.007106
 19686/100000: episode: 2219, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000047, mae: 0.004466, mean_q: 0.007012
 19688/100000: episode: 2220, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000038, mae: 0.004404, mean_q: 0.003110
 19690/100000: episode: 2221, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000105, mae: 0.007013, mean_q: 0.004034
 19692/100000: episode: 2222, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000035, mae: 0.004557, mean_q: 0.002099
 19694/100000: episode: 2223, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000025, mae: 0.003186, mean_q: 0.002892
 19696/100000: episode: 2224, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000037, mae: 0.004065, mean_q: 0.004337
 19698/100000: episode: 2225, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000032, mae: 0.004171, mean_q: 0.005534
 19700/100000: episode: 2226, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000144, mae: 0.005669, mean_q: 0.005980
 19702/100000: episode: 2227, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000087, mae: 0.007311, mean_q: 0.007979
 19704/100000: episode: 2228, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000040, mae: 0.005241, mean_q: 0.007314
 19706/100000: episode: 2229, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000029, mae: 0.004678, mean_q: 0.007413
 19708/100000: episode: 2230, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000056, mae: 0.005277, mean_q: 0.006803
 19710/100000: episode: 2231, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000169, mae: 0.007070, mean_q: 0.007089
 19712/100000: episode: 2232, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000041, mae: 0.004070, mean_q: 0.005534
 19714/100000: episode: 2233, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000161, mae: 0.005976, mean_q: 0.005998
 19716/100000: episode: 2234, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000039, mae: 0.003473, mean_q: 0.005351
 19718/100000: episode: 2235, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000164, mae: 0.006568, mean_q: 0.007918
 19720/100000: episode: 2236, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000006, mae: 0.002327, mean_q: 0.004545
 19722/100000: episode: 2237, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000025, mae: 0.004174, mean_q: 0.007650
 19724/100000: episode: 2238, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000090, mae: 0.006451, mean_q: 0.008086
 19726/100000: episode: 2239, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000038, mae: 0.004359, mean_q: 0.005763
 19728/100000: episode: 2240, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000019, mae: 0.002897, mean_q: 0.003557
 19730/100000: episode: 2241, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000036, mae: 0.004065, mean_q: 0.003690
 19732/100000: episode: 2242, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000153, mae: 0.005954, mean_q: 0.004221
 19734/100000: episode: 2243, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000018, mae: 0.002672, mean_q: 0.003574
 19736/100000: episode: 2244, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000047, mae: 0.003635, mean_q: 0.005571
 19738/100000: episode: 2245, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000282, mae: 0.009730, mean_q: 0.007454
 19740/100000: episode: 2246, duration: 0.014s, episode steps: 2, steps per second: 144, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000045, mae: 0.004302, mean_q: 0.006321
 19742/100000: episode: 2247, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000055, mae: 0.005377, mean_q: 0.007315
 19744/100000: episode: 2248, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000024, mae: 0.003095, mean_q: 0.004905
 19746/100000: episode: 2249, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000147, mae: 0.005048, mean_q: 0.006123
 19748/100000: episode: 2250, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000054, mae: 0.004209, mean_q: 0.005368
 19750/100000: episode: 2251, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000136, mae: 0.004324, mean_q: 0.005521
 19752/100000: episode: 2252, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000040, mae: 0.003808, mean_q: 0.004943
 19754/100000: episode: 2253, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000058, mae: 0.004902, mean_q: 0.006121
 19756/100000: episode: 2254, duration: 0.019s, episode steps: 2, steps per second: 107, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000037, mae: 0.003371, mean_q: 0.004710
 19758/100000: episode: 2255, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000232, mae: 0.007096, mean_q: 0.005192
 19760/100000: episode: 2256, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000169, mae: 0.005736, mean_q: 0.007313
 19762/100000: episode: 2257, duration: 0.015s, episode steps: 2, steps per second: 133, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000043, mae: 0.003861, mean_q: 0.004599
 19764/100000: episode: 2258, duration: 0.014s, episode steps: 2, steps per second: 144, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000047, mae: 0.004836, mean_q: 0.007994
 19766/100000: episode: 2259, duration: 0.015s, episode steps: 2, steps per second: 136, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000037, mae: 0.004156, mean_q: 0.005979
 19768/100000: episode: 2260, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000188, mae: 0.006136, mean_q: 0.006487
 19770/100000: episode: 2261, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000019, mae: 0.003088, mean_q: 0.004453
 19772/100000: episode: 2262, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000053, mae: 0.004906, mean_q: 0.005769
 19774/100000: episode: 2263, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000060, mae: 0.004692, mean_q: 0.003278
 19776/100000: episode: 2264, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000012, mae: 0.002259, mean_q: 0.002933
 19778/100000: episode: 2265, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002052, mae: 0.011178, mean_q: 0.012397
 19780/100000: episode: 2266, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000064, mae: 0.006962, mean_q: 0.010298
 19782/100000: episode: 2267, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000337, mae: 0.010104, mean_q: 0.015672
 19784/100000: episode: 2268, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000155, mae: 0.006213, mean_q: 0.009484
 19786/100000: episode: 2269, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000029, mae: 0.004014, mean_q: 0.001797
 19788/100000: episode: 2270, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000086, mae: 0.007225, mean_q: 0.002892
 19790/100000: episode: 2271, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000198, mae: 0.007905, mean_q: 0.001508
 19792/100000: episode: 2272, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000165, mae: 0.005943, mean_q: 0.004995
 19794/100000: episode: 2273, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000055, mae: 0.005849, mean_q: 0.007929
 19796/100000: episode: 2274, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000061, mae: 0.007033, mean_q: 0.009993
 19798/100000: episode: 2275, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000055, mae: 0.006364, mean_q: 0.010543
 19800/100000: episode: 2276, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000023, mae: 0.004548, mean_q: 0.007345
 19802/100000: episode: 2277, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000038, mae: 0.004058, mean_q: 0.006462
 19804/100000: episode: 2278, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000043, mae: 0.004039, mean_q: 0.005718
 19806/100000: episode: 2279, duration: 0.017s, episode steps: 2, steps per second: 118, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000028, mae: 0.004217, mean_q: 0.002053
 19808/100000: episode: 2280, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000586, mae: 0.009573, mean_q: 0.002325
 19810/100000: episode: 2281, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000040, mae: 0.004929, mean_q: 0.003361
 19812/100000: episode: 2282, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000144, mae: 0.004349, mean_q: 0.003878
 19814/100000: episode: 2283, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000055, mae: 0.004811, mean_q: 0.005416
 19816/100000: episode: 2284, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000204, mae: 0.008508, mean_q: 0.008460
 19818/100000: episode: 2285, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000006, mae: 0.002700, mean_q: 0.005408
 19820/100000: episode: 2286, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000119, mae: 0.006231, mean_q: 0.007551
 19822/100000: episode: 2287, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000023, mae: 0.003702, mean_q: 0.005374
 19824/100000: episode: 2288, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000162, mae: 0.007655, mean_q: 0.008326
 19826/100000: episode: 2289, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000053, mae: 0.004617, mean_q: 0.005991
 19828/100000: episode: 2290, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000038, mae: 0.003515, mean_q: 0.004033
 19830/100000: episode: 2291, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000058, mae: 0.004611, mean_q: 0.004469
 19832/100000: episode: 2292, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000038, mae: 0.003720, mean_q: 0.002857
 19834/100000: episode: 2293, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000032, mae: 0.003941, mean_q: 0.003996
 19836/100000: episode: 2294, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000022, mae: 0.002892, mean_q: 0.003693
 19838/100000: episode: 2295, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000023, mae: 0.003247, mean_q: 0.004268
 19840/100000: episode: 2296, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000032, mae: 0.004062, mean_q: 0.005359
 19842/100000: episode: 2297, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000031, mae: 0.003622, mean_q: 0.004306
 19844/100000: episode: 2298, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000008, mae: 0.002525, mean_q: 0.003415
 19846/100000: episode: 2299, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000048, mae: 0.004491, mean_q: 0.005909
 19848/100000: episode: 2300, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000045, mae: 0.003498, mean_q: 0.003659
 19850/100000: episode: 2301, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000041, mae: 0.004379, mean_q: 0.004888
 19852/100000: episode: 2302, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000034, mae: 0.002928, mean_q: 0.003903
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.04761342331767082
 19854/100000: episode: 2303, duration: 0.538s, episode steps: 2, steps per second: 4, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000064, mae: 0.005346, mean_q: 0.005993
 19864/100000: episode: 2304, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000056, mae: 0.003969, mean_q: 0.005075
 19874/100000: episode: 2305, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000093, mae: 0.004938, mean_q: 0.004932
 19884/100000: episode: 2306, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000061, mae: 0.004976, mean_q: 0.006824
 19894/100000: episode: 2307, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000062, mae: 0.004632, mean_q: 0.004968
 19904/100000: episode: 2308, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000139, mae: 0.005608, mean_q: 0.004395
 19914/100000: episode: 2309, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000032, mae: 0.004661, mean_q: 0.006406
 19924/100000: episode: 2310, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000033, mae: 0.003467, mean_q: 0.003528
 19934/100000: episode: 2311, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000034, mae: 0.004104, mean_q: 0.005324
 19944/100000: episode: 2312, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000039, mae: 0.004153, mean_q: 0.004829
 19954/100000: episode: 2313, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000052, mae: 0.004376, mean_q: 0.004594
 19964/100000: episode: 2314, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000083, mae: 0.005633, mean_q: 0.005891
 19974/100000: episode: 2315, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000059, mae: 0.004479, mean_q: 0.006164
 19984/100000: episode: 2316, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000124, mae: 0.005824, mean_q: 0.006924
 19994/100000: episode: 2317, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000121, mae: 0.005958, mean_q: 0.007019
 20004/100000: episode: 2318, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000037, mae: 0.004156, mean_q: 0.006194
 20014/100000: episode: 2319, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000041, mae: 0.004363, mean_q: 0.004917
 20024/100000: episode: 2320, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000038, mae: 0.003426, mean_q: 0.003734
 20034/100000: episode: 2321, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000199, mae: 0.006067, mean_q: 0.008471
 20044/100000: episode: 2322, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000093, mae: 0.004872, mean_q: 0.003942
 20054/100000: episode: 2323, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000148, mae: 0.005569, mean_q: 0.007263
 20064/100000: episode: 2324, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000097, mae: 0.005101, mean_q: 0.006036
 20074/100000: episode: 2325, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000042, mae: 0.004027, mean_q: 0.003169
 20084/100000: episode: 2326, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000056, mae: 0.004641, mean_q: 0.005394
 20094/100000: episode: 2327, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000031, mae: 0.004011, mean_q: 0.004841
 20104/100000: episode: 2328, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000060, mae: 0.004045, mean_q: 0.003959
 20114/100000: episode: 2329, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000233, mae: 0.005795, mean_q: 0.007496
 20124/100000: episode: 2330, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000039, mae: 0.003861, mean_q: 0.004879
 20134/100000: episode: 2331, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000060, mae: 0.004621, mean_q: 0.003641
 20144/100000: episode: 2332, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000039, mae: 0.004656, mean_q: 0.006293
 20154/100000: episode: 2333, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000030, mae: 0.004020, mean_q: 0.005352
 20164/100000: episode: 2334, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000086, mae: 0.004397, mean_q: 0.004264
 20174/100000: episode: 2335, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000043, mae: 0.004965, mean_q: 0.007129
 20184/100000: episode: 2336, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000046, mae: 0.003570, mean_q: 0.004425
 20194/100000: episode: 2337, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000111, mae: 0.005220, mean_q: 0.005388
 20204/100000: episode: 2338, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000166, mae: 0.005359, mean_q: 0.008264
 20214/100000: episode: 2339, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000061, mae: 0.005450, mean_q: 0.004078
 20224/100000: episode: 2340, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000075, mae: 0.004242, mean_q: 0.004291
 20234/100000: episode: 2341, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000035, mae: 0.004349, mean_q: 0.005394
 20244/100000: episode: 2342, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000062, mae: 0.004134, mean_q: 0.004313
 20254/100000: episode: 2343, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000033, mae: 0.003908, mean_q: 0.004598
 20264/100000: episode: 2344, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000088, mae: 0.005048, mean_q: 0.005790
 20274/100000: episode: 2345, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000048, mae: 0.003977, mean_q: 0.005650
 20284/100000: episode: 2346, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000039, mae: 0.004030, mean_q: 0.004866
 20294/100000: episode: 2347, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000027, mae: 0.003363, mean_q: 0.004689
 20304/100000: episode: 2348, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000090, mae: 0.004816, mean_q: 0.005451
 20314/100000: episode: 2349, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000673, mae: 0.009220, mean_q: 0.010840
 20324/100000: episode: 2350, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000434, mae: 0.007673, mean_q: 0.005729
 20334/100000: episode: 2351, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000043, mae: 0.004550, mean_q: 0.007367
 20344/100000: episode: 2352, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000087, mae: 0.005275, mean_q: 0.003628
 20354/100000: episode: 2353, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000055, mae: 0.004446, mean_q: 0.005391
 20364/100000: episode: 2354, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000028, mae: 0.003407, mean_q: 0.003877
 20374/100000: episode: 2355, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000086, mae: 0.004686, mean_q: 0.004736
 20384/100000: episode: 2356, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000061, mae: 0.004439, mean_q: 0.005050
 20394/100000: episode: 2357, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000055, mae: 0.004135, mean_q: 0.004895
 20404/100000: episode: 2358, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000039, mae: 0.004564, mean_q: 0.005619
 20414/100000: episode: 2359, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000215, mae: 0.004534, mean_q: 0.005799
 20424/100000: episode: 2360, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000080, mae: 0.005268, mean_q: 0.005855
 20434/100000: episode: 2361, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000059, mae: 0.004779, mean_q: 0.003795
 20444/100000: episode: 2362, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000288, mae: 0.007361, mean_q: 0.008487
 20454/100000: episode: 2363, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000061, mae: 0.005504, mean_q: 0.007411
 20464/100000: episode: 2364, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000057, mae: 0.004729, mean_q: 0.002552
 20474/100000: episode: 2365, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000159, mae: 0.005948, mean_q: 0.007912
 20484/100000: episode: 2366, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000144, mae: 0.005934, mean_q: 0.006625
 20494/100000: episode: 2367, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000066, mae: 0.004758, mean_q: 0.006144
 20504/100000: episode: 2368, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000102, mae: 0.005258, mean_q: 0.007415
 20514/100000: episode: 2369, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000059, mae: 0.004056, mean_q: 0.005399
 20524/100000: episode: 2370, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000093, mae: 0.005559, mean_q: 0.007177
 20534/100000: episode: 2371, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000120, mae: 0.005464, mean_q: 0.006411
 20544/100000: episode: 2372, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000222, mae: 0.005477, mean_q: 0.008245
 20554/100000: episode: 2373, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000081, mae: 0.004630, mean_q: 0.006002
 20564/100000: episode: 2374, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000034, mae: 0.003896, mean_q: 0.003776
 20574/100000: episode: 2375, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000096, mae: 0.005106, mean_q: 0.004223
 20584/100000: episode: 2376, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000053, mae: 0.005915, mean_q: 0.007293
 20594/100000: episode: 2377, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000057, mae: 0.003959, mean_q: 0.003888
 20604/100000: episode: 2378, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000044, mae: 0.004496, mean_q: 0.005232
 20614/100000: episode: 2379, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000024, mae: 0.003652, mean_q: 0.004741
 20624/100000: episode: 2380, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000151, mae: 0.005136, mean_q: 0.006389
 20634/100000: episode: 2381, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000090, mae: 0.006158, mean_q: 0.008156
 20644/100000: episode: 2382, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000048, mae: 0.004611, mean_q: 0.004762
 20654/100000: episode: 2383, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000150, mae: 0.005431, mean_q: 0.005493
 20664/100000: episode: 2384, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000108, mae: 0.006448, mean_q: 0.008080
 20674/100000: episode: 2385, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000049, mae: 0.004887, mean_q: 0.005869
 20684/100000: episode: 2386, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000203, mae: 0.006677, mean_q: 0.006769
 20694/100000: episode: 2387, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000141, mae: 0.005842, mean_q: 0.006082
 20704/100000: episode: 2388, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000071, mae: 0.004810, mean_q: 0.003773
 20714/100000: episode: 2389, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000097, mae: 0.006608, mean_q: 0.007591
 20724/100000: episode: 2390, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000076, mae: 0.004949, mean_q: 0.006214
 20734/100000: episode: 2391, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000041, mae: 0.004250, mean_q: 0.004466
 20744/100000: episode: 2392, duration: 0.052s, episode steps: 10, steps per second: 190, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000065, mae: 0.004738, mean_q: 0.005733
 20754/100000: episode: 2393, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000056, mae: 0.004105, mean_q: 0.005504
 20764/100000: episode: 2394, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000123, mae: 0.005802, mean_q: 0.005303
 20774/100000: episode: 2395, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000041, mae: 0.004315, mean_q: 0.005729
 20784/100000: episode: 2396, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000074, mae: 0.004803, mean_q: 0.005014
 20794/100000: episode: 2397, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000055, mae: 0.004243, mean_q: 0.005836
 20804/100000: episode: 2398, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000058, mae: 0.004346, mean_q: 0.005781
 20814/100000: episode: 2399, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000029, mae: 0.003475, mean_q: 0.003441
 20824/100000: episode: 2400, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000026, mae: 0.003408, mean_q: 0.004756
 20834/100000: episode: 2401, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000061, mae: 0.004253, mean_q: 0.005071
 20844/100000: episode: 2402, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000053, mae: 0.003599, mean_q: 0.004449
[Info] 1-TH LEVEL FOUND: 0.0176393985748291, Considering 10/100 traces
 20854/100000: episode: 2403, duration: 0.717s, episode steps: 10, steps per second: 14, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000065, mae: 0.004767, mean_q: 0.005604
 20858/100000: episode: 2404, duration: 0.026s, episode steps: 4, steps per second: 152, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001752, mae: 0.009961, mean_q: 0.007771
 20862/100000: episode: 2405, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000055, mae: 0.005969, mean_q: 0.009168
 20867/100000: episode: 2406, duration: 0.027s, episode steps: 5, steps per second: 189, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000169, mae: 0.006598, mean_q: 0.009991
 20872/100000: episode: 2407, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000163, mae: 0.006141, mean_q: 0.005689
 20874/100000: episode: 2408, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000075, mae: 0.007960, mean_q: 0.003001
 20879/100000: episode: 2409, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000037, mae: 0.004349, mean_q: 0.002764
 20881/100000: episode: 2410, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000071, mae: 0.006014, mean_q: 0.006457
 20885/100000: episode: 2411, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000020, mae: 0.003747, mean_q: 0.005828
 20889/100000: episode: 2412, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000087, mae: 0.005199, mean_q: 0.005961
 20891/100000: episode: 2413, duration: 0.015s, episode steps: 2, steps per second: 136, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000048, mae: 0.004969, mean_q: 0.005886
 20893/100000: episode: 2414, duration: 0.018s, episode steps: 2, steps per second: 113, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000178, mae: 0.006761, mean_q: 0.006131
 20897/100000: episode: 2415, duration: 0.030s, episode steps: 4, steps per second: 133, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000043, mae: 0.004615, mean_q: 0.006673
 20899/100000: episode: 2416, duration: 0.017s, episode steps: 2, steps per second: 115, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000024, mae: 0.003127, mean_q: 0.004389
 20903/100000: episode: 2417, duration: 0.032s, episode steps: 4, steps per second: 124, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000091, mae: 0.004698, mean_q: 0.005529
 20905/100000: episode: 2418, duration: 0.017s, episode steps: 2, steps per second: 120, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000042, mae: 0.003706, mean_q: 0.004205
 20907/100000: episode: 2419, duration: 0.023s, episode steps: 2, steps per second: 87, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000198, mae: 0.007922, mean_q: 0.006720
 20909/100000: episode: 2420, duration: 0.018s, episode steps: 2, steps per second: 114, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000048, mae: 0.004663, mean_q: 0.006174
 20913/100000: episode: 2421, duration: 0.030s, episode steps: 4, steps per second: 134, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000032, mae: 0.003987, mean_q: 0.005939
 20915/100000: episode: 2422, duration: 0.016s, episode steps: 2, steps per second: 125, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000201, mae: 0.008288, mean_q: 0.006940
 20920/100000: episode: 2423, duration: 0.035s, episode steps: 5, steps per second: 143, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000030, mae: 0.003624, mean_q: 0.004579
 20922/100000: episode: 2424, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000044, mae: 0.004093, mean_q: 0.003366
 20926/100000: episode: 2425, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000025, mae: 0.003522, mean_q: 0.004191
 20930/100000: episode: 2426, duration: 0.024s, episode steps: 4, steps per second: 166, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000114, mae: 0.006144, mean_q: 0.006201
 20932/100000: episode: 2427, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000058, mae: 0.005326, mean_q: 0.006720
 20934/100000: episode: 2428, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000036, mae: 0.004136, mean_q: 0.005376
 20938/100000: episode: 2429, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000094, mae: 0.004123, mean_q: 0.004005
 20940/100000: episode: 2430, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000202, mae: 0.006963, mean_q: 0.005394
 20944/100000: episode: 2431, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000101, mae: 0.005381, mean_q: 0.006534
 20949/100000: episode: 2432, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001060, mae: 0.010882, mean_q: 0.011709
 20953/100000: episode: 2433, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000096, mae: 0.009064, mean_q: 0.013544
 20955/100000: episode: 2434, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000061, mae: 0.003937, mean_q: 0.005144
 20959/100000: episode: 2435, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000118, mae: 0.007403, mean_q: 0.000623
 20964/100000: episode: 2436, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000098, mae: 0.006821, mean_q: 0.002706
 20968/100000: episode: 2437, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000098, mae: 0.005362, mean_q: 0.006491
 20973/100000: episode: 2438, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000113, mae: 0.007244, mean_q: 0.008436
 20978/100000: episode: 2439, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000065, mae: 0.005636, mean_q: 0.007155
 20980/100000: episode: 2440, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000030, mae: 0.003892, mean_q: 0.005390
 20984/100000: episode: 2441, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000158, mae: 0.006174, mean_q: 0.004658
 20989/100000: episode: 2442, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000262, mae: 0.007062, mean_q: 0.007423
 20994/100000: episode: 2443, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000185, mae: 0.006859, mean_q: 0.007335
 20999/100000: episode: 2444, duration: 0.027s, episode steps: 5, steps per second: 189, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000113, mae: 0.007975, mean_q: 0.010676
 21004/100000: episode: 2445, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000147, mae: 0.007008, mean_q: 0.011180
 21006/100000: episode: 2446, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000153, mae: 0.006444, mean_q: 0.008998
 21011/100000: episode: 2447, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000196, mae: 0.007802, mean_q: 0.005452
 21015/100000: episode: 2448, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000142, mae: 0.007313, mean_q: 0.001616
 21017/100000: episode: 2449, duration: 0.014s, episode steps: 2, steps per second: 144, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000227, mae: 0.008058, mean_q: 0.001939
 21019/100000: episode: 2450, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000664, mae: 0.009851, mean_q: 0.005808
 21023/100000: episode: 2451, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000077, mae: 0.007879, mean_q: 0.008942
 21028/100000: episode: 2452, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000091, mae: 0.007296, mean_q: 0.008971
 21030/100000: episode: 2453, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000047, mae: 0.006587, mean_q: 0.008356
 21034/100000: episode: 2454, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000038, mae: 0.004286, mean_q: 0.005494
 21039/100000: episode: 2455, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000189, mae: 0.006580, mean_q: 0.005312
 21044/100000: episode: 2456, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000807, mae: 0.008810, mean_q: 0.012554
 21049/100000: episode: 2457, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000045, mae: 0.005039, mean_q: 0.008568
 21051/100000: episode: 2458, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000020, mae: 0.003439, mean_q: 0.006713
 21055/100000: episode: 2459, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000120, mae: 0.006998, mean_q: 0.007607
 21057/100000: episode: 2460, duration: 0.015s, episode steps: 2, steps per second: 131, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000100, mae: 0.008613, mean_q: 0.008279
 21062/100000: episode: 2461, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000078, mae: 0.005974, mean_q: 0.006216
 21067/100000: episode: 2462, duration: 0.035s, episode steps: 5, steps per second: 144, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000092, mae: 0.007366, mean_q: 0.004380
 21071/100000: episode: 2463, duration: 0.027s, episode steps: 4, steps per second: 147, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000132, mae: 0.006746, mean_q: 0.005279
 21075/100000: episode: 2464, duration: 0.024s, episode steps: 4, steps per second: 163, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000143, mae: 0.008257, mean_q: 0.010421
 21080/100000: episode: 2465, duration: 0.032s, episode steps: 5, steps per second: 156, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000035, mae: 0.005379, mean_q: 0.007935
 21084/100000: episode: 2466, duration: 0.028s, episode steps: 4, steps per second: 144, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000096, mae: 0.005549, mean_q: 0.006907
 21088/100000: episode: 2467, duration: 0.025s, episode steps: 4, steps per second: 161, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002638, mae: 0.013521, mean_q: 0.010295
 21092/100000: episode: 2468, duration: 0.028s, episode steps: 4, steps per second: 143, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002194, mae: 0.014067, mean_q: 0.020988
 21094/100000: episode: 2469, duration: 0.017s, episode steps: 2, steps per second: 119, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000840, mae: 0.012391, mean_q: 0.008708
 21099/100000: episode: 2470, duration: 0.033s, episode steps: 5, steps per second: 150, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000048, mae: 0.007010, mean_q: -0.001077
 21104/100000: episode: 2471, duration: 0.032s, episode steps: 5, steps per second: 157, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000136, mae: 0.006003, mean_q: 0.001342
 21106/100000: episode: 2472, duration: 0.015s, episode steps: 2, steps per second: 132, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000052, mae: 0.005574, mean_q: 0.005631
 21108/100000: episode: 2473, duration: 0.019s, episode steps: 2, steps per second: 108, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000156, mae: 0.008615, mean_q: 0.007496
 21110/100000: episode: 2474, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001399, mae: 0.019599, mean_q: 0.009581
 21112/100000: episode: 2475, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000082, mae: 0.009666, mean_q: 0.011216
 21114/100000: episode: 2476, duration: 0.016s, episode steps: 2, steps per second: 124, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.007371, mae: 0.025716, mean_q: 0.012731
 21119/100000: episode: 2477, duration: 0.032s, episode steps: 5, steps per second: 154, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002997, mae: 0.018425, mean_q: 0.015217
 21123/100000: episode: 2478, duration: 0.028s, episode steps: 4, steps per second: 144, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000178, mae: 0.013344, mean_q: 0.018181
 21128/100000: episode: 2479, duration: 0.029s, episode steps: 5, steps per second: 170, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.003141, mae: 0.018855, mean_q: 0.016386
 21132/100000: episode: 2480, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000249, mae: 0.011811, mean_q: 0.011531
 21137/100000: episode: 2481, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001133, mae: 0.014125, mean_q: 0.010403
 21139/100000: episode: 2482, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000358, mae: 0.013268, mean_q: 0.018027
 21144/100000: episode: 2483, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000145, mae: 0.008807, mean_q: 0.010116
 21146/100000: episode: 2484, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000095, mae: 0.007339, mean_q: 0.006275
 21151/100000: episode: 2485, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002987, mae: 0.014298, mean_q: 0.003329
 21156/100000: episode: 2486, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001251, mae: 0.011420, mean_q: 0.012976
 21161/100000: episode: 2487, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000314, mae: 0.011554, mean_q: 0.017750
 21163/100000: episode: 2488, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000040, mae: 0.005262, mean_q: 0.009312
 21165/100000: episode: 2489, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006580, mae: 0.024809, mean_q: 0.019428
 21169/100000: episode: 2490, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000682, mae: 0.011447, mean_q: 0.017044
 21173/100000: episode: 2491, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002103, mae: 0.016325, mean_q: 0.013665
 21175/100000: episode: 2492, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000267, mae: 0.011452, mean_q: 0.000972
[Info] 2-TH LEVEL FOUND: 0.2997705340385437, Considering 15/100 traces
 21180/100000: episode: 2493, duration: 0.709s, episode steps: 5, steps per second: 7, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000145, mae: 0.011935, mean_q: 0.002016
 21184/100000: episode: 2494, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000113, mae: 0.007260, mean_q: -0.000198
 21188/100000: episode: 2495, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000401, mae: 0.010433, mean_q: 0.007812
 21192/100000: episode: 2496, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000108, mae: 0.006843, mean_q: 0.006902
[Info] FALSIFICATION!
 21195/100000: episode: 2497, duration: 0.271s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000034, mae: 0.006528, mean_q: 0.007582
 21199/100000: episode: 2498, duration: 0.033s, episode steps: 4, steps per second: 121, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000149, mae: 0.010161, mean_q: 0.010037
 21203/100000: episode: 2499, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000659, mae: 0.010820, mean_q: 0.010802
 21207/100000: episode: 2500, duration: 0.028s, episode steps: 4, steps per second: 143, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000251, mae: 0.009739, mean_q: 0.010830
 21211/100000: episode: 2501, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000516, mae: 0.011602, mean_q: 0.010155
 21215/100000: episode: 2502, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000116, mae: 0.007617, mean_q: 0.008357
 21219/100000: episode: 2503, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000292, mae: 0.010762, mean_q: 0.009268
 21223/100000: episode: 2504, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000249, mae: 0.010087, mean_q: 0.012549
 21227/100000: episode: 2505, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000574, mae: 0.013406, mean_q: 0.014743
 21231/100000: episode: 2506, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000108, mae: 0.006931, mean_q: 0.010442
 21235/100000: episode: 2507, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000098, mae: 0.005919, mean_q: 0.007415
 21239/100000: episode: 2508, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000081, mae: 0.006102, mean_q: 0.005628
 21243/100000: episode: 2509, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000178, mae: 0.008531, mean_q: 0.005466
[Info] FALSIFICATION!
 21246/100000: episode: 2510, duration: 0.257s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002008, mae: 0.012286, mean_q: 0.012024
 21250/100000: episode: 2511, duration: 0.026s, episode steps: 4, steps per second: 154, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000097, mae: 0.005932, mean_q: 0.006883
 21254/100000: episode: 2512, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001124, mae: 0.012379, mean_q: 0.017564
 21258/100000: episode: 2513, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000174, mae: 0.006922, mean_q: 0.011379
 21262/100000: episode: 2514, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000595, mae: 0.009931, mean_q: 0.014072
 21266/100000: episode: 2515, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000219, mae: 0.009276, mean_q: 0.011181
 21270/100000: episode: 2516, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000110, mae: 0.006526, mean_q: 0.004466
 21274/100000: episode: 2517, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000597, mae: 0.012110, mean_q: 0.012818
[Info] FALSIFICATION!
 21277/100000: episode: 2518, duration: 0.262s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000053, mae: 0.005389, mean_q: 0.007203
 21281/100000: episode: 2519, duration: 0.025s, episode steps: 4, steps per second: 161, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000348, mae: 0.012514, mean_q: 0.015029
[Info] FALSIFICATION!
 21284/100000: episode: 2520, duration: 0.278s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000411, mae: 0.015880, mean_q: 0.018605
 21288/100000: episode: 2521, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001077, mae: 0.018827, mean_q: 0.020457
 21292/100000: episode: 2522, duration: 0.028s, episode steps: 4, steps per second: 145, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000311, mae: 0.010688, mean_q: 0.012361
 21296/100000: episode: 2523, duration: 0.029s, episode steps: 4, steps per second: 138, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000988, mae: 0.010577, mean_q: 0.014280
 21300/100000: episode: 2524, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000636, mae: 0.012472, mean_q: 0.019195
 21304/100000: episode: 2525, duration: 0.029s, episode steps: 4, steps per second: 139, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000613, mae: 0.014820, mean_q: 0.016481
 21308/100000: episode: 2526, duration: 0.028s, episode steps: 4, steps per second: 144, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000392, mae: 0.006962, mean_q: 0.009735
 21312/100000: episode: 2527, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000389, mae: 0.010823, mean_q: 0.015495
 21316/100000: episode: 2528, duration: 0.029s, episode steps: 4, steps per second: 138, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001280, mae: 0.016570, mean_q: 0.029735
 21320/100000: episode: 2529, duration: 0.024s, episode steps: 4, steps per second: 166, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000937, mae: 0.015531, mean_q: 0.025629
 21324/100000: episode: 2530, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001050, mae: 0.014599, mean_q: 0.020041
 21328/100000: episode: 2531, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000397, mae: 0.012977, mean_q: 0.004713
 21332/100000: episode: 2532, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000484, mae: 0.010061, mean_q: 0.006720
 21336/100000: episode: 2533, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000193, mae: 0.008120, mean_q: 0.011411
 21340/100000: episode: 2534, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000321, mae: 0.010333, mean_q: 0.011706
[Info] FALSIFICATION!
 21343/100000: episode: 2535, duration: 0.256s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000419, mae: 0.012666, mean_q: 0.016837
[Info] FALSIFICATION!
 21346/100000: episode: 2536, duration: 0.262s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000136, mae: 0.008135, mean_q: 0.014296
 21350/100000: episode: 2537, duration: 0.026s, episode steps: 4, steps per second: 153, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001445, mae: 0.015429, mean_q: 0.016321
 21354/100000: episode: 2538, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000270, mae: 0.008117, mean_q: 0.012204
 21358/100000: episode: 2539, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000675, mae: 0.013190, mean_q: 0.016793
 21362/100000: episode: 2540, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000521, mae: 0.012388, mean_q: 0.014240
 21366/100000: episode: 2541, duration: 0.023s, episode steps: 4, steps per second: 170, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000189, mae: 0.008490, mean_q: 0.012470
 21370/100000: episode: 2542, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001186, mae: 0.013468, mean_q: 0.017376
[Info] FALSIFICATION!
 21373/100000: episode: 2543, duration: 0.260s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000215, mae: 0.007522, mean_q: 0.007275
[Info] FALSIFICATION!
 21376/100000: episode: 2544, duration: 0.268s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000702, mae: 0.013467, mean_q: 0.014689
[Info] FALSIFICATION!
 21379/100000: episode: 2545, duration: 0.175s, episode steps: 3, steps per second: 17, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000348, mae: 0.009610, mean_q: 0.013034
 21383/100000: episode: 2546, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.004553, mae: 0.023761, mean_q: 0.025340
 21387/100000: episode: 2547, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001304, mae: 0.013697, mean_q: 0.017089
 21391/100000: episode: 2548, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000993, mae: 0.014617, mean_q: 0.018193
 21395/100000: episode: 2549, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.005401, mae: 0.029972, mean_q: 0.025510
 21399/100000: episode: 2550, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000895, mae: 0.015188, mean_q: 0.023569
 21403/100000: episode: 2551, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001864, mae: 0.023381, mean_q: 0.035660
 21407/100000: episode: 2552, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.001904, mae: 0.020443, mean_q: 0.027438
 21411/100000: episode: 2553, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000293, mae: 0.009252, mean_q: 0.007253
 21415/100000: episode: 2554, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.004957, mae: 0.022346, mean_q: 0.009553
 21419/100000: episode: 2555, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000373, mae: 0.012153, mean_q: 0.018064
 21423/100000: episode: 2556, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.004612, mae: 0.025131, mean_q: 0.020033
 21427/100000: episode: 2557, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002038, mae: 0.022495, mean_q: 0.024271
 21431/100000: episode: 2558, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003801, mae: 0.025859, mean_q: 0.028994
 21435/100000: episode: 2559, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000514, mae: 0.016977, mean_q: 0.030294
 21439/100000: episode: 2560, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002147, mae: 0.025903, mean_q: 0.035810
 21443/100000: episode: 2561, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000789, mae: 0.016370, mean_q: 0.014595
 21447/100000: episode: 2562, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000603, mae: 0.018269, mean_q: 0.005848
[Info] FALSIFICATION!
 21450/100000: episode: 2563, duration: 0.170s, episode steps: 3, steps per second: 18, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000695, mae: 0.015784, mean_q: 0.001982
 21454/100000: episode: 2564, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001045, mae: 0.015666, mean_q: 0.005969
 21458/100000: episode: 2565, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000591, mae: 0.014642, mean_q: 0.014369
 21462/100000: episode: 2566, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.004809, mae: 0.029425, mean_q: 0.024562
 21466/100000: episode: 2567, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001448, mae: 0.026813, mean_q: 0.035216
 21470/100000: episode: 2568, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001076, mae: 0.026751, mean_q: 0.036408
 21474/100000: episode: 2569, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000700, mae: 0.018802, mean_q: 0.027228
 21478/100000: episode: 2570, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.002025, mae: 0.026418, mean_q: 0.043540
 21482/100000: episode: 2571, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000443, mae: 0.016621, mean_q: 0.009532
 21486/100000: episode: 2572, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000515, mae: 0.017917, mean_q: 0.007057
 21490/100000: episode: 2573, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000809, mae: 0.018074, mean_q: 0.011036
 21494/100000: episode: 2574, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001366, mae: 0.020412, mean_q: 0.019713
 21498/100000: episode: 2575, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001821, mae: 0.018941, mean_q: 0.031066
 21502/100000: episode: 2576, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000343, mae: 0.011027, mean_q: 0.014821
 21506/100000: episode: 2577, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.007052, mae: 0.030982, mean_q: 0.032611
[Info] Complete ISplit Iteration
[Info] Levels: [0.017639399, 0.29977053, 0.79862726]
[Info] Cond. Prob: [0.1, 0.15, 0.1]
[Info] Error Prob: 0.0015

 21510/100000: episode: 2578, duration: 0.884s, episode steps: 4, steps per second: 5, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.002783, mae: 0.028608, mean_q: 0.032794
 21520/100000: episode: 2579, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001245, mae: 0.018472, mean_q: 0.020959
 21530/100000: episode: 2580, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000931, mae: 0.014528, mean_q: 0.013686
 21540/100000: episode: 2581, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000999, mae: 0.020357, mean_q: 0.029135
 21550/100000: episode: 2582, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000743, mae: 0.015185, mean_q: 0.021292
 21560/100000: episode: 2583, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.004217, mae: 0.024875, mean_q: 0.023592
 21570/100000: episode: 2584, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002325, mae: 0.024076, mean_q: 0.034130
 21580/100000: episode: 2585, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000991, mae: 0.015897, mean_q: 0.012137
 21590/100000: episode: 2586, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002296, mae: 0.019491, mean_q: 0.022434
 21600/100000: episode: 2587, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000831, mae: 0.016069, mean_q: 0.026730
 21610/100000: episode: 2588, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001882, mae: 0.017183, mean_q: 0.016690
 21620/100000: episode: 2589, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001557, mae: 0.015457, mean_q: 0.018187
 21630/100000: episode: 2590, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001254, mae: 0.017019, mean_q: 0.023966
 21640/100000: episode: 2591, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001688, mae: 0.018668, mean_q: 0.026592
 21650/100000: episode: 2592, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000803, mae: 0.014310, mean_q: 0.018775
 21660/100000: episode: 2593, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001271, mae: 0.017069, mean_q: 0.028550
 21670/100000: episode: 2594, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001356, mae: 0.012898, mean_q: 0.014013
 21680/100000: episode: 2595, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002406, mae: 0.020022, mean_q: 0.023806
 21690/100000: episode: 2596, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001303, mae: 0.017301, mean_q: 0.026936
 21700/100000: episode: 2597, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000589, mae: 0.012807, mean_q: 0.011441
 21710/100000: episode: 2598, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001649, mae: 0.018963, mean_q: 0.022249
 21720/100000: episode: 2599, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001544, mae: 0.021930, mean_q: 0.035260
 21730/100000: episode: 2600, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000802, mae: 0.014260, mean_q: 0.012759
 21740/100000: episode: 2601, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000462, mae: 0.011615, mean_q: 0.009815
 21750/100000: episode: 2602, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000618, mae: 0.010097, mean_q: 0.011574
 21760/100000: episode: 2603, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000449, mae: 0.013220, mean_q: 0.014164
 21770/100000: episode: 2604, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000667, mae: 0.014431, mean_q: 0.018475
 21780/100000: episode: 2605, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000888, mae: 0.012888, mean_q: 0.016065
 21790/100000: episode: 2606, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001118, mae: 0.013516, mean_q: 0.018420
 21800/100000: episode: 2607, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001887, mae: 0.019571, mean_q: 0.026296
 21810/100000: episode: 2608, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000640, mae: 0.014224, mean_q: 0.019821
 21820/100000: episode: 2609, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001076, mae: 0.014968, mean_q: 0.010499
 21830/100000: episode: 2610, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001508, mae: 0.017330, mean_q: 0.022966
 21840/100000: episode: 2611, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001703, mae: 0.018831, mean_q: 0.023629
 21850/100000: episode: 2612, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000868, mae: 0.015015, mean_q: 0.021708
 21860/100000: episode: 2613, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001854, mae: 0.015304, mean_q: 0.016797
 21870/100000: episode: 2614, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001233, mae: 0.018148, mean_q: 0.030257
 21880/100000: episode: 2615, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000859, mae: 0.013528, mean_q: 0.015840
 21890/100000: episode: 2616, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.001859, mae: 0.017506, mean_q: 0.022985
 21900/100000: episode: 2617, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001530, mae: 0.016082, mean_q: 0.020360
 21910/100000: episode: 2618, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001788, mae: 0.018766, mean_q: 0.018660
 21920/100000: episode: 2619, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001250, mae: 0.017876, mean_q: 0.028661
 21930/100000: episode: 2620, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001618, mae: 0.016765, mean_q: 0.020421
 21940/100000: episode: 2621, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000473, mae: 0.012708, mean_q: 0.022730
 21950/100000: episode: 2622, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001590, mae: 0.015758, mean_q: 0.017223
 21960/100000: episode: 2623, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001326, mae: 0.017324, mean_q: 0.024140
 21970/100000: episode: 2624, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001846, mae: 0.018296, mean_q: 0.022511
 21980/100000: episode: 2625, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002132, mae: 0.020726, mean_q: 0.023114
 21990/100000: episode: 2626, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000521, mae: 0.011537, mean_q: 0.010873
 22000/100000: episode: 2627, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.001212, mae: 0.017861, mean_q: 0.026953
 22010/100000: episode: 2628, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000712, mae: 0.014093, mean_q: 0.024241
 22020/100000: episode: 2629, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002146, mae: 0.019838, mean_q: 0.024891
 22030/100000: episode: 2630, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000818, mae: 0.013747, mean_q: 0.019708
 22040/100000: episode: 2631, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000504, mae: 0.013525, mean_q: 0.012759
 22050/100000: episode: 2632, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000740, mae: 0.013789, mean_q: 0.018656
 22060/100000: episode: 2633, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002328, mae: 0.019963, mean_q: 0.018996
 22070/100000: episode: 2634, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.003692, mae: 0.028297, mean_q: 0.037729
 22080/100000: episode: 2635, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002476, mae: 0.025272, mean_q: 0.037644
 22090/100000: episode: 2636, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001199, mae: 0.017889, mean_q: 0.019367
 22100/100000: episode: 2637, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001209, mae: 0.015488, mean_q: 0.005215
 22110/100000: episode: 2638, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000645, mae: 0.010527, mean_q: 0.011868
 22120/100000: episode: 2639, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001860, mae: 0.020402, mean_q: 0.025536
 22130/100000: episode: 2640, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000815, mae: 0.015860, mean_q: 0.019942
 22140/100000: episode: 2641, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002675, mae: 0.021484, mean_q: 0.016295
 22150/100000: episode: 2642, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001281, mae: 0.019965, mean_q: 0.033677
 22160/100000: episode: 2643, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000571, mae: 0.013766, mean_q: 0.015402
 22170/100000: episode: 2644, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000848, mae: 0.014661, mean_q: 0.019149
 22180/100000: episode: 2645, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001122, mae: 0.015861, mean_q: 0.020028
 22190/100000: episode: 2646, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000549, mae: 0.011798, mean_q: 0.011637
 22200/100000: episode: 2647, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000600, mae: 0.011149, mean_q: 0.012099
 22210/100000: episode: 2648, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000804, mae: 0.011261, mean_q: 0.013998
 22220/100000: episode: 2649, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000687, mae: 0.014690, mean_q: 0.021688
 22230/100000: episode: 2650, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002267, mae: 0.019319, mean_q: 0.023031
 22240/100000: episode: 2651, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000648, mae: 0.012593, mean_q: 0.015053
 22250/100000: episode: 2652, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001278, mae: 0.015902, mean_q: 0.014774
 22260/100000: episode: 2653, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000581, mae: 0.013090, mean_q: 0.018373
 22270/100000: episode: 2654, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002293, mae: 0.024292, mean_q: 0.039125
 22280/100000: episode: 2655, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001985, mae: 0.017708, mean_q: 0.020629
 22290/100000: episode: 2656, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000569, mae: 0.013321, mean_q: 0.019134
 22300/100000: episode: 2657, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001538, mae: 0.017032, mean_q: 0.019368
 22310/100000: episode: 2658, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001158, mae: 0.015903, mean_q: 0.025457
 22320/100000: episode: 2659, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001411, mae: 0.018271, mean_q: 0.024133
 22330/100000: episode: 2660, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001834, mae: 0.018178, mean_q: 0.025388
 22340/100000: episode: 2661, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001053, mae: 0.017626, mean_q: 0.022837
 22350/100000: episode: 2662, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000990, mae: 0.014774, mean_q: 0.019702
 22360/100000: episode: 2663, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002033, mae: 0.023767, mean_q: 0.035926
 22370/100000: episode: 2664, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000664, mae: 0.014399, mean_q: 0.018324
 22380/100000: episode: 2665, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000616, mae: 0.011304, mean_q: 0.014678
 22390/100000: episode: 2666, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002430, mae: 0.021182, mean_q: 0.026744
 22400/100000: episode: 2667, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000958, mae: 0.017145, mean_q: 0.024346
 22410/100000: episode: 2668, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002675, mae: 0.025656, mean_q: 0.039131
 22420/100000: episode: 2669, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001722, mae: 0.019764, mean_q: 0.024679
 22430/100000: episode: 2670, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000824, mae: 0.015691, mean_q: 0.022620
 22440/100000: episode: 2671, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001631, mae: 0.017812, mean_q: 0.027135
 22450/100000: episode: 2672, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002887, mae: 0.023200, mean_q: 0.027933
 22460/100000: episode: 2673, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001342, mae: 0.019163, mean_q: 0.027725
 22470/100000: episode: 2674, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001882, mae: 0.019588, mean_q: 0.026154
 22480/100000: episode: 2675, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001512, mae: 0.016933, mean_q: 0.021485
 22490/100000: episode: 2676, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000700, mae: 0.014252, mean_q: 0.018070
 22500/100000: episode: 2677, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001546, mae: 0.015746, mean_q: 0.017489
[Info] 1-TH LEVEL FOUND: 0.025944432243704796, Considering 14/100 traces
 22510/100000: episode: 2678, duration: 0.932s, episode steps: 10, steps per second: 11, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000848, mae: 0.015446, mean_q: 0.023488
 22512/100000: episode: 2679, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000764, mae: 0.016924, mean_q: 0.015740
 22518/100000: episode: 2680, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002522, mae: 0.023501, mean_q: 0.030580
 22524/100000: episode: 2681, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000877, mae: 0.015726, mean_q: 0.020501
 22526/100000: episode: 2682, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000379, mae: 0.011346, mean_q: 0.013812
 22532/100000: episode: 2683, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000762, mae: 0.013359, mean_q: 0.015743
 22538/100000: episode: 2684, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001176, mae: 0.017597, mean_q: 0.018153
 22540/100000: episode: 2685, duration: 0.012s, episode steps: 2, steps per second: 166, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002305, mae: 0.019034, mean_q: 0.023174
 22546/100000: episode: 2686, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000289, mae: 0.009910, mean_q: 0.013321
 22552/100000: episode: 2687, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.003829, mae: 0.028084, mean_q: 0.032077
 22554/100000: episode: 2688, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000523, mae: 0.013112, mean_q: 0.014753
 22556/100000: episode: 2689, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001252, mae: 0.016426, mean_q: 0.019558
 22560/100000: episode: 2690, duration: 0.023s, episode steps: 4, steps per second: 170, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001320, mae: 0.016259, mean_q: 0.020289
 22566/100000: episode: 2691, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001738, mae: 0.020707, mean_q: 0.027945
 22568/100000: episode: 2692, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000585, mae: 0.014764, mean_q: 0.028232
 22574/100000: episode: 2693, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001485, mae: 0.012582, mean_q: 0.012632
 22576/100000: episode: 2694, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001685, mae: 0.020656, mean_q: 0.031068
 22578/100000: episode: 2695, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001107, mae: 0.016595, mean_q: 0.025823
 22580/100000: episode: 2696, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000833, mae: 0.014449, mean_q: 0.023474
 22586/100000: episode: 2697, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000756, mae: 0.015208, mean_q: 0.019027
 22592/100000: episode: 2698, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002060, mae: 0.022594, mean_q: 0.026683
 22594/100000: episode: 2699, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002367, mae: 0.022392, mean_q: 0.026974
 22596/100000: episode: 2700, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000492, mae: 0.012450, mean_q: 0.027264
 22598/100000: episode: 2701, duration: 0.012s, episode steps: 2, steps per second: 166, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000537, mae: 0.014460, mean_q: 0.019344
 22600/100000: episode: 2702, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001598, mae: 0.018166, mean_q: 0.027073
 22604/100000: episode: 2703, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000501, mae: 0.012820, mean_q: 0.022652
 22608/100000: episode: 2704, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001531, mae: 0.018692, mean_q: 0.023527
 22610/100000: episode: 2705, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001622, mae: 0.021979, mean_q: 0.025053
 22612/100000: episode: 2706, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001464, mae: 0.012353, mean_q: 0.018099
 22618/100000: episode: 2707, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.002300, mae: 0.027869, mean_q: 0.034550
 22624/100000: episode: 2708, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000635, mae: 0.012782, mean_q: 0.021422
 22628/100000: episode: 2709, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000652, mae: 0.017228, mean_q: 0.030972
 22634/100000: episode: 2710, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001166, mae: 0.017377, mean_q: 0.020862
 22640/100000: episode: 2711, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000584, mae: 0.011760, mean_q: 0.015235
 22642/100000: episode: 2712, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006126, mae: 0.032254, mean_q: 0.024542
 22648/100000: episode: 2713, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000953, mae: 0.016254, mean_q: 0.022531
 22650/100000: episode: 2714, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001298, mae: 0.019994, mean_q: 0.028506
 22656/100000: episode: 2715, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000896, mae: 0.016886, mean_q: 0.022382
 22662/100000: episode: 2716, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002739, mae: 0.027707, mean_q: 0.025331
 22664/100000: episode: 2717, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002162, mae: 0.020938, mean_q: 0.027832
 22670/100000: episode: 2718, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.002417, mae: 0.026375, mean_q: 0.038554
 22676/100000: episode: 2719, duration: 0.031s, episode steps: 6, steps per second: 192, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000437, mae: 0.011596, mean_q: 0.016727
 22680/100000: episode: 2720, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003571, mae: 0.025881, mean_q: 0.028743
 22686/100000: episode: 2721, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000366, mae: 0.010535, mean_q: 0.012552
 22692/100000: episode: 2722, duration: 0.037s, episode steps: 6, steps per second: 164, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001206, mae: 0.017354, mean_q: 0.024204
 22698/100000: episode: 2723, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000718, mae: 0.015174, mean_q: 0.016317
 22704/100000: episode: 2724, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.003583, mae: 0.023205, mean_q: 0.021272
 22710/100000: episode: 2725, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001112, mae: 0.019397, mean_q: 0.027693
 22712/100000: episode: 2726, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002562, mae: 0.031570, mean_q: 0.034371
 22714/100000: episode: 2727, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004207, mae: 0.024335, mean_q: 0.026050
 22720/100000: episode: 2728, duration: 0.034s, episode steps: 6, steps per second: 178, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001669, mae: 0.020742, mean_q: 0.026022
 22726/100000: episode: 2729, duration: 0.041s, episode steps: 6, steps per second: 148, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000775, mae: 0.017853, mean_q: 0.025368
 22732/100000: episode: 2730, duration: 0.042s, episode steps: 6, steps per second: 142, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001370, mae: 0.019946, mean_q: 0.024010
 22734/100000: episode: 2731, duration: 0.019s, episode steps: 2, steps per second: 106, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000965, mae: 0.014923, mean_q: 0.024600
 22740/100000: episode: 2732, duration: 0.037s, episode steps: 6, steps per second: 161, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002392, mae: 0.020783, mean_q: 0.022119
[Info] FALSIFICATION!
 22745/100000: episode: 2733, duration: 0.281s, episode steps: 5, steps per second: 18, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.001302, mae: 0.019706, mean_q: 0.027691
 22751/100000: episode: 2734, duration: 0.042s, episode steps: 6, steps per second: 141, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001514, mae: 0.022145, mean_q: 0.033742
 22757/100000: episode: 2735, duration: 0.038s, episode steps: 6, steps per second: 157, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.002754, mae: 0.025068, mean_q: 0.036333
 22761/100000: episode: 2736, duration: 0.027s, episode steps: 4, steps per second: 146, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001122, mae: 0.019546, mean_q: 0.026751
 22763/100000: episode: 2737, duration: 0.017s, episode steps: 2, steps per second: 120, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003255, mae: 0.033102, mean_q: 0.049134
 22769/100000: episode: 2738, duration: 0.038s, episode steps: 6, steps per second: 159, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000878, mae: 0.018519, mean_q: 0.016973
 22771/100000: episode: 2739, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001714, mae: 0.020698, mean_q: 0.018962
 22777/100000: episode: 2740, duration: 0.038s, episode steps: 6, steps per second: 160, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000598, mae: 0.014019, mean_q: 0.010392
 22783/100000: episode: 2741, duration: 0.038s, episode steps: 6, steps per second: 156, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.003810, mae: 0.021447, mean_q: 0.015113
 22785/100000: episode: 2742, duration: 0.016s, episode steps: 2, steps per second: 122, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001411, mae: 0.024718, mean_q: 0.023242
 22787/100000: episode: 2743, duration: 0.017s, episode steps: 2, steps per second: 120, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002592, mae: 0.026959, mean_q: 0.028452
 22793/100000: episode: 2744, duration: 0.038s, episode steps: 6, steps per second: 160, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001248, mae: 0.024794, mean_q: 0.037844
 22799/100000: episode: 2745, duration: 0.037s, episode steps: 6, steps per second: 160, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001996, mae: 0.022021, mean_q: 0.028300
 22801/100000: episode: 2746, duration: 0.016s, episode steps: 2, steps per second: 125, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000957, mae: 0.014837, mean_q: 0.024446
 22805/100000: episode: 2747, duration: 0.030s, episode steps: 4, steps per second: 135, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001743, mae: 0.028226, mean_q: 0.047419
 22811/100000: episode: 2748, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001002, mae: 0.016959, mean_q: 0.021314
 22817/100000: episode: 2749, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000659, mae: 0.013531, mean_q: 0.015847
 22821/100000: episode: 2750, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000933, mae: 0.016125, mean_q: 0.017751
 22823/100000: episode: 2751, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000233, mae: 0.008576, mean_q: 0.010609
 22827/100000: episode: 2752, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001116, mae: 0.013960, mean_q: 0.019778
 22833/100000: episode: 2753, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003132, mae: 0.026401, mean_q: 0.033737
 22839/100000: episode: 2754, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002821, mae: 0.024148, mean_q: 0.022691
 22843/100000: episode: 2755, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001550, mae: 0.021995, mean_q: 0.027127
 22847/100000: episode: 2756, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001918, mae: 0.020814, mean_q: 0.028091
 22853/100000: episode: 2757, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.002748, mae: 0.030277, mean_q: 0.042855
 22859/100000: episode: 2758, duration: 0.032s, episode steps: 6, steps per second: 190, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.002271, mae: 0.022769, mean_q: 0.023825
 22865/100000: episode: 2759, duration: 0.033s, episode steps: 6, steps per second: 182, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003278, mae: 0.028506, mean_q: 0.032445
 22871/100000: episode: 2760, duration: 0.037s, episode steps: 6, steps per second: 161, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001615, mae: 0.023610, mean_q: 0.035169
 22877/100000: episode: 2761, duration: 0.038s, episode steps: 6, steps per second: 159, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002627, mae: 0.021289, mean_q: 0.026509
 22883/100000: episode: 2762, duration: 0.039s, episode steps: 6, steps per second: 153, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000582, mae: 0.015122, mean_q: 0.018334
 22887/100000: episode: 2763, duration: 0.025s, episode steps: 4, steps per second: 158, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000839, mae: 0.017294, mean_q: 0.017215
[Info] Complete ISplit Iteration
[Info] Levels: [0.025944432, 0.8633562]
[Info] Cond. Prob: [0.14, 0.01]
[Info] Error Prob: 0.0014000000000000002

 22893/100000: episode: 2764, duration: 0.897s, episode steps: 6, steps per second: 7, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.002626, mae: 0.022590, mean_q: 0.024934
 22903/100000: episode: 2765, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002068, mae: 0.025266, mean_q: 0.038491
 22913/100000: episode: 2766, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002013, mae: 0.019795, mean_q: 0.016006
 22923/100000: episode: 2767, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002691, mae: 0.026893, mean_q: 0.036429
 22933/100000: episode: 2768, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001387, mae: 0.018771, mean_q: 0.025685
 22943/100000: episode: 2769, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001306, mae: 0.019506, mean_q: 0.027361
 22953/100000: episode: 2770, duration: 0.055s, episode steps: 10, steps per second: 180, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002189, mae: 0.020648, mean_q: 0.026479
 22963/100000: episode: 2771, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001453, mae: 0.021781, mean_q: 0.027850
 22973/100000: episode: 2772, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002007, mae: 0.022539, mean_q: 0.031111
 22983/100000: episode: 2773, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002477, mae: 0.021346, mean_q: 0.020508
 22993/100000: episode: 2774, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001724, mae: 0.021699, mean_q: 0.031278
 23003/100000: episode: 2775, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001286, mae: 0.018405, mean_q: 0.023613
 23013/100000: episode: 2776, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.003048, mae: 0.026652, mean_q: 0.028675
 23023/100000: episode: 2777, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002154, mae: 0.028378, mean_q: 0.044513
 23033/100000: episode: 2778, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001165, mae: 0.018548, mean_q: 0.022589
 23043/100000: episode: 2779, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002453, mae: 0.022511, mean_q: 0.023429
 23053/100000: episode: 2780, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001080, mae: 0.020954, mean_q: 0.030253
 23063/100000: episode: 2781, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002175, mae: 0.021662, mean_q: 0.028031
 23073/100000: episode: 2782, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002743, mae: 0.030134, mean_q: 0.040950
 23083/100000: episode: 2783, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000537, mae: 0.015276, mean_q: 0.016207
 23093/100000: episode: 2784, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001720, mae: 0.020114, mean_q: 0.018646
 23103/100000: episode: 2785, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001014, mae: 0.019184, mean_q: 0.027558
 23113/100000: episode: 2786, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001240, mae: 0.019472, mean_q: 0.025026
 23123/100000: episode: 2787, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002026, mae: 0.020434, mean_q: 0.021033
 23133/100000: episode: 2788, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001085, mae: 0.018825, mean_q: 0.024665
 23143/100000: episode: 2789, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002372, mae: 0.026143, mean_q: 0.032278
 23153/100000: episode: 2790, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000904, mae: 0.016987, mean_q: 0.021948
 23163/100000: episode: 2791, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002028, mae: 0.019943, mean_q: 0.026092
 23173/100000: episode: 2792, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000474, mae: 0.013515, mean_q: 0.018406
 23183/100000: episode: 2793, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001453, mae: 0.018149, mean_q: 0.018416
 23193/100000: episode: 2794, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001698, mae: 0.023970, mean_q: 0.031551
 23203/100000: episode: 2795, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000995, mae: 0.017464, mean_q: 0.021740
 23213/100000: episode: 2796, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002035, mae: 0.021734, mean_q: 0.028773
 23223/100000: episode: 2797, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001023, mae: 0.017111, mean_q: 0.025133
 23233/100000: episode: 2798, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001262, mae: 0.019784, mean_q: 0.021656
 23243/100000: episode: 2799, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001100, mae: 0.017190, mean_q: 0.026459
 23253/100000: episode: 2800, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001578, mae: 0.020544, mean_q: 0.031145
 23263/100000: episode: 2801, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.003000, mae: 0.026521, mean_q: 0.036354
 23273/100000: episode: 2802, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000804, mae: 0.015420, mean_q: 0.018958
 23283/100000: episode: 2803, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001026, mae: 0.018832, mean_q: 0.024559
 23293/100000: episode: 2804, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002386, mae: 0.026568, mean_q: 0.037472
 23303/100000: episode: 2805, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001360, mae: 0.021651, mean_q: 0.024131
 23313/100000: episode: 2806, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001254, mae: 0.021352, mean_q: 0.031822
 23323/100000: episode: 2807, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002162, mae: 0.021442, mean_q: 0.028661
 23333/100000: episode: 2808, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.002035, mae: 0.023533, mean_q: 0.035167
 23343/100000: episode: 2809, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002396, mae: 0.021336, mean_q: 0.022345
 23353/100000: episode: 2810, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.002050, mae: 0.021682, mean_q: 0.032452
 23363/100000: episode: 2811, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001730, mae: 0.020774, mean_q: 0.030968
 23373/100000: episode: 2812, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001530, mae: 0.020324, mean_q: 0.024590
 23383/100000: episode: 2813, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002016, mae: 0.026830, mean_q: 0.042068
 23393/100000: episode: 2814, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001259, mae: 0.020565, mean_q: 0.029201
 23403/100000: episode: 2815, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001969, mae: 0.020642, mean_q: 0.027944
 23413/100000: episode: 2816, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001201, mae: 0.018001, mean_q: 0.025651
 23423/100000: episode: 2817, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002079, mae: 0.020967, mean_q: 0.027971
 23433/100000: episode: 2818, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001385, mae: 0.019048, mean_q: 0.024736
 23443/100000: episode: 2819, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000952, mae: 0.016985, mean_q: 0.022680
 23453/100000: episode: 2820, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001810, mae: 0.020302, mean_q: 0.031763
 23463/100000: episode: 2821, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000874, mae: 0.017610, mean_q: 0.018810
 23473/100000: episode: 2822, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000995, mae: 0.014608, mean_q: 0.019114
 23483/100000: episode: 2823, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000731, mae: 0.016739, mean_q: 0.018601
 23493/100000: episode: 2824, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001676, mae: 0.019642, mean_q: 0.024545
 23503/100000: episode: 2825, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001101, mae: 0.022043, mean_q: 0.034106
 23513/100000: episode: 2826, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001178, mae: 0.017227, mean_q: 0.025284
 23523/100000: episode: 2827, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001767, mae: 0.016546, mean_q: 0.016106
 23533/100000: episode: 2828, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001444, mae: 0.019963, mean_q: 0.030388
 23543/100000: episode: 2829, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001995, mae: 0.023295, mean_q: 0.034596
 23553/100000: episode: 2830, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001008, mae: 0.016025, mean_q: 0.021592
 23563/100000: episode: 2831, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000577, mae: 0.012083, mean_q: 0.013200
 23573/100000: episode: 2832, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001177, mae: 0.019408, mean_q: 0.022837
 23583/100000: episode: 2833, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001254, mae: 0.021097, mean_q: 0.028004
 23593/100000: episode: 2834, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002115, mae: 0.023087, mean_q: 0.030832
 23603/100000: episode: 2835, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000871, mae: 0.019004, mean_q: 0.024799
 23613/100000: episode: 2836, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001064, mae: 0.017471, mean_q: 0.017560
 23623/100000: episode: 2837, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001843, mae: 0.023950, mean_q: 0.031065
 23633/100000: episode: 2838, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001212, mae: 0.020348, mean_q: 0.029507
 23643/100000: episode: 2839, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002029, mae: 0.022313, mean_q: 0.028453
 23653/100000: episode: 2840, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001043, mae: 0.018171, mean_q: 0.024804
 23663/100000: episode: 2841, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000747, mae: 0.014735, mean_q: 0.018616
 23673/100000: episode: 2842, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.001487, mae: 0.019036, mean_q: 0.023180
 23683/100000: episode: 2843, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001090, mae: 0.017904, mean_q: 0.023403
 23693/100000: episode: 2844, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002216, mae: 0.023653, mean_q: 0.033820
 23703/100000: episode: 2845, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001655, mae: 0.021472, mean_q: 0.030252
 23713/100000: episode: 2846, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000819, mae: 0.016776, mean_q: 0.025555
 23723/100000: episode: 2847, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000742, mae: 0.016043, mean_q: 0.017807
 23733/100000: episode: 2848, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002298, mae: 0.021596, mean_q: 0.024593
 23743/100000: episode: 2849, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001664, mae: 0.023042, mean_q: 0.028754
 23753/100000: episode: 2850, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001059, mae: 0.017454, mean_q: 0.024607
 23763/100000: episode: 2851, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001192, mae: 0.020226, mean_q: 0.029327
 23773/100000: episode: 2852, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001482, mae: 0.021981, mean_q: 0.028052
 23783/100000: episode: 2853, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001194, mae: 0.019148, mean_q: 0.031240
 23793/100000: episode: 2854, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001624, mae: 0.021097, mean_q: 0.030275
 23803/100000: episode: 2855, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001715, mae: 0.020375, mean_q: 0.022090
 23813/100000: episode: 2856, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000883, mae: 0.018048, mean_q: 0.025918
[Info] FALSIFICATION!
 23823/100000: episode: 2857, duration: 0.307s, episode steps: 10, steps per second: 33, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.001284, mae: 0.019328, mean_q: 0.026221
 23833/100000: episode: 2858, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002207, mae: 0.023926, mean_q: 0.034553
 23843/100000: episode: 2859, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001930, mae: 0.018943, mean_q: 0.023406
 23853/100000: episode: 2860, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000719, mae: 0.014975, mean_q: 0.017277
 23863/100000: episode: 2861, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001794, mae: 0.024615, mean_q: 0.027353
 23873/100000: episode: 2862, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001218, mae: 0.020761, mean_q: 0.032029
 23883/100000: episode: 2863, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001179, mae: 0.019012, mean_q: 0.025446
[Info] Complete ISplit Iteration
[Info] Levels: [0.82921463]
[Info] Cond. Prob: [0.01]
[Info] Error Prob: 0.01

 23893/100000: episode: 2864, duration: 0.934s, episode steps: 10, steps per second: 11, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001250, mae: 0.015886, mean_q: 0.021583
 23903/100000: episode: 2865, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001500, mae: 0.019440, mean_q: 0.023783
 23913/100000: episode: 2866, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001890, mae: 0.020892, mean_q: 0.031923
 23923/100000: episode: 2867, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001058, mae: 0.018241, mean_q: 0.022592
 23933/100000: episode: 2868, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001297, mae: 0.018728, mean_q: 0.019705
 23943/100000: episode: 2869, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000931, mae: 0.018207, mean_q: 0.024655
 23953/100000: episode: 2870, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000936, mae: 0.017334, mean_q: 0.023998
 23963/100000: episode: 2871, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001420, mae: 0.016705, mean_q: 0.023589
 23973/100000: episode: 2872, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001098, mae: 0.017095, mean_q: 0.025183
 23983/100000: episode: 2873, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002009, mae: 0.022471, mean_q: 0.029209
 23993/100000: episode: 2874, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001124, mae: 0.018031, mean_q: 0.021791
 24003/100000: episode: 2875, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000890, mae: 0.016507, mean_q: 0.022773
 24013/100000: episode: 2876, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001869, mae: 0.021563, mean_q: 0.031927
 24023/100000: episode: 2877, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001241, mae: 0.017505, mean_q: 0.023089
 24033/100000: episode: 2878, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002531, mae: 0.021424, mean_q: 0.025445
 24043/100000: episode: 2879, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001610, mae: 0.018494, mean_q: 0.022751
 24053/100000: episode: 2880, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.001004, mae: 0.016187, mean_q: 0.024012
 24063/100000: episode: 2881, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001072, mae: 0.016413, mean_q: 0.027063
 24073/100000: episode: 2882, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000981, mae: 0.018136, mean_q: 0.027982
 24083/100000: episode: 2883, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001369, mae: 0.019987, mean_q: 0.026591
 24093/100000: episode: 2884, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000941, mae: 0.016589, mean_q: 0.020610
 24103/100000: episode: 2885, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.002616, mae: 0.024804, mean_q: 0.038880
 24113/100000: episode: 2886, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002346, mae: 0.022579, mean_q: 0.028244
 24123/100000: episode: 2887, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000871, mae: 0.014033, mean_q: 0.021121
 24133/100000: episode: 2888, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000824, mae: 0.015711, mean_q: 0.022590
 24143/100000: episode: 2889, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001590, mae: 0.020101, mean_q: 0.024681
 24153/100000: episode: 2890, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001815, mae: 0.022646, mean_q: 0.032944
 24163/100000: episode: 2891, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001278, mae: 0.018621, mean_q: 0.033787
 24173/100000: episode: 2892, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001537, mae: 0.017294, mean_q: 0.019699
 24183/100000: episode: 2893, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001320, mae: 0.018366, mean_q: 0.028130
 24193/100000: episode: 2894, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001856, mae: 0.021090, mean_q: 0.035381
 24203/100000: episode: 2895, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001320, mae: 0.016809, mean_q: 0.024463
 24213/100000: episode: 2896, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000756, mae: 0.014678, mean_q: 0.018916
 24223/100000: episode: 2897, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001892, mae: 0.020769, mean_q: 0.034848
 24233/100000: episode: 2898, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001961, mae: 0.020280, mean_q: 0.025194
 24243/100000: episode: 2899, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001988, mae: 0.018301, mean_q: 0.027622
 24253/100000: episode: 2900, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001773, mae: 0.023052, mean_q: 0.044105
 24263/100000: episode: 2901, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000989, mae: 0.016987, mean_q: 0.032185
 24273/100000: episode: 2902, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001929, mae: 0.020244, mean_q: 0.022886
 24283/100000: episode: 2903, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000842, mae: 0.014749, mean_q: 0.018658
 24293/100000: episode: 2904, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001394, mae: 0.019838, mean_q: 0.035527
 24303/100000: episode: 2905, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001461, mae: 0.018470, mean_q: 0.026061
 24313/100000: episode: 2906, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.002287, mae: 0.023556, mean_q: 0.032079
 24323/100000: episode: 2907, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001443, mae: 0.020318, mean_q: 0.036576
 24333/100000: episode: 2908, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.003032, mae: 0.027220, mean_q: 0.035999
 24343/100000: episode: 2909, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001597, mae: 0.019295, mean_q: 0.030962
 24353/100000: episode: 2910, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001889, mae: 0.019994, mean_q: 0.026899
 24363/100000: episode: 2911, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000771, mae: 0.013531, mean_q: 0.019078
 24373/100000: episode: 2912, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000936, mae: 0.015415, mean_q: 0.025643
 24383/100000: episode: 2913, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001681, mae: 0.016789, mean_q: 0.020462
 24393/100000: episode: 2914, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001413, mae: 0.017299, mean_q: 0.027764
 24403/100000: episode: 2915, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000623, mae: 0.013873, mean_q: 0.019781
 24413/100000: episode: 2916, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001720, mae: 0.020436, mean_q: 0.028587
 24423/100000: episode: 2917, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000919, mae: 0.016869, mean_q: 0.027084
 24433/100000: episode: 2918, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001718, mae: 0.016976, mean_q: 0.025742
 24443/100000: episode: 2919, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001422, mae: 0.020085, mean_q: 0.031513
 24453/100000: episode: 2920, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001623, mae: 0.017969, mean_q: 0.021381
 24463/100000: episode: 2921, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002098, mae: 0.025605, mean_q: 0.040730
 24473/100000: episode: 2922, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001339, mae: 0.019654, mean_q: 0.026214
 24483/100000: episode: 2923, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001065, mae: 0.018452, mean_q: 0.025932
 24493/100000: episode: 2924, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001127, mae: 0.017877, mean_q: 0.026910
 24503/100000: episode: 2925, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001476, mae: 0.021829, mean_q: 0.036804
 24513/100000: episode: 2926, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002152, mae: 0.017423, mean_q: 0.020498
 24523/100000: episode: 2927, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000913, mae: 0.016549, mean_q: 0.024712
 24533/100000: episode: 2928, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002501, mae: 0.027854, mean_q: 0.043635
 24543/100000: episode: 2929, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001409, mae: 0.020409, mean_q: 0.032391
 24553/100000: episode: 2930, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001111, mae: 0.016386, mean_q: 0.023333
 24563/100000: episode: 2931, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001257, mae: 0.015494, mean_q: 0.020683
 24573/100000: episode: 2932, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001418, mae: 0.018940, mean_q: 0.026761
 24583/100000: episode: 2933, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001697, mae: 0.024527, mean_q: 0.049099
 24593/100000: episode: 2934, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001327, mae: 0.017746, mean_q: 0.024820
 24603/100000: episode: 2935, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001131, mae: 0.016540, mean_q: 0.014726
 24613/100000: episode: 2936, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001163, mae: 0.019460, mean_q: 0.033866
 24623/100000: episode: 2937, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000765, mae: 0.015865, mean_q: 0.023842
 24633/100000: episode: 2938, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001398, mae: 0.020338, mean_q: 0.034392
 24643/100000: episode: 2939, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001695, mae: 0.020108, mean_q: 0.028090
 24653/100000: episode: 2940, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.002054, mae: 0.021160, mean_q: 0.036135
 24663/100000: episode: 2941, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001679, mae: 0.020777, mean_q: 0.031367
 24673/100000: episode: 2942, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001132, mae: 0.019444, mean_q: 0.027525
 24683/100000: episode: 2943, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000782, mae: 0.013913, mean_q: 0.019921
 24693/100000: episode: 2944, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000715, mae: 0.013632, mean_q: 0.022197
 24703/100000: episode: 2945, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000549, mae: 0.012901, mean_q: 0.019882
 24713/100000: episode: 2946, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001367, mae: 0.013836, mean_q: 0.016069
 24723/100000: episode: 2947, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001313, mae: 0.019535, mean_q: 0.025625
 24733/100000: episode: 2948, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001164, mae: 0.016338, mean_q: 0.028159
 24743/100000: episode: 2949, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001324, mae: 0.016135, mean_q: 0.023361
 24753/100000: episode: 2950, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000806, mae: 0.014902, mean_q: 0.018855
 24763/100000: episode: 2951, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000703, mae: 0.015743, mean_q: 0.021453
 24773/100000: episode: 2952, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000985, mae: 0.016151, mean_q: 0.027228
 24783/100000: episode: 2953, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000852, mae: 0.014015, mean_q: 0.023162
 24793/100000: episode: 2954, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001926, mae: 0.015934, mean_q: 0.016319
 24803/100000: episode: 2955, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001484, mae: 0.021198, mean_q: 0.034324
 24813/100000: episode: 2956, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001805, mae: 0.021141, mean_q: 0.027863
 24823/100000: episode: 2957, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001504, mae: 0.018740, mean_q: 0.026453
 24833/100000: episode: 2958, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001183, mae: 0.018144, mean_q: 0.028996
 24843/100000: episode: 2959, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000884, mae: 0.015495, mean_q: 0.025879
 24853/100000: episode: 2960, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000789, mae: 0.013787, mean_q: 0.020560
 24863/100000: episode: 2961, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001753, mae: 0.017100, mean_q: 0.015511
 24873/100000: episode: 2962, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001403, mae: 0.019471, mean_q: 0.031767
 24883/100000: episode: 2963, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001078, mae: 0.018284, mean_q: 0.029429
[Info] 1-TH LEVEL FOUND: 0.026355013251304626, Considering 10/100 traces
 24893/100000: episode: 2964, duration: 0.693s, episode steps: 10, steps per second: 14, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000970, mae: 0.015754, mean_q: 0.019285
 24900/100000: episode: 2965, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001615, mae: 0.020097, mean_q: 0.025318
 24907/100000: episode: 2966, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001094, mae: 0.014255, mean_q: 0.016883
 24914/100000: episode: 2967, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001310, mae: 0.016723, mean_q: 0.018768
 24916/100000: episode: 2968, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000967, mae: 0.018870, mean_q: 0.025469
 24918/100000: episode: 2969, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001172, mae: 0.021227, mean_q: 0.037944
 24922/100000: episode: 2970, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000861, mae: 0.018262, mean_q: 0.027787
 24929/100000: episode: 2971, duration: 0.042s, episode steps: 7, steps per second: 167, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000614, mae: 0.013027, mean_q: 0.018638
 24931/100000: episode: 2972, duration: 0.022s, episode steps: 2, steps per second: 92, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000341, mae: 0.010650, mean_q: 0.013826
 24933/100000: episode: 2973, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002375, mae: 0.020024, mean_q: 0.030024
 24940/100000: episode: 2974, duration: 0.059s, episode steps: 7, steps per second: 118, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.002249, mae: 0.025189, mean_q: 0.038927
 24947/100000: episode: 2975, duration: 0.045s, episode steps: 7, steps per second: 155, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000757, mae: 0.016385, mean_q: 0.027618
 24954/100000: episode: 2976, duration: 0.038s, episode steps: 7, steps per second: 183, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.000856, mae: 0.014868, mean_q: 0.018383
 24956/100000: episode: 2977, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001243, mae: 0.020408, mean_q: 0.031765
 24963/100000: episode: 2978, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001132, mae: 0.016973, mean_q: 0.028605
 24967/100000: episode: 2979, duration: 0.035s, episode steps: 4, steps per second: 114, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001575, mae: 0.020331, mean_q: 0.027235
 24974/100000: episode: 2980, duration: 0.057s, episode steps: 7, steps per second: 123, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000976, mae: 0.014256, mean_q: 0.022152
 24981/100000: episode: 2981, duration: 0.039s, episode steps: 7, steps per second: 181, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000878, mae: 0.014944, mean_q: 0.018429
 24988/100000: episode: 2982, duration: 0.045s, episode steps: 7, steps per second: 156, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000837, mae: 0.014337, mean_q: 0.022619
 24990/100000: episode: 2983, duration: 0.014s, episode steps: 2, steps per second: 143, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003642, mae: 0.032378, mean_q: 0.039621
 24992/100000: episode: 2984, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001342, mae: 0.015556, mean_q: 0.031173
 24994/100000: episode: 2985, duration: 0.017s, episode steps: 2, steps per second: 117, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001098, mae: 0.017510, mean_q: 0.020330
 24996/100000: episode: 2986, duration: 0.021s, episode steps: 2, steps per second: 96, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002668, mae: 0.031784, mean_q: 0.033362
 25003/100000: episode: 2987, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001068, mae: 0.015813, mean_q: 0.023780
 25007/100000: episode: 2988, duration: 0.028s, episode steps: 4, steps per second: 141, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001057, mae: 0.014940, mean_q: 0.021093
 25014/100000: episode: 2989, duration: 0.044s, episode steps: 7, steps per second: 160, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001735, mae: 0.020026, mean_q: 0.032669
 25021/100000: episode: 2990, duration: 0.037s, episode steps: 7, steps per second: 189, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000981, mae: 0.015642, mean_q: 0.025459
 25028/100000: episode: 2991, duration: 0.042s, episode steps: 7, steps per second: 166, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000770, mae: 0.016841, mean_q: 0.022434
 25035/100000: episode: 2992, duration: 0.045s, episode steps: 7, steps per second: 154, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.002269, mae: 0.019347, mean_q: 0.026387
 25039/100000: episode: 2993, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001835, mae: 0.021979, mean_q: 0.039293
 25043/100000: episode: 2994, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000414, mae: 0.012613, mean_q: 0.017408
 25050/100000: episode: 2995, duration: 0.040s, episode steps: 7, steps per second: 177, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001220, mae: 0.018668, mean_q: 0.026419
 25052/100000: episode: 2996, duration: 0.014s, episode steps: 2, steps per second: 138, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000910, mae: 0.015463, mean_q: 0.027134
 25059/100000: episode: 2997, duration: 0.043s, episode steps: 7, steps per second: 164, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001019, mae: 0.016699, mean_q: 0.033334
 25063/100000: episode: 2998, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001461, mae: 0.018893, mean_q: 0.027945
 25070/100000: episode: 2999, duration: 0.045s, episode steps: 7, steps per second: 156, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001151, mae: 0.018586, mean_q: 0.032901
 25074/100000: episode: 3000, duration: 0.027s, episode steps: 4, steps per second: 150, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000935, mae: 0.015764, mean_q: 0.018556
 25078/100000: episode: 3001, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001663, mae: 0.018498, mean_q: 0.020542
 25080/100000: episode: 3002, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002266, mae: 0.022600, mean_q: 0.024239
 25082/100000: episode: 3003, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000663, mae: 0.014319, mean_q: 0.018016
 25084/100000: episode: 3004, duration: 0.017s, episode steps: 2, steps per second: 115, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000181, mae: 0.009644, mean_q: 0.012141
 25086/100000: episode: 3005, duration: 0.020s, episode steps: 2, steps per second: 99, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000671, mae: 0.018233, mean_q: 0.022591
 25093/100000: episode: 3006, duration: 0.040s, episode steps: 7, steps per second: 177, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000856, mae: 0.017727, mean_q: 0.024926
 25100/100000: episode: 3007, duration: 0.043s, episode steps: 7, steps per second: 164, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000990, mae: 0.017848, mean_q: 0.028507
 25104/100000: episode: 3008, duration: 0.027s, episode steps: 4, steps per second: 146, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002651, mae: 0.023754, mean_q: 0.037855
 25106/100000: episode: 3009, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000311, mae: 0.010671, mean_q: 0.025233
 25113/100000: episode: 3010, duration: 0.039s, episode steps: 7, steps per second: 180, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001105, mae: 0.018408, mean_q: 0.025155
 25117/100000: episode: 3011, duration: 0.029s, episode steps: 4, steps per second: 139, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001046, mae: 0.016385, mean_q: 0.025093
 25119/100000: episode: 3012, duration: 0.019s, episode steps: 2, steps per second: 104, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000310, mae: 0.012372, mean_q: 0.017981
 25126/100000: episode: 3013, duration: 0.048s, episode steps: 7, steps per second: 146, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000782, mae: 0.015229, mean_q: 0.021807
 25133/100000: episode: 3014, duration: 0.040s, episode steps: 7, steps per second: 175, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000986, mae: 0.016440, mean_q: 0.026412
 25137/100000: episode: 3015, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000805, mae: 0.015536, mean_q: 0.026768
 25139/100000: episode: 3016, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002498, mae: 0.031881, mean_q: 0.053526
 25146/100000: episode: 3017, duration: 0.044s, episode steps: 7, steps per second: 158, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.001815, mae: 0.022843, mean_q: 0.038464
 25153/100000: episode: 3018, duration: 0.046s, episode steps: 7, steps per second: 151, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001041, mae: 0.019316, mean_q: 0.030658
 25160/100000: episode: 3019, duration: 0.037s, episode steps: 7, steps per second: 189, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001431, mae: 0.017859, mean_q: 0.027838
 25167/100000: episode: 3020, duration: 0.048s, episode steps: 7, steps per second: 146, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000743, mae: 0.015955, mean_q: 0.024715
 25174/100000: episode: 3021, duration: 0.047s, episode steps: 7, steps per second: 148, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001210, mae: 0.021094, mean_q: 0.034141
 25178/100000: episode: 3022, duration: 0.028s, episode steps: 4, steps per second: 144, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001328, mae: 0.019737, mean_q: 0.028122
 25180/100000: episode: 3023, duration: 0.016s, episode steps: 2, steps per second: 125, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001215, mae: 0.015107, mean_q: 0.032159
 25182/100000: episode: 3024, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002758, mae: 0.033794, mean_q: 0.050204
 25189/100000: episode: 3025, duration: 0.039s, episode steps: 7, steps per second: 178, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001320, mae: 0.019109, mean_q: 0.023396
 25196/100000: episode: 3026, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001081, mae: 0.016447, mean_q: 0.026581
 25198/100000: episode: 3027, duration: 0.014s, episode steps: 2, steps per second: 140, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000980, mae: 0.020076, mean_q: 0.025862
 25200/100000: episode: 3028, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001418, mae: 0.028224, mean_q: 0.036152
 25207/100000: episode: 3029, duration: 0.044s, episode steps: 7, steps per second: 160, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001659, mae: 0.020546, mean_q: 0.030679
 25214/100000: episode: 3030, duration: 0.044s, episode steps: 7, steps per second: 160, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.002285, mae: 0.021617, mean_q: 0.027191
 25221/100000: episode: 3031, duration: 0.039s, episode steps: 7, steps per second: 179, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001273, mae: 0.019960, mean_q: 0.031694
 25228/100000: episode: 3032, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000717, mae: 0.012096, mean_q: 0.016175
 25235/100000: episode: 3033, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.002429, mae: 0.023061, mean_q: 0.029077
 25242/100000: episode: 3034, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001605, mae: 0.022787, mean_q: 0.035499
 25246/100000: episode: 3035, duration: 0.025s, episode steps: 4, steps per second: 161, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001137, mae: 0.022349, mean_q: 0.032689
 25250/100000: episode: 3036, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001085, mae: 0.018256, mean_q: 0.021498
 25252/100000: episode: 3037, duration: 0.014s, episode steps: 2, steps per second: 143, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000585, mae: 0.012690, mean_q: 0.016144
 25256/100000: episode: 3038, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001358, mae: 0.018189, mean_q: 0.029879
 25258/100000: episode: 3039, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000532, mae: 0.011801, mean_q: 0.015759
 25265/100000: episode: 3040, duration: 0.047s, episode steps: 7, steps per second: 150, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000941, mae: 0.016503, mean_q: 0.024177
 25272/100000: episode: 3041, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000627, mae: 0.013545, mean_q: 0.025264
 25279/100000: episode: 3042, duration: 0.041s, episode steps: 7, steps per second: 170, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001005, mae: 0.019089, mean_q: 0.026474
 25283/100000: episode: 3043, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001325, mae: 0.021009, mean_q: 0.038699
 25290/100000: episode: 3044, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.002120, mae: 0.023890, mean_q: 0.036329
 25297/100000: episode: 3045, duration: 0.038s, episode steps: 7, steps per second: 184, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001351, mae: 0.020696, mean_q: 0.039204
 25304/100000: episode: 3046, duration: 0.038s, episode steps: 7, steps per second: 184, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001173, mae: 0.019981, mean_q: 0.029155
 25311/100000: episode: 3047, duration: 0.040s, episode steps: 7, steps per second: 176, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001264, mae: 0.019933, mean_q: 0.025615
 25315/100000: episode: 3048, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001611, mae: 0.023024, mean_q: 0.032559
 25322/100000: episode: 3049, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001289, mae: 0.017533, mean_q: 0.028416
 25326/100000: episode: 3050, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000878, mae: 0.019609, mean_q: 0.029755
 25330/100000: episode: 3051, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001029, mae: 0.018350, mean_q: 0.024674
 25337/100000: episode: 3052, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.002322, mae: 0.024098, mean_q: 0.037989
 25339/100000: episode: 3053, duration: 0.015s, episode steps: 2, steps per second: 130, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001178, mae: 0.016171, mean_q: 0.026707
[Info] 2-TH LEVEL FOUND: 0.07637759298086166, Considering 15/100 traces
 25346/100000: episode: 3054, duration: 0.842s, episode steps: 7, steps per second: 8, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001928, mae: 0.024501, mean_q: 0.038571
 25348/100000: episode: 3055, duration: 0.029s, episode steps: 2, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001855, mae: 0.022244, mean_q: 0.037502
 25350/100000: episode: 3056, duration: 0.016s, episode steps: 2, steps per second: 127, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000995, mae: 0.017279, mean_q: 0.040893
 25352/100000: episode: 3057, duration: 0.016s, episode steps: 2, steps per second: 129, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001174, mae: 0.014721, mean_q: 0.020909
 25354/100000: episode: 3058, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000933, mae: 0.014813, mean_q: 0.017181
 25358/100000: episode: 3059, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001620, mae: 0.021383, mean_q: 0.041722
 25360/100000: episode: 3060, duration: 0.017s, episode steps: 2, steps per second: 117, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000717, mae: 0.016204, mean_q: 0.022066
 25362/100000: episode: 3061, duration: 0.018s, episode steps: 2, steps per second: 111, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000913, mae: 0.019598, mean_q: 0.027002
 25366/100000: episode: 3062, duration: 0.026s, episode steps: 4, steps per second: 156, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000875, mae: 0.018357, mean_q: 0.022088
 25370/100000: episode: 3063, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000867, mae: 0.016219, mean_q: 0.025546
 25374/100000: episode: 3064, duration: 0.026s, episode steps: 4, steps per second: 151, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002537, mae: 0.029236, mean_q: 0.045881
 25378/100000: episode: 3065, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002312, mae: 0.023430, mean_q: 0.027585
 25382/100000: episode: 3066, duration: 0.027s, episode steps: 4, steps per second: 147, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000749, mae: 0.012051, mean_q: 0.019755
 25384/100000: episode: 3067, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000773, mae: 0.009466, mean_q: 0.015152
 25388/100000: episode: 3068, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.002821, mae: 0.031510, mean_q: 0.046962
 25390/100000: episode: 3069, duration: 0.015s, episode steps: 2, steps per second: 131, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001031, mae: 0.015799, mean_q: 0.024997
 25392/100000: episode: 3070, duration: 0.019s, episode steps: 2, steps per second: 107, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002825, mae: 0.030093, mean_q: 0.045911
 25396/100000: episode: 3071, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001367, mae: 0.019691, mean_q: 0.026684
 25398/100000: episode: 3072, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001847, mae: 0.026207, mean_q: 0.033973
 25400/100000: episode: 3073, duration: 0.014s, episode steps: 2, steps per second: 144, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000763, mae: 0.013072, mean_q: 0.012651
 25402/100000: episode: 3074, duration: 0.019s, episode steps: 2, steps per second: 107, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000879, mae: 0.016917, mean_q: 0.024345
 25406/100000: episode: 3075, duration: 0.025s, episode steps: 4, steps per second: 161, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001091, mae: 0.016992, mean_q: 0.020910
 25408/100000: episode: 3076, duration: 0.016s, episode steps: 2, steps per second: 128, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001860, mae: 0.025077, mean_q: 0.030496
 25410/100000: episode: 3077, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001080, mae: 0.018240, mean_q: 0.018412
 25412/100000: episode: 3078, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003744, mae: 0.040090, mean_q: 0.054465
 25414/100000: episode: 3079, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001180, mae: 0.025297, mean_q: 0.039570
[Info] FALSIFICATION!
 25417/100000: episode: 3080, duration: 0.227s, episode steps: 3, steps per second: 13, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000896, mae: 0.020884, mean_q: 0.031897
[Info] FALSIFICATION!
 25420/100000: episode: 3081, duration: 0.278s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000918, mae: 0.013997, mean_q: 0.020969
 25422/100000: episode: 3082, duration: 0.019s, episode steps: 2, steps per second: 105, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001173, mae: 0.022565, mean_q: 0.028523
 25424/100000: episode: 3083, duration: 0.015s, episode steps: 2, steps per second: 131, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000840, mae: 0.017072, mean_q: 0.021402
 25426/100000: episode: 3084, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003013, mae: 0.022894, mean_q: 0.038242
 25428/100000: episode: 3085, duration: 0.017s, episode steps: 2, steps per second: 119, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000469, mae: 0.014144, mean_q: 0.019861
[Info] FALSIFICATION!
 25431/100000: episode: 3086, duration: 0.279s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.004325, mae: 0.038614, mean_q: 0.067516
[Info] FALSIFICATION!
 25434/100000: episode: 3087, duration: 0.261s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000737, mae: 0.013470, mean_q: 0.025114
 25436/100000: episode: 3088, duration: 0.016s, episode steps: 2, steps per second: 122, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000740, mae: 0.014736, mean_q: 0.017116
 25438/100000: episode: 3089, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000849, mae: 0.017758, mean_q: 0.025891
 25442/100000: episode: 3090, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000740, mae: 0.015115, mean_q: 0.021300
 25446/100000: episode: 3091, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002401, mae: 0.028239, mean_q: 0.038323
 25448/100000: episode: 3092, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001171, mae: 0.019057, mean_q: 0.028221
 25450/100000: episode: 3093, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000260, mae: 0.011050, mean_q: 0.014059
 25454/100000: episode: 3094, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001072, mae: 0.019282, mean_q: 0.021825
 25456/100000: episode: 3095, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001082, mae: 0.022370, mean_q: 0.031675
 25458/100000: episode: 3096, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000996, mae: 0.022907, mean_q: 0.029897
 25460/100000: episode: 3097, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002755, mae: 0.027110, mean_q: 0.052140
 25462/100000: episode: 3098, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000797, mae: 0.016850, mean_q: 0.023226
 25464/100000: episode: 3099, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002563, mae: 0.022993, mean_q: 0.025986
 25466/100000: episode: 3100, duration: 0.015s, episode steps: 2, steps per second: 136, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000334, mae: 0.011580, mean_q: 0.017405
 25468/100000: episode: 3101, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000887, mae: 0.019788, mean_q: 0.038302
 25470/100000: episode: 3102, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001300, mae: 0.020509, mean_q: 0.035986
 25474/100000: episode: 3103, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001407, mae: 0.018601, mean_q: 0.027295
 25478/100000: episode: 3104, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000996, mae: 0.017282, mean_q: 0.020082
 25480/100000: episode: 3105, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000652, mae: 0.011689, mean_q: 0.011216
 25484/100000: episode: 3106, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001185, mae: 0.016346, mean_q: 0.024252
 25488/100000: episode: 3107, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001015, mae: 0.014307, mean_q: 0.036300
 25490/100000: episode: 3108, duration: 0.015s, episode steps: 2, steps per second: 131, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001468, mae: 0.021760, mean_q: 0.039302
 25494/100000: episode: 3109, duration: 0.024s, episode steps: 4, steps per second: 166, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001457, mae: 0.020931, mean_q: 0.031923
 25496/100000: episode: 3110, duration: 0.015s, episode steps: 2, steps per second: 130, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001331, mae: 0.021334, mean_q: 0.025589
 25498/100000: episode: 3111, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001313, mae: 0.018472, mean_q: 0.029272
 25500/100000: episode: 3112, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000734, mae: 0.012416, mean_q: 0.015355
 25502/100000: episode: 3113, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000703, mae: 0.013470, mean_q: 0.016579
 25506/100000: episode: 3114, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003002, mae: 0.019931, mean_q: 0.017687
[Info] FALSIFICATION!
 25509/100000: episode: 3115, duration: 0.277s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000763, mae: 0.012322, mean_q: 0.015012
 25513/100000: episode: 3116, duration: 0.030s, episode steps: 4, steps per second: 133, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002158, mae: 0.029777, mean_q: 0.059211
 25515/100000: episode: 3117, duration: 0.020s, episode steps: 2, steps per second: 98, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000644, mae: 0.012470, mean_q: 0.022807
 25519/100000: episode: 3118, duration: 0.047s, episode steps: 4, steps per second: 85, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001967, mae: 0.021388, mean_q: 0.050033
[Info] FALSIFICATION!
 25522/100000: episode: 3119, duration: 0.327s, episode steps: 3, steps per second: 9, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000522, mae: 0.011574, mean_q: 0.014067
 25524/100000: episode: 3120, duration: 0.016s, episode steps: 2, steps per second: 125, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002687, mae: 0.028467, mean_q: 0.042977
 25526/100000: episode: 3121, duration: 0.015s, episode steps: 2, steps per second: 133, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001678, mae: 0.025743, mean_q: 0.040794
[Info] FALSIFICATION!
 25529/100000: episode: 3122, duration: 0.278s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002000, mae: 0.020851, mean_q: 0.022963
 25531/100000: episode: 3123, duration: 0.022s, episode steps: 2, steps per second: 89, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003170, mae: 0.028793, mean_q: 0.033111
 25533/100000: episode: 3124, duration: 0.032s, episode steps: 2, steps per second: 63, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001070, mae: 0.022427, mean_q: 0.029432
 25535/100000: episode: 3125, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001957, mae: 0.023299, mean_q: 0.038477
 25537/100000: episode: 3126, duration: 0.029s, episode steps: 2, steps per second: 68, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001073, mae: 0.020007, mean_q: 0.035773
 25541/100000: episode: 3127, duration: 0.047s, episode steps: 4, steps per second: 84, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002313, mae: 0.026162, mean_q: 0.041095
 25545/100000: episode: 3128, duration: 0.038s, episode steps: 4, steps per second: 106, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001822, mae: 0.024611, mean_q: 0.043663
 25547/100000: episode: 3129, duration: 0.028s, episode steps: 2, steps per second: 72, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000930, mae: 0.017428, mean_q: 0.029999
 25549/100000: episode: 3130, duration: 0.023s, episode steps: 2, steps per second: 86, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004253, mae: 0.032055, mean_q: 0.035531
 25551/100000: episode: 3131, duration: 0.027s, episode steps: 2, steps per second: 73, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001186, mae: 0.018588, mean_q: 0.024426
 25553/100000: episode: 3132, duration: 0.029s, episode steps: 2, steps per second: 69, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001413, mae: 0.022560, mean_q: 0.032602
 25555/100000: episode: 3133, duration: 0.032s, episode steps: 2, steps per second: 62, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000751, mae: 0.012054, mean_q: 0.022892
 25557/100000: episode: 3134, duration: 0.029s, episode steps: 2, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000768, mae: 0.016817, mean_q: 0.028276
 25561/100000: episode: 3135, duration: 0.045s, episode steps: 4, steps per second: 88, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001599, mae: 0.023911, mean_q: 0.038853
 25563/100000: episode: 3136, duration: 0.020s, episode steps: 2, steps per second: 99, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002662, mae: 0.026686, mean_q: 0.035799
 25567/100000: episode: 3137, duration: 0.057s, episode steps: 4, steps per second: 70, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001187, mae: 0.015808, mean_q: 0.019255
 25569/100000: episode: 3138, duration: 0.022s, episode steps: 2, steps per second: 92, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001684, mae: 0.019182, mean_q: 0.026854
[Info] Complete ISplit Iteration
[Info] Levels: [0.026355013, 0.07637759, 1.0386457]
[Info] Cond. Prob: [0.1, 0.15, 0.07]
[Info] Error Prob: 0.0010500000000000002

 25573/100000: episode: 3139, duration: 0.996s, episode steps: 4, steps per second: 4, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001954, mae: 0.023623, mean_q: 0.036458
[Info] FALSIFICATION!
 25583/100000: episode: 3140, duration: 0.362s, episode steps: 10, steps per second: 28, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.001570, mae: 0.022271, mean_q: 0.029408
 25593/100000: episode: 3141, duration: 0.117s, episode steps: 10, steps per second: 85, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001427, mae: 0.020877, mean_q: 0.027577
 25603/100000: episode: 3142, duration: 0.098s, episode steps: 10, steps per second: 102, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001479, mae: 0.023541, mean_q: 0.032580
 25613/100000: episode: 3143, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001469, mae: 0.021088, mean_q: 0.030423
 25623/100000: episode: 3144, duration: 0.110s, episode steps: 10, steps per second: 91, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001486, mae: 0.019484, mean_q: 0.030403
 25633/100000: episode: 3145, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000827, mae: 0.015229, mean_q: 0.027438
 25643/100000: episode: 3146, duration: 0.086s, episode steps: 10, steps per second: 117, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000599, mae: 0.013305, mean_q: 0.021198
 25653/100000: episode: 3147, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002388, mae: 0.024437, mean_q: 0.039239
 25663/100000: episode: 3148, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001443, mae: 0.019928, mean_q: 0.032250
 25673/100000: episode: 3149, duration: 0.084s, episode steps: 10, steps per second: 118, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001394, mae: 0.018022, mean_q: 0.020013
 25683/100000: episode: 3150, duration: 0.128s, episode steps: 10, steps per second: 78, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000689, mae: 0.015840, mean_q: 0.023645
 25693/100000: episode: 3151, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001204, mae: 0.020558, mean_q: 0.033603
 25703/100000: episode: 3152, duration: 0.073s, episode steps: 10, steps per second: 136, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001065, mae: 0.018430, mean_q: 0.026131
 25713/100000: episode: 3153, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000993, mae: 0.017481, mean_q: 0.027406
 25723/100000: episode: 3154, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000938, mae: 0.015110, mean_q: 0.023670
 25733/100000: episode: 3155, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001156, mae: 0.014857, mean_q: 0.019624
 25743/100000: episode: 3156, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001578, mae: 0.019992, mean_q: 0.030158
 25753/100000: episode: 3157, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000986, mae: 0.017153, mean_q: 0.031998
 25763/100000: episode: 3158, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001338, mae: 0.018403, mean_q: 0.033495
 25773/100000: episode: 3159, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000812, mae: 0.012113, mean_q: 0.015630
 25783/100000: episode: 3160, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000713, mae: 0.013822, mean_q: 0.018435
 25793/100000: episode: 3161, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000731, mae: 0.015372, mean_q: 0.023085
 25803/100000: episode: 3162, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000920, mae: 0.014692, mean_q: 0.017058
 25813/100000: episode: 3163, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002139, mae: 0.018934, mean_q: 0.020204
 25823/100000: episode: 3164, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000594, mae: 0.013561, mean_q: 0.019036
 25833/100000: episode: 3165, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001165, mae: 0.015219, mean_q: 0.025349
 25843/100000: episode: 3166, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001059, mae: 0.013061, mean_q: 0.021472
 25853/100000: episode: 3167, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001172, mae: 0.015293, mean_q: 0.021234
 25863/100000: episode: 3168, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001168, mae: 0.014352, mean_q: 0.013849
 25873/100000: episode: 3169, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000468, mae: 0.011817, mean_q: 0.014966
 25883/100000: episode: 3170, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000794, mae: 0.013739, mean_q: 0.019776
 25893/100000: episode: 3171, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000466, mae: 0.009129, mean_q: 0.011206
 25903/100000: episode: 3172, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001204, mae: 0.016026, mean_q: 0.022996
 25913/100000: episode: 3173, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000592, mae: 0.011756, mean_q: 0.013864
 25923/100000: episode: 3174, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001243, mae: 0.015667, mean_q: 0.021605
 25933/100000: episode: 3175, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000843, mae: 0.014536, mean_q: 0.018687
 25943/100000: episode: 3176, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000749, mae: 0.011710, mean_q: 0.014127
 25953/100000: episode: 3177, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000417, mae: 0.010949, mean_q: 0.010984
 25963/100000: episode: 3178, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000524, mae: 0.010606, mean_q: 0.013603
 25973/100000: episode: 3179, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000775, mae: 0.012620, mean_q: 0.016769
 25983/100000: episode: 3180, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000223, mae: 0.009372, mean_q: 0.010846
 25993/100000: episode: 3181, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000563, mae: 0.009231, mean_q: 0.010805
 26003/100000: episode: 3182, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000697, mae: 0.010649, mean_q: 0.011436
 26013/100000: episode: 3183, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000792, mae: 0.016996, mean_q: 0.019882
 26023/100000: episode: 3184, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000702, mae: 0.015045, mean_q: 0.020471
 26033/100000: episode: 3185, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000524, mae: 0.012404, mean_q: 0.016040
 26043/100000: episode: 3186, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000455, mae: 0.011168, mean_q: 0.015204
 26053/100000: episode: 3187, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000634, mae: 0.011173, mean_q: 0.017559
 26063/100000: episode: 3188, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001145, mae: 0.013874, mean_q: 0.018149
 26073/100000: episode: 3189, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000981, mae: 0.014172, mean_q: 0.018046
 26083/100000: episode: 3190, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000592, mae: 0.011766, mean_q: 0.020303
 26093/100000: episode: 3191, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000956, mae: 0.014864, mean_q: 0.023820
 26103/100000: episode: 3192, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000401, mae: 0.009084, mean_q: 0.006652
 26113/100000: episode: 3193, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000991, mae: 0.013765, mean_q: 0.017305
 26123/100000: episode: 3194, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000811, mae: 0.015508, mean_q: 0.025206
 26133/100000: episode: 3195, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000706, mae: 0.013500, mean_q: 0.023810
 26143/100000: episode: 3196, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000911, mae: 0.013865, mean_q: 0.016582
 26153/100000: episode: 3197, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000596, mae: 0.011766, mean_q: 0.014032
 26163/100000: episode: 3198, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000461, mae: 0.010048, mean_q: 0.013217
 26173/100000: episode: 3199, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000646, mae: 0.011357, mean_q: 0.014708
 26183/100000: episode: 3200, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000723, mae: 0.014158, mean_q: 0.020114
 26193/100000: episode: 3201, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000510, mae: 0.012271, mean_q: 0.016874
 26203/100000: episode: 3202, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000940, mae: 0.013910, mean_q: 0.018740
 26213/100000: episode: 3203, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000511, mae: 0.010501, mean_q: 0.015047
 26223/100000: episode: 3204, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000658, mae: 0.011622, mean_q: 0.013924
 26233/100000: episode: 3205, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000930, mae: 0.014267, mean_q: 0.022764
 26243/100000: episode: 3206, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000480, mae: 0.009220, mean_q: 0.009769
 26253/100000: episode: 3207, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000949, mae: 0.014461, mean_q: 0.013468
 26263/100000: episode: 3208, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000769, mae: 0.014007, mean_q: 0.021110
 26273/100000: episode: 3209, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001053, mae: 0.015497, mean_q: 0.022444
 26283/100000: episode: 3210, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000680, mae: 0.010515, mean_q: 0.015197
 26293/100000: episode: 3211, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000679, mae: 0.012815, mean_q: 0.010239
 26303/100000: episode: 3212, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001113, mae: 0.014768, mean_q: 0.018138
 26313/100000: episode: 3213, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000780, mae: 0.014737, mean_q: 0.023539
 26323/100000: episode: 3214, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001515, mae: 0.018695, mean_q: 0.033880
 26333/100000: episode: 3215, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000410, mae: 0.009483, mean_q: 0.014112
 26343/100000: episode: 3216, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001222, mae: 0.013639, mean_q: 0.017944
 26353/100000: episode: 3217, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000914, mae: 0.014480, mean_q: 0.028974
 26363/100000: episode: 3218, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000957, mae: 0.013931, mean_q: 0.021279
 26373/100000: episode: 3219, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001135, mae: 0.013804, mean_q: 0.018238
 26383/100000: episode: 3220, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000479, mae: 0.012482, mean_q: 0.015050
 26393/100000: episode: 3221, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000698, mae: 0.013170, mean_q: 0.021522
 26403/100000: episode: 3222, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000543, mae: 0.011276, mean_q: 0.014235
 26413/100000: episode: 3223, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000707, mae: 0.014144, mean_q: 0.030370
 26423/100000: episode: 3224, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000540, mae: 0.012580, mean_q: 0.020783
 26433/100000: episode: 3225, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001485, mae: 0.016768, mean_q: 0.026460
 26443/100000: episode: 3226, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000851, mae: 0.014335, mean_q: 0.015265
 26453/100000: episode: 3227, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000962, mae: 0.012099, mean_q: 0.013555
 26463/100000: episode: 3228, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000884, mae: 0.014513, mean_q: 0.018443
 26473/100000: episode: 3229, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000992, mae: 0.017091, mean_q: 0.023640
 26483/100000: episode: 3230, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000615, mae: 0.010834, mean_q: 0.011936
 26493/100000: episode: 3231, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000464, mae: 0.010280, mean_q: 0.014101
 26503/100000: episode: 3232, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000743, mae: 0.013213, mean_q: 0.016406
 26513/100000: episode: 3233, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000727, mae: 0.013105, mean_q: 0.013611
 26523/100000: episode: 3234, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000578, mae: 0.013799, mean_q: 0.020619
 26533/100000: episode: 3235, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001083, mae: 0.015691, mean_q: 0.025762
 26543/100000: episode: 3236, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000767, mae: 0.011319, mean_q: 0.014294
 26553/100000: episode: 3237, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000608, mae: 0.010520, mean_q: 0.014839
 26563/100000: episode: 3238, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001468, mae: 0.015348, mean_q: 0.027899
[Info] Complete ISplit Iteration
[Info] Levels: [1.079441]
[Info] Cond. Prob: [0.01]
[Info] Error Prob: 0.01

 26573/100000: episode: 3239, duration: 0.833s, episode steps: 10, steps per second: 12, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002138, mae: 0.017898, mean_q: 0.021879
 26583/100000: episode: 3240, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000516, mae: 0.009449, mean_q: 0.012072
 26593/100000: episode: 3241, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000681, mae: 0.012338, mean_q: 0.014786
 26603/100000: episode: 3242, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000521, mae: 0.011786, mean_q: 0.017930
 26613/100000: episode: 3243, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000968, mae: 0.012891, mean_q: 0.014529
 26623/100000: episode: 3244, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000475, mae: 0.011534, mean_q: 0.014989
 26633/100000: episode: 3245, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000697, mae: 0.014237, mean_q: 0.022212
 26643/100000: episode: 3246, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000794, mae: 0.012159, mean_q: 0.019438
 26653/100000: episode: 3247, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000685, mae: 0.010863, mean_q: 0.015815
 26663/100000: episode: 3248, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000436, mae: 0.009940, mean_q: 0.014727
 26673/100000: episode: 3249, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000237, mae: 0.007841, mean_q: 0.010714
 26683/100000: episode: 3250, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000320, mae: 0.008606, mean_q: 0.011746
 26693/100000: episode: 3251, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000571, mae: 0.011736, mean_q: 0.015418
 26703/100000: episode: 3252, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001238, mae: 0.016202, mean_q: 0.026654
 26713/100000: episode: 3253, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001482, mae: 0.013357, mean_q: 0.016538
 26723/100000: episode: 3254, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000540, mae: 0.010544, mean_q: 0.015060
 26733/100000: episode: 3255, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000386, mae: 0.010119, mean_q: 0.013634
 26743/100000: episode: 3256, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000659, mae: 0.010771, mean_q: 0.010078
 26753/100000: episode: 3257, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000607, mae: 0.011054, mean_q: 0.016035
 26763/100000: episode: 3258, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000465, mae: 0.009993, mean_q: 0.012081
 26773/100000: episode: 3259, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000531, mae: 0.011387, mean_q: 0.012884
 26783/100000: episode: 3260, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000406, mae: 0.010021, mean_q: 0.013740
 26793/100000: episode: 3261, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000578, mae: 0.011895, mean_q: 0.013833
 26803/100000: episode: 3262, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000206, mae: 0.009070, mean_q: 0.012960
 26813/100000: episode: 3263, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000643, mae: 0.010673, mean_q: 0.015225
 26823/100000: episode: 3264, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000375, mae: 0.010841, mean_q: 0.020678
 26833/100000: episode: 3265, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000590, mae: 0.008298, mean_q: 0.012505
 26843/100000: episode: 3266, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000906, mae: 0.011314, mean_q: 0.015610
 26853/100000: episode: 3267, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000953, mae: 0.013195, mean_q: 0.020193
 26863/100000: episode: 3268, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000862, mae: 0.012983, mean_q: 0.014778
 26873/100000: episode: 3269, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000425, mae: 0.009920, mean_q: 0.010426
 26883/100000: episode: 3270, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000283, mae: 0.009357, mean_q: 0.015000
 26893/100000: episode: 3271, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000466, mae: 0.011645, mean_q: 0.025731
 26903/100000: episode: 3272, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000429, mae: 0.011149, mean_q: 0.014252
 26913/100000: episode: 3273, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000427, mae: 0.010676, mean_q: 0.011189
 26923/100000: episode: 3274, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000515, mae: 0.011296, mean_q: 0.012347
 26933/100000: episode: 3275, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000436, mae: 0.009368, mean_q: 0.010515
 26943/100000: episode: 3276, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000252, mae: 0.008475, mean_q: 0.009883
 26953/100000: episode: 3277, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000401, mae: 0.010924, mean_q: 0.017175
 26963/100000: episode: 3278, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000583, mae: 0.011485, mean_q: 0.014266
 26973/100000: episode: 3279, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000640, mae: 0.011293, mean_q: 0.012860
 26983/100000: episode: 3280, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000551, mae: 0.010141, mean_q: 0.012746
 26993/100000: episode: 3281, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000664, mae: 0.011831, mean_q: 0.017826
 27003/100000: episode: 3282, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000756, mae: 0.012969, mean_q: 0.019836
 27013/100000: episode: 3283, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000096, mae: 0.006761, mean_q: 0.006631
 27023/100000: episode: 3284, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000661, mae: 0.011118, mean_q: 0.009298
 27033/100000: episode: 3285, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000257, mae: 0.010378, mean_q: 0.013729
 27043/100000: episode: 3286, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000659, mae: 0.011507, mean_q: 0.016400
 27053/100000: episode: 3287, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001248, mae: 0.013598, mean_q: 0.015471
 27063/100000: episode: 3288, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000342, mae: 0.008952, mean_q: 0.015991
 27073/100000: episode: 3289, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000347, mae: 0.008264, mean_q: 0.014505
 27083/100000: episode: 3290, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000670, mae: 0.011525, mean_q: 0.015655
 27093/100000: episode: 3291, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000753, mae: 0.010404, mean_q: 0.015165
 27103/100000: episode: 3292, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000577, mae: 0.010928, mean_q: 0.020452
 27113/100000: episode: 3293, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000682, mae: 0.012530, mean_q: 0.018100
 27123/100000: episode: 3294, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000985, mae: 0.008940, mean_q: 0.011375
 27133/100000: episode: 3295, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000431, mae: 0.010615, mean_q: 0.012303
 27143/100000: episode: 3296, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000338, mae: 0.009602, mean_q: 0.015844
 27153/100000: episode: 3297, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000908, mae: 0.012723, mean_q: 0.020993
 27163/100000: episode: 3298, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000703, mae: 0.011542, mean_q: 0.014111
 27173/100000: episode: 3299, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000499, mae: 0.009841, mean_q: 0.013517
 27183/100000: episode: 3300, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001293, mae: 0.013031, mean_q: 0.018238
 27193/100000: episode: 3301, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000816, mae: 0.013635, mean_q: 0.021583
 27203/100000: episode: 3302, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000559, mae: 0.008905, mean_q: 0.013110
 27213/100000: episode: 3303, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000562, mae: 0.010069, mean_q: 0.016726
 27223/100000: episode: 3304, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000364, mae: 0.009944, mean_q: 0.019630
 27233/100000: episode: 3305, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000198, mae: 0.007220, mean_q: 0.009240
 27243/100000: episode: 3306, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000213, mae: 0.006715, mean_q: 0.007844
 27253/100000: episode: 3307, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000382, mae: 0.008993, mean_q: 0.013592
 27263/100000: episode: 3308, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001243, mae: 0.011367, mean_q: 0.016688
 27273/100000: episode: 3309, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000672, mae: 0.010474, mean_q: 0.015914
 27283/100000: episode: 3310, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000361, mae: 0.008488, mean_q: 0.014558
 27293/100000: episode: 3311, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000597, mae: 0.008928, mean_q: 0.014756
 27303/100000: episode: 3312, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000390, mae: 0.006527, mean_q: 0.007870
 27313/100000: episode: 3313, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000386, mae: 0.008543, mean_q: 0.012240
 27323/100000: episode: 3314, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000808, mae: 0.011274, mean_q: 0.015978
 27333/100000: episode: 3315, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000356, mae: 0.007461, mean_q: 0.007900
 27343/100000: episode: 3316, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000353, mae: 0.008852, mean_q: 0.017732
 27353/100000: episode: 3317, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000565, mae: 0.010382, mean_q: 0.020792
 27363/100000: episode: 3318, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000313, mae: 0.008239, mean_q: 0.012179
 27373/100000: episode: 3319, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000342, mae: 0.007931, mean_q: 0.013832
 27383/100000: episode: 3320, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000884, mae: 0.010425, mean_q: 0.014504
 27393/100000: episode: 3321, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000757, mae: 0.010465, mean_q: 0.013794
 27403/100000: episode: 3322, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000285, mae: 0.007713, mean_q: 0.012104
 27413/100000: episode: 3323, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000428, mae: 0.008599, mean_q: 0.017437
 27423/100000: episode: 3324, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000928, mae: 0.010415, mean_q: 0.017217
 27433/100000: episode: 3325, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000648, mae: 0.011078, mean_q: 0.013692
 27443/100000: episode: 3326, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000255, mae: 0.007448, mean_q: 0.005854
 27453/100000: episode: 3327, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001866, mae: 0.014222, mean_q: 0.018375
 27463/100000: episode: 3328, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000521, mae: 0.012222, mean_q: 0.015430
 27473/100000: episode: 3329, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000295, mae: 0.006156, mean_q: 0.009240
 27483/100000: episode: 3330, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000656, mae: 0.009401, mean_q: 0.012348
 27493/100000: episode: 3331, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000238, mae: 0.008512, mean_q: 0.011354
 27503/100000: episode: 3332, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000749, mae: 0.011097, mean_q: 0.019065
 27513/100000: episode: 3333, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000231, mae: 0.008015, mean_q: 0.011959
 27523/100000: episode: 3334, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000320, mae: 0.007956, mean_q: 0.010295
 27533/100000: episode: 3335, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000445, mae: 0.008583, mean_q: 0.011820
 27543/100000: episode: 3336, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000801, mae: 0.010972, mean_q: 0.017724
 27553/100000: episode: 3337, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000527, mae: 0.008281, mean_q: 0.010155
 27563/100000: episode: 3338, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001194, mae: 0.009893, mean_q: 0.018697
[Info] 1-TH LEVEL FOUND: 0.03668772056698799, Considering 14/100 traces
 27573/100000: episode: 3339, duration: 0.926s, episode steps: 10, steps per second: 11, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000362, mae: 0.008890, mean_q: 0.016301
 27579/100000: episode: 3340, duration: 0.032s, episode steps: 6, steps per second: 185, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000438, mae: 0.009346, mean_q: 0.021276
 27585/100000: episode: 3341, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001578, mae: 0.013376, mean_q: 0.018393
 27589/100000: episode: 3342, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000780, mae: 0.010305, mean_q: 0.012999
 27593/100000: episode: 3343, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000033, mae: 0.005200, mean_q: 0.002134
 27597/100000: episode: 3344, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000919, mae: 0.010961, mean_q: 0.004109
 27603/100000: episode: 3345, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000161, mae: 0.007548, mean_q: 0.006971
 27609/100000: episode: 3346, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000977, mae: 0.013276, mean_q: 0.016023
 27613/100000: episode: 3347, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000817, mae: 0.013030, mean_q: 0.016583
 27619/100000: episode: 3348, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000654, mae: 0.013549, mean_q: 0.020450
 27625/100000: episode: 3349, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000942, mae: 0.010971, mean_q: 0.016193
 27629/100000: episode: 3350, duration: 0.020s, episode steps: 4, steps per second: 198, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002231, mae: 0.016835, mean_q: 0.025550
 27633/100000: episode: 3351, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000538, mae: 0.010904, mean_q: 0.019574
 27637/100000: episode: 3352, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000129, mae: 0.005543, mean_q: 0.011465
 27643/100000: episode: 3353, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000786, mae: 0.010358, mean_q: 0.012466
 27647/100000: episode: 3354, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000160, mae: 0.005934, mean_q: 0.011893
 27653/100000: episode: 3355, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000431, mae: 0.008374, mean_q: 0.009795
 27657/100000: episode: 3356, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001749, mae: 0.020053, mean_q: 0.027301
 27663/100000: episode: 3357, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000096, mae: 0.008748, mean_q: 0.018920
 27669/100000: episode: 3358, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002163, mae: 0.015851, mean_q: 0.020336
 27673/100000: episode: 3359, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001051, mae: 0.012431, mean_q: 0.023239
 27679/100000: episode: 3360, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000262, mae: 0.009416, mean_q: 0.006197
 27685/100000: episode: 3361, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001249, mae: 0.012609, mean_q: 0.008802
 27691/100000: episode: 3362, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001169, mae: 0.012309, mean_q: 0.016505
 27695/100000: episode: 3363, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000170, mae: 0.006794, mean_q: 0.013790
 27699/100000: episode: 3364, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000115, mae: 0.005864, mean_q: 0.008948
 27703/100000: episode: 3365, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000289, mae: 0.008372, mean_q: 0.010084
 27709/100000: episode: 3366, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000863, mae: 0.012208, mean_q: 0.023967
 27713/100000: episode: 3367, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001572, mae: 0.019734, mean_q: 0.026126
 27717/100000: episode: 3368, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000307, mae: 0.008997, mean_q: 0.012261
 27721/100000: episode: 3369, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000231, mae: 0.010097, mean_q: 0.019913
 27725/100000: episode: 3370, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000901, mae: 0.013595, mean_q: 0.022250
 27729/100000: episode: 3371, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000284, mae: 0.006777, mean_q: 0.012091
 27733/100000: episode: 3372, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000403, mae: 0.008347, mean_q: 0.010288
 27739/100000: episode: 3373, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000458, mae: 0.010601, mean_q: 0.014604
 27743/100000: episode: 3374, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000587, mae: 0.011241, mean_q: 0.011673
 27747/100000: episode: 3375, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000360, mae: 0.008375, mean_q: 0.013286
 27751/100000: episode: 3376, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000913, mae: 0.010639, mean_q: 0.017799
 27757/100000: episode: 3377, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000261, mae: 0.007228, mean_q: 0.010815
 27763/100000: episode: 3378, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000634, mae: 0.012214, mean_q: 0.020566
 27767/100000: episode: 3379, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000677, mae: 0.010696, mean_q: 0.018358
 27773/100000: episode: 3380, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001784, mae: 0.014227, mean_q: 0.016537
 27777/100000: episode: 3381, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000901, mae: 0.011013, mean_q: 0.019147
 27783/100000: episode: 3382, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000362, mae: 0.008169, mean_q: 0.007728
 27789/100000: episode: 3383, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000855, mae: 0.012281, mean_q: 0.019433
 27795/100000: episode: 3384, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001202, mae: 0.015914, mean_q: 0.021979
 27799/100000: episode: 3385, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001167, mae: 0.014139, mean_q: 0.035004
 27805/100000: episode: 3386, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000208, mae: 0.009427, mean_q: 0.017121
 27809/100000: episode: 3387, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000604, mae: 0.009061, mean_q: 0.019255
 27813/100000: episode: 3388, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002142, mae: 0.014949, mean_q: 0.021693
 27819/100000: episode: 3389, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000337, mae: 0.007615, mean_q: 0.007877
 27825/100000: episode: 3390, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000829, mae: 0.010843, mean_q: 0.010385
 27829/100000: episode: 3391, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000253, mae: 0.008578, mean_q: 0.006111
 27833/100000: episode: 3392, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000703, mae: 0.009779, mean_q: 0.008838
 27839/100000: episode: 3393, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000386, mae: 0.008794, mean_q: 0.008860
 27843/100000: episode: 3394, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000608, mae: 0.012582, mean_q: 0.016322
 27847/100000: episode: 3395, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000455, mae: 0.012144, mean_q: 0.017860
 27853/100000: episode: 3396, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000577, mae: 0.011592, mean_q: 0.015739
 27857/100000: episode: 3397, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000915, mae: 0.013472, mean_q: 0.017121
 27861/100000: episode: 3398, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000898, mae: 0.013960, mean_q: 0.018072
 27867/100000: episode: 3399, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000580, mae: 0.009656, mean_q: 0.013663
 27871/100000: episode: 3400, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000537, mae: 0.011527, mean_q: 0.012867
 27875/100000: episode: 3401, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000778, mae: 0.012755, mean_q: 0.020014
 27879/100000: episode: 3402, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000500, mae: 0.008794, mean_q: 0.014810
 27885/100000: episode: 3403, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000787, mae: 0.010187, mean_q: 0.014206
 27889/100000: episode: 3404, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000890, mae: 0.012118, mean_q: 0.015261
 27895/100000: episode: 3405, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000504, mae: 0.009950, mean_q: 0.010756
 27901/100000: episode: 3406, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000657, mae: 0.010899, mean_q: 0.015660
 27905/100000: episode: 3407, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000939, mae: 0.012520, mean_q: 0.017278
 27909/100000: episode: 3408, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000601, mae: 0.010032, mean_q: 0.011804
 27913/100000: episode: 3409, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001053, mae: 0.012943, mean_q: 0.009355
 27919/100000: episode: 3410, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000749, mae: 0.010251, mean_q: 0.009075
 27925/100000: episode: 3411, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001156, mae: 0.013598, mean_q: 0.015905
 27929/100000: episode: 3412, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000885, mae: 0.015658, mean_q: 0.023095
 27935/100000: episode: 3413, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000316, mae: 0.012478, mean_q: 0.024914
 27941/100000: episode: 3414, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000152, mae: 0.010120, mean_q: 0.014968
 27947/100000: episode: 3415, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000513, mae: 0.011099, mean_q: 0.019703
 27953/100000: episode: 3416, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001094, mae: 0.014064, mean_q: 0.017350
 27957/100000: episode: 3417, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000891, mae: 0.016451, mean_q: 0.020757
 27961/100000: episode: 3418, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000430, mae: 0.010044, mean_q: 0.013572
 27967/100000: episode: 3419, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000293, mae: 0.009364, mean_q: 0.015875
 27971/100000: episode: 3420, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000534, mae: 0.012692, mean_q: 0.022211
 27975/100000: episode: 3421, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001078, mae: 0.014386, mean_q: 0.018612
 27981/100000: episode: 3422, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000372, mae: 0.010318, mean_q: 0.014376
 27987/100000: episode: 3423, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000479, mae: 0.010894, mean_q: 0.014385
 27991/100000: episode: 3424, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000656, mae: 0.013876, mean_q: 0.020323
[Info] 2-TH LEVEL FOUND: 0.2712651193141937, Considering 10/100 traces
 27995/100000: episode: 3425, duration: 0.697s, episode steps: 4, steps per second: 6, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001182, mae: 0.014374, mean_q: 0.023066
 27999/100000: episode: 3426, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000440, mae: 0.011556, mean_q: 0.018988
 28003/100000: episode: 3427, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000650, mae: 0.012767, mean_q: 0.023331
[Info] FALSIFICATION!
 28006/100000: episode: 3428, duration: 0.269s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000451, mae: 0.011504, mean_q: 0.011390
 28010/100000: episode: 3429, duration: 0.024s, episode steps: 4, steps per second: 170, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000502, mae: 0.010596, mean_q: 0.011633
 28014/100000: episode: 3430, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000204, mae: 0.008720, mean_q: 0.010550
[Info] FALSIFICATION!
 28017/100000: episode: 3431, duration: 0.256s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000246, mae: 0.007778, mean_q: 0.009777
[Info] FALSIFICATION!
 28020/100000: episode: 3432, duration: 0.174s, episode steps: 3, steps per second: 17, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001067, mae: 0.013816, mean_q: 0.015985
 28024/100000: episode: 3433, duration: 0.023s, episode steps: 4, steps per second: 178, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001133, mae: 0.014858, mean_q: 0.034268
 28028/100000: episode: 3434, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000756, mae: 0.014374, mean_q: 0.020178
 28032/100000: episode: 3435, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.001103, mae: 0.018687, mean_q: 0.044720
 28036/100000: episode: 3436, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000396, mae: 0.014286, mean_q: 0.033267
 28040/100000: episode: 3437, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002408, mae: 0.021983, mean_q: 0.042495
 28044/100000: episode: 3438, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000560, mae: 0.012492, mean_q: 0.023396
 28048/100000: episode: 3439, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.001224, mae: 0.015118, mean_q: 0.023461
 28052/100000: episode: 3440, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001448, mae: 0.018915, mean_q: 0.029067
 28056/100000: episode: 3441, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000384, mae: 0.010689, mean_q: 0.008850
 28060/100000: episode: 3442, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000249, mae: 0.008153, mean_q: 0.006993
 28064/100000: episode: 3443, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000848, mae: 0.011928, mean_q: 0.014683
 28068/100000: episode: 3444, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000720, mae: 0.010232, mean_q: 0.011667
 28072/100000: episode: 3445, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000447, mae: 0.009344, mean_q: 0.010102
 28076/100000: episode: 3446, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001902, mae: 0.019754, mean_q: 0.023929
 28080/100000: episode: 3447, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000657, mae: 0.014722, mean_q: 0.023877
[Info] FALSIFICATION!
 28083/100000: episode: 3448, duration: 0.176s, episode steps: 3, steps per second: 17, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001068, mae: 0.019393, mean_q: 0.022952
 28087/100000: episode: 3449, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000498, mae: 0.014201, mean_q: 0.018887
 28091/100000: episode: 3450, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000755, mae: 0.012428, mean_q: 0.021671
 28095/100000: episode: 3451, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000537, mae: 0.014094, mean_q: 0.021070
 28099/100000: episode: 3452, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001249, mae: 0.015613, mean_q: 0.021056
 28103/100000: episode: 3453, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000535, mae: 0.012840, mean_q: 0.025421
 28107/100000: episode: 3454, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000825, mae: 0.014755, mean_q: 0.024700
 28111/100000: episode: 3455, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002503, mae: 0.022457, mean_q: 0.040989
 28115/100000: episode: 3456, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001102, mae: 0.015243, mean_q: 0.017113
 28119/100000: episode: 3457, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001109, mae: 0.015086, mean_q: 0.022203
 28123/100000: episode: 3458, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003794, mae: 0.030546, mean_q: 0.045039
 28127/100000: episode: 3459, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000332, mae: 0.013529, mean_q: 0.021677
 28131/100000: episode: 3460, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001781, mae: 0.016726, mean_q: 0.025519
 28135/100000: episode: 3461, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000586, mae: 0.012508, mean_q: 0.022577
 28139/100000: episode: 3462, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000834, mae: 0.015356, mean_q: 0.014035
 28143/100000: episode: 3463, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003671, mae: 0.026773, mean_q: 0.038924
 28147/100000: episode: 3464, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000782, mae: 0.013991, mean_q: 0.020476
 28151/100000: episode: 3465, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000481, mae: 0.010569, mean_q: 0.017076
 28155/100000: episode: 3466, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001793, mae: 0.020622, mean_q: 0.038485
 28159/100000: episode: 3467, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000369, mae: 0.010684, mean_q: 0.018244
 28163/100000: episode: 3468, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000827, mae: 0.010882, mean_q: 0.015511
 28167/100000: episode: 3469, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001793, mae: 0.019386, mean_q: 0.023320
 28171/100000: episode: 3470, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.001363, mae: 0.018717, mean_q: 0.029539
 28175/100000: episode: 3471, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001403, mae: 0.016683, mean_q: 0.025792
 28179/100000: episode: 3472, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001568, mae: 0.021318, mean_q: 0.038212
 28183/100000: episode: 3473, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002387, mae: 0.019492, mean_q: 0.032172
 28187/100000: episode: 3474, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000461, mae: 0.010640, mean_q: 0.017276
 28191/100000: episode: 3475, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.005442, mae: 0.028476, mean_q: 0.023157
 28195/100000: episode: 3476, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001374, mae: 0.018096, mean_q: 0.039386
 28199/100000: episode: 3477, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001309, mae: 0.020269, mean_q: 0.043634
 28203/100000: episode: 3478, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001412, mae: 0.016665, mean_q: 0.024637
 28207/100000: episode: 3479, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001860, mae: 0.024077, mean_q: 0.037923
[Info] FALSIFICATION!
 28210/100000: episode: 3480, duration: 0.253s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001847, mae: 0.018821, mean_q: 0.023809
 28214/100000: episode: 3481, duration: 0.026s, episode steps: 4, steps per second: 154, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000531, mae: 0.011398, mean_q: 0.015410
 28218/100000: episode: 3482, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001325, mae: 0.016279, mean_q: 0.017997
 28222/100000: episode: 3483, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001024, mae: 0.013636, mean_q: 0.025135
 28226/100000: episode: 3484, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000245, mae: 0.008827, mean_q: 0.013382
[Info] FALSIFICATION!
 28229/100000: episode: 3485, duration: 0.260s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.003017, mae: 0.021814, mean_q: 0.026784
 28233/100000: episode: 3486, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002718, mae: 0.020619, mean_q: 0.035023
 28237/100000: episode: 3487, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003046, mae: 0.029721, mean_q: 0.053835
 28241/100000: episode: 3488, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000782, mae: 0.019382, mean_q: 0.028387
 28245/100000: episode: 3489, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001529, mae: 0.018869, mean_q: 0.026155
[Info] FALSIFICATION!
 28248/100000: episode: 3490, duration: 0.262s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001722, mae: 0.023706, mean_q: 0.031944
 28252/100000: episode: 3491, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001285, mae: 0.017106, mean_q: 0.026245
 28256/100000: episode: 3492, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001659, mae: 0.020212, mean_q: 0.032103
 28260/100000: episode: 3493, duration: 0.023s, episode steps: 4, steps per second: 178, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002701, mae: 0.027070, mean_q: 0.047823
 28264/100000: episode: 3494, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.001145, mae: 0.020964, mean_q: 0.031178
[Info] FALSIFICATION!
 28267/100000: episode: 3495, duration: 0.276s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001522, mae: 0.022113, mean_q: 0.023417
 28271/100000: episode: 3496, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001409, mae: 0.018760, mean_q: 0.023489
 28275/100000: episode: 3497, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002053, mae: 0.021083, mean_q: 0.034533
 28279/100000: episode: 3498, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001154, mae: 0.014870, mean_q: 0.021283
 28283/100000: episode: 3499, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001952, mae: 0.023580, mean_q: 0.025021
 28287/100000: episode: 3500, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002402, mae: 0.023594, mean_q: 0.032287
[Info] FALSIFICATION!
 28290/100000: episode: 3501, duration: 0.224s, episode steps: 3, steps per second: 13, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002918, mae: 0.022142, mean_q: 0.026680
 28294/100000: episode: 3502, duration: 0.024s, episode steps: 4, steps per second: 166, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003116, mae: 0.030872, mean_q: 0.048333
[Info] FALSIFICATION!
 28297/100000: episode: 3503, duration: 0.174s, episode steps: 3, steps per second: 17, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.003018, mae: 0.031024, mean_q: 0.046642
 28301/100000: episode: 3504, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001501, mae: 0.020235, mean_q: 0.027242
 28305/100000: episode: 3505, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002502, mae: 0.026113, mean_q: 0.036569
 28309/100000: episode: 3506, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000748, mae: 0.012419, mean_q: 0.020317
 28313/100000: episode: 3507, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001853, mae: 0.022454, mean_q: 0.030312
 28317/100000: episode: 3508, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001889, mae: 0.019173, mean_q: 0.031261
 28321/100000: episode: 3509, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002445, mae: 0.026122, mean_q: 0.038623
 28325/100000: episode: 3510, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002864, mae: 0.027262, mean_q: 0.040589
 28329/100000: episode: 3511, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001907, mae: 0.023982, mean_q: 0.037767
[Info] FALSIFICATION!
 28332/100000: episode: 3512, duration: 0.262s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002816, mae: 0.027933, mean_q: 0.050722
 28336/100000: episode: 3513, duration: 0.025s, episode steps: 4, steps per second: 163, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001883, mae: 0.026156, mean_q: 0.060416
 28340/100000: episode: 3514, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001433, mae: 0.018233, mean_q: 0.031992
[Info] Complete ISplit Iteration
[Info] Levels: [0.03668772, 0.27126512, 1.0406054]
[Info] Cond. Prob: [0.14, 0.1, 0.17]
[Info] Error Prob: 0.0023800000000000006

 28344/100000: episode: 3515, duration: 0.909s, episode steps: 4, steps per second: 4, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.004003, mae: 0.034603, mean_q: 0.064189
 28354/100000: episode: 3516, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001426, mae: 0.019158, mean_q: 0.025108
 28364/100000: episode: 3517, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001733, mae: 0.022017, mean_q: 0.026296
 28374/100000: episode: 3518, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001807, mae: 0.021568, mean_q: 0.034371
 28384/100000: episode: 3519, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001393, mae: 0.019730, mean_q: 0.029553
 28394/100000: episode: 3520, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002534, mae: 0.022534, mean_q: 0.039801
 28404/100000: episode: 3521, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001903, mae: 0.021021, mean_q: 0.038684
 28414/100000: episode: 3522, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002486, mae: 0.025671, mean_q: 0.039715
 28424/100000: episode: 3523, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001481, mae: 0.018541, mean_q: 0.023135
 28434/100000: episode: 3524, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001307, mae: 0.020440, mean_q: 0.028644
 28444/100000: episode: 3525, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001903, mae: 0.023428, mean_q: 0.040491
 28454/100000: episode: 3526, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002389, mae: 0.023295, mean_q: 0.037937
 28464/100000: episode: 3527, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002252, mae: 0.025780, mean_q: 0.050178
 28474/100000: episode: 3528, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002286, mae: 0.021900, mean_q: 0.034325
 28484/100000: episode: 3529, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001837, mae: 0.021934, mean_q: 0.032693
 28494/100000: episode: 3530, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001631, mae: 0.021259, mean_q: 0.025319
 28504/100000: episode: 3531, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001500, mae: 0.021873, mean_q: 0.034069
 28514/100000: episode: 3532, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001974, mae: 0.024914, mean_q: 0.036855
 28524/100000: episode: 3533, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002483, mae: 0.026285, mean_q: 0.040221
 28534/100000: episode: 3534, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.002401, mae: 0.025900, mean_q: 0.033895
 28544/100000: episode: 3535, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001420, mae: 0.020988, mean_q: 0.040322
 28554/100000: episode: 3536, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002333, mae: 0.025840, mean_q: 0.043203
 28564/100000: episode: 3537, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001336, mae: 0.018378, mean_q: 0.027280
 28574/100000: episode: 3538, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002408, mae: 0.026845, mean_q: 0.042062
 28584/100000: episode: 3539, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001105, mae: 0.018468, mean_q: 0.037997
 28594/100000: episode: 3540, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.001797, mae: 0.022054, mean_q: 0.039219
 28604/100000: episode: 3541, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002632, mae: 0.024410, mean_q: 0.037045
 28614/100000: episode: 3542, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002287, mae: 0.026356, mean_q: 0.049853
 28624/100000: episode: 3543, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001554, mae: 0.020774, mean_q: 0.035967
 28634/100000: episode: 3544, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001857, mae: 0.020800, mean_q: 0.030249
 28644/100000: episode: 3545, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001119, mae: 0.018321, mean_q: 0.033988
 28654/100000: episode: 3546, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001946, mae: 0.022766, mean_q: 0.036807
 28664/100000: episode: 3547, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002044, mae: 0.025037, mean_q: 0.036016
 28674/100000: episode: 3548, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.003370, mae: 0.025998, mean_q: 0.036464
 28684/100000: episode: 3549, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001844, mae: 0.020197, mean_q: 0.026756
 28694/100000: episode: 3550, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001484, mae: 0.019682, mean_q: 0.021382
 28704/100000: episode: 3551, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001458, mae: 0.020267, mean_q: 0.029069
 28714/100000: episode: 3552, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001254, mae: 0.020178, mean_q: 0.035003
 28724/100000: episode: 3553, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000893, mae: 0.016502, mean_q: 0.025224
 28734/100000: episode: 3554, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002539, mae: 0.024612, mean_q: 0.041899
 28744/100000: episode: 3555, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002228, mae: 0.024884, mean_q: 0.036190
 28754/100000: episode: 3556, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002693, mae: 0.026458, mean_q: 0.046535
 28764/100000: episode: 3557, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001632, mae: 0.016533, mean_q: 0.016145
 28774/100000: episode: 3558, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002101, mae: 0.023230, mean_q: 0.037852
 28784/100000: episode: 3559, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001366, mae: 0.020411, mean_q: 0.031514
 28794/100000: episode: 3560, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001767, mae: 0.022861, mean_q: 0.038548
 28804/100000: episode: 3561, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.003334, mae: 0.026968, mean_q: 0.030853
 28814/100000: episode: 3562, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001605, mae: 0.020931, mean_q: 0.031937
 28824/100000: episode: 3563, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001815, mae: 0.021388, mean_q: 0.037238
 28834/100000: episode: 3564, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.002087, mae: 0.024065, mean_q: 0.043247
 28844/100000: episode: 3565, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002932, mae: 0.027187, mean_q: 0.035230
 28854/100000: episode: 3566, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002667, mae: 0.027376, mean_q: 0.042535
 28864/100000: episode: 3567, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001948, mae: 0.023079, mean_q: 0.031733
 28874/100000: episode: 3568, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002039, mae: 0.021151, mean_q: 0.037216
 28884/100000: episode: 3569, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001546, mae: 0.020203, mean_q: 0.038767
 28894/100000: episode: 3570, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001966, mae: 0.023527, mean_q: 0.034426
 28904/100000: episode: 3571, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001944, mae: 0.022107, mean_q: 0.037619
 28914/100000: episode: 3572, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002038, mae: 0.023413, mean_q: 0.037006
 28924/100000: episode: 3573, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001814, mae: 0.023172, mean_q: 0.039299
 28934/100000: episode: 3574, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002098, mae: 0.023178, mean_q: 0.042985
 28944/100000: episode: 3575, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002485, mae: 0.023781, mean_q: 0.036219
 28954/100000: episode: 3576, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001921, mae: 0.023488, mean_q: 0.038922
 28964/100000: episode: 3577, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002146, mae: 0.024085, mean_q: 0.034586
 28974/100000: episode: 3578, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002043, mae: 0.023824, mean_q: 0.036366
 28984/100000: episode: 3579, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001498, mae: 0.021702, mean_q: 0.037029
 28994/100000: episode: 3580, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.002988, mae: 0.028783, mean_q: 0.049622
 29004/100000: episode: 3581, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000972, mae: 0.016898, mean_q: 0.027022
 29014/100000: episode: 3582, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002051, mae: 0.020981, mean_q: 0.029577
 29024/100000: episode: 3583, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002543, mae: 0.021561, mean_q: 0.028912
 29034/100000: episode: 3584, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001336, mae: 0.018610, mean_q: 0.033108
 29044/100000: episode: 3585, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.002278, mae: 0.025631, mean_q: 0.038742
 29054/100000: episode: 3586, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002502, mae: 0.027609, mean_q: 0.048609
 29064/100000: episode: 3587, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001707, mae: 0.021708, mean_q: 0.041368
 29074/100000: episode: 3588, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002518, mae: 0.027182, mean_q: 0.047579
 29084/100000: episode: 3589, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002650, mae: 0.027765, mean_q: 0.027714
 29094/100000: episode: 3590, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001489, mae: 0.022960, mean_q: 0.035053
 29104/100000: episode: 3591, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002679, mae: 0.030101, mean_q: 0.049282
 29114/100000: episode: 3592, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002164, mae: 0.021197, mean_q: 0.034363
 29124/100000: episode: 3593, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001745, mae: 0.023933, mean_q: 0.043182
 29134/100000: episode: 3594, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001973, mae: 0.021435, mean_q: 0.034683
 29144/100000: episode: 3595, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002127, mae: 0.023407, mean_q: 0.039555
 29154/100000: episode: 3596, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001745, mae: 0.021779, mean_q: 0.030952
 29164/100000: episode: 3597, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.003579, mae: 0.031122, mean_q: 0.050646
 29174/100000: episode: 3598, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001503, mae: 0.020958, mean_q: 0.040723
 29184/100000: episode: 3599, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001859, mae: 0.020076, mean_q: 0.022327
 29194/100000: episode: 3600, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002024, mae: 0.023406, mean_q: 0.034011
 29204/100000: episode: 3601, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002340, mae: 0.028550, mean_q: 0.046707
 29214/100000: episode: 3602, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002079, mae: 0.025705, mean_q: 0.042444
 29224/100000: episode: 3603, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001579, mae: 0.022176, mean_q: 0.042445
 29234/100000: episode: 3604, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001213, mae: 0.020155, mean_q: 0.044188
 29244/100000: episode: 3605, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002277, mae: 0.024065, mean_q: 0.040952
 29254/100000: episode: 3606, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.003530, mae: 0.029516, mean_q: 0.029690
 29264/100000: episode: 3607, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001239, mae: 0.017889, mean_q: 0.028053
 29274/100000: episode: 3608, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002626, mae: 0.027490, mean_q: 0.044978
 29284/100000: episode: 3609, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001823, mae: 0.025396, mean_q: 0.043016
 29294/100000: episode: 3610, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001315, mae: 0.020420, mean_q: 0.033529
 29304/100000: episode: 3611, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000743, mae: 0.015605, mean_q: 0.025740
 29314/100000: episode: 3612, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001821, mae: 0.020024, mean_q: 0.049378
 29324/100000: episode: 3613, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.003305, mae: 0.025659, mean_q: 0.038796
 29334/100000: episode: 3614, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000997, mae: 0.016494, mean_q: 0.023291
[Info] 1-TH LEVEL FOUND: 0.027572687715291977, Considering 10/100 traces
 29344/100000: episode: 3615, duration: 0.723s, episode steps: 10, steps per second: 14, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001519, mae: 0.018599, mean_q: 0.023214
 29351/100000: episode: 3616, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001332, mae: 0.018052, mean_q: 0.027225
 29358/100000: episode: 3617, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.002118, mae: 0.024141, mean_q: 0.037783
 29365/100000: episode: 3618, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.002191, mae: 0.022128, mean_q: 0.041066
 29372/100000: episode: 3619, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002327, mae: 0.029018, mean_q: 0.042685
 29377/100000: episode: 3620, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.002250, mae: 0.023063, mean_q: 0.047458
 29384/100000: episode: 3621, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001637, mae: 0.019495, mean_q: 0.030112
 29389/100000: episode: 3622, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002492, mae: 0.027049, mean_q: 0.041621
 29391/100000: episode: 3623, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001538, mae: 0.025822, mean_q: 0.036598
 29398/100000: episode: 3624, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002053, mae: 0.017952, mean_q: 0.025748
 29405/100000: episode: 3625, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001563, mae: 0.019974, mean_q: 0.027067
 29410/100000: episode: 3626, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001412, mae: 0.016495, mean_q: 0.027154
 29415/100000: episode: 3627, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002467, mae: 0.024448, mean_q: 0.040680
 29422/100000: episode: 3628, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000782, mae: 0.015460, mean_q: 0.020330
 29424/100000: episode: 3629, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000561, mae: 0.012628, mean_q: 0.014981
 29431/100000: episode: 3630, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001666, mae: 0.019873, mean_q: 0.028408
 29438/100000: episode: 3631, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.002396, mae: 0.024992, mean_q: 0.050956
 29440/100000: episode: 3632, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001705, mae: 0.022117, mean_q: 0.033893
 29442/100000: episode: 3633, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000212, mae: 0.011503, mean_q: 0.019146
 29449/100000: episode: 3634, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001534, mae: 0.018389, mean_q: 0.033305
 29456/100000: episode: 3635, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000878, mae: 0.014149, mean_q: 0.029728
 29458/100000: episode: 3636, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001368, mae: 0.021861, mean_q: 0.037162
 29460/100000: episode: 3637, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003642, mae: 0.032378, mean_q: 0.040122
 29467/100000: episode: 3638, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.002589, mae: 0.025143, mean_q: 0.042328
 29472/100000: episode: 3639, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.002018, mae: 0.025247, mean_q: 0.040496
 29479/100000: episode: 3640, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.002299, mae: 0.025639, mean_q: 0.038475
 29484/100000: episode: 3641, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000955, mae: 0.016027, mean_q: 0.024840
 29491/100000: episode: 3642, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000780, mae: 0.015127, mean_q: 0.024338
 29498/100000: episode: 3643, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.002557, mae: 0.031156, mean_q: 0.049611
 29505/100000: episode: 3644, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.002206, mae: 0.024920, mean_q: 0.047325
 29507/100000: episode: 3645, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002244, mae: 0.021967, mean_q: 0.042576
 29512/100000: episode: 3646, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001524, mae: 0.018747, mean_q: 0.029054
 29519/100000: episode: 3647, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002541, mae: 0.024991, mean_q: 0.034579
 29524/100000: episode: 3648, duration: 0.030s, episode steps: 5, steps per second: 168, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.002409, mae: 0.027393, mean_q: 0.041044
 29526/100000: episode: 3649, duration: 0.017s, episode steps: 2, steps per second: 117, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003318, mae: 0.035966, mean_q: 0.073347
 29533/100000: episode: 3650, duration: 0.044s, episode steps: 7, steps per second: 161, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001419, mae: 0.018323, mean_q: 0.034600
 29540/100000: episode: 3651, duration: 0.045s, episode steps: 7, steps per second: 156, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001672, mae: 0.019810, mean_q: 0.031306
 29547/100000: episode: 3652, duration: 0.043s, episode steps: 7, steps per second: 161, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001871, mae: 0.022087, mean_q: 0.028616
 29554/100000: episode: 3653, duration: 0.042s, episode steps: 7, steps per second: 167, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.002078, mae: 0.022302, mean_q: 0.032756
 29556/100000: episode: 3654, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001011, mae: 0.018980, mean_q: 0.044431
 29563/100000: episode: 3655, duration: 0.045s, episode steps: 7, steps per second: 154, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001052, mae: 0.016442, mean_q: 0.024321
 29568/100000: episode: 3656, duration: 0.034s, episode steps: 5, steps per second: 148, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.001554, mae: 0.021185, mean_q: 0.046681
 29570/100000: episode: 3657, duration: 0.017s, episode steps: 2, steps per second: 119, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001478, mae: 0.017486, mean_q: 0.024720
 29577/100000: episode: 3658, duration: 0.045s, episode steps: 7, steps per second: 154, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001581, mae: 0.021473, mean_q: 0.037758
 29584/100000: episode: 3659, duration: 0.039s, episode steps: 7, steps per second: 178, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001679, mae: 0.020687, mean_q: 0.033029
 29586/100000: episode: 3660, duration: 0.014s, episode steps: 2, steps per second: 142, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002358, mae: 0.021123, mean_q: 0.029727
 29591/100000: episode: 3661, duration: 0.032s, episode steps: 5, steps per second: 156, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001768, mae: 0.020061, mean_q: 0.031591
 29598/100000: episode: 3662, duration: 0.042s, episode steps: 7, steps per second: 166, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.001073, mae: 0.018901, mean_q: 0.033483
 29600/100000: episode: 3663, duration: 0.016s, episode steps: 2, steps per second: 124, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002025, mae: 0.022092, mean_q: 0.043270
 29602/100000: episode: 3664, duration: 0.016s, episode steps: 2, steps per second: 128, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002343, mae: 0.020758, mean_q: 0.037132
 29609/100000: episode: 3665, duration: 0.046s, episode steps: 7, steps per second: 151, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.002036, mae: 0.021359, mean_q: 0.039646
 29616/100000: episode: 3666, duration: 0.045s, episode steps: 7, steps per second: 156, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001111, mae: 0.016185, mean_q: 0.023251
 29623/100000: episode: 3667, duration: 0.045s, episode steps: 7, steps per second: 155, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001221, mae: 0.016807, mean_q: 0.022925
 29628/100000: episode: 3668, duration: 0.033s, episode steps: 5, steps per second: 150, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001558, mae: 0.018019, mean_q: 0.022648
 29635/100000: episode: 3669, duration: 0.041s, episode steps: 7, steps per second: 169, episode reward: 1.947, mean reward: 0.278 [0.007, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 7.857 [5.000, 11.000], loss: 0.002263, mae: 0.022236, mean_q: 0.023229
 29637/100000: episode: 3670, duration: 0.017s, episode steps: 2, steps per second: 115, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001874, mae: 0.019263, mean_q: 0.037212
 29644/100000: episode: 3671, duration: 0.046s, episode steps: 7, steps per second: 151, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.001261, mae: 0.020601, mean_q: 0.027329
 29646/100000: episode: 3672, duration: 0.018s, episode steps: 2, steps per second: 111, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000787, mae: 0.014536, mean_q: 0.034673
 29648/100000: episode: 3673, duration: 0.017s, episode steps: 2, steps per second: 118, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001672, mae: 0.021971, mean_q: 0.034124
 29653/100000: episode: 3674, duration: 0.031s, episode steps: 5, steps per second: 162, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002749, mae: 0.029495, mean_q: 0.041349
 29660/100000: episode: 3675, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000863, mae: 0.014516, mean_q: 0.023020
 29662/100000: episode: 3676, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001552, mae: 0.015539, mean_q: 0.029810
 29664/100000: episode: 3677, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002209, mae: 0.026746, mean_q: 0.055393
 29669/100000: episode: 3678, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000768, mae: 0.012814, mean_q: 0.018354
 29676/100000: episode: 3679, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001324, mae: 0.017724, mean_q: 0.023174
 29681/100000: episode: 3680, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001969, mae: 0.016185, mean_q: 0.020612
 29688/100000: episode: 3681, duration: 0.045s, episode steps: 7, steps per second: 155, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001947, mae: 0.023729, mean_q: 0.034312
 29690/100000: episode: 3682, duration: 0.016s, episode steps: 2, steps per second: 125, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000839, mae: 0.017783, mean_q: 0.025303
 29695/100000: episode: 3683, duration: 0.035s, episode steps: 5, steps per second: 142, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001643, mae: 0.021786, mean_q: 0.037250
 29702/100000: episode: 3684, duration: 0.047s, episode steps: 7, steps per second: 150, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001030, mae: 0.017727, mean_q: 0.028251
 29704/100000: episode: 3685, duration: 0.017s, episode steps: 2, steps per second: 120, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002014, mae: 0.024250, mean_q: 0.034534
 29711/100000: episode: 3686, duration: 0.041s, episode steps: 7, steps per second: 169, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001751, mae: 0.021331, mean_q: 0.028486
 29713/100000: episode: 3687, duration: 0.017s, episode steps: 2, steps per second: 117, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001284, mae: 0.019079, mean_q: 0.030400
 29720/100000: episode: 3688, duration: 0.055s, episode steps: 7, steps per second: 127, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001157, mae: 0.017765, mean_q: 0.029237
 29727/100000: episode: 3689, duration: 0.044s, episode steps: 7, steps per second: 160, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.002120, mae: 0.027611, mean_q: 0.052049
 29732/100000: episode: 3690, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.002793, mae: 0.022815, mean_q: 0.031670
 29734/100000: episode: 3691, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004613, mae: 0.027526, mean_q: 0.030783
 29741/100000: episode: 3692, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.002272, mae: 0.024499, mean_q: 0.043103
 29748/100000: episode: 3693, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.003592, mae: 0.030510, mean_q: 0.050513
 29753/100000: episode: 3694, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001932, mae: 0.020892, mean_q: 0.034056
 29755/100000: episode: 3695, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000962, mae: 0.015747, mean_q: 0.013103
 29760/100000: episode: 3696, duration: 0.024s, episode steps: 5, steps per second: 206, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001888, mae: 0.023008, mean_q: 0.035358
 29762/100000: episode: 3697, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005204, mae: 0.036324, mean_q: 0.051145
 29769/100000: episode: 3698, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002009, mae: 0.019177, mean_q: 0.045433
 29774/100000: episode: 3699, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003315, mae: 0.027016, mean_q: 0.042275
 29781/100000: episode: 3700, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000990, mae: 0.015946, mean_q: 0.018734
 29788/100000: episode: 3701, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.004318, mae: 0.026481, mean_q: 0.018294
 29790/100000: episode: 3702, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001437, mae: 0.021897, mean_q: 0.028195
 29792/100000: episode: 3703, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001651, mae: 0.021215, mean_q: 0.026195
[Info] FALSIFICATION!
 29798/100000: episode: 3704, duration: 0.263s, episode steps: 6, steps per second: 23, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.001039, mae: 0.015678, mean_q: 0.025098
[Info] Complete ISplit Iteration
[Info] Levels: [0.027572688, 0.99724287]
[Info] Cond. Prob: [0.1, 0.02]
[Info] Error Prob: 0.002

 29800/100000: episode: 3705, duration: 0.811s, episode steps: 2, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000374, mae: 0.012432, mean_q: 0.018928
 29810/100000: episode: 3706, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002076, mae: 0.023445, mean_q: 0.038350
 29820/100000: episode: 3707, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002238, mae: 0.025108, mean_q: 0.041351
 29830/100000: episode: 3708, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002051, mae: 0.023378, mean_q: 0.037851
 29840/100000: episode: 3709, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001704, mae: 0.017776, mean_q: 0.029302
 29850/100000: episode: 3710, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001243, mae: 0.018320, mean_q: 0.028445
 29860/100000: episode: 3711, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001591, mae: 0.019202, mean_q: 0.028322
 29870/100000: episode: 3712, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001223, mae: 0.016634, mean_q: 0.025744
 29880/100000: episode: 3713, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001519, mae: 0.016892, mean_q: 0.026858
 29890/100000: episode: 3714, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001544, mae: 0.018623, mean_q: 0.026945
 29900/100000: episode: 3715, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001750, mae: 0.020124, mean_q: 0.033520
 29910/100000: episode: 3716, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001442, mae: 0.018703, mean_q: 0.034702
 29920/100000: episode: 3717, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000742, mae: 0.014499, mean_q: 0.031395
 29930/100000: episode: 3718, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002919, mae: 0.025667, mean_q: 0.045835
 29940/100000: episode: 3719, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000756, mae: 0.011949, mean_q: 0.019094
 29950/100000: episode: 3720, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001271, mae: 0.015809, mean_q: 0.025105
 29960/100000: episode: 3721, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001336, mae: 0.018526, mean_q: 0.027346
 29970/100000: episode: 3722, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001408, mae: 0.019937, mean_q: 0.035485
 29980/100000: episode: 3723, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001038, mae: 0.016822, mean_q: 0.033549
 29990/100000: episode: 3724, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001733, mae: 0.020097, mean_q: 0.041492
 30000/100000: episode: 3725, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001577, mae: 0.019259, mean_q: 0.028464
 30010/100000: episode: 3726, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001040, mae: 0.015335, mean_q: 0.021424
 30020/100000: episode: 3727, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002272, mae: 0.021774, mean_q: 0.036576
 30030/100000: episode: 3728, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001549, mae: 0.019244, mean_q: 0.041166
 30040/100000: episode: 3729, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001335, mae: 0.017389, mean_q: 0.022885
 30050/100000: episode: 3730, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001863, mae: 0.018804, mean_q: 0.028050
 30060/100000: episode: 3731, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001545, mae: 0.018627, mean_q: 0.029200
 30070/100000: episode: 3732, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001880, mae: 0.020800, mean_q: 0.028112
 30080/100000: episode: 3733, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000812, mae: 0.013985, mean_q: 0.014778
 30090/100000: episode: 3734, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000772, mae: 0.013145, mean_q: 0.016493
 30100/100000: episode: 3735, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001244, mae: 0.017814, mean_q: 0.027297
 30110/100000: episode: 3736, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001213, mae: 0.017061, mean_q: 0.023889
 30120/100000: episode: 3737, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001065, mae: 0.015454, mean_q: 0.030276
 30130/100000: episode: 3738, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001368, mae: 0.018131, mean_q: 0.025501
 30140/100000: episode: 3739, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000563, mae: 0.012207, mean_q: 0.019095
 30150/100000: episode: 3740, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001271, mae: 0.015132, mean_q: 0.024794
 30160/100000: episode: 3741, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001738, mae: 0.020076, mean_q: 0.037529
 30170/100000: episode: 3742, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000984, mae: 0.015352, mean_q: 0.026503
 30180/100000: episode: 3743, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001187, mae: 0.015330, mean_q: 0.025947
 30190/100000: episode: 3744, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001361, mae: 0.015412, mean_q: 0.025170
 30200/100000: episode: 3745, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001101, mae: 0.015702, mean_q: 0.025720
 30210/100000: episode: 3746, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001117, mae: 0.016570, mean_q: 0.026644
 30220/100000: episode: 3747, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.002078, mae: 0.019858, mean_q: 0.028897
 30230/100000: episode: 3748, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000958, mae: 0.014020, mean_q: 0.018212
 30240/100000: episode: 3749, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001220, mae: 0.016417, mean_q: 0.028085
 30250/100000: episode: 3750, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001506, mae: 0.018360, mean_q: 0.027919
 30260/100000: episode: 3751, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001780, mae: 0.018843, mean_q: 0.030024
 30270/100000: episode: 3752, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001595, mae: 0.019565, mean_q: 0.033602
 30280/100000: episode: 3753, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001154, mae: 0.015971, mean_q: 0.022824
 30290/100000: episode: 3754, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001438, mae: 0.015675, mean_q: 0.022017
 30300/100000: episode: 3755, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000991, mae: 0.017435, mean_q: 0.030013
 30310/100000: episode: 3756, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001515, mae: 0.019849, mean_q: 0.038354
 30320/100000: episode: 3757, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001176, mae: 0.015314, mean_q: 0.026023
 30330/100000: episode: 3758, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001592, mae: 0.017504, mean_q: 0.026327
 30340/100000: episode: 3759, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001458, mae: 0.019418, mean_q: 0.030397
 30350/100000: episode: 3760, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001559, mae: 0.020011, mean_q: 0.025731
 30360/100000: episode: 3761, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001431, mae: 0.017220, mean_q: 0.030519
 30370/100000: episode: 3762, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001037, mae: 0.015968, mean_q: 0.023442
 30380/100000: episode: 3763, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001692, mae: 0.017966, mean_q: 0.030761
 30390/100000: episode: 3764, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001028, mae: 0.015223, mean_q: 0.027944
 30400/100000: episode: 3765, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000648, mae: 0.012543, mean_q: 0.020275
 30410/100000: episode: 3766, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000955, mae: 0.014000, mean_q: 0.018497
 30420/100000: episode: 3767, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001625, mae: 0.016946, mean_q: 0.021895
 30430/100000: episode: 3768, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001145, mae: 0.017553, mean_q: 0.031760
 30440/100000: episode: 3769, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001760, mae: 0.019017, mean_q: 0.028804
 30450/100000: episode: 3770, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001106, mae: 0.016688, mean_q: 0.025456
 30460/100000: episode: 3771, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000726, mae: 0.012821, mean_q: 0.026140
 30470/100000: episode: 3772, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002173, mae: 0.019794, mean_q: 0.021751
 30480/100000: episode: 3773, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001624, mae: 0.022188, mean_q: 0.041613
 30490/100000: episode: 3774, duration: 0.066s, episode steps: 10, steps per second: 153, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001196, mae: 0.018966, mean_q: 0.032000
 30500/100000: episode: 3775, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001548, mae: 0.016424, mean_q: 0.024742
 30510/100000: episode: 3776, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001756, mae: 0.020667, mean_q: 0.040734
 30520/100000: episode: 3777, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001372, mae: 0.016687, mean_q: 0.027289
 30530/100000: episode: 3778, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001779, mae: 0.020784, mean_q: 0.035596
 30540/100000: episode: 3779, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001288, mae: 0.018367, mean_q: 0.032041
 30550/100000: episode: 3780, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001776, mae: 0.019911, mean_q: 0.034077
 30560/100000: episode: 3781, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001720, mae: 0.019227, mean_q: 0.033272
 30570/100000: episode: 3782, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000974, mae: 0.015009, mean_q: 0.030802
 30580/100000: episode: 3783, duration: 0.071s, episode steps: 10, steps per second: 142, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001838, mae: 0.018197, mean_q: 0.028026
 30590/100000: episode: 3784, duration: 0.069s, episode steps: 10, steps per second: 146, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001596, mae: 0.017570, mean_q: 0.032594
 30600/100000: episode: 3785, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000624, mae: 0.011549, mean_q: 0.020035
 30610/100000: episode: 3786, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001204, mae: 0.013018, mean_q: 0.022059
 30620/100000: episode: 3787, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000759, mae: 0.010957, mean_q: 0.017626
 30630/100000: episode: 3788, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001636, mae: 0.020789, mean_q: 0.035535
 30640/100000: episode: 3789, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000842, mae: 0.014109, mean_q: 0.024485
 30650/100000: episode: 3790, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001703, mae: 0.019091, mean_q: 0.020107
 30660/100000: episode: 3791, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001267, mae: 0.017382, mean_q: 0.031375
 30670/100000: episode: 3792, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002008, mae: 0.023983, mean_q: 0.051105
 30680/100000: episode: 3793, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000920, mae: 0.014540, mean_q: 0.023699
 30690/100000: episode: 3794, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002138, mae: 0.018856, mean_q: 0.027549
 30700/100000: episode: 3795, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002073, mae: 0.020964, mean_q: 0.039262
 30710/100000: episode: 3796, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001612, mae: 0.020020, mean_q: 0.032062
 30720/100000: episode: 3797, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001273, mae: 0.015856, mean_q: 0.023604
 30730/100000: episode: 3798, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001652, mae: 0.017549, mean_q: 0.020685
 30740/100000: episode: 3799, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001789, mae: 0.018237, mean_q: 0.028097
 30750/100000: episode: 3800, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001319, mae: 0.018688, mean_q: 0.035157
 30760/100000: episode: 3801, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001416, mae: 0.017096, mean_q: 0.026137
 30770/100000: episode: 3802, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000992, mae: 0.016391, mean_q: 0.024317
 30780/100000: episode: 3803, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001420, mae: 0.015897, mean_q: 0.026155
 30790/100000: episode: 3804, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000718, mae: 0.011972, mean_q: 0.029887
[Info] 1-TH LEVEL FOUND: 0.03373813256621361, Considering 12/100 traces
 30800/100000: episode: 3805, duration: 0.710s, episode steps: 10, steps per second: 14, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000677, mae: 0.013060, mean_q: 0.027390
 30807/100000: episode: 3806, duration: 0.035s, episode steps: 7, steps per second: 197, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001628, mae: 0.018738, mean_q: 0.034190
 30811/100000: episode: 3807, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001271, mae: 0.015732, mean_q: 0.027567
 30818/100000: episode: 3808, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000652, mae: 0.012388, mean_q: 0.016860
 30825/100000: episode: 3809, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001867, mae: 0.017113, mean_q: 0.017920
 30832/100000: episode: 3810, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.001387, mae: 0.022114, mean_q: 0.037534
 30839/100000: episode: 3811, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.002008, mae: 0.024452, mean_q: 0.040360
 30846/100000: episode: 3812, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001062, mae: 0.016062, mean_q: 0.021443
 30853/100000: episode: 3813, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001786, mae: 0.017581, mean_q: 0.014724
 30860/100000: episode: 3814, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.001293, mae: 0.016245, mean_q: 0.022899
 30867/100000: episode: 3815, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.001655, mae: 0.019856, mean_q: 0.036149
 30874/100000: episode: 3816, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001906, mae: 0.023774, mean_q: 0.044292
 30878/100000: episode: 3817, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001849, mae: 0.023637, mean_q: 0.043913
 30885/100000: episode: 3818, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.000810, mae: 0.012493, mean_q: 0.021328
 30889/100000: episode: 3819, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001506, mae: 0.017530, mean_q: 0.029091
 30896/100000: episode: 3820, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.001160, mae: 0.019525, mean_q: 0.029501
 30903/100000: episode: 3821, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001393, mae: 0.016095, mean_q: 0.024742
 30910/100000: episode: 3822, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001519, mae: 0.018526, mean_q: 0.025754
 30914/100000: episode: 3823, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001932, mae: 0.020814, mean_q: 0.023009
 30921/100000: episode: 3824, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001163, mae: 0.016395, mean_q: 0.020086
 30925/100000: episode: 3825, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000403, mae: 0.012193, mean_q: 0.012567
 30929/100000: episode: 3826, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001695, mae: 0.024719, mean_q: 0.048645
 30936/100000: episode: 3827, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001541, mae: 0.021572, mean_q: 0.037323
 30943/100000: episode: 3828, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001976, mae: 0.021285, mean_q: 0.035694
 30950/100000: episode: 3829, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.002502, mae: 0.024055, mean_q: 0.038625
 30957/100000: episode: 3830, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000759, mae: 0.012753, mean_q: 0.022287
 30961/100000: episode: 3831, duration: 0.020s, episode steps: 4, steps per second: 198, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000883, mae: 0.013045, mean_q: 0.011678
 30968/100000: episode: 3832, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.001731, mae: 0.019836, mean_q: 0.024893
 30975/100000: episode: 3833, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001602, mae: 0.023046, mean_q: 0.034028
 30982/100000: episode: 3834, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001073, mae: 0.016315, mean_q: 0.025664
 30989/100000: episode: 3835, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001247, mae: 0.018385, mean_q: 0.025291
 30996/100000: episode: 3836, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001337, mae: 0.016729, mean_q: 0.028662
 31000/100000: episode: 3837, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001848, mae: 0.018150, mean_q: 0.027701
 31004/100000: episode: 3838, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000947, mae: 0.015181, mean_q: 0.024819
 31011/100000: episode: 3839, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001504, mae: 0.018961, mean_q: 0.034537
 31015/100000: episode: 3840, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000683, mae: 0.013574, mean_q: 0.027836
 31022/100000: episode: 3841, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001564, mae: 0.019066, mean_q: 0.037200
 31026/100000: episode: 3842, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002249, mae: 0.022593, mean_q: 0.033681
 31030/100000: episode: 3843, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001345, mae: 0.018788, mean_q: 0.036951
 31037/100000: episode: 3844, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001436, mae: 0.017482, mean_q: 0.031672
 31044/100000: episode: 3845, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001560, mae: 0.022712, mean_q: 0.053202
 31051/100000: episode: 3846, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001539, mae: 0.020625, mean_q: 0.024416
 31058/100000: episode: 3847, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000898, mae: 0.015024, mean_q: 0.014173
 31065/100000: episode: 3848, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001264, mae: 0.015584, mean_q: 0.021285
 31072/100000: episode: 3849, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000978, mae: 0.017154, mean_q: 0.028831
 31079/100000: episode: 3850, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001879, mae: 0.022576, mean_q: 0.034528
 31086/100000: episode: 3851, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001143, mae: 0.016956, mean_q: 0.025497
 31093/100000: episode: 3852, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.002585, mae: 0.020189, mean_q: 0.028212
 31100/100000: episode: 3853, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.003007, mae: 0.026875, mean_q: 0.047216
 31107/100000: episode: 3854, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.002121, mae: 0.025065, mean_q: 0.036805
 31114/100000: episode: 3855, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000459, mae: 0.013188, mean_q: 0.015267
 31118/100000: episode: 3856, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003791, mae: 0.027094, mean_q: 0.014060
 31122/100000: episode: 3857, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001887, mae: 0.020070, mean_q: 0.024471
 31129/100000: episode: 3858, duration: 0.036s, episode steps: 7, steps per second: 192, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001071, mae: 0.019217, mean_q: 0.030898
 31133/100000: episode: 3859, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001192, mae: 0.019873, mean_q: 0.037079
 31140/100000: episode: 3860, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.001651, mae: 0.024156, mean_q: 0.045457
 31147/100000: episode: 3861, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000920, mae: 0.016431, mean_q: 0.027574
 31151/100000: episode: 3862, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000891, mae: 0.016615, mean_q: 0.031492
 31158/100000: episode: 3863, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.002128, mae: 0.023355, mean_q: 0.046671
 31165/100000: episode: 3864, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001711, mae: 0.020359, mean_q: 0.043662
 31169/100000: episode: 3865, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002727, mae: 0.028201, mean_q: 0.046881
 31173/100000: episode: 3866, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001415, mae: 0.019865, mean_q: 0.027963
 31180/100000: episode: 3867, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000989, mae: 0.015982, mean_q: 0.020466
 31187/100000: episode: 3868, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001305, mae: 0.019656, mean_q: 0.030976
 31194/100000: episode: 3869, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001465, mae: 0.017440, mean_q: 0.027499
 31201/100000: episode: 3870, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.001923, mae: 0.022128, mean_q: 0.041854
 31208/100000: episode: 3871, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001045, mae: 0.015997, mean_q: 0.025997
 31215/100000: episode: 3872, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001468, mae: 0.021858, mean_q: 0.039758
 31219/100000: episode: 3873, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000959, mae: 0.018507, mean_q: 0.032551
 31226/100000: episode: 3874, duration: 0.037s, episode steps: 7, steps per second: 188, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000550, mae: 0.013051, mean_q: 0.022264
 31230/100000: episode: 3875, duration: 0.024s, episode steps: 4, steps per second: 166, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001105, mae: 0.015233, mean_q: 0.020949
 31237/100000: episode: 3876, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.001414, mae: 0.020769, mean_q: 0.026452
 31244/100000: episode: 3877, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001635, mae: 0.022626, mean_q: 0.033879
 31251/100000: episode: 3878, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.002482, mae: 0.027503, mean_q: 0.052908
 31255/100000: episode: 3879, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002679, mae: 0.027879, mean_q: 0.042489
 31262/100000: episode: 3880, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.002635, mae: 0.028126, mean_q: 0.041202
 31266/100000: episode: 3881, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001374, mae: 0.021272, mean_q: 0.024684
 31273/100000: episode: 3882, duration: 0.036s, episode steps: 7, steps per second: 192, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001245, mae: 0.018186, mean_q: 0.026049
 31280/100000: episode: 3883, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001043, mae: 0.019187, mean_q: 0.035681
 31284/100000: episode: 3884, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002292, mae: 0.026882, mean_q: 0.047988
 31291/100000: episode: 3885, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002646, mae: 0.027110, mean_q: 0.046784
 31298/100000: episode: 3886, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001499, mae: 0.018293, mean_q: 0.030178
 31305/100000: episode: 3887, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001657, mae: 0.020293, mean_q: 0.031966
 31312/100000: episode: 3888, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001987, mae: 0.026431, mean_q: 0.047800
 31319/100000: episode: 3889, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001016, mae: 0.018293, mean_q: 0.031274
 31326/100000: episode: 3890, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.001063, mae: 0.018175, mean_q: 0.023127
 31333/100000: episode: 3891, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.003284, mae: 0.023684, mean_q: 0.033833
 31337/100000: episode: 3892, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002689, mae: 0.031707, mean_q: 0.056158
[Info] 2-TH LEVEL FOUND: 0.06464376300573349, Considering 13/100 traces
 31344/100000: episode: 3893, duration: 0.707s, episode steps: 7, steps per second: 10, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.001522, mae: 0.023521, mean_q: 0.035572
 31349/100000: episode: 3894, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001224, mae: 0.020626, mean_q: 0.031613
 31354/100000: episode: 3895, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002139, mae: 0.020125, mean_q: 0.018667
 31359/100000: episode: 3896, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000526, mae: 0.013306, mean_q: 0.018767
 31364/100000: episode: 3897, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001569, mae: 0.021574, mean_q: 0.034053
 31369/100000: episode: 3898, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001411, mae: 0.021857, mean_q: 0.049432
 31374/100000: episode: 3899, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001550, mae: 0.020917, mean_q: 0.038226
 31379/100000: episode: 3900, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002217, mae: 0.022787, mean_q: 0.035314
 31384/100000: episode: 3901, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001295, mae: 0.018678, mean_q: 0.030247
 31389/100000: episode: 3902, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001361, mae: 0.019529, mean_q: 0.037721
 31394/100000: episode: 3903, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001290, mae: 0.020255, mean_q: 0.028022
 31399/100000: episode: 3904, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001027, mae: 0.016551, mean_q: 0.023840
 31404/100000: episode: 3905, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001186, mae: 0.019480, mean_q: 0.027351
 31409/100000: episode: 3906, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.003743, mae: 0.033023, mean_q: 0.054870
 31414/100000: episode: 3907, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001327, mae: 0.022520, mean_q: 0.042475
 31419/100000: episode: 3908, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002478, mae: 0.026216, mean_q: 0.060725
 31424/100000: episode: 3909, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001304, mae: 0.020094, mean_q: 0.032236
 31429/100000: episode: 3910, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002047, mae: 0.017196, mean_q: 0.017383
 31434/100000: episode: 3911, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000736, mae: 0.014936, mean_q: 0.022254
 31439/100000: episode: 3912, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001282, mae: 0.019741, mean_q: 0.027929
 31444/100000: episode: 3913, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002578, mae: 0.024895, mean_q: 0.039206
 31449/100000: episode: 3914, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001376, mae: 0.020657, mean_q: 0.030471
 31454/100000: episode: 3915, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001890, mae: 0.022324, mean_q: 0.035965
 31459/100000: episode: 3916, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002064, mae: 0.025852, mean_q: 0.049938
 31464/100000: episode: 3917, duration: 0.028s, episode steps: 5, steps per second: 182, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001356, mae: 0.017046, mean_q: 0.029183
 31469/100000: episode: 3918, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001145, mae: 0.018880, mean_q: 0.033279
 31474/100000: episode: 3919, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002281, mae: 0.021115, mean_q: 0.029368
[Info] FALSIFICATION!
 31478/100000: episode: 3920, duration: 0.176s, episode steps: 4, steps per second: 23, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001129, mae: 0.018222, mean_q: 0.028055
 31483/100000: episode: 3921, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001463, mae: 0.021791, mean_q: 0.040562
 31488/100000: episode: 3922, duration: 0.028s, episode steps: 5, steps per second: 176, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000872, mae: 0.017441, mean_q: 0.033804
 31493/100000: episode: 3923, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001332, mae: 0.020847, mean_q: 0.030867
 31498/100000: episode: 3924, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.003312, mae: 0.030452, mean_q: 0.059611
 31503/100000: episode: 3925, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001858, mae: 0.024794, mean_q: 0.042947
 31508/100000: episode: 3926, duration: 0.028s, episode steps: 5, steps per second: 176, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002372, mae: 0.027177, mean_q: 0.061490
 31513/100000: episode: 3927, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002052, mae: 0.024604, mean_q: 0.044381
 31518/100000: episode: 3928, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001908, mae: 0.022792, mean_q: 0.030212
 31523/100000: episode: 3929, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001538, mae: 0.023459, mean_q: 0.037763
 31528/100000: episode: 3930, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001963, mae: 0.025718, mean_q: 0.039009
 31533/100000: episode: 3931, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000748, mae: 0.016581, mean_q: 0.024576
 31538/100000: episode: 3932, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.004300, mae: 0.032761, mean_q: 0.044742
 31543/100000: episode: 3933, duration: 0.030s, episode steps: 5, steps per second: 168, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002097, mae: 0.027319, mean_q: 0.053759
 31548/100000: episode: 3934, duration: 0.034s, episode steps: 5, steps per second: 145, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.001543, mae: 0.022673, mean_q: 0.042005
 31553/100000: episode: 3935, duration: 0.031s, episode steps: 5, steps per second: 159, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001184, mae: 0.018953, mean_q: 0.030308
 31558/100000: episode: 3936, duration: 0.034s, episode steps: 5, steps per second: 148, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001549, mae: 0.020649, mean_q: 0.024755
 31563/100000: episode: 3937, duration: 0.039s, episode steps: 5, steps per second: 129, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001558, mae: 0.022878, mean_q: 0.023833
 31568/100000: episode: 3938, duration: 0.036s, episode steps: 5, steps per second: 137, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.003483, mae: 0.028383, mean_q: 0.032538
 31573/100000: episode: 3939, duration: 0.038s, episode steps: 5, steps per second: 132, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001101, mae: 0.021709, mean_q: 0.039338
 31578/100000: episode: 3940, duration: 0.033s, episode steps: 5, steps per second: 151, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.002789, mae: 0.031242, mean_q: 0.068998
 31583/100000: episode: 3941, duration: 0.033s, episode steps: 5, steps per second: 151, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001555, mae: 0.021808, mean_q: 0.039548
 31588/100000: episode: 3942, duration: 0.033s, episode steps: 5, steps per second: 153, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.003981, mae: 0.032924, mean_q: 0.053478
 31593/100000: episode: 3943, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001977, mae: 0.029383, mean_q: 0.043001
 31598/100000: episode: 3944, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001236, mae: 0.023140, mean_q: 0.040253
 31603/100000: episode: 3945, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002706, mae: 0.030634, mean_q: 0.048773
 31608/100000: episode: 3946, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002859, mae: 0.031564, mean_q: 0.059455
 31613/100000: episode: 3947, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001272, mae: 0.019418, mean_q: 0.032797
 31618/100000: episode: 3948, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001518, mae: 0.019654, mean_q: 0.033848
 31623/100000: episode: 3949, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001233, mae: 0.019001, mean_q: 0.026144
 31628/100000: episode: 3950, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001715, mae: 0.021423, mean_q: 0.030197
 31633/100000: episode: 3951, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002253, mae: 0.027426, mean_q: 0.048465
 31638/100000: episode: 3952, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001773, mae: 0.024445, mean_q: 0.036581
 31643/100000: episode: 3953, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002059, mae: 0.025047, mean_q: 0.034504
 31648/100000: episode: 3954, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001718, mae: 0.021412, mean_q: 0.040555
 31653/100000: episode: 3955, duration: 0.037s, episode steps: 5, steps per second: 134, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001156, mae: 0.017728, mean_q: 0.026683
[Info] FALSIFICATION!
 31657/100000: episode: 3956, duration: 0.308s, episode steps: 4, steps per second: 13, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001679, mae: 0.017899, mean_q: 0.019110
 31662/100000: episode: 3957, duration: 0.028s, episode steps: 5, steps per second: 182, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.003183, mae: 0.030406, mean_q: 0.041808
 31667/100000: episode: 3958, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002997, mae: 0.034842, mean_q: 0.067389
 31672/100000: episode: 3959, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002180, mae: 0.028230, mean_q: 0.052374
 31677/100000: episode: 3960, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001577, mae: 0.026490, mean_q: 0.045855
 31682/100000: episode: 3961, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001452, mae: 0.023181, mean_q: 0.040328
 31687/100000: episode: 3962, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.003950, mae: 0.032702, mean_q: 0.047586
 31692/100000: episode: 3963, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001851, mae: 0.023256, mean_q: 0.043503
 31697/100000: episode: 3964, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001936, mae: 0.024301, mean_q: 0.038783
 31702/100000: episode: 3965, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000808, mae: 0.017467, mean_q: 0.023371
 31707/100000: episode: 3966, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002756, mae: 0.026015, mean_q: 0.035645
[Info] FALSIFICATION!
 31711/100000: episode: 3967, duration: 0.291s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001754, mae: 0.019711, mean_q: 0.024485
 31716/100000: episode: 3968, duration: 0.033s, episode steps: 5, steps per second: 150, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000797, mae: 0.016101, mean_q: 0.026927
 31721/100000: episode: 3969, duration: 0.036s, episode steps: 5, steps per second: 138, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002624, mae: 0.029791, mean_q: 0.041766
 31726/100000: episode: 3970, duration: 0.033s, episode steps: 5, steps per second: 150, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001878, mae: 0.024904, mean_q: 0.041441
 31731/100000: episode: 3971, duration: 0.036s, episode steps: 5, steps per second: 140, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001444, mae: 0.022605, mean_q: 0.029674
 31736/100000: episode: 3972, duration: 0.032s, episode steps: 5, steps per second: 155, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002146, mae: 0.025107, mean_q: 0.037896
 31741/100000: episode: 3973, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001904, mae: 0.025244, mean_q: 0.039691
 31746/100000: episode: 3974, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002801, mae: 0.031954, mean_q: 0.054807
 31751/100000: episode: 3975, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001970, mae: 0.027510, mean_q: 0.041367
 31756/100000: episode: 3976, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001317, mae: 0.021600, mean_q: 0.042995
 31761/100000: episode: 3977, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001235, mae: 0.024166, mean_q: 0.040898
 31766/100000: episode: 3978, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001469, mae: 0.021807, mean_q: 0.046779
 31771/100000: episode: 3979, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002251, mae: 0.022714, mean_q: 0.038121
[Info] Complete ISplit Iteration
[Info] Levels: [0.033738133, 0.06464376, 1.1006643]
[Info] Cond. Prob: [0.12, 0.13, 0.04]
[Info] Error Prob: 0.000624

 31776/100000: episode: 3980, duration: 0.849s, episode steps: 5, steps per second: 6, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001884, mae: 0.021296, mean_q: 0.041365
 31786/100000: episode: 3981, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002908, mae: 0.031554, mean_q: 0.048387
 31796/100000: episode: 3982, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002794, mae: 0.031365, mean_q: 0.042150
 31806/100000: episode: 3983, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001511, mae: 0.023422, mean_q: 0.035604
 31816/100000: episode: 3984, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001204, mae: 0.019789, mean_q: 0.031547
 31826/100000: episode: 3985, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001413, mae: 0.023363, mean_q: 0.034129
 31836/100000: episode: 3986, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.001169, mae: 0.020735, mean_q: 0.036404
 31846/100000: episode: 3987, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002306, mae: 0.028695, mean_q: 0.053507
 31856/100000: episode: 3988, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002314, mae: 0.027731, mean_q: 0.052631
 31866/100000: episode: 3989, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001858, mae: 0.026121, mean_q: 0.036076
 31876/100000: episode: 3990, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001071, mae: 0.019422, mean_q: 0.030660
 31886/100000: episode: 3991, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001095, mae: 0.022695, mean_q: 0.034249
 31896/100000: episode: 3992, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002797, mae: 0.027100, mean_q: 0.043624
 31906/100000: episode: 3993, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.002508, mae: 0.030420, mean_q: 0.044660
 31916/100000: episode: 3994, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001562, mae: 0.021207, mean_q: 0.023148
 31926/100000: episode: 3995, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001713, mae: 0.022280, mean_q: 0.035981
 31936/100000: episode: 3996, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002697, mae: 0.031354, mean_q: 0.056370
 31946/100000: episode: 3997, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001649, mae: 0.023185, mean_q: 0.040258
 31956/100000: episode: 3998, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001344, mae: 0.021143, mean_q: 0.036999
 31966/100000: episode: 3999, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002829, mae: 0.028679, mean_q: 0.042162
 31976/100000: episode: 4000, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.001607, mae: 0.025731, mean_q: 0.050541
 31986/100000: episode: 4001, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001931, mae: 0.025682, mean_q: 0.043858
 31996/100000: episode: 4002, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001937, mae: 0.025101, mean_q: 0.044536
 32006/100000: episode: 4003, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001869, mae: 0.025033, mean_q: 0.036146
 32016/100000: episode: 4004, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001714, mae: 0.023658, mean_q: 0.028521
 32026/100000: episode: 4005, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.002254, mae: 0.026612, mean_q: 0.040822
 32036/100000: episode: 4006, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001626, mae: 0.023732, mean_q: 0.042739
 32046/100000: episode: 4007, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002965, mae: 0.029401, mean_q: 0.051084
 32056/100000: episode: 4008, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002307, mae: 0.026861, mean_q: 0.041230
 32066/100000: episode: 4009, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001721, mae: 0.023242, mean_q: 0.038866
 32076/100000: episode: 4010, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.002001, mae: 0.026395, mean_q: 0.044120
 32086/100000: episode: 4011, duration: 0.072s, episode steps: 10, steps per second: 138, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001822, mae: 0.024587, mean_q: 0.040387
 32096/100000: episode: 4012, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002029, mae: 0.024725, mean_q: 0.044493
 32106/100000: episode: 4013, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001466, mae: 0.021578, mean_q: 0.033353
 32116/100000: episode: 4014, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002016, mae: 0.025743, mean_q: 0.038211
 32126/100000: episode: 4015, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002434, mae: 0.026146, mean_q: 0.039536
 32136/100000: episode: 4016, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002181, mae: 0.029404, mean_q: 0.054650
 32146/100000: episode: 4017, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001995, mae: 0.024861, mean_q: 0.048399
 32156/100000: episode: 4018, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001493, mae: 0.021831, mean_q: 0.038739
 32166/100000: episode: 4019, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.003546, mae: 0.032811, mean_q: 0.053993
 32176/100000: episode: 4020, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001629, mae: 0.021019, mean_q: 0.031184
 32186/100000: episode: 4021, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002658, mae: 0.030900, mean_q: 0.049968
 32196/100000: episode: 4022, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001682, mae: 0.023779, mean_q: 0.035439
 32206/100000: episode: 4023, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001842, mae: 0.022674, mean_q: 0.037345
 32216/100000: episode: 4024, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.003920, mae: 0.034951, mean_q: 0.056204
 32226/100000: episode: 4025, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002598, mae: 0.030760, mean_q: 0.050925
 32236/100000: episode: 4026, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001490, mae: 0.020611, mean_q: 0.029311
 32246/100000: episode: 4027, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002510, mae: 0.026925, mean_q: 0.045908
 32256/100000: episode: 4028, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001552, mae: 0.024274, mean_q: 0.041241
 32266/100000: episode: 4029, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001116, mae: 0.020963, mean_q: 0.037987
 32276/100000: episode: 4030, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001885, mae: 0.022868, mean_q: 0.038431
 32286/100000: episode: 4031, duration: 0.064s, episode steps: 10, steps per second: 155, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002501, mae: 0.028145, mean_q: 0.045093
 32296/100000: episode: 4032, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002009, mae: 0.025328, mean_q: 0.043707
 32306/100000: episode: 4033, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001769, mae: 0.023179, mean_q: 0.029583
 32316/100000: episode: 4034, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001375, mae: 0.019957, mean_q: 0.028697
 32326/100000: episode: 4035, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002652, mae: 0.032116, mean_q: 0.056844
 32336/100000: episode: 4036, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001505, mae: 0.023055, mean_q: 0.046764
 32346/100000: episode: 4037, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001742, mae: 0.023906, mean_q: 0.043232
 32356/100000: episode: 4038, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002061, mae: 0.022947, mean_q: 0.024729
 32366/100000: episode: 4039, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001377, mae: 0.018291, mean_q: 0.030240
 32376/100000: episode: 4040, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000926, mae: 0.015573, mean_q: 0.024636
 32386/100000: episode: 4041, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001487, mae: 0.024357, mean_q: 0.038017
 32396/100000: episode: 4042, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001739, mae: 0.022512, mean_q: 0.036075
 32406/100000: episode: 4043, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001891, mae: 0.021520, mean_q: 0.028262
 32416/100000: episode: 4044, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001245, mae: 0.020296, mean_q: 0.033076
 32426/100000: episode: 4045, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001613, mae: 0.020952, mean_q: 0.029489
 32436/100000: episode: 4046, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.001424, mae: 0.019267, mean_q: 0.029256
 32446/100000: episode: 4047, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001955, mae: 0.024373, mean_q: 0.044104
 32456/100000: episode: 4048, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001073, mae: 0.018484, mean_q: 0.036071
 32466/100000: episode: 4049, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000947, mae: 0.016175, mean_q: 0.024876
 32476/100000: episode: 4050, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000967, mae: 0.017416, mean_q: 0.026532
 32486/100000: episode: 4051, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002337, mae: 0.025691, mean_q: 0.037232
 32496/100000: episode: 4052, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001172, mae: 0.019109, mean_q: 0.031164
 32506/100000: episode: 4053, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001131, mae: 0.020277, mean_q: 0.038769
 32516/100000: episode: 4054, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002096, mae: 0.026094, mean_q: 0.044967
 32526/100000: episode: 4055, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.001151, mae: 0.018657, mean_q: 0.027414
 32536/100000: episode: 4056, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001291, mae: 0.019374, mean_q: 0.030817
 32546/100000: episode: 4057, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001439, mae: 0.019982, mean_q: 0.032685
 32556/100000: episode: 4058, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001207, mae: 0.019213, mean_q: 0.026093
 32566/100000: episode: 4059, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001709, mae: 0.019279, mean_q: 0.022755
 32576/100000: episode: 4060, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.001142, mae: 0.015715, mean_q: 0.018658
 32586/100000: episode: 4061, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001572, mae: 0.021419, mean_q: 0.033868
 32596/100000: episode: 4062, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000916, mae: 0.017617, mean_q: 0.029289
 32606/100000: episode: 4063, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001454, mae: 0.018832, mean_q: 0.026190
 32616/100000: episode: 4064, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001007, mae: 0.016761, mean_q: 0.026697
 32626/100000: episode: 4065, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001094, mae: 0.018263, mean_q: 0.035134
 32636/100000: episode: 4066, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001102, mae: 0.017949, mean_q: 0.031182
 32646/100000: episode: 4067, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000526, mae: 0.013652, mean_q: 0.023586
 32656/100000: episode: 4068, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000840, mae: 0.015195, mean_q: 0.025179
 32666/100000: episode: 4069, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000919, mae: 0.015275, mean_q: 0.022041
 32676/100000: episode: 4070, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000997, mae: 0.015353, mean_q: 0.023463
 32686/100000: episode: 4071, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001173, mae: 0.017330, mean_q: 0.024476
 32696/100000: episode: 4072, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000990, mae: 0.015430, mean_q: 0.026374
 32706/100000: episode: 4073, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000451, mae: 0.012751, mean_q: 0.024591
 32716/100000: episode: 4074, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000882, mae: 0.016061, mean_q: 0.026447
 32726/100000: episode: 4075, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001031, mae: 0.014340, mean_q: 0.021649
 32736/100000: episode: 4076, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000608, mae: 0.013347, mean_q: 0.019478
 32746/100000: episode: 4077, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000486, mae: 0.011246, mean_q: 0.018947
 32756/100000: episode: 4078, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000864, mae: 0.014111, mean_q: 0.022892
 32766/100000: episode: 4079, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000639, mae: 0.013296, mean_q: 0.020095
[Info] 1-TH LEVEL FOUND: 0.046566568315029144, Considering 11/100 traces
 32776/100000: episode: 4080, duration: 0.706s, episode steps: 10, steps per second: 14, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000581, mae: 0.014991, mean_q: 0.022790
 32783/100000: episode: 4081, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000800, mae: 0.014227, mean_q: 0.026421
 32790/100000: episode: 4082, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000783, mae: 0.012309, mean_q: 0.020957
 32797/100000: episode: 4083, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000588, mae: 0.013208, mean_q: 0.022952
 32804/100000: episode: 4084, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001521, mae: 0.018491, mean_q: 0.028974
 32811/100000: episode: 4085, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000415, mae: 0.011093, mean_q: 0.011694
 32815/100000: episode: 4086, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000166, mae: 0.008330, mean_q: 0.005513
 32822/100000: episode: 4087, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000483, mae: 0.013057, mean_q: 0.016716
 32829/100000: episode: 4088, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000577, mae: 0.013537, mean_q: 0.017423
 32836/100000: episode: 4089, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000515, mae: 0.013678, mean_q: 0.021396
 32843/100000: episode: 4090, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001092, mae: 0.021420, mean_q: 0.028859
 32850/100000: episode: 4091, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000326, mae: 0.013654, mean_q: 0.021796
 32857/100000: episode: 4092, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000972, mae: 0.017645, mean_q: 0.027616
 32864/100000: episode: 4093, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000647, mae: 0.012341, mean_q: 0.019516
 32871/100000: episode: 4094, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000690, mae: 0.014193, mean_q: 0.022448
 32878/100000: episode: 4095, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001375, mae: 0.013777, mean_q: 0.015434
 32885/100000: episode: 4096, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000871, mae: 0.016596, mean_q: 0.027116
 32892/100000: episode: 4097, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000363, mae: 0.012721, mean_q: 0.018711
 32899/100000: episode: 4098, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000445, mae: 0.012358, mean_q: 0.021522
 32906/100000: episode: 4099, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000886, mae: 0.015145, mean_q: 0.018127
 32913/100000: episode: 4100, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000880, mae: 0.016051, mean_q: 0.016839
 32920/100000: episode: 4101, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000462, mae: 0.012359, mean_q: 0.019884
 32927/100000: episode: 4102, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000462, mae: 0.012736, mean_q: 0.022403
 32934/100000: episode: 4103, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000639, mae: 0.011663, mean_q: 0.014248
 32941/100000: episode: 4104, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000529, mae: 0.013844, mean_q: 0.022769
 32948/100000: episode: 4105, duration: 0.047s, episode steps: 7, steps per second: 150, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000568, mae: 0.014792, mean_q: 0.021081
 32955/100000: episode: 4106, duration: 0.048s, episode steps: 7, steps per second: 146, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000442, mae: 0.012596, mean_q: 0.020418
 32962/100000: episode: 4107, duration: 0.049s, episode steps: 7, steps per second: 143, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000427, mae: 0.014397, mean_q: 0.020238
 32969/100000: episode: 4108, duration: 0.046s, episode steps: 7, steps per second: 154, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001213, mae: 0.019207, mean_q: 0.030005
 32973/100000: episode: 4109, duration: 0.031s, episode steps: 4, steps per second: 131, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000273, mae: 0.009768, mean_q: 0.012822
 32980/100000: episode: 4110, duration: 0.045s, episode steps: 7, steps per second: 156, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000650, mae: 0.013900, mean_q: 0.017210
 32987/100000: episode: 4111, duration: 0.043s, episode steps: 7, steps per second: 162, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000310, mae: 0.010705, mean_q: 0.014113
 32994/100000: episode: 4112, duration: 0.041s, episode steps: 7, steps per second: 169, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000771, mae: 0.016569, mean_q: 0.026352
 33001/100000: episode: 4113, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000518, mae: 0.012173, mean_q: 0.018249
 33008/100000: episode: 4114, duration: 0.035s, episode steps: 7, steps per second: 197, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001008, mae: 0.018509, mean_q: 0.028192
 33012/100000: episode: 4115, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001002, mae: 0.016434, mean_q: 0.024601
 33019/100000: episode: 4116, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001131, mae: 0.017089, mean_q: 0.026398
 33026/100000: episode: 4117, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001584, mae: 0.015796, mean_q: 0.019686
 33033/100000: episode: 4118, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000824, mae: 0.015000, mean_q: 0.018767
 33040/100000: episode: 4119, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000697, mae: 0.014303, mean_q: 0.021846
 33044/100000: episode: 4120, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000532, mae: 0.014713, mean_q: 0.024827
 33051/100000: episode: 4121, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001397, mae: 0.018867, mean_q: 0.030802
 33058/100000: episode: 4122, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000407, mae: 0.012423, mean_q: 0.018620
 33065/100000: episode: 4123, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000634, mae: 0.012823, mean_q: 0.021651
 33072/100000: episode: 4124, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000640, mae: 0.015678, mean_q: 0.023667
 33076/100000: episode: 4125, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000775, mae: 0.016025, mean_q: 0.022328
 33083/100000: episode: 4126, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000490, mae: 0.012666, mean_q: 0.012596
 33090/100000: episode: 4127, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.001192, mae: 0.017172, mean_q: 0.025462
 33094/100000: episode: 4128, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001638, mae: 0.022966, mean_q: 0.035366
 33101/100000: episode: 4129, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000751, mae: 0.015311, mean_q: 0.028115
 33108/100000: episode: 4130, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000455, mae: 0.013952, mean_q: 0.024200
 33115/100000: episode: 4131, duration: 0.040s, episode steps: 7, steps per second: 177, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000346, mae: 0.012586, mean_q: 0.021763
 33122/100000: episode: 4132, duration: 0.044s, episode steps: 7, steps per second: 158, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000424, mae: 0.013186, mean_q: 0.016784
 33126/100000: episode: 4133, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001473, mae: 0.021312, mean_q: 0.030693
 33133/100000: episode: 4134, duration: 0.048s, episode steps: 7, steps per second: 146, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000544, mae: 0.013855, mean_q: 0.013138
 33140/100000: episode: 4135, duration: 0.046s, episode steps: 7, steps per second: 154, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000543, mae: 0.014703, mean_q: 0.017402
 33147/100000: episode: 4136, duration: 0.042s, episode steps: 7, steps per second: 166, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000436, mae: 0.011529, mean_q: 0.015959
 33154/100000: episode: 4137, duration: 0.050s, episode steps: 7, steps per second: 139, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000560, mae: 0.013283, mean_q: 0.016836
 33161/100000: episode: 4138, duration: 0.044s, episode steps: 7, steps per second: 160, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000355, mae: 0.012509, mean_q: 0.021295
 33168/100000: episode: 4139, duration: 0.045s, episode steps: 7, steps per second: 156, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000437, mae: 0.014812, mean_q: 0.024927
 33175/100000: episode: 4140, duration: 0.039s, episode steps: 7, steps per second: 180, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000555, mae: 0.013074, mean_q: 0.019233
 33182/100000: episode: 4141, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001527, mae: 0.020077, mean_q: 0.029851
 33189/100000: episode: 4142, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000479, mae: 0.013506, mean_q: 0.023150
 33196/100000: episode: 4143, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001663, mae: 0.021220, mean_q: 0.031387
 33203/100000: episode: 4144, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000410, mae: 0.012663, mean_q: 0.018005
 33207/100000: episode: 4145, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000483, mae: 0.014537, mean_q: 0.022761
 33214/100000: episode: 4146, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001062, mae: 0.017967, mean_q: 0.027118
[Info] FALSIFICATION!
 33220/100000: episode: 4147, duration: 0.177s, episode steps: 6, steps per second: 34, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000934, mae: 0.015305, mean_q: 0.023854
 33224/100000: episode: 4148, duration: 0.023s, episode steps: 4, steps per second: 178, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000943, mae: 0.017558, mean_q: 0.023663
 33231/100000: episode: 4149, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000544, mae: 0.012015, mean_q: 0.016080
 33235/100000: episode: 4150, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000615, mae: 0.013977, mean_q: 0.014510
 33242/100000: episode: 4151, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000260, mae: 0.009746, mean_q: 0.014396
 33249/100000: episode: 4152, duration: 0.042s, episode steps: 7, steps per second: 167, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000720, mae: 0.014598, mean_q: 0.021605
 33253/100000: episode: 4153, duration: 0.033s, episode steps: 4, steps per second: 120, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000592, mae: 0.016491, mean_q: 0.030052
 33257/100000: episode: 4154, duration: 0.031s, episode steps: 4, steps per second: 128, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000520, mae: 0.014655, mean_q: 0.022520
 33264/100000: episode: 4155, duration: 0.047s, episode steps: 7, steps per second: 149, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000795, mae: 0.018920, mean_q: 0.031462
 33271/100000: episode: 4156, duration: 0.044s, episode steps: 7, steps per second: 158, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000544, mae: 0.016442, mean_q: 0.031912
 33278/100000: episode: 4157, duration: 0.044s, episode steps: 7, steps per second: 158, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000996, mae: 0.019495, mean_q: 0.035483
 33285/100000: episode: 4158, duration: 0.045s, episode steps: 7, steps per second: 154, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001386, mae: 0.017975, mean_q: 0.030650
 33289/100000: episode: 4159, duration: 0.025s, episode steps: 4, steps per second: 163, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000481, mae: 0.015473, mean_q: 0.023048
 33296/100000: episode: 4160, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001009, mae: 0.016661, mean_q: 0.030794
 33300/100000: episode: 4161, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000901, mae: 0.018822, mean_q: 0.030242
 33307/100000: episode: 4162, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000412, mae: 0.014163, mean_q: 0.016839
 33311/100000: episode: 4163, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001067, mae: 0.018833, mean_q: 0.023885
[Info] FALSIFICATION!
 33317/100000: episode: 4164, duration: 0.273s, episode steps: 6, steps per second: 22, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000437, mae: 0.013688, mean_q: 0.019063
 33324/100000: episode: 4165, duration: 0.047s, episode steps: 7, steps per second: 149, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000894, mae: 0.017400, mean_q: 0.024783
 33331/100000: episode: 4166, duration: 0.045s, episode steps: 7, steps per second: 156, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000737, mae: 0.015481, mean_q: 0.025182
 33338/100000: episode: 4167, duration: 0.046s, episode steps: 7, steps per second: 151, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001665, mae: 0.020075, mean_q: 0.028794
 33345/100000: episode: 4168, duration: 0.047s, episode steps: 7, steps per second: 149, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000845, mae: 0.017097, mean_q: 0.029368
[Info] Complete ISplit Iteration
[Info] Levels: [0.04656657, 0.92710763]
[Info] Cond. Prob: [0.11, 0.02]
[Info] Error Prob: 0.0022

 33352/100000: episode: 4169, duration: 0.896s, episode steps: 7, steps per second: 8, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000979, mae: 0.017405, mean_q: 0.029040
 33362/100000: episode: 4170, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000687, mae: 0.016069, mean_q: 0.019002
 33372/100000: episode: 4171, duration: 0.060s, episode steps: 10, steps per second: 165, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001488, mae: 0.017832, mean_q: 0.023056
 33382/100000: episode: 4172, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000559, mae: 0.016461, mean_q: 0.023924
 33392/100000: episode: 4173, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000924, mae: 0.014431, mean_q: 0.025000
 33402/100000: episode: 4174, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000943, mae: 0.017307, mean_q: 0.026495
 33412/100000: episode: 4175, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001177, mae: 0.018358, mean_q: 0.025462
 33422/100000: episode: 4176, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000756, mae: 0.016406, mean_q: 0.025716
 33432/100000: episode: 4177, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001094, mae: 0.018513, mean_q: 0.029158
 33442/100000: episode: 4178, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000660, mae: 0.016527, mean_q: 0.024337
 33452/100000: episode: 4179, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000465, mae: 0.012413, mean_q: 0.016781
 33462/100000: episode: 4180, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000628, mae: 0.014011, mean_q: 0.017383
 33472/100000: episode: 4181, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000515, mae: 0.015499, mean_q: 0.023714
 33482/100000: episode: 4182, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000711, mae: 0.017227, mean_q: 0.028431
 33492/100000: episode: 4183, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001319, mae: 0.018226, mean_q: 0.021389
 33502/100000: episode: 4184, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000635, mae: 0.015650, mean_q: 0.023581
 33512/100000: episode: 4185, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000442, mae: 0.014732, mean_q: 0.023280
 33522/100000: episode: 4186, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000624, mae: 0.015953, mean_q: 0.024938
 33532/100000: episode: 4187, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000431, mae: 0.012427, mean_q: 0.017604
 33542/100000: episode: 4188, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000367, mae: 0.013510, mean_q: 0.017197
 33552/100000: episode: 4189, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000821, mae: 0.015758, mean_q: 0.025502
 33562/100000: episode: 4190, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000702, mae: 0.016942, mean_q: 0.025016
 33572/100000: episode: 4191, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000765, mae: 0.017178, mean_q: 0.028862
 33582/100000: episode: 4192, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000756, mae: 0.016340, mean_q: 0.028123
 33592/100000: episode: 4193, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000601, mae: 0.014555, mean_q: 0.023823
 33602/100000: episode: 4194, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000786, mae: 0.016052, mean_q: 0.024326
 33612/100000: episode: 4195, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000594, mae: 0.014733, mean_q: 0.019497
 33622/100000: episode: 4196, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001215, mae: 0.018353, mean_q: 0.025745
 33632/100000: episode: 4197, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001228, mae: 0.016771, mean_q: 0.029374
 33642/100000: episode: 4198, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000651, mae: 0.015383, mean_q: 0.017368
 33652/100000: episode: 4199, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.001068, mae: 0.016757, mean_q: 0.023491
 33662/100000: episode: 4200, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001073, mae: 0.020472, mean_q: 0.042090
 33672/100000: episode: 4201, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000935, mae: 0.018094, mean_q: 0.030089
 33682/100000: episode: 4202, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000995, mae: 0.017530, mean_q: 0.026764
 33692/100000: episode: 4203, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000575, mae: 0.012971, mean_q: 0.016559
 33702/100000: episode: 4204, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000685, mae: 0.015890, mean_q: 0.025642
 33712/100000: episode: 4205, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000731, mae: 0.017032, mean_q: 0.029682
 33722/100000: episode: 4206, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000758, mae: 0.016653, mean_q: 0.024481
 33732/100000: episode: 4207, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001554, mae: 0.019210, mean_q: 0.022467
 33742/100000: episode: 4208, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000399, mae: 0.013076, mean_q: 0.022407
 33752/100000: episode: 4209, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000977, mae: 0.017985, mean_q: 0.025956
 33762/100000: episode: 4210, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001079, mae: 0.017868, mean_q: 0.026887
 33772/100000: episode: 4211, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000701, mae: 0.015272, mean_q: 0.022721
 33782/100000: episode: 4212, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000603, mae: 0.014672, mean_q: 0.023208
 33792/100000: episode: 4213, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001520, mae: 0.018053, mean_q: 0.019762
 33802/100000: episode: 4214, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001095, mae: 0.018060, mean_q: 0.028748
 33812/100000: episode: 4215, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000896, mae: 0.016515, mean_q: 0.024911
 33822/100000: episode: 4216, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000744, mae: 0.014920, mean_q: 0.013394
 33832/100000: episode: 4217, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000918, mae: 0.016576, mean_q: 0.022920
 33842/100000: episode: 4218, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000443, mae: 0.015115, mean_q: 0.025058
 33852/100000: episode: 4219, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000758, mae: 0.016645, mean_q: 0.023745
 33862/100000: episode: 4220, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000834, mae: 0.016028, mean_q: 0.026000
 33872/100000: episode: 4221, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001305, mae: 0.017794, mean_q: 0.027988
 33882/100000: episode: 4222, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000930, mae: 0.017101, mean_q: 0.028997
 33892/100000: episode: 4223, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000399, mae: 0.012402, mean_q: 0.013745
 33902/100000: episode: 4224, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001311, mae: 0.016488, mean_q: 0.019043
 33912/100000: episode: 4225, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000854, mae: 0.016358, mean_q: 0.026761
 33922/100000: episode: 4226, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000733, mae: 0.014052, mean_q: 0.023504
 33932/100000: episode: 4227, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000430, mae: 0.013324, mean_q: 0.017329
 33942/100000: episode: 4228, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000598, mae: 0.014255, mean_q: 0.019957
 33952/100000: episode: 4229, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000688, mae: 0.016736, mean_q: 0.026927
 33962/100000: episode: 4230, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000481, mae: 0.014140, mean_q: 0.023549
 33972/100000: episode: 4231, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000798, mae: 0.014289, mean_q: 0.022009
 33982/100000: episode: 4232, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001011, mae: 0.016334, mean_q: 0.021485
 33992/100000: episode: 4233, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000972, mae: 0.017480, mean_q: 0.029938
 34002/100000: episode: 4234, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001316, mae: 0.015731, mean_q: 0.023842
 34012/100000: episode: 4235, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000539, mae: 0.014362, mean_q: 0.020683
 34022/100000: episode: 4236, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001324, mae: 0.017728, mean_q: 0.028231
 34032/100000: episode: 4237, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000908, mae: 0.016165, mean_q: 0.021099
 34042/100000: episode: 4238, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000836, mae: 0.014117, mean_q: 0.023667
 34052/100000: episode: 4239, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001179, mae: 0.018107, mean_q: 0.028300
 34062/100000: episode: 4240, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000902, mae: 0.016118, mean_q: 0.027516
 34072/100000: episode: 4241, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001086, mae: 0.017564, mean_q: 0.026159
 34082/100000: episode: 4242, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000719, mae: 0.014691, mean_q: 0.019272
 34092/100000: episode: 4243, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001034, mae: 0.016530, mean_q: 0.026169
 34102/100000: episode: 4244, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000537, mae: 0.013202, mean_q: 0.018358
 34112/100000: episode: 4245, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000728, mae: 0.013493, mean_q: 0.019890
 34122/100000: episode: 4246, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000661, mae: 0.014813, mean_q: 0.021445
 34132/100000: episode: 4247, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000757, mae: 0.015289, mean_q: 0.021239
 34142/100000: episode: 4248, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000408, mae: 0.013121, mean_q: 0.023094
 34152/100000: episode: 4249, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000878, mae: 0.016819, mean_q: 0.033266
 34162/100000: episode: 4250, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000511, mae: 0.013838, mean_q: 0.019533
 34172/100000: episode: 4251, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000562, mae: 0.013561, mean_q: 0.021273
 34182/100000: episode: 4252, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000694, mae: 0.014072, mean_q: 0.019621
 34192/100000: episode: 4253, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000443, mae: 0.012646, mean_q: 0.022745
 34202/100000: episode: 4254, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000935, mae: 0.014696, mean_q: 0.031763
 34212/100000: episode: 4255, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002021, mae: 0.021140, mean_q: 0.030758
 34222/100000: episode: 4256, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000679, mae: 0.016993, mean_q: 0.011148
 34232/100000: episode: 4257, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001595, mae: 0.017819, mean_q: 0.020013
 34242/100000: episode: 4258, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000381, mae: 0.015246, mean_q: 0.027852
 34252/100000: episode: 4259, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001311, mae: 0.018641, mean_q: 0.029170
 34262/100000: episode: 4260, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000645, mae: 0.014289, mean_q: 0.022975
 34272/100000: episode: 4261, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000577, mae: 0.012965, mean_q: 0.014126
 34282/100000: episode: 4262, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000836, mae: 0.015335, mean_q: 0.020278
 34292/100000: episode: 4263, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000664, mae: 0.014143, mean_q: 0.020238
 34302/100000: episode: 4264, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001336, mae: 0.018457, mean_q: 0.027889
 34312/100000: episode: 4265, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000652, mae: 0.016041, mean_q: 0.027159
 34322/100000: episode: 4266, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000835, mae: 0.014213, mean_q: 0.019429
 34332/100000: episode: 4267, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000593, mae: 0.013163, mean_q: 0.017775
 34342/100000: episode: 4268, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000610, mae: 0.014240, mean_q: 0.019330
[Info] 1-TH LEVEL FOUND: 0.03640895336866379, Considering 14/100 traces
 34352/100000: episode: 4269, duration: 0.763s, episode steps: 10, steps per second: 13, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000668, mae: 0.016229, mean_q: 0.024023
 34356/100000: episode: 4270, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000240, mae: 0.010519, mean_q: 0.021923
 34360/100000: episode: 4271, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000681, mae: 0.012330, mean_q: 0.025113
 34362/100000: episode: 4272, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000251, mae: 0.009384, mean_q: 0.014197
 34364/100000: episode: 4273, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000305, mae: 0.011204, mean_q: 0.014081
 34368/100000: episode: 4274, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000462, mae: 0.015441, mean_q: 0.025800
 34375/100000: episode: 4275, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001239, mae: 0.015428, mean_q: 0.024617
 34382/100000: episode: 4276, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001279, mae: 0.016967, mean_q: 0.033325
 34386/100000: episode: 4277, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001091, mae: 0.015063, mean_q: 0.022859
 34388/100000: episode: 4278, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000306, mae: 0.012708, mean_q: 0.013801
 34390/100000: episode: 4279, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004103, mae: 0.036949, mean_q: 0.055735
 34392/100000: episode: 4280, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000313, mae: 0.011015, mean_q: 0.011417
 34394/100000: episode: 4281, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001380, mae: 0.019896, mean_q: 0.027053
 34398/100000: episode: 4282, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000558, mae: 0.017601, mean_q: 0.023012
 34402/100000: episode: 4283, duration: 0.024s, episode steps: 4, steps per second: 167, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001068, mae: 0.019504, mean_q: 0.036148
 34409/100000: episode: 4284, duration: 0.038s, episode steps: 7, steps per second: 184, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000782, mae: 0.016151, mean_q: 0.027961
 34413/100000: episode: 4285, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000679, mae: 0.011126, mean_q: 0.019236
 34415/100000: episode: 4286, duration: 0.014s, episode steps: 2, steps per second: 143, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001523, mae: 0.017787, mean_q: 0.027298
 34419/100000: episode: 4287, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000375, mae: 0.012772, mean_q: 0.020906
 34423/100000: episode: 4288, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001116, mae: 0.018419, mean_q: 0.034608
 34430/100000: episode: 4289, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000446, mae: 0.012681, mean_q: 0.021370
 34437/100000: episode: 4290, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000482, mae: 0.011900, mean_q: 0.021257
 34444/100000: episode: 4291, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000939, mae: 0.014918, mean_q: 0.023416
 34451/100000: episode: 4292, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001135, mae: 0.015659, mean_q: 0.020065
 34458/100000: episode: 4293, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000616, mae: 0.015226, mean_q: 0.014591
 34460/100000: episode: 4294, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000465, mae: 0.018547, mean_q: 0.018856
 34462/100000: episode: 4295, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002309, mae: 0.019739, mean_q: 0.020118
 34466/100000: episode: 4296, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000590, mae: 0.014049, mean_q: 0.023475
 34468/100000: episode: 4297, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001191, mae: 0.019858, mean_q: 0.029565
 34470/100000: episode: 4298, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001290, mae: 0.023446, mean_q: 0.038111
 34474/100000: episode: 4299, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001301, mae: 0.024417, mean_q: 0.043319
 34481/100000: episode: 4300, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000644, mae: 0.011774, mean_q: 0.020179
 34485/100000: episode: 4301, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000795, mae: 0.016677, mean_q: 0.023896
 34489/100000: episode: 4302, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000254, mae: 0.013430, mean_q: 0.007843
 34496/100000: episode: 4303, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000728, mae: 0.015398, mean_q: 0.013490
 34498/100000: episode: 4304, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000208, mae: 0.009737, mean_q: 0.007559
 34502/100000: episode: 4305, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000792, mae: 0.013872, mean_q: 0.019965
 34509/100000: episode: 4306, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000364, mae: 0.013383, mean_q: 0.019640
 34513/100000: episode: 4307, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000908, mae: 0.018396, mean_q: 0.027469
 34517/100000: episode: 4308, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000315, mae: 0.013476, mean_q: 0.020591
 34521/100000: episode: 4309, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000507, mae: 0.012138, mean_q: 0.013477
 34525/100000: episode: 4310, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001079, mae: 0.015041, mean_q: 0.019096
 34527/100000: episode: 4311, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001279, mae: 0.020227, mean_q: 0.031487
 34531/100000: episode: 4312, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002833, mae: 0.022336, mean_q: 0.032086
 34533/100000: episode: 4313, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000719, mae: 0.012633, mean_q: 0.018426
 34535/100000: episode: 4314, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000514, mae: 0.014661, mean_q: 0.026462
 34542/100000: episode: 4315, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001129, mae: 0.016304, mean_q: 0.027367
 34546/100000: episode: 4316, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000234, mae: 0.011129, mean_q: 0.014331
 34548/100000: episode: 4317, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000833, mae: 0.016844, mean_q: 0.026615
 34550/100000: episode: 4318, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001581, mae: 0.021148, mean_q: 0.020494
 34557/100000: episode: 4319, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000388, mae: 0.013486, mean_q: 0.012761
 34561/100000: episode: 4320, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000669, mae: 0.012250, mean_q: 0.013596
 34568/100000: episode: 4321, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000683, mae: 0.014508, mean_q: 0.021176
 34570/100000: episode: 4322, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001007, mae: 0.018965, mean_q: 0.027893
 34572/100000: episode: 4323, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000203, mae: 0.012767, mean_q: 0.019893
 34576/100000: episode: 4324, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000671, mae: 0.016988, mean_q: 0.028406
 34580/100000: episode: 4325, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000248, mae: 0.011731, mean_q: 0.015172
 34587/100000: episode: 4326, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000461, mae: 0.012843, mean_q: 0.016518
 34594/100000: episode: 4327, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000737, mae: 0.013977, mean_q: 0.022707
 34596/100000: episode: 4328, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000657, mae: 0.016155, mean_q: 0.018529
 34598/100000: episode: 4329, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000115, mae: 0.009289, mean_q: 0.012070
 34602/100000: episode: 4330, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001185, mae: 0.017283, mean_q: 0.027149
 34606/100000: episode: 4331, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001114, mae: 0.018318, mean_q: 0.028484
 34613/100000: episode: 4332, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000639, mae: 0.013791, mean_q: 0.024742
 34615/100000: episode: 4333, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000920, mae: 0.013839, mean_q: 0.028283
 34622/100000: episode: 4334, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000407, mae: 0.011071, mean_q: 0.017216
 34624/100000: episode: 4335, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001386, mae: 0.017649, mean_q: 0.038205
 34631/100000: episode: 4336, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000385, mae: 0.010695, mean_q: 0.018463
 34635/100000: episode: 4337, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000957, mae: 0.018120, mean_q: 0.016582
 34639/100000: episode: 4338, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001083, mae: 0.016461, mean_q: 0.018664
 34646/100000: episode: 4339, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000684, mae: 0.013461, mean_q: 0.020872
 34650/100000: episode: 4340, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000522, mae: 0.016126, mean_q: 0.028542
 34652/100000: episode: 4341, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001841, mae: 0.023992, mean_q: 0.035730
 34654/100000: episode: 4342, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000266, mae: 0.012012, mean_q: 0.013069
 34661/100000: episode: 4343, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000969, mae: 0.015230, mean_q: 0.025122
 34663/100000: episode: 4344, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000296, mae: 0.012053, mean_q: 0.019107
 34667/100000: episode: 4345, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000711, mae: 0.013189, mean_q: 0.022460
 34671/100000: episode: 4346, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000546, mae: 0.012791, mean_q: 0.017799
 34678/100000: episode: 4347, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000510, mae: 0.015952, mean_q: 0.025633
 34682/100000: episode: 4348, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000763, mae: 0.017286, mean_q: 0.029074
 34686/100000: episode: 4349, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000948, mae: 0.015935, mean_q: 0.025742
 34688/100000: episode: 4350, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000300, mae: 0.010858, mean_q: 0.013469
 34695/100000: episode: 4351, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000574, mae: 0.012452, mean_q: 0.019572
 34697/100000: episode: 4352, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001369, mae: 0.021185, mean_q: 0.025707
 34701/100000: episode: 4353, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001036, mae: 0.018033, mean_q: 0.027899
 34703/100000: episode: 4354, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000607, mae: 0.019294, mean_q: 0.025312
[Info] 2-TH LEVEL FOUND: 0.0634654238820076, Considering 11/100 traces
 34705/100000: episode: 4355, duration: 0.690s, episode steps: 2, steps per second: 3, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000285, mae: 0.011254, mean_q: 0.019376
 34711/100000: episode: 4356, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000586, mae: 0.016350, mean_q: 0.026122
 34717/100000: episode: 4357, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000995, mae: 0.017193, mean_q: 0.024869
 34723/100000: episode: 4358, duration: 0.028s, episode steps: 6, steps per second: 211, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000603, mae: 0.016065, mean_q: 0.025713
 34729/100000: episode: 4359, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001331, mae: 0.017663, mean_q: 0.034510
 34735/100000: episode: 4360, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000400, mae: 0.014588, mean_q: 0.029228
 34741/100000: episode: 4361, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000578, mae: 0.016325, mean_q: 0.032724
 34747/100000: episode: 4362, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002197, mae: 0.024572, mean_q: 0.042224
 34753/100000: episode: 4363, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000557, mae: 0.013581, mean_q: 0.016841
 34759/100000: episode: 4364, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000512, mae: 0.014018, mean_q: 0.019160
 34765/100000: episode: 4365, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000999, mae: 0.018187, mean_q: 0.027072
 34771/100000: episode: 4366, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000143, mae: 0.008752, mean_q: 0.012440
 34777/100000: episode: 4367, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000594, mae: 0.016257, mean_q: 0.025822
 34783/100000: episode: 4368, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.002056, mae: 0.016985, mean_q: 0.021460
 34789/100000: episode: 4369, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001347, mae: 0.020258, mean_q: 0.035800
 34795/100000: episode: 4370, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000414, mae: 0.013030, mean_q: 0.014591
 34801/100000: episode: 4371, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000527, mae: 0.013425, mean_q: 0.014485
 34807/100000: episode: 4372, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001039, mae: 0.017370, mean_q: 0.021193
 34813/100000: episode: 4373, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001182, mae: 0.017414, mean_q: 0.020225
 34819/100000: episode: 4374, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001157, mae: 0.018414, mean_q: 0.026732
 34825/100000: episode: 4375, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000411, mae: 0.015363, mean_q: 0.026758
 34831/100000: episode: 4376, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000870, mae: 0.016729, mean_q: 0.029438
 34837/100000: episode: 4377, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000569, mae: 0.014144, mean_q: 0.020876
 34843/100000: episode: 4378, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000707, mae: 0.015137, mean_q: 0.020975
[Info] FALSIFICATION!
 34848/100000: episode: 4379, duration: 0.267s, episode steps: 5, steps per second: 19, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.001505, mae: 0.022128, mean_q: 0.031466
 34854/100000: episode: 4380, duration: 0.033s, episode steps: 6, steps per second: 183, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000641, mae: 0.014823, mean_q: 0.014558
 34860/100000: episode: 4381, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001014, mae: 0.015103, mean_q: 0.015382
 34866/100000: episode: 4382, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001183, mae: 0.017532, mean_q: 0.021329
 34872/100000: episode: 4383, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000476, mae: 0.015043, mean_q: 0.023971
 34878/100000: episode: 4384, duration: 0.029s, episode steps: 6, steps per second: 210, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001370, mae: 0.020984, mean_q: 0.034779
 34884/100000: episode: 4385, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000904, mae: 0.017392, mean_q: 0.028618
 34890/100000: episode: 4386, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000735, mae: 0.017827, mean_q: 0.025112
 34896/100000: episode: 4387, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000504, mae: 0.015091, mean_q: 0.019000
 34902/100000: episode: 4388, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000792, mae: 0.016015, mean_q: 0.016502
 34908/100000: episode: 4389, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000773, mae: 0.017126, mean_q: 0.017370
 34914/100000: episode: 4390, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000533, mae: 0.013358, mean_q: 0.019356
 34920/100000: episode: 4391, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000552, mae: 0.015998, mean_q: 0.027758
 34926/100000: episode: 4392, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000394, mae: 0.015391, mean_q: 0.026893
 34932/100000: episode: 4393, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000515, mae: 0.014221, mean_q: 0.020197
 34938/100000: episode: 4394, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000546, mae: 0.013619, mean_q: 0.020000
 34944/100000: episode: 4395, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000153, mae: 0.009526, mean_q: 0.014012
 34950/100000: episode: 4396, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001404, mae: 0.019515, mean_q: 0.024963
 34956/100000: episode: 4397, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001107, mae: 0.020607, mean_q: 0.032032
 34962/100000: episode: 4398, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000601, mae: 0.016970, mean_q: 0.029787
 34968/100000: episode: 4399, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001789, mae: 0.022868, mean_q: 0.039032
 34974/100000: episode: 4400, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001788, mae: 0.023412, mean_q: 0.043164
 34980/100000: episode: 4401, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000683, mae: 0.017162, mean_q: 0.024376
 34986/100000: episode: 4402, duration: 0.028s, episode steps: 6, steps per second: 211, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001118, mae: 0.020200, mean_q: 0.028546
 34992/100000: episode: 4403, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001525, mae: 0.021756, mean_q: 0.026632
 34998/100000: episode: 4404, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001101, mae: 0.018714, mean_q: 0.032387
 35004/100000: episode: 4405, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000523, mae: 0.013765, mean_q: 0.019357
[Info] FALSIFICATION!
 35009/100000: episode: 4406, duration: 0.269s, episode steps: 5, steps per second: 19, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000705, mae: 0.016582, mean_q: 0.023280
 35015/100000: episode: 4407, duration: 0.044s, episode steps: 6, steps per second: 137, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000888, mae: 0.016036, mean_q: 0.028524
 35021/100000: episode: 4408, duration: 0.038s, episode steps: 6, steps per second: 157, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001022, mae: 0.018207, mean_q: 0.030031
 35027/100000: episode: 4409, duration: 0.037s, episode steps: 6, steps per second: 161, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001055, mae: 0.019370, mean_q: 0.031838
 35033/100000: episode: 4410, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000566, mae: 0.013248, mean_q: 0.016824
 35039/100000: episode: 4411, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001121, mae: 0.019569, mean_q: 0.023123
 35045/100000: episode: 4412, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000643, mae: 0.014767, mean_q: 0.018215
 35051/100000: episode: 4413, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000565, mae: 0.017029, mean_q: 0.028187
 35057/100000: episode: 4414, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001566, mae: 0.023597, mean_q: 0.042816
 35063/100000: episode: 4415, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000539, mae: 0.014644, mean_q: 0.021708
 35069/100000: episode: 4416, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000775, mae: 0.015838, mean_q: 0.023525
 35075/100000: episode: 4417, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001102, mae: 0.017923, mean_q: 0.023739
 35081/100000: episode: 4418, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000683, mae: 0.016347, mean_q: 0.030452
 35087/100000: episode: 4419, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000606, mae: 0.016813, mean_q: 0.022237
 35093/100000: episode: 4420, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000602, mae: 0.015805, mean_q: 0.022912
 35099/100000: episode: 4421, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001145, mae: 0.017412, mean_q: 0.021369
 35105/100000: episode: 4422, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000718, mae: 0.016524, mean_q: 0.019990
 35111/100000: episode: 4423, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000317, mae: 0.012305, mean_q: 0.013053
 35117/100000: episode: 4424, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001138, mae: 0.020020, mean_q: 0.025790
 35123/100000: episode: 4425, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000639, mae: 0.017480, mean_q: 0.027834
 35129/100000: episode: 4426, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002416, mae: 0.025925, mean_q: 0.043124
 35135/100000: episode: 4427, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000644, mae: 0.019211, mean_q: 0.035473
 35141/100000: episode: 4428, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000470, mae: 0.014890, mean_q: 0.020915
 35147/100000: episode: 4429, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001328, mae: 0.022238, mean_q: 0.023185
 35153/100000: episode: 4430, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001873, mae: 0.022437, mean_q: 0.031409
 35159/100000: episode: 4431, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000510, mae: 0.017030, mean_q: 0.025639
 35165/100000: episode: 4432, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000871, mae: 0.018706, mean_q: 0.028906
 35171/100000: episode: 4433, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000814, mae: 0.018942, mean_q: 0.030046
 35177/100000: episode: 4434, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000781, mae: 0.017194, mean_q: 0.021125
 35183/100000: episode: 4435, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000612, mae: 0.015223, mean_q: 0.027819
 35189/100000: episode: 4436, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001671, mae: 0.025315, mean_q: 0.044906
 35195/100000: episode: 4437, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000908, mae: 0.017569, mean_q: 0.028999
 35201/100000: episode: 4438, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001127, mae: 0.020165, mean_q: 0.029968
 35207/100000: episode: 4439, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000918, mae: 0.018681, mean_q: 0.030205
 35213/100000: episode: 4440, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000781, mae: 0.017779, mean_q: 0.026057
 35219/100000: episode: 4441, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001613, mae: 0.023900, mean_q: 0.026534
 35225/100000: episode: 4442, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000802, mae: 0.016956, mean_q: 0.021888
 35231/100000: episode: 4443, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000954, mae: 0.019760, mean_q: 0.027269
[Info] Complete ISplit Iteration
[Info] Levels: [0.036408953, 0.063465424, 0.96704125]
[Info] Cond. Prob: [0.14, 0.11, 0.02]
[Info] Error Prob: 0.00030800000000000006

 35237/100000: episode: 4444, duration: 0.757s, episode steps: 6, steps per second: 8, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.002177, mae: 0.027912, mean_q: 0.047880
 35247/100000: episode: 4445, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000611, mae: 0.016339, mean_q: 0.026466
 35257/100000: episode: 4446, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001862, mae: 0.023293, mean_q: 0.034389
 35267/100000: episode: 4447, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001224, mae: 0.020963, mean_q: 0.038502
 35277/100000: episode: 4448, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001098, mae: 0.020943, mean_q: 0.030485
 35287/100000: episode: 4449, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000826, mae: 0.017490, mean_q: 0.024208
 35297/100000: episode: 4450, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000790, mae: 0.017760, mean_q: 0.029890
 35307/100000: episode: 4451, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001535, mae: 0.022489, mean_q: 0.035151
 35317/100000: episode: 4452, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000754, mae: 0.017130, mean_q: 0.029001
 35327/100000: episode: 4453, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001205, mae: 0.022547, mean_q: 0.035907
 35337/100000: episode: 4454, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000494, mae: 0.015091, mean_q: 0.020696
 35347/100000: episode: 4455, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002121, mae: 0.023278, mean_q: 0.032497
 35357/100000: episode: 4456, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001164, mae: 0.022847, mean_q: 0.037380
 35367/100000: episode: 4457, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001047, mae: 0.019367, mean_q: 0.030486
 35377/100000: episode: 4458, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001889, mae: 0.022177, mean_q: 0.030108
 35387/100000: episode: 4459, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001192, mae: 0.019689, mean_q: 0.032947
 35397/100000: episode: 4460, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001640, mae: 0.022840, mean_q: 0.030182
 35407/100000: episode: 4461, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001244, mae: 0.021219, mean_q: 0.030138
 35417/100000: episode: 4462, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001048, mae: 0.018916, mean_q: 0.035800
 35427/100000: episode: 4463, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000507, mae: 0.015141, mean_q: 0.022723
 35437/100000: episode: 4464, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001062, mae: 0.020461, mean_q: 0.029078
 35447/100000: episode: 4465, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001030, mae: 0.016257, mean_q: 0.023903
 35457/100000: episode: 4466, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000840, mae: 0.016867, mean_q: 0.021980
 35467/100000: episode: 4467, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000791, mae: 0.017607, mean_q: 0.026461
 35477/100000: episode: 4468, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000798, mae: 0.019863, mean_q: 0.031445
 35487/100000: episode: 4469, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000584, mae: 0.015344, mean_q: 0.026467
 35497/100000: episode: 4470, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001318, mae: 0.017244, mean_q: 0.016545
 35507/100000: episode: 4471, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000717, mae: 0.015678, mean_q: 0.019198
 35517/100000: episode: 4472, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000687, mae: 0.014696, mean_q: 0.022538
 35527/100000: episode: 4473, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001362, mae: 0.016072, mean_q: 0.025173
 35537/100000: episode: 4474, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000848, mae: 0.017873, mean_q: 0.027206
 35547/100000: episode: 4475, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001258, mae: 0.018633, mean_q: 0.028835
 35557/100000: episode: 4476, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000998, mae: 0.018402, mean_q: 0.025790
 35567/100000: episode: 4477, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001116, mae: 0.020245, mean_q: 0.028638
 35577/100000: episode: 4478, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001493, mae: 0.020266, mean_q: 0.029261
 35587/100000: episode: 4479, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000888, mae: 0.015300, mean_q: 0.025602
 35597/100000: episode: 4480, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000828, mae: 0.016256, mean_q: 0.020164
 35607/100000: episode: 4481, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000753, mae: 0.016808, mean_q: 0.023989
 35617/100000: episode: 4482, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001123, mae: 0.018700, mean_q: 0.026945
 35627/100000: episode: 4483, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000787, mae: 0.016850, mean_q: 0.029487
 35637/100000: episode: 4484, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001259, mae: 0.019403, mean_q: 0.031643
 35647/100000: episode: 4485, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001003, mae: 0.016842, mean_q: 0.024434
 35657/100000: episode: 4486, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000649, mae: 0.013869, mean_q: 0.021440
 35667/100000: episode: 4487, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000689, mae: 0.015224, mean_q: 0.020359
 35677/100000: episode: 4488, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001397, mae: 0.017855, mean_q: 0.023091
 35687/100000: episode: 4489, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001675, mae: 0.021067, mean_q: 0.034491
 35697/100000: episode: 4490, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001072, mae: 0.019024, mean_q: 0.020223
 35707/100000: episode: 4491, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001505, mae: 0.017729, mean_q: 0.019768
 35717/100000: episode: 4492, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000607, mae: 0.015188, mean_q: 0.022339
 35727/100000: episode: 4493, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001118, mae: 0.020357, mean_q: 0.034007
 35737/100000: episode: 4494, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000958, mae: 0.017449, mean_q: 0.027919
 35747/100000: episode: 4495, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000461, mae: 0.013502, mean_q: 0.015648
 35757/100000: episode: 4496, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000437, mae: 0.013430, mean_q: 0.020037
 35767/100000: episode: 4497, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000541, mae: 0.014977, mean_q: 0.021406
 35777/100000: episode: 4498, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000794, mae: 0.015208, mean_q: 0.019477
 35787/100000: episode: 4499, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001008, mae: 0.015089, mean_q: 0.022080
 35797/100000: episode: 4500, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000676, mae: 0.016782, mean_q: 0.033424
 35807/100000: episode: 4501, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000441, mae: 0.015876, mean_q: 0.026270
 35817/100000: episode: 4502, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001376, mae: 0.017226, mean_q: 0.024750
 35827/100000: episode: 4503, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001866, mae: 0.021750, mean_q: 0.038102
 35837/100000: episode: 4504, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002094, mae: 0.021654, mean_q: 0.024217
 35847/100000: episode: 4505, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000794, mae: 0.016166, mean_q: 0.022076
 35857/100000: episode: 4506, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001119, mae: 0.019420, mean_q: 0.033300
 35867/100000: episode: 4507, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000920, mae: 0.019538, mean_q: 0.034562
 35877/100000: episode: 4508, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000897, mae: 0.017604, mean_q: 0.026501
 35887/100000: episode: 4509, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001109, mae: 0.018413, mean_q: 0.027067
 35897/100000: episode: 4510, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000655, mae: 0.013033, mean_q: 0.018216
 35907/100000: episode: 4511, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000586, mae: 0.014016, mean_q: 0.020005
 35917/100000: episode: 4512, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000418, mae: 0.013531, mean_q: 0.018403
 35927/100000: episode: 4513, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001329, mae: 0.016250, mean_q: 0.025934
 35937/100000: episode: 4514, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001096, mae: 0.020243, mean_q: 0.034235
 35947/100000: episode: 4515, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000687, mae: 0.014814, mean_q: 0.024460
 35957/100000: episode: 4516, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001143, mae: 0.016518, mean_q: 0.023477
 35967/100000: episode: 4517, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000788, mae: 0.015746, mean_q: 0.025177
 35977/100000: episode: 4518, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000389, mae: 0.012831, mean_q: 0.012590
 35987/100000: episode: 4519, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000940, mae: 0.014935, mean_q: 0.021427
 35997/100000: episode: 4520, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000503, mae: 0.013914, mean_q: 0.022160
 36007/100000: episode: 4521, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000622, mae: 0.015334, mean_q: 0.026761
 36017/100000: episode: 4522, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000883, mae: 0.014539, mean_q: 0.023360
 36027/100000: episode: 4523, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000522, mae: 0.013357, mean_q: 0.019166
 36037/100000: episode: 4524, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000373, mae: 0.011280, mean_q: 0.014400
 36047/100000: episode: 4525, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000993, mae: 0.014590, mean_q: 0.020746
 36057/100000: episode: 4526, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000358, mae: 0.009716, mean_q: 0.014325
 36067/100000: episode: 4527, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000820, mae: 0.013153, mean_q: 0.018956
 36077/100000: episode: 4528, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000712, mae: 0.014630, mean_q: 0.022954
 36087/100000: episode: 4529, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000702, mae: 0.012634, mean_q: 0.016871
 36097/100000: episode: 4530, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000564, mae: 0.012081, mean_q: 0.014092
 36107/100000: episode: 4531, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000465, mae: 0.012409, mean_q: 0.018990
 36117/100000: episode: 4532, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000483, mae: 0.013292, mean_q: 0.025284
 36127/100000: episode: 4533, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001349, mae: 0.017936, mean_q: 0.031643
 36137/100000: episode: 4534, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000375, mae: 0.010951, mean_q: 0.011184
 36147/100000: episode: 4535, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000320, mae: 0.010059, mean_q: 0.014265
 36157/100000: episode: 4536, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000820, mae: 0.015262, mean_q: 0.023952
 36167/100000: episode: 4537, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000433, mae: 0.011161, mean_q: 0.018786
 36177/100000: episode: 4538, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000481, mae: 0.012109, mean_q: 0.019497
 36187/100000: episode: 4539, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000691, mae: 0.013176, mean_q: 0.014769
 36197/100000: episode: 4540, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000567, mae: 0.011176, mean_q: 0.015640
 36207/100000: episode: 4541, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001272, mae: 0.015461, mean_q: 0.020899
 36217/100000: episode: 4542, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000541, mae: 0.010700, mean_q: 0.020485
 36227/100000: episode: 4543, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000499, mae: 0.011153, mean_q: 0.019496
[Info] 1-TH LEVEL FOUND: 0.030272915959358215, Considering 10/100 traces
 36237/100000: episode: 4544, duration: 0.689s, episode steps: 10, steps per second: 15, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000783, mae: 0.012262, mean_q: 0.016897
 36241/100000: episode: 4545, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000489, mae: 0.013013, mean_q: 0.015794
 36245/100000: episode: 4546, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000960, mae: 0.014239, mean_q: 0.016478
 36249/100000: episode: 4547, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001097, mae: 0.015863, mean_q: 0.018404
 36253/100000: episode: 4548, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000934, mae: 0.014501, mean_q: 0.018935
 36257/100000: episode: 4549, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000460, mae: 0.013166, mean_q: 0.022229
 36261/100000: episode: 4550, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000365, mae: 0.012158, mean_q: 0.018740
 36268/100000: episode: 4551, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000608, mae: 0.013668, mean_q: 0.017748
 36272/100000: episode: 4552, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000176, mae: 0.008944, mean_q: 0.014853
 36276/100000: episode: 4553, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000396, mae: 0.011318, mean_q: 0.014234
 36280/100000: episode: 4554, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000401, mae: 0.011805, mean_q: 0.018293
 36284/100000: episode: 4555, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000232, mae: 0.009765, mean_q: 0.014233
 36291/100000: episode: 4556, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000948, mae: 0.015312, mean_q: 0.025410
 36295/100000: episode: 4557, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000270, mae: 0.010940, mean_q: 0.018159
 36302/100000: episode: 4558, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000455, mae: 0.011392, mean_q: 0.019777
 36309/100000: episode: 4559, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001598, mae: 0.016616, mean_q: 0.017960
 36316/100000: episode: 4560, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000778, mae: 0.016438, mean_q: 0.024677
 36323/100000: episode: 4561, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000333, mae: 0.010702, mean_q: 0.016962
 36327/100000: episode: 4562, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000500, mae: 0.013067, mean_q: 0.017358
 36334/100000: episode: 4563, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000469, mae: 0.012155, mean_q: 0.016932
 36338/100000: episode: 4564, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000420, mae: 0.013948, mean_q: 0.015459
 36342/100000: episode: 4565, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000308, mae: 0.012512, mean_q: 0.017745
 36346/100000: episode: 4566, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000740, mae: 0.014599, mean_q: 0.018444
 36350/100000: episode: 4567, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000891, mae: 0.014227, mean_q: 0.023952
 36354/100000: episode: 4568, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000159, mae: 0.008953, mean_q: 0.011871
 36361/100000: episode: 4569, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000422, mae: 0.013267, mean_q: 0.022300
 36368/100000: episode: 4570, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000592, mae: 0.011076, mean_q: 0.016915
 36375/100000: episode: 4571, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000496, mae: 0.013412, mean_q: 0.017557
 36379/100000: episode: 4572, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000360, mae: 0.011923, mean_q: 0.013172
 36386/100000: episode: 4573, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000670, mae: 0.012642, mean_q: 0.017867
 36390/100000: episode: 4574, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000159, mae: 0.008798, mean_q: 0.013519
 36397/100000: episode: 4575, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000575, mae: 0.014164, mean_q: 0.017395
 36401/100000: episode: 4576, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000825, mae: 0.013887, mean_q: 0.018550
 36405/100000: episode: 4577, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000129, mae: 0.009505, mean_q: 0.015780
 36409/100000: episode: 4578, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000323, mae: 0.012928, mean_q: 0.019101
 36413/100000: episode: 4579, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000946, mae: 0.018888, mean_q: 0.031905
 36420/100000: episode: 4580, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000347, mae: 0.012305, mean_q: 0.018784
 36427/100000: episode: 4581, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000635, mae: 0.012557, mean_q: 0.020748
 36434/100000: episode: 4582, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000576, mae: 0.012356, mean_q: 0.016784
 36438/100000: episode: 4583, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000328, mae: 0.008404, mean_q: 0.012026
 36442/100000: episode: 4584, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000303, mae: 0.011599, mean_q: 0.015586
 36446/100000: episode: 4585, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000643, mae: 0.013195, mean_q: 0.017924
 36453/100000: episode: 4586, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000369, mae: 0.010257, mean_q: 0.015597
 36460/100000: episode: 4587, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000378, mae: 0.010650, mean_q: 0.014743
[Info] FALSIFICATION!
 36466/100000: episode: 4588, duration: 0.178s, episode steps: 6, steps per second: 34, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000374, mae: 0.010190, mean_q: 0.014349
 36470/100000: episode: 4589, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000810, mae: 0.013626, mean_q: 0.013301
 36477/100000: episode: 4590, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000322, mae: 0.011010, mean_q: 0.013850
 36481/100000: episode: 4591, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000742, mae: 0.014301, mean_q: 0.019849
 36485/100000: episode: 4592, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000426, mae: 0.012841, mean_q: 0.017823
 36489/100000: episode: 4593, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000859, mae: 0.017402, mean_q: 0.026930
 36493/100000: episode: 4594, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001422, mae: 0.022247, mean_q: 0.039032
 36497/100000: episode: 4595, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000456, mae: 0.015180, mean_q: 0.020974
 36501/100000: episode: 4596, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000277, mae: 0.010009, mean_q: 0.019793
 36505/100000: episode: 4597, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000296, mae: 0.010060, mean_q: 0.015484
 36509/100000: episode: 4598, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000603, mae: 0.012291, mean_q: 0.017170
 36513/100000: episode: 4599, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000757, mae: 0.012414, mean_q: 0.015141
 36517/100000: episode: 4600, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000263, mae: 0.009998, mean_q: 0.012368
 36521/100000: episode: 4601, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000245, mae: 0.010720, mean_q: 0.018110
 36528/100000: episode: 4602, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000560, mae: 0.013310, mean_q: 0.022426
 36532/100000: episode: 4603, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000467, mae: 0.011420, mean_q: 0.023765
 36539/100000: episode: 4604, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000864, mae: 0.014774, mean_q: 0.025496
 36546/100000: episode: 4605, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000894, mae: 0.014627, mean_q: 0.024563
 36553/100000: episode: 4606, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000329, mae: 0.010940, mean_q: 0.018610
 36557/100000: episode: 4607, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000423, mae: 0.012385, mean_q: 0.020109
 36561/100000: episode: 4608, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000968, mae: 0.014710, mean_q: 0.023848
 36565/100000: episode: 4609, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000500, mae: 0.014155, mean_q: 0.020684
 36572/100000: episode: 4610, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000828, mae: 0.013965, mean_q: 0.021400
 36576/100000: episode: 4611, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000929, mae: 0.020258, mean_q: 0.026536
 36580/100000: episode: 4612, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000904, mae: 0.015279, mean_q: 0.014719
 36584/100000: episode: 4613, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000523, mae: 0.012508, mean_q: 0.011538
 36588/100000: episode: 4614, duration: 0.020s, episode steps: 4, steps per second: 199, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000856, mae: 0.013668, mean_q: 0.023391
 36595/100000: episode: 4615, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000839, mae: 0.017618, mean_q: 0.025867
 36599/100000: episode: 4616, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000373, mae: 0.017102, mean_q: 0.023595
 36603/100000: episode: 4617, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000334, mae: 0.012002, mean_q: 0.018734
 36610/100000: episode: 4618, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000563, mae: 0.014695, mean_q: 0.024647
 36614/100000: episode: 4619, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000366, mae: 0.011478, mean_q: 0.020053
 36621/100000: episode: 4620, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000259, mae: 0.010132, mean_q: 0.013251
 36628/100000: episode: 4621, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000436, mae: 0.013185, mean_q: 0.017449
 36635/100000: episode: 4622, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000414, mae: 0.012717, mean_q: 0.019140
 36639/100000: episode: 4623, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000849, mae: 0.018200, mean_q: 0.026194
 36643/100000: episode: 4624, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000302, mae: 0.013221, mean_q: 0.021947
 36650/100000: episode: 4625, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000478, mae: 0.014910, mean_q: 0.028411
 36654/100000: episode: 4626, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000405, mae: 0.011487, mean_q: 0.018843
 36658/100000: episode: 4627, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000487, mae: 0.012661, mean_q: 0.019174
 36665/100000: episode: 4628, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001203, mae: 0.017224, mean_q: 0.031609
 36669/100000: episode: 4629, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001544, mae: 0.013408, mean_q: 0.021156
 36676/100000: episode: 4630, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001391, mae: 0.017082, mean_q: 0.024936
 36683/100000: episode: 4631, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.001276, mae: 0.018961, mean_q: 0.032788
 36690/100000: episode: 4632, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000352, mae: 0.011830, mean_q: 0.013235
 36697/100000: episode: 4633, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000559, mae: 0.013155, mean_q: 0.013080
[Info] Complete ISplit Iteration
[Info] Levels: [0.030272916, 0.90355635]
[Info] Cond. Prob: [0.1, 0.01]
[Info] Error Prob: 0.001

 36701/100000: episode: 4634, duration: 0.732s, episode steps: 4, steps per second: 5, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000946, mae: 0.016200, mean_q: 0.025638
 36711/100000: episode: 4635, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000561, mae: 0.016088, mean_q: 0.022265
 36721/100000: episode: 4636, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001525, mae: 0.021371, mean_q: 0.035608
 36731/100000: episode: 4637, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000938, mae: 0.017110, mean_q: 0.023904
 36741/100000: episode: 4638, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000525, mae: 0.012725, mean_q: 0.019089
 36751/100000: episode: 4639, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000438, mae: 0.012382, mean_q: 0.018908
 36761/100000: episode: 4640, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000999, mae: 0.015045, mean_q: 0.018094
 36771/100000: episode: 4641, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000257, mae: 0.010715, mean_q: 0.016048
 36781/100000: episode: 4642, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001208, mae: 0.016021, mean_q: 0.021822
 36791/100000: episode: 4643, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001426, mae: 0.020821, mean_q: 0.031367
 36801/100000: episode: 4644, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000591, mae: 0.013840, mean_q: 0.016028
 36811/100000: episode: 4645, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000419, mae: 0.012428, mean_q: 0.018294
 36821/100000: episode: 4646, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000317, mae: 0.013381, mean_q: 0.019625
 36831/100000: episode: 4647, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000276, mae: 0.012126, mean_q: 0.019667
 36841/100000: episode: 4648, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000611, mae: 0.012485, mean_q: 0.019703
 36851/100000: episode: 4649, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000592, mae: 0.013624, mean_q: 0.015655
 36861/100000: episode: 4650, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000577, mae: 0.015556, mean_q: 0.024676
 36871/100000: episode: 4651, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000579, mae: 0.013988, mean_q: 0.016872
 36881/100000: episode: 4652, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000707, mae: 0.015381, mean_q: 0.028001
 36891/100000: episode: 4653, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000382, mae: 0.009998, mean_q: 0.014838
 36901/100000: episode: 4654, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000364, mae: 0.011493, mean_q: 0.017316
 36911/100000: episode: 4655, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000767, mae: 0.013653, mean_q: 0.022161
 36921/100000: episode: 4656, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000547, mae: 0.015772, mean_q: 0.024126
 36931/100000: episode: 4657, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000677, mae: 0.014390, mean_q: 0.022296
 36941/100000: episode: 4658, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000361, mae: 0.011380, mean_q: 0.015214
 36951/100000: episode: 4659, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000363, mae: 0.011645, mean_q: 0.014271
 36961/100000: episode: 4660, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000774, mae: 0.014002, mean_q: 0.018238
 36971/100000: episode: 4661, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000583, mae: 0.015068, mean_q: 0.020401
 36981/100000: episode: 4662, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000254, mae: 0.012114, mean_q: 0.018442
 36991/100000: episode: 4663, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000528, mae: 0.014440, mean_q: 0.024525
 37001/100000: episode: 4664, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000591, mae: 0.015274, mean_q: 0.023767
 37011/100000: episode: 4665, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000527, mae: 0.013278, mean_q: 0.017950
 37021/100000: episode: 4666, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000663, mae: 0.015740, mean_q: 0.021054
 37031/100000: episode: 4667, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000858, mae: 0.015746, mean_q: 0.027520
 37041/100000: episode: 4668, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000308, mae: 0.010488, mean_q: 0.012990
 37051/100000: episode: 4669, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000683, mae: 0.013370, mean_q: 0.017226
 37061/100000: episode: 4670, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000873, mae: 0.017141, mean_q: 0.026327
 37071/100000: episode: 4671, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000537, mae: 0.013916, mean_q: 0.023365
 37081/100000: episode: 4672, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000358, mae: 0.011472, mean_q: 0.015557
 37091/100000: episode: 4673, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000572, mae: 0.015032, mean_q: 0.021661
 37101/100000: episode: 4674, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000338, mae: 0.012562, mean_q: 0.017014
 37111/100000: episode: 4675, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000785, mae: 0.014505, mean_q: 0.019697
 37121/100000: episode: 4676, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000310, mae: 0.012667, mean_q: 0.019459
 37131/100000: episode: 4677, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000645, mae: 0.013424, mean_q: 0.017907
 37141/100000: episode: 4678, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000455, mae: 0.013079, mean_q: 0.018065
 37151/100000: episode: 4679, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000731, mae: 0.015509, mean_q: 0.024813
 37161/100000: episode: 4680, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000678, mae: 0.015048, mean_q: 0.020991
 37171/100000: episode: 4681, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000946, mae: 0.014118, mean_q: 0.019927
 37181/100000: episode: 4682, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000491, mae: 0.013801, mean_q: 0.021749
 37191/100000: episode: 4683, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000407, mae: 0.012575, mean_q: 0.019874
 37201/100000: episode: 4684, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000320, mae: 0.009815, mean_q: 0.016879
 37211/100000: episode: 4685, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000539, mae: 0.013774, mean_q: 0.022032
 37221/100000: episode: 4686, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000647, mae: 0.014248, mean_q: 0.021247
 37231/100000: episode: 4687, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000948, mae: 0.015761, mean_q: 0.023582
 37241/100000: episode: 4688, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000572, mae: 0.015955, mean_q: 0.024984
 37251/100000: episode: 4689, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000793, mae: 0.016039, mean_q: 0.023675
 37261/100000: episode: 4690, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000621, mae: 0.014196, mean_q: 0.017952
 37271/100000: episode: 4691, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000666, mae: 0.015695, mean_q: 0.020613
 37281/100000: episode: 4692, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000925, mae: 0.018411, mean_q: 0.030722
 37291/100000: episode: 4693, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000761, mae: 0.014264, mean_q: 0.025690
 37301/100000: episode: 4694, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000477, mae: 0.013207, mean_q: 0.015900
 37311/100000: episode: 4695, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000488, mae: 0.012561, mean_q: 0.016986
 37321/100000: episode: 4696, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000886, mae: 0.016814, mean_q: 0.027863
 37331/100000: episode: 4697, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000266, mae: 0.011904, mean_q: 0.022607
 37341/100000: episode: 4698, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000994, mae: 0.014116, mean_q: 0.019150
 37351/100000: episode: 4699, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000589, mae: 0.012744, mean_q: 0.017581
 37361/100000: episode: 4700, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000925, mae: 0.016267, mean_q: 0.023445
 37371/100000: episode: 4701, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000591, mae: 0.014413, mean_q: 0.020745
 37381/100000: episode: 4702, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000692, mae: 0.013629, mean_q: 0.021047
 37391/100000: episode: 4703, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000741, mae: 0.014963, mean_q: 0.019649
 37401/100000: episode: 4704, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000552, mae: 0.011936, mean_q: 0.017860
 37411/100000: episode: 4705, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000256, mae: 0.009578, mean_q: 0.014038
 37421/100000: episode: 4706, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000679, mae: 0.012429, mean_q: 0.018598
 37431/100000: episode: 4707, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000307, mae: 0.010587, mean_q: 0.016280
 37441/100000: episode: 4708, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000266, mae: 0.010682, mean_q: 0.014776
 37451/100000: episode: 4709, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000397, mae: 0.011523, mean_q: 0.014958
 37461/100000: episode: 4710, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000217, mae: 0.011213, mean_q: 0.015161
 37471/100000: episode: 4711, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001271, mae: 0.016456, mean_q: 0.018483
 37481/100000: episode: 4712, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000391, mae: 0.013747, mean_q: 0.023115
 37491/100000: episode: 4713, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000434, mae: 0.012492, mean_q: 0.018408
 37501/100000: episode: 4714, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000177, mae: 0.009861, mean_q: 0.015575
 37511/100000: episode: 4715, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000529, mae: 0.012366, mean_q: 0.016165
 37521/100000: episode: 4716, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000696, mae: 0.013042, mean_q: 0.016755
 37531/100000: episode: 4717, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000344, mae: 0.010330, mean_q: 0.015663
 37541/100000: episode: 4718, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000361, mae: 0.012355, mean_q: 0.015091
 37551/100000: episode: 4719, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000484, mae: 0.012091, mean_q: 0.019752
 37561/100000: episode: 4720, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000506, mae: 0.012527, mean_q: 0.021872
 37571/100000: episode: 4721, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000575, mae: 0.014118, mean_q: 0.019843
 37581/100000: episode: 4722, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000227, mae: 0.010992, mean_q: 0.016323
 37591/100000: episode: 4723, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001104, mae: 0.010780, mean_q: 0.015532
 37601/100000: episode: 4724, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000564, mae: 0.010746, mean_q: 0.020894
 37611/100000: episode: 4725, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000720, mae: 0.013195, mean_q: 0.017522
 37621/100000: episode: 4726, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000620, mae: 0.014930, mean_q: 0.012691
 37631/100000: episode: 4727, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000721, mae: 0.012709, mean_q: 0.017850
 37641/100000: episode: 4728, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000680, mae: 0.015249, mean_q: 0.026942
 37651/100000: episode: 4729, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000336, mae: 0.010583, mean_q: 0.015538
 37661/100000: episode: 4730, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000249, mae: 0.010709, mean_q: 0.013657
 37671/100000: episode: 4731, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000516, mae: 0.012316, mean_q: 0.014723
 37681/100000: episode: 4732, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000507, mae: 0.013243, mean_q: 0.020900
 37691/100000: episode: 4733, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000485, mae: 0.012634, mean_q: 0.016925
[Info] 1-TH LEVEL FOUND: 0.03194599598646164, Considering 12/100 traces
 37701/100000: episode: 4734, duration: 0.754s, episode steps: 10, steps per second: 13, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000457, mae: 0.011221, mean_q: 0.015643
 37706/100000: episode: 4735, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000388, mae: 0.012146, mean_q: 0.016787
 37711/100000: episode: 4736, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000892, mae: 0.015473, mean_q: 0.020090
 37716/100000: episode: 4737, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.001390, mae: 0.017946, mean_q: 0.030450
 37721/100000: episode: 4738, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000663, mae: 0.011177, mean_q: 0.017373
 37728/100000: episode: 4739, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000146, mae: 0.007138, mean_q: 0.008445
 37735/100000: episode: 4740, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000989, mae: 0.013665, mean_q: 0.015954
 37740/100000: episode: 4741, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000480, mae: 0.012627, mean_q: 0.021746
 37745/100000: episode: 4742, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000678, mae: 0.014063, mean_q: 0.019509
 37750/100000: episode: 4743, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000540, mae: 0.012334, mean_q: 0.018694
 37755/100000: episode: 4744, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000214, mae: 0.010915, mean_q: 0.021281
 37760/100000: episode: 4745, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000179, mae: 0.009174, mean_q: 0.013311
 37765/100000: episode: 4746, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000362, mae: 0.009213, mean_q: 0.010397
 37770/100000: episode: 4747, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000215, mae: 0.008725, mean_q: 0.014319
 37775/100000: episode: 4748, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000084, mae: 0.006843, mean_q: 0.010512
 37780/100000: episode: 4749, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000196, mae: 0.009517, mean_q: 0.013952
 37785/100000: episode: 4750, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000193, mae: 0.008173, mean_q: 0.011276
 37790/100000: episode: 4751, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000361, mae: 0.011510, mean_q: 0.017542
 37795/100000: episode: 4752, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000367, mae: 0.010944, mean_q: 0.018292
 37800/100000: episode: 4753, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000551, mae: 0.011643, mean_q: 0.016317
 37805/100000: episode: 4754, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000108, mae: 0.008766, mean_q: 0.013662
 37810/100000: episode: 4755, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000629, mae: 0.012334, mean_q: 0.014371
 37817/100000: episode: 4756, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000158, mae: 0.008299, mean_q: 0.012225
 37822/100000: episode: 4757, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000386, mae: 0.011353, mean_q: 0.017814
 37829/100000: episode: 4758, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000944, mae: 0.014446, mean_q: 0.021987
 37836/100000: episode: 4759, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000467, mae: 0.012477, mean_q: 0.019237
 37841/100000: episode: 4760, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000339, mae: 0.013042, mean_q: 0.019188
 37846/100000: episode: 4761, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000226, mae: 0.010626, mean_q: 0.017977
 37851/100000: episode: 4762, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000937, mae: 0.015485, mean_q: 0.026545
 37858/100000: episode: 4763, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000549, mae: 0.010733, mean_q: 0.018708
 37863/100000: episode: 4764, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000354, mae: 0.012838, mean_q: 0.014515
 37870/100000: episode: 4765, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000392, mae: 0.011745, mean_q: 0.015859
 37877/100000: episode: 4766, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000494, mae: 0.013217, mean_q: 0.019113
 37882/100000: episode: 4767, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000599, mae: 0.012731, mean_q: 0.019874
 37887/100000: episode: 4768, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000469, mae: 0.012118, mean_q: 0.017531
 37892/100000: episode: 4769, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001439, mae: 0.013193, mean_q: 0.012953
 37897/100000: episode: 4770, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000196, mae: 0.010742, mean_q: 0.018330
 37904/100000: episode: 4771, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001217, mae: 0.016776, mean_q: 0.029776
 37909/100000: episode: 4772, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000277, mae: 0.010140, mean_q: 0.013460
 37916/100000: episode: 4773, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001112, mae: 0.015102, mean_q: 0.014284
 37921/100000: episode: 4774, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000241, mae: 0.009380, mean_q: 0.015047
 37926/100000: episode: 4775, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000573, mae: 0.012151, mean_q: 0.018067
 37931/100000: episode: 4776, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000494, mae: 0.012409, mean_q: 0.015298
 37936/100000: episode: 4777, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000161, mae: 0.008690, mean_q: 0.013694
 37941/100000: episode: 4778, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.001026, mae: 0.016389, mean_q: 0.025114
 37948/100000: episode: 4779, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000318, mae: 0.012726, mean_q: 0.020322
 37953/100000: episode: 4780, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000599, mae: 0.012435, mean_q: 0.018311
 37960/100000: episode: 4781, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 1.947, mean reward: 0.278 [0.007, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 7.857 [5.000, 11.000], loss: 0.000358, mae: 0.010860, mean_q: 0.016142
 37965/100000: episode: 4782, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000223, mae: 0.009191, mean_q: 0.013397
 37972/100000: episode: 4783, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000713, mae: 0.014041, mean_q: 0.019476
 37977/100000: episode: 4784, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000721, mae: 0.014081, mean_q: 0.021616
 37982/100000: episode: 4785, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001142, mae: 0.012018, mean_q: 0.015166
 37987/100000: episode: 4786, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000590, mae: 0.013131, mean_q: 0.024916
 37994/100000: episode: 4787, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000277, mae: 0.010479, mean_q: 0.016951
 38001/100000: episode: 4788, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000272, mae: 0.012226, mean_q: 0.015060
 38006/100000: episode: 4789, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000510, mae: 0.009975, mean_q: 0.011395
 38013/100000: episode: 4790, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.002051, mae: 0.021048, mean_q: 0.031577
 38020/100000: episode: 4791, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.001197, mae: 0.017979, mean_q: 0.027240
 38025/100000: episode: 4792, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000218, mae: 0.011995, mean_q: 0.015706
 38030/100000: episode: 4793, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000526, mae: 0.011451, mean_q: 0.010088
 38035/100000: episode: 4794, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.002339, mae: 0.019191, mean_q: 0.025203
 38042/100000: episode: 4795, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000984, mae: 0.016798, mean_q: 0.024098
 38047/100000: episode: 4796, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002550, mae: 0.028685, mean_q: 0.039952
 38052/100000: episode: 4797, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000531, mae: 0.010643, mean_q: 0.009188
 38059/100000: episode: 4798, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.001003, mae: 0.015797, mean_q: 0.012225
 38064/100000: episode: 4799, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000201, mae: 0.011232, mean_q: 0.016296
 38071/100000: episode: 4800, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000197, mae: 0.011483, mean_q: 0.019362
 38076/100000: episode: 4801, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000558, mae: 0.014948, mean_q: 0.020402
 38083/100000: episode: 4802, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000668, mae: 0.013238, mean_q: 0.018083
 38088/100000: episode: 4803, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001206, mae: 0.016220, mean_q: 0.021226
 38095/100000: episode: 4804, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000473, mae: 0.012673, mean_q: 0.024276
 38100/100000: episode: 4805, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000528, mae: 0.012672, mean_q: 0.023904
 38105/100000: episode: 4806, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000576, mae: 0.011361, mean_q: 0.021275
 38110/100000: episode: 4807, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000388, mae: 0.011878, mean_q: 0.016006
 38115/100000: episode: 4808, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.003197, mae: 0.017934, mean_q: 0.021289
 38120/100000: episode: 4809, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001337, mae: 0.018789, mean_q: 0.032297
 38125/100000: episode: 4810, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001343, mae: 0.015286, mean_q: 0.019751
 38130/100000: episode: 4811, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000829, mae: 0.015490, mean_q: 0.016495
 38137/100000: episode: 4812, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000542, mae: 0.013569, mean_q: 0.017967
 38144/100000: episode: 4813, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000462, mae: 0.012179, mean_q: 0.016386
 38151/100000: episode: 4814, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000208, mae: 0.009923, mean_q: 0.013945
 38158/100000: episode: 4815, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000562, mae: 0.014611, mean_q: 0.024479
 38165/100000: episode: 4816, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000546, mae: 0.012426, mean_q: 0.021798
 38170/100000: episode: 4817, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000599, mae: 0.013670, mean_q: 0.022094
 38175/100000: episode: 4818, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000464, mae: 0.012276, mean_q: 0.017916
 38180/100000: episode: 4819, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000257, mae: 0.010351, mean_q: 0.012125
 38185/100000: episode: 4820, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000809, mae: 0.015287, mean_q: 0.021453
 38190/100000: episode: 4821, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000200, mae: 0.011053, mean_q: 0.017280
[Info] 2-TH LEVEL FOUND: 0.059154536575078964, Considering 15/100 traces
 38197/100000: episode: 4822, duration: 0.658s, episode steps: 7, steps per second: 11, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000279, mae: 0.012269, mean_q: 0.023194
 38203/100000: episode: 4823, duration: 0.032s, episode steps: 6, steps per second: 190, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000205, mae: 0.010235, mean_q: 0.018041
 38209/100000: episode: 4824, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000657, mae: 0.015736, mean_q: 0.017772
 38215/100000: episode: 4825, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000678, mae: 0.012410, mean_q: 0.023877
 38221/100000: episode: 4826, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000429, mae: 0.014885, mean_q: 0.024105
[Info] FALSIFICATION!
 38226/100000: episode: 4827, duration: 0.268s, episode steps: 5, steps per second: 19, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000225, mae: 0.012110, mean_q: 0.018634
 38232/100000: episode: 4828, duration: 0.033s, episode steps: 6, steps per second: 182, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000347, mae: 0.010382, mean_q: 0.020786
 38238/100000: episode: 4829, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001345, mae: 0.016235, mean_q: 0.026785
 38244/100000: episode: 4830, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000296, mae: 0.011479, mean_q: 0.017281
 38250/100000: episode: 4831, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000324, mae: 0.012782, mean_q: 0.018348
 38256/100000: episode: 4832, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000227, mae: 0.011204, mean_q: 0.015956
 38262/100000: episode: 4833, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000271, mae: 0.010830, mean_q: 0.013217
 38268/100000: episode: 4834, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000936, mae: 0.015710, mean_q: 0.022091
 38274/100000: episode: 4835, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000973, mae: 0.014899, mean_q: 0.026237
 38280/100000: episode: 4836, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000416, mae: 0.011856, mean_q: 0.023589
 38286/100000: episode: 4837, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000819, mae: 0.014694, mean_q: 0.019817
 38292/100000: episode: 4838, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000681, mae: 0.016691, mean_q: 0.018724
 38298/100000: episode: 4839, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000723, mae: 0.015861, mean_q: 0.012314
 38304/100000: episode: 4840, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000203, mae: 0.009561, mean_q: 0.013685
 38310/100000: episode: 4841, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001190, mae: 0.015753, mean_q: 0.016315
 38316/100000: episode: 4842, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000537, mae: 0.016033, mean_q: 0.019361
 38322/100000: episode: 4843, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000817, mae: 0.018140, mean_q: 0.025654
 38328/100000: episode: 4844, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001816, mae: 0.021791, mean_q: 0.029058
 38334/100000: episode: 4845, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000432, mae: 0.014983, mean_q: 0.024143
 38340/100000: episode: 4846, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000664, mae: 0.016214, mean_q: 0.021667
 38346/100000: episode: 4847, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000279, mae: 0.010869, mean_q: 0.013319
 38352/100000: episode: 4848, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000278, mae: 0.011839, mean_q: 0.014965
 38358/100000: episode: 4849, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000232, mae: 0.011261, mean_q: 0.017986
 38364/100000: episode: 4850, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000797, mae: 0.018160, mean_q: 0.021639
[Info] FALSIFICATION!
 38369/100000: episode: 4851, duration: 0.181s, episode steps: 5, steps per second: 28, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000312, mae: 0.011077, mean_q: 0.017082
 38375/100000: episode: 4852, duration: 0.031s, episode steps: 6, steps per second: 191, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000879, mae: 0.017388, mean_q: 0.032062
 38381/100000: episode: 4853, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000360, mae: 0.012394, mean_q: 0.019479
 38387/100000: episode: 4854, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000358, mae: 0.014575, mean_q: 0.020997
 38393/100000: episode: 4855, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000704, mae: 0.014749, mean_q: 0.019814
 38399/100000: episode: 4856, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000264, mae: 0.011657, mean_q: 0.017186
 38405/100000: episode: 4857, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000188, mae: 0.009550, mean_q: 0.013735
 38411/100000: episode: 4858, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000623, mae: 0.012503, mean_q: 0.018559
 38417/100000: episode: 4859, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000516, mae: 0.014650, mean_q: 0.021266
 38423/100000: episode: 4860, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001332, mae: 0.019978, mean_q: 0.028393
 38429/100000: episode: 4861, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000346, mae: 0.014246, mean_q: 0.018987
 38435/100000: episode: 4862, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000503, mae: 0.014719, mean_q: 0.028430
 38441/100000: episode: 4863, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001124, mae: 0.018561, mean_q: 0.027438
 38447/100000: episode: 4864, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001950, mae: 0.022340, mean_q: 0.037820
 38453/100000: episode: 4865, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000405, mae: 0.012158, mean_q: 0.019336
 38459/100000: episode: 4866, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000863, mae: 0.017088, mean_q: 0.033159
 38465/100000: episode: 4867, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000457, mae: 0.014785, mean_q: 0.018331
 38471/100000: episode: 4868, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000196, mae: 0.010747, mean_q: 0.013503
 38477/100000: episode: 4869, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000611, mae: 0.013769, mean_q: 0.014121
 38483/100000: episode: 4870, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001019, mae: 0.016160, mean_q: 0.026523
 38489/100000: episode: 4871, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001136, mae: 0.017100, mean_q: 0.022671
 38495/100000: episode: 4872, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000523, mae: 0.011235, mean_q: 0.015799
 38501/100000: episode: 4873, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001908, mae: 0.020368, mean_q: 0.022935
 38507/100000: episode: 4874, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000982, mae: 0.018658, mean_q: 0.033340
 38513/100000: episode: 4875, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001290, mae: 0.018680, mean_q: 0.033615
 38519/100000: episode: 4876, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001052, mae: 0.018900, mean_q: 0.018990
 38525/100000: episode: 4877, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001412, mae: 0.019995, mean_q: 0.026370
 38531/100000: episode: 4878, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001728, mae: 0.021603, mean_q: 0.033216
 38537/100000: episode: 4879, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000851, mae: 0.017674, mean_q: 0.027340
 38543/100000: episode: 4880, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001159, mae: 0.018820, mean_q: 0.029624
 38549/100000: episode: 4881, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000872, mae: 0.017256, mean_q: 0.022653
 38555/100000: episode: 4882, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000383, mae: 0.010736, mean_q: 0.016753
 38561/100000: episode: 4883, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000194, mae: 0.010909, mean_q: 0.022310
 38567/100000: episode: 4884, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000906, mae: 0.018544, mean_q: 0.029206
 38573/100000: episode: 4885, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000392, mae: 0.016193, mean_q: 0.029844
 38579/100000: episode: 4886, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000582, mae: 0.013716, mean_q: 0.018286
 38585/100000: episode: 4887, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002490, mae: 0.014956, mean_q: 0.016016
[Info] FALSIFICATION!
 38590/100000: episode: 4888, duration: 0.269s, episode steps: 5, steps per second: 19, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000739, mae: 0.015432, mean_q: 0.027217
 38596/100000: episode: 4889, duration: 0.032s, episode steps: 6, steps per second: 186, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001165, mae: 0.019826, mean_q: 0.035109
 38602/100000: episode: 4890, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001097, mae: 0.019384, mean_q: 0.026683
 38608/100000: episode: 4891, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000540, mae: 0.013155, mean_q: 0.014747
 38614/100000: episode: 4892, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000506, mae: 0.013433, mean_q: 0.021335
 38620/100000: episode: 4893, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000732, mae: 0.016642, mean_q: 0.024828
 38626/100000: episode: 4894, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001153, mae: 0.020531, mean_q: 0.027420
 38632/100000: episode: 4895, duration: 0.029s, episode steps: 6, steps per second: 210, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.003379, mae: 0.024693, mean_q: 0.030825
 38638/100000: episode: 4896, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000382, mae: 0.016889, mean_q: 0.028181
 38644/100000: episode: 4897, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000836, mae: 0.016430, mean_q: 0.026089
 38650/100000: episode: 4898, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001000, mae: 0.019216, mean_q: 0.028984
 38656/100000: episode: 4899, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001505, mae: 0.017930, mean_q: 0.027189
 38662/100000: episode: 4900, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000961, mae: 0.015620, mean_q: 0.026180
 38668/100000: episode: 4901, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000725, mae: 0.017666, mean_q: 0.027488
 38674/100000: episode: 4902, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001417, mae: 0.023331, mean_q: 0.029389
 38680/100000: episode: 4903, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000678, mae: 0.017168, mean_q: 0.013681
 38686/100000: episode: 4904, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001831, mae: 0.023468, mean_q: 0.030687
 38692/100000: episode: 4905, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001516, mae: 0.025215, mean_q: 0.046440
 38698/100000: episode: 4906, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000388, mae: 0.015309, mean_q: 0.022206
[Info] Complete ISplit Iteration
[Info] Levels: [0.031945996, 0.059154537, 0.97920066]
[Info] Cond. Prob: [0.12, 0.15, 0.03]
[Info] Error Prob: 0.0005399999999999999

 38704/100000: episode: 4907, duration: 0.872s, episode steps: 6, steps per second: 7, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000648, mae: 0.016493, mean_q: 0.021432
 38714/100000: episode: 4908, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000996, mae: 0.020997, mean_q: 0.034175
 38724/100000: episode: 4909, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000713, mae: 0.016699, mean_q: 0.026622
 38734/100000: episode: 4910, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000898, mae: 0.015667, mean_q: 0.022147
 38744/100000: episode: 4911, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000661, mae: 0.015644, mean_q: 0.022565
 38754/100000: episode: 4912, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000587, mae: 0.014970, mean_q: 0.023209
 38764/100000: episode: 4913, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000725, mae: 0.017654, mean_q: 0.028093
 38774/100000: episode: 4914, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001374, mae: 0.022882, mean_q: 0.034282
 38784/100000: episode: 4915, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001389, mae: 0.022340, mean_q: 0.039053
 38794/100000: episode: 4916, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000777, mae: 0.018501, mean_q: 0.026073
 38804/100000: episode: 4917, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001693, mae: 0.019808, mean_q: 0.027164
 38814/100000: episode: 4918, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000598, mae: 0.018183, mean_q: 0.030797
 38824/100000: episode: 4919, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000840, mae: 0.017330, mean_q: 0.030481
 38834/100000: episode: 4920, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001438, mae: 0.023149, mean_q: 0.033080
 38844/100000: episode: 4921, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001268, mae: 0.019197, mean_q: 0.034126
 38854/100000: episode: 4922, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001064, mae: 0.017412, mean_q: 0.026765
 38864/100000: episode: 4923, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001131, mae: 0.020536, mean_q: 0.032480
 38874/100000: episode: 4924, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000930, mae: 0.017782, mean_q: 0.031061
 38884/100000: episode: 4925, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000747, mae: 0.017240, mean_q: 0.030883
 38894/100000: episode: 4926, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000621, mae: 0.015941, mean_q: 0.024660
 38904/100000: episode: 4927, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001364, mae: 0.019628, mean_q: 0.029237
 38914/100000: episode: 4928, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000781, mae: 0.016086, mean_q: 0.024403
 38924/100000: episode: 4929, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000510, mae: 0.014227, mean_q: 0.017554
 38934/100000: episode: 4930, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000772, mae: 0.016308, mean_q: 0.028161
 38944/100000: episode: 4931, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000730, mae: 0.016174, mean_q: 0.024129
 38954/100000: episode: 4932, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000550, mae: 0.014875, mean_q: 0.023055
 38964/100000: episode: 4933, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001480, mae: 0.020649, mean_q: 0.029273
 38974/100000: episode: 4934, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001118, mae: 0.019240, mean_q: 0.032689
 38984/100000: episode: 4935, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000957, mae: 0.017135, mean_q: 0.032210
 38994/100000: episode: 4936, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000570, mae: 0.015622, mean_q: 0.018872
 39004/100000: episode: 4937, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001274, mae: 0.019011, mean_q: 0.035681
 39014/100000: episode: 4938, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001079, mae: 0.018100, mean_q: 0.027715
 39024/100000: episode: 4939, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000720, mae: 0.015245, mean_q: 0.020715
 39034/100000: episode: 4940, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001017, mae: 0.018440, mean_q: 0.027572
 39044/100000: episode: 4941, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001473, mae: 0.018694, mean_q: 0.028107
 39054/100000: episode: 4942, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001586, mae: 0.019135, mean_q: 0.028655
 39064/100000: episode: 4943, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001387, mae: 0.021959, mean_q: 0.035699
 39074/100000: episode: 4944, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000545, mae: 0.015995, mean_q: 0.023832
 39084/100000: episode: 4945, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000490, mae: 0.013956, mean_q: 0.025233
 39094/100000: episode: 4946, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000958, mae: 0.017587, mean_q: 0.022452
 39104/100000: episode: 4947, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000932, mae: 0.015070, mean_q: 0.021980
 39114/100000: episode: 4948, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001694, mae: 0.021243, mean_q: 0.036588
 39124/100000: episode: 4949, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001184, mae: 0.019205, mean_q: 0.032266
 39134/100000: episode: 4950, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001079, mae: 0.018507, mean_q: 0.023372
 39144/100000: episode: 4951, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000852, mae: 0.016482, mean_q: 0.025100
 39154/100000: episode: 4952, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001007, mae: 0.017529, mean_q: 0.029188
 39164/100000: episode: 4953, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001590, mae: 0.019098, mean_q: 0.026717
 39174/100000: episode: 4954, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000377, mae: 0.013581, mean_q: 0.017871
 39184/100000: episode: 4955, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001112, mae: 0.018431, mean_q: 0.034615
 39194/100000: episode: 4956, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.001052, mae: 0.017355, mean_q: 0.030331
 39204/100000: episode: 4957, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001004, mae: 0.016522, mean_q: 0.031316
 39214/100000: episode: 4958, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001202, mae: 0.019758, mean_q: 0.029239
 39224/100000: episode: 4959, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000715, mae: 0.013230, mean_q: 0.020101
 39234/100000: episode: 4960, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000271, mae: 0.009755, mean_q: 0.015176
 39244/100000: episode: 4961, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001286, mae: 0.014200, mean_q: 0.018523
 39254/100000: episode: 4962, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002081, mae: 0.021862, mean_q: 0.037814
 39264/100000: episode: 4963, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000733, mae: 0.015219, mean_q: 0.017760
 39274/100000: episode: 4964, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002408, mae: 0.016836, mean_q: 0.015993
 39284/100000: episode: 4965, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000867, mae: 0.018142, mean_q: 0.034419
 39294/100000: episode: 4966, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000726, mae: 0.016531, mean_q: 0.023600
 39304/100000: episode: 4967, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000427, mae: 0.013609, mean_q: 0.019287
 39314/100000: episode: 4968, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000748, mae: 0.013959, mean_q: 0.016637
 39324/100000: episode: 4969, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000722, mae: 0.017283, mean_q: 0.025468
 39334/100000: episode: 4970, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000658, mae: 0.016459, mean_q: 0.027885
 39344/100000: episode: 4971, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000347, mae: 0.011506, mean_q: 0.018665
 39354/100000: episode: 4972, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000323, mae: 0.012115, mean_q: 0.019632
 39364/100000: episode: 4973, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001374, mae: 0.018334, mean_q: 0.024795
 39374/100000: episode: 4974, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000685, mae: 0.013422, mean_q: 0.021643
 39384/100000: episode: 4975, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000905, mae: 0.017155, mean_q: 0.030605
 39394/100000: episode: 4976, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000513, mae: 0.013584, mean_q: 0.014700
 39404/100000: episode: 4977, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000514, mae: 0.012349, mean_q: 0.014620
 39414/100000: episode: 4978, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000589, mae: 0.016046, mean_q: 0.022409
 39424/100000: episode: 4979, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000302, mae: 0.012700, mean_q: 0.019872
 39434/100000: episode: 4980, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000712, mae: 0.014055, mean_q: 0.023376
 39444/100000: episode: 4981, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000736, mae: 0.014912, mean_q: 0.025324
 39454/100000: episode: 4982, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000570, mae: 0.014041, mean_q: 0.023182
 39464/100000: episode: 4983, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000592, mae: 0.012093, mean_q: 0.016176
 39474/100000: episode: 4984, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000955, mae: 0.015756, mean_q: 0.020809
 39484/100000: episode: 4985, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000570, mae: 0.013743, mean_q: 0.022605
 39494/100000: episode: 4986, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000461, mae: 0.013394, mean_q: 0.020899
 39504/100000: episode: 4987, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000483, mae: 0.013696, mean_q: 0.024221
 39514/100000: episode: 4988, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000732, mae: 0.011960, mean_q: 0.017158
 39524/100000: episode: 4989, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000208, mae: 0.009441, mean_q: 0.016495
 39534/100000: episode: 4990, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000499, mae: 0.012113, mean_q: 0.014248
 39544/100000: episode: 4991, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000631, mae: 0.013814, mean_q: 0.016725
 39554/100000: episode: 4992, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000310, mae: 0.011275, mean_q: 0.015516
 39564/100000: episode: 4993, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000461, mae: 0.014780, mean_q: 0.023862
 39574/100000: episode: 4994, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000628, mae: 0.013474, mean_q: 0.019819
 39584/100000: episode: 4995, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001156, mae: 0.015574, mean_q: 0.023271
 39594/100000: episode: 4996, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000629, mae: 0.012146, mean_q: 0.020203
 39604/100000: episode: 4997, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001254, mae: 0.017591, mean_q: 0.027375
 39614/100000: episode: 4998, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000781, mae: 0.015798, mean_q: 0.028958
 39624/100000: episode: 4999, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000294, mae: 0.010334, mean_q: 0.013842
 39634/100000: episode: 5000, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000412, mae: 0.011634, mean_q: 0.016262
 39644/100000: episode: 5001, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001595, mae: 0.013671, mean_q: 0.016555
 39654/100000: episode: 5002, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000262, mae: 0.012725, mean_q: 0.018507
 39664/100000: episode: 5003, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001406, mae: 0.019355, mean_q: 0.027398
 39674/100000: episode: 5004, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000398, mae: 0.012259, mean_q: 0.020940
 39684/100000: episode: 5005, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000699, mae: 0.012663, mean_q: 0.016479
 39694/100000: episode: 5006, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000596, mae: 0.013850, mean_q: 0.024250
[Info] 1-TH LEVEL FOUND: 0.026479871943593025, Considering 11/100 traces
 39704/100000: episode: 5007, duration: 0.693s, episode steps: 10, steps per second: 14, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000729, mae: 0.011405, mean_q: 0.015806
 39709/100000: episode: 5008, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000628, mae: 0.016362, mean_q: 0.022828
 39714/100000: episode: 5009, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000485, mae: 0.012430, mean_q: 0.024497
 39719/100000: episode: 5010, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000179, mae: 0.010109, mean_q: 0.015618
 39724/100000: episode: 5011, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000096, mae: 0.007822, mean_q: 0.013647
 39731/100000: episode: 5012, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 1.947, mean reward: 0.278 [0.007, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 7.857 [5.000, 11.000], loss: 0.000657, mae: 0.010778, mean_q: 0.015932
 39736/100000: episode: 5013, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000483, mae: 0.011159, mean_q: 0.021967
 39741/100000: episode: 5014, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000188, mae: 0.009455, mean_q: 0.011893
 39746/100000: episode: 5015, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000981, mae: 0.014878, mean_q: 0.025674
 39753/100000: episode: 5016, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000272, mae: 0.010459, mean_q: 0.016789
 39760/100000: episode: 5017, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000434, mae: 0.012062, mean_q: 0.021219
 39767/100000: episode: 5018, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001277, mae: 0.015778, mean_q: 0.023347
 39772/100000: episode: 5019, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000280, mae: 0.009681, mean_q: 0.019998
 39777/100000: episode: 5020, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000186, mae: 0.007714, mean_q: 0.011534
 39784/100000: episode: 5021, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000791, mae: 0.013507, mean_q: 0.013834
 39791/100000: episode: 5022, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000211, mae: 0.010036, mean_q: 0.012547
 39796/100000: episode: 5023, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000180, mae: 0.009008, mean_q: 0.014295
 39801/100000: episode: 5024, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001528, mae: 0.017566, mean_q: 0.025707
 39806/100000: episode: 5025, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000698, mae: 0.014182, mean_q: 0.019731
 39811/100000: episode: 5026, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001142, mae: 0.015842, mean_q: 0.026806
 39816/100000: episode: 5027, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000419, mae: 0.012276, mean_q: 0.013240
 39823/100000: episode: 5028, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000782, mae: 0.012393, mean_q: 0.015325
 39830/100000: episode: 5029, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000373, mae: 0.010451, mean_q: 0.013261
 39837/100000: episode: 5030, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001128, mae: 0.017444, mean_q: 0.023413
 39842/100000: episode: 5031, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000465, mae: 0.014071, mean_q: 0.027379
 39847/100000: episode: 5032, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000808, mae: 0.017971, mean_q: 0.028697
 39854/100000: episode: 5033, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000780, mae: 0.014383, mean_q: 0.021016
 39861/100000: episode: 5034, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000603, mae: 0.013260, mean_q: 0.013346
 39866/100000: episode: 5035, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000379, mae: 0.011718, mean_q: 0.011934
 39873/100000: episode: 5036, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000637, mae: 0.014163, mean_q: 0.022457
 39880/100000: episode: 5037, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000713, mae: 0.014418, mean_q: 0.021541
 39887/100000: episode: 5038, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000501, mae: 0.013571, mean_q: 0.022959
 39892/100000: episode: 5039, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000657, mae: 0.014944, mean_q: 0.019275
 39897/100000: episode: 5040, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000374, mae: 0.012691, mean_q: 0.021319
 39904/100000: episode: 5041, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000271, mae: 0.011391, mean_q: 0.016637
 39911/100000: episode: 5042, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000474, mae: 0.011528, mean_q: 0.016667
 39916/100000: episode: 5043, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001662, mae: 0.016275, mean_q: 0.024033
 39923/100000: episode: 5044, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000318, mae: 0.012438, mean_q: 0.019016
 39928/100000: episode: 5045, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000465, mae: 0.012581, mean_q: 0.019264
 39933/100000: episode: 5046, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000574, mae: 0.012104, mean_q: 0.019157
 39938/100000: episode: 5047, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000542, mae: 0.012200, mean_q: 0.017509
 39943/100000: episode: 5048, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000269, mae: 0.011200, mean_q: 0.013503
 39948/100000: episode: 5049, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000658, mae: 0.012076, mean_q: 0.018522
 39953/100000: episode: 5050, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001038, mae: 0.020363, mean_q: 0.038209
 39960/100000: episode: 5051, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000332, mae: 0.011794, mean_q: 0.015723
 39965/100000: episode: 5052, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000440, mae: 0.014681, mean_q: 0.021140
 39972/100000: episode: 5053, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000479, mae: 0.012782, mean_q: 0.022257
 39979/100000: episode: 5054, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000405, mae: 0.013236, mean_q: 0.022235
 39984/100000: episode: 5055, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000489, mae: 0.015166, mean_q: 0.028433
 39989/100000: episode: 5056, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.001308, mae: 0.015266, mean_q: 0.020396
 39994/100000: episode: 5057, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.001793, mae: 0.018419, mean_q: 0.026594
 40001/100000: episode: 5058, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000841, mae: 0.016751, mean_q: 0.022363
 40008/100000: episode: 5059, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001072, mae: 0.014991, mean_q: 0.023353
 40015/100000: episode: 5060, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000497, mae: 0.014859, mean_q: 0.020007
 40022/100000: episode: 5061, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000984, mae: 0.017036, mean_q: 0.024871
 40027/100000: episode: 5062, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000205, mae: 0.009314, mean_q: 0.018841
 40032/100000: episode: 5063, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.001076, mae: 0.018846, mean_q: 0.032929
 40037/100000: episode: 5064, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000758, mae: 0.014639, mean_q: 0.022851
 40042/100000: episode: 5065, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.001276, mae: 0.017170, mean_q: 0.028830
 40047/100000: episode: 5066, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000279, mae: 0.011741, mean_q: 0.017558
 40052/100000: episode: 5067, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000378, mae: 0.011986, mean_q: 0.015420
 40059/100000: episode: 5068, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000898, mae: 0.015010, mean_q: 0.020090
 40066/100000: episode: 5069, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001008, mae: 0.018577, mean_q: 0.029622
 40071/100000: episode: 5070, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000650, mae: 0.015749, mean_q: 0.025616
 40076/100000: episode: 5071, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000513, mae: 0.014589, mean_q: 0.030733
 40081/100000: episode: 5072, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000318, mae: 0.012064, mean_q: 0.026864
 40086/100000: episode: 5073, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000229, mae: 0.010524, mean_q: 0.013909
 40091/100000: episode: 5074, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000193, mae: 0.009953, mean_q: 0.014530
 40098/100000: episode: 5075, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000190, mae: 0.009799, mean_q: 0.011113
 40105/100000: episode: 5076, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000500, mae: 0.012580, mean_q: 0.017434
 40112/100000: episode: 5077, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000780, mae: 0.014672, mean_q: 0.017951
 40117/100000: episode: 5078, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.001789, mae: 0.017123, mean_q: 0.025281
 40124/100000: episode: 5079, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000582, mae: 0.015991, mean_q: 0.023780
 40131/100000: episode: 5080, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000836, mae: 0.017412, mean_q: 0.026868
 40136/100000: episode: 5081, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.001755, mae: 0.021881, mean_q: 0.036019
 40141/100000: episode: 5082, duration: 0.024s, episode steps: 5, steps per second: 205, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000506, mae: 0.012354, mean_q: 0.023600
 40146/100000: episode: 5083, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000916, mae: 0.015585, mean_q: 0.026631
 40151/100000: episode: 5084, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.001876, mae: 0.019896, mean_q: 0.022551
 40158/100000: episode: 5085, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000246, mae: 0.010060, mean_q: 0.015783
 40165/100000: episode: 5086, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000957, mae: 0.015644, mean_q: 0.029795
 40170/100000: episode: 5087, duration: 0.024s, episode steps: 5, steps per second: 205, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000425, mae: 0.012273, mean_q: 0.020007
 40177/100000: episode: 5088, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000352, mae: 0.012452, mean_q: 0.019116
 40184/100000: episode: 5089, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000589, mae: 0.011553, mean_q: 0.015381
 40191/100000: episode: 5090, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000692, mae: 0.015426, mean_q: 0.025792
 40198/100000: episode: 5091, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000197, mae: 0.010142, mean_q: 0.016351
 40203/100000: episode: 5092, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001954, mae: 0.019977, mean_q: 0.023687
 40210/100000: episode: 5093, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000629, mae: 0.016991, mean_q: 0.031921
 40217/100000: episode: 5094, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000386, mae: 0.013660, mean_q: 0.027775
 40222/100000: episode: 5095, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000849, mae: 0.014692, mean_q: 0.024508
[Info] 2-TH LEVEL FOUND: 0.06311678141355515, Considering 16/100 traces
 40227/100000: episode: 5096, duration: 0.698s, episode steps: 5, steps per second: 7, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000208, mae: 0.010550, mean_q: 0.016552
 40233/100000: episode: 5097, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000469, mae: 0.012984, mean_q: 0.022776
 40239/100000: episode: 5098, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000342, mae: 0.012897, mean_q: 0.019115
 40245/100000: episode: 5099, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001362, mae: 0.015895, mean_q: 0.027176
 40251/100000: episode: 5100, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000886, mae: 0.013484, mean_q: 0.022320
 40257/100000: episode: 5101, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000174, mae: 0.009288, mean_q: 0.013936
 40263/100000: episode: 5102, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000437, mae: 0.011091, mean_q: 0.013246
 40269/100000: episode: 5103, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000174, mae: 0.008903, mean_q: 0.016325
 40275/100000: episode: 5104, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000844, mae: 0.015724, mean_q: 0.030538
 40281/100000: episode: 5105, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000815, mae: 0.017245, mean_q: 0.030468
 40287/100000: episode: 5106, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000482, mae: 0.015704, mean_q: 0.031821
 40293/100000: episode: 5107, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000858, mae: 0.015219, mean_q: 0.021585
 40299/100000: episode: 5108, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001140, mae: 0.017232, mean_q: 0.025788
 40305/100000: episode: 5109, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000615, mae: 0.015747, mean_q: 0.025856
 40311/100000: episode: 5110, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000760, mae: 0.015457, mean_q: 0.031139
 40317/100000: episode: 5111, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000380, mae: 0.012112, mean_q: 0.023092
 40323/100000: episode: 5112, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000342, mae: 0.012238, mean_q: 0.016672
 40329/100000: episode: 5113, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000630, mae: 0.016408, mean_q: 0.021144
 40335/100000: episode: 5114, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000355, mae: 0.012858, mean_q: 0.013301
 40341/100000: episode: 5115, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000422, mae: 0.012081, mean_q: 0.023005
 40347/100000: episode: 5116, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000252, mae: 0.011667, mean_q: 0.017571
 40353/100000: episode: 5117, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000372, mae: 0.014174, mean_q: 0.023459
 40359/100000: episode: 5118, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001195, mae: 0.019176, mean_q: 0.034210
 40365/100000: episode: 5119, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000623, mae: 0.016072, mean_q: 0.022734
 40371/100000: episode: 5120, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000631, mae: 0.014610, mean_q: 0.021393
 40377/100000: episode: 5121, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000627, mae: 0.012423, mean_q: 0.018865
 40383/100000: episode: 5122, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000556, mae: 0.013938, mean_q: 0.020182
 40389/100000: episode: 5123, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000598, mae: 0.015305, mean_q: 0.020863
 40395/100000: episode: 5124, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000756, mae: 0.015410, mean_q: 0.021974
 40401/100000: episode: 5125, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002008, mae: 0.019469, mean_q: 0.023353
[Info] FALSIFICATION!
 40406/100000: episode: 5126, duration: 0.269s, episode steps: 5, steps per second: 19, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000873, mae: 0.015553, mean_q: 0.024343
 40412/100000: episode: 5127, duration: 0.032s, episode steps: 6, steps per second: 187, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001185, mae: 0.019223, mean_q: 0.029942
 40418/100000: episode: 5128, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000656, mae: 0.016694, mean_q: 0.028703
 40424/100000: episode: 5129, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000365, mae: 0.013255, mean_q: 0.019209
 40430/100000: episode: 5130, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000354, mae: 0.013974, mean_q: 0.019854
 40436/100000: episode: 5131, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001061, mae: 0.016389, mean_q: 0.035372
 40442/100000: episode: 5132, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000599, mae: 0.016425, mean_q: 0.027377
 40448/100000: episode: 5133, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000549, mae: 0.012047, mean_q: 0.016956
 40454/100000: episode: 5134, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000677, mae: 0.015294, mean_q: 0.022873
 40460/100000: episode: 5135, duration: 0.028s, episode steps: 6, steps per second: 212, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000571, mae: 0.015334, mean_q: 0.022571
 40466/100000: episode: 5136, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001108, mae: 0.017180, mean_q: 0.025193
 40472/100000: episode: 5137, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001208, mae: 0.018037, mean_q: 0.031594
 40478/100000: episode: 5138, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001355, mae: 0.018279, mean_q: 0.030526
 40484/100000: episode: 5139, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000294, mae: 0.012126, mean_q: 0.018937
 40490/100000: episode: 5140, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000617, mae: 0.016243, mean_q: 0.024715
 40496/100000: episode: 5141, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000614, mae: 0.014402, mean_q: 0.022512
 40502/100000: episode: 5142, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001179, mae: 0.020033, mean_q: 0.037313
 40508/100000: episode: 5143, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000419, mae: 0.011540, mean_q: 0.019724
 40514/100000: episode: 5144, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000844, mae: 0.015654, mean_q: 0.021025
 40520/100000: episode: 5145, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000685, mae: 0.016812, mean_q: 0.026010
 40526/100000: episode: 5146, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001195, mae: 0.020785, mean_q: 0.035752
 40532/100000: episode: 5147, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000460, mae: 0.014797, mean_q: 0.024211
 40538/100000: episode: 5148, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000388, mae: 0.014994, mean_q: 0.026370
 40544/100000: episode: 5149, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000932, mae: 0.014774, mean_q: 0.022301
 40550/100000: episode: 5150, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000385, mae: 0.011543, mean_q: 0.019438
 40556/100000: episode: 5151, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001140, mae: 0.017672, mean_q: 0.036937
 40562/100000: episode: 5152, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000385, mae: 0.011517, mean_q: 0.025073
 40568/100000: episode: 5153, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000462, mae: 0.014581, mean_q: 0.028097
 40574/100000: episode: 5154, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001607, mae: 0.019477, mean_q: 0.033918
 40580/100000: episode: 5155, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.001806, mae: 0.023595, mean_q: 0.032005
 40586/100000: episode: 5156, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001086, mae: 0.019723, mean_q: 0.042067
 40592/100000: episode: 5157, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000570, mae: 0.016556, mean_q: 0.026151
 40598/100000: episode: 5158, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001239, mae: 0.018598, mean_q: 0.028848
[Info] FALSIFICATION!
 40603/100000: episode: 5159, duration: 0.180s, episode steps: 5, steps per second: 28, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.001088, mae: 0.017815, mean_q: 0.016452
 40609/100000: episode: 5160, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001037, mae: 0.018913, mean_q: 0.017962
 40615/100000: episode: 5161, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.003202, mae: 0.024630, mean_q: 0.028294
 40621/100000: episode: 5162, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001206, mae: 0.024552, mean_q: 0.035461
 40627/100000: episode: 5163, duration: 0.031s, episode steps: 6, steps per second: 197, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002035, mae: 0.027928, mean_q: 0.052401
 40633/100000: episode: 5164, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000672, mae: 0.017013, mean_q: 0.027426
 40639/100000: episode: 5165, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000706, mae: 0.018632, mean_q: 0.029045
 40645/100000: episode: 5166, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001320, mae: 0.021747, mean_q: 0.031018
 40651/100000: episode: 5167, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000925, mae: 0.020246, mean_q: 0.026279
 40657/100000: episode: 5168, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000771, mae: 0.020717, mean_q: 0.030875
 40663/100000: episode: 5169, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000985, mae: 0.020510, mean_q: 0.036797
 40669/100000: episode: 5170, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001370, mae: 0.018573, mean_q: 0.024325
 40675/100000: episode: 5171, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000729, mae: 0.016537, mean_q: 0.022507
 40681/100000: episode: 5172, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000725, mae: 0.014970, mean_q: 0.030202
 40687/100000: episode: 5173, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001103, mae: 0.020221, mean_q: 0.025584
 40693/100000: episode: 5174, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001311, mae: 0.018985, mean_q: 0.021615
 40699/100000: episode: 5175, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000725, mae: 0.015769, mean_q: 0.022985
 40705/100000: episode: 5176, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000692, mae: 0.017608, mean_q: 0.032147
 40711/100000: episode: 5177, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000994, mae: 0.019028, mean_q: 0.029705
 40717/100000: episode: 5178, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000812, mae: 0.017522, mean_q: 0.030677
 40723/100000: episode: 5179, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000877, mae: 0.014230, mean_q: 0.025443
[Info] Complete ISplit Iteration
[Info] Levels: [0.026479872, 0.06311678, 1.1624707]
[Info] Cond. Prob: [0.11, 0.16, 0.04]
[Info] Error Prob: 0.0007040000000000001

 40729/100000: episode: 5180, duration: 0.873s, episode steps: 6, steps per second: 7, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001592, mae: 0.019457, mean_q: 0.029467
 40739/100000: episode: 5181, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000651, mae: 0.014813, mean_q: 0.020351
 40749/100000: episode: 5182, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000822, mae: 0.019087, mean_q: 0.032399
 40759/100000: episode: 5183, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002117, mae: 0.024768, mean_q: 0.041500
 40769/100000: episode: 5184, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000545, mae: 0.013844, mean_q: 0.018187
 40779/100000: episode: 5185, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001674, mae: 0.022015, mean_q: 0.038366
 40789/100000: episode: 5186, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001049, mae: 0.014818, mean_q: 0.021144
 40799/100000: episode: 5187, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000827, mae: 0.018824, mean_q: 0.025100
 40809/100000: episode: 5188, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000853, mae: 0.017554, mean_q: 0.029312
 40819/100000: episode: 5189, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000981, mae: 0.017213, mean_q: 0.026011
 40829/100000: episode: 5190, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000906, mae: 0.015769, mean_q: 0.024897
 40839/100000: episode: 5191, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001697, mae: 0.021412, mean_q: 0.032465
 40849/100000: episode: 5192, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000776, mae: 0.018414, mean_q: 0.028713
 40859/100000: episode: 5193, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000963, mae: 0.017095, mean_q: 0.024179
 40869/100000: episode: 5194, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000778, mae: 0.015001, mean_q: 0.022489
 40879/100000: episode: 5195, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000991, mae: 0.016710, mean_q: 0.024431
 40889/100000: episode: 5196, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000707, mae: 0.016730, mean_q: 0.029560
 40899/100000: episode: 5197, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001815, mae: 0.023676, mean_q: 0.042544
 40909/100000: episode: 5198, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000812, mae: 0.015409, mean_q: 0.022021
 40919/100000: episode: 5199, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001938, mae: 0.022262, mean_q: 0.033924
 40929/100000: episode: 5200, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000536, mae: 0.014953, mean_q: 0.024501
 40939/100000: episode: 5201, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000454, mae: 0.013476, mean_q: 0.019024
 40949/100000: episode: 5202, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000343, mae: 0.012424, mean_q: 0.018951
 40959/100000: episode: 5203, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000771, mae: 0.015720, mean_q: 0.024005
 40969/100000: episode: 5204, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001738, mae: 0.023377, mean_q: 0.037540
 40979/100000: episode: 5205, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000568, mae: 0.015417, mean_q: 0.029233
 40989/100000: episode: 5206, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000418, mae: 0.012475, mean_q: 0.017658
 40999/100000: episode: 5207, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000677, mae: 0.015388, mean_q: 0.023954
 41009/100000: episode: 5208, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001428, mae: 0.021884, mean_q: 0.034904
 41019/100000: episode: 5209, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000654, mae: 0.016462, mean_q: 0.030025
 41029/100000: episode: 5210, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000870, mae: 0.016566, mean_q: 0.031197
 41039/100000: episode: 5211, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000506, mae: 0.012071, mean_q: 0.019395
 41049/100000: episode: 5212, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001416, mae: 0.017542, mean_q: 0.029017
 41059/100000: episode: 5213, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001060, mae: 0.014841, mean_q: 0.021263
 41069/100000: episode: 5214, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000550, mae: 0.013774, mean_q: 0.021272
 41079/100000: episode: 5215, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000648, mae: 0.016071, mean_q: 0.026762
 41089/100000: episode: 5216, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000561, mae: 0.015422, mean_q: 0.027812
 41099/100000: episode: 5217, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000640, mae: 0.016001, mean_q: 0.027598
 41109/100000: episode: 5218, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001500, mae: 0.018427, mean_q: 0.028188
 41119/100000: episode: 5219, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000696, mae: 0.016483, mean_q: 0.024342
 41129/100000: episode: 5220, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000541, mae: 0.013590, mean_q: 0.020369
 41139/100000: episode: 5221, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000743, mae: 0.015173, mean_q: 0.024228
 41149/100000: episode: 5222, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000921, mae: 0.018435, mean_q: 0.023903
 41159/100000: episode: 5223, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000342, mae: 0.015465, mean_q: 0.025567
 41169/100000: episode: 5224, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000996, mae: 0.014065, mean_q: 0.024951
 41179/100000: episode: 5225, duration: 0.084s, episode steps: 10, steps per second: 118, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001199, mae: 0.016285, mean_q: 0.025697
 41189/100000: episode: 5226, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000703, mae: 0.013929, mean_q: 0.021066
 41199/100000: episode: 5227, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001844, mae: 0.018709, mean_q: 0.028986
 41209/100000: episode: 5228, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000726, mae: 0.014715, mean_q: 0.014591
 41219/100000: episode: 5229, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001017, mae: 0.018205, mean_q: 0.029759
 41229/100000: episode: 5230, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000997, mae: 0.019328, mean_q: 0.034661
 41239/100000: episode: 5231, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000672, mae: 0.013478, mean_q: 0.023968
 41249/100000: episode: 5232, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000608, mae: 0.012873, mean_q: 0.017468
 41259/100000: episode: 5233, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000809, mae: 0.013620, mean_q: 0.024109
 41269/100000: episode: 5234, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000471, mae: 0.012918, mean_q: 0.019869
 41279/100000: episode: 5235, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001154, mae: 0.018596, mean_q: 0.029895
 41289/100000: episode: 5236, duration: 0.064s, episode steps: 10, steps per second: 155, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001165, mae: 0.016190, mean_q: 0.032088
 41299/100000: episode: 5237, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001564, mae: 0.020192, mean_q: 0.027919
 41309/100000: episode: 5238, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001706, mae: 0.019260, mean_q: 0.019189
 41319/100000: episode: 5239, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001193, mae: 0.019320, mean_q: 0.029297
 41329/100000: episode: 5240, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000803, mae: 0.015491, mean_q: 0.024041
 41339/100000: episode: 5241, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000408, mae: 0.010292, mean_q: 0.015419
 41349/100000: episode: 5242, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001008, mae: 0.016391, mean_q: 0.021231
 41359/100000: episode: 5243, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000694, mae: 0.016531, mean_q: 0.031006
 41369/100000: episode: 5244, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001708, mae: 0.023109, mean_q: 0.036277
 41379/100000: episode: 5245, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000424, mae: 0.012734, mean_q: 0.018266
 41389/100000: episode: 5246, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001301, mae: 0.015825, mean_q: 0.025470
 41399/100000: episode: 5247, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000663, mae: 0.015682, mean_q: 0.028496
 41409/100000: episode: 5248, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000410, mae: 0.012090, mean_q: 0.019127
 41419/100000: episode: 5249, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000831, mae: 0.015514, mean_q: 0.022868
 41429/100000: episode: 5250, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000962, mae: 0.017356, mean_q: 0.025695
 41439/100000: episode: 5251, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001088, mae: 0.017256, mean_q: 0.028183
 41449/100000: episode: 5252, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001148, mae: 0.019140, mean_q: 0.034715
 41459/100000: episode: 5253, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000551, mae: 0.014657, mean_q: 0.024054
 41469/100000: episode: 5254, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000740, mae: 0.013857, mean_q: 0.023594
 41479/100000: episode: 5255, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000683, mae: 0.015709, mean_q: 0.017812
 41489/100000: episode: 5256, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000396, mae: 0.011621, mean_q: 0.012174
 41499/100000: episode: 5257, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000264, mae: 0.013502, mean_q: 0.018856
 41509/100000: episode: 5258, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001244, mae: 0.017540, mean_q: 0.022679
 41519/100000: episode: 5259, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000672, mae: 0.015192, mean_q: 0.022476
 41529/100000: episode: 5260, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000774, mae: 0.015276, mean_q: 0.022229
 41539/100000: episode: 5261, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001368, mae: 0.017898, mean_q: 0.026954
 41549/100000: episode: 5262, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000869, mae: 0.015193, mean_q: 0.027902
 41559/100000: episode: 5263, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000508, mae: 0.013041, mean_q: 0.020144
 41569/100000: episode: 5264, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001000, mae: 0.018674, mean_q: 0.029484
 41579/100000: episode: 5265, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000434, mae: 0.013319, mean_q: 0.025399
 41589/100000: episode: 5266, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000650, mae: 0.013561, mean_q: 0.022699
 41599/100000: episode: 5267, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000966, mae: 0.014114, mean_q: 0.019776
 41609/100000: episode: 5268, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000814, mae: 0.014533, mean_q: 0.018820
 41619/100000: episode: 5269, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000639, mae: 0.014145, mean_q: 0.022683
 41629/100000: episode: 5270, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001310, mae: 0.017358, mean_q: 0.024524
 41639/100000: episode: 5271, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000881, mae: 0.018084, mean_q: 0.034215
 41649/100000: episode: 5272, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000751, mae: 0.012601, mean_q: 0.016647
 41659/100000: episode: 5273, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000681, mae: 0.013329, mean_q: 0.020567
 41669/100000: episode: 5274, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001239, mae: 0.013983, mean_q: 0.021619
 41679/100000: episode: 5275, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000947, mae: 0.016519, mean_q: 0.026454
 41689/100000: episode: 5276, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000669, mae: 0.013249, mean_q: 0.021874
 41699/100000: episode: 5277, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000350, mae: 0.010150, mean_q: 0.019465
 41709/100000: episode: 5278, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001697, mae: 0.016600, mean_q: 0.021511
 41719/100000: episode: 5279, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000974, mae: 0.017098, mean_q: 0.029393
[Info] 1-TH LEVEL FOUND: 0.022380156442523003, Considering 10/100 traces
 41729/100000: episode: 5280, duration: 0.754s, episode steps: 10, steps per second: 13, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000474, mae: 0.013819, mean_q: 0.022279
 41736/100000: episode: 5281, duration: 0.046s, episode steps: 7, steps per second: 153, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000246, mae: 0.010800, mean_q: 0.014846
 41741/100000: episode: 5282, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001647, mae: 0.019179, mean_q: 0.033091
 41746/100000: episode: 5283, duration: 0.030s, episode steps: 5, steps per second: 167, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000895, mae: 0.017144, mean_q: 0.037922
 41753/100000: episode: 5284, duration: 0.038s, episode steps: 7, steps per second: 185, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001434, mae: 0.020622, mean_q: 0.039830
 41760/100000: episode: 5285, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000687, mae: 0.016251, mean_q: 0.022936
 41767/100000: episode: 5286, duration: 0.037s, episode steps: 7, steps per second: 189, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.001065, mae: 0.014785, mean_q: 0.016041
 41774/100000: episode: 5287, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000559, mae: 0.011400, mean_q: 0.014781
 41779/100000: episode: 5288, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001652, mae: 0.017941, mean_q: 0.021849
 41786/100000: episode: 5289, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000600, mae: 0.018455, mean_q: 0.034989
 41793/100000: episode: 5290, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000769, mae: 0.016756, mean_q: 0.029762
 41798/100000: episode: 5291, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000260, mae: 0.011934, mean_q: 0.017397
 41805/100000: episode: 5292, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001034, mae: 0.015848, mean_q: 0.022286
 41812/100000: episode: 5293, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001407, mae: 0.018684, mean_q: 0.023159
 41819/100000: episode: 5294, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000375, mae: 0.011380, mean_q: 0.019177
 41826/100000: episode: 5295, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001052, mae: 0.019885, mean_q: 0.033643
 41831/100000: episode: 5296, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001187, mae: 0.018925, mean_q: 0.034418
 41838/100000: episode: 5297, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.001944, mae: 0.022510, mean_q: 0.039222
 41845/100000: episode: 5298, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000892, mae: 0.015060, mean_q: 0.019928
 41852/100000: episode: 5299, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.001413, mae: 0.018210, mean_q: 0.031448
 41857/100000: episode: 5300, duration: 0.030s, episode steps: 5, steps per second: 165, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001885, mae: 0.024645, mean_q: 0.033091
 41864/100000: episode: 5301, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001231, mae: 0.022394, mean_q: 0.038321
 41871/100000: episode: 5302, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001144, mae: 0.018014, mean_q: 0.028109
 41878/100000: episode: 5303, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001047, mae: 0.017276, mean_q: 0.021941
 41885/100000: episode: 5304, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.001286, mae: 0.020747, mean_q: 0.031286
 41890/100000: episode: 5305, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000915, mae: 0.018748, mean_q: 0.029750
 41895/100000: episode: 5306, duration: 0.037s, episode steps: 5, steps per second: 136, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001017, mae: 0.017877, mean_q: 0.029278
 41900/100000: episode: 5307, duration: 0.043s, episode steps: 5, steps per second: 115, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000533, mae: 0.012907, mean_q: 0.020298
 41907/100000: episode: 5308, duration: 0.045s, episode steps: 7, steps per second: 156, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.001205, mae: 0.014499, mean_q: 0.018592
 41914/100000: episode: 5309, duration: 0.044s, episode steps: 7, steps per second: 159, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000831, mae: 0.016261, mean_q: 0.026261
 41919/100000: episode: 5310, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000625, mae: 0.012563, mean_q: 0.016375
 41926/100000: episode: 5311, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000398, mae: 0.012748, mean_q: 0.021359
 41933/100000: episode: 5312, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000745, mae: 0.015472, mean_q: 0.026934
 41940/100000: episode: 5313, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001187, mae: 0.017265, mean_q: 0.027475
 41947/100000: episode: 5314, duration: 0.057s, episode steps: 7, steps per second: 122, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001004, mae: 0.017286, mean_q: 0.031107
 41952/100000: episode: 5315, duration: 0.035s, episode steps: 5, steps per second: 144, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000835, mae: 0.018865, mean_q: 0.036982
 41957/100000: episode: 5316, duration: 0.061s, episode steps: 5, steps per second: 82, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000354, mae: 0.014340, mean_q: 0.021302
 41962/100000: episode: 5317, duration: 0.064s, episode steps: 5, steps per second: 78, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.001188, mae: 0.021817, mean_q: 0.031541
 41967/100000: episode: 5318, duration: 0.041s, episode steps: 5, steps per second: 123, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.001119, mae: 0.015746, mean_q: 0.021347
 41974/100000: episode: 5319, duration: 0.053s, episode steps: 7, steps per second: 132, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000803, mae: 0.017243, mean_q: 0.018753
 41979/100000: episode: 5320, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000640, mae: 0.014486, mean_q: 0.016726
 41984/100000: episode: 5321, duration: 0.032s, episode steps: 5, steps per second: 158, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000578, mae: 0.015422, mean_q: 0.023014
 41991/100000: episode: 5322, duration: 0.056s, episode steps: 7, steps per second: 124, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.002515, mae: 0.019865, mean_q: 0.026156
 41996/100000: episode: 5323, duration: 0.053s, episode steps: 5, steps per second: 94, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000581, mae: 0.015802, mean_q: 0.029894
 42003/100000: episode: 5324, duration: 0.066s, episode steps: 7, steps per second: 107, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.001060, mae: 0.018849, mean_q: 0.027660
 42010/100000: episode: 5325, duration: 0.040s, episode steps: 7, steps per second: 173, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000163, mae: 0.009018, mean_q: 0.015731
 42015/100000: episode: 5326, duration: 0.034s, episode steps: 5, steps per second: 145, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000880, mae: 0.016938, mean_q: 0.023480
 42020/100000: episode: 5327, duration: 0.041s, episode steps: 5, steps per second: 122, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001385, mae: 0.017745, mean_q: 0.021362
 42027/100000: episode: 5328, duration: 0.067s, episode steps: 7, steps per second: 105, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000381, mae: 0.015393, mean_q: 0.024499
 42032/100000: episode: 5329, duration: 0.049s, episode steps: 5, steps per second: 102, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.001087, mae: 0.018795, mean_q: 0.033314
 42039/100000: episode: 5330, duration: 0.094s, episode steps: 7, steps per second: 75, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.000909, mae: 0.017144, mean_q: 0.031582
 42044/100000: episode: 5331, duration: 0.053s, episode steps: 5, steps per second: 94, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001076, mae: 0.015895, mean_q: 0.020182
 42049/100000: episode: 5332, duration: 0.066s, episode steps: 5, steps per second: 76, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000508, mae: 0.011899, mean_q: 0.020256
[Info] FALSIFICATION!
 42055/100000: episode: 5333, duration: 0.415s, episode steps: 6, steps per second: 14, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.001168, mae: 0.016845, mean_q: 0.026723
 42060/100000: episode: 5334, duration: 0.056s, episode steps: 5, steps per second: 89, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001893, mae: 0.017251, mean_q: 0.024469
 42065/100000: episode: 5335, duration: 0.049s, episode steps: 5, steps per second: 101, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001144, mae: 0.018335, mean_q: 0.031653
 42072/100000: episode: 5336, duration: 0.070s, episode steps: 7, steps per second: 100, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000478, mae: 0.015399, mean_q: 0.026439
 42077/100000: episode: 5337, duration: 0.055s, episode steps: 5, steps per second: 91, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000590, mae: 0.016626, mean_q: 0.026814
 42082/100000: episode: 5338, duration: 0.057s, episode steps: 5, steps per second: 87, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000509, mae: 0.015639, mean_q: 0.026858
 42089/100000: episode: 5339, duration: 0.050s, episode steps: 7, steps per second: 139, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.001640, mae: 0.020952, mean_q: 0.033655
 42096/100000: episode: 5340, duration: 0.069s, episode steps: 7, steps per second: 101, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000542, mae: 0.016303, mean_q: 0.025154
 42103/100000: episode: 5341, duration: 0.091s, episode steps: 7, steps per second: 77, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000824, mae: 0.018068, mean_q: 0.034720
 42108/100000: episode: 5342, duration: 0.057s, episode steps: 5, steps per second: 88, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000612, mae: 0.017187, mean_q: 0.031096
 42115/100000: episode: 5343, duration: 0.082s, episode steps: 7, steps per second: 85, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.001101, mae: 0.017371, mean_q: 0.032402
 42122/100000: episode: 5344, duration: 0.070s, episode steps: 7, steps per second: 100, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001618, mae: 0.021519, mean_q: 0.032735
 42129/100000: episode: 5345, duration: 0.072s, episode steps: 7, steps per second: 98, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.000953, mae: 0.018942, mean_q: 0.022137
 42134/100000: episode: 5346, duration: 0.059s, episode steps: 5, steps per second: 85, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.001283, mae: 0.020490, mean_q: 0.027436
 42141/100000: episode: 5347, duration: 0.081s, episode steps: 7, steps per second: 86, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000368, mae: 0.013479, mean_q: 0.022684
 42148/100000: episode: 5348, duration: 0.060s, episode steps: 7, steps per second: 117, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.001989, mae: 0.018336, mean_q: 0.023732
 42155/100000: episode: 5349, duration: 0.060s, episode steps: 7, steps per second: 117, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001389, mae: 0.024212, mean_q: 0.034579
 42162/100000: episode: 5350, duration: 0.054s, episode steps: 7, steps per second: 129, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001848, mae: 0.025714, mean_q: 0.042717
 42169/100000: episode: 5351, duration: 0.040s, episode steps: 7, steps per second: 175, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001128, mae: 0.020048, mean_q: 0.031951
 42176/100000: episode: 5352, duration: 0.039s, episode steps: 7, steps per second: 182, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000399, mae: 0.014133, mean_q: 0.016362
 42183/100000: episode: 5353, duration: 0.048s, episode steps: 7, steps per second: 147, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001174, mae: 0.016753, mean_q: 0.025296
 42190/100000: episode: 5354, duration: 0.049s, episode steps: 7, steps per second: 142, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002133, mae: 0.020699, mean_q: 0.033319
 42197/100000: episode: 5355, duration: 0.038s, episode steps: 7, steps per second: 185, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000693, mae: 0.016825, mean_q: 0.035431
 42204/100000: episode: 5356, duration: 0.045s, episode steps: 7, steps per second: 155, episode reward: 1.947, mean reward: 0.278 [0.007, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 7.857 [5.000, 11.000], loss: 0.001193, mae: 0.019208, mean_q: 0.036919
 42211/100000: episode: 5357, duration: 0.042s, episode steps: 7, steps per second: 167, episode reward: 1.947, mean reward: 0.278 [0.007, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 7.857 [5.000, 11.000], loss: 0.001754, mae: 0.020607, mean_q: 0.026736
 42218/100000: episode: 5358, duration: 0.038s, episode steps: 7, steps per second: 186, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000994, mae: 0.015645, mean_q: 0.016377
 42223/100000: episode: 5359, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000991, mae: 0.019603, mean_q: 0.028537
 42228/100000: episode: 5360, duration: 0.032s, episode steps: 5, steps per second: 156, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000819, mae: 0.017843, mean_q: 0.030567
 42235/100000: episode: 5361, duration: 0.040s, episode steps: 7, steps per second: 176, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000765, mae: 0.017603, mean_q: 0.029470
 42240/100000: episode: 5362, duration: 0.031s, episode steps: 5, steps per second: 162, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000375, mae: 0.013868, mean_q: 0.022248
 42245/100000: episode: 5363, duration: 0.046s, episode steps: 5, steps per second: 109, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000590, mae: 0.016605, mean_q: 0.030608
 42252/100000: episode: 5364, duration: 0.049s, episode steps: 7, steps per second: 142, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000751, mae: 0.016006, mean_q: 0.029144
 42259/100000: episode: 5365, duration: 0.039s, episode steps: 7, steps per second: 181, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001658, mae: 0.020071, mean_q: 0.029401
 42266/100000: episode: 5366, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000719, mae: 0.017866, mean_q: 0.034531
 42273/100000: episode: 5367, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001295, mae: 0.021460, mean_q: 0.032751
 42280/100000: episode: 5368, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001238, mae: 0.019039, mean_q: 0.025932
 42287/100000: episode: 5369, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001299, mae: 0.018070, mean_q: 0.025857
[Info] Complete ISplit Iteration
[Info] Levels: [0.022380156, 1.1926383]
[Info] Cond. Prob: [0.1, 0.01]
[Info] Error Prob: 0.001

 42294/100000: episode: 5370, duration: 0.764s, episode steps: 7, steps per second: 9, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001471, mae: 0.020985, mean_q: 0.035566
 42304/100000: episode: 5371, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000996, mae: 0.019241, mean_q: 0.033337
 42314/100000: episode: 5372, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001548, mae: 0.018616, mean_q: 0.029835
 42324/100000: episode: 5373, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000947, mae: 0.015857, mean_q: 0.024133
 42334/100000: episode: 5374, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001143, mae: 0.018626, mean_q: 0.031021
 42344/100000: episode: 5375, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001679, mae: 0.022117, mean_q: 0.042588
 42354/100000: episode: 5376, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001219, mae: 0.020648, mean_q: 0.035979
 42364/100000: episode: 5377, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000538, mae: 0.014280, mean_q: 0.024484
 42374/100000: episode: 5378, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001466, mae: 0.020835, mean_q: 0.027081
 42384/100000: episode: 5379, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000867, mae: 0.017103, mean_q: 0.025680
 42394/100000: episode: 5380, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001506, mae: 0.022078, mean_q: 0.045390
 42404/100000: episode: 5381, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001063, mae: 0.018892, mean_q: 0.034051
 42414/100000: episode: 5382, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000586, mae: 0.014885, mean_q: 0.020428
 42424/100000: episode: 5383, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000632, mae: 0.015216, mean_q: 0.029832
 42434/100000: episode: 5384, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000748, mae: 0.018906, mean_q: 0.030377
 42444/100000: episode: 5385, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001215, mae: 0.019899, mean_q: 0.037880
 42454/100000: episode: 5386, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001639, mae: 0.019735, mean_q: 0.037860
 42464/100000: episode: 5387, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000788, mae: 0.015239, mean_q: 0.028172
 42474/100000: episode: 5388, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000626, mae: 0.012214, mean_q: 0.022214
 42484/100000: episode: 5389, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000489, mae: 0.014340, mean_q: 0.022477
 42494/100000: episode: 5390, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001613, mae: 0.020183, mean_q: 0.033037
 42504/100000: episode: 5391, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000800, mae: 0.017634, mean_q: 0.026787
 42514/100000: episode: 5392, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000883, mae: 0.017091, mean_q: 0.027830
 42524/100000: episode: 5393, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000996, mae: 0.018739, mean_q: 0.031251
 42534/100000: episode: 5394, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001454, mae: 0.021805, mean_q: 0.039935
 42544/100000: episode: 5395, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000407, mae: 0.013685, mean_q: 0.021775
 42554/100000: episode: 5396, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000861, mae: 0.015551, mean_q: 0.024985
 42564/100000: episode: 5397, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000975, mae: 0.016837, mean_q: 0.029471
 42574/100000: episode: 5398, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000500, mae: 0.015274, mean_q: 0.025051
 42584/100000: episode: 5399, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000798, mae: 0.016384, mean_q: 0.029354
 42594/100000: episode: 5400, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000608, mae: 0.016104, mean_q: 0.031769
 42604/100000: episode: 5401, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000790, mae: 0.017754, mean_q: 0.030191
 42614/100000: episode: 5402, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000978, mae: 0.017585, mean_q: 0.035278
 42624/100000: episode: 5403, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001140, mae: 0.017492, mean_q: 0.032393
 42634/100000: episode: 5404, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000943, mae: 0.016760, mean_q: 0.030781
 42644/100000: episode: 5405, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000625, mae: 0.015157, mean_q: 0.021496
 42654/100000: episode: 5406, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000889, mae: 0.018497, mean_q: 0.033781
 42664/100000: episode: 5407, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000623, mae: 0.015129, mean_q: 0.029740
 42674/100000: episode: 5408, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001801, mae: 0.017705, mean_q: 0.024928
 42684/100000: episode: 5409, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000636, mae: 0.012672, mean_q: 0.022763
 42694/100000: episode: 5410, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000517, mae: 0.015342, mean_q: 0.022274
 42704/100000: episode: 5411, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000905, mae: 0.016785, mean_q: 0.030876
 42714/100000: episode: 5412, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000786, mae: 0.014364, mean_q: 0.026292
 42724/100000: episode: 5413, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000516, mae: 0.013232, mean_q: 0.018093
 42734/100000: episode: 5414, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000880, mae: 0.017415, mean_q: 0.030888
 42744/100000: episode: 5415, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000711, mae: 0.015300, mean_q: 0.027856
 42754/100000: episode: 5416, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000963, mae: 0.016436, mean_q: 0.026969
 42764/100000: episode: 5417, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000928, mae: 0.014782, mean_q: 0.018450
 42774/100000: episode: 5418, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001684, mae: 0.018282, mean_q: 0.024173
 42784/100000: episode: 5419, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001577, mae: 0.021377, mean_q: 0.038178
 42794/100000: episode: 5420, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001596, mae: 0.020662, mean_q: 0.034040
 42804/100000: episode: 5421, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000455, mae: 0.011807, mean_q: 0.019874
 42814/100000: episode: 5422, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000553, mae: 0.014563, mean_q: 0.028673
 42824/100000: episode: 5423, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000584, mae: 0.014499, mean_q: 0.027347
 42834/100000: episode: 5424, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001640, mae: 0.017521, mean_q: 0.029518
 42844/100000: episode: 5425, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001031, mae: 0.016197, mean_q: 0.029656
 42854/100000: episode: 5426, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000634, mae: 0.013666, mean_q: 0.024407
 42864/100000: episode: 5427, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000923, mae: 0.015483, mean_q: 0.022948
 42874/100000: episode: 5428, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000729, mae: 0.014288, mean_q: 0.024433
 42884/100000: episode: 5429, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000864, mae: 0.014588, mean_q: 0.021385
 42894/100000: episode: 5430, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000372, mae: 0.010265, mean_q: 0.012345
 42904/100000: episode: 5431, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001286, mae: 0.017852, mean_q: 0.032385
 42914/100000: episode: 5432, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000464, mae: 0.014373, mean_q: 0.026975
 42924/100000: episode: 5433, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000385, mae: 0.011048, mean_q: 0.020472
 42934/100000: episode: 5434, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000728, mae: 0.012314, mean_q: 0.018058
 42944/100000: episode: 5435, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001338, mae: 0.015995, mean_q: 0.022030
 42954/100000: episode: 5436, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000480, mae: 0.012636, mean_q: 0.022507
 42964/100000: episode: 5437, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000260, mae: 0.009969, mean_q: 0.018407
 42974/100000: episode: 5438, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001497, mae: 0.017203, mean_q: 0.024009
 42984/100000: episode: 5439, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000948, mae: 0.015277, mean_q: 0.021175
 42994/100000: episode: 5440, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000788, mae: 0.014825, mean_q: 0.023330
 43004/100000: episode: 5441, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000632, mae: 0.013988, mean_q: 0.021125
 43014/100000: episode: 5442, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000591, mae: 0.013566, mean_q: 0.020443
 43024/100000: episode: 5443, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000527, mae: 0.011245, mean_q: 0.017911
 43034/100000: episode: 5444, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000294, mae: 0.009947, mean_q: 0.018962
 43044/100000: episode: 5445, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000419, mae: 0.011011, mean_q: 0.019755
 43054/100000: episode: 5446, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000762, mae: 0.012392, mean_q: 0.018370
 43064/100000: episode: 5447, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000718, mae: 0.013274, mean_q: 0.019961
 43074/100000: episode: 5448, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001168, mae: 0.016599, mean_q: 0.024484
 43084/100000: episode: 5449, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000489, mae: 0.010930, mean_q: 0.015789
 43094/100000: episode: 5450, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000335, mae: 0.010366, mean_q: 0.016051
 43104/100000: episode: 5451, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001205, mae: 0.012675, mean_q: 0.016679
 43114/100000: episode: 5452, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001221, mae: 0.017170, mean_q: 0.025538
 43124/100000: episode: 5453, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000864, mae: 0.012714, mean_q: 0.020369
 43134/100000: episode: 5454, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000506, mae: 0.009579, mean_q: 0.012569
 43144/100000: episode: 5455, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000708, mae: 0.012350, mean_q: 0.018168
 43154/100000: episode: 5456, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000802, mae: 0.015218, mean_q: 0.020662
 43164/100000: episode: 5457, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000397, mae: 0.013188, mean_q: 0.024175
 43174/100000: episode: 5458, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000401, mae: 0.011538, mean_q: 0.023392
 43184/100000: episode: 5459, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000223, mae: 0.009778, mean_q: 0.018443
 43194/100000: episode: 5460, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001426, mae: 0.016088, mean_q: 0.024809
 43204/100000: episode: 5461, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000587, mae: 0.012471, mean_q: 0.013874
 43214/100000: episode: 5462, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000938, mae: 0.013030, mean_q: 0.013299
 43224/100000: episode: 5463, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000396, mae: 0.012285, mean_q: 0.020723
 43234/100000: episode: 5464, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000580, mae: 0.014542, mean_q: 0.029161
 43244/100000: episode: 5465, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000290, mae: 0.010298, mean_q: 0.016623
 43254/100000: episode: 5466, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001279, mae: 0.012664, mean_q: 0.025549
 43264/100000: episode: 5467, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000613, mae: 0.011637, mean_q: 0.018199
 43274/100000: episode: 5468, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000219, mae: 0.007810, mean_q: 0.012508
 43284/100000: episode: 5469, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000260, mae: 0.008133, mean_q: 0.017631
[Info] 1-TH LEVEL FOUND: 0.041455142199993134, Considering 12/100 traces
 43294/100000: episode: 5470, duration: 0.764s, episode steps: 10, steps per second: 13, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000868, mae: 0.014675, mean_q: 0.025064
 43300/100000: episode: 5471, duration: 0.033s, episode steps: 6, steps per second: 180, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000540, mae: 0.013831, mean_q: 0.021859
 43303/100000: episode: 5472, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000651, mae: 0.014819, mean_q: 0.026096
 43306/100000: episode: 5473, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000431, mae: 0.010283, mean_q: 0.014940
 43310/100000: episode: 5474, duration: 0.024s, episode steps: 4, steps per second: 167, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001292, mae: 0.013459, mean_q: 0.019129
 43313/100000: episode: 5475, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000637, mae: 0.013281, mean_q: 0.022499
 43316/100000: episode: 5476, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001736, mae: 0.018036, mean_q: 0.028709
 43319/100000: episode: 5477, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000704, mae: 0.014253, mean_q: 0.018791
 43322/100000: episode: 5478, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000324, mae: 0.010060, mean_q: 0.014798
 43325/100000: episode: 5479, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000302, mae: 0.011088, mean_q: 0.013134
 43331/100000: episode: 5480, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000529, mae: 0.011184, mean_q: 0.020487
 43335/100000: episode: 5481, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000481, mae: 0.014836, mean_q: 0.022575
 43338/100000: episode: 5482, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000279, mae: 0.012018, mean_q: 0.021150
 43341/100000: episode: 5483, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001812, mae: 0.018893, mean_q: 0.030101
 43344/100000: episode: 5484, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000454, mae: 0.013548, mean_q: 0.026145
 43347/100000: episode: 5485, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002386, mae: 0.019418, mean_q: 0.027129
 43351/100000: episode: 5486, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000542, mae: 0.011729, mean_q: 0.016652
 43355/100000: episode: 5487, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000312, mae: 0.009947, mean_q: 0.016260
 43358/100000: episode: 5488, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000552, mae: 0.014041, mean_q: 0.012982
 43362/100000: episode: 5489, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001175, mae: 0.015927, mean_q: 0.023810
 43368/100000: episode: 5490, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.003860, mae: 0.023661, mean_q: 0.025915
 43371/100000: episode: 5491, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000744, mae: 0.014707, mean_q: 0.029561
 43374/100000: episode: 5492, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000177, mae: 0.011462, mean_q: 0.021742
 43377/100000: episode: 5493, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000784, mae: 0.013039, mean_q: 0.018702
 43381/100000: episode: 5494, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001054, mae: 0.015168, mean_q: 0.020988
 43384/100000: episode: 5495, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000280, mae: 0.007795, mean_q: 0.009369
 43387/100000: episode: 5496, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000957, mae: 0.014218, mean_q: 0.019442
 43391/100000: episode: 5497, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000095, mae: 0.008587, mean_q: 0.013609
 43394/100000: episode: 5498, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000210, mae: 0.012638, mean_q: 0.018451
 43400/100000: episode: 5499, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001045, mae: 0.017537, mean_q: 0.027183
 43406/100000: episode: 5500, duration: 0.033s, episode steps: 6, steps per second: 180, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000700, mae: 0.014141, mean_q: 0.029438
 43410/100000: episode: 5501, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001713, mae: 0.017093, mean_q: 0.033900
 43414/100000: episode: 5502, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001051, mae: 0.015931, mean_q: 0.024279
 43420/100000: episode: 5503, duration: 0.033s, episode steps: 6, steps per second: 185, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000377, mae: 0.010098, mean_q: 0.012537
 43423/100000: episode: 5504, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000232, mae: 0.010030, mean_q: 0.014053
 43426/100000: episode: 5505, duration: 0.019s, episode steps: 3, steps per second: 162, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000270, mae: 0.011693, mean_q: 0.023336
 43430/100000: episode: 5506, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000245, mae: 0.011658, mean_q: 0.020565
 43433/100000: episode: 5507, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000716, mae: 0.012286, mean_q: 0.014385
 43437/100000: episode: 5508, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001762, mae: 0.014391, mean_q: 0.018070
 43441/100000: episode: 5509, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000355, mae: 0.011616, mean_q: 0.023175
 43444/100000: episode: 5510, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000191, mae: 0.010207, mean_q: 0.014498
 43447/100000: episode: 5511, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000189, mae: 0.011449, mean_q: 0.016030
 43451/100000: episode: 5512, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000607, mae: 0.012490, mean_q: 0.017389
 43457/100000: episode: 5513, duration: 0.031s, episode steps: 6, steps per second: 192, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000626, mae: 0.013027, mean_q: 0.022063
 43461/100000: episode: 5514, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000492, mae: 0.012572, mean_q: 0.019375
 43464/100000: episode: 5515, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000249, mae: 0.011609, mean_q: 0.016275
 43467/100000: episode: 5516, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002318, mae: 0.018896, mean_q: 0.027107
 43470/100000: episode: 5517, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000404, mae: 0.012461, mean_q: 0.017961
 43474/100000: episode: 5518, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000786, mae: 0.015768, mean_q: 0.027002
 43477/100000: episode: 5519, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001325, mae: 0.015157, mean_q: 0.029810
 43481/100000: episode: 5520, duration: 0.025s, episode steps: 4, steps per second: 160, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000140, mae: 0.008903, mean_q: 0.016047
 43484/100000: episode: 5521, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000322, mae: 0.008585, mean_q: 0.009180
 43487/100000: episode: 5522, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001519, mae: 0.015656, mean_q: 0.017957
 43490/100000: episode: 5523, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000295, mae: 0.011507, mean_q: 0.013707
 43493/100000: episode: 5524, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000391, mae: 0.013006, mean_q: 0.024836
 43499/100000: episode: 5525, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000611, mae: 0.013628, mean_q: 0.022969
 43503/100000: episode: 5526, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000536, mae: 0.013562, mean_q: 0.019523
 43506/100000: episode: 5527, duration: 0.019s, episode steps: 3, steps per second: 156, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000354, mae: 0.012684, mean_q: 0.026815
 43509/100000: episode: 5528, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000979, mae: 0.017109, mean_q: 0.022867
 43512/100000: episode: 5529, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000737, mae: 0.013346, mean_q: 0.019600
 43515/100000: episode: 5530, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000685, mae: 0.012587, mean_q: 0.019703
 43518/100000: episode: 5531, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001160, mae: 0.015073, mean_q: 0.022420
 43522/100000: episode: 5532, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000221, mae: 0.011067, mean_q: 0.017576
 43528/100000: episode: 5533, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000600, mae: 0.013155, mean_q: 0.020647
 43534/100000: episode: 5534, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001434, mae: 0.015068, mean_q: 0.022635
 43537/100000: episode: 5535, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001738, mae: 0.019991, mean_q: 0.037227
 43541/100000: episode: 5536, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000297, mae: 0.011052, mean_q: 0.016084
 43545/100000: episode: 5537, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000435, mae: 0.011675, mean_q: 0.017867
 43548/100000: episode: 5538, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000575, mae: 0.011195, mean_q: 0.019234
 43551/100000: episode: 5539, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000542, mae: 0.012010, mean_q: 0.016595
 43554/100000: episode: 5540, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001002, mae: 0.015887, mean_q: 0.030009
 43560/100000: episode: 5541, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000303, mae: 0.010445, mean_q: 0.015511
 43564/100000: episode: 5542, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000533, mae: 0.012550, mean_q: 0.017642
 43570/100000: episode: 5543, duration: 0.031s, episode steps: 6, steps per second: 193, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000469, mae: 0.011856, mean_q: 0.023569
 43573/100000: episode: 5544, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000963, mae: 0.018766, mean_q: 0.036415
 43579/100000: episode: 5545, duration: 0.031s, episode steps: 6, steps per second: 192, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000398, mae: 0.012138, mean_q: 0.029198
 43582/100000: episode: 5546, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000484, mae: 0.013790, mean_q: 0.030767
 43586/100000: episode: 5547, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002686, mae: 0.023651, mean_q: 0.037838
 43592/100000: episode: 5548, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000599, mae: 0.012153, mean_q: 0.011910
 43596/100000: episode: 5549, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000333, mae: 0.010369, mean_q: 0.009268
 43599/100000: episode: 5550, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000122, mae: 0.007198, mean_q: 0.010243
 43602/100000: episode: 5551, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001008, mae: 0.012131, mean_q: 0.017013
 43605/100000: episode: 5552, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001037, mae: 0.017495, mean_q: 0.034142
 43608/100000: episode: 5553, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000695, mae: 0.013973, mean_q: 0.021377
 43611/100000: episode: 5554, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001230, mae: 0.018169, mean_q: 0.030826
 43614/100000: episode: 5555, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000728, mae: 0.016312, mean_q: 0.034915
 43618/100000: episode: 5556, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000422, mae: 0.013605, mean_q: 0.029554
 43621/100000: episode: 5557, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000332, mae: 0.012482, mean_q: 0.022553
[Info] 2-TH LEVEL FOUND: 0.10132403671741486, Considering 11/100 traces
 43624/100000: episode: 5558, duration: 0.705s, episode steps: 3, steps per second: 4, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000138, mae: 0.009235, mean_q: 0.019027
 43629/100000: episode: 5559, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000625, mae: 0.014992, mean_q: 0.026896
[Info] FALSIFICATION!
 43633/100000: episode: 5560, duration: 0.275s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001215, mae: 0.016943, mean_q: 0.028383
 43638/100000: episode: 5561, duration: 0.028s, episode steps: 5, steps per second: 176, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000448, mae: 0.013172, mean_q: 0.028694
 43643/100000: episode: 5562, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000449, mae: 0.011412, mean_q: 0.021613
 43648/100000: episode: 5563, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000796, mae: 0.014692, mean_q: 0.027699
 43653/100000: episode: 5564, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000557, mae: 0.012104, mean_q: 0.025422
 43658/100000: episode: 5565, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002651, mae: 0.021094, mean_q: 0.027481
 43663/100000: episode: 5566, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000328, mae: 0.010149, mean_q: 0.008841
 43668/100000: episode: 5567, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000649, mae: 0.014378, mean_q: 0.018195
 43673/100000: episode: 5568, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000994, mae: 0.019402, mean_q: 0.032869
 43678/100000: episode: 5569, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000733, mae: 0.016913, mean_q: 0.030666
 43683/100000: episode: 5570, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000706, mae: 0.018640, mean_q: 0.039292
 43688/100000: episode: 5571, duration: 0.028s, episode steps: 5, steps per second: 179, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000373, mae: 0.012620, mean_q: 0.020463
 43693/100000: episode: 5572, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001065, mae: 0.016719, mean_q: 0.026428
 43698/100000: episode: 5573, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000296, mae: 0.011749, mean_q: 0.020418
 43703/100000: episode: 5574, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000342, mae: 0.011509, mean_q: 0.020928
 43708/100000: episode: 5575, duration: 0.028s, episode steps: 5, steps per second: 179, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000607, mae: 0.013345, mean_q: 0.027402
 43713/100000: episode: 5576, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000381, mae: 0.011940, mean_q: 0.021655
 43718/100000: episode: 5577, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001481, mae: 0.013868, mean_q: 0.021303
 43723/100000: episode: 5578, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001786, mae: 0.019170, mean_q: 0.031851
 43728/100000: episode: 5579, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000820, mae: 0.012246, mean_q: 0.023689
 43733/100000: episode: 5580, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000876, mae: 0.012580, mean_q: 0.016033
 43738/100000: episode: 5581, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000929, mae: 0.016033, mean_q: 0.020609
 43743/100000: episode: 5582, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000161, mae: 0.010407, mean_q: 0.017109
 43748/100000: episode: 5583, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000456, mae: 0.012754, mean_q: 0.028052
 43753/100000: episode: 5584, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000359, mae: 0.011314, mean_q: 0.017264
 43758/100000: episode: 5585, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000601, mae: 0.014107, mean_q: 0.020772
[Info] FALSIFICATION!
 43762/100000: episode: 5586, duration: 0.273s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000815, mae: 0.016877, mean_q: 0.030034
 43767/100000: episode: 5587, duration: 0.029s, episode steps: 5, steps per second: 174, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002726, mae: 0.023253, mean_q: 0.033549
 43772/100000: episode: 5588, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000757, mae: 0.015009, mean_q: 0.023542
 43777/100000: episode: 5589, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000694, mae: 0.017146, mean_q: 0.030019
 43782/100000: episode: 5590, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001308, mae: 0.020474, mean_q: 0.032593
 43787/100000: episode: 5591, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000662, mae: 0.011549, mean_q: 0.017638
 43792/100000: episode: 5592, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000385, mae: 0.009506, mean_q: 0.013823
 43797/100000: episode: 5593, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001240, mae: 0.017670, mean_q: 0.031444
 43802/100000: episode: 5594, duration: 0.029s, episode steps: 5, steps per second: 173, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000546, mae: 0.014563, mean_q: 0.031573
 43807/100000: episode: 5595, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000981, mae: 0.017559, mean_q: 0.033819
[Info] FALSIFICATION!
 43811/100000: episode: 5596, duration: 0.284s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001022, mae: 0.017308, mean_q: 0.033892
 43816/100000: episode: 5597, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000540, mae: 0.013202, mean_q: 0.019091
 43821/100000: episode: 5598, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001167, mae: 0.018025, mean_q: 0.024592
 43826/100000: episode: 5599, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000136, mae: 0.009146, mean_q: 0.012765
 43831/100000: episode: 5600, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000727, mae: 0.014148, mean_q: 0.016467
[Info] FALSIFICATION!
 43835/100000: episode: 5601, duration: 0.232s, episode steps: 4, steps per second: 17, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000772, mae: 0.015880, mean_q: 0.025286
 43840/100000: episode: 5602, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002662, mae: 0.025242, mean_q: 0.041566
 43845/100000: episode: 5603, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000169, mae: 0.011177, mean_q: 0.018625
[Info] FALSIFICATION!
 43849/100000: episode: 5604, duration: 0.269s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001381, mae: 0.020965, mean_q: 0.042717
 43854/100000: episode: 5605, duration: 0.028s, episode steps: 5, steps per second: 176, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001767, mae: 0.021105, mean_q: 0.038231
 43859/100000: episode: 5606, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.001216, mae: 0.020839, mean_q: 0.027187
 43864/100000: episode: 5607, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000695, mae: 0.014198, mean_q: 0.020544
 43869/100000: episode: 5608, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001503, mae: 0.021793, mean_q: 0.034235
 43874/100000: episode: 5609, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001015, mae: 0.014344, mean_q: 0.024409
 43879/100000: episode: 5610, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000642, mae: 0.014547, mean_q: 0.024527
 43884/100000: episode: 5611, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001138, mae: 0.019647, mean_q: 0.032532
 43889/100000: episode: 5612, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000614, mae: 0.015695, mean_q: 0.029369
 43894/100000: episode: 5613, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001039, mae: 0.017256, mean_q: 0.024020
 43899/100000: episode: 5614, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002038, mae: 0.021810, mean_q: 0.032241
 43904/100000: episode: 5615, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001732, mae: 0.018761, mean_q: 0.038290
 43909/100000: episode: 5616, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.003669, mae: 0.028787, mean_q: 0.048993
 43914/100000: episode: 5617, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002264, mae: 0.021886, mean_q: 0.026812
 43919/100000: episode: 5618, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000725, mae: 0.015087, mean_q: 0.028029
 43924/100000: episode: 5619, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000557, mae: 0.014879, mean_q: 0.029896
 43929/100000: episode: 5620, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000451, mae: 0.014935, mean_q: 0.030866
 43934/100000: episode: 5621, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000960, mae: 0.020605, mean_q: 0.037226
 43939/100000: episode: 5622, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000838, mae: 0.016068, mean_q: 0.029461
 43944/100000: episode: 5623, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001172, mae: 0.017393, mean_q: 0.033918
 43949/100000: episode: 5624, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000539, mae: 0.015126, mean_q: 0.025588
 43954/100000: episode: 5625, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000865, mae: 0.016110, mean_q: 0.028625
 43959/100000: episode: 5626, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000239, mae: 0.010883, mean_q: 0.018216
 43964/100000: episode: 5627, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000816, mae: 0.016234, mean_q: 0.027410
 43969/100000: episode: 5628, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001964, mae: 0.016113, mean_q: 0.022041
 43974/100000: episode: 5629, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001956, mae: 0.023396, mean_q: 0.040541
 43979/100000: episode: 5630, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001741, mae: 0.020869, mean_q: 0.029589
 43984/100000: episode: 5631, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001303, mae: 0.020241, mean_q: 0.035733
 43989/100000: episode: 5632, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000673, mae: 0.017705, mean_q: 0.032416
 43994/100000: episode: 5633, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000901, mae: 0.022015, mean_q: 0.038380
 43999/100000: episode: 5634, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001079, mae: 0.016003, mean_q: 0.028246
 44004/100000: episode: 5635, duration: 0.029s, episode steps: 5, steps per second: 171, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000622, mae: 0.012352, mean_q: 0.018502
 44009/100000: episode: 5636, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000559, mae: 0.015002, mean_q: 0.029633
 44014/100000: episode: 5637, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000650, mae: 0.015262, mean_q: 0.029384
 44019/100000: episode: 5638, duration: 0.028s, episode steps: 5, steps per second: 182, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000692, mae: 0.017310, mean_q: 0.032775
 44024/100000: episode: 5639, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001693, mae: 0.025474, mean_q: 0.045653
 44029/100000: episode: 5640, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001521, mae: 0.022366, mean_q: 0.045899
 44034/100000: episode: 5641, duration: 0.030s, episode steps: 5, steps per second: 168, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001365, mae: 0.017257, mean_q: 0.035004
 44039/100000: episode: 5642, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002214, mae: 0.022392, mean_q: 0.046256
 44044/100000: episode: 5643, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001203, mae: 0.018666, mean_q: 0.029335
 44049/100000: episode: 5644, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001132, mae: 0.016053, mean_q: 0.018336
 44054/100000: episode: 5645, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001599, mae: 0.017219, mean_q: 0.022341
 44059/100000: episode: 5646, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000904, mae: 0.017697, mean_q: 0.029777
[Info] Complete ISplit Iteration
[Info] Levels: [0.041455142, 0.10132404, 0.91307956]
[Info] Cond. Prob: [0.12, 0.11, 0.09]
[Info] Error Prob: 0.001188

 44064/100000: episode: 5647, duration: 0.903s, episode steps: 5, steps per second: 6, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001465, mae: 0.021201, mean_q: 0.034139
 44074/100000: episode: 5648, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001209, mae: 0.021109, mean_q: 0.032548
 44084/100000: episode: 5649, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001046, mae: 0.017876, mean_q: 0.031409
 44094/100000: episode: 5650, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000818, mae: 0.019262, mean_q: 0.041354
 44104/100000: episode: 5651, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001403, mae: 0.018491, mean_q: 0.033177
 44114/100000: episode: 5652, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001135, mae: 0.019064, mean_q: 0.035234
 44124/100000: episode: 5653, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001825, mae: 0.021196, mean_q: 0.030206
 44134/100000: episode: 5654, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001559, mae: 0.022507, mean_q: 0.043950
 44144/100000: episode: 5655, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001785, mae: 0.023597, mean_q: 0.039745
 44154/100000: episode: 5656, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001106, mae: 0.020006, mean_q: 0.041277
 44164/100000: episode: 5657, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000534, mae: 0.014740, mean_q: 0.026916
 44174/100000: episode: 5658, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001941, mae: 0.020240, mean_q: 0.031209
 44184/100000: episode: 5659, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000663, mae: 0.014673, mean_q: 0.025394
 44194/100000: episode: 5660, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001293, mae: 0.018496, mean_q: 0.034791
 44204/100000: episode: 5661, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000850, mae: 0.016668, mean_q: 0.027892
 44214/100000: episode: 5662, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000833, mae: 0.013897, mean_q: 0.025043
 44224/100000: episode: 5663, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001441, mae: 0.021328, mean_q: 0.034885
 44234/100000: episode: 5664, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000944, mae: 0.018472, mean_q: 0.039172
 44244/100000: episode: 5665, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001648, mae: 0.021259, mean_q: 0.040462
 44254/100000: episode: 5666, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002245, mae: 0.021558, mean_q: 0.035673
 44264/100000: episode: 5667, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001975, mae: 0.022328, mean_q: 0.028864
 44274/100000: episode: 5668, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001323, mae: 0.021184, mean_q: 0.035266
 44284/100000: episode: 5669, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001457, mae: 0.021611, mean_q: 0.039698
 44294/100000: episode: 5670, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000783, mae: 0.015467, mean_q: 0.028182
 44304/100000: episode: 5671, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001221, mae: 0.015987, mean_q: 0.023837
 44314/100000: episode: 5672, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001451, mae: 0.021136, mean_q: 0.033989
 44324/100000: episode: 5673, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000964, mae: 0.017329, mean_q: 0.032641
 44334/100000: episode: 5674, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001797, mae: 0.021675, mean_q: 0.034028
 44344/100000: episode: 5675, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000808, mae: 0.014062, mean_q: 0.022774
 44354/100000: episode: 5676, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001612, mae: 0.021197, mean_q: 0.036883
 44364/100000: episode: 5677, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000558, mae: 0.012300, mean_q: 0.013745
 44374/100000: episode: 5678, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002875, mae: 0.023208, mean_q: 0.029487
 44384/100000: episode: 5679, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001403, mae: 0.023339, mean_q: 0.041661
 44394/100000: episode: 5680, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001388, mae: 0.021922, mean_q: 0.029578
 44404/100000: episode: 5681, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000821, mae: 0.014297, mean_q: 0.020005
 44414/100000: episode: 5682, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000915, mae: 0.019172, mean_q: 0.039036
 44424/100000: episode: 5683, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000804, mae: 0.016184, mean_q: 0.037382
 44434/100000: episode: 5684, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001307, mae: 0.017109, mean_q: 0.033999
 44444/100000: episode: 5685, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000780, mae: 0.016988, mean_q: 0.033473
 44454/100000: episode: 5686, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001181, mae: 0.018322, mean_q: 0.032716
 44464/100000: episode: 5687, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000995, mae: 0.016919, mean_q: 0.029234
 44474/100000: episode: 5688, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000883, mae: 0.015984, mean_q: 0.032851
 44484/100000: episode: 5689, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001374, mae: 0.021749, mean_q: 0.040788
 44494/100000: episode: 5690, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001092, mae: 0.017006, mean_q: 0.025290
 44504/100000: episode: 5691, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001046, mae: 0.016628, mean_q: 0.036131
 44514/100000: episode: 5692, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001594, mae: 0.020211, mean_q: 0.036950
 44524/100000: episode: 5693, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001231, mae: 0.019406, mean_q: 0.029310
 44534/100000: episode: 5694, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001592, mae: 0.022052, mean_q: 0.028812
 44544/100000: episode: 5695, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001544, mae: 0.020944, mean_q: 0.037587
 44554/100000: episode: 5696, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001790, mae: 0.024133, mean_q: 0.046971
 44564/100000: episode: 5697, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000813, mae: 0.013158, mean_q: 0.024498
 44574/100000: episode: 5698, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000988, mae: 0.015943, mean_q: 0.024634
 44584/100000: episode: 5699, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001485, mae: 0.018733, mean_q: 0.030172
 44594/100000: episode: 5700, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000771, mae: 0.016147, mean_q: 0.028391
 44604/100000: episode: 5701, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001389, mae: 0.019035, mean_q: 0.034306
 44614/100000: episode: 5702, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000593, mae: 0.014427, mean_q: 0.022798
 44624/100000: episode: 5703, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000788, mae: 0.013143, mean_q: 0.020533
 44634/100000: episode: 5704, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001184, mae: 0.016178, mean_q: 0.019914
 44644/100000: episode: 5705, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001545, mae: 0.022798, mean_q: 0.036039
 44654/100000: episode: 5706, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001441, mae: 0.018929, mean_q: 0.035770
 44664/100000: episode: 5707, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000928, mae: 0.016131, mean_q: 0.027069
 44674/100000: episode: 5708, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000914, mae: 0.015102, mean_q: 0.026519
 44684/100000: episode: 5709, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001316, mae: 0.019154, mean_q: 0.025836
 44694/100000: episode: 5710, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001036, mae: 0.017290, mean_q: 0.030633
 44704/100000: episode: 5711, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001622, mae: 0.017122, mean_q: 0.026170
 44714/100000: episode: 5712, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001096, mae: 0.015621, mean_q: 0.029259
 44724/100000: episode: 5713, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001297, mae: 0.018248, mean_q: 0.028528
 44734/100000: episode: 5714, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000682, mae: 0.015906, mean_q: 0.024387
 44744/100000: episode: 5715, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002362, mae: 0.023046, mean_q: 0.036750
 44754/100000: episode: 5716, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001845, mae: 0.020540, mean_q: 0.037039
 44764/100000: episode: 5717, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001625, mae: 0.020165, mean_q: 0.031742
 44774/100000: episode: 5718, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001509, mae: 0.020435, mean_q: 0.033057
 44784/100000: episode: 5719, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000963, mae: 0.015871, mean_q: 0.026391
 44794/100000: episode: 5720, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000801, mae: 0.014811, mean_q: 0.026850
 44804/100000: episode: 5721, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001335, mae: 0.017309, mean_q: 0.032264
 44814/100000: episode: 5722, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000670, mae: 0.013435, mean_q: 0.030818
 44824/100000: episode: 5723, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000636, mae: 0.012285, mean_q: 0.022852
 44834/100000: episode: 5724, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000788, mae: 0.014058, mean_q: 0.023329
 44844/100000: episode: 5725, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000835, mae: 0.013365, mean_q: 0.024582
 44854/100000: episode: 5726, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001512, mae: 0.018763, mean_q: 0.033431
 44864/100000: episode: 5727, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001206, mae: 0.016081, mean_q: 0.024623
 44874/100000: episode: 5728, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000487, mae: 0.014763, mean_q: 0.026779
 44884/100000: episode: 5729, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001055, mae: 0.015246, mean_q: 0.025250
 44894/100000: episode: 5730, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001074, mae: 0.015416, mean_q: 0.022836
 44904/100000: episode: 5731, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001924, mae: 0.022313, mean_q: 0.041991
 44914/100000: episode: 5732, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001050, mae: 0.014377, mean_q: 0.024845
 44924/100000: episode: 5733, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000565, mae: 0.011844, mean_q: 0.023218
 44934/100000: episode: 5734, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000974, mae: 0.014763, mean_q: 0.024687
 44944/100000: episode: 5735, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000502, mae: 0.011422, mean_q: 0.018517
 44954/100000: episode: 5736, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001764, mae: 0.017911, mean_q: 0.032236
 44964/100000: episode: 5737, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001252, mae: 0.017260, mean_q: 0.028174
 44974/100000: episode: 5738, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001109, mae: 0.014762, mean_q: 0.020524
 44984/100000: episode: 5739, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001750, mae: 0.018540, mean_q: 0.029106
 44994/100000: episode: 5740, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000608, mae: 0.013911, mean_q: 0.031548
 45004/100000: episode: 5741, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001161, mae: 0.015283, mean_q: 0.031224
 45014/100000: episode: 5742, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001033, mae: 0.014248, mean_q: 0.017265
 45024/100000: episode: 5743, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000840, mae: 0.013222, mean_q: 0.017867
 45034/100000: episode: 5744, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001307, mae: 0.017964, mean_q: 0.032527
 45044/100000: episode: 5745, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000469, mae: 0.012182, mean_q: 0.022239
 45054/100000: episode: 5746, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000912, mae: 0.013511, mean_q: 0.027348
[Info] 1-TH LEVEL FOUND: 0.027945833280682564, Considering 15/100 traces
 45064/100000: episode: 5747, duration: 0.738s, episode steps: 10, steps per second: 14, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001674, mae: 0.015351, mean_q: 0.023631
 45067/100000: episode: 5748, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000733, mae: 0.015293, mean_q: 0.029900
 45070/100000: episode: 5749, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000593, mae: 0.012396, mean_q: 0.024575
 45073/100000: episode: 5750, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000753, mae: 0.015857, mean_q: 0.028638
 45076/100000: episode: 5751, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002249, mae: 0.024287, mean_q: 0.040071
 45082/100000: episode: 5752, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000345, mae: 0.011865, mean_q: 0.020940
 45085/100000: episode: 5753, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000527, mae: 0.011194, mean_q: 0.030434
 45088/100000: episode: 5754, duration: 0.021s, episode steps: 3, steps per second: 146, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001187, mae: 0.014641, mean_q: 0.029962
 45091/100000: episode: 5755, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000173, mae: 0.007870, mean_q: 0.015706
 45095/100000: episode: 5756, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000340, mae: 0.010420, mean_q: 0.019411
 45098/100000: episode: 5757, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002400, mae: 0.020255, mean_q: 0.033200
 45101/100000: episode: 5758, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000734, mae: 0.012636, mean_q: 0.022733
 45105/100000: episode: 5759, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001994, mae: 0.020443, mean_q: 0.040211
[Info] FALSIFICATION!
 45110/100000: episode: 5760, duration: 0.224s, episode steps: 5, steps per second: 22, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.001348, mae: 0.014661, mean_q: 0.035391
 45114/100000: episode: 5761, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000886, mae: 0.012395, mean_q: 0.021017
 45118/100000: episode: 5762, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001306, mae: 0.014694, mean_q: 0.022365
 45122/100000: episode: 5763, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000807, mae: 0.012379, mean_q: 0.021632
 45125/100000: episode: 5764, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000391, mae: 0.011526, mean_q: 0.018743
 45128/100000: episode: 5765, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000212, mae: 0.009220, mean_q: 0.037540
 45131/100000: episode: 5766, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000393, mae: 0.010317, mean_q: 0.017342
 45134/100000: episode: 5767, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000105, mae: 0.007369, mean_q: 0.014390
 45138/100000: episode: 5768, duration: 0.023s, episode steps: 4, steps per second: 178, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000303, mae: 0.011538, mean_q: 0.018970
 45142/100000: episode: 5769, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000191, mae: 0.009592, mean_q: 0.019582
 45145/100000: episode: 5770, duration: 0.020s, episode steps: 3, steps per second: 149, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000828, mae: 0.015198, mean_q: 0.031470
 45148/100000: episode: 5771, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002521, mae: 0.021762, mean_q: 0.039872
 45151/100000: episode: 5772, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001205, mae: 0.014082, mean_q: 0.021924
 45154/100000: episode: 5773, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001188, mae: 0.015016, mean_q: 0.035053
 45157/100000: episode: 5774, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001268, mae: 0.020474, mean_q: 0.028960
 45160/100000: episode: 5775, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000655, mae: 0.012687, mean_q: 0.024228
 45163/100000: episode: 5776, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000934, mae: 0.015089, mean_q: 0.022315
 45166/100000: episode: 5777, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001212, mae: 0.014689, mean_q: 0.022689
 45169/100000: episode: 5778, duration: 0.021s, episode steps: 3, steps per second: 143, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000812, mae: 0.014158, mean_q: 0.029662
 45172/100000: episode: 5779, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000288, mae: 0.008788, mean_q: 0.014551
 45175/100000: episode: 5780, duration: 0.020s, episode steps: 3, steps per second: 153, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000903, mae: 0.018436, mean_q: 0.034197
 45178/100000: episode: 5781, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001239, mae: 0.021410, mean_q: 0.054642
 45181/100000: episode: 5782, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001637, mae: 0.020626, mean_q: 0.033009
 45184/100000: episode: 5783, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000343, mae: 0.013650, mean_q: 0.022201
 45188/100000: episode: 5784, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001268, mae: 0.016727, mean_q: 0.036257
 45194/100000: episode: 5785, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001552, mae: 0.017056, mean_q: 0.028573
 45200/100000: episode: 5786, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000611, mae: 0.012822, mean_q: 0.018848
 45203/100000: episode: 5787, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000741, mae: 0.015376, mean_q: 0.035723
 45209/100000: episode: 5788, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002840, mae: 0.023579, mean_q: 0.041602
 45215/100000: episode: 5789, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001106, mae: 0.015186, mean_q: 0.019319
 45221/100000: episode: 5790, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000943, mae: 0.012696, mean_q: 0.016883
 45224/100000: episode: 5791, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000493, mae: 0.014344, mean_q: 0.021164
 45228/100000: episode: 5792, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000628, mae: 0.016623, mean_q: 0.030943
 45231/100000: episode: 5793, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000480, mae: 0.014514, mean_q: 0.026198
 45235/100000: episode: 5794, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000870, mae: 0.014198, mean_q: 0.025596
 45238/100000: episode: 5795, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000168, mae: 0.008163, mean_q: 0.024940
 45241/100000: episode: 5796, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000676, mae: 0.012842, mean_q: 0.028760
 45244/100000: episode: 5797, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000556, mae: 0.014006, mean_q: 0.028489
 45247/100000: episode: 5798, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002439, mae: 0.016623, mean_q: 0.024054
 45251/100000: episode: 5799, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000825, mae: 0.011045, mean_q: 0.018654
 45255/100000: episode: 5800, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001138, mae: 0.015093, mean_q: 0.036871
 45258/100000: episode: 5801, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001054, mae: 0.018389, mean_q: 0.037449
 45262/100000: episode: 5802, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000879, mae: 0.014751, mean_q: 0.039563
 45268/100000: episode: 5803, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001863, mae: 0.020510, mean_q: 0.045373
 45271/100000: episode: 5804, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000764, mae: 0.012715, mean_q: 0.013343
 45274/100000: episode: 5805, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002594, mae: 0.019509, mean_q: 0.010122
 45277/100000: episode: 5806, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001943, mae: 0.020401, mean_q: 0.026138
 45280/100000: episode: 5807, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001175, mae: 0.018342, mean_q: 0.030292
 45283/100000: episode: 5808, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002552, mae: 0.027454, mean_q: 0.045226
 45286/100000: episode: 5809, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000368, mae: 0.016632, mean_q: 0.026874
 45290/100000: episode: 5810, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001406, mae: 0.018009, mean_q: 0.036984
 45294/100000: episode: 5811, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001439, mae: 0.016629, mean_q: 0.026009
 45298/100000: episode: 5812, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000957, mae: 0.014367, mean_q: 0.018975
 45301/100000: episode: 5813, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000396, mae: 0.010480, mean_q: 0.017806
 45304/100000: episode: 5814, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001810, mae: 0.021066, mean_q: 0.036326
 45307/100000: episode: 5815, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000155, mae: 0.008542, mean_q: 0.013631
 45310/100000: episode: 5816, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001085, mae: 0.017283, mean_q: 0.026459
 45313/100000: episode: 5817, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000184, mae: 0.010477, mean_q: 0.019573
 45316/100000: episode: 5818, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000964, mae: 0.018533, mean_q: 0.028607
 45320/100000: episode: 5819, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000346, mae: 0.010649, mean_q: 0.021299
 45323/100000: episode: 5820, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000167, mae: 0.008033, mean_q: 0.011196
 45326/100000: episode: 5821, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000133, mae: 0.007614, mean_q: 0.012469
 45329/100000: episode: 5822, duration: 0.019s, episode steps: 3, steps per second: 157, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000845, mae: 0.013354, mean_q: 0.016670
 45332/100000: episode: 5823, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000429, mae: 0.012588, mean_q: 0.020421
 45335/100000: episode: 5824, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002102, mae: 0.023889, mean_q: 0.038116
 45338/100000: episode: 5825, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000472, mae: 0.013424, mean_q: 0.022775
 45341/100000: episode: 5826, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000760, mae: 0.015393, mean_q: 0.024861
[Info] FALSIFICATION!
 45346/100000: episode: 5827, duration: 0.272s, episode steps: 5, steps per second: 18, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.001185, mae: 0.014749, mean_q: 0.028090
 45352/100000: episode: 5828, duration: 0.034s, episode steps: 6, steps per second: 174, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001004, mae: 0.016183, mean_q: 0.025685
 45356/100000: episode: 5829, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000686, mae: 0.011274, mean_q: 0.022638
 45359/100000: episode: 5830, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001272, mae: 0.019108, mean_q: 0.036814
 45362/100000: episode: 5831, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000251, mae: 0.007657, mean_q: 0.015178
[Info] Complete ISplit Iteration
[Info] Levels: [0.027945833, 0.89190793]
[Info] Cond. Prob: [0.15, 0.02]
[Info] Error Prob: 0.003

 45365/100000: episode: 5832, duration: 0.875s, episode steps: 3, steps per second: 3, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001836, mae: 0.018183, mean_q: 0.029931
 45375/100000: episode: 5833, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001004, mae: 0.012639, mean_q: 0.017570
 45385/100000: episode: 5834, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000923, mae: 0.016528, mean_q: 0.028917
 45395/100000: episode: 5835, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001174, mae: 0.015937, mean_q: 0.024144
 45405/100000: episode: 5836, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000872, mae: 0.016331, mean_q: 0.031133
 45415/100000: episode: 5837, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001034, mae: 0.015060, mean_q: 0.032313
 45425/100000: episode: 5838, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001296, mae: 0.014373, mean_q: 0.027174
 45435/100000: episode: 5839, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001179, mae: 0.017071, mean_q: 0.033864
 45445/100000: episode: 5840, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001006, mae: 0.015015, mean_q: 0.026655
 45455/100000: episode: 5841, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000664, mae: 0.011899, mean_q: 0.019753
 45465/100000: episode: 5842, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000601, mae: 0.012671, mean_q: 0.020844
 45475/100000: episode: 5843, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001012, mae: 0.015341, mean_q: 0.030593
 45485/100000: episode: 5844, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000710, mae: 0.012446, mean_q: 0.028284
 45495/100000: episode: 5845, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000879, mae: 0.013238, mean_q: 0.030106
 45505/100000: episode: 5846, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000712, mae: 0.011396, mean_q: 0.023470
 45515/100000: episode: 5847, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001239, mae: 0.015902, mean_q: 0.029789
 45525/100000: episode: 5848, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000270, mae: 0.008658, mean_q: 0.016772
 45535/100000: episode: 5849, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001228, mae: 0.016918, mean_q: 0.031363
 45545/100000: episode: 5850, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001549, mae: 0.016704, mean_q: 0.027806
 45555/100000: episode: 5851, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000970, mae: 0.015022, mean_q: 0.020318
 45565/100000: episode: 5852, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000673, mae: 0.015309, mean_q: 0.028578
 45575/100000: episode: 5853, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000973, mae: 0.016987, mean_q: 0.031955
 45585/100000: episode: 5854, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000884, mae: 0.014533, mean_q: 0.022148
 45595/100000: episode: 5855, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000616, mae: 0.012177, mean_q: 0.018441
 45605/100000: episode: 5856, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001083, mae: 0.016022, mean_q: 0.030744
 45615/100000: episode: 5857, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001300, mae: 0.017380, mean_q: 0.026981
 45625/100000: episode: 5858, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000829, mae: 0.015184, mean_q: 0.027521
 45635/100000: episode: 5859, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000917, mae: 0.014308, mean_q: 0.026553
 45645/100000: episode: 5860, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000733, mae: 0.013522, mean_q: 0.027588
 45655/100000: episode: 5861, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001199, mae: 0.018592, mean_q: 0.041293
 45665/100000: episode: 5862, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000786, mae: 0.014251, mean_q: 0.033807
 45675/100000: episode: 5863, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001260, mae: 0.014700, mean_q: 0.032130
 45685/100000: episode: 5864, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000538, mae: 0.010745, mean_q: 0.017416
 45695/100000: episode: 5865, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001118, mae: 0.015404, mean_q: 0.020270
 45705/100000: episode: 5866, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001175, mae: 0.013609, mean_q: 0.019247
 45715/100000: episode: 5867, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002036, mae: 0.026503, mean_q: 0.057303
 45725/100000: episode: 5868, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000609, mae: 0.011886, mean_q: 0.020746
 45735/100000: episode: 5869, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000891, mae: 0.013830, mean_q: 0.016705
 45745/100000: episode: 5870, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000715, mae: 0.012005, mean_q: 0.015924
 45755/100000: episode: 5871, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001666, mae: 0.020184, mean_q: 0.036224
 45765/100000: episode: 5872, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001036, mae: 0.018796, mean_q: 0.036270
 45775/100000: episode: 5873, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001941, mae: 0.020330, mean_q: 0.035156
 45785/100000: episode: 5874, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001175, mae: 0.015617, mean_q: 0.025918
 45795/100000: episode: 5875, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001045, mae: 0.018773, mean_q: 0.033890
 45805/100000: episode: 5876, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001360, mae: 0.018005, mean_q: 0.033486
 45815/100000: episode: 5877, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000970, mae: 0.014412, mean_q: 0.026866
 45825/100000: episode: 5878, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000212, mae: 0.008385, mean_q: 0.015616
 45835/100000: episode: 5879, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001075, mae: 0.016105, mean_q: 0.022810
 45845/100000: episode: 5880, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.002260, mae: 0.018474, mean_q: 0.025480
 45855/100000: episode: 5881, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001666, mae: 0.020085, mean_q: 0.040013
 45865/100000: episode: 5882, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001345, mae: 0.018922, mean_q: 0.031869
 45875/100000: episode: 5883, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000758, mae: 0.013467, mean_q: 0.022014
 45885/100000: episode: 5884, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001273, mae: 0.014810, mean_q: 0.022376
 45895/100000: episode: 5885, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001671, mae: 0.019385, mean_q: 0.033757
 45905/100000: episode: 5886, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001084, mae: 0.019510, mean_q: 0.041502
 45915/100000: episode: 5887, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001222, mae: 0.016969, mean_q: 0.027599
 45925/100000: episode: 5888, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001092, mae: 0.014988, mean_q: 0.026085
 45935/100000: episode: 5889, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000910, mae: 0.011766, mean_q: 0.019841
 45945/100000: episode: 5890, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000843, mae: 0.013606, mean_q: 0.024994
 45955/100000: episode: 5891, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000895, mae: 0.016031, mean_q: 0.034910
 45965/100000: episode: 5892, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001067, mae: 0.015023, mean_q: 0.025915
 45975/100000: episode: 5893, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001771, mae: 0.018781, mean_q: 0.034441
 45985/100000: episode: 5894, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001234, mae: 0.016738, mean_q: 0.033872
 45995/100000: episode: 5895, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001287, mae: 0.018658, mean_q: 0.032410
 46005/100000: episode: 5896, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000854, mae: 0.012932, mean_q: 0.017077
 46015/100000: episode: 5897, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002093, mae: 0.016983, mean_q: 0.024271
 46025/100000: episode: 5898, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000954, mae: 0.016315, mean_q: 0.033099
 46035/100000: episode: 5899, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001605, mae: 0.016406, mean_q: 0.032166
 46045/100000: episode: 5900, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001453, mae: 0.017350, mean_q: 0.027529
 46055/100000: episode: 5901, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001516, mae: 0.019682, mean_q: 0.038264
 46065/100000: episode: 5902, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000864, mae: 0.015330, mean_q: 0.027872
 46075/100000: episode: 5903, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000915, mae: 0.014593, mean_q: 0.029673
 46085/100000: episode: 5904, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001389, mae: 0.018355, mean_q: 0.032316
 46095/100000: episode: 5905, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001307, mae: 0.015846, mean_q: 0.028063
 46105/100000: episode: 5906, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001251, mae: 0.013916, mean_q: 0.025890
 46115/100000: episode: 5907, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000820, mae: 0.013277, mean_q: 0.023720
 46125/100000: episode: 5908, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000831, mae: 0.014883, mean_q: 0.025348
 46135/100000: episode: 5909, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001278, mae: 0.016522, mean_q: 0.033818
 46145/100000: episode: 5910, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001629, mae: 0.017666, mean_q: 0.029753
 46155/100000: episode: 5911, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001619, mae: 0.016103, mean_q: 0.024156
 46165/100000: episode: 5912, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000822, mae: 0.013688, mean_q: 0.016108
 46175/100000: episode: 5913, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000961, mae: 0.015452, mean_q: 0.020052
 46185/100000: episode: 5914, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000891, mae: 0.016001, mean_q: 0.025858
 46195/100000: episode: 5915, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001128, mae: 0.015983, mean_q: 0.029185
 46205/100000: episode: 5916, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000384, mae: 0.011030, mean_q: 0.023246
 46215/100000: episode: 5917, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000804, mae: 0.013671, mean_q: 0.025410
 46225/100000: episode: 5918, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000894, mae: 0.011012, mean_q: 0.014109
 46235/100000: episode: 5919, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001700, mae: 0.020645, mean_q: 0.036797
 46245/100000: episode: 5920, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000536, mae: 0.012633, mean_q: 0.025593
 46255/100000: episode: 5921, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000787, mae: 0.013822, mean_q: 0.023842
 46265/100000: episode: 5922, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000635, mae: 0.013339, mean_q: 0.025578
 46275/100000: episode: 5923, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001275, mae: 0.016899, mean_q: 0.031861
 46285/100000: episode: 5924, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000941, mae: 0.016102, mean_q: 0.015463
 46295/100000: episode: 5925, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000974, mae: 0.014319, mean_q: 0.024355
 46305/100000: episode: 5926, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000291, mae: 0.012224, mean_q: 0.027214
 46315/100000: episode: 5927, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002146, mae: 0.020357, mean_q: 0.032898
 46325/100000: episode: 5928, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001121, mae: 0.018011, mean_q: 0.018568
 46335/100000: episode: 5929, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001216, mae: 0.017557, mean_q: 0.034887
 46345/100000: episode: 5930, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000856, mae: 0.017558, mean_q: 0.033216
 46355/100000: episode: 5931, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001365, mae: 0.015719, mean_q: 0.026375
[Info] 1-TH LEVEL FOUND: 0.026768779382109642, Considering 11/100 traces
 46365/100000: episode: 5932, duration: 0.727s, episode steps: 10, steps per second: 14, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000877, mae: 0.011475, mean_q: 0.016766
 46368/100000: episode: 5933, duration: 0.020s, episode steps: 3, steps per second: 153, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000468, mae: 0.015362, mean_q: 0.027591
 46371/100000: episode: 5934, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000375, mae: 0.010006, mean_q: 0.016412
 46374/100000: episode: 5935, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000294, mae: 0.011954, mean_q: 0.028657
[Info] FALSIFICATION!
 46379/100000: episode: 5936, duration: 0.268s, episode steps: 5, steps per second: 19, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.001203, mae: 0.016949, mean_q: 0.028262
 46382/100000: episode: 5937, duration: 0.018s, episode steps: 3, steps per second: 162, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001303, mae: 0.017900, mean_q: 0.031306
 46385/100000: episode: 5938, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000906, mae: 0.014455, mean_q: 0.031257
 46391/100000: episode: 5939, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001132, mae: 0.016695, mean_q: 0.041394
 46395/100000: episode: 5940, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001238, mae: 0.015803, mean_q: 0.034026
 46399/100000: episode: 5941, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001416, mae: 0.012692, mean_q: 0.021308
 46402/100000: episode: 5942, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001224, mae: 0.011746, mean_q: 0.017369
 46405/100000: episode: 5943, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000477, mae: 0.009353, mean_q: 0.015623
 46411/100000: episode: 5944, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001719, mae: 0.020227, mean_q: 0.029728
 46414/100000: episode: 5945, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001055, mae: 0.011344, mean_q: 0.024377
 46420/100000: episode: 5946, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000956, mae: 0.015118, mean_q: 0.025127
 46424/100000: episode: 5947, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000959, mae: 0.012610, mean_q: 0.024323
 46427/100000: episode: 5948, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000887, mae: 0.015171, mean_q: 0.024276
 46430/100000: episode: 5949, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001149, mae: 0.015025, mean_q: 0.023967
 46434/100000: episode: 5950, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000464, mae: 0.012983, mean_q: 0.024091
 46438/100000: episode: 5951, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000543, mae: 0.011532, mean_q: 0.027135
 46441/100000: episode: 5952, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000839, mae: 0.012481, mean_q: 0.021215
 46444/100000: episode: 5953, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001603, mae: 0.017287, mean_q: 0.037543
 46447/100000: episode: 5954, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000761, mae: 0.014116, mean_q: 0.028590
 46453/100000: episode: 5955, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000505, mae: 0.009797, mean_q: 0.020907
 46459/100000: episode: 5956, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000628, mae: 0.009556, mean_q: 0.019983
 46462/100000: episode: 5957, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001563, mae: 0.019198, mean_q: 0.033648
 46468/100000: episode: 5958, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000364, mae: 0.009560, mean_q: 0.016314
 46471/100000: episode: 5959, duration: 0.020s, episode steps: 3, steps per second: 152, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001100, mae: 0.017413, mean_q: 0.027666
 46474/100000: episode: 5960, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001100, mae: 0.016597, mean_q: 0.019703
 46478/100000: episode: 5961, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001319, mae: 0.014155, mean_q: 0.018555
 46484/100000: episode: 5962, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000420, mae: 0.010249, mean_q: 0.019657
 46488/100000: episode: 5963, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001350, mae: 0.018172, mean_q: 0.033045
 46494/100000: episode: 5964, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000971, mae: 0.017469, mean_q: 0.029904
 46498/100000: episode: 5965, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000611, mae: 0.016093, mean_q: 0.030088
 46501/100000: episode: 5966, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001235, mae: 0.017788, mean_q: 0.035314
 46504/100000: episode: 5967, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000201, mae: 0.010443, mean_q: 0.025404
 46510/100000: episode: 5968, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001127, mae: 0.012653, mean_q: 0.019420
 46513/100000: episode: 5969, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000259, mae: 0.011329, mean_q: 0.012296
 46517/100000: episode: 5970, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000691, mae: 0.012853, mean_q: 0.018940
 46520/100000: episode: 5971, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003437, mae: 0.016196, mean_q: 0.013992
 46526/100000: episode: 5972, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001643, mae: 0.015921, mean_q: 0.025371
 46529/100000: episode: 5973, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000609, mae: 0.011719, mean_q: 0.024045
 46532/100000: episode: 5974, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000489, mae: 0.012697, mean_q: 0.026727
 46535/100000: episode: 5975, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000785, mae: 0.016287, mean_q: 0.038060
 46539/100000: episode: 5976, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000997, mae: 0.013829, mean_q: 0.025814
 46543/100000: episode: 5977, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000848, mae: 0.014471, mean_q: 0.028627
 46546/100000: episode: 5978, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000393, mae: 0.009786, mean_q: 0.020173
 46549/100000: episode: 5979, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000372, mae: 0.010771, mean_q: 0.020864
 46555/100000: episode: 5980, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000800, mae: 0.012542, mean_q: 0.029295
 46558/100000: episode: 5981, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000353, mae: 0.008534, mean_q: 0.026430
 46564/100000: episode: 5982, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000674, mae: 0.010893, mean_q: 0.020837
 46567/100000: episode: 5983, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001357, mae: 0.017253, mean_q: 0.032913
 46570/100000: episode: 5984, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000138, mae: 0.007792, mean_q: 0.014215
 46574/100000: episode: 5985, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000653, mae: 0.011599, mean_q: 0.027585
 46580/100000: episode: 5986, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001412, mae: 0.017516, mean_q: 0.028924
 46583/100000: episode: 5987, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000642, mae: 0.008893, mean_q: 0.012723
 46587/100000: episode: 5988, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000648, mae: 0.010395, mean_q: 0.013654
 46590/100000: episode: 5989, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001722, mae: 0.018889, mean_q: 0.040292
 46593/100000: episode: 5990, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002117, mae: 0.022310, mean_q: 0.036015
 46597/100000: episode: 5991, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002108, mae: 0.021185, mean_q: 0.039319
 46600/100000: episode: 5992, duration: 0.019s, episode steps: 3, steps per second: 155, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001229, mae: 0.015277, mean_q: 0.023797
 46603/100000: episode: 5993, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000506, mae: 0.011838, mean_q: 0.020697
 46606/100000: episode: 5994, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000780, mae: 0.012821, mean_q: 0.018842
 46609/100000: episode: 5995, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000083, mae: 0.005835, mean_q: 0.009711
 46615/100000: episode: 5996, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001775, mae: 0.016316, mean_q: 0.022907
 46619/100000: episode: 5997, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001069, mae: 0.014516, mean_q: 0.027221
 46622/100000: episode: 5998, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001124, mae: 0.017673, mean_q: 0.030495
 46628/100000: episode: 5999, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000733, mae: 0.014899, mean_q: 0.030813
 46631/100000: episode: 6000, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000157, mae: 0.010013, mean_q: 0.018100
 46634/100000: episode: 6001, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001100, mae: 0.014980, mean_q: 0.021860
 46637/100000: episode: 6002, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000405, mae: 0.010635, mean_q: 0.021655
 46640/100000: episode: 6003, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000104, mae: 0.005555, mean_q: 0.016619
 46646/100000: episode: 6004, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001014, mae: 0.013782, mean_q: 0.025467
 46649/100000: episode: 6005, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000716, mae: 0.012572, mean_q: 0.022939
 46652/100000: episode: 6006, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001224, mae: 0.016621, mean_q: 0.026417
 46655/100000: episode: 6007, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001168, mae: 0.014387, mean_q: 0.020930
 46658/100000: episode: 6008, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001060, mae: 0.016581, mean_q: 0.028617
 46664/100000: episode: 6009, duration: 0.034s, episode steps: 6, steps per second: 179, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000874, mae: 0.015010, mean_q: 0.022419
 46667/100000: episode: 6010, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001255, mae: 0.016159, mean_q: 0.023480
 46673/100000: episode: 6011, duration: 0.031s, episode steps: 6, steps per second: 197, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000693, mae: 0.010753, mean_q: 0.015824
 46677/100000: episode: 6012, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000877, mae: 0.012755, mean_q: 0.021356
 46680/100000: episode: 6013, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000853, mae: 0.014691, mean_q: 0.029055
 46684/100000: episode: 6014, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000746, mae: 0.011752, mean_q: 0.021999
 46688/100000: episode: 6015, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001631, mae: 0.018419, mean_q: 0.036723
 46691/100000: episode: 6016, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002178, mae: 0.021542, mean_q: 0.035637
 46694/100000: episode: 6017, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000840, mae: 0.013027, mean_q: 0.017634
 46698/100000: episode: 6018, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000646, mae: 0.011564, mean_q: 0.019086
 46701/100000: episode: 6019, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000675, mae: 0.011878, mean_q: 0.020264
 46707/100000: episode: 6020, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000470, mae: 0.010800, mean_q: 0.022873
[Info] Complete ISplit Iteration
[Info] Levels: [0.02676878, 0.97012967]
[Info] Cond. Prob: [0.11, 0.01]
[Info] Error Prob: 0.0011

 46711/100000: episode: 6021, duration: 0.743s, episode steps: 4, steps per second: 5, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000228, mae: 0.010554, mean_q: 0.018107
 46721/100000: episode: 6022, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001066, mae: 0.011683, mean_q: 0.020929
 46731/100000: episode: 6023, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000370, mae: 0.009574, mean_q: 0.017646
 46741/100000: episode: 6024, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000948, mae: 0.013912, mean_q: 0.028832
 46751/100000: episode: 6025, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000616, mae: 0.012980, mean_q: 0.026372
 46761/100000: episode: 6026, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000624, mae: 0.011226, mean_q: 0.021136
 46771/100000: episode: 6027, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001399, mae: 0.017339, mean_q: 0.032762
 46781/100000: episode: 6028, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001165, mae: 0.015025, mean_q: 0.022219
 46791/100000: episode: 6029, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000792, mae: 0.014169, mean_q: 0.024383
 46801/100000: episode: 6030, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000515, mae: 0.011412, mean_q: 0.018947
 46811/100000: episode: 6031, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000795, mae: 0.012590, mean_q: 0.024228
 46821/100000: episode: 6032, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000963, mae: 0.015317, mean_q: 0.026655
 46831/100000: episode: 6033, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000653, mae: 0.011522, mean_q: 0.023453
 46841/100000: episode: 6034, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001090, mae: 0.013974, mean_q: 0.025442
 46851/100000: episode: 6035, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000787, mae: 0.013556, mean_q: 0.026995
 46861/100000: episode: 6036, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001693, mae: 0.017544, mean_q: 0.030830
 46871/100000: episode: 6037, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000817, mae: 0.013422, mean_q: 0.028968
 46881/100000: episode: 6038, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000905, mae: 0.011950, mean_q: 0.025416
 46891/100000: episode: 6039, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000717, mae: 0.011658, mean_q: 0.021679
 46901/100000: episode: 6040, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000716, mae: 0.013575, mean_q: 0.023646
 46911/100000: episode: 6041, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000485, mae: 0.011879, mean_q: 0.025773
 46921/100000: episode: 6042, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000611, mae: 0.013641, mean_q: 0.025759
 46931/100000: episode: 6043, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000735, mae: 0.010718, mean_q: 0.020272
 46941/100000: episode: 6044, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000550, mae: 0.011456, mean_q: 0.022613
 46951/100000: episode: 6045, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000714, mae: 0.013121, mean_q: 0.031975
 46961/100000: episode: 6046, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000982, mae: 0.013858, mean_q: 0.032121
 46971/100000: episode: 6047, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000936, mae: 0.015269, mean_q: 0.021486
 46981/100000: episode: 6048, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001108, mae: 0.014217, mean_q: 0.029040
 46991/100000: episode: 6049, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.001242, mae: 0.018013, mean_q: 0.034404
 47001/100000: episode: 6050, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001668, mae: 0.018252, mean_q: 0.029501
 47011/100000: episode: 6051, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000861, mae: 0.012123, mean_q: 0.017142
 47021/100000: episode: 6052, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001669, mae: 0.016513, mean_q: 0.029129
 47031/100000: episode: 6053, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.001747, mae: 0.020627, mean_q: 0.039523
 47041/100000: episode: 6054, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000829, mae: 0.012094, mean_q: 0.018765
 47051/100000: episode: 6055, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000647, mae: 0.011510, mean_q: 0.016781
 47061/100000: episode: 6056, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001507, mae: 0.016036, mean_q: 0.023848
 47071/100000: episode: 6057, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000527, mae: 0.011868, mean_q: 0.020625
 47081/100000: episode: 6058, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000470, mae: 0.012811, mean_q: 0.024661
 47091/100000: episode: 6059, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001259, mae: 0.016915, mean_q: 0.032434
 47101/100000: episode: 6060, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000704, mae: 0.011572, mean_q: 0.019956
 47111/100000: episode: 6061, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000909, mae: 0.012434, mean_q: 0.015679
 47121/100000: episode: 6062, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000992, mae: 0.016547, mean_q: 0.036890
 47131/100000: episode: 6063, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001080, mae: 0.015525, mean_q: 0.027841
 47141/100000: episode: 6064, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000723, mae: 0.012384, mean_q: 0.016399
 47151/100000: episode: 6065, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000320, mae: 0.009904, mean_q: 0.016074
 47161/100000: episode: 6066, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001161, mae: 0.017566, mean_q: 0.035000
 47171/100000: episode: 6067, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001113, mae: 0.013856, mean_q: 0.027604
 47181/100000: episode: 6068, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000728, mae: 0.012634, mean_q: 0.021007
 47191/100000: episode: 6069, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000416, mae: 0.010763, mean_q: 0.020236
 47201/100000: episode: 6070, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000562, mae: 0.013217, mean_q: 0.025308
 47211/100000: episode: 6071, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001212, mae: 0.013256, mean_q: 0.021237
 47221/100000: episode: 6072, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001196, mae: 0.013956, mean_q: 0.030909
 47231/100000: episode: 6073, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001894, mae: 0.019150, mean_q: 0.038272
 47241/100000: episode: 6074, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001017, mae: 0.014522, mean_q: 0.018506
 47251/100000: episode: 6075, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000222, mae: 0.010886, mean_q: 0.019520
 47261/100000: episode: 6076, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000854, mae: 0.012746, mean_q: 0.023279
 47271/100000: episode: 6077, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000899, mae: 0.014100, mean_q: 0.024586
 47281/100000: episode: 6078, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000542, mae: 0.010750, mean_q: 0.018132
 47291/100000: episode: 6079, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000882, mae: 0.013421, mean_q: 0.020324
 47301/100000: episode: 6080, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001243, mae: 0.014748, mean_q: 0.024330
 47311/100000: episode: 6081, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000487, mae: 0.013089, mean_q: 0.030430
 47321/100000: episode: 6082, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000589, mae: 0.010867, mean_q: 0.022080
 47331/100000: episode: 6083, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001081, mae: 0.013740, mean_q: 0.023424
 47341/100000: episode: 6084, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000558, mae: 0.011860, mean_q: 0.015682
 47351/100000: episode: 6085, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001365, mae: 0.017804, mean_q: 0.033994
 47361/100000: episode: 6086, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000456, mae: 0.010717, mean_q: 0.020430
 47371/100000: episode: 6087, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001118, mae: 0.014543, mean_q: 0.024674
 47381/100000: episode: 6088, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001152, mae: 0.016537, mean_q: 0.030181
 47391/100000: episode: 6089, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000898, mae: 0.013800, mean_q: 0.020549
 47401/100000: episode: 6090, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001331, mae: 0.016572, mean_q: 0.034809
 47411/100000: episode: 6091, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001067, mae: 0.017777, mean_q: 0.037128
 47421/100000: episode: 6092, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000308, mae: 0.009012, mean_q: 0.022963
 47431/100000: episode: 6093, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000659, mae: 0.011497, mean_q: 0.019473
 47441/100000: episode: 6094, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000826, mae: 0.013781, mean_q: 0.024234
 47451/100000: episode: 6095, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000274, mae: 0.010827, mean_q: 0.025840
 47461/100000: episode: 6096, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001385, mae: 0.016928, mean_q: 0.036971
 47471/100000: episode: 6097, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001527, mae: 0.016945, mean_q: 0.026963
 47481/100000: episode: 6098, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000812, mae: 0.014577, mean_q: 0.027394
 47491/100000: episode: 6099, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000911, mae: 0.017275, mean_q: 0.032051
 47501/100000: episode: 6100, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000427, mae: 0.010585, mean_q: 0.015993
 47511/100000: episode: 6101, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000645, mae: 0.011023, mean_q: 0.022227
 47521/100000: episode: 6102, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001099, mae: 0.012306, mean_q: 0.023428
 47531/100000: episode: 6103, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000812, mae: 0.013124, mean_q: 0.025428
 47541/100000: episode: 6104, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001132, mae: 0.013305, mean_q: 0.024668
 47551/100000: episode: 6105, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000826, mae: 0.015031, mean_q: 0.024635
 47561/100000: episode: 6106, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000416, mae: 0.011185, mean_q: 0.019829
 47571/100000: episode: 6107, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000530, mae: 0.013065, mean_q: 0.023608
 47581/100000: episode: 6108, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000793, mae: 0.014225, mean_q: 0.033913
 47591/100000: episode: 6109, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000846, mae: 0.014841, mean_q: 0.037794
 47601/100000: episode: 6110, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001581, mae: 0.016707, mean_q: 0.029458
 47611/100000: episode: 6111, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001123, mae: 0.014386, mean_q: 0.020955
 47621/100000: episode: 6112, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001791, mae: 0.017221, mean_q: 0.024063
 47631/100000: episode: 6113, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001448, mae: 0.020799, mean_q: 0.036256
 47641/100000: episode: 6114, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000284, mae: 0.009892, mean_q: 0.019821
 47651/100000: episode: 6115, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001723, mae: 0.017498, mean_q: 0.034100
 47661/100000: episode: 6116, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000716, mae: 0.012572, mean_q: 0.020376
 47671/100000: episode: 6117, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001992, mae: 0.017370, mean_q: 0.021777
 47681/100000: episode: 6118, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001370, mae: 0.018167, mean_q: 0.035284
 47691/100000: episode: 6119, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000871, mae: 0.013215, mean_q: 0.026859
 47701/100000: episode: 6120, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001149, mae: 0.014789, mean_q: 0.022382
[Info] 1-TH LEVEL FOUND: 0.018399203196167946, Considering 18/100 traces
 47711/100000: episode: 6121, duration: 0.733s, episode steps: 10, steps per second: 14, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001475, mae: 0.017945, mean_q: 0.030384
 47717/100000: episode: 6122, duration: 0.032s, episode steps: 6, steps per second: 187, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000443, mae: 0.010586, mean_q: 0.013561
 47723/100000: episode: 6123, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000927, mae: 0.013930, mean_q: 0.021270
 47726/100000: episode: 6124, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000716, mae: 0.012351, mean_q: 0.021928
 47729/100000: episode: 6125, duration: 0.019s, episode steps: 3, steps per second: 157, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001971, mae: 0.019177, mean_q: 0.042188
 47732/100000: episode: 6126, duration: 0.019s, episode steps: 3, steps per second: 154, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001712, mae: 0.018621, mean_q: 0.033611
 47738/100000: episode: 6127, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000968, mae: 0.015787, mean_q: 0.029028
 47742/100000: episode: 6128, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000511, mae: 0.013964, mean_q: 0.021942
 47745/100000: episode: 6129, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001333, mae: 0.018119, mean_q: 0.024583
 47748/100000: episode: 6130, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001781, mae: 0.024349, mean_q: 0.049646
 47751/100000: episode: 6131, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000137, mae: 0.007869, mean_q: 0.016673
 47755/100000: episode: 6132, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000467, mae: 0.011464, mean_q: 0.025914
 47761/100000: episode: 6133, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000300, mae: 0.010417, mean_q: 0.023798
 47764/100000: episode: 6134, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000144, mae: 0.007991, mean_q: 0.019454
 47768/100000: episode: 6135, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001129, mae: 0.015999, mean_q: 0.032170
 47774/100000: episode: 6136, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000168, mae: 0.008332, mean_q: 0.012133
 47777/100000: episode: 6137, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000874, mae: 0.010078, mean_q: 0.010753
 47783/100000: episode: 6138, duration: 0.033s, episode steps: 6, steps per second: 184, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000455, mae: 0.010001, mean_q: 0.010622
 47786/100000: episode: 6139, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001143, mae: 0.018166, mean_q: 0.032201
 47792/100000: episode: 6140, duration: 0.035s, episode steps: 6, steps per second: 172, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001194, mae: 0.013277, mean_q: 0.019009
 47795/100000: episode: 6141, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001500, mae: 0.019085, mean_q: 0.037596
 47801/100000: episode: 6142, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000524, mae: 0.013565, mean_q: 0.023503
 47804/100000: episode: 6143, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000100, mae: 0.006443, mean_q: 0.010203
 47808/100000: episode: 6144, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000627, mae: 0.012650, mean_q: 0.024491
 47811/100000: episode: 6145, duration: 0.019s, episode steps: 3, steps per second: 157, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000577, mae: 0.013896, mean_q: 0.021924
 47814/100000: episode: 6146, duration: 0.020s, episode steps: 3, steps per second: 149, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000189, mae: 0.010075, mean_q: 0.024276
 47820/100000: episode: 6147, duration: 0.032s, episode steps: 6, steps per second: 189, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000858, mae: 0.011608, mean_q: 0.018975
 47826/100000: episode: 6148, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000995, mae: 0.015982, mean_q: 0.021186
 47829/100000: episode: 6149, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000636, mae: 0.012613, mean_q: 0.024693
 47833/100000: episode: 6150, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000138, mae: 0.008790, mean_q: 0.002456
 47837/100000: episode: 6151, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001489, mae: 0.018705, mean_q: 0.032260
 47843/100000: episode: 6152, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001446, mae: 0.014034, mean_q: 0.022344
 47849/100000: episode: 6153, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001026, mae: 0.017493, mean_q: 0.029018
 47852/100000: episode: 6154, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001801, mae: 0.022045, mean_q: 0.033232
 47858/100000: episode: 6155, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000893, mae: 0.013560, mean_q: 0.021914
 47862/100000: episode: 6156, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000132, mae: 0.007285, mean_q: 0.011399
 47865/100000: episode: 6157, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001538, mae: 0.014428, mean_q: 0.020243
 47871/100000: episode: 6158, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000510, mae: 0.011412, mean_q: 0.022846
 47877/100000: episode: 6159, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000761, mae: 0.012380, mean_q: 0.020690
 47883/100000: episode: 6160, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001232, mae: 0.013903, mean_q: 0.020613
 47886/100000: episode: 6161, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000903, mae: 0.012670, mean_q: 0.014127
 47889/100000: episode: 6162, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001024, mae: 0.017580, mean_q: 0.024161
 47892/100000: episode: 6163, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001742, mae: 0.020423, mean_q: 0.029737
 47898/100000: episode: 6164, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000586, mae: 0.014541, mean_q: 0.026328
 47904/100000: episode: 6165, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000314, mae: 0.011720, mean_q: 0.020606
 47907/100000: episode: 6166, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001085, mae: 0.016593, mean_q: 0.029099
 47910/100000: episode: 6167, duration: 0.017s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001426, mae: 0.014770, mean_q: 0.033530
 47914/100000: episode: 6168, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000356, mae: 0.009913, mean_q: 0.019863
 47920/100000: episode: 6169, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000788, mae: 0.009168, mean_q: 0.014898
 47923/100000: episode: 6170, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000434, mae: 0.011842, mean_q: 0.017439
 47929/100000: episode: 6171, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000669, mae: 0.013185, mean_q: 0.024714
 47932/100000: episode: 6172, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000480, mae: 0.010613, mean_q: 0.023271
 47935/100000: episode: 6173, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001268, mae: 0.015195, mean_q: 0.025280
 47938/100000: episode: 6174, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000509, mae: 0.012093, mean_q: 0.028062
 47944/100000: episode: 6175, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001188, mae: 0.012783, mean_q: 0.023103
 47947/100000: episode: 6176, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001539, mae: 0.019211, mean_q: 0.031095
 47950/100000: episode: 6177, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000249, mae: 0.010228, mean_q: 0.026250
 47956/100000: episode: 6178, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000515, mae: 0.011077, mean_q: 0.021510
 47959/100000: episode: 6179, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001501, mae: 0.014636, mean_q: 0.039248
 47963/100000: episode: 6180, duration: 0.020s, episode steps: 4, steps per second: 199, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000131, mae: 0.006599, mean_q: 0.016650
 47966/100000: episode: 6181, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001422, mae: 0.015995, mean_q: 0.030307
 47972/100000: episode: 6182, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000615, mae: 0.013556, mean_q: 0.031111
 47975/100000: episode: 6183, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000155, mae: 0.005902, mean_q: 0.007654
 47981/100000: episode: 6184, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000727, mae: 0.013284, mean_q: 0.027556
 47987/100000: episode: 6185, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000441, mae: 0.011857, mean_q: 0.020160
 47990/100000: episode: 6186, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000985, mae: 0.017014, mean_q: 0.027302
 47996/100000: episode: 6187, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000632, mae: 0.013392, mean_q: 0.024353
 47999/100000: episode: 6188, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000675, mae: 0.012840, mean_q: 0.021753
 48005/100000: episode: 6189, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001141, mae: 0.014251, mean_q: 0.024955
 48008/100000: episode: 6190, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000233, mae: 0.009760, mean_q: 0.026415
 48011/100000: episode: 6191, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001927, mae: 0.018611, mean_q: 0.026923
 48017/100000: episode: 6192, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000459, mae: 0.010341, mean_q: 0.018203
 48023/100000: episode: 6193, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000993, mae: 0.011517, mean_q: 0.024270
 48026/100000: episode: 6194, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000663, mae: 0.013727, mean_q: 0.016085
 48029/100000: episode: 6195, duration: 0.018s, episode steps: 3, steps per second: 162, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000262, mae: 0.009652, mean_q: 0.013088
 48035/100000: episode: 6196, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001422, mae: 0.017629, mean_q: 0.028992
 48039/100000: episode: 6197, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001105, mae: 0.018576, mean_q: 0.032309
 48042/100000: episode: 6198, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000384, mae: 0.012306, mean_q: 0.019309
 48045/100000: episode: 6199, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000281, mae: 0.008454, mean_q: 0.019666
 48048/100000: episode: 6200, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001376, mae: 0.017477, mean_q: 0.028511
 48051/100000: episode: 6201, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002294, mae: 0.019905, mean_q: 0.029699
 48055/100000: episode: 6202, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000328, mae: 0.007914, mean_q: 0.010489
[Info] 2-TH LEVEL FOUND: 0.09932141751050949, Considering 19/100 traces
 48058/100000: episode: 6203, duration: 0.778s, episode steps: 3, steps per second: 4, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000291, mae: 0.008224, mean_q: 0.022124
 48063/100000: episode: 6204, duration: 0.033s, episode steps: 5, steps per second: 154, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002104, mae: 0.015531, mean_q: 0.020963
 48068/100000: episode: 6205, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001595, mae: 0.019611, mean_q: 0.036701
 48073/100000: episode: 6206, duration: 0.030s, episode steps: 5, steps per second: 165, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000650, mae: 0.012249, mean_q: 0.019594
 48078/100000: episode: 6207, duration: 0.029s, episode steps: 5, steps per second: 174, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000321, mae: 0.010731, mean_q: 0.018180
 48083/100000: episode: 6208, duration: 0.030s, episode steps: 5, steps per second: 167, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000450, mae: 0.013241, mean_q: 0.024063
 48088/100000: episode: 6209, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000368, mae: 0.010919, mean_q: 0.020432
 48093/100000: episode: 6210, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000307, mae: 0.008396, mean_q: 0.014696
 48098/100000: episode: 6211, duration: 0.030s, episode steps: 5, steps per second: 167, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001292, mae: 0.014452, mean_q: 0.030532
 48103/100000: episode: 6212, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000675, mae: 0.011780, mean_q: 0.019139
 48108/100000: episode: 6213, duration: 0.030s, episode steps: 5, steps per second: 165, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000741, mae: 0.013204, mean_q: 0.025566
 48113/100000: episode: 6214, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000308, mae: 0.008503, mean_q: 0.018600
 48118/100000: episode: 6215, duration: 0.030s, episode steps: 5, steps per second: 164, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000207, mae: 0.008160, mean_q: 0.018350
 48123/100000: episode: 6216, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000868, mae: 0.012525, mean_q: 0.019664
 48128/100000: episode: 6217, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000232, mae: 0.009949, mean_q: 0.019088
 48133/100000: episode: 6218, duration: 0.030s, episode steps: 5, steps per second: 164, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000685, mae: 0.011483, mean_q: 0.018492
 48138/100000: episode: 6219, duration: 0.029s, episode steps: 5, steps per second: 173, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000812, mae: 0.011893, mean_q: 0.021659
 48143/100000: episode: 6220, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000607, mae: 0.010248, mean_q: 0.015497
 48148/100000: episode: 6221, duration: 0.029s, episode steps: 5, steps per second: 170, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000264, mae: 0.008078, mean_q: 0.013162
 48153/100000: episode: 6222, duration: 0.029s, episode steps: 5, steps per second: 171, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000451, mae: 0.011607, mean_q: 0.025175
 48158/100000: episode: 6223, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000247, mae: 0.009241, mean_q: 0.016380
 48163/100000: episode: 6224, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.001054, mae: 0.014088, mean_q: 0.024534
 48168/100000: episode: 6225, duration: 0.027s, episode steps: 5, steps per second: 189, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000362, mae: 0.008155, mean_q: 0.012621
 48173/100000: episode: 6226, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000944, mae: 0.011587, mean_q: 0.013286
 48178/100000: episode: 6227, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000643, mae: 0.012135, mean_q: 0.018099
 48183/100000: episode: 6228, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001248, mae: 0.016278, mean_q: 0.024234
 48188/100000: episode: 6229, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000387, mae: 0.012238, mean_q: 0.021158
[Info] FALSIFICATION!
 48192/100000: episode: 6230, duration: 0.272s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000650, mae: 0.012727, mean_q: 0.027860
 48197/100000: episode: 6231, duration: 0.029s, episode steps: 5, steps per second: 171, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000119, mae: 0.006996, mean_q: 0.011750
 48202/100000: episode: 6232, duration: 0.029s, episode steps: 5, steps per second: 173, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001253, mae: 0.014945, mean_q: 0.021092
 48207/100000: episode: 6233, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001108, mae: 0.012365, mean_q: 0.016275
 48212/100000: episode: 6234, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000337, mae: 0.010602, mean_q: 0.013517
 48217/100000: episode: 6235, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001033, mae: 0.015912, mean_q: 0.023713
[Info] FALSIFICATION!
 48221/100000: episode: 6236, duration: 0.265s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000705, mae: 0.014469, mean_q: 0.021277
 48226/100000: episode: 6237, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000936, mae: 0.015114, mean_q: 0.021072
 48231/100000: episode: 6238, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000088, mae: 0.007113, mean_q: 0.011107
 48236/100000: episode: 6239, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001925, mae: 0.017365, mean_q: 0.031713
 48241/100000: episode: 6240, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000278, mae: 0.009067, mean_q: 0.018926
 48246/100000: episode: 6241, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001250, mae: 0.015578, mean_q: 0.026907
 48251/100000: episode: 6242, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001510, mae: 0.014544, mean_q: 0.023904
 48256/100000: episode: 6243, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000644, mae: 0.010413, mean_q: 0.016897
 48261/100000: episode: 6244, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000393, mae: 0.007641, mean_q: 0.012962
 48266/100000: episode: 6245, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000233, mae: 0.007140, mean_q: 0.009905
 48271/100000: episode: 6246, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000609, mae: 0.012110, mean_q: 0.012207
 48276/100000: episode: 6247, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000906, mae: 0.014125, mean_q: 0.022008
 48281/100000: episode: 6248, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000789, mae: 0.014765, mean_q: 0.022383
 48286/100000: episode: 6249, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000788, mae: 0.014079, mean_q: 0.022073
 48291/100000: episode: 6250, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000499, mae: 0.012982, mean_q: 0.023842
 48296/100000: episode: 6251, duration: 0.028s, episode steps: 5, steps per second: 179, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000496, mae: 0.013053, mean_q: 0.022608
 48301/100000: episode: 6252, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000803, mae: 0.011850, mean_q: 0.020100
 48306/100000: episode: 6253, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001380, mae: 0.014062, mean_q: 0.022333
 48311/100000: episode: 6254, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000399, mae: 0.008584, mean_q: 0.017677
 48316/100000: episode: 6255, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000131, mae: 0.007634, mean_q: 0.017894
 48321/100000: episode: 6256, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001251, mae: 0.014311, mean_q: 0.027049
 48326/100000: episode: 6257, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000920, mae: 0.013845, mean_q: 0.022553
 48331/100000: episode: 6258, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000515, mae: 0.010664, mean_q: 0.014406
 48336/100000: episode: 6259, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000743, mae: 0.011547, mean_q: 0.014382
 48341/100000: episode: 6260, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000200, mae: 0.008556, mean_q: 0.014063
 48346/100000: episode: 6261, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000183, mae: 0.009485, mean_q: 0.020877
 48351/100000: episode: 6262, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000550, mae: 0.012361, mean_q: 0.019307
 48356/100000: episode: 6263, duration: 0.028s, episode steps: 5, steps per second: 182, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000204, mae: 0.008357, mean_q: 0.014370
 48361/100000: episode: 6264, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000527, mae: 0.010609, mean_q: 0.025382
 48366/100000: episode: 6265, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000505, mae: 0.010236, mean_q: 0.017636
 48371/100000: episode: 6266, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000843, mae: 0.013730, mean_q: 0.020695
 48376/100000: episode: 6267, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000196, mae: 0.009129, mean_q: 0.014395
[Info] FALSIFICATION!
 48380/100000: episode: 6268, duration: 0.179s, episode steps: 4, steps per second: 22, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000799, mae: 0.013442, mean_q: 0.020046
 48385/100000: episode: 6269, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000715, mae: 0.013181, mean_q: 0.020574
 48390/100000: episode: 6270, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001255, mae: 0.017582, mean_q: 0.025547
 48395/100000: episode: 6271, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001448, mae: 0.016136, mean_q: 0.033133
 48400/100000: episode: 6272, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000599, mae: 0.011041, mean_q: 0.018631
 48405/100000: episode: 6273, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000674, mae: 0.011429, mean_q: 0.017932
 48410/100000: episode: 6274, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000769, mae: 0.013360, mean_q: 0.023890
 48415/100000: episode: 6275, duration: 0.029s, episode steps: 5, steps per second: 173, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000188, mae: 0.009279, mean_q: 0.015823
[Info] FALSIFICATION!
 48419/100000: episode: 6276, duration: 0.287s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000407, mae: 0.011752, mean_q: 0.019748
 48424/100000: episode: 6277, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000424, mae: 0.011032, mean_q: 0.020255
 48429/100000: episode: 6278, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000694, mae: 0.009800, mean_q: 0.013927
 48434/100000: episode: 6279, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000090, mae: 0.005913, mean_q: 0.010017
 48439/100000: episode: 6280, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000767, mae: 0.010434, mean_q: 0.017152
 48444/100000: episode: 6281, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001027, mae: 0.012317, mean_q: 0.020441
 48449/100000: episode: 6282, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000526, mae: 0.009906, mean_q: 0.013650
 48454/100000: episode: 6283, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001268, mae: 0.016944, mean_q: 0.021974
[Info] Complete ISplit Iteration
[Info] Levels: [0.018399203, 0.09932142, 1.0188137]
[Info] Cond. Prob: [0.18, 0.19, 0.06]
[Info] Error Prob: 0.002052

 48459/100000: episode: 6284, duration: 0.778s, episode steps: 5, steps per second: 6, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000810, mae: 0.014229, mean_q: 0.021178
 48469/100000: episode: 6285, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000620, mae: 0.012552, mean_q: 0.020633
 48479/100000: episode: 6286, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000957, mae: 0.017276, mean_q: 0.029054
 48489/100000: episode: 6287, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000385, mae: 0.010183, mean_q: 0.024244
 48499/100000: episode: 6288, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000562, mae: 0.011674, mean_q: 0.018448
 48509/100000: episode: 6289, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000764, mae: 0.012359, mean_q: 0.025544
 48519/100000: episode: 6290, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000458, mae: 0.008736, mean_q: 0.017552
 48529/100000: episode: 6291, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000270, mae: 0.007122, mean_q: 0.010798
 48539/100000: episode: 6292, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000429, mae: 0.010369, mean_q: 0.015292
 48549/100000: episode: 6293, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000588, mae: 0.011650, mean_q: 0.018625
 48559/100000: episode: 6294, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000351, mae: 0.008987, mean_q: 0.016975
 48569/100000: episode: 6295, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001072, mae: 0.013807, mean_q: 0.018070
 48579/100000: episode: 6296, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000759, mae: 0.012841, mean_q: 0.021429
 48589/100000: episode: 6297, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000431, mae: 0.011802, mean_q: 0.021489
 48599/100000: episode: 6298, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000494, mae: 0.011024, mean_q: 0.017625
 48609/100000: episode: 6299, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000835, mae: 0.012743, mean_q: 0.015370
 48619/100000: episode: 6300, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000583, mae: 0.011462, mean_q: 0.020712
 48629/100000: episode: 6301, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000619, mae: 0.012182, mean_q: 0.027978
 48639/100000: episode: 6302, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001515, mae: 0.018415, mean_q: 0.033092
 48649/100000: episode: 6303, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000940, mae: 0.013163, mean_q: 0.029074
 48659/100000: episode: 6304, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000686, mae: 0.012579, mean_q: 0.021044
 48669/100000: episode: 6305, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000621, mae: 0.011207, mean_q: 0.020088
 48679/100000: episode: 6306, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000437, mae: 0.011606, mean_q: 0.017822
 48689/100000: episode: 6307, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000926, mae: 0.012827, mean_q: 0.020380
 48699/100000: episode: 6308, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000468, mae: 0.009075, mean_q: 0.014850
 48709/100000: episode: 6309, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000559, mae: 0.010401, mean_q: 0.020706
 48719/100000: episode: 6310, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000859, mae: 0.012413, mean_q: 0.019395
 48729/100000: episode: 6311, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000669, mae: 0.012548, mean_q: 0.019652
 48739/100000: episode: 6312, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000410, mae: 0.011448, mean_q: 0.020186
 48749/100000: episode: 6313, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000717, mae: 0.015024, mean_q: 0.029658
 48759/100000: episode: 6314, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000564, mae: 0.010323, mean_q: 0.015164
 48769/100000: episode: 6315, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000937, mae: 0.013048, mean_q: 0.020224
 48779/100000: episode: 6316, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000675, mae: 0.010926, mean_q: 0.014062
 48789/100000: episode: 6317, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000629, mae: 0.015149, mean_q: 0.026154
 48799/100000: episode: 6318, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000473, mae: 0.010519, mean_q: 0.018726
 48809/100000: episode: 6319, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000374, mae: 0.010056, mean_q: 0.016886
 48819/100000: episode: 6320, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000820, mae: 0.012691, mean_q: 0.020646
 48829/100000: episode: 6321, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000087, mae: 0.006435, mean_q: 0.011258
 48839/100000: episode: 6322, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000660, mae: 0.011350, mean_q: 0.017862
 48849/100000: episode: 6323, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000684, mae: 0.010907, mean_q: 0.021028
 48859/100000: episode: 6324, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000366, mae: 0.009572, mean_q: 0.014437
 48869/100000: episode: 6325, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001277, mae: 0.017014, mean_q: 0.023225
 48879/100000: episode: 6326, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000971, mae: 0.015237, mean_q: 0.028302
 48889/100000: episode: 6327, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001022, mae: 0.014020, mean_q: 0.022984
 48899/100000: episode: 6328, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000522, mae: 0.010710, mean_q: 0.015325
 48909/100000: episode: 6329, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000885, mae: 0.014088, mean_q: 0.025161
 48919/100000: episode: 6330, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000298, mae: 0.010052, mean_q: 0.018642
 48929/100000: episode: 6331, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001461, mae: 0.016074, mean_q: 0.029412
 48939/100000: episode: 6332, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000877, mae: 0.012437, mean_q: 0.013381
 48949/100000: episode: 6333, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000486, mae: 0.011796, mean_q: 0.018594
 48959/100000: episode: 6334, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000221, mae: 0.011196, mean_q: 0.019168
 48969/100000: episode: 6335, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000809, mae: 0.014084, mean_q: 0.021188
 48979/100000: episode: 6336, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000665, mae: 0.013549, mean_q: 0.021529
 48989/100000: episode: 6337, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000537, mae: 0.011354, mean_q: 0.015997
 48999/100000: episode: 6338, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000424, mae: 0.010506, mean_q: 0.014443
 49009/100000: episode: 6339, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001020, mae: 0.015580, mean_q: 0.024356
 49019/100000: episode: 6340, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000771, mae: 0.014853, mean_q: 0.024729
 49029/100000: episode: 6341, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000397, mae: 0.009078, mean_q: 0.014614
 49039/100000: episode: 6342, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000465, mae: 0.011104, mean_q: 0.014977
 49049/100000: episode: 6343, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000436, mae: 0.008655, mean_q: 0.012304
 49059/100000: episode: 6344, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000232, mae: 0.009501, mean_q: 0.021203
 49069/100000: episode: 6345, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000476, mae: 0.010505, mean_q: 0.019894
 49079/100000: episode: 6346, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000235, mae: 0.008334, mean_q: 0.013035
 49089/100000: episode: 6347, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000715, mae: 0.011651, mean_q: 0.022408
 49099/100000: episode: 6348, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000848, mae: 0.012856, mean_q: 0.028087
 49109/100000: episode: 6349, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000682, mae: 0.012625, mean_q: 0.020118
 49119/100000: episode: 6350, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000867, mae: 0.012847, mean_q: 0.022945
 49129/100000: episode: 6351, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000309, mae: 0.008837, mean_q: 0.015093
 49139/100000: episode: 6352, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000727, mae: 0.011382, mean_q: 0.019064
 49149/100000: episode: 6353, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000197, mae: 0.007352, mean_q: 0.012096
 49159/100000: episode: 6354, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000986, mae: 0.012226, mean_q: 0.017149
 49169/100000: episode: 6355, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000626, mae: 0.013020, mean_q: 0.022070
 49179/100000: episode: 6356, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000534, mae: 0.010200, mean_q: 0.015221
 49189/100000: episode: 6357, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000825, mae: 0.012409, mean_q: 0.023001
 49199/100000: episode: 6358, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000161, mae: 0.008264, mean_q: 0.018187
 49209/100000: episode: 6359, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000159, mae: 0.006777, mean_q: 0.012960
 49219/100000: episode: 6360, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000787, mae: 0.011080, mean_q: 0.017995
 49229/100000: episode: 6361, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000733, mae: 0.012249, mean_q: 0.021549
 49239/100000: episode: 6362, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001041, mae: 0.014594, mean_q: 0.022738
 49249/100000: episode: 6363, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000430, mae: 0.009972, mean_q: 0.016290
 49259/100000: episode: 6364, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000499, mae: 0.009921, mean_q: 0.016957
 49269/100000: episode: 6365, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000452, mae: 0.010795, mean_q: 0.017303
 49279/100000: episode: 6366, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000514, mae: 0.010259, mean_q: 0.016516
 49289/100000: episode: 6367, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000583, mae: 0.010284, mean_q: 0.014641
 49299/100000: episode: 6368, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000715, mae: 0.011817, mean_q: 0.020861
 49309/100000: episode: 6369, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001122, mae: 0.013612, mean_q: 0.022272
 49319/100000: episode: 6370, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000948, mae: 0.013991, mean_q: 0.020844
 49329/100000: episode: 6371, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000988, mae: 0.014139, mean_q: 0.023804
 49339/100000: episode: 6372, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000700, mae: 0.011467, mean_q: 0.018875
 49349/100000: episode: 6373, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000295, mae: 0.009221, mean_q: 0.015390
 49359/100000: episode: 6374, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000548, mae: 0.010260, mean_q: 0.016198
 49369/100000: episode: 6375, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001305, mae: 0.014634, mean_q: 0.018049
 49379/100000: episode: 6376, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000342, mae: 0.011588, mean_q: 0.019686
 49389/100000: episode: 6377, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000466, mae: 0.011216, mean_q: 0.016214
 49399/100000: episode: 6378, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000440, mae: 0.011113, mean_q: 0.021023
 49409/100000: episode: 6379, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000441, mae: 0.009114, mean_q: 0.019009
 49419/100000: episode: 6380, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001309, mae: 0.013886, mean_q: 0.025769
 49429/100000: episode: 6381, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000502, mae: 0.010796, mean_q: 0.013761
 49439/100000: episode: 6382, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001181, mae: 0.014442, mean_q: 0.023328
 49449/100000: episode: 6383, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000561, mae: 0.011580, mean_q: 0.018952
[Info] 1-TH LEVEL FOUND: 0.0027695512399077415, Considering 100/100 traces
 49459/100000: episode: 6384, duration: 0.723s, episode steps: 10, steps per second: 14, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000427, mae: 0.010277, mean_q: 0.016118
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.0027695512399077415
 49469/100000: episode: 6385, duration: 0.514s, episode steps: 10, steps per second: 19, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000487, mae: 0.010769, mean_q: 0.016096
 49479/100000: episode: 6386, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000626, mae: 0.012199, mean_q: 0.019264
 49489/100000: episode: 6387, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000617, mae: 0.011227, mean_q: 0.020592
 49499/100000: episode: 6388, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000683, mae: 0.012061, mean_q: 0.020461
 49509/100000: episode: 6389, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000460, mae: 0.010648, mean_q: 0.018308
 49519/100000: episode: 6390, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000350, mae: 0.009667, mean_q: 0.019171
 49529/100000: episode: 6391, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000542, mae: 0.009623, mean_q: 0.016511
 49539/100000: episode: 6392, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000612, mae: 0.009922, mean_q: 0.012335
 49549/100000: episode: 6393, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000476, mae: 0.009096, mean_q: 0.016489
 49559/100000: episode: 6394, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000709, mae: 0.011254, mean_q: 0.019795
 49569/100000: episode: 6395, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001431, mae: 0.016523, mean_q: 0.029409
 49579/100000: episode: 6396, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000264, mae: 0.008496, mean_q: 0.011621
 49589/100000: episode: 6397, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000767, mae: 0.012223, mean_q: 0.015035
 49599/100000: episode: 6398, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000391, mae: 0.009191, mean_q: 0.014246
 49609/100000: episode: 6399, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000703, mae: 0.011902, mean_q: 0.022815
 49619/100000: episode: 6400, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000143, mae: 0.006491, mean_q: 0.012583
 49629/100000: episode: 6401, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000337, mae: 0.008723, mean_q: 0.015000
 49639/100000: episode: 6402, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000291, mae: 0.009173, mean_q: 0.016322
 49649/100000: episode: 6403, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000665, mae: 0.009330, mean_q: 0.014807
 49659/100000: episode: 6404, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000580, mae: 0.009768, mean_q: 0.011536
 49669/100000: episode: 6405, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000722, mae: 0.012868, mean_q: 0.020100
 49679/100000: episode: 6406, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000314, mae: 0.009474, mean_q: 0.014631
 49689/100000: episode: 6407, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000632, mae: 0.011473, mean_q: 0.019943
 49699/100000: episode: 6408, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000580, mae: 0.010633, mean_q: 0.019686
 49709/100000: episode: 6409, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000550, mae: 0.010390, mean_q: 0.016128
 49719/100000: episode: 6410, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000298, mae: 0.008458, mean_q: 0.013069
 49729/100000: episode: 6411, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000198, mae: 0.007976, mean_q: 0.012742
 49739/100000: episode: 6412, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000857, mae: 0.013392, mean_q: 0.023588
 49749/100000: episode: 6413, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000397, mae: 0.008069, mean_q: 0.011918
 49759/100000: episode: 6414, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000408, mae: 0.009138, mean_q: 0.017134
 49769/100000: episode: 6415, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000814, mae: 0.013494, mean_q: 0.022311
 49779/100000: episode: 6416, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000280, mae: 0.007476, mean_q: 0.009963
 49789/100000: episode: 6417, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000302, mae: 0.006329, mean_q: 0.010070
 49799/100000: episode: 6418, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000258, mae: 0.008676, mean_q: 0.015742
 49809/100000: episode: 6419, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000525, mae: 0.011371, mean_q: 0.023301
 49819/100000: episode: 6420, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000387, mae: 0.010035, mean_q: 0.019779
 49829/100000: episode: 6421, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000586, mae: 0.009213, mean_q: 0.018848
 49839/100000: episode: 6422, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000911, mae: 0.013736, mean_q: 0.017860
 49849/100000: episode: 6423, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000513, mae: 0.010814, mean_q: 0.013665
 49859/100000: episode: 6424, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000267, mae: 0.008321, mean_q: 0.016165
 49869/100000: episode: 6425, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000396, mae: 0.010359, mean_q: 0.019292
 49879/100000: episode: 6426, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000601, mae: 0.009789, mean_q: 0.017818
 49889/100000: episode: 6427, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000639, mae: 0.011582, mean_q: 0.020043
 49899/100000: episode: 6428, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000818, mae: 0.011261, mean_q: 0.011439
 49909/100000: episode: 6429, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000529, mae: 0.009366, mean_q: 0.013459
 49919/100000: episode: 6430, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000589, mae: 0.010209, mean_q: 0.015351
 49929/100000: episode: 6431, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000600, mae: 0.009997, mean_q: 0.014460
 49939/100000: episode: 6432, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000243, mae: 0.008526, mean_q: 0.013977
 49949/100000: episode: 6433, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000551, mae: 0.010322, mean_q: 0.018276
 49959/100000: episode: 6434, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000544, mae: 0.008238, mean_q: 0.013300
 49969/100000: episode: 6435, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000604, mae: 0.011795, mean_q: 0.019568
 49979/100000: episode: 6436, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000827, mae: 0.012195, mean_q: 0.021378
 49989/100000: episode: 6437, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000261, mae: 0.008391, mean_q: 0.015505
 49999/100000: episode: 6438, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000469, mae: 0.009350, mean_q: 0.015339
 50009/100000: episode: 6439, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000196, mae: 0.007899, mean_q: 0.013327
 50019/100000: episode: 6440, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000298, mae: 0.009805, mean_q: 0.022437
 50029/100000: episode: 6441, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000415, mae: 0.009219, mean_q: 0.018786
 50039/100000: episode: 6442, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000469, mae: 0.009774, mean_q: 0.023503
 50049/100000: episode: 6443, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000488, mae: 0.009827, mean_q: 0.018365
 50059/100000: episode: 6444, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000787, mae: 0.013068, mean_q: 0.023816
 50069/100000: episode: 6445, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000660, mae: 0.011078, mean_q: 0.014136
 50079/100000: episode: 6446, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000903, mae: 0.013567, mean_q: 0.023661
 50089/100000: episode: 6447, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000826, mae: 0.013666, mean_q: 0.025361
 50099/100000: episode: 6448, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000629, mae: 0.009663, mean_q: 0.015674
 50109/100000: episode: 6449, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000576, mae: 0.010684, mean_q: 0.021625
 50119/100000: episode: 6450, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000758, mae: 0.012960, mean_q: 0.029922
 50129/100000: episode: 6451, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000233, mae: 0.007857, mean_q: 0.016556
 50139/100000: episode: 6452, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000474, mae: 0.008335, mean_q: 0.015005
 50149/100000: episode: 6453, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000199, mae: 0.007888, mean_q: 0.011573
 50159/100000: episode: 6454, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000518, mae: 0.008767, mean_q: 0.017509
 50169/100000: episode: 6455, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000662, mae: 0.010615, mean_q: 0.017535
 50179/100000: episode: 6456, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000404, mae: 0.008688, mean_q: 0.022032
 50189/100000: episode: 6457, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000945, mae: 0.012431, mean_q: 0.024839
 50199/100000: episode: 6458, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000869, mae: 0.011808, mean_q: 0.022656
 50209/100000: episode: 6459, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001198, mae: 0.013009, mean_q: 0.018489
 50219/100000: episode: 6460, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000734, mae: 0.011620, mean_q: 0.017701
 50229/100000: episode: 6461, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000924, mae: 0.013497, mean_q: 0.023103
 50239/100000: episode: 6462, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000359, mae: 0.008299, mean_q: 0.009819
 50249/100000: episode: 6463, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000682, mae: 0.011187, mean_q: 0.017017
 50259/100000: episode: 6464, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000813, mae: 0.011343, mean_q: 0.015079
 50269/100000: episode: 6465, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000532, mae: 0.013383, mean_q: 0.014697
 50279/100000: episode: 6466, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000711, mae: 0.010384, mean_q: 0.014763
 50289/100000: episode: 6467, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000152, mae: 0.006884, mean_q: 0.012485
 50299/100000: episode: 6468, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000132, mae: 0.007400, mean_q: 0.012640
 50309/100000: episode: 6469, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000131, mae: 0.007033, mean_q: 0.012321
 50319/100000: episode: 6470, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000833, mae: 0.010151, mean_q: 0.013256
 50329/100000: episode: 6471, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000441, mae: 0.009033, mean_q: 0.014573
 50339/100000: episode: 6472, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000606, mae: 0.010973, mean_q: 0.019503
 50349/100000: episode: 6473, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000376, mae: 0.007781, mean_q: 0.012935
 50359/100000: episode: 6474, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000385, mae: 0.008692, mean_q: 0.010305
 50369/100000: episode: 6475, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000461, mae: 0.009085, mean_q: 0.014076
 50379/100000: episode: 6476, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000676, mae: 0.012606, mean_q: 0.023413
 50389/100000: episode: 6477, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000138, mae: 0.006065, mean_q: 0.010980
 50399/100000: episode: 6478, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001064, mae: 0.014401, mean_q: 0.027081
 50409/100000: episode: 6479, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000662, mae: 0.011079, mean_q: 0.027481
 50419/100000: episode: 6480, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001244, mae: 0.012217, mean_q: 0.018959
 50429/100000: episode: 6481, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001275, mae: 0.019345, mean_q: 0.021576
 50439/100000: episode: 6482, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000612, mae: 0.012567, mean_q: 0.014507
 50449/100000: episode: 6483, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000476, mae: 0.012296, mean_q: 0.018229
 50459/100000: episode: 6484, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000971, mae: 0.014296, mean_q: 0.019079
[Info] 1-TH LEVEL FOUND: 0.007560575846582651, Considering 100/100 traces
 50469/100000: episode: 6485, duration: 0.715s, episode steps: 10, steps per second: 14, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000755, mae: 0.012276, mean_q: 0.009419
[Info] 2-TH LEVEL FOUND: 0.027384072542190552, Considering 15/100 traces
 50479/100000: episode: 6486, duration: 0.697s, episode steps: 10, steps per second: 14, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000738, mae: 0.015297, mean_q: 0.022665
 50483/100000: episode: 6487, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000367, mae: 0.013104, mean_q: 0.018630
 50486/100000: episode: 6488, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000621, mae: 0.012654, mean_q: 0.021297
 50492/100000: episode: 6489, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000493, mae: 0.009301, mean_q: 0.015271
 50495/100000: episode: 6490, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000313, mae: 0.010319, mean_q: 0.014613
 50499/100000: episode: 6491, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000109, mae: 0.006425, mean_q: 0.011018
 50502/100000: episode: 6492, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001587, mae: 0.020356, mean_q: 0.026212
 50506/100000: episode: 6493, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000161, mae: 0.007981, mean_q: 0.013586
 50512/100000: episode: 6494, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000715, mae: 0.012413, mean_q: 0.021871
 50515/100000: episode: 6495, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000501, mae: 0.009109, mean_q: 0.015906
 50518/100000: episode: 6496, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000272, mae: 0.010456, mean_q: 0.012986
 50522/100000: episode: 6497, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000107, mae: 0.008107, mean_q: 0.012473
 50525/100000: episode: 6498, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000153, mae: 0.009224, mean_q: 0.012299
 50528/100000: episode: 6499, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001157, mae: 0.013338, mean_q: 0.015294
 50531/100000: episode: 6500, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000094, mae: 0.006224, mean_q: 0.011209
 50534/100000: episode: 6501, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001204, mae: 0.013382, mean_q: 0.019623
 50537/100000: episode: 6502, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000272, mae: 0.010753, mean_q: 0.021204
 50540/100000: episode: 6503, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000127, mae: 0.008581, mean_q: 0.016329
 50544/100000: episode: 6504, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000054, mae: 0.004831, mean_q: 0.012125
 50547/100000: episode: 6505, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000719, mae: 0.011662, mean_q: 0.020360
 50551/100000: episode: 6506, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000683, mae: 0.010270, mean_q: 0.018991
 50555/100000: episode: 6507, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000156, mae: 0.007638, mean_q: 0.012343
 50558/100000: episode: 6508, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000159, mae: 0.008486, mean_q: 0.013232
 50562/100000: episode: 6509, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000434, mae: 0.010489, mean_q: 0.017018
 50568/100000: episode: 6510, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000814, mae: 0.010997, mean_q: 0.014197
 50574/100000: episode: 6511, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000602, mae: 0.010903, mean_q: 0.020601
 50578/100000: episode: 6512, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001447, mae: 0.017373, mean_q: 0.030156
 50582/100000: episode: 6513, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000590, mae: 0.011469, mean_q: 0.018887
 50585/100000: episode: 6514, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000198, mae: 0.009155, mean_q: 0.011829
 50588/100000: episode: 6515, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000109, mae: 0.008724, mean_q: 0.007750
 50594/100000: episode: 6516, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000205, mae: 0.008602, mean_q: 0.007906
 50598/100000: episode: 6517, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000252, mae: 0.008739, mean_q: 0.013814
 50602/100000: episode: 6518, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000334, mae: 0.010357, mean_q: 0.015879
 50605/100000: episode: 6519, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000105, mae: 0.007551, mean_q: 0.012927
 50611/100000: episode: 6520, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000222, mae: 0.007990, mean_q: 0.012594
 50615/100000: episode: 6521, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000770, mae: 0.009823, mean_q: 0.018202
 50621/100000: episode: 6522, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.001080, mae: 0.014470, mean_q: 0.022635
 50624/100000: episode: 6523, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000380, mae: 0.010428, mean_q: 0.017608
 50630/100000: episode: 6524, duration: 0.034s, episode steps: 6, steps per second: 176, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000309, mae: 0.009770, mean_q: 0.019791
 50633/100000: episode: 6525, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001198, mae: 0.016574, mean_q: 0.026470
 50637/100000: episode: 6526, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000713, mae: 0.014373, mean_q: 0.025299
 50641/100000: episode: 6527, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000690, mae: 0.013506, mean_q: 0.022170
 50645/100000: episode: 6528, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000707, mae: 0.010286, mean_q: 0.014175
 50649/100000: episode: 6529, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000498, mae: 0.009550, mean_q: 0.012457
 50652/100000: episode: 6530, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001238, mae: 0.015458, mean_q: 0.032253
 50656/100000: episode: 6531, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000235, mae: 0.007359, mean_q: 0.012722
 50660/100000: episode: 6532, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000171, mae: 0.007469, mean_q: 0.019729
 50664/100000: episode: 6533, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000508, mae: 0.008222, mean_q: 0.012623
 50670/100000: episode: 6534, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000419, mae: 0.008761, mean_q: 0.015381
 50676/100000: episode: 6535, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000499, mae: 0.009096, mean_q: 0.016973
 50680/100000: episode: 6536, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000747, mae: 0.011903, mean_q: 0.019086
 50686/100000: episode: 6537, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000996, mae: 0.013824, mean_q: 0.022707
 50690/100000: episode: 6538, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000082, mae: 0.007024, mean_q: 0.014027
 50693/100000: episode: 6539, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000108, mae: 0.006289, mean_q: 0.012340
 50696/100000: episode: 6540, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000215, mae: 0.008031, mean_q: 0.022967
 50702/100000: episode: 6541, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000432, mae: 0.009332, mean_q: 0.015636
 50706/100000: episode: 6542, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000500, mae: 0.011401, mean_q: 0.023748
 50709/100000: episode: 6543, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000693, mae: 0.012466, mean_q: 0.020471
 50713/100000: episode: 6544, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000367, mae: 0.011170, mean_q: 0.019229
 50717/100000: episode: 6545, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000169, mae: 0.008970, mean_q: 0.017676
 50720/100000: episode: 6546, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000221, mae: 0.007441, mean_q: 0.013215
 50723/100000: episode: 6547, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000092, mae: 0.005506, mean_q: 0.010981
 50726/100000: episode: 6548, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000469, mae: 0.009059, mean_q: 0.016077
 50730/100000: episode: 6549, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000982, mae: 0.011315, mean_q: 0.021298
 50734/100000: episode: 6550, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000983, mae: 0.013306, mean_q: 0.029419
 50737/100000: episode: 6551, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000099, mae: 0.007161, mean_q: 0.014837
 50740/100000: episode: 6552, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000605, mae: 0.008608, mean_q: 0.023109
 50744/100000: episode: 6553, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000541, mae: 0.011122, mean_q: 0.016671
 50747/100000: episode: 6554, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001366, mae: 0.015192, mean_q: 0.022011
 50750/100000: episode: 6555, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000644, mae: 0.011663, mean_q: 0.014247
 50753/100000: episode: 6556, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000839, mae: 0.011440, mean_q: 0.021661
 50759/100000: episode: 6557, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000333, mae: 0.010504, mean_q: 0.015790
 50763/100000: episode: 6558, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000553, mae: 0.011447, mean_q: 0.018434
 50767/100000: episode: 6559, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000477, mae: 0.011238, mean_q: 0.017265
 50771/100000: episode: 6560, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001012, mae: 0.014859, mean_q: 0.021090
 50775/100000: episode: 6561, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000604, mae: 0.009518, mean_q: 0.013795
 50779/100000: episode: 6562, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000245, mae: 0.005780, mean_q: 0.006871
 50785/100000: episode: 6563, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000157, mae: 0.005703, mean_q: 0.011844
 50788/100000: episode: 6564, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000962, mae: 0.011977, mean_q: 0.016754
 50791/100000: episode: 6565, duration: 0.017s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000664, mae: 0.013704, mean_q: 0.019049
 50797/100000: episode: 6566, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001051, mae: 0.015747, mean_q: 0.027878
 50800/100000: episode: 6567, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000822, mae: 0.013984, mean_q: 0.023260
 50803/100000: episode: 6568, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000402, mae: 0.011389, mean_q: 0.024633
 50806/100000: episode: 6569, duration: 0.019s, episode steps: 3, steps per second: 162, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000072, mae: 0.005077, mean_q: 0.010175
 50810/100000: episode: 6570, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002256, mae: 0.021474, mean_q: 0.033026
[Info] 3-TH LEVEL FOUND: 0.09817394614219666, Considering 16/100 traces
 50813/100000: episode: 6571, duration: 0.710s, episode steps: 3, steps per second: 4, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000066, mae: 0.006099, mean_q: 0.011478
 50818/100000: episode: 6572, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000329, mae: 0.009573, mean_q: 0.016472
 50823/100000: episode: 6573, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000217, mae: 0.007970, mean_q: 0.013908
 50825/100000: episode: 6574, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000185, mae: 0.007044, mean_q: 0.013713
 50827/100000: episode: 6575, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000169, mae: 0.007409, mean_q: 0.012635
 50832/100000: episode: 6576, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000176, mae: 0.007468, mean_q: 0.011519
 50834/100000: episode: 6577, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000085, mae: 0.006779, mean_q: 0.012049
 50836/100000: episode: 6578, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000745, mae: 0.010823, mean_q: 0.017759
 50841/100000: episode: 6579, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000452, mae: 0.010079, mean_q: 0.018051
 50846/100000: episode: 6580, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000232, mae: 0.008292, mean_q: 0.014079
 50851/100000: episode: 6581, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000134, mae: 0.007657, mean_q: 0.012562
 50856/100000: episode: 6582, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000825, mae: 0.013701, mean_q: 0.021785
 50861/100000: episode: 6583, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000592, mae: 0.011095, mean_q: 0.020205
 50863/100000: episode: 6584, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001097, mae: 0.014997, mean_q: 0.020327
 50868/100000: episode: 6585, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001110, mae: 0.013922, mean_q: 0.020548
 50870/100000: episode: 6586, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000387, mae: 0.011390, mean_q: 0.024395
 50875/100000: episode: 6587, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000502, mae: 0.009359, mean_q: 0.015668
 50880/100000: episode: 6588, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000282, mae: 0.009452, mean_q: 0.016506
[Info] FALSIFICATION!
 50884/100000: episode: 6589, duration: 0.278s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001102, mae: 0.012638, mean_q: 0.021211
 50886/100000: episode: 6590, duration: 0.015s, episode steps: 2, steps per second: 132, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000408, mae: 0.009184, mean_q: 0.023515
 50888/100000: episode: 6591, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001207, mae: 0.015850, mean_q: 0.022830
 50893/100000: episode: 6592, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000667, mae: 0.011847, mean_q: 0.021828
 50895/100000: episode: 6593, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000165, mae: 0.007721, mean_q: 0.013841
 50900/100000: episode: 6594, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000671, mae: 0.010198, mean_q: 0.014633
 50902/100000: episode: 6595, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000209, mae: 0.011427, mean_q: 0.030166
 50907/100000: episode: 6596, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000702, mae: 0.012512, mean_q: 0.023552
 50909/100000: episode: 6597, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000221, mae: 0.010214, mean_q: 0.020497
 50911/100000: episode: 6598, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000060, mae: 0.005926, mean_q: 0.009786
 50916/100000: episode: 6599, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000804, mae: 0.009629, mean_q: 0.015330
 50918/100000: episode: 6600, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000923, mae: 0.016245, mean_q: 0.035584
 50920/100000: episode: 6601, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000347, mae: 0.010579, mean_q: 0.017863
 50925/100000: episode: 6602, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000657, mae: 0.010150, mean_q: 0.015928
 50927/100000: episode: 6603, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001153, mae: 0.014568, mean_q: 0.024094
 50932/100000: episode: 6604, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000442, mae: 0.009293, mean_q: 0.015646
 50937/100000: episode: 6605, duration: 0.028s, episode steps: 5, steps per second: 176, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000322, mae: 0.009542, mean_q: 0.022920
 50939/100000: episode: 6606, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000213, mae: 0.012464, mean_q: 0.021534
[Info] FALSIFICATION!
 50943/100000: episode: 6607, duration: 0.198s, episode steps: 4, steps per second: 20, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000533, mae: 0.011266, mean_q: 0.018762
 50948/100000: episode: 6608, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000315, mae: 0.007756, mean_q: 0.017564
 50953/100000: episode: 6609, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000778, mae: 0.011814, mean_q: 0.020129
 50958/100000: episode: 6610, duration: 0.031s, episode steps: 5, steps per second: 164, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000917, mae: 0.013267, mean_q: 0.019376
 50963/100000: episode: 6611, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000548, mae: 0.010135, mean_q: 0.017291
 50968/100000: episode: 6612, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000905, mae: 0.012380, mean_q: 0.016087
[Info] FALSIFICATION!
 50972/100000: episode: 6613, duration: 0.279s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000416, mae: 0.009746, mean_q: 0.016459
 50977/100000: episode: 6614, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000843, mae: 0.012609, mean_q: 0.020094
 50979/100000: episode: 6615, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001593, mae: 0.014183, mean_q: 0.015542
[Info] FALSIFICATION!
 50983/100000: episode: 6616, duration: 0.195s, episode steps: 4, steps per second: 21, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000346, mae: 0.011198, mean_q: 0.020446
 50988/100000: episode: 6617, duration: 0.043s, episode steps: 5, steps per second: 116, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000837, mae: 0.019474, mean_q: 0.026280
 50990/100000: episode: 6618, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002208, mae: 0.022735, mean_q: 0.034931
 50992/100000: episode: 6619, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000275, mae: 0.013226, mean_q: 0.015219
 50994/100000: episode: 6620, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000501, mae: 0.015782, mean_q: 0.017281
 50999/100000: episode: 6621, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000445, mae: 0.011403, mean_q: 0.026852
 51004/100000: episode: 6622, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000887, mae: 0.011631, mean_q: 0.015147
 51009/100000: episode: 6623, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001333, mae: 0.015529, mean_q: 0.018123
 51014/100000: episode: 6624, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000585, mae: 0.011251, mean_q: 0.016411
 51016/100000: episode: 6625, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006478, mae: 0.036684, mean_q: 0.047400
 51018/100000: episode: 6626, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001529, mae: 0.023358, mean_q: 0.035427
 51023/100000: episode: 6627, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001483, mae: 0.020465, mean_q: 0.036568
 51025/100000: episode: 6628, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000481, mae: 0.011997, mean_q: 0.019951
 51027/100000: episode: 6629, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000992, mae: 0.014920, mean_q: 0.013021
 51032/100000: episode: 6630, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.004241, mae: 0.021013, mean_q: 0.020088
 51037/100000: episode: 6631, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000815, mae: 0.011706, mean_q: 0.019547
 51042/100000: episode: 6632, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000466, mae: 0.009647, mean_q: 0.018731
 51047/100000: episode: 6633, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000243, mae: 0.009377, mean_q: 0.019165
 51052/100000: episode: 6634, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000366, mae: 0.010362, mean_q: 0.022722
 51054/100000: episode: 6635, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000142, mae: 0.008166, mean_q: 0.015125
 51056/100000: episode: 6636, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000161, mae: 0.009422, mean_q: 0.024489
 51061/100000: episode: 6637, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001764, mae: 0.017976, mean_q: 0.028635
 51063/100000: episode: 6638, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000645, mae: 0.012835, mean_q: 0.038512
 51065/100000: episode: 6639, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001406, mae: 0.016000, mean_q: 0.030191
 51070/100000: episode: 6640, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000281, mae: 0.009140, mean_q: 0.013590
 51072/100000: episode: 6641, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000374, mae: 0.007462, mean_q: 0.008622
 51077/100000: episode: 6642, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000407, mae: 0.009902, mean_q: 0.019024
 51082/100000: episode: 6643, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000634, mae: 0.011451, mean_q: 0.021217
 51087/100000: episode: 6644, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000889, mae: 0.016173, mean_q: 0.032415
 51092/100000: episode: 6645, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000344, mae: 0.009457, mean_q: 0.028622
 51094/100000: episode: 6646, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000692, mae: 0.015220, mean_q: 0.020940
 51099/100000: episode: 6647, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001022, mae: 0.013930, mean_q: 0.018594
 51101/100000: episode: 6648, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000397, mae: 0.010815, mean_q: 0.025470
 51106/100000: episode: 6649, duration: 0.028s, episode steps: 5, steps per second: 179, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000396, mae: 0.010095, mean_q: 0.021726
 51111/100000: episode: 6650, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000378, mae: 0.010830, mean_q: 0.023784
 51113/100000: episode: 6651, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000063, mae: 0.006926, mean_q: 0.016783
 51115/100000: episode: 6652, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001166, mae: 0.014646, mean_q: 0.027394
 51117/100000: episode: 6653, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000051, mae: 0.005248, mean_q: 0.011932
 51119/100000: episode: 6654, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000214, mae: 0.005962, mean_q: 0.012462
[Info] Complete ISplit Iteration
[Info] Levels: [0.007560576, 0.027384073, 0.098173946, 1.1630399]
[Info] Cond. Prob: [1.0, 0.15, 0.16, 0.06]
[Info] Error Prob: 0.0014399999999999999

 51121/100000: episode: 6655, duration: 0.922s, episode steps: 2, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001102, mae: 0.015751, mean_q: 0.021757
 51131/100000: episode: 6656, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000980, mae: 0.011929, mean_q: 0.016555
 51141/100000: episode: 6657, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000935, mae: 0.016012, mean_q: 0.028465
 51151/100000: episode: 6658, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000959, mae: 0.012914, mean_q: 0.019546
 51161/100000: episode: 6659, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000720, mae: 0.012017, mean_q: 0.019646
 51171/100000: episode: 6660, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000594, mae: 0.012256, mean_q: 0.017379
 51181/100000: episode: 6661, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000623, mae: 0.011703, mean_q: 0.016919
 51191/100000: episode: 6662, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000504, mae: 0.010766, mean_q: 0.020490
 51201/100000: episode: 6663, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001023, mae: 0.014357, mean_q: 0.023892
 51211/100000: episode: 6664, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001272, mae: 0.016371, mean_q: 0.021178
 51221/100000: episode: 6665, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000941, mae: 0.014693, mean_q: 0.023197
 51231/100000: episode: 6666, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000649, mae: 0.013623, mean_q: 0.023187
 51241/100000: episode: 6667, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001044, mae: 0.014297, mean_q: 0.021548
 51251/100000: episode: 6668, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000781, mae: 0.011030, mean_q: 0.019286
 51261/100000: episode: 6669, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000866, mae: 0.015182, mean_q: 0.030644
 51271/100000: episode: 6670, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002138, mae: 0.017342, mean_q: 0.018198
 51281/100000: episode: 6671, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000284, mae: 0.009038, mean_q: 0.015242
 51291/100000: episode: 6672, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000258, mae: 0.010312, mean_q: 0.018810
 51301/100000: episode: 6673, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000803, mae: 0.012399, mean_q: 0.025155
 51311/100000: episode: 6674, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000897, mae: 0.014088, mean_q: 0.020874
 51321/100000: episode: 6675, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000504, mae: 0.012958, mean_q: 0.026276
 51331/100000: episode: 6676, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002069, mae: 0.021389, mean_q: 0.029383
 51341/100000: episode: 6677, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000315, mae: 0.011117, mean_q: 0.008311
 51351/100000: episode: 6678, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001781, mae: 0.014826, mean_q: 0.015965
 51361/100000: episode: 6679, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001358, mae: 0.020573, mean_q: 0.029081
 51371/100000: episode: 6680, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001789, mae: 0.023528, mean_q: 0.039005
 51381/100000: episode: 6681, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000797, mae: 0.014130, mean_q: 0.017832
 51391/100000: episode: 6682, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001228, mae: 0.014117, mean_q: 0.021788
 51401/100000: episode: 6683, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000649, mae: 0.013577, mean_q: 0.023444
 51411/100000: episode: 6684, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000353, mae: 0.008992, mean_q: 0.017593
 51421/100000: episode: 6685, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000558, mae: 0.011387, mean_q: 0.016915
 51431/100000: episode: 6686, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000453, mae: 0.010245, mean_q: 0.017550
 51441/100000: episode: 6687, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001520, mae: 0.013502, mean_q: 0.021579
 51451/100000: episode: 6688, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001197, mae: 0.018548, mean_q: 0.029954
 51461/100000: episode: 6689, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000706, mae: 0.012596, mean_q: 0.018060
 51471/100000: episode: 6690, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001039, mae: 0.014812, mean_q: 0.024183
 51481/100000: episode: 6691, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000567, mae: 0.010892, mean_q: 0.019926
 51491/100000: episode: 6692, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000695, mae: 0.011884, mean_q: 0.024204
 51501/100000: episode: 6693, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001148, mae: 0.014150, mean_q: 0.020784
 51511/100000: episode: 6694, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000716, mae: 0.012898, mean_q: 0.019798
 51521/100000: episode: 6695, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000687, mae: 0.012814, mean_q: 0.023310
 51531/100000: episode: 6696, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000827, mae: 0.014433, mean_q: 0.030482
 51541/100000: episode: 6697, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000752, mae: 0.011848, mean_q: 0.020748
 51551/100000: episode: 6698, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000256, mae: 0.007256, mean_q: 0.013795
 51561/100000: episode: 6699, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001049, mae: 0.012486, mean_q: 0.017919
 51571/100000: episode: 6700, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000964, mae: 0.016542, mean_q: 0.030772
 51581/100000: episode: 6701, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000499, mae: 0.012915, mean_q: 0.020374
 51591/100000: episode: 6702, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001084, mae: 0.015043, mean_q: 0.018045
 51601/100000: episode: 6703, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000678, mae: 0.011160, mean_q: 0.017604
 51611/100000: episode: 6704, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000825, mae: 0.013174, mean_q: 0.023501
 51621/100000: episode: 6705, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000889, mae: 0.013293, mean_q: 0.023261
 51631/100000: episode: 6706, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000412, mae: 0.010354, mean_q: 0.020062
 51641/100000: episode: 6707, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000636, mae: 0.010678, mean_q: 0.022174
 51651/100000: episode: 6708, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001804, mae: 0.019125, mean_q: 0.037790
 51661/100000: episode: 6709, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000745, mae: 0.012897, mean_q: 0.022142
 51671/100000: episode: 6710, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001078, mae: 0.015143, mean_q: 0.030191
 51681/100000: episode: 6711, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001027, mae: 0.014422, mean_q: 0.028817
 51691/100000: episode: 6712, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001112, mae: 0.014448, mean_q: 0.034633
 51701/100000: episode: 6713, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001122, mae: 0.014916, mean_q: 0.024875
 51711/100000: episode: 6714, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000393, mae: 0.012261, mean_q: 0.017882
 51721/100000: episode: 6715, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001427, mae: 0.018169, mean_q: 0.022654
 51731/100000: episode: 6716, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000907, mae: 0.012101, mean_q: 0.017262
 51741/100000: episode: 6717, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001263, mae: 0.016025, mean_q: 0.020718
 51751/100000: episode: 6718, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000931, mae: 0.015577, mean_q: 0.025233
 51761/100000: episode: 6719, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000753, mae: 0.014060, mean_q: 0.026772
 51771/100000: episode: 6720, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000627, mae: 0.012243, mean_q: 0.017225
 51781/100000: episode: 6721, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000695, mae: 0.010622, mean_q: 0.016826
 51791/100000: episode: 6722, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000871, mae: 0.013586, mean_q: 0.024155
 51801/100000: episode: 6723, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000574, mae: 0.010830, mean_q: 0.018034
 51811/100000: episode: 6724, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000463, mae: 0.008832, mean_q: 0.015625
 51821/100000: episode: 6725, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000944, mae: 0.012958, mean_q: 0.019833
 51831/100000: episode: 6726, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000915, mae: 0.014314, mean_q: 0.027514
 51841/100000: episode: 6727, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000704, mae: 0.012334, mean_q: 0.025386
 51851/100000: episode: 6728, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000971, mae: 0.012293, mean_q: 0.016484
 51861/100000: episode: 6729, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000687, mae: 0.013026, mean_q: 0.021039
 51871/100000: episode: 6730, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000749, mae: 0.013858, mean_q: 0.023978
 51881/100000: episode: 6731, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000863, mae: 0.013516, mean_q: 0.020413
 51891/100000: episode: 6732, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000697, mae: 0.013218, mean_q: 0.022439
 51901/100000: episode: 6733, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000693, mae: 0.011388, mean_q: 0.017886
 51911/100000: episode: 6734, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001467, mae: 0.016191, mean_q: 0.024929
 51921/100000: episode: 6735, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000972, mae: 0.013962, mean_q: 0.021861
 51931/100000: episode: 6736, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001049, mae: 0.017414, mean_q: 0.033574
 51941/100000: episode: 6737, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000743, mae: 0.012608, mean_q: 0.027326
 51951/100000: episode: 6738, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000599, mae: 0.011030, mean_q: 0.015929
 51961/100000: episode: 6739, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000885, mae: 0.013385, mean_q: 0.018398
 51971/100000: episode: 6740, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001068, mae: 0.010887, mean_q: 0.014527
 51981/100000: episode: 6741, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000650, mae: 0.010470, mean_q: 0.016554
 51991/100000: episode: 6742, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001466, mae: 0.016688, mean_q: 0.025573
 52001/100000: episode: 6743, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001216, mae: 0.015741, mean_q: 0.025505
 52011/100000: episode: 6744, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000579, mae: 0.011156, mean_q: 0.021506
 52021/100000: episode: 6745, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000370, mae: 0.009936, mean_q: 0.018304
 52031/100000: episode: 6746, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000498, mae: 0.009738, mean_q: 0.019204
 52041/100000: episode: 6747, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000450, mae: 0.011644, mean_q: 0.020344
 52051/100000: episode: 6748, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000627, mae: 0.010774, mean_q: 0.016712
 52061/100000: episode: 6749, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000509, mae: 0.011626, mean_q: 0.014546
 52071/100000: episode: 6750, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000514, mae: 0.009640, mean_q: 0.011854
 52081/100000: episode: 6751, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001118, mae: 0.015707, mean_q: 0.027982
 52091/100000: episode: 6752, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000765, mae: 0.017554, mean_q: 0.034178
 52101/100000: episode: 6753, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000527, mae: 0.010115, mean_q: 0.016232
 52111/100000: episode: 6754, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001176, mae: 0.013609, mean_q: 0.020323
[Info] 1-TH LEVEL FOUND: 0.023668156936764717, Considering 13/100 traces
 52121/100000: episode: 6755, duration: 0.712s, episode steps: 10, steps per second: 14, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000759, mae: 0.014246, mean_q: 0.025262
 52124/100000: episode: 6756, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000919, mae: 0.011401, mean_q: 0.021657
 52127/100000: episode: 6757, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000878, mae: 0.013402, mean_q: 0.030391
 52130/100000: episode: 6758, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000713, mae: 0.011709, mean_q: 0.018291
 52133/100000: episode: 6759, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000770, mae: 0.012263, mean_q: 0.017942
 52137/100000: episode: 6760, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001661, mae: 0.019613, mean_q: 0.038074
 52140/100000: episode: 6761, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001075, mae: 0.016024, mean_q: 0.030036
 52143/100000: episode: 6762, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000479, mae: 0.009382, mean_q: 0.017310
 52147/100000: episode: 6763, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001002, mae: 0.014601, mean_q: 0.027388
 52150/100000: episode: 6764, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000925, mae: 0.012588, mean_q: 0.021130
 52154/100000: episode: 6765, duration: 0.025s, episode steps: 4, steps per second: 163, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000293, mae: 0.009896, mean_q: 0.018814
 52157/100000: episode: 6766, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000935, mae: 0.011465, mean_q: 0.017946
 52160/100000: episode: 6767, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000124, mae: 0.007435, mean_q: 0.005304
 52163/100000: episode: 6768, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001670, mae: 0.015799, mean_q: 0.012596
 52166/100000: episode: 6769, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000466, mae: 0.009010, mean_q: 0.013593
 52169/100000: episode: 6770, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001172, mae: 0.011137, mean_q: 0.015905
 52172/100000: episode: 6771, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000457, mae: 0.010684, mean_q: 0.019217
 52175/100000: episode: 6772, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000642, mae: 0.013226, mean_q: 0.021708
 52179/100000: episode: 6773, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000555, mae: 0.010678, mean_q: 0.019064
 52182/100000: episode: 6774, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000072, mae: 0.007343, mean_q: 0.014174
 52185/100000: episode: 6775, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002093, mae: 0.018253, mean_q: 0.023463
 52188/100000: episode: 6776, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001261, mae: 0.016522, mean_q: 0.034623
 52191/100000: episode: 6777, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001415, mae: 0.016736, mean_q: 0.032558
 52195/100000: episode: 6778, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000601, mae: 0.013412, mean_q: 0.031163
 52198/100000: episode: 6779, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001040, mae: 0.015134, mean_q: 0.025636
 52202/100000: episode: 6780, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000710, mae: 0.009816, mean_q: 0.018073
 52206/100000: episode: 6781, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000097, mae: 0.005878, mean_q: 0.010003
 52209/100000: episode: 6782, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000112, mae: 0.006728, mean_q: 0.011101
 52213/100000: episode: 6783, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000668, mae: 0.011990, mean_q: 0.019188
 52216/100000: episode: 6784, duration: 0.020s, episode steps: 3, steps per second: 153, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000082, mae: 0.006504, mean_q: 0.008413
 52219/100000: episode: 6785, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000109, mae: 0.008097, mean_q: 0.012800
 52222/100000: episode: 6786, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000896, mae: 0.011940, mean_q: 0.026204
 52225/100000: episode: 6787, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001366, mae: 0.015068, mean_q: 0.030052
 52229/100000: episode: 6788, duration: 0.027s, episode steps: 4, steps per second: 151, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001151, mae: 0.015831, mean_q: 0.023220
 52232/100000: episode: 6789, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001091, mae: 0.013809, mean_q: 0.027622
 52235/100000: episode: 6790, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000904, mae: 0.013611, mean_q: 0.020205
 52238/100000: episode: 6791, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001245, mae: 0.015990, mean_q: 0.027182
 52241/100000: episode: 6792, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000925, mae: 0.015050, mean_q: 0.039295
 52244/100000: episode: 6793, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001982, mae: 0.019789, mean_q: 0.026255
 52247/100000: episode: 6794, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000283, mae: 0.008752, mean_q: 0.012878
 52250/100000: episode: 6795, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001440, mae: 0.018633, mean_q: 0.031401
 52253/100000: episode: 6796, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001179, mae: 0.016344, mean_q: 0.034304
 52256/100000: episode: 6797, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000083, mae: 0.006573, mean_q: 0.010406
 52259/100000: episode: 6798, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000111, mae: 0.007221, mean_q: 0.013293
 52262/100000: episode: 6799, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000330, mae: 0.008555, mean_q: 0.012125
 52265/100000: episode: 6800, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000152, mae: 0.007502, mean_q: 0.010759
 52268/100000: episode: 6801, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.003761, mae: 0.024853, mean_q: 0.029705
 52271/100000: episode: 6802, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001787, mae: 0.022732, mean_q: 0.036125
 52275/100000: episode: 6803, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000189, mae: 0.010462, mean_q: 0.025427
 52279/100000: episode: 6804, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000282, mae: 0.008690, mean_q: 0.018130
 52282/100000: episode: 6805, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000221, mae: 0.009585, mean_q: 0.015222
 52285/100000: episode: 6806, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001580, mae: 0.012950, mean_q: 0.017812
 52289/100000: episode: 6807, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001472, mae: 0.015483, mean_q: 0.021774
 52292/100000: episode: 6808, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000333, mae: 0.009847, mean_q: 0.013715
 52295/100000: episode: 6809, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001083, mae: 0.017756, mean_q: 0.035473
 52298/100000: episode: 6810, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001687, mae: 0.017846, mean_q: 0.034451
 52301/100000: episode: 6811, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000475, mae: 0.014650, mean_q: 0.038987
 52304/100000: episode: 6812, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000854, mae: 0.016218, mean_q: 0.035940
 52307/100000: episode: 6813, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000101, mae: 0.005403, mean_q: 0.012441
 52310/100000: episode: 6814, duration: 0.019s, episode steps: 3, steps per second: 162, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000886, mae: 0.014013, mean_q: 0.027404
 52313/100000: episode: 6815, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000900, mae: 0.013231, mean_q: 0.022597
 52316/100000: episode: 6816, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001413, mae: 0.018776, mean_q: 0.023551
 52319/100000: episode: 6817, duration: 0.019s, episode steps: 3, steps per second: 154, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000645, mae: 0.013446, mean_q: 0.018225
 52323/100000: episode: 6818, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000296, mae: 0.007589, mean_q: 0.016880
 52327/100000: episode: 6819, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001048, mae: 0.015646, mean_q: 0.024698
 52330/100000: episode: 6820, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000034, mae: 0.004506, mean_q: 0.010146
 52333/100000: episode: 6821, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001114, mae: 0.014000, mean_q: 0.022920
 52336/100000: episode: 6822, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001570, mae: 0.019425, mean_q: 0.023773
 52340/100000: episode: 6823, duration: 0.024s, episode steps: 4, steps per second: 167, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001380, mae: 0.012206, mean_q: 0.021807
 52343/100000: episode: 6824, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000312, mae: 0.007838, mean_q: 0.012190
 52346/100000: episode: 6825, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000845, mae: 0.010908, mean_q: 0.015755
 52350/100000: episode: 6826, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000525, mae: 0.014713, mean_q: 0.030504
 52354/100000: episode: 6827, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001098, mae: 0.016732, mean_q: 0.034040
 52357/100000: episode: 6828, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000331, mae: 0.009777, mean_q: 0.026973
 52360/100000: episode: 6829, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000905, mae: 0.012008, mean_q: 0.020955
 52364/100000: episode: 6830, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000301, mae: 0.009125, mean_q: 0.020172
 52368/100000: episode: 6831, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001284, mae: 0.015000, mean_q: 0.021521
 52371/100000: episode: 6832, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000119, mae: 0.008086, mean_q: 0.010648
 52375/100000: episode: 6833, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002360, mae: 0.022533, mean_q: 0.038598
 52378/100000: episode: 6834, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000745, mae: 0.013220, mean_q: 0.022168
 52381/100000: episode: 6835, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000228, mae: 0.010040, mean_q: 0.018513
 52384/100000: episode: 6836, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000286, mae: 0.010874, mean_q: 0.022645
 52387/100000: episode: 6837, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001524, mae: 0.019132, mean_q: 0.034174
 52390/100000: episode: 6838, duration: 0.020s, episode steps: 3, steps per second: 153, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000857, mae: 0.011108, mean_q: 0.013319
 52393/100000: episode: 6839, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000206, mae: 0.010916, mean_q: 0.006633
 52396/100000: episode: 6840, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001040, mae: 0.015681, mean_q: 0.016138
 52399/100000: episode: 6841, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000281, mae: 0.009790, mean_q: 0.008416
[Info] 2-TH LEVEL FOUND: 0.06799543648958206, Considering 10/100 traces
 52402/100000: episode: 6842, duration: 0.793s, episode steps: 3, steps per second: 4, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000687, mae: 0.009831, mean_q: 0.015331
 52405/100000: episode: 6843, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001326, mae: 0.015539, mean_q: 0.018082
 52408/100000: episode: 6844, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000684, mae: 0.014350, mean_q: 0.022465
 52411/100000: episode: 6845, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000119, mae: 0.009559, mean_q: 0.014053
 52414/100000: episode: 6846, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000361, mae: 0.010855, mean_q: 0.016613
 52417/100000: episode: 6847, duration: 0.019s, episode steps: 3, steps per second: 157, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001076, mae: 0.018790, mean_q: 0.035027
 52420/100000: episode: 6848, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000447, mae: 0.015775, mean_q: 0.033750
 52423/100000: episode: 6849, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000281, mae: 0.010672, mean_q: 0.020324
 52426/100000: episode: 6850, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000470, mae: 0.011603, mean_q: 0.028004
 52429/100000: episode: 6851, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000965, mae: 0.011162, mean_q: 0.018125
 52432/100000: episode: 6852, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001038, mae: 0.014624, mean_q: 0.015741
 52435/100000: episode: 6853, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001089, mae: 0.013351, mean_q: 0.016206
 52438/100000: episode: 6854, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000376, mae: 0.010081, mean_q: 0.021594
 52441/100000: episode: 6855, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000674, mae: 0.009356, mean_q: 0.015151
 52444/100000: episode: 6856, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000967, mae: 0.014288, mean_q: 0.035485
 52447/100000: episode: 6857, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000615, mae: 0.009270, mean_q: 0.017870
 52450/100000: episode: 6858, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000247, mae: 0.006887, mean_q: 0.011988
 52453/100000: episode: 6859, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001876, mae: 0.015826, mean_q: 0.023170
 52456/100000: episode: 6860, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001080, mae: 0.011627, mean_q: 0.018061
 52459/100000: episode: 6861, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000539, mae: 0.009894, mean_q: 0.012318
 52462/100000: episode: 6862, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000732, mae: 0.014304, mean_q: 0.037895
 52465/100000: episode: 6863, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001209, mae: 0.011924, mean_q: 0.014755
 52468/100000: episode: 6864, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000800, mae: 0.013350, mean_q: 0.027144
 52471/100000: episode: 6865, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001445, mae: 0.013849, mean_q: 0.025685
 52474/100000: episode: 6866, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001680, mae: 0.017016, mean_q: 0.023779
 52477/100000: episode: 6867, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001117, mae: 0.012748, mean_q: 0.021105
 52480/100000: episode: 6868, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000260, mae: 0.007973, mean_q: 0.021501
 52483/100000: episode: 6869, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000381, mae: 0.011244, mean_q: 0.024631
 52486/100000: episode: 6870, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000837, mae: 0.012159, mean_q: 0.020761
 52489/100000: episode: 6871, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000344, mae: 0.012103, mean_q: 0.024785
 52492/100000: episode: 6872, duration: 0.017s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000410, mae: 0.009924, mean_q: 0.020058
 52495/100000: episode: 6873, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000205, mae: 0.008097, mean_q: 0.018663
 52498/100000: episode: 6874, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000954, mae: 0.011661, mean_q: 0.023861
 52501/100000: episode: 6875, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002170, mae: 0.018770, mean_q: 0.033823
 52504/100000: episode: 6876, duration: 0.019s, episode steps: 3, steps per second: 155, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000500, mae: 0.011938, mean_q: 0.015327
 52507/100000: episode: 6877, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001491, mae: 0.018107, mean_q: 0.022258
 52510/100000: episode: 6878, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000109, mae: 0.006196, mean_q: 0.011784
 52513/100000: episode: 6879, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001074, mae: 0.013690, mean_q: 0.020506
 52516/100000: episode: 6880, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000491, mae: 0.008629, mean_q: 0.015458
 52519/100000: episode: 6881, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000607, mae: 0.012942, mean_q: 0.026540
 52522/100000: episode: 6882, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000458, mae: 0.010985, mean_q: 0.018833
 52525/100000: episode: 6883, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000986, mae: 0.014851, mean_q: 0.029220
 52528/100000: episode: 6884, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000923, mae: 0.015550, mean_q: 0.025131
 52531/100000: episode: 6885, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000909, mae: 0.013804, mean_q: 0.024526
 52534/100000: episode: 6886, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000075, mae: 0.005738, mean_q: 0.012166
 52537/100000: episode: 6887, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001480, mae: 0.016275, mean_q: 0.036189
 52540/100000: episode: 6888, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001480, mae: 0.013018, mean_q: 0.018321
 52543/100000: episode: 6889, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000849, mae: 0.010141, mean_q: 0.010665
 52546/100000: episode: 6890, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000275, mae: 0.010507, mean_q: 0.007551
 52549/100000: episode: 6891, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000522, mae: 0.007583, mean_q: 0.010924
 52552/100000: episode: 6892, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000451, mae: 0.009415, mean_q: 0.018002
 52555/100000: episode: 6893, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001120, mae: 0.012642, mean_q: 0.020334
 52558/100000: episode: 6894, duration: 0.023s, episode steps: 3, steps per second: 131, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002189, mae: 0.020287, mean_q: 0.033074
 52561/100000: episode: 6895, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001443, mae: 0.017333, mean_q: 0.025966
 52564/100000: episode: 6896, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000164, mae: 0.009738, mean_q: 0.018408
 52567/100000: episode: 6897, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002432, mae: 0.022126, mean_q: 0.033697
 52570/100000: episode: 6898, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000320, mae: 0.007624, mean_q: 0.010770
 52573/100000: episode: 6899, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000079, mae: 0.005364, mean_q: 0.010262
 52576/100000: episode: 6900, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001021, mae: 0.013127, mean_q: 0.021080
 52579/100000: episode: 6901, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000291, mae: 0.009182, mean_q: 0.022666
 52582/100000: episode: 6902, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001253, mae: 0.012990, mean_q: 0.025562
 52585/100000: episode: 6903, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000906, mae: 0.013404, mean_q: 0.021424
 52588/100000: episode: 6904, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000137, mae: 0.007561, mean_q: 0.015176
 52591/100000: episode: 6905, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002329, mae: 0.016016, mean_q: 0.011772
 52594/100000: episode: 6906, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000373, mae: 0.010655, mean_q: 0.019888
 52597/100000: episode: 6907, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000942, mae: 0.011225, mean_q: 0.017373
 52600/100000: episode: 6908, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000551, mae: 0.011415, mean_q: 0.021098
 52603/100000: episode: 6909, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000300, mae: 0.009449, mean_q: 0.015760
 52606/100000: episode: 6910, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000132, mae: 0.008310, mean_q: 0.015103
 52609/100000: episode: 6911, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002890, mae: 0.016313, mean_q: 0.019257
 52612/100000: episode: 6912, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000359, mae: 0.009116, mean_q: 0.017753
 52615/100000: episode: 6913, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001042, mae: 0.013453, mean_q: 0.017068
 52618/100000: episode: 6914, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000166, mae: 0.006577, mean_q: 0.013651
 52621/100000: episode: 6915, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002754, mae: 0.014939, mean_q: 0.027203
 52624/100000: episode: 6916, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000757, mae: 0.010213, mean_q: 0.016782
 52627/100000: episode: 6917, duration: 0.020s, episode steps: 3, steps per second: 151, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001068, mae: 0.012729, mean_q: 0.015290
 52630/100000: episode: 6918, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000822, mae: 0.013915, mean_q: 0.022227
 52633/100000: episode: 6919, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000392, mae: 0.010656, mean_q: 0.019540
 52636/100000: episode: 6920, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000307, mae: 0.008424, mean_q: 0.012374
 52639/100000: episode: 6921, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000111, mae: 0.007546, mean_q: 0.009556
 52642/100000: episode: 6922, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001020, mae: 0.014286, mean_q: 0.025096
 52645/100000: episode: 6923, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000063, mae: 0.005726, mean_q: 0.009433
 52648/100000: episode: 6924, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000027, mae: 0.004330, mean_q: 0.007924
 52651/100000: episode: 6925, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000582, mae: 0.011127, mean_q: 0.023985
 52654/100000: episode: 6926, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000547, mae: 0.012597, mean_q: 0.021303
 52657/100000: episode: 6927, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000484, mae: 0.011625, mean_q: 0.019105
 52660/100000: episode: 6928, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000238, mae: 0.007658, mean_q: 0.011696
 52663/100000: episode: 6929, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000217, mae: 0.008381, mean_q: 0.018576
 52666/100000: episode: 6930, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001764, mae: 0.012682, mean_q: 0.015490
 52669/100000: episode: 6931, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001925, mae: 0.015655, mean_q: 0.019532
[Info] 3-TH LEVEL FOUND: 0.13005006313323975, Considering 100/100 traces
 52672/100000: episode: 6932, duration: 0.717s, episode steps: 3, steps per second: 4, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000266, mae: 0.009990, mean_q: 0.023489
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.13005006313323975
 52675/100000: episode: 6933, duration: 0.503s, episode steps: 3, steps per second: 6, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001077, mae: 0.017101, mean_q: 0.031671
 52685/100000: episode: 6934, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000542, mae: 0.009153, mean_q: 0.010648
 52695/100000: episode: 6935, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000680, mae: 0.010150, mean_q: 0.015403
 52705/100000: episode: 6936, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000549, mae: 0.009358, mean_q: 0.020753
 52715/100000: episode: 6937, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000400, mae: 0.006925, mean_q: 0.012095
 52725/100000: episode: 6938, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000284, mae: 0.006696, mean_q: 0.011336
 52735/100000: episode: 6939, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000397, mae: 0.008536, mean_q: 0.024003
 52745/100000: episode: 6940, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000317, mae: 0.007321, mean_q: 0.016624
 52755/100000: episode: 6941, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000245, mae: 0.007091, mean_q: 0.012278
 52765/100000: episode: 6942, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000525, mae: 0.008597, mean_q: 0.018049
 52775/100000: episode: 6943, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000313, mae: 0.007644, mean_q: 0.012584
 52785/100000: episode: 6944, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000465, mae: 0.008495, mean_q: 0.015273
 52795/100000: episode: 6945, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000949, mae: 0.010463, mean_q: 0.018609
 52805/100000: episode: 6946, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000363, mae: 0.007808, mean_q: 0.009170
 52815/100000: episode: 6947, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000266, mae: 0.007014, mean_q: 0.009099
 52825/100000: episode: 6948, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000525, mae: 0.009023, mean_q: 0.012683
 52835/100000: episode: 6949, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000192, mae: 0.008862, mean_q: 0.016783
 52845/100000: episode: 6950, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000312, mae: 0.006174, mean_q: 0.010175
 52855/100000: episode: 6951, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000348, mae: 0.007363, mean_q: 0.012388
 52865/100000: episode: 6952, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000334, mae: 0.007056, mean_q: 0.016875
 52875/100000: episode: 6953, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000717, mae: 0.008893, mean_q: 0.014433
 52885/100000: episode: 6954, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000481, mae: 0.008585, mean_q: 0.017759
 52895/100000: episode: 6955, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000461, mae: 0.008472, mean_q: 0.016511
 52905/100000: episode: 6956, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000649, mae: 0.009805, mean_q: 0.017259
 52915/100000: episode: 6957, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001333, mae: 0.008442, mean_q: 0.009269
 52925/100000: episode: 6958, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000477, mae: 0.010744, mean_q: 0.019784
 52935/100000: episode: 6959, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000446, mae: 0.008604, mean_q: 0.016109
 52945/100000: episode: 6960, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000438, mae: 0.007871, mean_q: 0.012329
 52955/100000: episode: 6961, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000309, mae: 0.007124, mean_q: 0.012215
 52965/100000: episode: 6962, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000508, mae: 0.008152, mean_q: 0.014079
 52975/100000: episode: 6963, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000687, mae: 0.010698, mean_q: 0.016238
 52985/100000: episode: 6964, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000255, mae: 0.008411, mean_q: 0.017352
 52995/100000: episode: 6965, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000246, mae: 0.006926, mean_q: 0.012687
 53005/100000: episode: 6966, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000555, mae: 0.009043, mean_q: 0.013756
 53015/100000: episode: 6967, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000467, mae: 0.008291, mean_q: 0.014276
 53025/100000: episode: 6968, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000502, mae: 0.010915, mean_q: 0.029876
 53035/100000: episode: 6969, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000440, mae: 0.009737, mean_q: 0.023876
 53045/100000: episode: 6970, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000423, mae: 0.008678, mean_q: 0.012633
 53055/100000: episode: 6971, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000248, mae: 0.008643, mean_q: 0.011852
 53065/100000: episode: 6972, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000284, mae: 0.007022, mean_q: 0.011474
 53075/100000: episode: 6973, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000802, mae: 0.012026, mean_q: 0.021646
 53085/100000: episode: 6974, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000171, mae: 0.006905, mean_q: 0.014416
 53095/100000: episode: 6975, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000350, mae: 0.007745, mean_q: 0.017661
 53105/100000: episode: 6976, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000418, mae: 0.009943, mean_q: 0.017465
 53115/100000: episode: 6977, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000268, mae: 0.007943, mean_q: 0.012202
 53125/100000: episode: 6978, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000742, mae: 0.009915, mean_q: 0.019011
 53135/100000: episode: 6979, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000849, mae: 0.011674, mean_q: 0.018319
 53145/100000: episode: 6980, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000790, mae: 0.012167, mean_q: 0.022018
 53155/100000: episode: 6981, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000214, mae: 0.008135, mean_q: 0.015202
 53165/100000: episode: 6982, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000309, mae: 0.007050, mean_q: 0.011182
 53175/100000: episode: 6983, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000429, mae: 0.008153, mean_q: 0.013108
 53185/100000: episode: 6984, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000377, mae: 0.008806, mean_q: 0.018735
 53195/100000: episode: 6985, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000361, mae: 0.009287, mean_q: 0.014741
 53205/100000: episode: 6986, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000507, mae: 0.009747, mean_q: 0.015818
 53215/100000: episode: 6987, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000409, mae: 0.009344, mean_q: 0.017657
 53225/100000: episode: 6988, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000154, mae: 0.006782, mean_q: 0.011759
 53235/100000: episode: 6989, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001340, mae: 0.008797, mean_q: 0.011135
 53245/100000: episode: 6990, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000311, mae: 0.008927, mean_q: 0.019551
 53255/100000: episode: 6991, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.001307, mae: 0.011154, mean_q: 0.018872
 53265/100000: episode: 6992, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000374, mae: 0.009112, mean_q: 0.010544
 53275/100000: episode: 6993, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001412, mae: 0.011686, mean_q: 0.015843
 53285/100000: episode: 6994, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000403, mae: 0.009707, mean_q: 0.017569
 53295/100000: episode: 6995, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000345, mae: 0.009392, mean_q: 0.020853
 53305/100000: episode: 6996, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000572, mae: 0.011272, mean_q: 0.017881
 53315/100000: episode: 6997, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000884, mae: 0.010907, mean_q: 0.018261
 53325/100000: episode: 6998, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000453, mae: 0.009543, mean_q: 0.019218
 53335/100000: episode: 6999, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000507, mae: 0.008033, mean_q: 0.013164
 53345/100000: episode: 7000, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000204, mae: 0.005880, mean_q: 0.009363
 53355/100000: episode: 7001, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000154, mae: 0.006121, mean_q: 0.012332
 53365/100000: episode: 7002, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000220, mae: 0.007494, mean_q: 0.011762
 53375/100000: episode: 7003, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000417, mae: 0.009290, mean_q: 0.016921
 53385/100000: episode: 7004, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000551, mae: 0.008174, mean_q: 0.011973
 53395/100000: episode: 7005, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000823, mae: 0.009469, mean_q: 0.016150
 53405/100000: episode: 7006, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000294, mae: 0.008663, mean_q: 0.013343
 53415/100000: episode: 7007, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000239, mae: 0.008975, mean_q: 0.017138
 53425/100000: episode: 7008, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000628, mae: 0.010747, mean_q: 0.018939
 53435/100000: episode: 7009, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000442, mae: 0.009324, mean_q: 0.012313
 53445/100000: episode: 7010, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001493, mae: 0.009668, mean_q: 0.011580
 53455/100000: episode: 7011, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000718, mae: 0.011456, mean_q: 0.022857
 53465/100000: episode: 7012, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001094, mae: 0.013113, mean_q: 0.022101
 53475/100000: episode: 7013, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000568, mae: 0.008703, mean_q: 0.013444
 53485/100000: episode: 7014, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000934, mae: 0.012343, mean_q: 0.022461
 53495/100000: episode: 7015, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000623, mae: 0.011467, mean_q: 0.025176
 53505/100000: episode: 7016, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000351, mae: 0.008600, mean_q: 0.018582
 53515/100000: episode: 7017, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000371, mae: 0.007829, mean_q: 0.012414
 53525/100000: episode: 7018, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000232, mae: 0.007154, mean_q: 0.012915
 53535/100000: episode: 7019, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000997, mae: 0.011908, mean_q: 0.019634
 53545/100000: episode: 7020, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000341, mae: 0.008720, mean_q: 0.014587
 53555/100000: episode: 7021, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000984, mae: 0.011188, mean_q: 0.016873
 53565/100000: episode: 7022, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000160, mae: 0.004852, mean_q: 0.006796
 53575/100000: episode: 7023, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000237, mae: 0.007272, mean_q: 0.011357
 53585/100000: episode: 7024, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000210, mae: 0.008080, mean_q: 0.014184
 53595/100000: episode: 7025, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000392, mae: 0.008339, mean_q: 0.014068
 53605/100000: episode: 7026, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000242, mae: 0.007441, mean_q: 0.011971
 53615/100000: episode: 7027, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000190, mae: 0.007457, mean_q: 0.014445
 53625/100000: episode: 7028, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000588, mae: 0.008901, mean_q: 0.013978
 53635/100000: episode: 7029, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000576, mae: 0.011334, mean_q: 0.019141
 53645/100000: episode: 7030, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000404, mae: 0.007119, mean_q: 0.015249
 53655/100000: episode: 7031, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000248, mae: 0.007196, mean_q: 0.013448
 53665/100000: episode: 7032, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000237, mae: 0.006651, mean_q: 0.012811
[Info] 1-TH LEVEL FOUND: 0.028869539499282837, Considering 12/100 traces
 53675/100000: episode: 7033, duration: 0.714s, episode steps: 10, steps per second: 14, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000166, mae: 0.006522, mean_q: 0.012567
 53679/100000: episode: 7034, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000051, mae: 0.004437, mean_q: 0.010140
 53682/100000: episode: 7035, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001183, mae: 0.013027, mean_q: 0.021722
 53685/100000: episode: 7036, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001224, mae: 0.008664, mean_q: 0.014382
 53689/100000: episode: 7037, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000153, mae: 0.007819, mean_q: 0.016119
 53692/100000: episode: 7038, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000579, mae: 0.008439, mean_q: 0.015949
 53698/100000: episode: 7039, duration: 0.033s, episode steps: 6, steps per second: 180, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000236, mae: 0.008503, mean_q: 0.013435
 53701/100000: episode: 7040, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000209, mae: 0.007504, mean_q: 0.011685
 53704/100000: episode: 7041, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000213, mae: 0.006797, mean_q: 0.011864
 53710/100000: episode: 7042, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000074, mae: 0.005226, mean_q: 0.009924
 53716/100000: episode: 7043, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000086, mae: 0.004882, mean_q: 0.011540
 53722/100000: episode: 7044, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.001070, mae: 0.011579, mean_q: 0.016898
 53728/100000: episode: 7045, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000320, mae: 0.008120, mean_q: 0.010231
 53734/100000: episode: 7046, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000120, mae: 0.007399, mean_q: 0.012317
 53737/100000: episode: 7047, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000110, mae: 0.007525, mean_q: 0.013845
 53740/100000: episode: 7048, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000655, mae: 0.009993, mean_q: 0.017624
 53743/100000: episode: 7049, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000070, mae: 0.005552, mean_q: 0.011508
 53747/100000: episode: 7050, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000087, mae: 0.006140, mean_q: 0.011753
 53753/100000: episode: 7051, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000149, mae: 0.006295, mean_q: 0.011072
 53757/100000: episode: 7052, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000094, mae: 0.005557, mean_q: 0.009910
 53763/100000: episode: 7053, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000124, mae: 0.005392, mean_q: 0.009834
 53766/100000: episode: 7054, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000274, mae: 0.008002, mean_q: 0.019365
 53770/100000: episode: 7055, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001179, mae: 0.015504, mean_q: 0.031540
 53773/100000: episode: 7056, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000096, mae: 0.006669, mean_q: 0.011311
 53777/100000: episode: 7057, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000246, mae: 0.008509, mean_q: 0.017535
 53780/100000: episode: 7058, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000109, mae: 0.007095, mean_q: 0.015344
 53784/100000: episode: 7059, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000677, mae: 0.011893, mean_q: 0.024803
 53788/100000: episode: 7060, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000210, mae: 0.007676, mean_q: 0.013275
 53791/100000: episode: 7061, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001129, mae: 0.015471, mean_q: 0.024231
 53794/100000: episode: 7062, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000754, mae: 0.010133, mean_q: 0.014354
 53798/100000: episode: 7063, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000658, mae: 0.011920, mean_q: 0.016818
 53801/100000: episode: 7064, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000597, mae: 0.012290, mean_q: 0.023135
 53807/100000: episode: 7065, duration: 0.033s, episode steps: 6, steps per second: 181, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000214, mae: 0.009821, mean_q: 0.017507
 53813/100000: episode: 7066, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000121, mae: 0.008327, mean_q: 0.017331
 53819/100000: episode: 7067, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000833, mae: 0.012076, mean_q: 0.034201
 53825/100000: episode: 7068, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000472, mae: 0.009415, mean_q: 0.010524
 53831/100000: episode: 7069, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000165, mae: 0.007403, mean_q: 0.007438
 53837/100000: episode: 7070, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000563, mae: 0.010547, mean_q: 0.013827
 53840/100000: episode: 7071, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001009, mae: 0.010463, mean_q: 0.014202
 53846/100000: episode: 7072, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000100, mae: 0.007360, mean_q: 0.013961
 53852/100000: episode: 7073, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001608, mae: 0.012991, mean_q: 0.018779
 53855/100000: episode: 7074, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001593, mae: 0.015279, mean_q: 0.024968
 53859/100000: episode: 7075, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000457, mae: 0.010588, mean_q: 0.018835
 53865/100000: episode: 7076, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000287, mae: 0.008978, mean_q: 0.012569
 53868/100000: episode: 7077, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000380, mae: 0.008698, mean_q: 0.024503
 53874/100000: episode: 7078, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000545, mae: 0.010285, mean_q: 0.016953
 53877/100000: episode: 7079, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000119, mae: 0.007129, mean_q: 0.018134
 53880/100000: episode: 7080, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000168, mae: 0.007944, mean_q: 0.014605
 53886/100000: episode: 7081, duration: 0.032s, episode steps: 6, steps per second: 187, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000287, mae: 0.009077, mean_q: 0.012988
 53892/100000: episode: 7082, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000115, mae: 0.007104, mean_q: 0.011889
 53898/100000: episode: 7083, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000683, mae: 0.009843, mean_q: 0.018114
 53901/100000: episode: 7084, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000413, mae: 0.009409, mean_q: 0.014876
 53905/100000: episode: 7085, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001080, mae: 0.012011, mean_q: 0.021279
 53909/100000: episode: 7086, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000712, mae: 0.013998, mean_q: 0.025553
 53915/100000: episode: 7087, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000242, mae: 0.008983, mean_q: 0.014730
 53918/100000: episode: 7088, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000803, mae: 0.013972, mean_q: 0.020194
 53924/100000: episode: 7089, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000913, mae: 0.012483, mean_q: 0.027097
 53928/100000: episode: 7090, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000404, mae: 0.009372, mean_q: 0.017446
 53932/100000: episode: 7091, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000337, mae: 0.008717, mean_q: 0.016369
 53935/100000: episode: 7092, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000971, mae: 0.008953, mean_q: 0.010851
 53941/100000: episode: 7093, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000196, mae: 0.007745, mean_q: 0.014520
 53947/100000: episode: 7094, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000274, mae: 0.008859, mean_q: 0.020027
 53950/100000: episode: 7095, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000765, mae: 0.014771, mean_q: 0.033256
 53954/100000: episode: 7096, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000511, mae: 0.011407, mean_q: 0.018928
 53960/100000: episode: 7097, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000259, mae: 0.009660, mean_q: 0.021938
 53963/100000: episode: 7098, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001468, mae: 0.013774, mean_q: 0.024305
 53969/100000: episode: 7099, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000122, mae: 0.008880, mean_q: 0.011097
 53973/100000: episode: 7100, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000100, mae: 0.007531, mean_q: 0.006392
 53977/100000: episode: 7101, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000128, mae: 0.007695, mean_q: 0.013350
 53980/100000: episode: 7102, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001423, mae: 0.014381, mean_q: 0.016038
 53986/100000: episode: 7103, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000276, mae: 0.009261, mean_q: 0.019135
 53989/100000: episode: 7104, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000242, mae: 0.006811, mean_q: 0.008782
 53992/100000: episode: 7105, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000426, mae: 0.009741, mean_q: 0.014276
 53996/100000: episode: 7106, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000111, mae: 0.008059, mean_q: 0.014249
 54002/100000: episode: 7107, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000082, mae: 0.006658, mean_q: 0.016511
 54005/100000: episode: 7108, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000106, mae: 0.006801, mean_q: 0.013855
 54008/100000: episode: 7109, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000099, mae: 0.006252, mean_q: 0.012427
[Info] FALSIFICATION!
 54013/100000: episode: 7110, duration: 0.183s, episode steps: 5, steps per second: 27, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000772, mae: 0.009617, mean_q: 0.013496
 54019/100000: episode: 7111, duration: 0.031s, episode steps: 6, steps per second: 191, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001412, mae: 0.012188, mean_q: 0.016159
 54025/100000: episode: 7112, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000495, mae: 0.011776, mean_q: 0.024201
 54029/100000: episode: 7113, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000611, mae: 0.011473, mean_q: 0.026725
 54035/100000: episode: 7114, duration: 0.032s, episode steps: 6, steps per second: 190, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000621, mae: 0.009273, mean_q: 0.016392
 54041/100000: episode: 7115, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000798, mae: 0.013126, mean_q: 0.027666
 54045/100000: episode: 7116, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000344, mae: 0.009925, mean_q: 0.026260
 54049/100000: episode: 7117, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001498, mae: 0.017287, mean_q: 0.032744
 54055/100000: episode: 7118, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000320, mae: 0.009213, mean_q: 0.017420
 54059/100000: episode: 7119, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000376, mae: 0.007879, mean_q: 0.016469
 54065/100000: episode: 7120, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000126, mae: 0.007419, mean_q: 0.015324
[Info] Complete ISplit Iteration
[Info] Levels: [0.02886954, 1.2374136]
[Info] Cond. Prob: [0.12, 0.03]
[Info] Error Prob: 0.0036

 54071/100000: episode: 7121, duration: 0.849s, episode steps: 6, steps per second: 7, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000865, mae: 0.011165, mean_q: 0.020175
 54081/100000: episode: 7122, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000439, mae: 0.011334, mean_q: 0.025166
 54091/100000: episode: 7123, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000949, mae: 0.010359, mean_q: 0.018721
 54101/100000: episode: 7124, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000508, mae: 0.010932, mean_q: 0.022302
 54111/100000: episode: 7125, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000580, mae: 0.010970, mean_q: 0.020754
 54121/100000: episode: 7126, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001843, mae: 0.018092, mean_q: 0.026977
 54131/100000: episode: 7127, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000669, mae: 0.012433, mean_q: 0.025167
 54141/100000: episode: 7128, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000549, mae: 0.011566, mean_q: 0.021561
 54151/100000: episode: 7129, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000342, mae: 0.008609, mean_q: 0.013294
 54161/100000: episode: 7130, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000398, mae: 0.009938, mean_q: 0.017953
 54171/100000: episode: 7131, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000370, mae: 0.010407, mean_q: 0.019621
 54181/100000: episode: 7132, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000512, mae: 0.010066, mean_q: 0.018422
 54191/100000: episode: 7133, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000755, mae: 0.012690, mean_q: 0.020860
 54201/100000: episode: 7134, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000539, mae: 0.011140, mean_q: 0.021002
 54211/100000: episode: 7135, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000571, mae: 0.011268, mean_q: 0.021742
 54221/100000: episode: 7136, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000365, mae: 0.008760, mean_q: 0.019825
 54231/100000: episode: 7137, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000365, mae: 0.008263, mean_q: 0.016127
 54241/100000: episode: 7138, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000198, mae: 0.006339, mean_q: 0.009957
 54251/100000: episode: 7139, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000095, mae: 0.006328, mean_q: 0.014943
 54261/100000: episode: 7140, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000495, mae: 0.007956, mean_q: 0.012655
 54271/100000: episode: 7141, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000214, mae: 0.008267, mean_q: 0.016205
 54281/100000: episode: 7142, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000653, mae: 0.011987, mean_q: 0.020005
 54291/100000: episode: 7143, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000856, mae: 0.012669, mean_q: 0.020862
 54301/100000: episode: 7144, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000237, mae: 0.008538, mean_q: 0.019862
 54311/100000: episode: 7145, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000904, mae: 0.010552, mean_q: 0.018121
 54321/100000: episode: 7146, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001414, mae: 0.013017, mean_q: 0.016232
 54331/100000: episode: 7147, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000381, mae: 0.010793, mean_q: 0.025073
 54341/100000: episode: 7148, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000865, mae: 0.011861, mean_q: 0.025884
 54351/100000: episode: 7149, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000441, mae: 0.010412, mean_q: 0.015702
 54361/100000: episode: 7150, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000379, mae: 0.008833, mean_q: 0.017063
 54371/100000: episode: 7151, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000774, mae: 0.013491, mean_q: 0.025713
 54381/100000: episode: 7152, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000482, mae: 0.011794, mean_q: 0.031464
 54391/100000: episode: 7153, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001233, mae: 0.013815, mean_q: 0.016437
 54401/100000: episode: 7154, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001322, mae: 0.014387, mean_q: 0.021829
 54411/100000: episode: 7155, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000799, mae: 0.011330, mean_q: 0.020343
 54421/100000: episode: 7156, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001060, mae: 0.012189, mean_q: 0.021143
 54431/100000: episode: 7157, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000595, mae: 0.011283, mean_q: 0.023604
 54441/100000: episode: 7158, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000491, mae: 0.011187, mean_q: 0.024489
 54451/100000: episode: 7159, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000727, mae: 0.011059, mean_q: 0.025296
 54461/100000: episode: 7160, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000211, mae: 0.008117, mean_q: 0.013356
 54471/100000: episode: 7161, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000163, mae: 0.008734, mean_q: 0.022155
 54481/100000: episode: 7162, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000290, mae: 0.008321, mean_q: 0.018144
 54491/100000: episode: 7163, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000583, mae: 0.011771, mean_q: 0.022374
 54501/100000: episode: 7164, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000531, mae: 0.012154, mean_q: 0.021066
 54511/100000: episode: 7165, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000779, mae: 0.013415, mean_q: 0.022406
 54521/100000: episode: 7166, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000268, mae: 0.009946, mean_q: 0.021538
 54531/100000: episode: 7167, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000973, mae: 0.013375, mean_q: 0.029483
 54541/100000: episode: 7168, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000389, mae: 0.008807, mean_q: 0.013718
 54551/100000: episode: 7169, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000471, mae: 0.010913, mean_q: 0.022140
 54561/100000: episode: 7170, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000505, mae: 0.010086, mean_q: 0.020060
 54571/100000: episode: 7171, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000317, mae: 0.008901, mean_q: 0.016690
 54581/100000: episode: 7172, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000908, mae: 0.014951, mean_q: 0.029043
 54591/100000: episode: 7173, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000447, mae: 0.011276, mean_q: 0.020146
 54601/100000: episode: 7174, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000620, mae: 0.011675, mean_q: 0.022915
 54611/100000: episode: 7175, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000783, mae: 0.013519, mean_q: 0.026110
 54621/100000: episode: 7176, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000631, mae: 0.011176, mean_q: 0.017695
 54631/100000: episode: 7177, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000293, mae: 0.008949, mean_q: 0.016578
 54641/100000: episode: 7178, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000623, mae: 0.011775, mean_q: 0.021410
 54651/100000: episode: 7179, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000228, mae: 0.009638, mean_q: 0.017333
 54661/100000: episode: 7180, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000856, mae: 0.012107, mean_q: 0.023616
 54671/100000: episode: 7181, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000796, mae: 0.013080, mean_q: 0.020370
 54681/100000: episode: 7182, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000544, mae: 0.011907, mean_q: 0.022533
 54691/100000: episode: 7183, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001609, mae: 0.012277, mean_q: 0.020613
 54701/100000: episode: 7184, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000914, mae: 0.012720, mean_q: 0.025065
 54711/100000: episode: 7185, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000975, mae: 0.012921, mean_q: 0.018319
 54721/100000: episode: 7186, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000749, mae: 0.012911, mean_q: 0.023324
 54731/100000: episode: 7187, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000280, mae: 0.010140, mean_q: 0.020490
 54741/100000: episode: 7188, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000374, mae: 0.010298, mean_q: 0.019528
 54751/100000: episode: 7189, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001078, mae: 0.013378, mean_q: 0.022754
 54761/100000: episode: 7190, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000549, mae: 0.010443, mean_q: 0.017694
 54771/100000: episode: 7191, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001199, mae: 0.013978, mean_q: 0.016820
 54781/100000: episode: 7192, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001476, mae: 0.020674, mean_q: 0.034807
 54791/100000: episode: 7193, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001167, mae: 0.013508, mean_q: 0.028945
 54801/100000: episode: 7194, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001237, mae: 0.014629, mean_q: 0.028160
 54811/100000: episode: 7195, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000491, mae: 0.011019, mean_q: 0.011452
 54821/100000: episode: 7196, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000544, mae: 0.011429, mean_q: 0.030421
 54831/100000: episode: 7197, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001695, mae: 0.015537, mean_q: 0.025169
 54841/100000: episode: 7198, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000569, mae: 0.014039, mean_q: 0.009807
 54851/100000: episode: 7199, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001128, mae: 0.013934, mean_q: 0.016124
 54861/100000: episode: 7200, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000573, mae: 0.014916, mean_q: 0.025502
 54871/100000: episode: 7201, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000479, mae: 0.011695, mean_q: 0.021243
 54881/100000: episode: 7202, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000473, mae: 0.010056, mean_q: 0.014922
 54891/100000: episode: 7203, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000928, mae: 0.011589, mean_q: 0.021961
 54901/100000: episode: 7204, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000476, mae: 0.009148, mean_q: 0.015936
 54911/100000: episode: 7205, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000672, mae: 0.010567, mean_q: 0.017600
 54921/100000: episode: 7206, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000441, mae: 0.010315, mean_q: 0.021521
 54931/100000: episode: 7207, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000988, mae: 0.013173, mean_q: 0.024626
 54941/100000: episode: 7208, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000764, mae: 0.010399, mean_q: 0.013897
 54951/100000: episode: 7209, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000453, mae: 0.009687, mean_q: 0.020619
 54961/100000: episode: 7210, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000868, mae: 0.010051, mean_q: 0.015753
 54971/100000: episode: 7211, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001026, mae: 0.012337, mean_q: 0.019734
 54981/100000: episode: 7212, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001037, mae: 0.015012, mean_q: 0.028754
 54991/100000: episode: 7213, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000464, mae: 0.009669, mean_q: 0.020587
 55001/100000: episode: 7214, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000254, mae: 0.008265, mean_q: 0.019737
 55011/100000: episode: 7215, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000794, mae: 0.012046, mean_q: 0.030123
 55021/100000: episode: 7216, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000429, mae: 0.009200, mean_q: 0.016610
 55031/100000: episode: 7217, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000694, mae: 0.011357, mean_q: 0.022537
 55041/100000: episode: 7218, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000326, mae: 0.008719, mean_q: 0.018261
 55051/100000: episode: 7219, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000574, mae: 0.010536, mean_q: 0.031126
 55061/100000: episode: 7220, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000341, mae: 0.009431, mean_q: 0.021583
[Info] 1-TH LEVEL FOUND: 0.02719668671488762, Considering 17/100 traces
 55071/100000: episode: 7221, duration: 0.702s, episode steps: 10, steps per second: 14, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000991, mae: 0.010329, mean_q: 0.023064
 55077/100000: episode: 7222, duration: 0.033s, episode steps: 6, steps per second: 183, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001618, mae: 0.015183, mean_q: 0.026610
 55081/100000: episode: 7223, duration: 0.024s, episode steps: 4, steps per second: 167, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000459, mae: 0.012908, mean_q: 0.024339
 55084/100000: episode: 7224, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001194, mae: 0.011681, mean_q: 0.018125
 55088/100000: episode: 7225, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000492, mae: 0.006701, mean_q: 0.009281
 55091/100000: episode: 7226, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000507, mae: 0.010117, mean_q: 0.020076
 55095/100000: episode: 7227, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000269, mae: 0.009865, mean_q: 0.022871
 55101/100000: episode: 7228, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001212, mae: 0.015331, mean_q: 0.028355
 55105/100000: episode: 7229, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000746, mae: 0.012305, mean_q: 0.020616
 55109/100000: episode: 7230, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000302, mae: 0.009043, mean_q: 0.015181
 55115/100000: episode: 7231, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000654, mae: 0.010486, mean_q: 0.022247
 55119/100000: episode: 7232, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000301, mae: 0.011517, mean_q: 0.027506
 55123/100000: episode: 7233, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000610, mae: 0.011255, mean_q: 0.020448
 55127/100000: episode: 7234, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000201, mae: 0.008148, mean_q: 0.012011
 55133/100000: episode: 7235, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000491, mae: 0.009579, mean_q: 0.015429
 55136/100000: episode: 7236, duration: 0.016s, episode steps: 3, steps per second: 187, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000124, mae: 0.005721, mean_q: 0.009625
 55142/100000: episode: 7237, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000215, mae: 0.006589, mean_q: 0.012636
 55146/100000: episode: 7238, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000982, mae: 0.010891, mean_q: 0.011274
 55150/100000: episode: 7239, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001602, mae: 0.017537, mean_q: 0.025913
 55156/100000: episode: 7240, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000249, mae: 0.010696, mean_q: 0.016642
 55160/100000: episode: 7241, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002178, mae: 0.013692, mean_q: 0.015076
 55163/100000: episode: 7242, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000293, mae: 0.007895, mean_q: 0.011956
 55167/100000: episode: 7243, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001130, mae: 0.014457, mean_q: 0.027335
 55173/100000: episode: 7244, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000657, mae: 0.011752, mean_q: 0.018954
 55176/100000: episode: 7245, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000522, mae: 0.013549, mean_q: 0.018277
 55179/100000: episode: 7246, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000790, mae: 0.014819, mean_q: 0.026665
 55182/100000: episode: 7247, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000784, mae: 0.014119, mean_q: 0.029624
 55185/100000: episode: 7248, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000578, mae: 0.009750, mean_q: 0.020139
 55188/100000: episode: 7249, duration: 0.020s, episode steps: 3, steps per second: 147, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001074, mae: 0.010623, mean_q: 0.017523
 55194/100000: episode: 7250, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000452, mae: 0.009039, mean_q: 0.018474
 55197/100000: episode: 7251, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000186, mae: 0.008449, mean_q: 0.016685
 55201/100000: episode: 7252, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001746, mae: 0.013114, mean_q: 0.018793
 55205/100000: episode: 7253, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000722, mae: 0.009389, mean_q: 0.016671
 55209/100000: episode: 7254, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000360, mae: 0.010281, mean_q: 0.023284
 55212/100000: episode: 7255, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000476, mae: 0.010907, mean_q: 0.028109
 55215/100000: episode: 7256, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001169, mae: 0.011943, mean_q: 0.020808
 55218/100000: episode: 7257, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001270, mae: 0.012489, mean_q: 0.020606
 55221/100000: episode: 7258, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000313, mae: 0.008470, mean_q: 0.011085
 55224/100000: episode: 7259, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000115, mae: 0.007026, mean_q: 0.006364
 55228/100000: episode: 7260, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000661, mae: 0.011272, mean_q: 0.021414
[Info] FALSIFICATION!
 55233/100000: episode: 7261, duration: 0.179s, episode steps: 5, steps per second: 28, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000363, mae: 0.008860, mean_q: 0.017521
 55237/100000: episode: 7262, duration: 0.024s, episode steps: 4, steps per second: 170, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001248, mae: 0.013518, mean_q: 0.022254
 55240/100000: episode: 7263, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000359, mae: 0.009567, mean_q: 0.022173
 55243/100000: episode: 7264, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002266, mae: 0.020474, mean_q: 0.029136
 55247/100000: episode: 7265, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000253, mae: 0.008939, mean_q: 0.014657
 55251/100000: episode: 7266, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000581, mae: 0.011143, mean_q: 0.019896
 55257/100000: episode: 7267, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000334, mae: 0.009579, mean_q: 0.016848
 55260/100000: episode: 7268, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000662, mae: 0.010381, mean_q: 0.016614
 55263/100000: episode: 7269, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001936, mae: 0.015818, mean_q: 0.024092
 55267/100000: episode: 7270, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000697, mae: 0.008182, mean_q: 0.013760
 55271/100000: episode: 7271, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000190, mae: 0.007144, mean_q: 0.014941
 55275/100000: episode: 7272, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000644, mae: 0.010379, mean_q: 0.020498
 55278/100000: episode: 7273, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000809, mae: 0.011734, mean_q: 0.019748
 55281/100000: episode: 7274, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001201, mae: 0.012822, mean_q: 0.015995
 55285/100000: episode: 7275, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000505, mae: 0.008585, mean_q: 0.013384
 55291/100000: episode: 7276, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001495, mae: 0.013786, mean_q: 0.015527
 55294/100000: episode: 7277, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000837, mae: 0.010813, mean_q: 0.018712
 55297/100000: episode: 7278, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000284, mae: 0.008463, mean_q: 0.012279
 55301/100000: episode: 7279, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001859, mae: 0.018828, mean_q: 0.033369
 55304/100000: episode: 7280, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000329, mae: 0.010282, mean_q: 0.020090
 55307/100000: episode: 7281, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000106, mae: 0.005918, mean_q: 0.011933
 55313/100000: episode: 7282, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000389, mae: 0.008526, mean_q: 0.016729
 55319/100000: episode: 7283, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000482, mae: 0.009631, mean_q: 0.017466
 55322/100000: episode: 7284, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000098, mae: 0.005984, mean_q: 0.010561
 55326/100000: episode: 7285, duration: 0.024s, episode steps: 4, steps per second: 170, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000143, mae: 0.007248, mean_q: 0.013384
 55330/100000: episode: 7286, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000188, mae: 0.007628, mean_q: 0.014697
 55334/100000: episode: 7287, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000368, mae: 0.009720, mean_q: 0.026207
 55337/100000: episode: 7288, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000100, mae: 0.006873, mean_q: 0.012836
 55340/100000: episode: 7289, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000125, mae: 0.005556, mean_q: 0.013822
 55343/100000: episode: 7290, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000703, mae: 0.011873, mean_q: 0.020625
 55347/100000: episode: 7291, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000634, mae: 0.008513, mean_q: 0.016281
 55351/100000: episode: 7292, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000320, mae: 0.009210, mean_q: 0.019973
 55355/100000: episode: 7293, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000158, mae: 0.007379, mean_q: 0.013274
 55358/100000: episode: 7294, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000088, mae: 0.006233, mean_q: 0.011317
 55364/100000: episode: 7295, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000450, mae: 0.009531, mean_q: 0.021231
 55367/100000: episode: 7296, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000072, mae: 0.005728, mean_q: 0.011113
 55370/100000: episode: 7297, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000288, mae: 0.008525, mean_q: 0.013692
 55373/100000: episode: 7298, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000288, mae: 0.007956, mean_q: 0.016000
 55376/100000: episode: 7299, duration: 0.021s, episode steps: 3, steps per second: 144, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001068, mae: 0.013200, mean_q: 0.022160
 55380/100000: episode: 7300, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000085, mae: 0.005530, mean_q: 0.008318
 55383/100000: episode: 7301, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001959, mae: 0.019947, mean_q: 0.025109
 55386/100000: episode: 7302, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000127, mae: 0.007657, mean_q: 0.010699
 55390/100000: episode: 7303, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000404, mae: 0.006842, mean_q: 0.011997
[Info] Complete ISplit Iteration
[Info] Levels: [0.027196687, 1.1760244]
[Info] Cond. Prob: [0.17, 0.01]
[Info] Error Prob: 0.0017000000000000001

 55394/100000: episode: 7304, duration: 0.743s, episode steps: 4, steps per second: 5, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000235, mae: 0.008534, mean_q: 0.014932
 55404/100000: episode: 7305, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000644, mae: 0.009602, mean_q: 0.015675
 55414/100000: episode: 7306, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000203, mae: 0.007220, mean_q: 0.015208
 55424/100000: episode: 7307, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000617, mae: 0.010225, mean_q: 0.021216
 55434/100000: episode: 7308, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001215, mae: 0.012573, mean_q: 0.026970
 55444/100000: episode: 7309, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001221, mae: 0.012153, mean_q: 0.022087
 55454/100000: episode: 7310, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000359, mae: 0.006858, mean_q: 0.010531
 55464/100000: episode: 7311, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000635, mae: 0.011188, mean_q: 0.016231
 55474/100000: episode: 7312, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000356, mae: 0.009237, mean_q: 0.017402
 55484/100000: episode: 7313, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000621, mae: 0.010332, mean_q: 0.018840
 55494/100000: episode: 7314, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000249, mae: 0.006623, mean_q: 0.010556
 55504/100000: episode: 7315, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000809, mae: 0.012712, mean_q: 0.021705
 55514/100000: episode: 7316, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000459, mae: 0.009440, mean_q: 0.017063
 55524/100000: episode: 7317, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000494, mae: 0.009649, mean_q: 0.012798
 55534/100000: episode: 7318, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000099, mae: 0.006349, mean_q: 0.013502
 55544/100000: episode: 7319, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000087, mae: 0.006599, mean_q: 0.012786
 55554/100000: episode: 7320, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000523, mae: 0.009215, mean_q: 0.017367
 55564/100000: episode: 7321, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000578, mae: 0.007021, mean_q: 0.010617
 55574/100000: episode: 7322, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000060, mae: 0.005463, mean_q: 0.009886
 55584/100000: episode: 7323, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000481, mae: 0.008061, mean_q: 0.015430
 55594/100000: episode: 7324, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000153, mae: 0.007816, mean_q: 0.016446
 55604/100000: episode: 7325, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000625, mae: 0.009919, mean_q: 0.014668
 55614/100000: episode: 7326, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000323, mae: 0.007647, mean_q: 0.012362
 55624/100000: episode: 7327, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000160, mae: 0.006944, mean_q: 0.011685
 55634/100000: episode: 7328, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000315, mae: 0.008894, mean_q: 0.016308
 55644/100000: episode: 7329, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000309, mae: 0.009252, mean_q: 0.017728
 55654/100000: episode: 7330, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000143, mae: 0.005933, mean_q: 0.010836
 55664/100000: episode: 7331, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000233, mae: 0.008765, mean_q: 0.014940
 55674/100000: episode: 7332, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000675, mae: 0.007678, mean_q: 0.012996
 55684/100000: episode: 7333, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000417, mae: 0.007746, mean_q: 0.014965
 55694/100000: episode: 7334, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000954, mae: 0.010040, mean_q: 0.018187
 55704/100000: episode: 7335, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000381, mae: 0.008492, mean_q: 0.013429
 55714/100000: episode: 7336, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000576, mae: 0.009836, mean_q: 0.015318
 55724/100000: episode: 7337, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000385, mae: 0.009007, mean_q: 0.017239
 55734/100000: episode: 7338, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000480, mae: 0.009253, mean_q: 0.016120
 55744/100000: episode: 7339, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001092, mae: 0.010488, mean_q: 0.015508
 55754/100000: episode: 7340, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000294, mae: 0.008190, mean_q: 0.013411
 55764/100000: episode: 7341, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000361, mae: 0.009359, mean_q: 0.017667
 55774/100000: episode: 7342, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000097, mae: 0.006797, mean_q: 0.012499
 55784/100000: episode: 7343, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000618, mae: 0.010027, mean_q: 0.018600
 55794/100000: episode: 7344, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000262, mae: 0.007507, mean_q: 0.013322
 55804/100000: episode: 7345, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000302, mae: 0.007908, mean_q: 0.013978
 55814/100000: episode: 7346, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000573, mae: 0.009964, mean_q: 0.022962
 55824/100000: episode: 7347, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000259, mae: 0.008182, mean_q: 0.014549
 55834/100000: episode: 7348, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000518, mae: 0.009213, mean_q: 0.014337
 55844/100000: episode: 7349, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000478, mae: 0.008344, mean_q: 0.014374
 55854/100000: episode: 7350, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000202, mae: 0.008133, mean_q: 0.016498
 55864/100000: episode: 7351, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000103, mae: 0.006356, mean_q: 0.012427
 55874/100000: episode: 7352, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000623, mae: 0.009304, mean_q: 0.015824
 55884/100000: episode: 7353, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000289, mae: 0.008387, mean_q: 0.011545
 55894/100000: episode: 7354, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000460, mae: 0.010945, mean_q: 0.020332
 55904/100000: episode: 7355, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000369, mae: 0.009469, mean_q: 0.019340
 55914/100000: episode: 7356, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000221, mae: 0.006984, mean_q: 0.014120
 55924/100000: episode: 7357, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000121, mae: 0.006917, mean_q: 0.012935
 55934/100000: episode: 7358, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000952, mae: 0.011642, mean_q: 0.020135
 55944/100000: episode: 7359, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000251, mae: 0.007468, mean_q: 0.012171
 55954/100000: episode: 7360, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000167, mae: 0.006713, mean_q: 0.011426
 55964/100000: episode: 7361, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000179, mae: 0.007685, mean_q: 0.014520
 55974/100000: episode: 7362, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001476, mae: 0.010939, mean_q: 0.014354
 55984/100000: episode: 7363, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000487, mae: 0.010463, mean_q: 0.020455
 55994/100000: episode: 7364, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000946, mae: 0.009328, mean_q: 0.018052
 56004/100000: episode: 7365, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000518, mae: 0.011115, mean_q: 0.014602
 56014/100000: episode: 7366, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000616, mae: 0.009767, mean_q: 0.008609
 56024/100000: episode: 7367, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000468, mae: 0.010009, mean_q: 0.016800
 56034/100000: episode: 7368, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000156, mae: 0.008514, mean_q: 0.015221
 56044/100000: episode: 7369, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000402, mae: 0.008415, mean_q: 0.014944
 56054/100000: episode: 7370, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000617, mae: 0.008528, mean_q: 0.011058
 56064/100000: episode: 7371, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000442, mae: 0.007568, mean_q: 0.013974
 56074/100000: episode: 7372, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000802, mae: 0.010434, mean_q: 0.014103
 56084/100000: episode: 7373, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000061, mae: 0.005794, mean_q: 0.011393
 56094/100000: episode: 7374, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000566, mae: 0.010480, mean_q: 0.020548
 56104/100000: episode: 7375, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000420, mae: 0.008157, mean_q: 0.014804
 56114/100000: episode: 7376, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000126, mae: 0.005731, mean_q: 0.005821
 56124/100000: episode: 7377, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000147, mae: 0.007019, mean_q: 0.012469
 56134/100000: episode: 7378, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000816, mae: 0.009535, mean_q: 0.016704
 56144/100000: episode: 7379, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000246, mae: 0.007457, mean_q: 0.013626
 56154/100000: episode: 7380, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000256, mae: 0.008374, mean_q: 0.013462
 56164/100000: episode: 7381, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000432, mae: 0.008495, mean_q: 0.015080
 56174/100000: episode: 7382, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000520, mae: 0.009140, mean_q: 0.013045
 56184/100000: episode: 7383, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000320, mae: 0.006301, mean_q: 0.009151
 56194/100000: episode: 7384, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000523, mae: 0.009346, mean_q: 0.018073
 56204/100000: episode: 7385, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000566, mae: 0.009158, mean_q: 0.019441
 56214/100000: episode: 7386, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000266, mae: 0.007157, mean_q: 0.013588
 56224/100000: episode: 7387, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000393, mae: 0.009374, mean_q: 0.019418
 56234/100000: episode: 7388, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000214, mae: 0.006487, mean_q: 0.012152
 56244/100000: episode: 7389, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000097, mae: 0.005633, mean_q: 0.008925
 56254/100000: episode: 7390, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000436, mae: 0.007614, mean_q: 0.016318
 56264/100000: episode: 7391, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000071, mae: 0.005698, mean_q: 0.012459
 56274/100000: episode: 7392, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000607, mae: 0.009246, mean_q: 0.014870
 56284/100000: episode: 7393, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000570, mae: 0.009642, mean_q: 0.020612
 56294/100000: episode: 7394, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000455, mae: 0.008441, mean_q: 0.010733
 56304/100000: episode: 7395, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000297, mae: 0.009073, mean_q: 0.016970
 56314/100000: episode: 7396, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000412, mae: 0.008242, mean_q: 0.013672
 56324/100000: episode: 7397, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000354, mae: 0.009318, mean_q: 0.017215
 56334/100000: episode: 7398, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000131, mae: 0.008580, mean_q: 0.017554
 56344/100000: episode: 7399, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000142, mae: 0.006726, mean_q: 0.015759
 56354/100000: episode: 7400, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000148, mae: 0.006049, mean_q: 0.007992
 56364/100000: episode: 7401, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000988, mae: 0.010093, mean_q: 0.017387
 56374/100000: episode: 7402, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001031, mae: 0.010289, mean_q: 0.017254
 56384/100000: episode: 7403, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001425, mae: 0.013134, mean_q: 0.021041
[Info] 1-TH LEVEL FOUND: -0.0007611461915075779, Considering 100/100 traces
 56394/100000: episode: 7404, duration: 0.670s, episode steps: 10, steps per second: 15, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000205, mae: 0.009916, mean_q: 0.010407
[Info] 2-TH LEVEL FOUND: 0.00610352260991931, Considering 100/100 traces
 56404/100000: episode: 7405, duration: 0.690s, episode steps: 10, steps per second: 14, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000219, mae: 0.008950, mean_q: 0.009252
[Info] 3-TH LEVEL FOUND: 0.007684293668717146, Considering 100/100 traces
 56414/100000: episode: 7406, duration: 0.696s, episode steps: 10, steps per second: 14, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000146, mae: 0.010371, mean_q: 0.014945
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.007684293668717146
 56424/100000: episode: 7407, duration: 0.484s, episode steps: 10, steps per second: 21, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000148, mae: 0.010481, mean_q: 0.015014
 56434/100000: episode: 7408, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000149, mae: 0.008814, mean_q: 0.012901
 56444/100000: episode: 7409, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000102, mae: 0.008325, mean_q: 0.014435
 56454/100000: episode: 7410, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001487, mae: 0.011556, mean_q: 0.016665
 56464/100000: episode: 7411, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000384, mae: 0.009899, mean_q: 0.019455
 56474/100000: episode: 7412, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000393, mae: 0.009081, mean_q: 0.011478
 56484/100000: episode: 7413, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000082, mae: 0.005507, mean_q: 0.011054
 56494/100000: episode: 7414, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000392, mae: 0.008416, mean_q: 0.016396
 56504/100000: episode: 7415, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000219, mae: 0.008148, mean_q: 0.010407
 56514/100000: episode: 7416, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000243, mae: 0.007845, mean_q: 0.016136
 56524/100000: episode: 7417, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000265, mae: 0.008159, mean_q: 0.015800
 56534/100000: episode: 7418, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000113, mae: 0.005611, mean_q: 0.014027
 56544/100000: episode: 7419, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000405, mae: 0.006653, mean_q: 0.010854
 56554/100000: episode: 7420, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000957, mae: 0.011511, mean_q: 0.016450
 56564/100000: episode: 7421, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000283, mae: 0.009031, mean_q: 0.011944
 56574/100000: episode: 7422, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000219, mae: 0.008659, mean_q: 0.010109
 56584/100000: episode: 7423, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000195, mae: 0.009053, mean_q: 0.015165
 56594/100000: episode: 7424, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000965, mae: 0.010428, mean_q: 0.015794
 56604/100000: episode: 7425, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000669, mae: 0.010672, mean_q: 0.017157
 56614/100000: episode: 7426, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000392, mae: 0.009398, mean_q: 0.016370
 56624/100000: episode: 7427, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000500, mae: 0.009388, mean_q: 0.015455
 56634/100000: episode: 7428, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000877, mae: 0.012416, mean_q: 0.022978
 56644/100000: episode: 7429, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000192, mae: 0.007798, mean_q: 0.010883
 56654/100000: episode: 7430, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000150, mae: 0.006910, mean_q: 0.013726
 56664/100000: episode: 7431, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000300, mae: 0.007699, mean_q: 0.012502
 56674/100000: episode: 7432, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000130, mae: 0.006631, mean_q: 0.010143
 56684/100000: episode: 7433, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000339, mae: 0.009680, mean_q: 0.017663
 56694/100000: episode: 7434, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000111, mae: 0.006610, mean_q: 0.014508
 56704/100000: episode: 7435, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000268, mae: 0.006584, mean_q: 0.008959
 56714/100000: episode: 7436, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000304, mae: 0.008045, mean_q: 0.016368
 56724/100000: episode: 7437, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000378, mae: 0.008527, mean_q: 0.014554
 56734/100000: episode: 7438, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000173, mae: 0.007359, mean_q: 0.012980
 56744/100000: episode: 7439, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000088, mae: 0.006456, mean_q: 0.011477
 56754/100000: episode: 7440, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000300, mae: 0.007175, mean_q: 0.011225
 56764/100000: episode: 7441, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000345, mae: 0.007420, mean_q: 0.009715
 56774/100000: episode: 7442, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000453, mae: 0.008482, mean_q: 0.015350
 56784/100000: episode: 7443, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000085, mae: 0.006055, mean_q: 0.013149
 56794/100000: episode: 7444, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000130, mae: 0.005337, mean_q: 0.012431
 56804/100000: episode: 7445, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000179, mae: 0.006010, mean_q: 0.010713
 56814/100000: episode: 7446, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000267, mae: 0.008838, mean_q: 0.016167
 56824/100000: episode: 7447, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000378, mae: 0.007835, mean_q: 0.016988
 56834/100000: episode: 7448, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000425, mae: 0.008012, mean_q: 0.013349
 56844/100000: episode: 7449, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000300, mae: 0.006266, mean_q: 0.013773
 56854/100000: episode: 7450, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000054, mae: 0.004092, mean_q: 0.008825
 56864/100000: episode: 7451, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000420, mae: 0.008424, mean_q: 0.018337
 56874/100000: episode: 7452, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000102, mae: 0.005023, mean_q: 0.008225
 56884/100000: episode: 7453, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000895, mae: 0.009549, mean_q: 0.014040
 56894/100000: episode: 7454, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000466, mae: 0.010361, mean_q: 0.017194
 56904/100000: episode: 7455, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000551, mae: 0.009016, mean_q: 0.010398
 56914/100000: episode: 7456, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000419, mae: 0.007047, mean_q: 0.008209
 56924/100000: episode: 7457, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000335, mae: 0.008322, mean_q: 0.013502
 56934/100000: episode: 7458, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000173, mae: 0.007165, mean_q: 0.019023
 56944/100000: episode: 7459, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000088, mae: 0.004638, mean_q: 0.009725
 56954/100000: episode: 7460, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000128, mae: 0.005074, mean_q: 0.011081
 56964/100000: episode: 7461, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000370, mae: 0.007089, mean_q: 0.012333
 56974/100000: episode: 7462, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000410, mae: 0.007466, mean_q: 0.010453
 56984/100000: episode: 7463, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000862, mae: 0.010854, mean_q: 0.016668
 56994/100000: episode: 7464, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000259, mae: 0.006961, mean_q: 0.013264
 57004/100000: episode: 7465, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000505, mae: 0.007728, mean_q: 0.013148
 57014/100000: episode: 7466, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000069, mae: 0.005088, mean_q: 0.006762
 57024/100000: episode: 7467, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000395, mae: 0.007090, mean_q: 0.009150
 57034/100000: episode: 7468, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000275, mae: 0.008942, mean_q: 0.015058
 57044/100000: episode: 7469, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000364, mae: 0.007721, mean_q: 0.014595
 57054/100000: episode: 7470, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000308, mae: 0.006407, mean_q: 0.011088
 57064/100000: episode: 7471, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000350, mae: 0.009159, mean_q: 0.016241
 57074/100000: episode: 7472, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000076, mae: 0.005702, mean_q: 0.010314
 57084/100000: episode: 7473, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000152, mae: 0.005393, mean_q: 0.011300
 57094/100000: episode: 7474, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000069, mae: 0.005000, mean_q: 0.011263
 57104/100000: episode: 7475, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000869, mae: 0.009559, mean_q: 0.018764
 57114/100000: episode: 7476, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000589, mae: 0.007498, mean_q: 0.016698
 57124/100000: episode: 7477, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000110, mae: 0.005497, mean_q: 0.006626
 57134/100000: episode: 7478, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000380, mae: 0.007880, mean_q: 0.009302
 57144/100000: episode: 7479, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000348, mae: 0.008485, mean_q: 0.012148
 57154/100000: episode: 7480, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000371, mae: 0.008149, mean_q: 0.011656
 57164/100000: episode: 7481, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000233, mae: 0.006646, mean_q: 0.014463
 57174/100000: episode: 7482, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000455, mae: 0.007797, mean_q: 0.011549
 57184/100000: episode: 7483, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000048, mae: 0.004157, mean_q: 0.006978
 57194/100000: episode: 7484, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000304, mae: 0.007056, mean_q: 0.017451
 57204/100000: episode: 7485, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000642, mae: 0.008265, mean_q: 0.014984
 57214/100000: episode: 7486, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000167, mae: 0.007642, mean_q: 0.015031
 57224/100000: episode: 7487, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000284, mae: 0.006818, mean_q: 0.013454
 57234/100000: episode: 7488, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000381, mae: 0.007207, mean_q: 0.009439
 57244/100000: episode: 7489, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000358, mae: 0.008598, mean_q: 0.014944
 57254/100000: episode: 7490, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000239, mae: 0.006364, mean_q: 0.014812
 57264/100000: episode: 7491, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000387, mae: 0.006832, mean_q: 0.011349
 57274/100000: episode: 7492, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001554, mae: 0.009302, mean_q: 0.011421
 57284/100000: episode: 7493, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000413, mae: 0.008128, mean_q: 0.012892
 57294/100000: episode: 7494, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000141, mae: 0.006843, mean_q: 0.012794
 57304/100000: episode: 7495, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000447, mae: 0.006782, mean_q: 0.008023
 57314/100000: episode: 7496, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000412, mae: 0.006405, mean_q: 0.010805
 57324/100000: episode: 7497, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000178, mae: 0.006126, mean_q: 0.012493
 57334/100000: episode: 7498, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000991, mae: 0.007174, mean_q: 0.008820
 57344/100000: episode: 7499, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.000299, mae: 0.009298, mean_q: 0.015504
 57354/100000: episode: 7500, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000174, mae: 0.005232, mean_q: 0.010119
 57364/100000: episode: 7501, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000758, mae: 0.009735, mean_q: 0.013235
 57374/100000: episode: 7502, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000646, mae: 0.009901, mean_q: 0.021764
 57384/100000: episode: 7503, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000150, mae: 0.005684, mean_q: 0.011117
 57394/100000: episode: 7504, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000222, mae: 0.006219, mean_q: 0.007866
 57404/100000: episode: 7505, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000390, mae: 0.005969, mean_q: 0.009127
 57414/100000: episode: 7506, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000693, mae: 0.008435, mean_q: 0.013505
[Info] 1-TH LEVEL FOUND: 0.025614283978939056, Considering 12/100 traces
 57424/100000: episode: 7507, duration: 0.756s, episode steps: 10, steps per second: 13, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000856, mae: 0.006896, mean_q: 0.012199
 57429/100000: episode: 7508, duration: 0.029s, episode steps: 5, steps per second: 170, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000035, mae: 0.004256, mean_q: 0.007396
 57434/100000: episode: 7509, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000237, mae: 0.006833, mean_q: 0.014201
 57439/100000: episode: 7510, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000352, mae: 0.008657, mean_q: 0.021785
 57444/100000: episode: 7511, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000118, mae: 0.006137, mean_q: 0.019003
 57447/100000: episode: 7512, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000791, mae: 0.008486, mean_q: 0.012529
 57453/100000: episode: 7513, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000669, mae: 0.010488, mean_q: 0.017907
[Info] FALSIFICATION!
 57458/100000: episode: 7514, duration: 0.267s, episode steps: 5, steps per second: 19, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000188, mae: 0.008212, mean_q: 0.008033
 57461/100000: episode: 7515, duration: 0.020s, episode steps: 3, steps per second: 151, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000052, mae: 0.003777, mean_q: 0.003723
 57466/100000: episode: 7516, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000061, mae: 0.004491, mean_q: 0.006804
 57469/100000: episode: 7517, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000199, mae: 0.007165, mean_q: 0.010774
 57474/100000: episode: 7518, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000441, mae: 0.009185, mean_q: 0.013673
 57477/100000: episode: 7519, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000381, mae: 0.009368, mean_q: 0.020499
 57483/100000: episode: 7520, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000288, mae: 0.008232, mean_q: 0.022037
 57486/100000: episode: 7521, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000034, mae: 0.004469, mean_q: 0.010175
 57489/100000: episode: 7522, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000457, mae: 0.010013, mean_q: 0.024460
 57492/100000: episode: 7523, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000317, mae: 0.006547, mean_q: 0.042508
 57495/100000: episode: 7524, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000824, mae: 0.012081, mean_q: 0.022503
 57500/100000: episode: 7525, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.001077, mae: 0.014042, mean_q: 0.022492
 57503/100000: episode: 7526, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000152, mae: 0.010147, mean_q: 0.006065
 57508/100000: episode: 7527, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000362, mae: 0.007365, mean_q: 0.006364
 57511/100000: episode: 7528, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000085, mae: 0.005426, mean_q: 0.005867
 57514/100000: episode: 7529, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000054, mae: 0.005237, mean_q: 0.008020
 57520/100000: episode: 7530, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000431, mae: 0.008960, mean_q: 0.013895
 57526/100000: episode: 7531, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000259, mae: 0.009031, mean_q: 0.013813
 57532/100000: episode: 7532, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000835, mae: 0.010849, mean_q: 0.021297
 57535/100000: episode: 7533, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000244, mae: 0.008052, mean_q: 0.012487
 57538/100000: episode: 7534, duration: 0.020s, episode steps: 3, steps per second: 151, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000924, mae: 0.013114, mean_q: 0.013051
 57543/100000: episode: 7535, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000441, mae: 0.010424, mean_q: 0.017954
 57548/100000: episode: 7536, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000274, mae: 0.009315, mean_q: 0.014399
 57551/100000: episode: 7537, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000343, mae: 0.009263, mean_q: 0.015022
 57556/100000: episode: 7538, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000440, mae: 0.008278, mean_q: 0.020021
 57561/100000: episode: 7539, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000142, mae: 0.007630, mean_q: 0.015045
 57566/100000: episode: 7540, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000049, mae: 0.004647, mean_q: 0.005573
 57572/100000: episode: 7541, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000424, mae: 0.007580, mean_q: 0.013541
 57575/100000: episode: 7542, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001057, mae: 0.010959, mean_q: 0.017509
 57580/100000: episode: 7543, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000518, mae: 0.010283, mean_q: 0.020129
 57586/100000: episode: 7544, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000062, mae: 0.004353, mean_q: 0.005166
 57591/100000: episode: 7545, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000550, mae: 0.008412, mean_q: 0.014937
 57596/100000: episode: 7546, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000088, mae: 0.005652, mean_q: 0.007534
 57601/100000: episode: 7547, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002124, mae: 0.009367, mean_q: 0.008136
 57604/100000: episode: 7548, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001239, mae: 0.014301, mean_q: 0.025035
 57607/100000: episode: 7549, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000190, mae: 0.008939, mean_q: 0.012467
 57612/100000: episode: 7550, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000395, mae: 0.010093, mean_q: 0.017051
 57615/100000: episode: 7551, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000086, mae: 0.005171, mean_q: 0.007225
 57618/100000: episode: 7552, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000267, mae: 0.008415, mean_q: 0.017918
 57623/100000: episode: 7553, duration: 0.028s, episode steps: 5, steps per second: 176, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000213, mae: 0.007924, mean_q: 0.008369
 57628/100000: episode: 7554, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000202, mae: 0.007627, mean_q: 0.007381
 57633/100000: episode: 7555, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000075, mae: 0.005790, mean_q: 0.009707
 57639/100000: episode: 7556, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001279, mae: 0.011826, mean_q: 0.017501
 57642/100000: episode: 7557, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000123, mae: 0.007952, mean_q: 0.015827
 57645/100000: episode: 7558, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000058, mae: 0.004890, mean_q: 0.010987
 57648/100000: episode: 7559, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002190, mae: 0.017533, mean_q: 0.026362
 57654/100000: episode: 7560, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000512, mae: 0.008055, mean_q: 0.016172
 57660/100000: episode: 7561, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000128, mae: 0.006707, mean_q: 0.012629
 57665/100000: episode: 7562, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000393, mae: 0.007733, mean_q: 0.013638
 57670/100000: episode: 7563, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000405, mae: 0.008115, mean_q: 0.012489
 57675/100000: episode: 7564, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000387, mae: 0.008210, mean_q: 0.018241
 57680/100000: episode: 7565, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000314, mae: 0.005998, mean_q: 0.007621
 57685/100000: episode: 7566, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000591, mae: 0.007911, mean_q: 0.010025
 57688/100000: episode: 7567, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000069, mae: 0.006812, mean_q: 0.013009
 57693/100000: episode: 7568, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.001024, mae: 0.014027, mean_q: 0.026007
 57696/100000: episode: 7569, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000164, mae: 0.008641, mean_q: 0.014939
 57701/100000: episode: 7570, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000393, mae: 0.009632, mean_q: 0.026208
 57704/100000: episode: 7571, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000095, mae: 0.005317, mean_q: 0.011148
 57707/100000: episode: 7572, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000065, mae: 0.005127, mean_q: 0.008251
 57712/100000: episode: 7573, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000967, mae: 0.009240, mean_q: 0.013384
 57717/100000: episode: 7574, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000463, mae: 0.007709, mean_q: 0.012913
 57722/100000: episode: 7575, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000301, mae: 0.008523, mean_q: 0.010668
 57727/100000: episode: 7576, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000120, mae: 0.007316, mean_q: 0.012111
 57732/100000: episode: 7577, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000623, mae: 0.011840, mean_q: 0.017118
 57735/100000: episode: 7578, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001138, mae: 0.009838, mean_q: 0.009803
 57740/100000: episode: 7579, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000729, mae: 0.009923, mean_q: 0.011493
 57745/100000: episode: 7580, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000530, mae: 0.011166, mean_q: 0.016623
 57750/100000: episode: 7581, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000500, mae: 0.012123, mean_q: 0.020486
 57753/100000: episode: 7582, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000125, mae: 0.008266, mean_q: 0.016560
 57759/100000: episode: 7583, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000380, mae: 0.009706, mean_q: 0.017423
 57762/100000: episode: 7584, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000048, mae: 0.003706, mean_q: 0.009168
 57765/100000: episode: 7585, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000032, mae: 0.003671, mean_q: 0.006120
 57770/100000: episode: 7586, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000228, mae: 0.007244, mean_q: 0.014435
 57775/100000: episode: 7587, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000432, mae: 0.006588, mean_q: 0.013922
 57780/100000: episode: 7588, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000165, mae: 0.006894, mean_q: 0.011576
 57785/100000: episode: 7589, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000740, mae: 0.010271, mean_q: 0.020971
 57788/100000: episode: 7590, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000098, mae: 0.005108, mean_q: 0.014450
 57794/100000: episode: 7591, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000449, mae: 0.008319, mean_q: 0.013659
 57799/100000: episode: 7592, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000121, mae: 0.007529, mean_q: 0.018793
 57804/100000: episode: 7593, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000377, mae: 0.008172, mean_q: 0.016216
 57807/100000: episode: 7594, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000057, mae: 0.005572, mean_q: 0.010475
[Info] Complete ISplit Iteration
[Info] Levels: [0.025614284, 1.209764]
[Info] Cond. Prob: [0.12, 0.02]
[Info] Error Prob: 0.0024

 57810/100000: episode: 7595, duration: 0.827s, episode steps: 3, steps per second: 4, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000098, mae: 0.007448, mean_q: 0.016188
 57820/100000: episode: 7596, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000074, mae: 0.005624, mean_q: 0.012297
 57830/100000: episode: 7597, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.001195, mae: 0.011644, mean_q: 0.024636
 57840/100000: episode: 7598, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000332, mae: 0.009540, mean_q: 0.012813
 57850/100000: episode: 7599, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000456, mae: 0.008701, mean_q: 0.012739
 57860/100000: episode: 7600, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000274, mae: 0.007480, mean_q: 0.016073
 57870/100000: episode: 7601, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000907, mae: 0.011727, mean_q: 0.020981
 57880/100000: episode: 7602, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001038, mae: 0.012405, mean_q: 0.021334
 57890/100000: episode: 7603, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000567, mae: 0.012419, mean_q: 0.014919
 57900/100000: episode: 7604, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000141, mae: 0.006775, mean_q: 0.009792
 57910/100000: episode: 7605, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000566, mae: 0.011863, mean_q: 0.020428
 57920/100000: episode: 7606, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000795, mae: 0.011731, mean_q: 0.021742
 57930/100000: episode: 7607, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000190, mae: 0.006985, mean_q: 0.010928
 57940/100000: episode: 7608, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000331, mae: 0.007744, mean_q: 0.013609
 57950/100000: episode: 7609, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000330, mae: 0.007827, mean_q: 0.015376
 57960/100000: episode: 7610, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000460, mae: 0.007408, mean_q: 0.016991
 57970/100000: episode: 7611, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000340, mae: 0.008561, mean_q: 0.011086
 57980/100000: episode: 7612, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000408, mae: 0.007903, mean_q: 0.013635
 57990/100000: episode: 7613, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000804, mae: 0.011734, mean_q: 0.020516
 58000/100000: episode: 7614, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000573, mae: 0.010001, mean_q: 0.018072
 58010/100000: episode: 7615, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000149, mae: 0.005432, mean_q: 0.010340
 58020/100000: episode: 7616, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000471, mae: 0.008465, mean_q: 0.014895
 58030/100000: episode: 7617, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000227, mae: 0.007181, mean_q: 0.018555
 58040/100000: episode: 7618, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000482, mae: 0.009735, mean_q: 0.016497
 58050/100000: episode: 7619, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000453, mae: 0.009712, mean_q: 0.019394
 58060/100000: episode: 7620, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000648, mae: 0.010733, mean_q: 0.017569
 58070/100000: episode: 7621, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000430, mae: 0.009661, mean_q: 0.020894
 58080/100000: episode: 7622, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000225, mae: 0.008005, mean_q: 0.020765
 58090/100000: episode: 7623, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000414, mae: 0.009573, mean_q: 0.024136
 58100/100000: episode: 7624, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000791, mae: 0.009352, mean_q: 0.020333
 58110/100000: episode: 7625, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000843, mae: 0.009555, mean_q: 0.015565
 58120/100000: episode: 7626, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000560, mae: 0.010612, mean_q: 0.017948
 58130/100000: episode: 7627, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000183, mae: 0.008614, mean_q: 0.020491
 58140/100000: episode: 7628, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000441, mae: 0.008362, mean_q: 0.016888
 58150/100000: episode: 7629, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000122, mae: 0.006039, mean_q: 0.007812
 58160/100000: episode: 7630, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000132, mae: 0.005737, mean_q: 0.009933
 58170/100000: episode: 7631, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000329, mae: 0.007907, mean_q: 0.013268
 58180/100000: episode: 7632, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000322, mae: 0.008381, mean_q: 0.013780
 58190/100000: episode: 7633, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000082, mae: 0.006672, mean_q: 0.015536
 58200/100000: episode: 7634, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000606, mae: 0.010060, mean_q: 0.020548
 58210/100000: episode: 7635, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000392, mae: 0.007840, mean_q: 0.014036
 58220/100000: episode: 7636, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000081, mae: 0.005360, mean_q: 0.012092
 58230/100000: episode: 7637, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000211, mae: 0.007312, mean_q: 0.013270
 58240/100000: episode: 7638, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001103, mae: 0.009789, mean_q: 0.016949
 58250/100000: episode: 7639, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000458, mae: 0.009525, mean_q: 0.018944
 58260/100000: episode: 7640, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000421, mae: 0.006990, mean_q: 0.011843
 58270/100000: episode: 7641, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000329, mae: 0.006635, mean_q: 0.012039
 58280/100000: episode: 7642, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001283, mae: 0.009202, mean_q: 0.010931
 58290/100000: episode: 7643, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000426, mae: 0.008678, mean_q: 0.015564
 58300/100000: episode: 7644, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001085, mae: 0.011718, mean_q: 0.018147
 58310/100000: episode: 7645, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000802, mae: 0.009450, mean_q: 0.011523
 58320/100000: episode: 7646, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000067, mae: 0.005782, mean_q: 0.010435
 58330/100000: episode: 7647, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000966, mae: 0.008299, mean_q: 0.011288
 58340/100000: episode: 7648, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000823, mae: 0.010985, mean_q: 0.027049
 58350/100000: episode: 7649, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000455, mae: 0.006979, mean_q: 0.010192
 58360/100000: episode: 7650, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000278, mae: 0.007927, mean_q: 0.009349
 58370/100000: episode: 7651, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000235, mae: 0.008555, mean_q: 0.019047
 58380/100000: episode: 7652, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000067, mae: 0.005289, mean_q: 0.010329
 58390/100000: episode: 7653, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000286, mae: 0.006702, mean_q: 0.013428
 58400/100000: episode: 7654, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000208, mae: 0.006879, mean_q: 0.011663
 58410/100000: episode: 7655, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000252, mae: 0.007369, mean_q: 0.014993
 58420/100000: episode: 7656, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000528, mae: 0.007270, mean_q: 0.015117
 58430/100000: episode: 7657, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000737, mae: 0.007882, mean_q: 0.012171
 58440/100000: episode: 7658, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000363, mae: 0.007943, mean_q: 0.008673
 58450/100000: episode: 7659, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000283, mae: 0.006471, mean_q: 0.011107
 58460/100000: episode: 7660, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000245, mae: 0.007271, mean_q: 0.013767
 58470/100000: episode: 7661, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000360, mae: 0.007137, mean_q: 0.012303
 58480/100000: episode: 7662, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000059, mae: 0.004656, mean_q: 0.005388
 58490/100000: episode: 7663, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000174, mae: 0.006172, mean_q: 0.010226
 58500/100000: episode: 7664, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000334, mae: 0.007876, mean_q: 0.014818
 58510/100000: episode: 7665, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000064, mae: 0.004975, mean_q: 0.009313
 58520/100000: episode: 7666, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000075, mae: 0.004225, mean_q: 0.006855
 58530/100000: episode: 7667, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000246, mae: 0.006655, mean_q: 0.012998
 58540/100000: episode: 7668, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000067, mae: 0.004689, mean_q: 0.008071
 58550/100000: episode: 7669, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000158, mae: 0.005257, mean_q: 0.011018
 58560/100000: episode: 7670, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000157, mae: 0.005631, mean_q: 0.011957
 58570/100000: episode: 7671, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000289, mae: 0.006213, mean_q: 0.013808
 58580/100000: episode: 7672, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000238, mae: 0.005788, mean_q: 0.007549
 58590/100000: episode: 7673, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000102, mae: 0.004800, mean_q: 0.009392
 58600/100000: episode: 7674, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000419, mae: 0.007981, mean_q: 0.011940
 58610/100000: episode: 7675, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000121, mae: 0.005184, mean_q: 0.009056
 58620/100000: episode: 7676, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000083, mae: 0.003993, mean_q: 0.006482
 58630/100000: episode: 7677, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000051, mae: 0.003925, mean_q: 0.005736
 58640/100000: episode: 7678, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000177, mae: 0.006112, mean_q: 0.009101
 58650/100000: episode: 7679, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000396, mae: 0.006779, mean_q: 0.010497
 58660/100000: episode: 7680, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000042, mae: 0.004153, mean_q: 0.006608
 58670/100000: episode: 7681, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000317, mae: 0.006809, mean_q: 0.011028
 58680/100000: episode: 7682, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000064, mae: 0.005102, mean_q: 0.007002
 58690/100000: episode: 7683, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000110, mae: 0.004589, mean_q: 0.007370
 58700/100000: episode: 7684, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000162, mae: 0.005839, mean_q: 0.009065
 58710/100000: episode: 7685, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000082, mae: 0.004080, mean_q: 0.007857
 58720/100000: episode: 7686, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000763, mae: 0.009253, mean_q: 0.011647
 58730/100000: episode: 7687, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000072, mae: 0.006532, mean_q: 0.011328
 58740/100000: episode: 7688, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000113, mae: 0.006086, mean_q: 0.009087
 58750/100000: episode: 7689, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000369, mae: 0.006222, mean_q: 0.009574
 58760/100000: episode: 7690, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000353, mae: 0.006816, mean_q: 0.012937
 58770/100000: episode: 7691, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000066, mae: 0.005688, mean_q: 0.010248
 58780/100000: episode: 7692, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000240, mae: 0.006063, mean_q: 0.010595
 58790/100000: episode: 7693, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000366, mae: 0.006541, mean_q: 0.010891
 58800/100000: episode: 7694, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000190, mae: 0.005908, mean_q: 0.010639
[Info] 1-TH LEVEL FOUND: 0.07794259488582611, Considering 10/100 traces
 58810/100000: episode: 7695, duration: 0.714s, episode steps: 10, steps per second: 14, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000180, mae: 0.005239, mean_q: 0.009834
 58815/100000: episode: 7696, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000069, mae: 0.005124, mean_q: 0.006633
 58819/100000: episode: 7697, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000155, mae: 0.005782, mean_q: 0.007509
 58823/100000: episode: 7698, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003440, mae: 0.011101, mean_q: 0.006869
 58827/100000: episode: 7699, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000137, mae: 0.007157, mean_q: 0.014694
 58831/100000: episode: 7700, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000114, mae: 0.007544, mean_q: 0.012627
 58835/100000: episode: 7701, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000278, mae: 0.007688, mean_q: 0.013278
 58839/100000: episode: 7702, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000163, mae: 0.004984, mean_q: 0.008213
 58843/100000: episode: 7703, duration: 0.024s, episode steps: 4, steps per second: 167, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000584, mae: 0.011236, mean_q: 0.017051
 58847/100000: episode: 7704, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000141, mae: 0.008311, mean_q: 0.009517
 58851/100000: episode: 7705, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000496, mae: 0.009766, mean_q: 0.010676
[Info] FALSIFICATION!
 58855/100000: episode: 7706, duration: 0.174s, episode steps: 4, steps per second: 23, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000096, mae: 0.006452, mean_q: 0.010391
 58859/100000: episode: 7707, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000334, mae: 0.006411, mean_q: 0.010110
 58863/100000: episode: 7708, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000621, mae: 0.012448, mean_q: 0.022906
 58867/100000: episode: 7709, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000422, mae: 0.008923, mean_q: 0.018484
 58871/100000: episode: 7710, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000053, mae: 0.005431, mean_q: 0.011243
 58875/100000: episode: 7711, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000759, mae: 0.009916, mean_q: 0.018783
 58879/100000: episode: 7712, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000088, mae: 0.005726, mean_q: 0.013486
 58883/100000: episode: 7713, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000082, mae: 0.005186, mean_q: 0.008443
 58887/100000: episode: 7714, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000401, mae: 0.008472, mean_q: 0.015027
 58891/100000: episode: 7715, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000526, mae: 0.010233, mean_q: 0.017846
 58895/100000: episode: 7716, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000071, mae: 0.005029, mean_q: 0.007969
 58899/100000: episode: 7717, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000157, mae: 0.006973, mean_q: 0.011382
 58903/100000: episode: 7718, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000223, mae: 0.007462, mean_q: 0.014296
 58907/100000: episode: 7719, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000105, mae: 0.008102, mean_q: 0.011750
 58911/100000: episode: 7720, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000265, mae: 0.008986, mean_q: 0.018153
 58915/100000: episode: 7721, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000040, mae: 0.003339, mean_q: 0.006582
 58919/100000: episode: 7722, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000079, mae: 0.004999, mean_q: 0.011542
 58923/100000: episode: 7723, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000055, mae: 0.003981, mean_q: 0.007596
 58928/100000: episode: 7724, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000056, mae: 0.003894, mean_q: 0.006381
 58932/100000: episode: 7725, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000065, mae: 0.004475, mean_q: 0.006727
 58936/100000: episode: 7726, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000075, mae: 0.005296, mean_q: 0.007157
 58940/100000: episode: 7727, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000311, mae: 0.007576, mean_q: 0.014826
 58944/100000: episode: 7728, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000060, mae: 0.005124, mean_q: 0.009900
 58948/100000: episode: 7729, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000039, mae: 0.005035, mean_q: 0.010322
 58952/100000: episode: 7730, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000113, mae: 0.006850, mean_q: 0.012169
 58956/100000: episode: 7731, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000370, mae: 0.008581, mean_q: 0.016543
 58961/100000: episode: 7732, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000105, mae: 0.007123, mean_q: 0.008700
 58965/100000: episode: 7733, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000073, mae: 0.004889, mean_q: 0.007386
 58969/100000: episode: 7734, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000210, mae: 0.006785, mean_q: 0.010736
 58973/100000: episode: 7735, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000047, mae: 0.005132, mean_q: 0.009605
 58977/100000: episode: 7736, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000408, mae: 0.009344, mean_q: 0.016707
 58981/100000: episode: 7737, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000300, mae: 0.008856, mean_q: 0.016768
 58985/100000: episode: 7738, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000226, mae: 0.006697, mean_q: 0.012127
 58989/100000: episode: 7739, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000015, mae: 0.003695, mean_q: 0.007517
 58993/100000: episode: 7740, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000098, mae: 0.005923, mean_q: 0.013332
 58997/100000: episode: 7741, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001614, mae: 0.011810, mean_q: 0.015433
 59001/100000: episode: 7742, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000108, mae: 0.006798, mean_q: 0.009441
 59005/100000: episode: 7743, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000895, mae: 0.012517, mean_q: 0.028783
 59009/100000: episode: 7744, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000487, mae: 0.007823, mean_q: 0.011255
 59013/100000: episode: 7745, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000783, mae: 0.011054, mean_q: 0.015152
 59018/100000: episode: 7746, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000080, mae: 0.006534, mean_q: 0.004295
 59022/100000: episode: 7747, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000261, mae: 0.006777, mean_q: 0.007325
 59027/100000: episode: 7748, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000077, mae: 0.004939, mean_q: 0.007931
 59031/100000: episode: 7749, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000076, mae: 0.005578, mean_q: 0.009503
 59035/100000: episode: 7750, duration: 0.024s, episode steps: 4, steps per second: 170, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000178, mae: 0.006796, mean_q: 0.011012
 59039/100000: episode: 7751, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000999, mae: 0.011640, mean_q: 0.018588
 59043/100000: episode: 7752, duration: 0.026s, episode steps: 4, steps per second: 152, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000110, mae: 0.008919, mean_q: 0.016328
 59047/100000: episode: 7753, duration: 0.025s, episode steps: 4, steps per second: 161, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000195, mae: 0.008519, mean_q: 0.013798
 59051/100000: episode: 7754, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000239, mae: 0.007684, mean_q: 0.013469
 59055/100000: episode: 7755, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000647, mae: 0.008759, mean_q: 0.013495
 59060/100000: episode: 7756, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000793, mae: 0.010221, mean_q: 0.019841
 59064/100000: episode: 7757, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000073, mae: 0.004725, mean_q: 0.008791
 59069/100000: episode: 7758, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000510, mae: 0.009756, mean_q: 0.023037
[Info] FALSIFICATION!
 59073/100000: episode: 7759, duration: 0.263s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000062, mae: 0.004252, mean_q: 0.006909
 59077/100000: episode: 7760, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000779, mae: 0.008921, mean_q: 0.015054
 59081/100000: episode: 7761, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000465, mae: 0.008531, mean_q: 0.018882
 59085/100000: episode: 7762, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000086, mae: 0.004822, mean_q: 0.008613
 59090/100000: episode: 7763, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000452, mae: 0.009244, mean_q: 0.014663
 59094/100000: episode: 7764, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000414, mae: 0.006775, mean_q: 0.011529
 59098/100000: episode: 7765, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000384, mae: 0.007167, mean_q: 0.012255
 59102/100000: episode: 7766, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000363, mae: 0.007207, mean_q: 0.013807
 59106/100000: episode: 7767, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000470, mae: 0.009462, mean_q: 0.018919
 59110/100000: episode: 7768, duration: 0.023s, episode steps: 4, steps per second: 178, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000061, mae: 0.007188, mean_q: 0.012884
 59114/100000: episode: 7769, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000141, mae: 0.007290, mean_q: 0.015481
 59118/100000: episode: 7770, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001027, mae: 0.013408, mean_q: 0.031172
 59122/100000: episode: 7771, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000220, mae: 0.007093, mean_q: 0.010969
 59126/100000: episode: 7772, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000266, mae: 0.010190, mean_q: 0.014483
 59130/100000: episode: 7773, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000056, mae: 0.005687, mean_q: 0.003538
 59134/100000: episode: 7774, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001729, mae: 0.018047, mean_q: 0.024317
 59139/100000: episode: 7775, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000118, mae: 0.007478, mean_q: 0.007816
 59144/100000: episode: 7776, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000733, mae: 0.008303, mean_q: 0.013651
 59148/100000: episode: 7777, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000481, mae: 0.012210, mean_q: 0.024785
 59152/100000: episode: 7778, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000474, mae: 0.012073, mean_q: 0.021567
 59156/100000: episode: 7779, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000156, mae: 0.009243, mean_q: 0.017381
 59160/100000: episode: 7780, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000101, mae: 0.006485, mean_q: 0.016254
 59164/100000: episode: 7781, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000084, mae: 0.005431, mean_q: 0.007134
 59168/100000: episode: 7782, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000245, mae: 0.009022, mean_q: 0.015710
 59172/100000: episode: 7783, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000106, mae: 0.007123, mean_q: 0.009500
 59176/100000: episode: 7784, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000112, mae: 0.006898, mean_q: 0.015431
[Info] Complete ISplit Iteration
[Info] Levels: [0.077942595, 1.1633276]
[Info] Cond. Prob: [0.1, 0.02]
[Info] Error Prob: 0.002

 59180/100000: episode: 7785, duration: 0.840s, episode steps: 4, steps per second: 5, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000091, mae: 0.005860, mean_q: 0.013071
 59190/100000: episode: 7786, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000161, mae: 0.005625, mean_q: 0.011117
 59200/100000: episode: 7787, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000284, mae: 0.007564, mean_q: 0.016175
 59210/100000: episode: 7788, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000385, mae: 0.008820, mean_q: 0.019812
 59220/100000: episode: 7789, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000778, mae: 0.010880, mean_q: 0.021525
 59230/100000: episode: 7790, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000403, mae: 0.007314, mean_q: 0.009318
 59240/100000: episode: 7791, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000431, mae: 0.009227, mean_q: 0.016550
 59250/100000: episode: 7792, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000173, mae: 0.008723, mean_q: 0.015946
 59260/100000: episode: 7793, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000161, mae: 0.007085, mean_q: 0.013915
 59270/100000: episode: 7794, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000206, mae: 0.005561, mean_q: 0.012320
 59280/100000: episode: 7795, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001680, mae: 0.011180, mean_q: 0.015278
 59290/100000: episode: 7796, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000555, mae: 0.009566, mean_q: 0.019605
 59300/100000: episode: 7797, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000506, mae: 0.010038, mean_q: 0.013792
 59310/100000: episode: 7798, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000580, mae: 0.009213, mean_q: 0.016758
 59320/100000: episode: 7799, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000524, mae: 0.010252, mean_q: 0.017742
 59330/100000: episode: 7800, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000297, mae: 0.009980, mean_q: 0.018265
 59340/100000: episode: 7801, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000114, mae: 0.006887, mean_q: 0.014829
 59350/100000: episode: 7802, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000212, mae: 0.006515, mean_q: 0.013520
 59360/100000: episode: 7803, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000373, mae: 0.008112, mean_q: 0.016784
 59370/100000: episode: 7804, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000257, mae: 0.008506, mean_q: 0.018122
 59380/100000: episode: 7805, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000530, mae: 0.007942, mean_q: 0.017674
 59390/100000: episode: 7806, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001129, mae: 0.011670, mean_q: 0.025001
 59400/100000: episode: 7807, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000148, mae: 0.006383, mean_q: 0.010374
 59410/100000: episode: 7808, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000116, mae: 0.006588, mean_q: 0.012919
 59420/100000: episode: 7809, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000423, mae: 0.009038, mean_q: 0.016766
 59430/100000: episode: 7810, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000089, mae: 0.005575, mean_q: 0.009797
 59440/100000: episode: 7811, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000340, mae: 0.009395, mean_q: 0.016077
 59450/100000: episode: 7812, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000180, mae: 0.008237, mean_q: 0.018275
 59460/100000: episode: 7813, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000544, mae: 0.008748, mean_q: 0.012565
 59470/100000: episode: 7814, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000189, mae: 0.006642, mean_q: 0.010923
 59480/100000: episode: 7815, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000320, mae: 0.008536, mean_q: 0.017492
 59490/100000: episode: 7816, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000272, mae: 0.009941, mean_q: 0.019624
 59500/100000: episode: 7817, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000470, mae: 0.009470, mean_q: 0.021583
 59510/100000: episode: 7818, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000364, mae: 0.009200, mean_q: 0.010080
 59520/100000: episode: 7819, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000609, mae: 0.009879, mean_q: 0.016295
 59530/100000: episode: 7820, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000442, mae: 0.009763, mean_q: 0.018843
 59540/100000: episode: 7821, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000178, mae: 0.007617, mean_q: 0.013532
 59550/100000: episode: 7822, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000568, mae: 0.009556, mean_q: 0.017523
 59560/100000: episode: 7823, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000262, mae: 0.007193, mean_q: 0.013423
 59570/100000: episode: 7824, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000132, mae: 0.007019, mean_q: 0.011969
 59580/100000: episode: 7825, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000265, mae: 0.007038, mean_q: 0.012755
 59590/100000: episode: 7826, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000253, mae: 0.007098, mean_q: 0.012450
 59600/100000: episode: 7827, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000532, mae: 0.009297, mean_q: 0.017873
 59610/100000: episode: 7828, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000256, mae: 0.008186, mean_q: 0.009341
 59620/100000: episode: 7829, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000494, mae: 0.008597, mean_q: 0.011311
 59630/100000: episode: 7830, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000300, mae: 0.007379, mean_q: 0.011766
 59640/100000: episode: 7831, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000180, mae: 0.007181, mean_q: 0.011080
 59650/100000: episode: 7832, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000363, mae: 0.007713, mean_q: 0.014679
 59660/100000: episode: 7833, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000314, mae: 0.009111, mean_q: 0.018849
 59670/100000: episode: 7834, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000082, mae: 0.005339, mean_q: 0.011443
 59680/100000: episode: 7835, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000479, mae: 0.007209, mean_q: 0.012791
 59690/100000: episode: 7836, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000114, mae: 0.004934, mean_q: 0.007496
 59700/100000: episode: 7837, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000181, mae: 0.006101, mean_q: 0.010133
 59710/100000: episode: 7838, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000084, mae: 0.006150, mean_q: 0.010276
 59720/100000: episode: 7839, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000199, mae: 0.007471, mean_q: 0.013839
 59730/100000: episode: 7840, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000052, mae: 0.004226, mean_q: 0.007278
 59740/100000: episode: 7841, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000103, mae: 0.005306, mean_q: 0.009590
 59750/100000: episode: 7842, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000842, mae: 0.009227, mean_q: 0.016229
 59760/100000: episode: 7843, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000367, mae: 0.008519, mean_q: 0.015337
 59770/100000: episode: 7844, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000166, mae: 0.006882, mean_q: 0.010986
 59780/100000: episode: 7845, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000503, mae: 0.009348, mean_q: 0.018708
 59790/100000: episode: 7846, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000281, mae: 0.007243, mean_q: 0.012619
 59800/100000: episode: 7847, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000267, mae: 0.006740, mean_q: 0.011375
 59810/100000: episode: 7848, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000413, mae: 0.006494, mean_q: 0.010416
 59820/100000: episode: 7849, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000057, mae: 0.004726, mean_q: 0.008767
 59830/100000: episode: 7850, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000653, mae: 0.008250, mean_q: 0.016183
 59840/100000: episode: 7851, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000142, mae: 0.005801, mean_q: 0.008827
 59850/100000: episode: 7852, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000213, mae: 0.005648, mean_q: 0.007810
 59860/100000: episode: 7853, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000131, mae: 0.005462, mean_q: 0.009699
 59870/100000: episode: 7854, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000364, mae: 0.006241, mean_q: 0.010251
 59880/100000: episode: 7855, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000106, mae: 0.005465, mean_q: 0.011256
 59890/100000: episode: 7856, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000426, mae: 0.008509, mean_q: 0.016209
 59900/100000: episode: 7857, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000120, mae: 0.005971, mean_q: 0.010176
 59910/100000: episode: 7858, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001127, mae: 0.010376, mean_q: 0.018798
 59920/100000: episode: 7859, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000393, mae: 0.008500, mean_q: 0.015960
 59930/100000: episode: 7860, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000278, mae: 0.006724, mean_q: 0.013519
 59940/100000: episode: 7861, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000109, mae: 0.005215, mean_q: 0.009948
 59950/100000: episode: 7862, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000592, mae: 0.008111, mean_q: 0.017484
 59960/100000: episode: 7863, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000257, mae: 0.006659, mean_q: 0.012979
 59970/100000: episode: 7864, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000146, mae: 0.005554, mean_q: 0.011521
 59980/100000: episode: 7865, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000141, mae: 0.004933, mean_q: 0.009050
 59990/100000: episode: 7866, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000252, mae: 0.007092, mean_q: 0.012469
 60000/100000: episode: 7867, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000186, mae: 0.006980, mean_q: 0.017179
 60010/100000: episode: 7868, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000312, mae: 0.006190, mean_q: 0.011122
 60020/100000: episode: 7869, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000221, mae: 0.006012, mean_q: 0.009788
 60030/100000: episode: 7870, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000246, mae: 0.007128, mean_q: 0.013573
 60040/100000: episode: 7871, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000666, mae: 0.010349, mean_q: 0.017508
 60050/100000: episode: 7872, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000417, mae: 0.007998, mean_q: 0.012401
 60060/100000: episode: 7873, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000166, mae: 0.007485, mean_q: 0.014553
 60070/100000: episode: 7874, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000068, mae: 0.005378, mean_q: 0.008774
 60080/100000: episode: 7875, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000084, mae: 0.005940, mean_q: 0.008350
 60090/100000: episode: 7876, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000407, mae: 0.007769, mean_q: 0.011327
 60100/100000: episode: 7877, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000458, mae: 0.008826, mean_q: 0.013348
 60110/100000: episode: 7878, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000250, mae: 0.007747, mean_q: 0.015961
 60120/100000: episode: 7879, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000534, mae: 0.008826, mean_q: 0.018950
 60130/100000: episode: 7880, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000738, mae: 0.008708, mean_q: 0.016710
 60140/100000: episode: 7881, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000802, mae: 0.009515, mean_q: 0.015425
 60150/100000: episode: 7882, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000194, mae: 0.008596, mean_q: 0.008297
 60160/100000: episode: 7883, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000205, mae: 0.007271, mean_q: 0.011526
 60170/100000: episode: 7884, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000254, mae: 0.006437, mean_q: 0.010879
[Info] 1-TH LEVEL FOUND: 0.02605447731912136, Considering 12/100 traces
 60180/100000: episode: 7885, duration: 0.679s, episode steps: 10, steps per second: 15, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000223, mae: 0.006455, mean_q: 0.011337
 60183/100000: episode: 7886, duration: 0.021s, episode steps: 3, steps per second: 146, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000071, mae: 0.005305, mean_q: 0.008559
 60186/100000: episode: 7887, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000361, mae: 0.009480, mean_q: 0.022082
 60189/100000: episode: 7888, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000478, mae: 0.010316, mean_q: 0.022157
 60192/100000: episode: 7889, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000082, mae: 0.006668, mean_q: 0.010873
 60195/100000: episode: 7890, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000355, mae: 0.009148, mean_q: 0.020027
 60198/100000: episode: 7891, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000199, mae: 0.007296, mean_q: 0.019269
 60201/100000: episode: 7892, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000274, mae: 0.008971, mean_q: 0.019585
 60204/100000: episode: 7893, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000053, mae: 0.005394, mean_q: 0.009972
 60208/100000: episode: 7894, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000091, mae: 0.005720, mean_q: 0.012566
 60211/100000: episode: 7895, duration: 0.018s, episode steps: 3, steps per second: 162, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000038, mae: 0.003694, mean_q: 0.005444
 60217/100000: episode: 7896, duration: 0.033s, episode steps: 6, steps per second: 182, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000245, mae: 0.006015, mean_q: 0.009532
 60221/100000: episode: 7897, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000070, mae: 0.005399, mean_q: 0.008471
 60224/100000: episode: 7898, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000080, mae: 0.005516, mean_q: 0.015370
 60227/100000: episode: 7899, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000110, mae: 0.006781, mean_q: 0.016817
 60231/100000: episode: 7900, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000058, mae: 0.004138, mean_q: 0.005527
 60237/100000: episode: 7901, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000547, mae: 0.006379, mean_q: 0.009907
 60241/100000: episode: 7902, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000031, mae: 0.002969, mean_q: 0.005045
 60245/100000: episode: 7903, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001605, mae: 0.012235, mean_q: 0.017301
 60248/100000: episode: 7904, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000304, mae: 0.009671, mean_q: 0.021322
 60251/100000: episode: 7905, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000123, mae: 0.008682, mean_q: 0.014414
 60255/100000: episode: 7906, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000748, mae: 0.012269, mean_q: 0.019670
 60261/100000: episode: 7907, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000140, mae: 0.006279, mean_q: 0.008975
 60265/100000: episode: 7908, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001362, mae: 0.016202, mean_q: 0.029516
 60269/100000: episode: 7909, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000177, mae: 0.008103, mean_q: 0.006338
 60275/100000: episode: 7910, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000157, mae: 0.008907, mean_q: 0.007666
 60279/100000: episode: 7911, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000232, mae: 0.008465, mean_q: 0.008256
 60282/100000: episode: 7912, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000104, mae: 0.007146, mean_q: 0.011499
 60285/100000: episode: 7913, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000089, mae: 0.007874, mean_q: 0.012477
 60288/100000: episode: 7914, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000026, mae: 0.005232, mean_q: 0.007119
 60291/100000: episode: 7915, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000172, mae: 0.008966, mean_q: 0.014854
 60294/100000: episode: 7916, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000056, mae: 0.006315, mean_q: 0.010175
 60300/100000: episode: 7917, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000164, mae: 0.007316, mean_q: 0.011691
 60303/100000: episode: 7918, duration: 0.018s, episode steps: 3, steps per second: 162, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000161, mae: 0.006300, mean_q: 0.008918
 60307/100000: episode: 7919, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000349, mae: 0.006288, mean_q: 0.010775
 60311/100000: episode: 7920, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000300, mae: 0.007336, mean_q: 0.011807
 60314/100000: episode: 7921, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000077, mae: 0.005454, mean_q: 0.010327
 60318/100000: episode: 7922, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000904, mae: 0.009882, mean_q: 0.015010
 60321/100000: episode: 7923, duration: 0.019s, episode steps: 3, steps per second: 156, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000727, mae: 0.007679, mean_q: 0.007205
 60324/100000: episode: 7924, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000188, mae: 0.008333, mean_q: 0.014483
 60328/100000: episode: 7925, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000576, mae: 0.010878, mean_q: 0.018015
 60331/100000: episode: 7926, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000580, mae: 0.008502, mean_q: 0.015867
 60334/100000: episode: 7927, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000074, mae: 0.004601, mean_q: 0.009329
 60338/100000: episode: 7928, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000076, mae: 0.005072, mean_q: 0.007238
 60342/100000: episode: 7929, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000062, mae: 0.004568, mean_q: 0.006848
 60346/100000: episode: 7930, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000111, mae: 0.006693, mean_q: 0.010097
[Info] FALSIFICATION!
 60351/100000: episode: 7931, duration: 0.182s, episode steps: 5, steps per second: 28, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000081, mae: 0.007090, mean_q: 0.013459
 60354/100000: episode: 7932, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000084, mae: 0.006538, mean_q: 0.014067
 60357/100000: episode: 7933, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000043, mae: 0.004716, mean_q: 0.008698
 60363/100000: episode: 7934, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000356, mae: 0.007142, mean_q: 0.011523
 60366/100000: episode: 7935, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000762, mae: 0.009032, mean_q: 0.009822
 60372/100000: episode: 7936, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000522, mae: 0.009848, mean_q: 0.017381
 60376/100000: episode: 7937, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000716, mae: 0.011152, mean_q: 0.016000
 60379/100000: episode: 7938, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000322, mae: 0.009351, mean_q: 0.011690
 60383/100000: episode: 7939, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000220, mae: 0.006491, mean_q: 0.013997
 60386/100000: episode: 7940, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000072, mae: 0.005648, mean_q: 0.009809
 60389/100000: episode: 7941, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000082, mae: 0.005850, mean_q: 0.011846
 60393/100000: episode: 7942, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000317, mae: 0.007423, mean_q: 0.020710
 60396/100000: episode: 7943, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000040, mae: 0.002804, mean_q: 0.006278
 60399/100000: episode: 7944, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000096, mae: 0.006215, mean_q: 0.013974
 60403/100000: episode: 7945, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000445, mae: 0.008187, mean_q: 0.011731
 60406/100000: episode: 7946, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000146, mae: 0.005942, mean_q: 0.013604
 60409/100000: episode: 7947, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000070, mae: 0.005166, mean_q: 0.013405
 60413/100000: episode: 7948, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000125, mae: 0.008021, mean_q: 0.019410
 60416/100000: episode: 7949, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000060, mae: 0.004272, mean_q: 0.012297
 60419/100000: episode: 7950, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001434, mae: 0.010912, mean_q: 0.019999
 60422/100000: episode: 7951, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000123, mae: 0.006789, mean_q: 0.011984
 60425/100000: episode: 7952, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000051, mae: 0.004703, mean_q: 0.006553
 60428/100000: episode: 7953, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000088, mae: 0.006334, mean_q: 0.009823
 60432/100000: episode: 7954, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000113, mae: 0.006089, mean_q: 0.012872
 60436/100000: episode: 7955, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000714, mae: 0.008440, mean_q: 0.014339
 60439/100000: episode: 7956, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000057, mae: 0.004003, mean_q: 0.008592
 60443/100000: episode: 7957, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000604, mae: 0.010056, mean_q: 0.020589
 60447/100000: episode: 7958, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000432, mae: 0.008580, mean_q: 0.018182
 60451/100000: episode: 7959, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000679, mae: 0.012070, mean_q: 0.023823
 60454/100000: episode: 7960, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000113, mae: 0.007501, mean_q: 0.014677
 60457/100000: episode: 7961, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000129, mae: 0.007463, mean_q: 0.012180
 60460/100000: episode: 7962, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001204, mae: 0.012118, mean_q: 0.018233
 60463/100000: episode: 7963, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001479, mae: 0.012478, mean_q: 0.022131
 60467/100000: episode: 7964, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000056, mae: 0.004675, mean_q: 0.009780
 60471/100000: episode: 7965, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000478, mae: 0.009960, mean_q: 0.019640
 60477/100000: episode: 7966, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000309, mae: 0.008366, mean_q: 0.018029
 60480/100000: episode: 7967, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000539, mae: 0.009459, mean_q: 0.014882
 60484/100000: episode: 7968, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000914, mae: 0.007494, mean_q: 0.011802
 60488/100000: episode: 7969, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000113, mae: 0.006069, mean_q: 0.007397
 60494/100000: episode: 7970, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000177, mae: 0.006967, mean_q: 0.015194
 60497/100000: episode: 7971, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000140, mae: 0.008096, mean_q: 0.013629
 60501/100000: episode: 7972, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000168, mae: 0.009170, mean_q: 0.013964
[Info] Complete ISplit Iteration
[Info] Levels: [0.026054477, 1.1902534]
[Info] Cond. Prob: [0.12, 0.01]
[Info] Error Prob: 0.0012

 60504/100000: episode: 7973, duration: 0.841s, episode steps: 3, steps per second: 4, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000109, mae: 0.007532, mean_q: 0.012800
 60514/100000: episode: 7974, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000495, mae: 0.008568, mean_q: 0.018365
 60524/100000: episode: 7975, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000504, mae: 0.010968, mean_q: 0.018894
 60534/100000: episode: 7976, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000134, mae: 0.006161, mean_q: 0.011889
 60544/100000: episode: 7977, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000253, mae: 0.008286, mean_q: 0.019936
 60554/100000: episode: 7978, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000110, mae: 0.005448, mean_q: 0.010478
 60564/100000: episode: 7979, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001308, mae: 0.011537, mean_q: 0.019336
 60574/100000: episode: 7980, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000491, mae: 0.009726, mean_q: 0.011449
 60584/100000: episode: 7981, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000132, mae: 0.008159, mean_q: 0.013904
 60594/100000: episode: 7982, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000705, mae: 0.010628, mean_q: 0.018313
 60604/100000: episode: 7983, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000395, mae: 0.006490, mean_q: 0.012557
 60614/100000: episode: 7984, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000207, mae: 0.006482, mean_q: 0.008361
 60624/100000: episode: 7985, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000107, mae: 0.007140, mean_q: 0.012493
 60634/100000: episode: 7986, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000414, mae: 0.010271, mean_q: 0.018462
 60644/100000: episode: 7987, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000243, mae: 0.008666, mean_q: 0.013987
 60654/100000: episode: 7988, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000282, mae: 0.009183, mean_q: 0.021551
 60664/100000: episode: 7989, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000519, mae: 0.009391, mean_q: 0.017124
 60674/100000: episode: 7990, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000280, mae: 0.007742, mean_q: 0.009975
 60684/100000: episode: 7991, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000129, mae: 0.006097, mean_q: 0.012507
 60694/100000: episode: 7992, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000202, mae: 0.007032, mean_q: 0.013914
 60704/100000: episode: 7993, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000963, mae: 0.009801, mean_q: 0.018388
 60714/100000: episode: 7994, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000601, mae: 0.009050, mean_q: 0.013981
 60724/100000: episode: 7995, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000235, mae: 0.008922, mean_q: 0.018203
 60734/100000: episode: 7996, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000237, mae: 0.007566, mean_q: 0.015984
 60744/100000: episode: 7997, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000185, mae: 0.007070, mean_q: 0.006537
 60754/100000: episode: 7998, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000195, mae: 0.007128, mean_q: 0.010947
 60764/100000: episode: 7999, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000280, mae: 0.008790, mean_q: 0.016531
 60774/100000: episode: 8000, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000675, mae: 0.009904, mean_q: 0.016764
 60784/100000: episode: 8001, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000147, mae: 0.008344, mean_q: 0.005727
 60794/100000: episode: 8002, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000284, mae: 0.009172, mean_q: 0.012993
 60804/100000: episode: 8003, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000632, mae: 0.011418, mean_q: 0.017863
 60814/100000: episode: 8004, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000142, mae: 0.007407, mean_q: 0.011182
 60824/100000: episode: 8005, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000160, mae: 0.006033, mean_q: 0.015542
 60834/100000: episode: 8006, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000096, mae: 0.005772, mean_q: 0.011912
 60844/100000: episode: 8007, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000073, mae: 0.004962, mean_q: 0.012240
 60854/100000: episode: 8008, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000083, mae: 0.006013, mean_q: 0.011597
 60864/100000: episode: 8009, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000077, mae: 0.005913, mean_q: 0.015028
 60874/100000: episode: 8010, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000803, mae: 0.011385, mean_q: 0.022056
 60884/100000: episode: 8011, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000185, mae: 0.006486, mean_q: 0.010645
 60894/100000: episode: 8012, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000538, mae: 0.008723, mean_q: 0.017854
 60904/100000: episode: 8013, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000377, mae: 0.009513, mean_q: 0.018285
 60914/100000: episode: 8014, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000697, mae: 0.009398, mean_q: 0.018533
 60924/100000: episode: 8015, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000328, mae: 0.006634, mean_q: 0.007356
 60934/100000: episode: 8016, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000348, mae: 0.008297, mean_q: 0.012179
 60944/100000: episode: 8017, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000135, mae: 0.008113, mean_q: 0.013449
 60954/100000: episode: 8018, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000842, mae: 0.010225, mean_q: 0.015835
 60964/100000: episode: 8019, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000128, mae: 0.005943, mean_q: 0.011874
 60974/100000: episode: 8020, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000135, mae: 0.007675, mean_q: 0.009270
 60984/100000: episode: 8021, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000096, mae: 0.007322, mean_q: 0.013376
 60994/100000: episode: 8022, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000442, mae: 0.009539, mean_q: 0.016580
 61004/100000: episode: 8023, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000228, mae: 0.007454, mean_q: 0.012572
 61014/100000: episode: 8024, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000114, mae: 0.007179, mean_q: 0.015515
 61024/100000: episode: 8025, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000654, mae: 0.008737, mean_q: 0.016429
 61034/100000: episode: 8026, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000538, mae: 0.008981, mean_q: 0.011734
 61044/100000: episode: 8027, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000436, mae: 0.007815, mean_q: 0.015364
 61054/100000: episode: 8028, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000520, mae: 0.009445, mean_q: 0.014158
 61064/100000: episode: 8029, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000186, mae: 0.008280, mean_q: 0.012202
 61074/100000: episode: 8030, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000345, mae: 0.009607, mean_q: 0.020920
 61084/100000: episode: 8031, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000290, mae: 0.008638, mean_q: 0.017632
 61094/100000: episode: 8032, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000225, mae: 0.007303, mean_q: 0.018583
 61104/100000: episode: 8033, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000091, mae: 0.005972, mean_q: 0.012059
 61114/100000: episode: 8034, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000173, mae: 0.006401, mean_q: 0.012722
 61124/100000: episode: 8035, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001779, mae: 0.010629, mean_q: 0.014568
 61134/100000: episode: 8036, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000753, mae: 0.010930, mean_q: 0.022660
 61144/100000: episode: 8037, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000265, mae: 0.008304, mean_q: 0.010640
 61154/100000: episode: 8038, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000239, mae: 0.006821, mean_q: 0.013170
 61164/100000: episode: 8039, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000096, mae: 0.007761, mean_q: 0.015434
 61174/100000: episode: 8040, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000346, mae: 0.007914, mean_q: 0.017266
 61184/100000: episode: 8041, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000377, mae: 0.008926, mean_q: 0.017053
 61194/100000: episode: 8042, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000124, mae: 0.006150, mean_q: 0.010102
 61204/100000: episode: 8043, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000536, mae: 0.009641, mean_q: 0.012085
 61214/100000: episode: 8044, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000093, mae: 0.006690, mean_q: 0.008275
 61224/100000: episode: 8045, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000552, mae: 0.010756, mean_q: 0.015461
 61234/100000: episode: 8046, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000339, mae: 0.010030, mean_q: 0.016707
 61244/100000: episode: 8047, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000163, mae: 0.007766, mean_q: 0.016636
 61254/100000: episode: 8048, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000086, mae: 0.006208, mean_q: 0.017032
 61264/100000: episode: 8049, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001008, mae: 0.010348, mean_q: 0.017981
 61274/100000: episode: 8050, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000188, mae: 0.007240, mean_q: 0.010974
 61284/100000: episode: 8051, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000268, mae: 0.008430, mean_q: 0.014487
 61294/100000: episode: 8052, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000088, mae: 0.006983, mean_q: 0.012640
 61304/100000: episode: 8053, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000536, mae: 0.010278, mean_q: 0.018278
 61314/100000: episode: 8054, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000163, mae: 0.006171, mean_q: 0.012406
 61324/100000: episode: 8055, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000592, mae: 0.009523, mean_q: 0.022476
 61334/100000: episode: 8056, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000082, mae: 0.005901, mean_q: 0.013077
 61344/100000: episode: 8057, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000737, mae: 0.010630, mean_q: 0.018428
 61354/100000: episode: 8058, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000159, mae: 0.006738, mean_q: 0.012407
 61364/100000: episode: 8059, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000218, mae: 0.007293, mean_q: 0.011649
 61374/100000: episode: 8060, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000308, mae: 0.009324, mean_q: 0.022690
 61384/100000: episode: 8061, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000205, mae: 0.006542, mean_q: 0.012007
 61394/100000: episode: 8062, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000649, mae: 0.009972, mean_q: 0.014654
 61404/100000: episode: 8063, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000170, mae: 0.007423, mean_q: 0.004953
 61414/100000: episode: 8064, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000272, mae: 0.009607, mean_q: 0.013862
 61424/100000: episode: 8065, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000302, mae: 0.010750, mean_q: 0.018612
 61434/100000: episode: 8066, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000526, mae: 0.009694, mean_q: 0.016518
 61444/100000: episode: 8067, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000206, mae: 0.007361, mean_q: 0.010778
 61454/100000: episode: 8068, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000078, mae: 0.006228, mean_q: 0.011296
 61464/100000: episode: 8069, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000594, mae: 0.010764, mean_q: 0.023628
 61474/100000: episode: 8070, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001078, mae: 0.008927, mean_q: 0.010563
 61484/100000: episode: 8071, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000271, mae: 0.008282, mean_q: 0.017127
 61494/100000: episode: 8072, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000495, mae: 0.009730, mean_q: 0.022064
[Info] 1-TH LEVEL FOUND: 0.0174298956990242, Considering 16/100 traces
 61504/100000: episode: 8073, duration: 0.670s, episode steps: 10, steps per second: 15, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000426, mae: 0.008947, mean_q: 0.012698
 61507/100000: episode: 8074, duration: 0.021s, episode steps: 3, steps per second: 144, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000033, mae: 0.004056, mean_q: 0.002674
 61513/100000: episode: 8075, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000074, mae: 0.004900, mean_q: 0.005373
 61516/100000: episode: 8076, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000101, mae: 0.004928, mean_q: 0.006324
 61522/100000: episode: 8077, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000173, mae: 0.006886, mean_q: 0.010304
 61528/100000: episode: 8078, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000159, mae: 0.009445, mean_q: 0.016872
 61532/100000: episode: 8079, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001075, mae: 0.013525, mean_q: 0.021440
 61535/100000: episode: 8080, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000083, mae: 0.007391, mean_q: 0.013785
 61538/100000: episode: 8081, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000234, mae: 0.010207, mean_q: 0.014115
 61544/100000: episode: 8082, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000650, mae: 0.011498, mean_q: 0.021161
 61547/100000: episode: 8083, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000120, mae: 0.006967, mean_q: 0.012219
 61550/100000: episode: 8084, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000733, mae: 0.010042, mean_q: 0.016773
 61553/100000: episode: 8085, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000140, mae: 0.007351, mean_q: 0.007475
 61556/100000: episode: 8086, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000413, mae: 0.008783, mean_q: 0.010555
 61562/100000: episode: 8087, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000445, mae: 0.010243, mean_q: 0.017950
 61566/100000: episode: 8088, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000107, mae: 0.008200, mean_q: 0.020122
 61569/100000: episode: 8089, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000172, mae: 0.009283, mean_q: 0.016749
 61572/100000: episode: 8090, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000469, mae: 0.011042, mean_q: 0.022532
 61575/100000: episode: 8091, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000089, mae: 0.006273, mean_q: 0.010210
 61581/100000: episode: 8092, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000648, mae: 0.011247, mean_q: 0.013503
 61587/100000: episode: 8093, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001092, mae: 0.014312, mean_q: 0.026017
 61593/100000: episode: 8094, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000090, mae: 0.006653, mean_q: 0.012752
 61596/100000: episode: 8095, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000071, mae: 0.005749, mean_q: 0.011528
 61599/100000: episode: 8096, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000192, mae: 0.007737, mean_q: 0.013770
 61602/100000: episode: 8097, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000455, mae: 0.007774, mean_q: 0.015899
 61606/100000: episode: 8098, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000400, mae: 0.008712, mean_q: 0.018733
 61612/100000: episode: 8099, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000243, mae: 0.009287, mean_q: 0.017461
 61615/100000: episode: 8100, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000126, mae: 0.007868, mean_q: 0.012058
 61618/100000: episode: 8101, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000111, mae: 0.006582, mean_q: 0.014466
 61624/100000: episode: 8102, duration: 0.033s, episode steps: 6, steps per second: 184, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000599, mae: 0.009780, mean_q: 0.013168
 61628/100000: episode: 8103, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000295, mae: 0.009498, mean_q: 0.006374
 61632/100000: episode: 8104, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000122, mae: 0.005899, mean_q: 0.006073
 61635/100000: episode: 8105, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000139, mae: 0.008774, mean_q: 0.014895
 61638/100000: episode: 8106, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000606, mae: 0.013303, mean_q: 0.025057
 61641/100000: episode: 8107, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000109, mae: 0.008792, mean_q: 0.016663
 61644/100000: episode: 8108, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000124, mae: 0.008566, mean_q: 0.016631
 61648/100000: episode: 8109, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000047, mae: 0.005212, mean_q: 0.011524
 61651/100000: episode: 8110, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000093, mae: 0.005810, mean_q: 0.009954
 61655/100000: episode: 8111, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000483, mae: 0.010276, mean_q: 0.020513
 61658/100000: episode: 8112, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000817, mae: 0.009856, mean_q: 0.021885
 61661/100000: episode: 8113, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000109, mae: 0.007475, mean_q: 0.012174
 61664/100000: episode: 8114, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000523, mae: 0.009509, mean_q: 0.018532
 61667/100000: episode: 8115, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000743, mae: 0.010480, mean_q: 0.016516
 61670/100000: episode: 8116, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000116, mae: 0.007763, mean_q: 0.011738
 61673/100000: episode: 8117, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000865, mae: 0.014320, mean_q: 0.024232
 61677/100000: episode: 8118, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000261, mae: 0.009187, mean_q: 0.013561
 61680/100000: episode: 8119, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001497, mae: 0.018914, mean_q: 0.030695
 61683/100000: episode: 8120, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000320, mae: 0.011231, mean_q: 0.019323
 61686/100000: episode: 8121, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000082, mae: 0.007341, mean_q: 0.012909
 61689/100000: episode: 8122, duration: 0.019s, episode steps: 3, steps per second: 156, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000757, mae: 0.010576, mean_q: 0.018019
 61693/100000: episode: 8123, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000598, mae: 0.011360, mean_q: 0.023132
 61696/100000: episode: 8124, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000245, mae: 0.009400, mean_q: 0.018363
 61699/100000: episode: 8125, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000086, mae: 0.005932, mean_q: 0.011768
 61705/100000: episode: 8126, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001096, mae: 0.014749, mean_q: 0.028495
 61708/100000: episode: 8127, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000168, mae: 0.007952, mean_q: 0.016311
 61711/100000: episode: 8128, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001238, mae: 0.013790, mean_q: 0.026596
 61714/100000: episode: 8129, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000162, mae: 0.007176, mean_q: 0.020406
 61720/100000: episode: 8130, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000816, mae: 0.012958, mean_q: 0.014232
 61724/100000: episode: 8131, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000100, mae: 0.007544, mean_q: 0.002903
 61727/100000: episode: 8132, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000070, mae: 0.005458, mean_q: 0.005702
 61730/100000: episode: 8133, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000131, mae: 0.008588, mean_q: 0.010459
 61736/100000: episode: 8134, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000260, mae: 0.011192, mean_q: 0.016823
 61739/100000: episode: 8135, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000594, mae: 0.012496, mean_q: 0.016666
 61742/100000: episode: 8136, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000634, mae: 0.011312, mean_q: 0.018043
 61745/100000: episode: 8137, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000070, mae: 0.007225, mean_q: 0.013338
 61751/100000: episode: 8138, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000544, mae: 0.011492, mean_q: 0.018461
 61754/100000: episode: 8139, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000164, mae: 0.008994, mean_q: 0.016145
 61758/100000: episode: 8140, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000116, mae: 0.007260, mean_q: 0.011764
 61761/100000: episode: 8141, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000302, mae: 0.007907, mean_q: 0.012958
 61764/100000: episode: 8142, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000721, mae: 0.010461, mean_q: 0.018820
 61767/100000: episode: 8143, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001073, mae: 0.013305, mean_q: 0.023505
 61770/100000: episode: 8144, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000602, mae: 0.009398, mean_q: 0.013119
 61773/100000: episode: 8145, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000325, mae: 0.008847, mean_q: 0.012592
 61776/100000: episode: 8146, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000115, mae: 0.007614, mean_q: 0.012004
 61780/100000: episode: 8147, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000393, mae: 0.009218, mean_q: 0.015571
 61786/100000: episode: 8148, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000249, mae: 0.007493, mean_q: 0.014310
 61792/100000: episode: 8149, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001079, mae: 0.011681, mean_q: 0.020941
 61798/100000: episode: 8150, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000217, mae: 0.007241, mean_q: 0.012583
 61801/100000: episode: 8151, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001017, mae: 0.011616, mean_q: 0.016820
 61804/100000: episode: 8152, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000993, mae: 0.011883, mean_q: 0.017912
 61807/100000: episode: 8153, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000086, mae: 0.007390, mean_q: 0.013864
 61810/100000: episode: 8154, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000712, mae: 0.011271, mean_q: 0.019747
 61813/100000: episode: 8155, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000095, mae: 0.006989, mean_q: 0.014128
 61816/100000: episode: 8156, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000041, mae: 0.005058, mean_q: 0.009742
[Info] 2-TH LEVEL FOUND: 0.1137155219912529, Considering 13/100 traces
 61819/100000: episode: 8157, duration: 0.653s, episode steps: 3, steps per second: 5, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000066, mae: 0.005731, mean_q: 0.011557
 61824/100000: episode: 8158, duration: 0.029s, episode steps: 5, steps per second: 171, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000096, mae: 0.006575, mean_q: 0.013678
 61829/100000: episode: 8159, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001031, mae: 0.013008, mean_q: 0.021305
 61834/100000: episode: 8160, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000741, mae: 0.010060, mean_q: 0.012197
 61839/100000: episode: 8161, duration: 0.028s, episode steps: 5, steps per second: 182, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000447, mae: 0.009058, mean_q: 0.015047
 61844/100000: episode: 8162, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003477, mae: 0.015771, mean_q: 0.016691
 61849/100000: episode: 8163, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000219, mae: 0.009960, mean_q: 0.015839
 61854/100000: episode: 8164, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000215, mae: 0.009965, mean_q: 0.016278
 61859/100000: episode: 8165, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000798, mae: 0.013081, mean_q: 0.018175
[Info] FALSIFICATION!
 61863/100000: episode: 8166, duration: 0.183s, episode steps: 4, steps per second: 22, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000634, mae: 0.010080, mean_q: 0.016246
 61868/100000: episode: 8167, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000106, mae: 0.008151, mean_q: 0.015552
 61873/100000: episode: 8168, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001380, mae: 0.015362, mean_q: 0.026371
 61878/100000: episode: 8169, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000166, mae: 0.007737, mean_q: 0.015691
 61883/100000: episode: 8170, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000325, mae: 0.007409, mean_q: 0.017514
 61888/100000: episode: 8171, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000053, mae: 0.005308, mean_q: 0.011517
 61893/100000: episode: 8172, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000188, mae: 0.008083, mean_q: 0.014713
 61898/100000: episode: 8173, duration: 0.029s, episode steps: 5, steps per second: 171, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000152, mae: 0.007959, mean_q: 0.014834
 61903/100000: episode: 8174, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000196, mae: 0.007644, mean_q: 0.021326
 61908/100000: episode: 8175, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000620, mae: 0.009686, mean_q: 0.013654
 61913/100000: episode: 8176, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000224, mae: 0.008195, mean_q: 0.009189
 61918/100000: episode: 8177, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000318, mae: 0.009463, mean_q: 0.010789
 61923/100000: episode: 8178, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000166, mae: 0.007763, mean_q: 0.015864
 61928/100000: episode: 8179, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000275, mae: 0.009340, mean_q: 0.021005
 61933/100000: episode: 8180, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000552, mae: 0.011306, mean_q: 0.022660
 61938/100000: episode: 8181, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000095, mae: 0.006547, mean_q: 0.012748
 61943/100000: episode: 8182, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000191, mae: 0.006742, mean_q: 0.010352
[Info] FALSIFICATION!
 61947/100000: episode: 8183, duration: 0.264s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000218, mae: 0.008944, mean_q: 0.011786
 61952/100000: episode: 8184, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000152, mae: 0.007310, mean_q: 0.012487
 61957/100000: episode: 8185, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000096, mae: 0.007602, mean_q: 0.014974
 61962/100000: episode: 8186, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000111, mae: 0.006850, mean_q: 0.011625
 61967/100000: episode: 8187, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000518, mae: 0.010795, mean_q: 0.018035
 61972/100000: episode: 8188, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000466, mae: 0.009183, mean_q: 0.014276
 61977/100000: episode: 8189, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000708, mae: 0.010459, mean_q: 0.017601
 61982/100000: episode: 8190, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000711, mae: 0.009528, mean_q: 0.015627
 61987/100000: episode: 8191, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000549, mae: 0.010160, mean_q: 0.019072
 61992/100000: episode: 8192, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000181, mae: 0.009225, mean_q: 0.015587
 61997/100000: episode: 8193, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000628, mae: 0.012819, mean_q: 0.022714
 62002/100000: episode: 8194, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000386, mae: 0.011615, mean_q: 0.020616
 62007/100000: episode: 8195, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000739, mae: 0.013524, mean_q: 0.027399
 62012/100000: episode: 8196, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000656, mae: 0.010483, mean_q: 0.017173
 62017/100000: episode: 8197, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000368, mae: 0.011757, mean_q: 0.016068
 62022/100000: episode: 8198, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001295, mae: 0.016506, mean_q: 0.019000
 62027/100000: episode: 8199, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000517, mae: 0.011528, mean_q: 0.020470
 62032/100000: episode: 8200, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000358, mae: 0.011453, mean_q: 0.020457
 62037/100000: episode: 8201, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000114, mae: 0.006919, mean_q: 0.012584
 62042/100000: episode: 8202, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000095, mae: 0.006129, mean_q: 0.010234
 62047/100000: episode: 8203, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000530, mae: 0.009040, mean_q: 0.014658
 62052/100000: episode: 8204, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000395, mae: 0.010764, mean_q: 0.019170
 62057/100000: episode: 8205, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000558, mae: 0.010848, mean_q: 0.021787
 62062/100000: episode: 8206, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001994, mae: 0.014594, mean_q: 0.019470
 62067/100000: episode: 8207, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000510, mae: 0.010654, mean_q: 0.018715
 62072/100000: episode: 8208, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000390, mae: 0.011991, mean_q: 0.021579
[Info] FALSIFICATION!
 62076/100000: episode: 8209, duration: 0.180s, episode steps: 4, steps per second: 22, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000323, mae: 0.011756, mean_q: 0.020930
 62081/100000: episode: 8210, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000385, mae: 0.007891, mean_q: 0.013642
 62086/100000: episode: 8211, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000542, mae: 0.012280, mean_q: 0.021488
 62091/100000: episode: 8212, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000087, mae: 0.005143, mean_q: 0.010950
 62096/100000: episode: 8213, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000320, mae: 0.009700, mean_q: 0.020102
 62101/100000: episode: 8214, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000251, mae: 0.009764, mean_q: 0.020627
 62106/100000: episode: 8215, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001328, mae: 0.013162, mean_q: 0.023528
 62111/100000: episode: 8216, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000488, mae: 0.009470, mean_q: 0.022486
 62116/100000: episode: 8217, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000607, mae: 0.009123, mean_q: 0.017265
 62121/100000: episode: 8218, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000829, mae: 0.013957, mean_q: 0.029004
 62126/100000: episode: 8219, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000792, mae: 0.012387, mean_q: 0.022475
 62131/100000: episode: 8220, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000289, mae: 0.007157, mean_q: 0.015567
 62136/100000: episode: 8221, duration: 0.029s, episode steps: 5, steps per second: 174, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000271, mae: 0.009868, mean_q: 0.016202
 62141/100000: episode: 8222, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000402, mae: 0.012667, mean_q: 0.020936
 62146/100000: episode: 8223, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000225, mae: 0.008702, mean_q: 0.014274
 62151/100000: episode: 8224, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000471, mae: 0.010938, mean_q: 0.020860
 62156/100000: episode: 8225, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001619, mae: 0.019439, mean_q: 0.035310
 62161/100000: episode: 8226, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000382, mae: 0.010288, mean_q: 0.015912
[Info] FALSIFICATION!
 62165/100000: episode: 8227, duration: 0.280s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000081, mae: 0.005513, mean_q: 0.008481
 62170/100000: episode: 8228, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000321, mae: 0.009850, mean_q: 0.014449
 62175/100000: episode: 8229, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000405, mae: 0.010137, mean_q: 0.018218
 62180/100000: episode: 8230, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000739, mae: 0.012428, mean_q: 0.026331
 62185/100000: episode: 8231, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001023, mae: 0.015797, mean_q: 0.023332
 62190/100000: episode: 8232, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000439, mae: 0.010642, mean_q: 0.015577
 62195/100000: episode: 8233, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000756, mae: 0.011007, mean_q: 0.017638
 62200/100000: episode: 8234, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000798, mae: 0.014350, mean_q: 0.021936
 62205/100000: episode: 8235, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000392, mae: 0.011699, mean_q: 0.023733
 62210/100000: episode: 8236, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000518, mae: 0.011082, mean_q: 0.017981
 62215/100000: episode: 8237, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000203, mae: 0.008663, mean_q: 0.013482
 62220/100000: episode: 8238, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000841, mae: 0.011914, mean_q: 0.013862
 62225/100000: episode: 8239, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000732, mae: 0.011545, mean_q: 0.022555
 62230/100000: episode: 8240, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000348, mae: 0.010645, mean_q: 0.023206
 62235/100000: episode: 8241, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002036, mae: 0.017212, mean_q: 0.026523
 62240/100000: episode: 8242, duration: 0.031s, episode steps: 5, steps per second: 163, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001819, mae: 0.019106, mean_q: 0.029733
 62245/100000: episode: 8243, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000105, mae: 0.007406, mean_q: 0.016272
[Info] Complete ISplit Iteration
[Info] Levels: [0.017429896, 0.11371552, 1.1073681]
[Info] Cond. Prob: [0.16, 0.13, 0.04]
[Info] Error Prob: 0.0008320000000000002

 62250/100000: episode: 8244, duration: 0.991s, episode steps: 5, steps per second: 5, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000607, mae: 0.013189, mean_q: 0.022219
 62260/100000: episode: 8245, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000265, mae: 0.007758, mean_q: 0.018666
 62270/100000: episode: 8246, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000642, mae: 0.010901, mean_q: 0.019576
 62280/100000: episode: 8247, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000700, mae: 0.012020, mean_q: 0.017978
 62290/100000: episode: 8248, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000552, mae: 0.011821, mean_q: 0.025602
 62300/100000: episode: 8249, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000577, mae: 0.009433, mean_q: 0.015903
 62310/100000: episode: 8250, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000806, mae: 0.012842, mean_q: 0.024366
 62320/100000: episode: 8251, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001621, mae: 0.015307, mean_q: 0.024169
 62330/100000: episode: 8252, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000495, mae: 0.012568, mean_q: 0.025354
 62340/100000: episode: 8253, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000444, mae: 0.011409, mean_q: 0.015748
 62350/100000: episode: 8254, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000316, mae: 0.008336, mean_q: 0.018290
 62360/100000: episode: 8255, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001031, mae: 0.011259, mean_q: 0.016177
 62370/100000: episode: 8256, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000668, mae: 0.013312, mean_q: 0.023868
 62380/100000: episode: 8257, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000862, mae: 0.014316, mean_q: 0.028815
 62390/100000: episode: 8258, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000175, mae: 0.007514, mean_q: 0.019739
 62400/100000: episode: 8259, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001177, mae: 0.016765, mean_q: 0.029563
 62410/100000: episode: 8260, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000484, mae: 0.011209, mean_q: 0.018437
 62420/100000: episode: 8261, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000278, mae: 0.009228, mean_q: 0.022430
 62430/100000: episode: 8262, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000407, mae: 0.008392, mean_q: 0.014192
 62440/100000: episode: 8263, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000651, mae: 0.012630, mean_q: 0.021487
 62450/100000: episode: 8264, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000769, mae: 0.013161, mean_q: 0.025257
 62460/100000: episode: 8265, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000605, mae: 0.010630, mean_q: 0.016189
 62470/100000: episode: 8266, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000905, mae: 0.013801, mean_q: 0.022558
 62480/100000: episode: 8267, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000537, mae: 0.011832, mean_q: 0.019582
 62490/100000: episode: 8268, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000705, mae: 0.011682, mean_q: 0.019447
 62500/100000: episode: 8269, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000783, mae: 0.013554, mean_q: 0.022951
 62510/100000: episode: 8270, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000747, mae: 0.014394, mean_q: 0.030123
 62520/100000: episode: 8271, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000489, mae: 0.010098, mean_q: 0.023281
 62530/100000: episode: 8272, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000430, mae: 0.009659, mean_q: 0.014886
 62540/100000: episode: 8273, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000267, mae: 0.009783, mean_q: 0.012991
 62550/100000: episode: 8274, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000454, mae: 0.012487, mean_q: 0.021235
 62560/100000: episode: 8275, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000310, mae: 0.010896, mean_q: 0.019789
 62570/100000: episode: 8276, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000507, mae: 0.011706, mean_q: 0.019236
 62580/100000: episode: 8277, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000659, mae: 0.011330, mean_q: 0.020296
 62590/100000: episode: 8278, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000324, mae: 0.009635, mean_q: 0.018177
 62600/100000: episode: 8279, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000377, mae: 0.009373, mean_q: 0.020747
 62610/100000: episode: 8280, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000502, mae: 0.010802, mean_q: 0.017577
 62620/100000: episode: 8281, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000533, mae: 0.010510, mean_q: 0.016415
 62630/100000: episode: 8282, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000222, mae: 0.010809, mean_q: 0.021698
 62640/100000: episode: 8283, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000150, mae: 0.007052, mean_q: 0.014425
 62650/100000: episode: 8284, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000553, mae: 0.011516, mean_q: 0.019867
 62660/100000: episode: 8285, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000186, mae: 0.008377, mean_q: 0.018576
 62670/100000: episode: 8286, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000463, mae: 0.009831, mean_q: 0.020157
 62680/100000: episode: 8287, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000455, mae: 0.009214, mean_q: 0.018437
 62690/100000: episode: 8288, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000406, mae: 0.010665, mean_q: 0.022808
 62700/100000: episode: 8289, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000822, mae: 0.012360, mean_q: 0.022379
 62710/100000: episode: 8290, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000900, mae: 0.013322, mean_q: 0.020215
 62720/100000: episode: 8291, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001032, mae: 0.012606, mean_q: 0.018510
 62730/100000: episode: 8292, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000603, mae: 0.012003, mean_q: 0.024816
 62740/100000: episode: 8293, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000382, mae: 0.010609, mean_q: 0.021175
 62750/100000: episode: 8294, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000737, mae: 0.011385, mean_q: 0.022436
 62760/100000: episode: 8295, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000753, mae: 0.012253, mean_q: 0.017100
 62770/100000: episode: 8296, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000531, mae: 0.010664, mean_q: 0.018962
 62780/100000: episode: 8297, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000704, mae: 0.014272, mean_q: 0.026901
 62790/100000: episode: 8298, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000521, mae: 0.012086, mean_q: 0.024068
 62800/100000: episode: 8299, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000428, mae: 0.011391, mean_q: 0.019249
 62810/100000: episode: 8300, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000254, mae: 0.009719, mean_q: 0.018697
 62820/100000: episode: 8301, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000359, mae: 0.008937, mean_q: 0.016183
 62830/100000: episode: 8302, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000481, mae: 0.009781, mean_q: 0.014333
 62840/100000: episode: 8303, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000684, mae: 0.012170, mean_q: 0.022665
 62850/100000: episode: 8304, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000456, mae: 0.011686, mean_q: 0.021179
 62860/100000: episode: 8305, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000792, mae: 0.013783, mean_q: 0.021454
 62870/100000: episode: 8306, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000641, mae: 0.011224, mean_q: 0.018596
 62880/100000: episode: 8307, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000299, mae: 0.011143, mean_q: 0.025437
 62890/100000: episode: 8308, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000448, mae: 0.008339, mean_q: 0.014036
 62900/100000: episode: 8309, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000615, mae: 0.012723, mean_q: 0.023707
 62910/100000: episode: 8310, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000464, mae: 0.011069, mean_q: 0.022467
 62920/100000: episode: 8311, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000486, mae: 0.009510, mean_q: 0.014580
 62930/100000: episode: 8312, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001195, mae: 0.016647, mean_q: 0.026502
 62940/100000: episode: 8313, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001044, mae: 0.018210, mean_q: 0.033498
 62950/100000: episode: 8314, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000272, mae: 0.009394, mean_q: 0.015538
 62960/100000: episode: 8315, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000447, mae: 0.009730, mean_q: 0.016023
 62970/100000: episode: 8316, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000594, mae: 0.011229, mean_q: 0.018876
 62980/100000: episode: 8317, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000790, mae: 0.011755, mean_q: 0.022082
 62990/100000: episode: 8318, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000461, mae: 0.010290, mean_q: 0.022389
 63000/100000: episode: 8319, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000670, mae: 0.010948, mean_q: 0.016068
 63010/100000: episode: 8320, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000749, mae: 0.011321, mean_q: 0.021310
 63020/100000: episode: 8321, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001012, mae: 0.011695, mean_q: 0.021591
 63030/100000: episode: 8322, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000613, mae: 0.012009, mean_q: 0.020002
 63040/100000: episode: 8323, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000507, mae: 0.011563, mean_q: 0.022518
 63050/100000: episode: 8324, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000947, mae: 0.012126, mean_q: 0.019447
 63060/100000: episode: 8325, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000539, mae: 0.011434, mean_q: 0.019777
 63070/100000: episode: 8326, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000291, mae: 0.009454, mean_q: 0.016911
 63080/100000: episode: 8327, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000547, mae: 0.011901, mean_q: 0.021349
 63090/100000: episode: 8328, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000581, mae: 0.010150, mean_q: 0.021384
 63100/100000: episode: 8329, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000537, mae: 0.012181, mean_q: 0.021544
 63110/100000: episode: 8330, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000495, mae: 0.010429, mean_q: 0.016656
 63120/100000: episode: 8331, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000743, mae: 0.012747, mean_q: 0.022592
 63130/100000: episode: 8332, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000610, mae: 0.012541, mean_q: 0.020540
 63140/100000: episode: 8333, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000973, mae: 0.013824, mean_q: 0.020019
 63150/100000: episode: 8334, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000261, mae: 0.010743, mean_q: 0.019030
 63160/100000: episode: 8335, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000170, mae: 0.008956, mean_q: 0.017074
 63170/100000: episode: 8336, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000678, mae: 0.012819, mean_q: 0.029770
 63180/100000: episode: 8337, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000511, mae: 0.011091, mean_q: 0.023998
 63190/100000: episode: 8338, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000353, mae: 0.009631, mean_q: 0.021315
 63200/100000: episode: 8339, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000636, mae: 0.010551, mean_q: 0.017867
 63210/100000: episode: 8340, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000652, mae: 0.011972, mean_q: 0.020929
 63220/100000: episode: 8341, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000789, mae: 0.012051, mean_q: 0.021896
 63230/100000: episode: 8342, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000975, mae: 0.013707, mean_q: 0.023216
 63240/100000: episode: 8343, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001499, mae: 0.016380, mean_q: 0.026371
[Info] 1-TH LEVEL FOUND: 0.0484372042119503, Considering 10/100 traces
 63250/100000: episode: 8344, duration: 0.720s, episode steps: 10, steps per second: 14, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000438, mae: 0.013382, mean_q: 0.015368
 63256/100000: episode: 8345, duration: 0.032s, episode steps: 6, steps per second: 190, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000868, mae: 0.013659, mean_q: 0.014028
 63260/100000: episode: 8346, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000132, mae: 0.009393, mean_q: 0.018146
 63264/100000: episode: 8347, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001281, mae: 0.015667, mean_q: 0.022106
 63270/100000: episode: 8348, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000298, mae: 0.011149, mean_q: 0.015752
 63276/100000: episode: 8349, duration: 0.033s, episode steps: 6, steps per second: 181, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001209, mae: 0.013754, mean_q: 0.020122
 63282/100000: episode: 8350, duration: 0.033s, episode steps: 6, steps per second: 183, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000469, mae: 0.009365, mean_q: 0.017732
 63288/100000: episode: 8351, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000450, mae: 0.011097, mean_q: 0.017557
 63294/100000: episode: 8352, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000383, mae: 0.009990, mean_q: 0.016236
 63298/100000: episode: 8353, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000519, mae: 0.010941, mean_q: 0.015644
[Info] FALSIFICATION!
 63303/100000: episode: 8354, duration: 0.266s, episode steps: 5, steps per second: 19, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000644, mae: 0.010081, mean_q: 0.018980
 63309/100000: episode: 8355, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000309, mae: 0.009215, mean_q: 0.019002
 63315/100000: episode: 8356, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000825, mae: 0.013545, mean_q: 0.026403
 63321/100000: episode: 8357, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000315, mae: 0.007843, mean_q: 0.013147
 63327/100000: episode: 8358, duration: 0.032s, episode steps: 6, steps per second: 187, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000667, mae: 0.010261, mean_q: 0.015234
 63331/100000: episode: 8359, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000381, mae: 0.011303, mean_q: 0.018449
 63337/100000: episode: 8360, duration: 0.035s, episode steps: 6, steps per second: 174, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000235, mae: 0.009143, mean_q: 0.020242
 63343/100000: episode: 8361, duration: 0.033s, episode steps: 6, steps per second: 185, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000698, mae: 0.014370, mean_q: 0.027919
 63349/100000: episode: 8362, duration: 0.035s, episode steps: 6, steps per second: 170, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000987, mae: 0.013458, mean_q: 0.028964
 63353/100000: episode: 8363, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000203, mae: 0.008878, mean_q: 0.019646
 63359/100000: episode: 8364, duration: 0.033s, episode steps: 6, steps per second: 181, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001180, mae: 0.013779, mean_q: 0.029198
[Info] FALSIFICATION!
 63364/100000: episode: 8365, duration: 0.286s, episode steps: 5, steps per second: 18, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.001120, mae: 0.011570, mean_q: 0.024449
 63368/100000: episode: 8366, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000456, mae: 0.010246, mean_q: 0.022419
 63374/100000: episode: 8367, duration: 0.036s, episode steps: 6, steps per second: 169, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000660, mae: 0.012142, mean_q: 0.019899
 63378/100000: episode: 8368, duration: 0.024s, episode steps: 4, steps per second: 166, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000389, mae: 0.008498, mean_q: 0.013455
 63384/100000: episode: 8369, duration: 0.037s, episode steps: 6, steps per second: 160, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000901, mae: 0.012300, mean_q: 0.020354
 63390/100000: episode: 8370, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000682, mae: 0.013155, mean_q: 0.025331
 63394/100000: episode: 8371, duration: 0.026s, episode steps: 4, steps per second: 154, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000164, mae: 0.008619, mean_q: 0.013652
 63398/100000: episode: 8372, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000297, mae: 0.007919, mean_q: 0.013343
 63402/100000: episode: 8373, duration: 0.025s, episode steps: 4, steps per second: 163, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000072, mae: 0.005207, mean_q: 0.009046
 63406/100000: episode: 8374, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000544, mae: 0.009594, mean_q: 0.014329
 63412/100000: episode: 8375, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000833, mae: 0.010138, mean_q: 0.014484
 63418/100000: episode: 8376, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.001277, mae: 0.015140, mean_q: 0.023025
 63424/100000: episode: 8377, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000287, mae: 0.011881, mean_q: 0.025799
 63430/100000: episode: 8378, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000528, mae: 0.011989, mean_q: 0.021281
 63436/100000: episode: 8379, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000619, mae: 0.009330, mean_q: 0.015379
 63440/100000: episode: 8380, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000088, mae: 0.007173, mean_q: 0.010059
 63446/100000: episode: 8381, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000347, mae: 0.008739, mean_q: 0.010787
 63452/100000: episode: 8382, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000832, mae: 0.010356, mean_q: 0.015424
 63458/100000: episode: 8383, duration: 0.032s, episode steps: 6, steps per second: 185, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000230, mae: 0.011167, mean_q: 0.020070
 63462/100000: episode: 8384, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000531, mae: 0.013210, mean_q: 0.025074
 63468/100000: episode: 8385, duration: 0.031s, episode steps: 6, steps per second: 192, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000951, mae: 0.014504, mean_q: 0.026224
 63474/100000: episode: 8386, duration: 0.032s, episode steps: 6, steps per second: 187, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000374, mae: 0.007168, mean_q: 0.011441
 63480/100000: episode: 8387, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000934, mae: 0.011907, mean_q: 0.017706
 63484/100000: episode: 8388, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000097, mae: 0.006413, mean_q: 0.011434
 63488/100000: episode: 8389, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000222, mae: 0.007772, mean_q: 0.015052
 63492/100000: episode: 8390, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000100, mae: 0.007834, mean_q: 0.016897
 63496/100000: episode: 8391, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000863, mae: 0.013271, mean_q: 0.023624
 63502/100000: episode: 8392, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000820, mae: 0.012478, mean_q: 0.023788
 63508/100000: episode: 8393, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000989, mae: 0.014721, mean_q: 0.022748
 63512/100000: episode: 8394, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000277, mae: 0.008888, mean_q: 0.015594
 63518/100000: episode: 8395, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000869, mae: 0.014093, mean_q: 0.024596
 63524/100000: episode: 8396, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000338, mae: 0.008404, mean_q: 0.016603
 63530/100000: episode: 8397, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000517, mae: 0.009589, mean_q: 0.014761
 63536/100000: episode: 8398, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000624, mae: 0.010206, mean_q: 0.013346
 63542/100000: episode: 8399, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000897, mae: 0.012990, mean_q: 0.023017
 63546/100000: episode: 8400, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000472, mae: 0.009506, mean_q: 0.017409
 63550/100000: episode: 8401, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000788, mae: 0.012264, mean_q: 0.025874
 63554/100000: episode: 8402, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000636, mae: 0.009907, mean_q: 0.018013
 63558/100000: episode: 8403, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000538, mae: 0.009905, mean_q: 0.017012
 63562/100000: episode: 8404, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000972, mae: 0.013336, mean_q: 0.029419
 63568/100000: episode: 8405, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001045, mae: 0.015594, mean_q: 0.028590
 63574/100000: episode: 8406, duration: 0.031s, episode steps: 6, steps per second: 197, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000612, mae: 0.011972, mean_q: 0.012486
 63578/100000: episode: 8407, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000685, mae: 0.011888, mean_q: 0.012790
 63582/100000: episode: 8408, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000157, mae: 0.009207, mean_q: 0.016116
 63588/100000: episode: 8409, duration: 0.035s, episode steps: 6, steps per second: 170, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000249, mae: 0.009439, mean_q: 0.016469
 63592/100000: episode: 8410, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000447, mae: 0.015130, mean_q: 0.028530
 63598/100000: episode: 8411, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000646, mae: 0.010971, mean_q: 0.019994
 63604/100000: episode: 8412, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001517, mae: 0.015958, mean_q: 0.020024
 63610/100000: episode: 8413, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000889, mae: 0.013645, mean_q: 0.021567
 63614/100000: episode: 8414, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000881, mae: 0.017026, mean_q: 0.034135
 63620/100000: episode: 8415, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000375, mae: 0.010619, mean_q: 0.022012
 63626/100000: episode: 8416, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000291, mae: 0.008996, mean_q: 0.015219
 63630/100000: episode: 8417, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000735, mae: 0.014479, mean_q: 0.022444
 63634/100000: episode: 8418, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000733, mae: 0.013340, mean_q: 0.027041
 63640/100000: episode: 8419, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000517, mae: 0.010281, mean_q: 0.016744
 63646/100000: episode: 8420, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000641, mae: 0.012746, mean_q: 0.021388
 63652/100000: episode: 8421, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000590, mae: 0.011503, mean_q: 0.023437
[Info] FALSIFICATION!
 63657/100000: episode: 8422, duration: 0.270s, episode steps: 5, steps per second: 18, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.001069, mae: 0.016560, mean_q: 0.027762
 63661/100000: episode: 8423, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000843, mae: 0.011247, mean_q: 0.019654
 63667/100000: episode: 8424, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000643, mae: 0.014418, mean_q: 0.024415
 63673/100000: episode: 8425, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000699, mae: 0.014120, mean_q: 0.027265
 63679/100000: episode: 8426, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000618, mae: 0.012993, mean_q: 0.017263
 63683/100000: episode: 8427, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000197, mae: 0.011211, mean_q: 0.012772
 63689/100000: episode: 8428, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000184, mae: 0.008360, mean_q: 0.012201
 63695/100000: episode: 8429, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000399, mae: 0.010653, mean_q: 0.019660
 63701/100000: episode: 8430, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000660, mae: 0.012120, mean_q: 0.019919
 63707/100000: episode: 8431, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000494, mae: 0.011246, mean_q: 0.024072
 63713/100000: episode: 8432, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000561, mae: 0.013328, mean_q: 0.024741
 63719/100000: episode: 8433, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000660, mae: 0.012272, mean_q: 0.024344
[Info] Complete ISplit Iteration
[Info] Levels: [0.048437204, 1.1732097]
[Info] Cond. Prob: [0.1, 0.03]
[Info] Error Prob: 0.003

 63725/100000: episode: 8434, duration: 0.849s, episode steps: 6, steps per second: 7, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000726, mae: 0.013103, mean_q: 0.024187
 63735/100000: episode: 8435, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000470, mae: 0.010233, mean_q: 0.020226
 63745/100000: episode: 8436, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000310, mae: 0.009353, mean_q: 0.016933
 63755/100000: episode: 8437, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000853, mae: 0.012718, mean_q: 0.022819
 63765/100000: episode: 8438, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000840, mae: 0.013536, mean_q: 0.024265
 63775/100000: episode: 8439, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000400, mae: 0.009086, mean_q: 0.018470
 63785/100000: episode: 8440, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001171, mae: 0.016471, mean_q: 0.031388
 63795/100000: episode: 8441, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001019, mae: 0.015273, mean_q: 0.024412
 63805/100000: episode: 8442, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000547, mae: 0.014035, mean_q: 0.023888
 63815/100000: episode: 8443, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000462, mae: 0.011967, mean_q: 0.020399
 63825/100000: episode: 8444, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000703, mae: 0.012552, mean_q: 0.022237
 63835/100000: episode: 8445, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000301, mae: 0.010768, mean_q: 0.019891
 63845/100000: episode: 8446, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000966, mae: 0.015212, mean_q: 0.027411
 63855/100000: episode: 8447, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000858, mae: 0.014002, mean_q: 0.028629
 63865/100000: episode: 8448, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000227, mae: 0.009584, mean_q: 0.018813
 63875/100000: episode: 8449, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000559, mae: 0.013344, mean_q: 0.027873
 63885/100000: episode: 8450, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000872, mae: 0.013473, mean_q: 0.023424
 63895/100000: episode: 8451, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000581, mae: 0.011029, mean_q: 0.016667
 63905/100000: episode: 8452, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000851, mae: 0.014542, mean_q: 0.027818
 63915/100000: episode: 8453, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001097, mae: 0.015113, mean_q: 0.024787
 63925/100000: episode: 8454, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001000, mae: 0.014337, mean_q: 0.024347
 63935/100000: episode: 8455, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000985, mae: 0.013554, mean_q: 0.025084
 63945/100000: episode: 8456, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000732, mae: 0.014040, mean_q: 0.029502
 63955/100000: episode: 8457, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000584, mae: 0.010977, mean_q: 0.022566
 63965/100000: episode: 8458, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000556, mae: 0.011534, mean_q: 0.021264
 63975/100000: episode: 8459, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000544, mae: 0.010876, mean_q: 0.014050
 63985/100000: episode: 8460, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000841, mae: 0.014191, mean_q: 0.025643
 63995/100000: episode: 8461, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000675, mae: 0.010075, mean_q: 0.015606
 64005/100000: episode: 8462, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000750, mae: 0.012198, mean_q: 0.015089
 64015/100000: episode: 8463, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000606, mae: 0.014279, mean_q: 0.025994
 64025/100000: episode: 8464, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000917, mae: 0.016142, mean_q: 0.026401
 64035/100000: episode: 8465, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001040, mae: 0.017367, mean_q: 0.029999
 64045/100000: episode: 8466, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000364, mae: 0.007614, mean_q: 0.015053
 64055/100000: episode: 8467, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000303, mae: 0.008938, mean_q: 0.017864
 64065/100000: episode: 8468, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000632, mae: 0.011695, mean_q: 0.023774
 64075/100000: episode: 8469, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000612, mae: 0.011199, mean_q: 0.018994
 64085/100000: episode: 8470, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000595, mae: 0.012311, mean_q: 0.023217
 64095/100000: episode: 8471, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000764, mae: 0.012124, mean_q: 0.022180
 64105/100000: episode: 8472, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000400, mae: 0.009908, mean_q: 0.019311
 64115/100000: episode: 8473, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001064, mae: 0.015579, mean_q: 0.028668
 64125/100000: episode: 8474, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000592, mae: 0.015299, mean_q: 0.029589
 64135/100000: episode: 8475, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001183, mae: 0.013715, mean_q: 0.023289
 64145/100000: episode: 8476, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000718, mae: 0.012853, mean_q: 0.027330
 64155/100000: episode: 8477, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000924, mae: 0.013794, mean_q: 0.028998
 64165/100000: episode: 8478, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000356, mae: 0.009237, mean_q: 0.018234
 64175/100000: episode: 8479, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001098, mae: 0.014286, mean_q: 0.030523
 64185/100000: episode: 8480, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000697, mae: 0.011889, mean_q: 0.020606
 64195/100000: episode: 8481, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000498, mae: 0.010062, mean_q: 0.013403
 64205/100000: episode: 8482, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000253, mae: 0.008225, mean_q: 0.012831
 64215/100000: episode: 8483, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000680, mae: 0.012761, mean_q: 0.024118
 64225/100000: episode: 8484, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000897, mae: 0.014930, mean_q: 0.027629
 64235/100000: episode: 8485, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001195, mae: 0.016380, mean_q: 0.031224
 64245/100000: episode: 8486, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000844, mae: 0.014620, mean_q: 0.018418
 64255/100000: episode: 8487, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000556, mae: 0.012464, mean_q: 0.022744
 64265/100000: episode: 8488, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001048, mae: 0.014124, mean_q: 0.031825
 64275/100000: episode: 8489, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000771, mae: 0.012841, mean_q: 0.021427
 64285/100000: episode: 8490, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000325, mae: 0.011737, mean_q: 0.010438
 64295/100000: episode: 8491, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001845, mae: 0.017623, mean_q: 0.026042
 64305/100000: episode: 8492, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000799, mae: 0.017350, mean_q: 0.030553
 64315/100000: episode: 8493, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000903, mae: 0.013055, mean_q: 0.022029
 64325/100000: episode: 8494, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001130, mae: 0.015800, mean_q: 0.025590
 64335/100000: episode: 8495, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000910, mae: 0.014851, mean_q: 0.024186
 64345/100000: episode: 8496, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000512, mae: 0.012150, mean_q: 0.022046
 64355/100000: episode: 8497, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000488, mae: 0.012526, mean_q: 0.022520
 64365/100000: episode: 8498, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000491, mae: 0.010679, mean_q: 0.017002
 64375/100000: episode: 8499, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000463, mae: 0.012204, mean_q: 0.024017
 64385/100000: episode: 8500, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000673, mae: 0.012988, mean_q: 0.023879
 64395/100000: episode: 8501, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000937, mae: 0.014365, mean_q: 0.023851
 64405/100000: episode: 8502, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001234, mae: 0.014264, mean_q: 0.024393
 64415/100000: episode: 8503, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000992, mae: 0.014785, mean_q: 0.027640
 64425/100000: episode: 8504, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000637, mae: 0.014175, mean_q: 0.026102
 64435/100000: episode: 8505, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000684, mae: 0.012190, mean_q: 0.018995
 64445/100000: episode: 8506, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000538, mae: 0.012404, mean_q: 0.020949
 64455/100000: episode: 8507, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000560, mae: 0.012203, mean_q: 0.022925
 64465/100000: episode: 8508, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000939, mae: 0.015282, mean_q: 0.025343
 64475/100000: episode: 8509, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000840, mae: 0.013961, mean_q: 0.023660
 64485/100000: episode: 8510, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000536, mae: 0.013104, mean_q: 0.027679
 64495/100000: episode: 8511, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000710, mae: 0.012624, mean_q: 0.022370
 64505/100000: episode: 8512, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000969, mae: 0.013655, mean_q: 0.025553
 64515/100000: episode: 8513, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000836, mae: 0.013575, mean_q: 0.022949
 64525/100000: episode: 8514, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000613, mae: 0.012142, mean_q: 0.018113
 64535/100000: episode: 8515, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001178, mae: 0.018528, mean_q: 0.034893
 64545/100000: episode: 8516, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000880, mae: 0.013973, mean_q: 0.024406
 64555/100000: episode: 8517, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000954, mae: 0.014552, mean_q: 0.027256
 64565/100000: episode: 8518, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000402, mae: 0.011722, mean_q: 0.021722
 64575/100000: episode: 8519, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000966, mae: 0.014758, mean_q: 0.026951
 64585/100000: episode: 8520, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000457, mae: 0.011625, mean_q: 0.019917
 64595/100000: episode: 8521, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000655, mae: 0.014237, mean_q: 0.027740
 64605/100000: episode: 8522, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000621, mae: 0.013873, mean_q: 0.025427
 64615/100000: episode: 8523, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000441, mae: 0.011536, mean_q: 0.021414
 64625/100000: episode: 8524, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001242, mae: 0.015175, mean_q: 0.027842
 64635/100000: episode: 8525, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001278, mae: 0.016779, mean_q: 0.029965
 64645/100000: episode: 8526, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000429, mae: 0.010986, mean_q: 0.021134
 64655/100000: episode: 8527, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001777, mae: 0.018483, mean_q: 0.030558
 64665/100000: episode: 8528, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000604, mae: 0.012333, mean_q: 0.024145
 64675/100000: episode: 8529, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000997, mae: 0.014091, mean_q: 0.032268
 64685/100000: episode: 8530, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000676, mae: 0.011503, mean_q: 0.019414
 64695/100000: episode: 8531, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000499, mae: 0.010760, mean_q: 0.021076
 64705/100000: episode: 8532, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000676, mae: 0.012236, mean_q: 0.023594
 64715/100000: episode: 8533, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000680, mae: 0.011547, mean_q: 0.019298
[Info] 1-TH LEVEL FOUND: 0.017406931146979332, Considering 14/100 traces
 64725/100000: episode: 8534, duration: 0.716s, episode steps: 10, steps per second: 14, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000735, mae: 0.012136, mean_q: 0.019103
 64728/100000: episode: 8535, duration: 0.020s, episode steps: 3, steps per second: 148, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.003234, mae: 0.022405, mean_q: 0.030343
 64731/100000: episode: 8536, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000490, mae: 0.011516, mean_q: 0.019285
 64734/100000: episode: 8537, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000997, mae: 0.018205, mean_q: 0.032462
 64737/100000: episode: 8538, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000758, mae: 0.015691, mean_q: 0.033384
 64740/100000: episode: 8539, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001566, mae: 0.016561, mean_q: 0.028903
 64743/100000: episode: 8540, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000603, mae: 0.013414, mean_q: 0.023200
 64746/100000: episode: 8541, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001005, mae: 0.015478, mean_q: 0.027662
 64752/100000: episode: 8542, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000244, mae: 0.009849, mean_q: 0.016058
 64755/100000: episode: 8543, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001270, mae: 0.017319, mean_q: 0.027702
 64758/100000: episode: 8544, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001002, mae: 0.015087, mean_q: 0.027532
 64761/100000: episode: 8545, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001253, mae: 0.016420, mean_q: 0.024370
 64765/100000: episode: 8546, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000665, mae: 0.011376, mean_q: 0.019615
 64768/100000: episode: 8547, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000945, mae: 0.016796, mean_q: 0.023662
 64774/100000: episode: 8548, duration: 0.033s, episode steps: 6, steps per second: 180, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000935, mae: 0.014034, mean_q: 0.027400
 64780/100000: episode: 8549, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000814, mae: 0.012543, mean_q: 0.023765
 64783/100000: episode: 8550, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000682, mae: 0.010436, mean_q: 0.015471
 64786/100000: episode: 8551, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001187, mae: 0.014443, mean_q: 0.023371
 64789/100000: episode: 8552, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000097, mae: 0.006090, mean_q: 0.009872
 64792/100000: episode: 8553, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000323, mae: 0.009135, mean_q: 0.014854
 64798/100000: episode: 8554, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000347, mae: 0.010328, mean_q: 0.017602
 64804/100000: episode: 8555, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001098, mae: 0.014781, mean_q: 0.025682
 64807/100000: episode: 8556, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000357, mae: 0.012583, mean_q: 0.023904
 64810/100000: episode: 8557, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000354, mae: 0.011739, mean_q: 0.022071
 64813/100000: episode: 8558, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000516, mae: 0.012531, mean_q: 0.022553
 64816/100000: episode: 8559, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000334, mae: 0.009391, mean_q: 0.016678
 64819/100000: episode: 8560, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001086, mae: 0.012273, mean_q: 0.023243
 64822/100000: episode: 8561, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001104, mae: 0.013392, mean_q: 0.023491
 64825/100000: episode: 8562, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001498, mae: 0.017645, mean_q: 0.031933
 64828/100000: episode: 8563, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000369, mae: 0.012307, mean_q: 0.019945
 64831/100000: episode: 8564, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000922, mae: 0.014428, mean_q: 0.024054
 64834/100000: episode: 8565, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000178, mae: 0.010093, mean_q: 0.024808
 64837/100000: episode: 8566, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000925, mae: 0.014651, mean_q: 0.024233
 64840/100000: episode: 8567, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000083, mae: 0.006916, mean_q: 0.008770
 64843/100000: episode: 8568, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000561, mae: 0.012768, mean_q: 0.021242
 64846/100000: episode: 8569, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001111, mae: 0.015275, mean_q: 0.016667
 64849/100000: episode: 8570, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000493, mae: 0.011488, mean_q: 0.018878
 64853/100000: episode: 8571, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000779, mae: 0.014423, mean_q: 0.022809
 64856/100000: episode: 8572, duration: 0.019s, episode steps: 3, steps per second: 156, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000346, mae: 0.012708, mean_q: 0.022845
 64862/100000: episode: 8573, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000309, mae: 0.010957, mean_q: 0.021133
 64865/100000: episode: 8574, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001044, mae: 0.013380, mean_q: 0.020490
 64868/100000: episode: 8575, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000173, mae: 0.009590, mean_q: 0.018980
 64874/100000: episode: 8576, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000133, mae: 0.007613, mean_q: 0.014095
 64877/100000: episode: 8577, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000958, mae: 0.016686, mean_q: 0.036441
 64883/100000: episode: 8578, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000669, mae: 0.012754, mean_q: 0.022769
 64889/100000: episode: 8579, duration: 0.032s, episode steps: 6, steps per second: 189, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000201, mae: 0.008911, mean_q: 0.015226
 64892/100000: episode: 8580, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000337, mae: 0.009456, mean_q: 0.014987
 64895/100000: episode: 8581, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001776, mae: 0.020156, mean_q: 0.031506
 64898/100000: episode: 8582, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000335, mae: 0.011521, mean_q: 0.018257
 64901/100000: episode: 8583, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000153, mae: 0.010162, mean_q: 0.017816
 64907/100000: episode: 8584, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000619, mae: 0.012520, mean_q: 0.029247
 64913/100000: episode: 8585, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000466, mae: 0.009933, mean_q: 0.024883
 64916/100000: episode: 8586, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000985, mae: 0.011742, mean_q: 0.017901
 64919/100000: episode: 8587, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000513, mae: 0.013353, mean_q: 0.027513
 64925/100000: episode: 8588, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000824, mae: 0.013477, mean_q: 0.027557
 64928/100000: episode: 8589, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000952, mae: 0.010587, mean_q: 0.021639
 64931/100000: episode: 8590, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000823, mae: 0.011683, mean_q: 0.034502
 64934/100000: episode: 8591, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000264, mae: 0.009750, mean_q: 0.022723
 64937/100000: episode: 8592, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000671, mae: 0.013209, mean_q: 0.021959
 64943/100000: episode: 8593, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000782, mae: 0.013531, mean_q: 0.016318
 64949/100000: episode: 8594, duration: 0.032s, episode steps: 6, steps per second: 186, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000792, mae: 0.013011, mean_q: 0.016829
 64952/100000: episode: 8595, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000084, mae: 0.007091, mean_q: 0.013303
 64958/100000: episode: 8596, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000341, mae: 0.011790, mean_q: 0.022204
 64962/100000: episode: 8597, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000110, mae: 0.008773, mean_q: 0.018314
 64966/100000: episode: 8598, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000653, mae: 0.011555, mean_q: 0.018964
 64969/100000: episode: 8599, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000928, mae: 0.015350, mean_q: 0.027084
 64972/100000: episode: 8600, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000565, mae: 0.013034, mean_q: 0.025478
 64975/100000: episode: 8601, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000333, mae: 0.009176, mean_q: 0.016080
 64978/100000: episode: 8602, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000590, mae: 0.010874, mean_q: 0.012913
 64981/100000: episode: 8603, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000399, mae: 0.007791, mean_q: 0.013343
 64984/100000: episode: 8604, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000784, mae: 0.010937, mean_q: 0.016675
 64987/100000: episode: 8605, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000998, mae: 0.012900, mean_q: 0.023359
 64990/100000: episode: 8606, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000370, mae: 0.008914, mean_q: 0.015435
 64993/100000: episode: 8607, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000875, mae: 0.013164, mean_q: 0.032612
 64996/100000: episode: 8608, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000757, mae: 0.015145, mean_q: 0.025393
 65000/100000: episode: 8609, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000164, mae: 0.008919, mean_q: 0.017447
 65003/100000: episode: 8610, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000186, mae: 0.010980, mean_q: 0.019944
 65009/100000: episode: 8611, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000563, mae: 0.013168, mean_q: 0.018250
 65015/100000: episode: 8612, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000624, mae: 0.011024, mean_q: 0.018403
 65018/100000: episode: 8613, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001487, mae: 0.017556, mean_q: 0.024813
 65024/100000: episode: 8614, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000370, mae: 0.009941, mean_q: 0.014901
 65027/100000: episode: 8615, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001317, mae: 0.013084, mean_q: 0.013493
 65030/100000: episode: 8616, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000099, mae: 0.006624, mean_q: 0.012193
 65033/100000: episode: 8617, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000537, mae: 0.013275, mean_q: 0.019470
 65039/100000: episode: 8618, duration: 0.032s, episode steps: 6, steps per second: 190, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000277, mae: 0.011551, mean_q: 0.019537
 65042/100000: episode: 8619, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000309, mae: 0.012020, mean_q: 0.028629
[Info] 2-TH LEVEL FOUND: 0.10247291624546051, Considering 14/100 traces
 65045/100000: episode: 8620, duration: 0.691s, episode steps: 3, steps per second: 4, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000147, mae: 0.007631, mean_q: 0.020007
 65048/100000: episode: 8621, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000573, mae: 0.013089, mean_q: 0.022249
 65051/100000: episode: 8622, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000362, mae: 0.012087, mean_q: 0.024950
 65056/100000: episode: 8623, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002363, mae: 0.017022, mean_q: 0.026377
 65061/100000: episode: 8624, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000778, mae: 0.015917, mean_q: 0.028378
 65064/100000: episode: 8625, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000094, mae: 0.007731, mean_q: 0.015355
 65069/100000: episode: 8626, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000611, mae: 0.013087, mean_q: 0.029752
[Info] FALSIFICATION!
 65073/100000: episode: 8627, duration: 0.214s, episode steps: 4, steps per second: 19, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000215, mae: 0.008266, mean_q: 0.015082
 65078/100000: episode: 8628, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000516, mae: 0.009391, mean_q: 0.023089
 65081/100000: episode: 8629, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001127, mae: 0.013340, mean_q: 0.017640
 65086/100000: episode: 8630, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000203, mae: 0.008906, mean_q: 0.017872
 65089/100000: episode: 8631, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001113, mae: 0.018858, mean_q: 0.033249
[Info] FALSIFICATION!
 65093/100000: episode: 8632, duration: 0.183s, episode steps: 4, steps per second: 22, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001405, mae: 0.016921, mean_q: 0.032840
 65098/100000: episode: 8633, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002709, mae: 0.023233, mean_q: 0.039365
 65103/100000: episode: 8634, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000552, mae: 0.013471, mean_q: 0.021454
 65108/100000: episode: 8635, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001285, mae: 0.019814, mean_q: 0.032439
 65111/100000: episode: 8636, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000273, mae: 0.011644, mean_q: 0.021285
[Info] FALSIFICATION!
 65115/100000: episode: 8637, duration: 0.273s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001250, mae: 0.017330, mean_q: 0.027004
 65118/100000: episode: 8638, duration: 0.020s, episode steps: 3, steps per second: 151, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000119, mae: 0.009049, mean_q: 0.019687
 65121/100000: episode: 8639, duration: 0.019s, episode steps: 3, steps per second: 162, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000128, mae: 0.009495, mean_q: 0.022139
 65126/100000: episode: 8640, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000464, mae: 0.012392, mean_q: 0.026160
[Info] FALSIFICATION!
 65130/100000: episode: 8641, duration: 0.271s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000483, mae: 0.011859, mean_q: 0.021246
 65135/100000: episode: 8642, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000817, mae: 0.011800, mean_q: 0.014893
 65140/100000: episode: 8643, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000590, mae: 0.012246, mean_q: 0.018704
 65143/100000: episode: 8644, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000597, mae: 0.011452, mean_q: 0.019881
 65148/100000: episode: 8645, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001321, mae: 0.018086, mean_q: 0.033569
 65151/100000: episode: 8646, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000320, mae: 0.008944, mean_q: 0.019931
 65154/100000: episode: 8647, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000163, mae: 0.009806, mean_q: 0.017900
 65159/100000: episode: 8648, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001294, mae: 0.015425, mean_q: 0.026380
 65164/100000: episode: 8649, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000423, mae: 0.011641, mean_q: 0.025534
 65167/100000: episode: 8650, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001308, mae: 0.014633, mean_q: 0.019944
 65170/100000: episode: 8651, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000454, mae: 0.009768, mean_q: 0.021815
 65175/100000: episode: 8652, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000261, mae: 0.007333, mean_q: 0.012315
 65180/100000: episode: 8653, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000427, mae: 0.009275, mean_q: 0.022129
 65185/100000: episode: 8654, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001216, mae: 0.013171, mean_q: 0.018858
 65188/100000: episode: 8655, duration: 0.020s, episode steps: 3, steps per second: 150, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001041, mae: 0.014356, mean_q: 0.025361
 65193/100000: episode: 8656, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001773, mae: 0.017953, mean_q: 0.027095
 65198/100000: episode: 8657, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000823, mae: 0.016030, mean_q: 0.033394
 65201/100000: episode: 8658, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000226, mae: 0.012384, mean_q: 0.029354
 65204/100000: episode: 8659, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000929, mae: 0.013359, mean_q: 0.020623
 65209/100000: episode: 8660, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000932, mae: 0.013891, mean_q: 0.038878
 65214/100000: episode: 8661, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000834, mae: 0.011721, mean_q: 0.024371
 65217/100000: episode: 8662, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000341, mae: 0.010545, mean_q: 0.025233
 65222/100000: episode: 8663, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000871, mae: 0.016245, mean_q: 0.032588
 65227/100000: episode: 8664, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000856, mae: 0.013651, mean_q: 0.021702
 65230/100000: episode: 8665, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000872, mae: 0.013091, mean_q: 0.029880
 65233/100000: episode: 8666, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001498, mae: 0.016297, mean_q: 0.035044
 65236/100000: episode: 8667, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000329, mae: 0.010524, mean_q: 0.023168
 65239/100000: episode: 8668, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000337, mae: 0.011621, mean_q: 0.026613
 65242/100000: episode: 8669, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000527, mae: 0.014484, mean_q: 0.024634
 65245/100000: episode: 8670, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000413, mae: 0.015027, mean_q: 0.026297
 65248/100000: episode: 8671, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000168, mae: 0.008290, mean_q: 0.016098
 65253/100000: episode: 8672, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000941, mae: 0.012783, mean_q: 0.036614
 65256/100000: episode: 8673, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000329, mae: 0.010648, mean_q: 0.026549
 65259/100000: episode: 8674, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001604, mae: 0.018182, mean_q: 0.041526
 65262/100000: episode: 8675, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001119, mae: 0.012390, mean_q: 0.020976
 65265/100000: episode: 8676, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000377, mae: 0.011233, mean_q: 0.012636
 65268/100000: episode: 8677, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000392, mae: 0.011279, mean_q: 0.014449
 65271/100000: episode: 8678, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002551, mae: 0.022995, mean_q: 0.033369
 65276/100000: episode: 8679, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000956, mae: 0.013882, mean_q: 0.022535
 65281/100000: episode: 8680, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000737, mae: 0.014278, mean_q: 0.029066
 65284/100000: episode: 8681, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000893, mae: 0.012925, mean_q: 0.022914
 65289/100000: episode: 8682, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000450, mae: 0.011375, mean_q: 0.017875
 65292/100000: episode: 8683, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000937, mae: 0.013803, mean_q: 0.021876
 65295/100000: episode: 8684, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000348, mae: 0.010342, mean_q: 0.020647
 65300/100000: episode: 8685, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001687, mae: 0.018660, mean_q: 0.033197
 65305/100000: episode: 8686, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000733, mae: 0.012960, mean_q: 0.020058
 65308/100000: episode: 8687, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001731, mae: 0.021057, mean_q: 0.034601
 65311/100000: episode: 8688, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000211, mae: 0.010350, mean_q: 0.017063
 65314/100000: episode: 8689, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000258, mae: 0.010022, mean_q: 0.015390
 65317/100000: episode: 8690, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002052, mae: 0.024448, mean_q: 0.039170
 65320/100000: episode: 8691, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001028, mae: 0.016153, mean_q: 0.032696
 65323/100000: episode: 8692, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001489, mae: 0.017615, mean_q: 0.026568
 65326/100000: episode: 8693, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000876, mae: 0.014485, mean_q: 0.021219
 65331/100000: episode: 8694, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001516, mae: 0.018807, mean_q: 0.036959
 65334/100000: episode: 8695, duration: 0.019s, episode steps: 3, steps per second: 156, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000884, mae: 0.015842, mean_q: 0.029303
 65339/100000: episode: 8696, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000324, mae: 0.012838, mean_q: 0.024776
 65342/100000: episode: 8697, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000977, mae: 0.017597, mean_q: 0.032060
 65345/100000: episode: 8698, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000693, mae: 0.014602, mean_q: 0.021386
 65348/100000: episode: 8699, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001070, mae: 0.012127, mean_q: 0.020350
 65353/100000: episode: 8700, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001406, mae: 0.021445, mean_q: 0.053484
 65358/100000: episode: 8701, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001207, mae: 0.020587, mean_q: 0.033648
 65363/100000: episode: 8702, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000640, mae: 0.014538, mean_q: 0.018562
 65368/100000: episode: 8703, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001082, mae: 0.018356, mean_q: 0.032610
 65373/100000: episode: 8704, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001725, mae: 0.017856, mean_q: 0.026192
 65378/100000: episode: 8705, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000374, mae: 0.010907, mean_q: 0.014283
[Info] Complete ISplit Iteration
[Info] Levels: [0.017406931, 0.102472916, 1.1928601]
[Info] Cond. Prob: [0.14, 0.14, 0.04]
[Info] Error Prob: 0.0007840000000000001

 65383/100000: episode: 8706, duration: 0.896s, episode steps: 5, steps per second: 6, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001342, mae: 0.019706, mean_q: 0.028217
 65393/100000: episode: 8707, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002175, mae: 0.024942, mean_q: 0.037904
 65403/100000: episode: 8708, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001055, mae: 0.016607, mean_q: 0.029756
 65413/100000: episode: 8709, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000680, mae: 0.013026, mean_q: 0.016946
 65423/100000: episode: 8710, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001143, mae: 0.015999, mean_q: 0.029813
 65433/100000: episode: 8711, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000876, mae: 0.016243, mean_q: 0.035383
 65443/100000: episode: 8712, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000835, mae: 0.017519, mean_q: 0.032668
 65453/100000: episode: 8713, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001666, mae: 0.021197, mean_q: 0.037348
 65463/100000: episode: 8714, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001122, mae: 0.016127, mean_q: 0.032208
 65473/100000: episode: 8715, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000713, mae: 0.013558, mean_q: 0.023653
 65483/100000: episode: 8716, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001230, mae: 0.015698, mean_q: 0.026627
 65493/100000: episode: 8717, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001015, mae: 0.015508, mean_q: 0.023777
 65503/100000: episode: 8718, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000714, mae: 0.013075, mean_q: 0.021060
 65513/100000: episode: 8719, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001399, mae: 0.018111, mean_q: 0.027169
 65523/100000: episode: 8720, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000893, mae: 0.016297, mean_q: 0.030110
 65533/100000: episode: 8721, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000606, mae: 0.013500, mean_q: 0.027878
 65543/100000: episode: 8722, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000676, mae: 0.013396, mean_q: 0.027388
 65553/100000: episode: 8723, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000736, mae: 0.014055, mean_q: 0.029792
 65563/100000: episode: 8724, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001231, mae: 0.018642, mean_q: 0.028963
 65573/100000: episode: 8725, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000410, mae: 0.012501, mean_q: 0.026622
 65583/100000: episode: 8726, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000610, mae: 0.012056, mean_q: 0.024422
 65593/100000: episode: 8727, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000361, mae: 0.010751, mean_q: 0.021246
 65603/100000: episode: 8728, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000743, mae: 0.012148, mean_q: 0.021289
 65613/100000: episode: 8729, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001519, mae: 0.020833, mean_q: 0.037081
 65623/100000: episode: 8730, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001158, mae: 0.016599, mean_q: 0.029819
 65633/100000: episode: 8731, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000810, mae: 0.014622, mean_q: 0.020172
 65643/100000: episode: 8732, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001147, mae: 0.018072, mean_q: 0.027173
 65653/100000: episode: 8733, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001359, mae: 0.019199, mean_q: 0.035410
 65663/100000: episode: 8734, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000725, mae: 0.013446, mean_q: 0.023403
 65673/100000: episode: 8735, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000661, mae: 0.012502, mean_q: 0.023563
 65683/100000: episode: 8736, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000996, mae: 0.015909, mean_q: 0.029501
 65693/100000: episode: 8737, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000969, mae: 0.017107, mean_q: 0.028920
 65703/100000: episode: 8738, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000493, mae: 0.014819, mean_q: 0.021714
 65713/100000: episode: 8739, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001070, mae: 0.015610, mean_q: 0.020052
 65723/100000: episode: 8740, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001214, mae: 0.016894, mean_q: 0.030408
 65733/100000: episode: 8741, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001347, mae: 0.020277, mean_q: 0.034281
 65743/100000: episode: 8742, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000390, mae: 0.013611, mean_q: 0.031538
 65753/100000: episode: 8743, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001478, mae: 0.018801, mean_q: 0.032699
 65763/100000: episode: 8744, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000297, mae: 0.010076, mean_q: 0.024700
 65773/100000: episode: 8745, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001105, mae: 0.015823, mean_q: 0.026600
 65783/100000: episode: 8746, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001292, mae: 0.020939, mean_q: 0.044274
 65793/100000: episode: 8747, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001678, mae: 0.017881, mean_q: 0.035463
 65803/100000: episode: 8748, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002350, mae: 0.020947, mean_q: 0.040754
 65813/100000: episode: 8749, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001943, mae: 0.018330, mean_q: 0.032861
 65823/100000: episode: 8750, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001640, mae: 0.020719, mean_q: 0.028246
 65833/100000: episode: 8751, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001155, mae: 0.016534, mean_q: 0.028920
 65843/100000: episode: 8752, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001110, mae: 0.018064, mean_q: 0.018557
 65853/100000: episode: 8753, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000256, mae: 0.010840, mean_q: 0.014584
 65863/100000: episode: 8754, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000602, mae: 0.011551, mean_q: 0.018822
 65873/100000: episode: 8755, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000908, mae: 0.015416, mean_q: 0.023367
 65883/100000: episode: 8756, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001671, mae: 0.021051, mean_q: 0.038198
 65893/100000: episode: 8757, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000819, mae: 0.015058, mean_q: 0.029190
 65903/100000: episode: 8758, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001609, mae: 0.020250, mean_q: 0.040601
 65913/100000: episode: 8759, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000558, mae: 0.012427, mean_q: 0.023305
 65923/100000: episode: 8760, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000821, mae: 0.015673, mean_q: 0.036750
 65933/100000: episode: 8761, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002005, mae: 0.019817, mean_q: 0.030145
 65943/100000: episode: 8762, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001050, mae: 0.015575, mean_q: 0.030825
 65953/100000: episode: 8763, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000803, mae: 0.012871, mean_q: 0.023973
 65963/100000: episode: 8764, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001105, mae: 0.016312, mean_q: 0.029058
 65973/100000: episode: 8765, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001691, mae: 0.018049, mean_q: 0.030293
 65983/100000: episode: 8766, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001274, mae: 0.017118, mean_q: 0.030503
 65993/100000: episode: 8767, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000499, mae: 0.012332, mean_q: 0.025652
 66003/100000: episode: 8768, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001250, mae: 0.015430, mean_q: 0.026260
 66013/100000: episode: 8769, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000885, mae: 0.016039, mean_q: 0.018036
 66023/100000: episode: 8770, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001194, mae: 0.015999, mean_q: 0.022900
 66033/100000: episode: 8771, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000916, mae: 0.016184, mean_q: 0.026770
 66043/100000: episode: 8772, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001112, mae: 0.017189, mean_q: 0.028349
 66053/100000: episode: 8773, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001155, mae: 0.014752, mean_q: 0.020876
 66063/100000: episode: 8774, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000990, mae: 0.014067, mean_q: 0.020635
 66073/100000: episode: 8775, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000571, mae: 0.012029, mean_q: 0.022736
 66083/100000: episode: 8776, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000959, mae: 0.016872, mean_q: 0.032589
 66093/100000: episode: 8777, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000803, mae: 0.014135, mean_q: 0.026039
 66103/100000: episode: 8778, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001138, mae: 0.018248, mean_q: 0.037657
 66113/100000: episode: 8779, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000770, mae: 0.013159, mean_q: 0.022362
 66123/100000: episode: 8780, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000828, mae: 0.014385, mean_q: 0.025213
 66133/100000: episode: 8781, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000441, mae: 0.011490, mean_q: 0.018287
 66143/100000: episode: 8782, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000503, mae: 0.011637, mean_q: 0.022257
 66153/100000: episode: 8783, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001122, mae: 0.013817, mean_q: 0.019400
 66163/100000: episode: 8784, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001402, mae: 0.019986, mean_q: 0.032690
 66173/100000: episode: 8785, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001479, mae: 0.017950, mean_q: 0.031313
 66183/100000: episode: 8786, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001065, mae: 0.014416, mean_q: 0.021048
 66193/100000: episode: 8787, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000480, mae: 0.012328, mean_q: 0.022022
 66203/100000: episode: 8788, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000322, mae: 0.011264, mean_q: 0.021732
 66213/100000: episode: 8789, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000775, mae: 0.013991, mean_q: 0.029467
 66223/100000: episode: 8790, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001135, mae: 0.012964, mean_q: 0.021473
 66233/100000: episode: 8791, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001133, mae: 0.018538, mean_q: 0.035723
 66243/100000: episode: 8792, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000239, mae: 0.009308, mean_q: 0.011780
 66253/100000: episode: 8793, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001299, mae: 0.017485, mean_q: 0.022963
 66263/100000: episode: 8794, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000665, mae: 0.013665, mean_q: 0.026519
 66273/100000: episode: 8795, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000637, mae: 0.016548, mean_q: 0.033593
 66283/100000: episode: 8796, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000823, mae: 0.014483, mean_q: 0.028424
 66293/100000: episode: 8797, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001488, mae: 0.019429, mean_q: 0.035697
 66303/100000: episode: 8798, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000322, mae: 0.012181, mean_q: 0.023942
 66313/100000: episode: 8799, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001009, mae: 0.015597, mean_q: 0.033180
 66323/100000: episode: 8800, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000797, mae: 0.013102, mean_q: 0.023130
 66333/100000: episode: 8801, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000416, mae: 0.013746, mean_q: 0.028302
 66343/100000: episode: 8802, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000335, mae: 0.013103, mean_q: 0.031420
 66353/100000: episode: 8803, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000805, mae: 0.012872, mean_q: 0.026644
 66363/100000: episode: 8804, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000442, mae: 0.010407, mean_q: 0.019158
 66373/100000: episode: 8805, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000811, mae: 0.012320, mean_q: 0.014878
[Info] 1-TH LEVEL FOUND: 0.01370889414101839, Considering 12/100 traces
 66383/100000: episode: 8806, duration: 0.704s, episode steps: 10, steps per second: 14, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000453, mae: 0.009761, mean_q: 0.018229
 66388/100000: episode: 8807, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001364, mae: 0.018442, mean_q: 0.024103
 66393/100000: episode: 8808, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001541, mae: 0.016938, mean_q: 0.022270
 66399/100000: episode: 8809, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000395, mae: 0.010514, mean_q: 0.016296
 66404/100000: episode: 8810, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000451, mae: 0.010179, mean_q: 0.014836
 66409/100000: episode: 8811, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000614, mae: 0.012546, mean_q: 0.026775
 66414/100000: episode: 8812, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000466, mae: 0.010367, mean_q: 0.019867
 66419/100000: episode: 8813, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.001477, mae: 0.012623, mean_q: 0.015976
 66425/100000: episode: 8814, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001385, mae: 0.015050, mean_q: 0.021954
 66431/100000: episode: 8815, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000483, mae: 0.012321, mean_q: 0.028807
 66436/100000: episode: 8816, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000144, mae: 0.008018, mean_q: 0.015959
 66439/100000: episode: 8817, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001883, mae: 0.014735, mean_q: 0.027660
 66444/100000: episode: 8818, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.001058, mae: 0.013323, mean_q: 0.018514
 66449/100000: episode: 8819, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.001575, mae: 0.016073, mean_q: 0.030189
 66454/100000: episode: 8820, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000498, mae: 0.009516, mean_q: 0.016108
 66459/100000: episode: 8821, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001442, mae: 0.016884, mean_q: 0.031413
 66464/100000: episode: 8822, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000800, mae: 0.014811, mean_q: 0.027404
 66469/100000: episode: 8823, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001259, mae: 0.017367, mean_q: 0.029113
 66472/100000: episode: 8824, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001649, mae: 0.019303, mean_q: 0.031598
 66477/100000: episode: 8825, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000605, mae: 0.013743, mean_q: 0.029465
 66480/100000: episode: 8826, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000155, mae: 0.010080, mean_q: 0.026611
 66485/100000: episode: 8827, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000860, mae: 0.014581, mean_q: 0.030936
 66490/100000: episode: 8828, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000887, mae: 0.012607, mean_q: 0.021888
 66493/100000: episode: 8829, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000345, mae: 0.010898, mean_q: 0.021724
 66498/100000: episode: 8830, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001495, mae: 0.016827, mean_q: 0.031708
 66503/100000: episode: 8831, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000242, mae: 0.008700, mean_q: 0.013869
 66508/100000: episode: 8832, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001329, mae: 0.015462, mean_q: 0.026840
 66511/100000: episode: 8833, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000282, mae: 0.009689, mean_q: 0.025333
 66514/100000: episode: 8834, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002126, mae: 0.024000, mean_q: 0.059103
 66520/100000: episode: 8835, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001139, mae: 0.016493, mean_q: 0.032589
 66525/100000: episode: 8836, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000708, mae: 0.013838, mean_q: 0.025095
 66530/100000: episode: 8837, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000543, mae: 0.012157, mean_q: 0.021473
 66535/100000: episode: 8838, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000478, mae: 0.011674, mean_q: 0.025841
 66540/100000: episode: 8839, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001251, mae: 0.013849, mean_q: 0.020891
 66543/100000: episode: 8840, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001344, mae: 0.014699, mean_q: 0.020953
 66548/100000: episode: 8841, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000668, mae: 0.013449, mean_q: 0.021553
 66553/100000: episode: 8842, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.001590, mae: 0.017118, mean_q: 0.026084
 66559/100000: episode: 8843, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000726, mae: 0.014502, mean_q: 0.024774
 66562/100000: episode: 8844, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000634, mae: 0.010622, mean_q: 0.017727
 66567/100000: episode: 8845, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000798, mae: 0.013946, mean_q: 0.027954
 66570/100000: episode: 8846, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000906, mae: 0.012019, mean_q: 0.020073
 66576/100000: episode: 8847, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002749, mae: 0.021382, mean_q: 0.025886
 66581/100000: episode: 8848, duration: 0.024s, episode steps: 5, steps per second: 205, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000446, mae: 0.010326, mean_q: 0.019018
 66586/100000: episode: 8849, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000466, mae: 0.012349, mean_q: 0.021651
 66591/100000: episode: 8850, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000614, mae: 0.013498, mean_q: 0.025996
 66594/100000: episode: 8851, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001067, mae: 0.014718, mean_q: 0.038268
 66600/100000: episode: 8852, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000873, mae: 0.012933, mean_q: 0.025698
 66606/100000: episode: 8853, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000711, mae: 0.011691, mean_q: 0.015330
 66611/100000: episode: 8854, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000247, mae: 0.009924, mean_q: 0.011989
 66614/100000: episode: 8855, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000364, mae: 0.011586, mean_q: 0.015012
 66620/100000: episode: 8856, duration: 0.033s, episode steps: 6, steps per second: 181, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000690, mae: 0.010220, mean_q: 0.017502
 66623/100000: episode: 8857, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000146, mae: 0.007736, mean_q: 0.014009
 66628/100000: episode: 8858, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000774, mae: 0.012033, mean_q: 0.020270
 66631/100000: episode: 8859, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000126, mae: 0.008069, mean_q: 0.013440
 66636/100000: episode: 8860, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001661, mae: 0.018226, mean_q: 0.033159
 66641/100000: episode: 8861, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000688, mae: 0.014263, mean_q: 0.022457
 66646/100000: episode: 8862, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001060, mae: 0.015310, mean_q: 0.026683
 66651/100000: episode: 8863, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000413, mae: 0.009453, mean_q: 0.014085
 66656/100000: episode: 8864, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000697, mae: 0.012904, mean_q: 0.019801
 66661/100000: episode: 8865, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001027, mae: 0.013865, mean_q: 0.023246
 66666/100000: episode: 8866, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001045, mae: 0.014953, mean_q: 0.024650
 66671/100000: episode: 8867, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000243, mae: 0.011217, mean_q: 0.021494
 66674/100000: episode: 8868, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000084, mae: 0.007353, mean_q: 0.015500
 66679/100000: episode: 8869, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000649, mae: 0.009695, mean_q: 0.018639
 66684/100000: episode: 8870, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000152, mae: 0.007764, mean_q: 0.013780
 66689/100000: episode: 8871, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000658, mae: 0.010423, mean_q: 0.015514
 66695/100000: episode: 8872, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000315, mae: 0.009550, mean_q: 0.011676
 66701/100000: episode: 8873, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000222, mae: 0.009439, mean_q: 0.014387
 66706/100000: episode: 8874, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000466, mae: 0.010204, mean_q: 0.018641
 66711/100000: episode: 8875, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000253, mae: 0.010141, mean_q: 0.022843
 66717/100000: episode: 8876, duration: 0.032s, episode steps: 6, steps per second: 189, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000538, mae: 0.009461, mean_q: 0.017235
 66723/100000: episode: 8877, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000367, mae: 0.008765, mean_q: 0.019401
 66728/100000: episode: 8878, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000686, mae: 0.011704, mean_q: 0.023950
 66731/100000: episode: 8879, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000214, mae: 0.009481, mean_q: 0.024652
 66736/100000: episode: 8880, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000515, mae: 0.010233, mean_q: 0.023164
 66741/100000: episode: 8881, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000522, mae: 0.011948, mean_q: 0.023112
 66746/100000: episode: 8882, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000633, mae: 0.010145, mean_q: 0.017067
 66751/100000: episode: 8883, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000372, mae: 0.009968, mean_q: 0.013447
 66756/100000: episode: 8884, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000436, mae: 0.012760, mean_q: 0.016680
 66761/100000: episode: 8885, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000921, mae: 0.011386, mean_q: 0.015237
 66767/100000: episode: 8886, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000262, mae: 0.011569, mean_q: 0.019781
 66773/100000: episode: 8887, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000262, mae: 0.010854, mean_q: 0.026702
 66778/100000: episode: 8888, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000169, mae: 0.008223, mean_q: 0.014313
 66781/100000: episode: 8889, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001040, mae: 0.014887, mean_q: 0.021355
 66784/100000: episode: 8890, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001143, mae: 0.014685, mean_q: 0.022273
 66790/100000: episode: 8891, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000331, mae: 0.010004, mean_q: 0.013732
 66795/100000: episode: 8892, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001015, mae: 0.015715, mean_q: 0.027292
 66800/100000: episode: 8893, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000243, mae: 0.011223, mean_q: 0.019571
[Info] 2-TH LEVEL FOUND: 0.07255018502473831, Considering 28/100 traces
 66805/100000: episode: 8894, duration: 0.698s, episode steps: 5, steps per second: 7, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000478, mae: 0.013544, mean_q: 0.030328
 66808/100000: episode: 8895, duration: 0.019s, episode steps: 3, steps per second: 162, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000119, mae: 0.008069, mean_q: 0.012648
 66813/100000: episode: 8896, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000535, mae: 0.010297, mean_q: 0.017545
 66816/100000: episode: 8897, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001080, mae: 0.016331, mean_q: 0.030705
 66821/100000: episode: 8898, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000125, mae: 0.006828, mean_q: 0.011012
 66824/100000: episode: 8899, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000039, mae: 0.005153, mean_q: 0.009501
 66827/100000: episode: 8900, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000718, mae: 0.011649, mean_q: 0.021600
 66832/100000: episode: 8901, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000118, mae: 0.008520, mean_q: 0.021431
 66835/100000: episode: 8902, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001112, mae: 0.013359, mean_q: 0.029912
 66840/100000: episode: 8903, duration: 0.029s, episode steps: 5, steps per second: 174, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000218, mae: 0.009303, mean_q: 0.016701
 66843/100000: episode: 8904, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000690, mae: 0.009775, mean_q: 0.021827
 66846/100000: episode: 8905, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000876, mae: 0.012005, mean_q: 0.017067
 66849/100000: episode: 8906, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000140, mae: 0.009198, mean_q: 0.016640
 66852/100000: episode: 8907, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000291, mae: 0.012089, mean_q: 0.029286
 66857/100000: episode: 8908, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000611, mae: 0.010458, mean_q: 0.019002
 66860/100000: episode: 8909, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000915, mae: 0.014273, mean_q: 0.026437
 66863/100000: episode: 8910, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001075, mae: 0.017235, mean_q: 0.027952
 66868/100000: episode: 8911, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001037, mae: 0.015479, mean_q: 0.030314
 66871/100000: episode: 8912, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000119, mae: 0.008313, mean_q: 0.014291
 66876/100000: episode: 8913, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000515, mae: 0.010148, mean_q: 0.014199
 66879/100000: episode: 8914, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000939, mae: 0.013274, mean_q: 0.021671
 66882/100000: episode: 8915, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000858, mae: 0.013131, mean_q: 0.022163
 66885/100000: episode: 8916, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000196, mae: 0.008786, mean_q: 0.016575
 66890/100000: episode: 8917, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000540, mae: 0.009689, mean_q: 0.016071
 66893/100000: episode: 8918, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000205, mae: 0.009236, mean_q: 0.015897
 66896/100000: episode: 8919, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000200, mae: 0.009698, mean_q: 0.016800
 66899/100000: episode: 8920, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000125, mae: 0.008406, mean_q: 0.022697
 66904/100000: episode: 8921, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000128, mae: 0.008520, mean_q: 0.015759
 66907/100000: episode: 8922, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000648, mae: 0.009952, mean_q: 0.018293
 66912/100000: episode: 8923, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000116, mae: 0.007621, mean_q: 0.013804
 66915/100000: episode: 8924, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002263, mae: 0.018264, mean_q: 0.029179
 66918/100000: episode: 8925, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000138, mae: 0.007596, mean_q: 0.011407
 66923/100000: episode: 8926, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000716, mae: 0.011822, mean_q: 0.017495
 66926/100000: episode: 8927, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001327, mae: 0.016202, mean_q: 0.022978
 66931/100000: episode: 8928, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000129, mae: 0.008818, mean_q: 0.015606
 66936/100000: episode: 8929, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001028, mae: 0.015875, mean_q: 0.025726
 66939/100000: episode: 8930, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000818, mae: 0.015255, mean_q: 0.024361
 66942/100000: episode: 8931, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000141, mae: 0.008076, mean_q: 0.013319
 66945/100000: episode: 8932, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001425, mae: 0.014475, mean_q: 0.020312
 66948/100000: episode: 8933, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000868, mae: 0.011973, mean_q: 0.024692
 66951/100000: episode: 8934, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001072, mae: 0.013341, mean_q: 0.018164
 66954/100000: episode: 8935, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000762, mae: 0.010784, mean_q: 0.019180
 66959/100000: episode: 8936, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000833, mae: 0.014333, mean_q: 0.025578
 66962/100000: episode: 8937, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001570, mae: 0.017903, mean_q: 0.028211
 66965/100000: episode: 8938, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000846, mae: 0.010725, mean_q: 0.014952
 66970/100000: episode: 8939, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002427, mae: 0.016957, mean_q: 0.021596
 66973/100000: episode: 8940, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000804, mae: 0.012671, mean_q: 0.021463
[Info] FALSIFICATION!
 66977/100000: episode: 8941, duration: 0.273s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001683, mae: 0.021185, mean_q: 0.031866
 66980/100000: episode: 8942, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000329, mae: 0.012189, mean_q: 0.021343
 66985/100000: episode: 8943, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000293, mae: 0.012776, mean_q: 0.023316
 66988/100000: episode: 8944, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000179, mae: 0.010520, mean_q: 0.019691
 66993/100000: episode: 8945, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000901, mae: 0.014287, mean_q: 0.026187
 66996/100000: episode: 8946, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000601, mae: 0.016675, mean_q: 0.039116
 66999/100000: episode: 8947, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000143, mae: 0.008850, mean_q: 0.015413
 67004/100000: episode: 8948, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001785, mae: 0.018569, mean_q: 0.030369
 67009/100000: episode: 8949, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000818, mae: 0.013635, mean_q: 0.022806
 67014/100000: episode: 8950, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000509, mae: 0.010834, mean_q: 0.018964
 67017/100000: episode: 8951, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001219, mae: 0.016655, mean_q: 0.029013
 67020/100000: episode: 8952, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000385, mae: 0.014027, mean_q: 0.024300
 67025/100000: episode: 8953, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001072, mae: 0.014627, mean_q: 0.026398
[Info] FALSIFICATION!
 67029/100000: episode: 8954, duration: 0.180s, episode steps: 4, steps per second: 22, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000168, mae: 0.008776, mean_q: 0.011953
 67032/100000: episode: 8955, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001850, mae: 0.014964, mean_q: 0.020476
 67037/100000: episode: 8956, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000933, mae: 0.015699, mean_q: 0.025730
 67040/100000: episode: 8957, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000332, mae: 0.013851, mean_q: 0.029771
 67043/100000: episode: 8958, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000780, mae: 0.017088, mean_q: 0.033129
 67046/100000: episode: 8959, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000296, mae: 0.010750, mean_q: 0.019884
 67051/100000: episode: 8960, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000656, mae: 0.012654, mean_q: 0.023154
 67054/100000: episode: 8961, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000277, mae: 0.010779, mean_q: 0.012395
 67057/100000: episode: 8962, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000855, mae: 0.011486, mean_q: 0.012467
 67060/100000: episode: 8963, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001710, mae: 0.019515, mean_q: 0.029579
 67063/100000: episode: 8964, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000978, mae: 0.016301, mean_q: 0.031145
 67066/100000: episode: 8965, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001332, mae: 0.017447, mean_q: 0.028290
[Info] Complete ISplit Iteration
[Info] Levels: [0.013708894, 0.072550185, 1.2580377]
[Info] Cond. Prob: [0.12, 0.28, 0.03]
[Info] Error Prob: 0.0010080000000000002

 67069/100000: episode: 8966, duration: 0.853s, episode steps: 3, steps per second: 4, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000333, mae: 0.010548, mean_q: 0.016736
 67079/100000: episode: 8967, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000248, mae: 0.010655, mean_q: 0.022639
 67089/100000: episode: 8968, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000647, mae: 0.015123, mean_q: 0.027186
 67099/100000: episode: 8969, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001241, mae: 0.017308, mean_q: 0.034324
 67109/100000: episode: 8970, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001191, mae: 0.016638, mean_q: 0.027559
 67119/100000: episode: 8971, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000550, mae: 0.010830, mean_q: 0.019995
 67129/100000: episode: 8972, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.001107, mae: 0.015979, mean_q: 0.024781
 67139/100000: episode: 8973, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000323, mae: 0.010370, mean_q: 0.017495
 67149/100000: episode: 8974, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000637, mae: 0.012268, mean_q: 0.023849
 67159/100000: episode: 8975, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000480, mae: 0.012886, mean_q: 0.025466
 67169/100000: episode: 8976, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001090, mae: 0.014477, mean_q: 0.029969
 67179/100000: episode: 8977, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000625, mae: 0.012675, mean_q: 0.024099
 67189/100000: episode: 8978, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000947, mae: 0.014802, mean_q: 0.029014
 67199/100000: episode: 8979, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000654, mae: 0.012955, mean_q: 0.021880
 67209/100000: episode: 8980, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000894, mae: 0.015747, mean_q: 0.030546
 67219/100000: episode: 8981, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001299, mae: 0.017306, mean_q: 0.032152
 67229/100000: episode: 8982, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000430, mae: 0.011218, mean_q: 0.021174
 67239/100000: episode: 8983, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001320, mae: 0.017324, mean_q: 0.027462
 67249/100000: episode: 8984, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000555, mae: 0.013477, mean_q: 0.026065
 67259/100000: episode: 8985, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000874, mae: 0.015575, mean_q: 0.027031
 67269/100000: episode: 8986, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000631, mae: 0.013670, mean_q: 0.022664
 67279/100000: episode: 8987, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000342, mae: 0.011509, mean_q: 0.019569
 67289/100000: episode: 8988, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000789, mae: 0.013730, mean_q: 0.022630
 67299/100000: episode: 8989, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002510, mae: 0.019445, mean_q: 0.028874
 67309/100000: episode: 8990, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001314, mae: 0.018431, mean_q: 0.032719
 67319/100000: episode: 8991, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000699, mae: 0.013849, mean_q: 0.028019
 67329/100000: episode: 8992, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000747, mae: 0.013240, mean_q: 0.025025
 67339/100000: episode: 8993, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000446, mae: 0.010028, mean_q: 0.018838
 67349/100000: episode: 8994, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000929, mae: 0.014785, mean_q: 0.028002
 67359/100000: episode: 8995, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000875, mae: 0.013805, mean_q: 0.031199
 67369/100000: episode: 8996, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000710, mae: 0.012923, mean_q: 0.022848
 67379/100000: episode: 8997, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000690, mae: 0.011856, mean_q: 0.020153
 67389/100000: episode: 8998, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000884, mae: 0.014227, mean_q: 0.024653
 67399/100000: episode: 8999, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001146, mae: 0.015650, mean_q: 0.027979
 67409/100000: episode: 9000, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000453, mae: 0.011890, mean_q: 0.022867
 67419/100000: episode: 9001, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000757, mae: 0.012626, mean_q: 0.021414
 67429/100000: episode: 9002, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000707, mae: 0.014399, mean_q: 0.020734
 67439/100000: episode: 9003, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000902, mae: 0.015715, mean_q: 0.029741
 67449/100000: episode: 9004, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000848, mae: 0.013130, mean_q: 0.023031
 67459/100000: episode: 9005, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000480, mae: 0.012135, mean_q: 0.019950
 67469/100000: episode: 9006, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001258, mae: 0.017756, mean_q: 0.033627
 67479/100000: episode: 9007, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000578, mae: 0.012814, mean_q: 0.023253
 67489/100000: episode: 9008, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000822, mae: 0.013055, mean_q: 0.021033
 67499/100000: episode: 9009, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000680, mae: 0.013180, mean_q: 0.024444
 67509/100000: episode: 9010, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000410, mae: 0.011095, mean_q: 0.015353
 67519/100000: episode: 9011, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000833, mae: 0.015432, mean_q: 0.024810
 67529/100000: episode: 9012, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000928, mae: 0.017339, mean_q: 0.039481
 67539/100000: episode: 9013, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001324, mae: 0.015738, mean_q: 0.028471
 67549/100000: episode: 9014, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000684, mae: 0.015254, mean_q: 0.026186
 67559/100000: episode: 9015, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000757, mae: 0.013734, mean_q: 0.017996
 67569/100000: episode: 9016, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000956, mae: 0.014073, mean_q: 0.028257
 67579/100000: episode: 9017, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000580, mae: 0.011912, mean_q: 0.021727
 67589/100000: episode: 9018, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000775, mae: 0.013283, mean_q: 0.023217
 67599/100000: episode: 9019, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000787, mae: 0.013264, mean_q: 0.026969
 67609/100000: episode: 9020, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001093, mae: 0.013798, mean_q: 0.022082
 67619/100000: episode: 9021, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001021, mae: 0.015493, mean_q: 0.026091
 67629/100000: episode: 9022, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000728, mae: 0.013095, mean_q: 0.028780
 67639/100000: episode: 9023, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000885, mae: 0.014204, mean_q: 0.019382
 67649/100000: episode: 9024, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000752, mae: 0.012663, mean_q: 0.024162
 67659/100000: episode: 9025, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000684, mae: 0.012893, mean_q: 0.027345
 67669/100000: episode: 9026, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000800, mae: 0.013605, mean_q: 0.023305
 67679/100000: episode: 9027, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000556, mae: 0.011183, mean_q: 0.023716
 67689/100000: episode: 9028, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000608, mae: 0.011401, mean_q: 0.019807
 67699/100000: episode: 9029, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001100, mae: 0.017034, mean_q: 0.042065
 67709/100000: episode: 9030, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000328, mae: 0.009844, mean_q: 0.019570
 67719/100000: episode: 9031, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000909, mae: 0.012004, mean_q: 0.017928
 67729/100000: episode: 9032, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000951, mae: 0.012385, mean_q: 0.024559
 67739/100000: episode: 9033, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000705, mae: 0.012703, mean_q: 0.021218
 67749/100000: episode: 9034, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001855, mae: 0.018351, mean_q: 0.027515
 67759/100000: episode: 9035, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000533, mae: 0.012556, mean_q: 0.024721
 67769/100000: episode: 9036, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000914, mae: 0.014627, mean_q: 0.024681
 67779/100000: episode: 9037, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000428, mae: 0.010475, mean_q: 0.019177
 67789/100000: episode: 9038, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000520, mae: 0.011642, mean_q: 0.024237
 67799/100000: episode: 9039, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000295, mae: 0.009959, mean_q: 0.020853
 67809/100000: episode: 9040, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000575, mae: 0.010349, mean_q: 0.019399
 67819/100000: episode: 9041, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000876, mae: 0.014097, mean_q: 0.032866
 67829/100000: episode: 9042, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001009, mae: 0.013937, mean_q: 0.023995
 67839/100000: episode: 9043, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000289, mae: 0.008826, mean_q: 0.017687
 67849/100000: episode: 9044, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000661, mae: 0.013567, mean_q: 0.032579
 67859/100000: episode: 9045, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000450, mae: 0.009607, mean_q: 0.013349
 67869/100000: episode: 9046, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000723, mae: 0.012373, mean_q: 0.019807
 67879/100000: episode: 9047, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000426, mae: 0.010966, mean_q: 0.018228
 67889/100000: episode: 9048, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000520, mae: 0.009911, mean_q: 0.019827
 67899/100000: episode: 9049, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000654, mae: 0.011421, mean_q: 0.021083
 67909/100000: episode: 9050, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000831, mae: 0.014529, mean_q: 0.026494
 67919/100000: episode: 9051, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000533, mae: 0.012729, mean_q: 0.023850
 67929/100000: episode: 9052, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000494, mae: 0.010140, mean_q: 0.018118
 67939/100000: episode: 9053, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001084, mae: 0.013322, mean_q: 0.030759
 67949/100000: episode: 9054, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000518, mae: 0.011232, mean_q: 0.024646
 67959/100000: episode: 9055, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000447, mae: 0.009943, mean_q: 0.016525
 67969/100000: episode: 9056, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000530, mae: 0.009632, mean_q: 0.012297
 67979/100000: episode: 9057, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000267, mae: 0.010392, mean_q: 0.020252
 67989/100000: episode: 9058, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000719, mae: 0.012475, mean_q: 0.021937
 67999/100000: episode: 9059, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000395, mae: 0.009510, mean_q: 0.021078
 68009/100000: episode: 9060, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000837, mae: 0.012014, mean_q: 0.021822
 68019/100000: episode: 9061, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000588, mae: 0.010436, mean_q: 0.013938
 68029/100000: episode: 9062, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000479, mae: 0.010679, mean_q: 0.017430
 68039/100000: episode: 9063, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000394, mae: 0.011629, mean_q: 0.019724
 68049/100000: episode: 9064, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000619, mae: 0.011136, mean_q: 0.018900
 68059/100000: episode: 9065, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000425, mae: 0.008737, mean_q: 0.016413
[Info] 1-TH LEVEL FOUND: 0.03801120072603226, Considering 10/100 traces
 68069/100000: episode: 9066, duration: 0.708s, episode steps: 10, steps per second: 14, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000517, mae: 0.011409, mean_q: 0.022421
 68072/100000: episode: 9067, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000332, mae: 0.010551, mean_q: 0.017050
 68075/100000: episode: 9068, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001108, mae: 0.016171, mean_q: 0.026831
 68078/100000: episode: 9069, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000125, mae: 0.009090, mean_q: 0.016647
 68081/100000: episode: 9070, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000105, mae: 0.007389, mean_q: 0.013354
 68084/100000: episode: 9071, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000640, mae: 0.012221, mean_q: 0.030750
 68088/100000: episode: 9072, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000164, mae: 0.009034, mean_q: 0.017209
 68091/100000: episode: 9073, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000047, mae: 0.004920, mean_q: 0.009780
 68094/100000: episode: 9074, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000086, mae: 0.005065, mean_q: 0.009048
 68097/100000: episode: 9075, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000099, mae: 0.005375, mean_q: 0.008765
 68101/100000: episode: 9076, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001149, mae: 0.013692, mean_q: 0.021066
 68104/100000: episode: 9077, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001302, mae: 0.018289, mean_q: 0.033764
 68107/100000: episode: 9078, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000177, mae: 0.010392, mean_q: 0.007117
 68113/100000: episode: 9079, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000435, mae: 0.008563, mean_q: 0.009811
 68119/100000: episode: 9080, duration: 0.033s, episode steps: 6, steps per second: 184, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000866, mae: 0.012504, mean_q: 0.017451
 68122/100000: episode: 9081, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000484, mae: 0.012374, mean_q: 0.022606
 68125/100000: episode: 9082, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000240, mae: 0.006829, mean_q: 0.010643
 68128/100000: episode: 9083, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000077, mae: 0.005768, mean_q: 0.010678
 68134/100000: episode: 9084, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000557, mae: 0.011799, mean_q: 0.017512
 68137/100000: episode: 9085, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001556, mae: 0.016391, mean_q: 0.022661
 68140/100000: episode: 9086, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000888, mae: 0.015762, mean_q: 0.026714
 68143/100000: episode: 9087, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000175, mae: 0.010009, mean_q: 0.015809
 68146/100000: episode: 9088, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000996, mae: 0.015728, mean_q: 0.026566
 68149/100000: episode: 9089, duration: 0.020s, episode steps: 3, steps per second: 153, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000397, mae: 0.011969, mean_q: 0.023784
 68152/100000: episode: 9090, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000298, mae: 0.011775, mean_q: 0.035216
 68158/100000: episode: 9091, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000393, mae: 0.009844, mean_q: 0.021298
 68161/100000: episode: 9092, duration: 0.020s, episode steps: 3, steps per second: 152, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000410, mae: 0.010660, mean_q: 0.021028
 68167/100000: episode: 9093, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001088, mae: 0.014211, mean_q: 0.027434
 68170/100000: episode: 9094, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000246, mae: 0.008206, mean_q: 0.022898
 68173/100000: episode: 9095, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000212, mae: 0.007091, mean_q: 0.008167
 68176/100000: episode: 9096, duration: 0.020s, episode steps: 3, steps per second: 147, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000164, mae: 0.008310, mean_q: 0.009515
 68179/100000: episode: 9097, duration: 0.017s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000286, mae: 0.008306, mean_q: 0.012606
 68182/100000: episode: 9098, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000245, mae: 0.010716, mean_q: 0.017757
 68185/100000: episode: 9099, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000568, mae: 0.015419, mean_q: 0.031694
 68188/100000: episode: 9100, duration: 0.017s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001549, mae: 0.020781, mean_q: 0.033284
 68192/100000: episode: 9101, duration: 0.030s, episode steps: 4, steps per second: 132, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000168, mae: 0.008926, mean_q: 0.015255
 68196/100000: episode: 9102, duration: 0.042s, episode steps: 4, steps per second: 95, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000860, mae: 0.015291, mean_q: 0.026529
 68199/100000: episode: 9103, duration: 0.038s, episode steps: 3, steps per second: 78, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000098, mae: 0.007911, mean_q: 0.015028
 68205/100000: episode: 9104, duration: 0.067s, episode steps: 6, steps per second: 90, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000997, mae: 0.012910, mean_q: 0.022918
 68209/100000: episode: 9105, duration: 0.027s, episode steps: 4, steps per second: 146, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000162, mae: 0.008995, mean_q: 0.017419
 68212/100000: episode: 9106, duration: 0.020s, episode steps: 3, steps per second: 150, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000510, mae: 0.011217, mean_q: 0.017911
 68215/100000: episode: 9107, duration: 0.020s, episode steps: 3, steps per second: 152, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000179, mae: 0.009891, mean_q: 0.019980
 68219/100000: episode: 9108, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000557, mae: 0.012434, mean_q: 0.023878
 68222/100000: episode: 9109, duration: 0.021s, episode steps: 3, steps per second: 141, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000620, mae: 0.010233, mean_q: 0.021570
 68225/100000: episode: 9110, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000262, mae: 0.007071, mean_q: 0.020386
 68228/100000: episode: 9111, duration: 0.026s, episode steps: 3, steps per second: 116, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001247, mae: 0.017658, mean_q: 0.031816
 68231/100000: episode: 9112, duration: 0.020s, episode steps: 3, steps per second: 149, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001137, mae: 0.017375, mean_q: 0.020838
 68235/100000: episode: 9113, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001977, mae: 0.021675, mean_q: 0.026592
 68238/100000: episode: 9114, duration: 0.033s, episode steps: 3, steps per second: 90, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000244, mae: 0.008551, mean_q: 0.010886
 68241/100000: episode: 9115, duration: 0.032s, episode steps: 3, steps per second: 93, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000193, mae: 0.010143, mean_q: 0.016207
 68244/100000: episode: 9116, duration: 0.030s, episode steps: 3, steps per second: 101, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001935, mae: 0.024533, mean_q: 0.034848
 68248/100000: episode: 9117, duration: 0.037s, episode steps: 4, steps per second: 108, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000361, mae: 0.011587, mean_q: 0.019776
 68251/100000: episode: 9118, duration: 0.031s, episode steps: 3, steps per second: 98, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000183, mae: 0.010298, mean_q: 0.016019
 68254/100000: episode: 9119, duration: 0.025s, episode steps: 3, steps per second: 119, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000082, mae: 0.007343, mean_q: 0.013903
 68257/100000: episode: 9120, duration: 0.030s, episode steps: 3, steps per second: 99, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000444, mae: 0.012905, mean_q: 0.020114
 68260/100000: episode: 9121, duration: 0.023s, episode steps: 3, steps per second: 132, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001416, mae: 0.017509, mean_q: 0.031372
 68263/100000: episode: 9122, duration: 0.021s, episode steps: 3, steps per second: 144, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000199, mae: 0.010409, mean_q: 0.018515
 68267/100000: episode: 9123, duration: 0.044s, episode steps: 4, steps per second: 90, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000444, mae: 0.008748, mean_q: 0.012005
 68273/100000: episode: 9124, duration: 0.085s, episode steps: 6, steps per second: 71, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000565, mae: 0.013427, mean_q: 0.024449
 68277/100000: episode: 9125, duration: 0.049s, episode steps: 4, steps per second: 82, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000306, mae: 0.009413, mean_q: 0.016888
 68280/100000: episode: 9126, duration: 0.056s, episode steps: 3, steps per second: 54, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000372, mae: 0.010542, mean_q: 0.018026
 68283/100000: episode: 9127, duration: 0.055s, episode steps: 3, steps per second: 55, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000094, mae: 0.007507, mean_q: 0.018464
 68289/100000: episode: 9128, duration: 0.077s, episode steps: 6, steps per second: 78, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002054, mae: 0.016215, mean_q: 0.027401
 68293/100000: episode: 9129, duration: 0.044s, episode steps: 4, steps per second: 91, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001003, mae: 0.014690, mean_q: 0.031519
 68297/100000: episode: 9130, duration: 0.034s, episode steps: 4, steps per second: 117, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000081, mae: 0.006833, mean_q: 0.019480
 68301/100000: episode: 9131, duration: 0.028s, episode steps: 4, steps per second: 143, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001332, mae: 0.017557, mean_q: 0.033134
 68304/100000: episode: 9132, duration: 0.027s, episode steps: 3, steps per second: 110, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001453, mae: 0.013531, mean_q: 0.023587
 68307/100000: episode: 9133, duration: 0.024s, episode steps: 3, steps per second: 123, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000120, mae: 0.006973, mean_q: 0.008434
 68311/100000: episode: 9134, duration: 0.035s, episode steps: 4, steps per second: 114, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000374, mae: 0.011263, mean_q: 0.014520
 68314/100000: episode: 9135, duration: 0.026s, episode steps: 3, steps per second: 114, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000143, mae: 0.008341, mean_q: 0.012678
 68318/100000: episode: 9136, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000733, mae: 0.010737, mean_q: 0.020661
 68321/100000: episode: 9137, duration: 0.020s, episode steps: 3, steps per second: 151, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000098, mae: 0.005941, mean_q: 0.009224
 68324/100000: episode: 9138, duration: 0.022s, episode steps: 3, steps per second: 139, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000086, mae: 0.005430, mean_q: 0.007561
 68327/100000: episode: 9139, duration: 0.021s, episode steps: 3, steps per second: 146, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000375, mae: 0.008819, mean_q: 0.012376
 68330/100000: episode: 9140, duration: 0.025s, episode steps: 3, steps per second: 120, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000851, mae: 0.014596, mean_q: 0.027293
 68333/100000: episode: 9141, duration: 0.022s, episode steps: 3, steps per second: 138, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000778, mae: 0.009394, mean_q: 0.012709
 68336/100000: episode: 9142, duration: 0.020s, episode steps: 3, steps per second: 153, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000352, mae: 0.012887, mean_q: 0.027176
 68339/100000: episode: 9143, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000371, mae: 0.011364, mean_q: 0.018801
 68342/100000: episode: 9144, duration: 0.024s, episode steps: 3, steps per second: 125, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000341, mae: 0.012760, mean_q: 0.020604
 68345/100000: episode: 9145, duration: 0.039s, episode steps: 3, steps per second: 76, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000613, mae: 0.008432, mean_q: 0.012671
 68348/100000: episode: 9146, duration: 0.032s, episode steps: 3, steps per second: 95, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000708, mae: 0.009858, mean_q: 0.020748
 68351/100000: episode: 9147, duration: 0.026s, episode steps: 3, steps per second: 115, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000624, mae: 0.010653, mean_q: 0.011397
 68354/100000: episode: 9148, duration: 0.025s, episode steps: 3, steps per second: 118, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000667, mae: 0.014872, mean_q: 0.018064
 68357/100000: episode: 9149, duration: 0.025s, episode steps: 3, steps per second: 118, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000886, mae: 0.013837, mean_q: 0.030230
 68360/100000: episode: 9150, duration: 0.022s, episode steps: 3, steps per second: 136, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000457, mae: 0.014425, mean_q: 0.031760
 68363/100000: episode: 9151, duration: 0.038s, episode steps: 3, steps per second: 80, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000769, mae: 0.012645, mean_q: 0.021500
 68366/100000: episode: 9152, duration: 0.034s, episode steps: 3, steps per second: 88, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000343, mae: 0.012069, mean_q: 0.022137
 68370/100000: episode: 9153, duration: 0.037s, episode steps: 4, steps per second: 108, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000576, mae: 0.011041, mean_q: 0.015507
 68374/100000: episode: 9154, duration: 0.040s, episode steps: 4, steps per second: 100, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000480, mae: 0.008389, mean_q: 0.013499
 68377/100000: episode: 9155, duration: 0.042s, episode steps: 3, steps per second: 72, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000818, mae: 0.012542, mean_q: 0.025800
[Info] 2-TH LEVEL FOUND: 0.06805911660194397, Considering 25/100 traces
 68383/100000: episode: 9156, duration: 1.127s, episode steps: 6, steps per second: 5, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000695, mae: 0.011946, mean_q: 0.018159
 68387/100000: episode: 9157, duration: 0.033s, episode steps: 4, steps per second: 120, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000847, mae: 0.012235, mean_q: 0.018491
 68391/100000: episode: 9158, duration: 0.032s, episode steps: 4, steps per second: 123, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000480, mae: 0.008124, mean_q: 0.012016
 68395/100000: episode: 9159, duration: 0.033s, episode steps: 4, steps per second: 121, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000685, mae: 0.010874, mean_q: 0.020667
 68399/100000: episode: 9160, duration: 0.032s, episode steps: 4, steps per second: 124, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001948, mae: 0.015150, mean_q: 0.017623
 68403/100000: episode: 9161, duration: 0.025s, episode steps: 4, steps per second: 163, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000324, mae: 0.008514, mean_q: 0.019016
 68407/100000: episode: 9162, duration: 0.033s, episode steps: 4, steps per second: 123, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000198, mae: 0.010458, mean_q: 0.016092
 68411/100000: episode: 9163, duration: 0.031s, episode steps: 4, steps per second: 129, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001419, mae: 0.012939, mean_q: 0.024297
 68415/100000: episode: 9164, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000792, mae: 0.010731, mean_q: 0.017916
 68419/100000: episode: 9165, duration: 0.026s, episode steps: 4, steps per second: 153, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000789, mae: 0.013575, mean_q: 0.019516
 68423/100000: episode: 9166, duration: 0.030s, episode steps: 4, steps per second: 134, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000237, mae: 0.008387, mean_q: 0.016149
 68427/100000: episode: 9167, duration: 0.034s, episode steps: 4, steps per second: 116, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000557, mae: 0.013834, mean_q: 0.029378
 68431/100000: episode: 9168, duration: 0.035s, episode steps: 4, steps per second: 114, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000441, mae: 0.010307, mean_q: 0.013998
 68436/100000: episode: 9169, duration: 0.033s, episode steps: 5, steps per second: 152, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000479, mae: 0.009442, mean_q: 0.013800
 68440/100000: episode: 9170, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000496, mae: 0.014473, mean_q: 0.023705
 68445/100000: episode: 9171, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000889, mae: 0.015949, mean_q: 0.036754
 68449/100000: episode: 9172, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000416, mae: 0.011638, mean_q: 0.024980
 68453/100000: episode: 9173, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000632, mae: 0.013605, mean_q: 0.023952
 68457/100000: episode: 9174, duration: 0.026s, episode steps: 4, steps per second: 156, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000885, mae: 0.012893, mean_q: 0.024262
 68461/100000: episode: 9175, duration: 0.034s, episode steps: 4, steps per second: 117, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000697, mae: 0.013890, mean_q: 0.020066
 68465/100000: episode: 9176, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000147, mae: 0.008181, mean_q: 0.013650
 68470/100000: episode: 9177, duration: 0.039s, episode steps: 5, steps per second: 129, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000518, mae: 0.011544, mean_q: 0.016691
 68474/100000: episode: 9178, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000864, mae: 0.014596, mean_q: 0.024196
 68478/100000: episode: 9179, duration: 0.033s, episode steps: 4, steps per second: 121, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000248, mae: 0.010510, mean_q: 0.027421
 68482/100000: episode: 9180, duration: 0.025s, episode steps: 4, steps per second: 161, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001417, mae: 0.015517, mean_q: 0.028597
 68486/100000: episode: 9181, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000827, mae: 0.010227, mean_q: 0.017060
 68491/100000: episode: 9182, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000246, mae: 0.007348, mean_q: 0.012169
 68495/100000: episode: 9183, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000299, mae: 0.008184, mean_q: 0.014207
 68500/100000: episode: 9184, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001522, mae: 0.014572, mean_q: 0.023437
 68505/100000: episode: 9185, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000829, mae: 0.012684, mean_q: 0.027776
 68509/100000: episode: 9186, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000796, mae: 0.013115, mean_q: 0.030027
 68513/100000: episode: 9187, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001210, mae: 0.020334, mean_q: 0.042132
 68517/100000: episode: 9188, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000112, mae: 0.006826, mean_q: 0.012437
 68521/100000: episode: 9189, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001142, mae: 0.018945, mean_q: 0.031918
 68526/100000: episode: 9190, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000463, mae: 0.013288, mean_q: 0.014262
 68530/100000: episode: 9191, duration: 0.025s, episode steps: 4, steps per second: 158, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000660, mae: 0.014051, mean_q: 0.012387
 68534/100000: episode: 9192, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001048, mae: 0.016716, mean_q: 0.022474
 68538/100000: episode: 9193, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001536, mae: 0.017506, mean_q: 0.025970
 68542/100000: episode: 9194, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001038, mae: 0.016346, mean_q: 0.024686
 68546/100000: episode: 9195, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001286, mae: 0.018565, mean_q: 0.032601
 68550/100000: episode: 9196, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000381, mae: 0.011638, mean_q: 0.019665
 68554/100000: episode: 9197, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000346, mae: 0.013392, mean_q: 0.027770
 68558/100000: episode: 9198, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000061, mae: 0.007005, mean_q: 0.014215
 68562/100000: episode: 9199, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001620, mae: 0.020702, mean_q: 0.042326
 68566/100000: episode: 9200, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000846, mae: 0.011182, mean_q: 0.016295
 68570/100000: episode: 9201, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000468, mae: 0.010032, mean_q: 0.017945
 68574/100000: episode: 9202, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000663, mae: 0.013185, mean_q: 0.020475
 68578/100000: episode: 9203, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000652, mae: 0.009253, mean_q: 0.015238
 68582/100000: episode: 9204, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000309, mae: 0.011124, mean_q: 0.018182
 68586/100000: episode: 9205, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001103, mae: 0.013153, mean_q: 0.020643
 68590/100000: episode: 9206, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001668, mae: 0.017362, mean_q: 0.028648
 68594/100000: episode: 9207, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000102, mae: 0.006568, mean_q: 0.011588
 68599/100000: episode: 9208, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000762, mae: 0.012613, mean_q: 0.018617
 68604/100000: episode: 9209, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000245, mae: 0.009580, mean_q: 0.022649
 68608/100000: episode: 9210, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000647, mae: 0.012589, mean_q: 0.021546
 68612/100000: episode: 9211, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001141, mae: 0.015938, mean_q: 0.034053
 68616/100000: episode: 9212, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000176, mae: 0.010078, mean_q: 0.023266
 68621/100000: episode: 9213, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000295, mae: 0.011056, mean_q: 0.017085
 68625/100000: episode: 9214, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000293, mae: 0.011488, mean_q: 0.024429
 68629/100000: episode: 9215, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000780, mae: 0.011951, mean_q: 0.024577
 68633/100000: episode: 9216, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000560, mae: 0.010919, mean_q: 0.020688
 68637/100000: episode: 9217, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000705, mae: 0.011543, mean_q: 0.021343
 68641/100000: episode: 9218, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000345, mae: 0.008890, mean_q: 0.020504
 68645/100000: episode: 9219, duration: 0.024s, episode steps: 4, steps per second: 166, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000721, mae: 0.015576, mean_q: 0.029760
 68649/100000: episode: 9220, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000424, mae: 0.009971, mean_q: 0.020867
 68653/100000: episode: 9221, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000607, mae: 0.013543, mean_q: 0.028183
 68657/100000: episode: 9222, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001748, mae: 0.016657, mean_q: 0.034577
 68661/100000: episode: 9223, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000280, mae: 0.008394, mean_q: 0.012449
 68666/100000: episode: 9224, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000915, mae: 0.016456, mean_q: 0.015147
 68670/100000: episode: 9225, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000388, mae: 0.011822, mean_q: 0.014694
 68674/100000: episode: 9226, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000147, mae: 0.008265, mean_q: 0.013162
 68679/100000: episode: 9227, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001415, mae: 0.017087, mean_q: 0.027279
 68683/100000: episode: 9228, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001035, mae: 0.015318, mean_q: 0.031713
 68687/100000: episode: 9229, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000305, mae: 0.009552, mean_q: 0.019948
 68691/100000: episode: 9230, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000321, mae: 0.010922, mean_q: 0.016817
[Info] 3-TH LEVEL FOUND: 0.11204289644956589, Considering 16/100 traces
 68695/100000: episode: 9231, duration: 0.807s, episode steps: 4, steps per second: 5, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000216, mae: 0.011750, mean_q: 0.020424
 68700/100000: episode: 9232, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001183, mae: 0.016862, mean_q: 0.029611
 68705/100000: episode: 9233, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000671, mae: 0.012720, mean_q: 0.024507
 68710/100000: episode: 9234, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000307, mae: 0.009947, mean_q: 0.015566
 68715/100000: episode: 9235, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000244, mae: 0.010202, mean_q: 0.022513
 68720/100000: episode: 9236, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.003135, mae: 0.018576, mean_q: 0.024604
 68725/100000: episode: 9237, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000602, mae: 0.013002, mean_q: 0.021428
[Info] FALSIFICATION!
 68729/100000: episode: 9238, duration: 0.281s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001136, mae: 0.013951, mean_q: 0.029465
 68734/100000: episode: 9239, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001318, mae: 0.017017, mean_q: 0.026431
 68739/100000: episode: 9240, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001112, mae: 0.013979, mean_q: 0.025018
 68744/100000: episode: 9241, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000170, mae: 0.010111, mean_q: 0.018036
 68749/100000: episode: 9242, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000151, mae: 0.009912, mean_q: 0.014694
 68754/100000: episode: 9243, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000423, mae: 0.012714, mean_q: 0.019987
[Info] FALSIFICATION!
 68758/100000: episode: 9244, duration: 0.285s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000221, mae: 0.009628, mean_q: 0.019098
 68763/100000: episode: 9245, duration: 0.030s, episode steps: 5, steps per second: 168, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002006, mae: 0.016734, mean_q: 0.021473
 68768/100000: episode: 9246, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000732, mae: 0.012008, mean_q: 0.023311
 68773/100000: episode: 9247, duration: 0.029s, episode steps: 5, steps per second: 171, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000214, mae: 0.010228, mean_q: 0.016773
 68778/100000: episode: 9248, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000300, mae: 0.011682, mean_q: 0.021879
 68783/100000: episode: 9249, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000434, mae: 0.013672, mean_q: 0.027886
 68788/100000: episode: 9250, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001290, mae: 0.015583, mean_q: 0.027604
 68793/100000: episode: 9251, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001438, mae: 0.018321, mean_q: 0.027750
 68798/100000: episode: 9252, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000455, mae: 0.012436, mean_q: 0.025772
 68803/100000: episode: 9253, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000627, mae: 0.014859, mean_q: 0.019420
 68808/100000: episode: 9254, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000182, mae: 0.010456, mean_q: 0.021238
 68813/100000: episode: 9255, duration: 0.029s, episode steps: 5, steps per second: 173, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000477, mae: 0.010935, mean_q: 0.022607
 68818/100000: episode: 9256, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001180, mae: 0.015306, mean_q: 0.025742
 68823/100000: episode: 9257, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000838, mae: 0.014305, mean_q: 0.028032
 68828/100000: episode: 9258, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000664, mae: 0.013213, mean_q: 0.024861
 68833/100000: episode: 9259, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000434, mae: 0.012780, mean_q: 0.023642
 68838/100000: episode: 9260, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000293, mae: 0.010920, mean_q: 0.018820
 68843/100000: episode: 9261, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000598, mae: 0.011829, mean_q: 0.023724
 68848/100000: episode: 9262, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000259, mae: 0.012212, mean_q: 0.027064
 68853/100000: episode: 9263, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000829, mae: 0.014661, mean_q: 0.028942
 68858/100000: episode: 9264, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000893, mae: 0.014372, mean_q: 0.031333
 68863/100000: episode: 9265, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000265, mae: 0.010544, mean_q: 0.024399
[Info] FALSIFICATION!
 68867/100000: episode: 9266, duration: 0.210s, episode steps: 4, steps per second: 19, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000766, mae: 0.012675, mean_q: 0.029278
 68872/100000: episode: 9267, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000757, mae: 0.015804, mean_q: 0.038276
 68877/100000: episode: 9268, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000907, mae: 0.016191, mean_q: 0.028548
 68882/100000: episode: 9269, duration: 0.031s, episode steps: 5, steps per second: 160, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001187, mae: 0.016258, mean_q: 0.031117
 68887/100000: episode: 9270, duration: 0.035s, episode steps: 5, steps per second: 142, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000686, mae: 0.012592, mean_q: 0.016519
[Info] FALSIFICATION!
 68891/100000: episode: 9271, duration: 0.222s, episode steps: 4, steps per second: 18, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000413, mae: 0.014967, mean_q: 0.028114
 68896/100000: episode: 9272, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000568, mae: 0.014810, mean_q: 0.033289
 68901/100000: episode: 9273, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001158, mae: 0.019279, mean_q: 0.035675
 68906/100000: episode: 9274, duration: 0.035s, episode steps: 5, steps per second: 145, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001286, mae: 0.017835, mean_q: 0.030981
 68911/100000: episode: 9275, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001005, mae: 0.017946, mean_q: 0.029120
 68916/100000: episode: 9276, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001651, mae: 0.021219, mean_q: 0.037675
 68921/100000: episode: 9277, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000662, mae: 0.015713, mean_q: 0.026703
 68926/100000: episode: 9278, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001585, mae: 0.020232, mean_q: 0.030103
 68931/100000: episode: 9279, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.002971, mae: 0.019736, mean_q: 0.028965
 68936/100000: episode: 9280, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000552, mae: 0.014507, mean_q: 0.028392
 68941/100000: episode: 9281, duration: 0.031s, episode steps: 5, steps per second: 160, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000743, mae: 0.017458, mean_q: 0.025486
 68946/100000: episode: 9282, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001681, mae: 0.024552, mean_q: 0.046770
 68951/100000: episode: 9283, duration: 0.028s, episode steps: 5, steps per second: 176, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000878, mae: 0.019330, mean_q: 0.037899
 68956/100000: episode: 9284, duration: 0.033s, episode steps: 5, steps per second: 153, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001021, mae: 0.014973, mean_q: 0.027516
 68961/100000: episode: 9285, duration: 0.029s, episode steps: 5, steps per second: 171, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001119, mae: 0.018914, mean_q: 0.021397
 68966/100000: episode: 9286, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000806, mae: 0.014937, mean_q: 0.023128
 68971/100000: episode: 9287, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001668, mae: 0.020075, mean_q: 0.033790
 68976/100000: episode: 9288, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001134, mae: 0.017444, mean_q: 0.038231
 68981/100000: episode: 9289, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000729, mae: 0.016194, mean_q: 0.028493
 68986/100000: episode: 9290, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000649, mae: 0.014958, mean_q: 0.024313
 68991/100000: episode: 9291, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000819, mae: 0.016486, mean_q: 0.022150
 68996/100000: episode: 9292, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000859, mae: 0.014589, mean_q: 0.022878
 69001/100000: episode: 9293, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000321, mae: 0.012818, mean_q: 0.022738
 69006/100000: episode: 9294, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001047, mae: 0.019007, mean_q: 0.036586
 69011/100000: episode: 9295, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001070, mae: 0.017351, mean_q: 0.032445
 69016/100000: episode: 9296, duration: 0.031s, episode steps: 5, steps per second: 163, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000931, mae: 0.017032, mean_q: 0.034820
 69021/100000: episode: 9297, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000818, mae: 0.016851, mean_q: 0.040165
 69026/100000: episode: 9298, duration: 0.033s, episode steps: 5, steps per second: 152, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001206, mae: 0.015815, mean_q: 0.026943
 69031/100000: episode: 9299, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000951, mae: 0.014516, mean_q: 0.028445
 69036/100000: episode: 9300, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001930, mae: 0.021431, mean_q: 0.035395
 69041/100000: episode: 9301, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000756, mae: 0.016303, mean_q: 0.025790
 69046/100000: episode: 9302, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000856, mae: 0.014746, mean_q: 0.023154
 69051/100000: episode: 9303, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001597, mae: 0.018316, mean_q: 0.040147
 69056/100000: episode: 9304, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.002233, mae: 0.022681, mean_q: 0.038639
 69061/100000: episode: 9305, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000720, mae: 0.013904, mean_q: 0.028404
 69066/100000: episode: 9306, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000293, mae: 0.010583, mean_q: 0.012404
 69071/100000: episode: 9307, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001862, mae: 0.021411, mean_q: 0.030118
 69076/100000: episode: 9308, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001584, mae: 0.022208, mean_q: 0.033018
 69081/100000: episode: 9309, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001434, mae: 0.022891, mean_q: 0.038763
 69086/100000: episode: 9310, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000968, mae: 0.019468, mean_q: 0.037976
 69091/100000: episode: 9311, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001596, mae: 0.021176, mean_q: 0.042807
 69096/100000: episode: 9312, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001514, mae: 0.019069, mean_q: 0.034904
 69101/100000: episode: 9313, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002050, mae: 0.026290, mean_q: 0.040118
 69106/100000: episode: 9314, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000735, mae: 0.016608, mean_q: 0.036608
[Info] Complete ISplit Iteration
[Info] Levels: [0.0380112, 0.06805912, 0.1120429, 1.280665]
[Info] Cond. Prob: [0.1, 0.25, 0.16, 0.08]
[Info] Error Prob: 0.00032

 69111/100000: episode: 9315, duration: 0.859s, episode steps: 5, steps per second: 6, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001208, mae: 0.017890, mean_q: 0.033405
 69121/100000: episode: 9316, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001493, mae: 0.019195, mean_q: 0.033136
 69131/100000: episode: 9317, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000900, mae: 0.016633, mean_q: 0.031983
 69141/100000: episode: 9318, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001868, mae: 0.017664, mean_q: 0.026828
 69151/100000: episode: 9319, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000955, mae: 0.019254, mean_q: 0.033938
 69161/100000: episode: 9320, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.001079, mae: 0.017008, mean_q: 0.035337
 69171/100000: episode: 9321, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001701, mae: 0.020167, mean_q: 0.028775
 69181/100000: episode: 9322, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000778, mae: 0.015345, mean_q: 0.030875
 69191/100000: episode: 9323, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001054, mae: 0.017212, mean_q: 0.029808
 69201/100000: episode: 9324, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000774, mae: 0.016866, mean_q: 0.030064
 69211/100000: episode: 9325, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001456, mae: 0.019676, mean_q: 0.038250
 69221/100000: episode: 9326, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000862, mae: 0.015737, mean_q: 0.031116
 69231/100000: episode: 9327, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000870, mae: 0.015527, mean_q: 0.022118
 69241/100000: episode: 9328, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001258, mae: 0.019820, mean_q: 0.030508
 69251/100000: episode: 9329, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000625, mae: 0.015046, mean_q: 0.028178
 69261/100000: episode: 9330, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001329, mae: 0.019837, mean_q: 0.039874
 69271/100000: episode: 9331, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001390, mae: 0.019361, mean_q: 0.036205
 69281/100000: episode: 9332, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001491, mae: 0.020349, mean_q: 0.038033
 69291/100000: episode: 9333, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001460, mae: 0.019132, mean_q: 0.039249
 69301/100000: episode: 9334, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.001072, mae: 0.016121, mean_q: 0.025337
 69311/100000: episode: 9335, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001128, mae: 0.018192, mean_q: 0.039085
 69321/100000: episode: 9336, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001029, mae: 0.019793, mean_q: 0.037611
 69331/100000: episode: 9337, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001130, mae: 0.017014, mean_q: 0.028198
 69341/100000: episode: 9338, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002191, mae: 0.021787, mean_q: 0.044808
 69351/100000: episode: 9339, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001064, mae: 0.017464, mean_q: 0.029120
 69361/100000: episode: 9340, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.003108, mae: 0.021261, mean_q: 0.022844
 69371/100000: episode: 9341, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001274, mae: 0.018353, mean_q: 0.029379
 69381/100000: episode: 9342, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001083, mae: 0.017305, mean_q: 0.032950
 69391/100000: episode: 9343, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000968, mae: 0.016340, mean_q: 0.031668
 69401/100000: episode: 9344, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000914, mae: 0.013995, mean_q: 0.026272
 69411/100000: episode: 9345, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.001565, mae: 0.016608, mean_q: 0.025039
 69421/100000: episode: 9346, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001761, mae: 0.021941, mean_q: 0.037440
 69431/100000: episode: 9347, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000907, mae: 0.014200, mean_q: 0.030420
 69441/100000: episode: 9348, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001175, mae: 0.015497, mean_q: 0.022991
 69451/100000: episode: 9349, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000874, mae: 0.015331, mean_q: 0.031397
 69461/100000: episode: 9350, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000502, mae: 0.011133, mean_q: 0.022875
 69471/100000: episode: 9351, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000472, mae: 0.011553, mean_q: 0.020264
 69481/100000: episode: 9352, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001170, mae: 0.019936, mean_q: 0.032276
 69491/100000: episode: 9353, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000686, mae: 0.015503, mean_q: 0.032933
 69501/100000: episode: 9354, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001010, mae: 0.016211, mean_q: 0.036930
 69511/100000: episode: 9355, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000920, mae: 0.015517, mean_q: 0.024635
 69521/100000: episode: 9356, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000751, mae: 0.012948, mean_q: 0.019604
 69531/100000: episode: 9357, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000404, mae: 0.010994, mean_q: 0.020732
 69541/100000: episode: 9358, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000439, mae: 0.011301, mean_q: 0.019007
 69551/100000: episode: 9359, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000629, mae: 0.012567, mean_q: 0.022014
 69561/100000: episode: 9360, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000306, mae: 0.011255, mean_q: 0.021928
 69571/100000: episode: 9361, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000719, mae: 0.011123, mean_q: 0.019422
 69581/100000: episode: 9362, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000754, mae: 0.014941, mean_q: 0.031885
 69591/100000: episode: 9363, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000291, mae: 0.010397, mean_q: 0.019457
 69601/100000: episode: 9364, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000771, mae: 0.013113, mean_q: 0.024583
 69611/100000: episode: 9365, duration: 0.060s, episode steps: 10, steps per second: 165, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001311, mae: 0.014915, mean_q: 0.030442
 69621/100000: episode: 9366, duration: 0.093s, episode steps: 10, steps per second: 108, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000961, mae: 0.013883, mean_q: 0.026105
 69631/100000: episode: 9367, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000725, mae: 0.011701, mean_q: 0.021157
 69641/100000: episode: 9368, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001217, mae: 0.018849, mean_q: 0.026886
 69651/100000: episode: 9369, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001004, mae: 0.016381, mean_q: 0.018864
 69661/100000: episode: 9370, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000325, mae: 0.013791, mean_q: 0.024937
 69671/100000: episode: 9371, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000519, mae: 0.013269, mean_q: 0.021024
 69681/100000: episode: 9372, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001801, mae: 0.013819, mean_q: 0.018940
 69691/100000: episode: 9373, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000270, mae: 0.011087, mean_q: 0.017483
 69701/100000: episode: 9374, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000197, mae: 0.010730, mean_q: 0.021684
 69711/100000: episode: 9375, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000162, mae: 0.009093, mean_q: 0.017959
 69721/100000: episode: 9376, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001470, mae: 0.014682, mean_q: 0.020773
 69731/100000: episode: 9377, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002473, mae: 0.023649, mean_q: 0.037766
 69741/100000: episode: 9378, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000564, mae: 0.013380, mean_q: 0.020388
 69751/100000: episode: 9379, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001260, mae: 0.017072, mean_q: 0.020095
 69761/100000: episode: 9380, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000658, mae: 0.012052, mean_q: 0.020675
 69771/100000: episode: 9381, duration: 0.128s, episode steps: 10, steps per second: 78, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000246, mae: 0.010241, mean_q: 0.019951
 69781/100000: episode: 9382, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000403, mae: 0.010145, mean_q: 0.020815
 69791/100000: episode: 9383, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001498, mae: 0.017380, mean_q: 0.033318
 69801/100000: episode: 9384, duration: 0.070s, episode steps: 10, steps per second: 144, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000632, mae: 0.013125, mean_q: 0.026679
 69811/100000: episode: 9385, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000447, mae: 0.009470, mean_q: 0.018127
 69821/100000: episode: 9386, duration: 0.071s, episode steps: 10, steps per second: 142, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001118, mae: 0.014403, mean_q: 0.027647
 69831/100000: episode: 9387, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000631, mae: 0.013738, mean_q: 0.026963
 69841/100000: episode: 9388, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000818, mae: 0.015419, mean_q: 0.029691
 69851/100000: episode: 9389, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001118, mae: 0.015482, mean_q: 0.025737
 69861/100000: episode: 9390, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000385, mae: 0.010298, mean_q: 0.020172
 69871/100000: episode: 9391, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000231, mae: 0.008394, mean_q: 0.013411
 69881/100000: episode: 9392, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000817, mae: 0.012308, mean_q: 0.024261
 69891/100000: episode: 9393, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000974, mae: 0.012959, mean_q: 0.023848
 69901/100000: episode: 9394, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000858, mae: 0.014012, mean_q: 0.028787
 69911/100000: episode: 9395, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000771, mae: 0.012885, mean_q: 0.026173
 69921/100000: episode: 9396, duration: 0.092s, episode steps: 10, steps per second: 108, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001254, mae: 0.017034, mean_q: 0.028740
 69931/100000: episode: 9397, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000501, mae: 0.009913, mean_q: 0.018004
 69941/100000: episode: 9398, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000998, mae: 0.015674, mean_q: 0.027472
 69951/100000: episode: 9399, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000697, mae: 0.012775, mean_q: 0.023102
 69961/100000: episode: 9400, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000637, mae: 0.010536, mean_q: 0.021335
 69971/100000: episode: 9401, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000820, mae: 0.014008, mean_q: 0.023877
 69981/100000: episode: 9402, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000447, mae: 0.010155, mean_q: 0.020429
 69991/100000: episode: 9403, duration: 0.099s, episode steps: 10, steps per second: 102, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000338, mae: 0.009749, mean_q: 0.018582
 70001/100000: episode: 9404, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000842, mae: 0.012048, mean_q: 0.020291
 70011/100000: episode: 9405, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000554, mae: 0.012403, mean_q: 0.029768
 70021/100000: episode: 9406, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000972, mae: 0.013751, mean_q: 0.030677
 70031/100000: episode: 9407, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000787, mae: 0.014943, mean_q: 0.037022
 70041/100000: episode: 9408, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000664, mae: 0.013254, mean_q: 0.025631
 70051/100000: episode: 9409, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000361, mae: 0.010429, mean_q: 0.021215
 70061/100000: episode: 9410, duration: 0.098s, episode steps: 10, steps per second: 102, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001160, mae: 0.016228, mean_q: 0.028004
 70071/100000: episode: 9411, duration: 0.070s, episode steps: 10, steps per second: 144, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000722, mae: 0.013581, mean_q: 0.025598
 70081/100000: episode: 9412, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000622, mae: 0.013125, mean_q: 0.021244
 70091/100000: episode: 9413, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001129, mae: 0.013532, mean_q: 0.023095
 70101/100000: episode: 9414, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002943, mae: 0.022638, mean_q: 0.035428
[Info] 1-TH LEVEL FOUND: 0.02296900749206543, Considering 11/100 traces
 70111/100000: episode: 9415, duration: 0.753s, episode steps: 10, steps per second: 13, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000761, mae: 0.013215, mean_q: 0.022912
 70114/100000: episode: 9416, duration: 0.020s, episode steps: 3, steps per second: 153, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000851, mae: 0.014084, mean_q: 0.014509
 70117/100000: episode: 9417, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000895, mae: 0.020475, mean_q: 0.038379
 70120/100000: episode: 9418, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001928, mae: 0.020817, mean_q: 0.020035
 70123/100000: episode: 9419, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000786, mae: 0.015509, mean_q: 0.026152
 70126/100000: episode: 9420, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000857, mae: 0.009782, mean_q: 0.012712
 70129/100000: episode: 9421, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000299, mae: 0.008915, mean_q: 0.014279
 70132/100000: episode: 9422, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001553, mae: 0.015805, mean_q: 0.023741
 70136/100000: episode: 9423, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000724, mae: 0.013634, mean_q: 0.025879
 70139/100000: episode: 9424, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001758, mae: 0.021485, mean_q: 0.035843
 70142/100000: episode: 9425, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000316, mae: 0.010310, mean_q: 0.017243
 70145/100000: episode: 9426, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000294, mae: 0.009439, mean_q: 0.016521
 70148/100000: episode: 9427, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001390, mae: 0.014873, mean_q: 0.030498
 70152/100000: episode: 9428, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000518, mae: 0.011427, mean_q: 0.020522
 70158/100000: episode: 9429, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000648, mae: 0.010908, mean_q: 0.015440
 70161/100000: episode: 9430, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000269, mae: 0.010208, mean_q: 0.022897
 70164/100000: episode: 9431, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001823, mae: 0.016351, mean_q: 0.025223
 70167/100000: episode: 9432, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000544, mae: 0.013210, mean_q: 0.025972
 70171/100000: episode: 9433, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000372, mae: 0.011441, mean_q: 0.016528
 70174/100000: episode: 9434, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000420, mae: 0.014512, mean_q: 0.038570
 70177/100000: episode: 9435, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000289, mae: 0.010762, mean_q: 0.028062
 70180/100000: episode: 9436, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000911, mae: 0.014159, mean_q: 0.024810
 70183/100000: episode: 9437, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000185, mae: 0.010808, mean_q: 0.022087
 70187/100000: episode: 9438, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001572, mae: 0.018063, mean_q: 0.037944
 70190/100000: episode: 9439, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000643, mae: 0.013030, mean_q: 0.017900
 70193/100000: episode: 9440, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001531, mae: 0.021893, mean_q: 0.039974
 70196/100000: episode: 9441, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000630, mae: 0.012480, mean_q: 0.027016
 70199/100000: episode: 9442, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000252, mae: 0.009736, mean_q: 0.021336
 70202/100000: episode: 9443, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000187, mae: 0.010937, mean_q: 0.034835
 70206/100000: episode: 9444, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001328, mae: 0.014721, mean_q: 0.023569
 70210/100000: episode: 9445, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001759, mae: 0.022035, mean_q: 0.055445
 70213/100000: episode: 9446, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000566, mae: 0.010706, mean_q: 0.022032
 70217/100000: episode: 9447, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000353, mae: 0.010126, mean_q: 0.014819
 70220/100000: episode: 9448, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000943, mae: 0.012075, mean_q: 0.024712
 70223/100000: episode: 9449, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000161, mae: 0.008885, mean_q: 0.016706
 70227/100000: episode: 9450, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000665, mae: 0.011422, mean_q: 0.022185
 70231/100000: episode: 9451, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001011, mae: 0.011279, mean_q: 0.023553
 70234/100000: episode: 9452, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000428, mae: 0.012239, mean_q: 0.022618
 70237/100000: episode: 9453, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001723, mae: 0.020156, mean_q: 0.032313
 70240/100000: episode: 9454, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000930, mae: 0.017189, mean_q: 0.028124
 70243/100000: episode: 9455, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001026, mae: 0.017590, mean_q: 0.030895
 70247/100000: episode: 9456, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000833, mae: 0.012912, mean_q: 0.023303
 70250/100000: episode: 9457, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000666, mae: 0.012694, mean_q: 0.025006
 70253/100000: episode: 9458, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000391, mae: 0.010875, mean_q: 0.019816
 70257/100000: episode: 9459, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000552, mae: 0.013766, mean_q: 0.034668
 70261/100000: episode: 9460, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000816, mae: 0.014374, mean_q: 0.023849
 70264/100000: episode: 9461, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000419, mae: 0.012325, mean_q: 0.022532
 70267/100000: episode: 9462, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000356, mae: 0.011963, mean_q: 0.029221
 70271/100000: episode: 9463, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001644, mae: 0.020188, mean_q: 0.039695
 70275/100000: episode: 9464, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000571, mae: 0.010922, mean_q: 0.017754
 70278/100000: episode: 9465, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000777, mae: 0.013860, mean_q: 0.027694
 70281/100000: episode: 9466, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001649, mae: 0.021200, mean_q: 0.033656
 70285/100000: episode: 9467, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000877, mae: 0.014632, mean_q: 0.027898
 70288/100000: episode: 9468, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000782, mae: 0.014682, mean_q: 0.044388
 70292/100000: episode: 9469, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000360, mae: 0.011090, mean_q: 0.023358
 70295/100000: episode: 9470, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000780, mae: 0.014344, mean_q: 0.027458
 70299/100000: episode: 9471, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001264, mae: 0.015324, mean_q: 0.036948
 70302/100000: episode: 9472, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000417, mae: 0.010607, mean_q: 0.026689
 70306/100000: episode: 9473, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000270, mae: 0.010275, mean_q: 0.016105
 70309/100000: episode: 9474, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000827, mae: 0.013772, mean_q: 0.020720
 70313/100000: episode: 9475, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000448, mae: 0.012823, mean_q: 0.023349
 70316/100000: episode: 9476, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000625, mae: 0.013667, mean_q: 0.023183
 70322/100000: episode: 9477, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000404, mae: 0.011363, mean_q: 0.025906
 70325/100000: episode: 9478, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000466, mae: 0.010466, mean_q: 0.022338
 70328/100000: episode: 9479, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003231, mae: 0.028996, mean_q: 0.050478
 70332/100000: episode: 9480, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000483, mae: 0.014459, mean_q: 0.026161
 70338/100000: episode: 9481, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000902, mae: 0.012828, mean_q: 0.024306
 70342/100000: episode: 9482, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001272, mae: 0.015900, mean_q: 0.024204
 70348/100000: episode: 9483, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000837, mae: 0.011375, mean_q: 0.020094
 70351/100000: episode: 9484, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000600, mae: 0.010131, mean_q: 0.019420
 70354/100000: episode: 9485, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001354, mae: 0.015512, mean_q: 0.030320
 70357/100000: episode: 9486, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000125, mae: 0.007924, mean_q: 0.014533
 70361/100000: episode: 9487, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001525, mae: 0.018633, mean_q: 0.040360
 70364/100000: episode: 9488, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001023, mae: 0.014829, mean_q: 0.029174
 70367/100000: episode: 9489, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000485, mae: 0.011767, mean_q: 0.023919
 70370/100000: episode: 9490, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000142, mae: 0.008752, mean_q: 0.012477
 70373/100000: episode: 9491, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000653, mae: 0.013627, mean_q: 0.016052
 70377/100000: episode: 9492, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000223, mae: 0.008656, mean_q: 0.013211
 70381/100000: episode: 9493, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001026, mae: 0.012467, mean_q: 0.019510
 70384/100000: episode: 9494, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000431, mae: 0.013515, mean_q: 0.039470
 70387/100000: episode: 9495, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001479, mae: 0.017954, mean_q: 0.029598
 70390/100000: episode: 9496, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001516, mae: 0.017448, mean_q: 0.032351
 70393/100000: episode: 9497, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001737, mae: 0.017004, mean_q: 0.032013
 70396/100000: episode: 9498, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000464, mae: 0.013108, mean_q: 0.029209
 70399/100000: episode: 9499, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000166, mae: 0.009747, mean_q: 0.021316
 70402/100000: episode: 9500, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000413, mae: 0.012256, mean_q: 0.022554
 70408/100000: episode: 9501, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001177, mae: 0.016489, mean_q: 0.030746
 70411/100000: episode: 9502, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000472, mae: 0.012804, mean_q: 0.037155
 70415/100000: episode: 9503, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000633, mae: 0.014822, mean_q: 0.034064
[Info] 2-TH LEVEL FOUND: 0.07370525598526001, Considering 14/100 traces
 70419/100000: episode: 9504, duration: 0.690s, episode steps: 4, steps per second: 6, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001636, mae: 0.020976, mean_q: 0.025481
 70424/100000: episode: 9505, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000301, mae: 0.009270, mean_q: 0.016263
 70427/100000: episode: 9506, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001607, mae: 0.018385, mean_q: 0.038687
 70432/100000: episode: 9507, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000917, mae: 0.015435, mean_q: 0.029154
 70437/100000: episode: 9508, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001034, mae: 0.014029, mean_q: 0.032456
 70442/100000: episode: 9509, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001219, mae: 0.017809, mean_q: 0.030682
 70445/100000: episode: 9510, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001092, mae: 0.018534, mean_q: 0.023717
 70448/100000: episode: 9511, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001431, mae: 0.018542, mean_q: 0.024044
 70453/100000: episode: 9512, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000424, mae: 0.011853, mean_q: 0.022458
 70456/100000: episode: 9513, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000112, mae: 0.007609, mean_q: 0.014492
 70461/100000: episode: 9514, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000517, mae: 0.012156, mean_q: 0.024380
 70464/100000: episode: 9515, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000817, mae: 0.017306, mean_q: 0.033953
 70469/100000: episode: 9516, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000219, mae: 0.010687, mean_q: 0.018645
 70472/100000: episode: 9517, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000158, mae: 0.009759, mean_q: 0.018703
 70477/100000: episode: 9518, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000124, mae: 0.007687, mean_q: 0.017201
 70480/100000: episode: 9519, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000438, mae: 0.010198, mean_q: 0.012977
 70483/100000: episode: 9520, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002173, mae: 0.024011, mean_q: 0.055560
 70488/100000: episode: 9521, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000495, mae: 0.012505, mean_q: 0.022528
 70491/100000: episode: 9522, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000246, mae: 0.008300, mean_q: 0.014521
 70496/100000: episode: 9523, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000358, mae: 0.011028, mean_q: 0.026287
 70499/100000: episode: 9524, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000228, mae: 0.010457, mean_q: 0.021495
 70502/100000: episode: 9525, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001260, mae: 0.018220, mean_q: 0.039973
 70505/100000: episode: 9526, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000275, mae: 0.011849, mean_q: 0.027493
 70508/100000: episode: 9527, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002855, mae: 0.021230, mean_q: 0.038032
 70511/100000: episode: 9528, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002791, mae: 0.028906, mean_q: 0.051245
 70514/100000: episode: 9529, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000731, mae: 0.017273, mean_q: 0.038040
 70517/100000: episode: 9530, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001420, mae: 0.017437, mean_q: 0.045386
 70520/100000: episode: 9531, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000113, mae: 0.007977, mean_q: 0.014827
 70523/100000: episode: 9532, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000221, mae: 0.012337, mean_q: 0.018508
 70528/100000: episode: 9533, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000845, mae: 0.014895, mean_q: 0.021501
 70533/100000: episode: 9534, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000634, mae: 0.012614, mean_q: 0.018993
 70536/100000: episode: 9535, duration: 0.021s, episode steps: 3, steps per second: 140, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000314, mae: 0.011017, mean_q: 0.024474
 70541/100000: episode: 9536, duration: 0.045s, episode steps: 5, steps per second: 111, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000413, mae: 0.013613, mean_q: 0.028197
 70544/100000: episode: 9537, duration: 0.027s, episode steps: 3, steps per second: 113, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001407, mae: 0.017870, mean_q: 0.032981
 70547/100000: episode: 9538, duration: 0.027s, episode steps: 3, steps per second: 113, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001722, mae: 0.018595, mean_q: 0.034144
 70552/100000: episode: 9539, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001456, mae: 0.017219, mean_q: 0.037790
 70555/100000: episode: 9540, duration: 0.031s, episode steps: 3, steps per second: 97, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000168, mae: 0.009880, mean_q: 0.016762
 70560/100000: episode: 9541, duration: 0.030s, episode steps: 5, steps per second: 167, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000605, mae: 0.014553, mean_q: 0.017397
 70563/100000: episode: 9542, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000517, mae: 0.013651, mean_q: 0.021434
 70566/100000: episode: 9543, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000754, mae: 0.017610, mean_q: 0.020007
 70569/100000: episode: 9544, duration: 0.026s, episode steps: 3, steps per second: 115, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000412, mae: 0.011988, mean_q: 0.017444
 70574/100000: episode: 9545, duration: 0.030s, episode steps: 5, steps per second: 167, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002124, mae: 0.018008, mean_q: 0.022556
 70579/100000: episode: 9546, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002460, mae: 0.028400, mean_q: 0.044477
 70582/100000: episode: 9547, duration: 0.020s, episode steps: 3, steps per second: 151, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000418, mae: 0.014911, mean_q: 0.029609
 70585/100000: episode: 9548, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000212, mae: 0.012157, mean_q: 0.023525
 70590/100000: episode: 9549, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001187, mae: 0.016312, mean_q: 0.027686
 70593/100000: episode: 9550, duration: 0.027s, episode steps: 3, steps per second: 110, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001064, mae: 0.015593, mean_q: 0.025352
 70596/100000: episode: 9551, duration: 0.024s, episode steps: 3, steps per second: 126, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001467, mae: 0.014926, mean_q: 0.024170
 70599/100000: episode: 9552, duration: 0.029s, episode steps: 3, steps per second: 103, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001570, mae: 0.018753, mean_q: 0.030321
 70604/100000: episode: 9553, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001048, mae: 0.017381, mean_q: 0.028970
 70607/100000: episode: 9554, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001115, mae: 0.019166, mean_q: 0.021771
 70610/100000: episode: 9555, duration: 0.020s, episode steps: 3, steps per second: 150, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000457, mae: 0.013940, mean_q: 0.021842
 70613/100000: episode: 9556, duration: 0.028s, episode steps: 3, steps per second: 107, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001704, mae: 0.018745, mean_q: 0.019689
 70616/100000: episode: 9557, duration: 0.019s, episode steps: 3, steps per second: 155, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002237, mae: 0.022053, mean_q: 0.038067
 70619/100000: episode: 9558, duration: 0.019s, episode steps: 3, steps per second: 155, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000323, mae: 0.010939, mean_q: 0.019958
 70622/100000: episode: 9559, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003370, mae: 0.025627, mean_q: 0.036287
 70625/100000: episode: 9560, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000219, mae: 0.013108, mean_q: 0.029317
 70628/100000: episode: 9561, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000266, mae: 0.011285, mean_q: 0.024541
 70631/100000: episode: 9562, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000767, mae: 0.013432, mean_q: 0.033151
 70634/100000: episode: 9563, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000364, mae: 0.014097, mean_q: 0.025130
 70637/100000: episode: 9564, duration: 0.027s, episode steps: 3, steps per second: 111, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002163, mae: 0.019142, mean_q: 0.036316
 70642/100000: episode: 9565, duration: 0.064s, episode steps: 5, steps per second: 78, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001108, mae: 0.015095, mean_q: 0.034211
 70645/100000: episode: 9566, duration: 0.032s, episode steps: 3, steps per second: 93, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002045, mae: 0.022162, mean_q: 0.039334
 70648/100000: episode: 9567, duration: 0.030s, episode steps: 3, steps per second: 99, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001068, mae: 0.016668, mean_q: 0.028279
 70651/100000: episode: 9568, duration: 0.025s, episode steps: 3, steps per second: 120, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000878, mae: 0.016270, mean_q: 0.029031
 70654/100000: episode: 9569, duration: 0.019s, episode steps: 3, steps per second: 156, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000810, mae: 0.021050, mean_q: 0.036639
 70659/100000: episode: 9570, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001622, mae: 0.020114, mean_q: 0.030737
 70664/100000: episode: 9571, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000385, mae: 0.015771, mean_q: 0.023428
 70667/100000: episode: 9572, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001484, mae: 0.018039, mean_q: 0.024182
 70670/100000: episode: 9573, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002533, mae: 0.024763, mean_q: 0.032859
 70673/100000: episode: 9574, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001353, mae: 0.018321, mean_q: 0.042883
 70676/100000: episode: 9575, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001211, mae: 0.017067, mean_q: 0.024846
 70679/100000: episode: 9576, duration: 0.019s, episode steps: 3, steps per second: 162, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000451, mae: 0.011252, mean_q: 0.017944
 70682/100000: episode: 9577, duration: 0.021s, episode steps: 3, steps per second: 145, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001010, mae: 0.017879, mean_q: 0.029991
 70687/100000: episode: 9578, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001575, mae: 0.023800, mean_q: 0.038408
 70690/100000: episode: 9579, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001650, mae: 0.020082, mean_q: 0.038937
 70693/100000: episode: 9580, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000313, mae: 0.012043, mean_q: 0.020546
 70696/100000: episode: 9581, duration: 0.033s, episode steps: 3, steps per second: 91, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000264, mae: 0.012215, mean_q: 0.028864
 70699/100000: episode: 9582, duration: 0.046s, episode steps: 3, steps per second: 65, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000467, mae: 0.015038, mean_q: 0.033765
 70702/100000: episode: 9583, duration: 0.020s, episode steps: 3, steps per second: 152, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001241, mae: 0.013807, mean_q: 0.028914
 70705/100000: episode: 9584, duration: 0.035s, episode steps: 3, steps per second: 86, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001170, mae: 0.020985, mean_q: 0.042540
 70708/100000: episode: 9585, duration: 0.022s, episode steps: 3, steps per second: 134, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001528, mae: 0.017004, mean_q: 0.023088
 70711/100000: episode: 9586, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001331, mae: 0.015626, mean_q: 0.027680
 70716/100000: episode: 9587, duration: 0.035s, episode steps: 5, steps per second: 143, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000416, mae: 0.012658, mean_q: 0.025984
 70719/100000: episode: 9588, duration: 0.027s, episode steps: 3, steps per second: 113, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001293, mae: 0.018210, mean_q: 0.031423
 70722/100000: episode: 9589, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000495, mae: 0.013181, mean_q: 0.030094
[Info] 3-TH LEVEL FOUND: 0.16199210286140442, Considering 15/100 traces
 70727/100000: episode: 9590, duration: 1.007s, episode steps: 5, steps per second: 5, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001140, mae: 0.016174, mean_q: 0.028372
 70731/100000: episode: 9591, duration: 0.029s, episode steps: 4, steps per second: 140, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000411, mae: 0.012722, mean_q: 0.022263
 70735/100000: episode: 9592, duration: 0.026s, episode steps: 4, steps per second: 152, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001042, mae: 0.016389, mean_q: 0.024883
 70739/100000: episode: 9593, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000631, mae: 0.013894, mean_q: 0.026505
 70743/100000: episode: 9594, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001512, mae: 0.019564, mean_q: 0.043820
 70747/100000: episode: 9595, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001732, mae: 0.019016, mean_q: 0.028032
 70751/100000: episode: 9596, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000688, mae: 0.014961, mean_q: 0.024201
 70755/100000: episode: 9597, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001105, mae: 0.017005, mean_q: 0.026563
[Info] FALSIFICATION!
 70758/100000: episode: 9598, duration: 0.307s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000253, mae: 0.010708, mean_q: 0.019957
 70762/100000: episode: 9599, duration: 0.035s, episode steps: 4, steps per second: 115, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000738, mae: 0.013913, mean_q: 0.030460
 70766/100000: episode: 9600, duration: 0.023s, episode steps: 4, steps per second: 170, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001129, mae: 0.015570, mean_q: 0.023700
 70770/100000: episode: 9601, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000852, mae: 0.015036, mean_q: 0.029273
 70774/100000: episode: 9602, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000885, mae: 0.017148, mean_q: 0.030361
 70778/100000: episode: 9603, duration: 0.044s, episode steps: 4, steps per second: 91, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001312, mae: 0.014755, mean_q: 0.024462
[Info] FALSIFICATION!
 70781/100000: episode: 9604, duration: 0.298s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001698, mae: 0.019290, mean_q: 0.034918
 70785/100000: episode: 9605, duration: 0.044s, episode steps: 4, steps per second: 90, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001275, mae: 0.017535, mean_q: 0.033303
 70789/100000: episode: 9606, duration: 0.053s, episode steps: 4, steps per second: 76, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002047, mae: 0.024280, mean_q: 0.049914
 70793/100000: episode: 9607, duration: 0.029s, episode steps: 4, steps per second: 138, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001828, mae: 0.023221, mean_q: 0.048190
[Info] FALSIFICATION!
 70796/100000: episode: 9608, duration: 0.296s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001496, mae: 0.020176, mean_q: 0.037670
 70800/100000: episode: 9609, duration: 0.060s, episode steps: 4, steps per second: 67, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000824, mae: 0.015216, mean_q: 0.025589
 70804/100000: episode: 9610, duration: 0.025s, episode steps: 4, steps per second: 163, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000854, mae: 0.015839, mean_q: 0.039048
[Info] FALSIFICATION!
 70807/100000: episode: 9611, duration: 0.290s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001243, mae: 0.018595, mean_q: 0.034627
 70811/100000: episode: 9612, duration: 0.042s, episode steps: 4, steps per second: 96, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.002036, mae: 0.020172, mean_q: 0.036916
 70815/100000: episode: 9613, duration: 0.041s, episode steps: 4, steps per second: 97, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000808, mae: 0.014809, mean_q: 0.035355
 70819/100000: episode: 9614, duration: 0.061s, episode steps: 4, steps per second: 65, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001153, mae: 0.019057, mean_q: 0.036859
 70823/100000: episode: 9615, duration: 0.039s, episode steps: 4, steps per second: 103, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001795, mae: 0.022003, mean_q: 0.048227
 70827/100000: episode: 9616, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000419, mae: 0.010300, mean_q: 0.021084
 70831/100000: episode: 9617, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.001162, mae: 0.016933, mean_q: 0.037166
 70835/100000: episode: 9618, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000511, mae: 0.012438, mean_q: 0.036299
 70839/100000: episode: 9619, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000589, mae: 0.013912, mean_q: 0.018374
 70843/100000: episode: 9620, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001365, mae: 0.021031, mean_q: 0.043594
 70847/100000: episode: 9621, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000647, mae: 0.014626, mean_q: 0.030556
 70851/100000: episode: 9622, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000583, mae: 0.016230, mean_q: 0.041671
 70855/100000: episode: 9623, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001200, mae: 0.020615, mean_q: 0.035597
 70859/100000: episode: 9624, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001053, mae: 0.015357, mean_q: 0.026277
 70863/100000: episode: 9625, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000870, mae: 0.015184, mean_q: 0.030026
 70867/100000: episode: 9626, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001392, mae: 0.021531, mean_q: 0.043940
 70871/100000: episode: 9627, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001419, mae: 0.021460, mean_q: 0.048402
[Info] FALSIFICATION!
 70874/100000: episode: 9628, duration: 0.183s, episode steps: 3, steps per second: 16, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000268, mae: 0.011064, mean_q: 0.025090
 70878/100000: episode: 9629, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000968, mae: 0.016155, mean_q: 0.030452
 70882/100000: episode: 9630, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.001128, mae: 0.021633, mean_q: 0.035324
 70886/100000: episode: 9631, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000574, mae: 0.014774, mean_q: 0.031987
[Info] FALSIFICATION!
 70889/100000: episode: 9632, duration: 0.280s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000490, mae: 0.015185, mean_q: 0.032896
 70893/100000: episode: 9633, duration: 0.039s, episode steps: 4, steps per second: 102, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001723, mae: 0.018827, mean_q: 0.034663
[Info] FALSIFICATION!
 70896/100000: episode: 9634, duration: 0.273s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000746, mae: 0.016807, mean_q: 0.035395
 70900/100000: episode: 9635, duration: 0.031s, episode steps: 4, steps per second: 128, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002190, mae: 0.025027, mean_q: 0.028291
 70904/100000: episode: 9636, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000783, mae: 0.014570, mean_q: 0.014474
 70908/100000: episode: 9637, duration: 0.024s, episode steps: 4, steps per second: 166, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.001284, mae: 0.017154, mean_q: 0.024346
 70912/100000: episode: 9638, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002543, mae: 0.029795, mean_q: 0.056670
 70916/100000: episode: 9639, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003175, mae: 0.019549, mean_q: 0.019944
[Info] FALSIFICATION!
 70919/100000: episode: 9640, duration: 0.297s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000765, mae: 0.012961, mean_q: 0.020064
 70923/100000: episode: 9641, duration: 0.032s, episode steps: 4, steps per second: 124, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002563, mae: 0.028987, mean_q: 0.057678
 70927/100000: episode: 9642, duration: 0.023s, episode steps: 4, steps per second: 178, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001789, mae: 0.022912, mean_q: 0.040037
 70931/100000: episode: 9643, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001713, mae: 0.018070, mean_q: 0.029563
 70935/100000: episode: 9644, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000211, mae: 0.009397, mean_q: 0.020937
 70939/100000: episode: 9645, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002438, mae: 0.024817, mean_q: 0.037200
 70943/100000: episode: 9646, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000899, mae: 0.016634, mean_q: 0.028940
 70947/100000: episode: 9647, duration: 0.026s, episode steps: 4, steps per second: 157, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003190, mae: 0.028928, mean_q: 0.043441
 70951/100000: episode: 9648, duration: 0.029s, episode steps: 4, steps per second: 137, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001371, mae: 0.020924, mean_q: 0.038891
 70955/100000: episode: 9649, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002278, mae: 0.026687, mean_q: 0.057100
 70959/100000: episode: 9650, duration: 0.024s, episode steps: 4, steps per second: 166, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002111, mae: 0.024606, mean_q: 0.044100
 70963/100000: episode: 9651, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002442, mae: 0.026377, mean_q: 0.051089
 70967/100000: episode: 9652, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000346, mae: 0.012459, mean_q: 0.025526
 70971/100000: episode: 9653, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002011, mae: 0.022851, mean_q: 0.034784
 70975/100000: episode: 9654, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000857, mae: 0.016291, mean_q: 0.023721
[Info] FALSIFICATION!
 70978/100000: episode: 9655, duration: 0.292s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.003650, mae: 0.027126, mean_q: 0.034435
 70982/100000: episode: 9656, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001152, mae: 0.016910, mean_q: 0.026584
 70986/100000: episode: 9657, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000709, mae: 0.014941, mean_q: 0.043357
 70990/100000: episode: 9658, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003591, mae: 0.029736, mean_q: 0.049598
 70994/100000: episode: 9659, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001677, mae: 0.022479, mean_q: 0.037996
 70998/100000: episode: 9660, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000705, mae: 0.015041, mean_q: 0.029139
 71002/100000: episode: 9661, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000748, mae: 0.013427, mean_q: 0.025394
 71006/100000: episode: 9662, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003700, mae: 0.032063, mean_q: 0.050219
 71010/100000: episode: 9663, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001231, mae: 0.014777, mean_q: 0.033494
 71014/100000: episode: 9664, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001831, mae: 0.025575, mean_q: 0.049240
 71018/100000: episode: 9665, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000615, mae: 0.012296, mean_q: 0.024745
 71022/100000: episode: 9666, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003881, mae: 0.031321, mean_q: 0.063877
 71026/100000: episode: 9667, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.004155, mae: 0.029551, mean_q: 0.044834
[Info] FALSIFICATION!
 71029/100000: episode: 9668, duration: 0.277s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002102, mae: 0.029655, mean_q: 0.042863
 71033/100000: episode: 9669, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.003184, mae: 0.036338, mean_q: 0.056861
 71037/100000: episode: 9670, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002101, mae: 0.022707, mean_q: 0.052750
 71041/100000: episode: 9671, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000704, mae: 0.015179, mean_q: 0.028250
 71045/100000: episode: 9672, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.002144, mae: 0.024839, mean_q: 0.036756
 71049/100000: episode: 9673, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000611, mae: 0.015185, mean_q: 0.018349
 71053/100000: episode: 9674, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001902, mae: 0.021134, mean_q: 0.024265
[Info] Complete ISplit Iteration
[Info] Levels: [0.022969007, 0.073705256, 0.1619921, 1.2732451]
[Info] Cond. Prob: [0.11, 0.14, 0.15, 0.16]
[Info] Error Prob: 0.0003696000000000001

 71057/100000: episode: 9675, duration: 1.004s, episode steps: 4, steps per second: 4, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003514, mae: 0.024380, mean_q: 0.040505
 71067/100000: episode: 9676, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002445, mae: 0.028700, mean_q: 0.054271
 71077/100000: episode: 9677, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002148, mae: 0.026506, mean_q: 0.052174
 71087/100000: episode: 9678, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001822, mae: 0.023168, mean_q: 0.042693
 71097/100000: episode: 9679, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001654, mae: 0.020371, mean_q: 0.039610
 71107/100000: episode: 9680, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001723, mae: 0.020276, mean_q: 0.037645
 71117/100000: episode: 9681, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001869, mae: 0.021873, mean_q: 0.041099
 71127/100000: episode: 9682, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001397, mae: 0.017830, mean_q: 0.038209
 71137/100000: episode: 9683, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001575, mae: 0.019286, mean_q: 0.043005
 71147/100000: episode: 9684, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001288, mae: 0.017543, mean_q: 0.034828
 71157/100000: episode: 9685, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000955, mae: 0.015493, mean_q: 0.029589
 71167/100000: episode: 9686, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000912, mae: 0.015497, mean_q: 0.034079
 71177/100000: episode: 9687, duration: 0.096s, episode steps: 10, steps per second: 105, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002179, mae: 0.020826, mean_q: 0.033088
 71187/100000: episode: 9688, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001341, mae: 0.019970, mean_q: 0.034172
 71197/100000: episode: 9689, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001507, mae: 0.021061, mean_q: 0.043774
 71207/100000: episode: 9690, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001534, mae: 0.020852, mean_q: 0.042171
 71217/100000: episode: 9691, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002745, mae: 0.028965, mean_q: 0.049868
 71227/100000: episode: 9692, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001742, mae: 0.020763, mean_q: 0.038715
 71237/100000: episode: 9693, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002084, mae: 0.023645, mean_q: 0.050390
 71247/100000: episode: 9694, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000862, mae: 0.016223, mean_q: 0.039082
 71257/100000: episode: 9695, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001546, mae: 0.018291, mean_q: 0.037735
 71267/100000: episode: 9696, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001957, mae: 0.023195, mean_q: 0.038761
 71277/100000: episode: 9697, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002377, mae: 0.024200, mean_q: 0.050968
 71287/100000: episode: 9698, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002029, mae: 0.022083, mean_q: 0.031166
 71297/100000: episode: 9699, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002058, mae: 0.021889, mean_q: 0.042269
 71307/100000: episode: 9700, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002303, mae: 0.025753, mean_q: 0.054360
 71317/100000: episode: 9701, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.001352, mae: 0.015327, mean_q: 0.032349
 71327/100000: episode: 9702, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001515, mae: 0.019927, mean_q: 0.044606
 71337/100000: episode: 9703, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002307, mae: 0.026290, mean_q: 0.041435
 71347/100000: episode: 9704, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000917, mae: 0.017319, mean_q: 0.041203
 71357/100000: episode: 9705, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003127, mae: 0.029069, mean_q: 0.059339
 71367/100000: episode: 9706, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002479, mae: 0.026325, mean_q: 0.047874
 71377/100000: episode: 9707, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002181, mae: 0.023707, mean_q: 0.053798
 71387/100000: episode: 9708, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002255, mae: 0.022973, mean_q: 0.030731
 71397/100000: episode: 9709, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002515, mae: 0.024563, mean_q: 0.043264
 71407/100000: episode: 9710, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001843, mae: 0.024049, mean_q: 0.042266
 71417/100000: episode: 9711, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001142, mae: 0.018333, mean_q: 0.040115
 71427/100000: episode: 9712, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002016, mae: 0.022853, mean_q: 0.033053
 71437/100000: episode: 9713, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001811, mae: 0.019540, mean_q: 0.038913
 71447/100000: episode: 9714, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001322, mae: 0.015923, mean_q: 0.032603
 71457/100000: episode: 9715, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001287, mae: 0.018992, mean_q: 0.040816
 71467/100000: episode: 9716, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001374, mae: 0.018614, mean_q: 0.033198
 71477/100000: episode: 9717, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002678, mae: 0.025767, mean_q: 0.043091
 71487/100000: episode: 9718, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001379, mae: 0.018637, mean_q: 0.036329
 71497/100000: episode: 9719, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001119, mae: 0.018196, mean_q: 0.042330
 71507/100000: episode: 9720, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001583, mae: 0.019002, mean_q: 0.042117
 71517/100000: episode: 9721, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001378, mae: 0.021016, mean_q: 0.035410
 71527/100000: episode: 9722, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001584, mae: 0.019593, mean_q: 0.033140
 71537/100000: episode: 9723, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002254, mae: 0.025924, mean_q: 0.055111
 71547/100000: episode: 9724, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001253, mae: 0.018550, mean_q: 0.033066
 71557/100000: episode: 9725, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001094, mae: 0.017163, mean_q: 0.027782
 71567/100000: episode: 9726, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002215, mae: 0.024581, mean_q: 0.037417
 71577/100000: episode: 9727, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002415, mae: 0.022225, mean_q: 0.039489
 71587/100000: episode: 9728, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002028, mae: 0.022384, mean_q: 0.039560
 71597/100000: episode: 9729, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001066, mae: 0.015419, mean_q: 0.029546
 71607/100000: episode: 9730, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001319, mae: 0.016062, mean_q: 0.028332
 71617/100000: episode: 9731, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002345, mae: 0.023900, mean_q: 0.036908
 71627/100000: episode: 9732, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000725, mae: 0.014598, mean_q: 0.026320
 71637/100000: episode: 9733, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001021, mae: 0.014389, mean_q: 0.027987
 71647/100000: episode: 9734, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002455, mae: 0.025102, mean_q: 0.040591
 71657/100000: episode: 9735, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001058, mae: 0.018654, mean_q: 0.038026
 71667/100000: episode: 9736, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001593, mae: 0.020733, mean_q: 0.039629
 71677/100000: episode: 9737, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001963, mae: 0.022741, mean_q: 0.034488
 71687/100000: episode: 9738, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001216, mae: 0.016666, mean_q: 0.035059
 71697/100000: episode: 9739, duration: 0.084s, episode steps: 10, steps per second: 118, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001685, mae: 0.021432, mean_q: 0.044053
 71707/100000: episode: 9740, duration: 0.101s, episode steps: 10, steps per second: 99, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001375, mae: 0.016868, mean_q: 0.034968
 71717/100000: episode: 9741, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001870, mae: 0.019478, mean_q: 0.038047
 71727/100000: episode: 9742, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001947, mae: 0.020089, mean_q: 0.038350
 71737/100000: episode: 9743, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002026, mae: 0.022913, mean_q: 0.050168
 71747/100000: episode: 9744, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001688, mae: 0.020970, mean_q: 0.042123
 71757/100000: episode: 9745, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001166, mae: 0.016499, mean_q: 0.027145
 71767/100000: episode: 9746, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001308, mae: 0.016721, mean_q: 0.031184
 71777/100000: episode: 9747, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001363, mae: 0.017357, mean_q: 0.038867
 71787/100000: episode: 9748, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001678, mae: 0.019825, mean_q: 0.038544
 71797/100000: episode: 9749, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001300, mae: 0.018590, mean_q: 0.040898
 71807/100000: episode: 9750, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002230, mae: 0.023722, mean_q: 0.046246
 71817/100000: episode: 9751, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001976, mae: 0.023548, mean_q: 0.041857
 71827/100000: episode: 9752, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001498, mae: 0.019328, mean_q: 0.038041
 71837/100000: episode: 9753, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001240, mae: 0.018945, mean_q: 0.038561
 71847/100000: episode: 9754, duration: 0.071s, episode steps: 10, steps per second: 142, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000973, mae: 0.016819, mean_q: 0.034388
 71857/100000: episode: 9755, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000858, mae: 0.016260, mean_q: 0.043052
 71867/100000: episode: 9756, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002754, mae: 0.024856, mean_q: 0.036080
 71877/100000: episode: 9757, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002823, mae: 0.025217, mean_q: 0.039686
 71887/100000: episode: 9758, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001145, mae: 0.017387, mean_q: 0.038478
 71897/100000: episode: 9759, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001921, mae: 0.019745, mean_q: 0.033888
 71907/100000: episode: 9760, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001363, mae: 0.019357, mean_q: 0.037161
 71917/100000: episode: 9761, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001696, mae: 0.021940, mean_q: 0.046994
 71927/100000: episode: 9762, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001482, mae: 0.019170, mean_q: 0.034815
 71937/100000: episode: 9763, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001895, mae: 0.020602, mean_q: 0.031675
 71947/100000: episode: 9764, duration: 0.076s, episode steps: 10, steps per second: 131, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001927, mae: 0.023060, mean_q: 0.033418
 71957/100000: episode: 9765, duration: 0.108s, episode steps: 10, steps per second: 93, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002103, mae: 0.021859, mean_q: 0.038158
 71967/100000: episode: 9766, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001884, mae: 0.022811, mean_q: 0.041373
 71977/100000: episode: 9767, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001840, mae: 0.020895, mean_q: 0.035265
 71987/100000: episode: 9768, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001715, mae: 0.024064, mean_q: 0.050061
 71997/100000: episode: 9769, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002204, mae: 0.025031, mean_q: 0.047249
 72007/100000: episode: 9770, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001220, mae: 0.016801, mean_q: 0.036656
 72017/100000: episode: 9771, duration: 0.107s, episode steps: 10, steps per second: 93, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001840, mae: 0.021578, mean_q: 0.045209
 72027/100000: episode: 9772, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001158, mae: 0.019709, mean_q: 0.046492
 72037/100000: episode: 9773, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002120, mae: 0.020802, mean_q: 0.036988
 72047/100000: episode: 9774, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001198, mae: 0.019346, mean_q: 0.034142
[Info] 1-TH LEVEL FOUND: 0.023822877556085587, Considering 11/100 traces
 72057/100000: episode: 9775, duration: 0.955s, episode steps: 10, steps per second: 10, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001544, mae: 0.018384, mean_q: 0.034206
 72061/100000: episode: 9776, duration: 0.039s, episode steps: 4, steps per second: 102, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.003325, mae: 0.029552, mean_q: 0.054748
 72067/100000: episode: 9777, duration: 0.045s, episode steps: 6, steps per second: 134, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000963, mae: 0.014362, mean_q: 0.026550
 72070/100000: episode: 9778, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000934, mae: 0.015196, mean_q: 0.029337
 72073/100000: episode: 9779, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001601, mae: 0.021859, mean_q: 0.049841
 72077/100000: episode: 9780, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001939, mae: 0.020190, mean_q: 0.029726
 72080/100000: episode: 9781, duration: 0.027s, episode steps: 3, steps per second: 113, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002346, mae: 0.022477, mean_q: 0.036938
 72083/100000: episode: 9782, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003354, mae: 0.033584, mean_q: 0.069517
 72086/100000: episode: 9783, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002612, mae: 0.026071, mean_q: 0.050385
 72092/100000: episode: 9784, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001857, mae: 0.021734, mean_q: 0.036485
 72096/100000: episode: 9785, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001834, mae: 0.023860, mean_q: 0.041087
 72100/100000: episode: 9786, duration: 0.060s, episode steps: 4, steps per second: 67, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001898, mae: 0.022796, mean_q: 0.035178
 72106/100000: episode: 9787, duration: 0.071s, episode steps: 6, steps per second: 84, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001112, mae: 0.018461, mean_q: 0.035147
 72110/100000: episode: 9788, duration: 0.039s, episode steps: 4, steps per second: 103, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000681, mae: 0.011826, mean_q: 0.025604
 72114/100000: episode: 9789, duration: 0.033s, episode steps: 4, steps per second: 123, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001631, mae: 0.020689, mean_q: 0.032073
 72118/100000: episode: 9790, duration: 0.032s, episode steps: 4, steps per second: 124, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001328, mae: 0.017968, mean_q: 0.033958
 72121/100000: episode: 9791, duration: 0.021s, episode steps: 3, steps per second: 145, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001216, mae: 0.018431, mean_q: 0.049172
 72125/100000: episode: 9792, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001544, mae: 0.020207, mean_q: 0.043577
 72128/100000: episode: 9793, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001642, mae: 0.021028, mean_q: 0.043105
 72132/100000: episode: 9794, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002634, mae: 0.023645, mean_q: 0.043737
 72136/100000: episode: 9795, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001002, mae: 0.021094, mean_q: 0.030509
 72139/100000: episode: 9796, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.004730, mae: 0.031306, mean_q: 0.029764
 72142/100000: episode: 9797, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002537, mae: 0.025059, mean_q: 0.031732
 72145/100000: episode: 9798, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.004326, mae: 0.032394, mean_q: 0.052045
 72148/100000: episode: 9799, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001862, mae: 0.021887, mean_q: 0.040107
 72152/100000: episode: 9800, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001543, mae: 0.026984, mean_q: 0.054318
 72156/100000: episode: 9801, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000539, mae: 0.012897, mean_q: 0.028986
 72159/100000: episode: 9802, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003298, mae: 0.028015, mean_q: 0.048071
 72162/100000: episode: 9803, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001456, mae: 0.015559, mean_q: 0.031049
 72165/100000: episode: 9804, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001899, mae: 0.021720, mean_q: 0.034358
 72169/100000: episode: 9805, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002434, mae: 0.023605, mean_q: 0.040727
 72172/100000: episode: 9806, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.004533, mae: 0.030313, mean_q: 0.044313
 72175/100000: episode: 9807, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002681, mae: 0.028463, mean_q: 0.057578
 72178/100000: episode: 9808, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001545, mae: 0.016786, mean_q: 0.026367
 72181/100000: episode: 9809, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.003002, mae: 0.026393, mean_q: 0.042847
 72185/100000: episode: 9810, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001064, mae: 0.020237, mean_q: 0.034704
 72189/100000: episode: 9811, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001176, mae: 0.024490, mean_q: 0.050810
 72193/100000: episode: 9812, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002010, mae: 0.024417, mean_q: 0.042623
 72196/100000: episode: 9813, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001318, mae: 0.020719, mean_q: 0.043816
 72199/100000: episode: 9814, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001236, mae: 0.020363, mean_q: 0.039905
 72202/100000: episode: 9815, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000375, mae: 0.012774, mean_q: 0.023868
 72205/100000: episode: 9816, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001479, mae: 0.018744, mean_q: 0.038475
 72211/100000: episode: 9817, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001491, mae: 0.018622, mean_q: 0.034092
 72215/100000: episode: 9818, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001157, mae: 0.015169, mean_q: 0.031754
 72219/100000: episode: 9819, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001698, mae: 0.023086, mean_q: 0.050423
 72222/100000: episode: 9820, duration: 0.025s, episode steps: 3, steps per second: 122, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001765, mae: 0.023444, mean_q: 0.043347
 72226/100000: episode: 9821, duration: 0.025s, episode steps: 4, steps per second: 161, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000273, mae: 0.010836, mean_q: 0.025357
 72230/100000: episode: 9822, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001853, mae: 0.021743, mean_q: 0.035233
 72234/100000: episode: 9823, duration: 0.026s, episode steps: 4, steps per second: 154, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001589, mae: 0.018906, mean_q: 0.040074
 72238/100000: episode: 9824, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000698, mae: 0.013363, mean_q: 0.036436
 72242/100000: episode: 9825, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001806, mae: 0.019510, mean_q: 0.031399
 72245/100000: episode: 9826, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000794, mae: 0.015288, mean_q: 0.030711
 72249/100000: episode: 9827, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000885, mae: 0.015259, mean_q: 0.026252
 72252/100000: episode: 9828, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.004439, mae: 0.036799, mean_q: 0.056701
 72256/100000: episode: 9829, duration: 0.027s, episode steps: 4, steps per second: 150, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001443, mae: 0.018878, mean_q: 0.028331
 72260/100000: episode: 9830, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002567, mae: 0.024928, mean_q: 0.042370
 72263/100000: episode: 9831, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000617, mae: 0.014276, mean_q: 0.034910
 72267/100000: episode: 9832, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000343, mae: 0.014333, mean_q: 0.037583
 72270/100000: episode: 9833, duration: 0.033s, episode steps: 3, steps per second: 90, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.003164, mae: 0.032600, mean_q: 0.058710
 72276/100000: episode: 9834, duration: 0.056s, episode steps: 6, steps per second: 107, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001408, mae: 0.020083, mean_q: 0.040056
 72282/100000: episode: 9835, duration: 0.049s, episode steps: 6, steps per second: 122, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001356, mae: 0.019910, mean_q: 0.040903
 72285/100000: episode: 9836, duration: 0.022s, episode steps: 3, steps per second: 138, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000863, mae: 0.014543, mean_q: 0.037093
 72289/100000: episode: 9837, duration: 0.024s, episode steps: 4, steps per second: 167, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000767, mae: 0.015432, mean_q: 0.043250
 72293/100000: episode: 9838, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002182, mae: 0.026826, mean_q: 0.061321
 72296/100000: episode: 9839, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000638, mae: 0.015209, mean_q: 0.035244
 72300/100000: episode: 9840, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001911, mae: 0.022332, mean_q: 0.038762
 72303/100000: episode: 9841, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002931, mae: 0.028441, mean_q: 0.043674
 72307/100000: episode: 9842, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.003181, mae: 0.027848, mean_q: 0.025750
 72311/100000: episode: 9843, duration: 0.023s, episode steps: 4, steps per second: 170, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001988, mae: 0.023847, mean_q: 0.029000
 72314/100000: episode: 9844, duration: 0.021s, episode steps: 3, steps per second: 144, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001518, mae: 0.020678, mean_q: 0.030128
 72317/100000: episode: 9845, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001876, mae: 0.021589, mean_q: 0.036426
 72323/100000: episode: 9846, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001088, mae: 0.019704, mean_q: 0.039360
 72327/100000: episode: 9847, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002034, mae: 0.027746, mean_q: 0.052903
 72331/100000: episode: 9848, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001500, mae: 0.030266, mean_q: 0.058541
 72335/100000: episode: 9849, duration: 0.038s, episode steps: 4, steps per second: 105, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001682, mae: 0.023350, mean_q: 0.044395
 72339/100000: episode: 9850, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001716, mae: 0.020176, mean_q: 0.033565
 72345/100000: episode: 9851, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001208, mae: 0.018721, mean_q: 0.034470
 72349/100000: episode: 9852, duration: 0.024s, episode steps: 4, steps per second: 166, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002418, mae: 0.023170, mean_q: 0.039950
 72352/100000: episode: 9853, duration: 0.023s, episode steps: 3, steps per second: 129, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001564, mae: 0.020927, mean_q: 0.039299
 72356/100000: episode: 9854, duration: 0.028s, episode steps: 4, steps per second: 143, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001178, mae: 0.019202, mean_q: 0.050289
 72359/100000: episode: 9855, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001051, mae: 0.011879, mean_q: 0.023033
 72362/100000: episode: 9856, duration: 0.019s, episode steps: 3, steps per second: 156, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.003291, mae: 0.028743, mean_q: 0.057790
 72366/100000: episode: 9857, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001989, mae: 0.022718, mean_q: 0.041321
 72369/100000: episode: 9858, duration: 0.026s, episode steps: 3, steps per second: 115, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000990, mae: 0.013760, mean_q: 0.015856
 72372/100000: episode: 9859, duration: 0.022s, episode steps: 3, steps per second: 136, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001753, mae: 0.021542, mean_q: 0.033441
 72378/100000: episode: 9860, duration: 0.044s, episode steps: 6, steps per second: 138, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002390, mae: 0.024763, mean_q: 0.041752
 72381/100000: episode: 9861, duration: 0.040s, episode steps: 3, steps per second: 75, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002427, mae: 0.025436, mean_q: 0.054548
 72384/100000: episode: 9862, duration: 0.025s, episode steps: 3, steps per second: 118, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001082, mae: 0.016138, mean_q: 0.028508
 72387/100000: episode: 9863, duration: 0.031s, episode steps: 3, steps per second: 97, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001984, mae: 0.025727, mean_q: 0.043351
[Info] 2-TH LEVEL FOUND: 0.11899261176586151, Considering 25/100 traces
 72390/100000: episode: 9864, duration: 0.886s, episode steps: 3, steps per second: 3, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001250, mae: 0.018597, mean_q: 0.035762
 72393/100000: episode: 9865, duration: 0.027s, episode steps: 3, steps per second: 112, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001162, mae: 0.019265, mean_q: 0.039919
 72396/100000: episode: 9866, duration: 0.020s, episode steps: 3, steps per second: 152, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001591, mae: 0.020229, mean_q: 0.043003
 72399/100000: episode: 9867, duration: 0.020s, episode steps: 3, steps per second: 151, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002920, mae: 0.032831, mean_q: 0.068964
 72402/100000: episode: 9868, duration: 0.019s, episode steps: 3, steps per second: 157, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001077, mae: 0.017080, mean_q: 0.028580
 72405/100000: episode: 9869, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000478, mae: 0.013451, mean_q: 0.029204
 72408/100000: episode: 9870, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003441, mae: 0.030884, mean_q: 0.047552
 72411/100000: episode: 9871, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003456, mae: 0.030662, mean_q: 0.065227
 72414/100000: episode: 9872, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000379, mae: 0.014132, mean_q: 0.025356
 72417/100000: episode: 9873, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001211, mae: 0.023052, mean_q: 0.046934
 72420/100000: episode: 9874, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001407, mae: 0.021533, mean_q: 0.043610
 72423/100000: episode: 9875, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002695, mae: 0.025985, mean_q: 0.050632
 72426/100000: episode: 9876, duration: 0.024s, episode steps: 3, steps per second: 127, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002149, mae: 0.024285, mean_q: 0.029744
 72429/100000: episode: 9877, duration: 0.032s, episode steps: 3, steps per second: 95, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.004263, mae: 0.030216, mean_q: 0.027000
 72432/100000: episode: 9878, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001637, mae: 0.020201, mean_q: 0.026916
 72435/100000: episode: 9879, duration: 0.030s, episode steps: 3, steps per second: 100, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002421, mae: 0.022461, mean_q: 0.025240
 72438/100000: episode: 9880, duration: 0.039s, episode steps: 3, steps per second: 76, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.004633, mae: 0.038899, mean_q: 0.056200
 72441/100000: episode: 9881, duration: 0.025s, episode steps: 3, steps per second: 118, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001380, mae: 0.020669, mean_q: 0.046723
 72444/100000: episode: 9882, duration: 0.043s, episode steps: 3, steps per second: 70, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003106, mae: 0.034986, mean_q: 0.084362
 72447/100000: episode: 9883, duration: 0.024s, episode steps: 3, steps per second: 126, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001845, mae: 0.026477, mean_q: 0.055333
 72450/100000: episode: 9884, duration: 0.025s, episode steps: 3, steps per second: 120, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001769, mae: 0.024760, mean_q: 0.054113
 72454/100000: episode: 9885, duration: 0.027s, episode steps: 4, steps per second: 151, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000838, mae: 0.015937, mean_q: 0.035961
 72457/100000: episode: 9886, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002184, mae: 0.025474, mean_q: 0.057579
 72460/100000: episode: 9887, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002646, mae: 0.028217, mean_q: 0.077345
 72463/100000: episode: 9888, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000877, mae: 0.016958, mean_q: 0.036464
 72466/100000: episode: 9889, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000561, mae: 0.015268, mean_q: 0.029049
 72469/100000: episode: 9890, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002319, mae: 0.031442, mean_q: 0.058299
 72472/100000: episode: 9891, duration: 0.024s, episode steps: 3, steps per second: 127, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002001, mae: 0.029141, mean_q: 0.037408
 72475/100000: episode: 9892, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001069, mae: 0.018154, mean_q: 0.035641
 72478/100000: episode: 9893, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001200, mae: 0.015930, mean_q: 0.019264
 72481/100000: episode: 9894, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002888, mae: 0.031426, mean_q: 0.058184
 72484/100000: episode: 9895, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000437, mae: 0.013825, mean_q: 0.024416
 72487/100000: episode: 9896, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002030, mae: 0.023744, mean_q: 0.052307
 72490/100000: episode: 9897, duration: 0.016s, episode steps: 3, steps per second: 187, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001636, mae: 0.022389, mean_q: 0.047170
 72493/100000: episode: 9898, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002224, mae: 0.027235, mean_q: 0.055489
 72496/100000: episode: 9899, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002007, mae: 0.022077, mean_q: 0.048796
 72499/100000: episode: 9900, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001140, mae: 0.017393, mean_q: 0.037278
 72502/100000: episode: 9901, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002916, mae: 0.029220, mean_q: 0.062779
 72505/100000: episode: 9902, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001134, mae: 0.014199, mean_q: 0.024362
 72508/100000: episode: 9903, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000949, mae: 0.015338, mean_q: 0.030795
 72511/100000: episode: 9904, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003661, mae: 0.029099, mean_q: 0.046653
 72514/100000: episode: 9905, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001236, mae: 0.018702, mean_q: 0.024221
 72517/100000: episode: 9906, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002319, mae: 0.028229, mean_q: 0.042773
 72520/100000: episode: 9907, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002148, mae: 0.022821, mean_q: 0.036820
 72523/100000: episode: 9908, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001498, mae: 0.021038, mean_q: 0.037074
 72526/100000: episode: 9909, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000652, mae: 0.012319, mean_q: 0.024538
 72529/100000: episode: 9910, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001666, mae: 0.020098, mean_q: 0.037638
 72532/100000: episode: 9911, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001655, mae: 0.021354, mean_q: 0.051843
 72535/100000: episode: 9912, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000353, mae: 0.011734, mean_q: 0.021744
 72538/100000: episode: 9913, duration: 0.021s, episode steps: 3, steps per second: 142, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000858, mae: 0.014697, mean_q: 0.028350
 72541/100000: episode: 9914, duration: 0.036s, episode steps: 3, steps per second: 83, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000931, mae: 0.018268, mean_q: 0.028104
 72544/100000: episode: 9915, duration: 0.025s, episode steps: 3, steps per second: 118, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001113, mae: 0.021588, mean_q: 0.042215
 72547/100000: episode: 9916, duration: 0.029s, episode steps: 3, steps per second: 102, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001603, mae: 0.022286, mean_q: 0.038190
 72550/100000: episode: 9917, duration: 0.019s, episode steps: 3, steps per second: 156, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001273, mae: 0.018104, mean_q: 0.031514
 72553/100000: episode: 9918, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000267, mae: 0.012211, mean_q: 0.025657
 72556/100000: episode: 9919, duration: 0.019s, episode steps: 3, steps per second: 162, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002627, mae: 0.025679, mean_q: 0.049276
 72559/100000: episode: 9920, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001527, mae: 0.020173, mean_q: 0.040784
 72562/100000: episode: 9921, duration: 0.027s, episode steps: 3, steps per second: 112, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000838, mae: 0.016787, mean_q: 0.032942
 72565/100000: episode: 9922, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000980, mae: 0.017517, mean_q: 0.030481
 72568/100000: episode: 9923, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001674, mae: 0.022700, mean_q: 0.047085
 72571/100000: episode: 9924, duration: 0.021s, episode steps: 3, steps per second: 146, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002156, mae: 0.023843, mean_q: 0.053475
 72574/100000: episode: 9925, duration: 0.024s, episode steps: 3, steps per second: 124, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001254, mae: 0.021941, mean_q: 0.048893
 72577/100000: episode: 9926, duration: 0.020s, episode steps: 3, steps per second: 147, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000745, mae: 0.015211, mean_q: 0.036773
 72580/100000: episode: 9927, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001459, mae: 0.022563, mean_q: 0.042020
 72583/100000: episode: 9928, duration: 0.024s, episode steps: 3, steps per second: 127, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000780, mae: 0.014986, mean_q: 0.022386
 72586/100000: episode: 9929, duration: 0.026s, episode steps: 3, steps per second: 114, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003552, mae: 0.024667, mean_q: 0.034396
 72589/100000: episode: 9930, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001922, mae: 0.026871, mean_q: 0.062806
 72592/100000: episode: 9931, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002541, mae: 0.029401, mean_q: 0.063753
 72595/100000: episode: 9932, duration: 0.020s, episode steps: 3, steps per second: 149, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003163, mae: 0.026998, mean_q: 0.048333
 72598/100000: episode: 9933, duration: 0.031s, episode steps: 3, steps per second: 96, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000926, mae: 0.014507, mean_q: 0.035238
 72601/100000: episode: 9934, duration: 0.020s, episode steps: 3, steps per second: 150, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000806, mae: 0.013417, mean_q: 0.026954
 72604/100000: episode: 9935, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001738, mae: 0.023797, mean_q: 0.043401
 72607/100000: episode: 9936, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003078, mae: 0.033975, mean_q: 0.080793
 72610/100000: episode: 9937, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004055, mae: 0.035212, mean_q: 0.069811
 72613/100000: episode: 9938, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000618, mae: 0.012434, mean_q: 0.026143
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.11899261176586151
 72616/100000: episode: 9939, duration: 0.751s, episode steps: 3, steps per second: 4, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000543, mae: 0.014356, mean_q: 0.033984
 72626/100000: episode: 9940, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002037, mae: 0.023044, mean_q: 0.031309
 72636/100000: episode: 9941, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001658, mae: 0.020975, mean_q: 0.041840
 72646/100000: episode: 9942, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001559, mae: 0.021968, mean_q: 0.041443
 72656/100000: episode: 9943, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002736, mae: 0.026537, mean_q: 0.052239
 72666/100000: episode: 9944, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001777, mae: 0.021744, mean_q: 0.049900
 72676/100000: episode: 9945, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001392, mae: 0.019329, mean_q: 0.040417
 72686/100000: episode: 9946, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001983, mae: 0.022581, mean_q: 0.035313
 72696/100000: episode: 9947, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002012, mae: 0.026533, mean_q: 0.058546
 72706/100000: episode: 9948, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002562, mae: 0.029436, mean_q: 0.066826
 72716/100000: episode: 9949, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001431, mae: 0.020543, mean_q: 0.032319
 72726/100000: episode: 9950, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000648, mae: 0.014398, mean_q: 0.024883
 72736/100000: episode: 9951, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001500, mae: 0.021061, mean_q: 0.043107
 72746/100000: episode: 9952, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001650, mae: 0.020999, mean_q: 0.040405
 72756/100000: episode: 9953, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001753, mae: 0.021829, mean_q: 0.040631
 72766/100000: episode: 9954, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000561, mae: 0.013074, mean_q: 0.023832
 72776/100000: episode: 9955, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002932, mae: 0.025919, mean_q: 0.040543
 72786/100000: episode: 9956, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002968, mae: 0.028918, mean_q: 0.050554
 72796/100000: episode: 9957, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.002181, mae: 0.023483, mean_q: 0.041229
 72806/100000: episode: 9958, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.002256, mae: 0.024594, mean_q: 0.051025
 72816/100000: episode: 9959, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001716, mae: 0.021210, mean_q: 0.036358
 72826/100000: episode: 9960, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001822, mae: 0.022063, mean_q: 0.037919
 72836/100000: episode: 9961, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001569, mae: 0.018611, mean_q: 0.037704
 72846/100000: episode: 9962, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001584, mae: 0.020692, mean_q: 0.039692
 72856/100000: episode: 9963, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001059, mae: 0.018129, mean_q: 0.027491
 72866/100000: episode: 9964, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001811, mae: 0.021975, mean_q: 0.034239
 72876/100000: episode: 9965, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001321, mae: 0.019393, mean_q: 0.035692
 72886/100000: episode: 9966, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001297, mae: 0.020876, mean_q: 0.041246
 72896/100000: episode: 9967, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002133, mae: 0.022086, mean_q: 0.038296
 72906/100000: episode: 9968, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001301, mae: 0.019792, mean_q: 0.041178
 72916/100000: episode: 9969, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001273, mae: 0.018256, mean_q: 0.034615
 72926/100000: episode: 9970, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002640, mae: 0.025311, mean_q: 0.046924
 72936/100000: episode: 9971, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002328, mae: 0.024401, mean_q: 0.050555
 72946/100000: episode: 9972, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001366, mae: 0.017992, mean_q: 0.031688
 72956/100000: episode: 9973, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001017, mae: 0.016470, mean_q: 0.036483
 72966/100000: episode: 9974, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.001800, mae: 0.020069, mean_q: 0.044544
 72976/100000: episode: 9975, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002124, mae: 0.021605, mean_q: 0.040783
 72986/100000: episode: 9976, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001834, mae: 0.020163, mean_q: 0.042641
 72996/100000: episode: 9977, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001198, mae: 0.015963, mean_q: 0.027990
 73006/100000: episode: 9978, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001227, mae: 0.017534, mean_q: 0.027279
 73016/100000: episode: 9979, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000608, mae: 0.013323, mean_q: 0.021061
 73026/100000: episode: 9980, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.003835, mae: 0.024673, mean_q: 0.028259
 73036/100000: episode: 9981, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000828, mae: 0.019588, mean_q: 0.036335
 73046/100000: episode: 9982, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001207, mae: 0.019687, mean_q: 0.041673
 73056/100000: episode: 9983, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000878, mae: 0.016808, mean_q: 0.036689
 73066/100000: episode: 9984, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000732, mae: 0.014569, mean_q: 0.024539
 73076/100000: episode: 9985, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001322, mae: 0.016835, mean_q: 0.029531
 73086/100000: episode: 9986, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001516, mae: 0.016949, mean_q: 0.030096
 73096/100000: episode: 9987, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000906, mae: 0.014258, mean_q: 0.028285
 73106/100000: episode: 9988, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001750, mae: 0.018352, mean_q: 0.036083
 73116/100000: episode: 9989, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001774, mae: 0.021063, mean_q: 0.038932
 73126/100000: episode: 9990, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001870, mae: 0.021852, mean_q: 0.048551
 73136/100000: episode: 9991, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001285, mae: 0.015450, mean_q: 0.029230
 73146/100000: episode: 9992, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001364, mae: 0.017885, mean_q: 0.023474
 73156/100000: episode: 9993, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001508, mae: 0.017619, mean_q: 0.031809
 73166/100000: episode: 9994, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001580, mae: 0.018137, mean_q: 0.033247
 73176/100000: episode: 9995, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000854, mae: 0.014023, mean_q: 0.030038
 73186/100000: episode: 9996, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001776, mae: 0.019326, mean_q: 0.038444
 73196/100000: episode: 9997, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001290, mae: 0.016518, mean_q: 0.033076
 73206/100000: episode: 9998, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000840, mae: 0.013284, mean_q: 0.022779
 73216/100000: episode: 9999, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000988, mae: 0.015103, mean_q: 0.021989
 73226/100000: episode: 10000, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001106, mae: 0.015789, mean_q: 0.030052
 73236/100000: episode: 10001, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001240, mae: 0.017901, mean_q: 0.040933
 73246/100000: episode: 10002, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001538, mae: 0.019071, mean_q: 0.029455
 73256/100000: episode: 10003, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001526, mae: 0.016915, mean_q: 0.025110
 73266/100000: episode: 10004, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000713, mae: 0.011334, mean_q: 0.023251
 73276/100000: episode: 10005, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002366, mae: 0.021506, mean_q: 0.038732
 73286/100000: episode: 10006, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002615, mae: 0.022621, mean_q: 0.044443
 73296/100000: episode: 10007, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000760, mae: 0.014653, mean_q: 0.023307
 73306/100000: episode: 10008, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000832, mae: 0.016283, mean_q: 0.035160
 73316/100000: episode: 10009, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001292, mae: 0.018376, mean_q: 0.036369
 73326/100000: episode: 10010, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000942, mae: 0.012554, mean_q: 0.022399
 73336/100000: episode: 10011, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000578, mae: 0.013901, mean_q: 0.027951
 73346/100000: episode: 10012, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000821, mae: 0.012677, mean_q: 0.023706
 73356/100000: episode: 10013, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002045, mae: 0.018910, mean_q: 0.037292
 73366/100000: episode: 10014, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001377, mae: 0.014712, mean_q: 0.027558
 73376/100000: episode: 10015, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001254, mae: 0.015031, mean_q: 0.027910
 73386/100000: episode: 10016, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000620, mae: 0.011648, mean_q: 0.027628
 73396/100000: episode: 10017, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001689, mae: 0.017495, mean_q: 0.044340
 73406/100000: episode: 10018, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001304, mae: 0.015261, mean_q: 0.032684
 73416/100000: episode: 10019, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001012, mae: 0.015670, mean_q: 0.014163
 73426/100000: episode: 10020, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001265, mae: 0.015929, mean_q: 0.021887
 73436/100000: episode: 10021, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000830, mae: 0.014332, mean_q: 0.023004
 73446/100000: episode: 10022, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000525, mae: 0.010734, mean_q: 0.017885
 73456/100000: episode: 10023, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001204, mae: 0.015409, mean_q: 0.021966
 73466/100000: episode: 10024, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000958, mae: 0.016256, mean_q: 0.028713
 73476/100000: episode: 10025, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000721, mae: 0.011724, mean_q: 0.025874
 73486/100000: episode: 10026, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001377, mae: 0.014501, mean_q: 0.026759
 73496/100000: episode: 10027, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001460, mae: 0.017964, mean_q: 0.034211
 73506/100000: episode: 10028, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.001356, mae: 0.017027, mean_q: 0.026787
 73516/100000: episode: 10029, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000934, mae: 0.013569, mean_q: 0.029917
 73526/100000: episode: 10030, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001535, mae: 0.017422, mean_q: 0.033599
 73536/100000: episode: 10031, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000639, mae: 0.010599, mean_q: 0.017264
 73546/100000: episode: 10032, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001182, mae: 0.014770, mean_q: 0.029205
 73556/100000: episode: 10033, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001118, mae: 0.013167, mean_q: 0.022562
 73566/100000: episode: 10034, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001419, mae: 0.016948, mean_q: 0.036609
 73576/100000: episode: 10035, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001627, mae: 0.017333, mean_q: 0.033542
 73586/100000: episode: 10036, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000751, mae: 0.011785, mean_q: 0.020048
 73596/100000: episode: 10037, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000872, mae: 0.012292, mean_q: 0.027301
 73606/100000: episode: 10038, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001903, mae: 0.017726, mean_q: 0.030601
[Info] 1-TH LEVEL FOUND: 0.05162433534860611, Considering 11/100 traces
 73616/100000: episode: 10039, duration: 0.725s, episode steps: 10, steps per second: 14, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000951, mae: 0.014572, mean_q: 0.029692
 73620/100000: episode: 10040, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001505, mae: 0.018178, mean_q: 0.035470
 73626/100000: episode: 10041, duration: 0.034s, episode steps: 6, steps per second: 177, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001677, mae: 0.020633, mean_q: 0.043224
 73630/100000: episode: 10042, duration: 0.042s, episode steps: 4, steps per second: 96, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000471, mae: 0.010970, mean_q: 0.024149
 73634/100000: episode: 10043, duration: 0.026s, episode steps: 4, steps per second: 156, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000686, mae: 0.011099, mean_q: 0.024048
 73638/100000: episode: 10044, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001278, mae: 0.013760, mean_q: 0.019859
 73644/100000: episode: 10045, duration: 0.046s, episode steps: 6, steps per second: 130, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000692, mae: 0.012761, mean_q: 0.025407
 73650/100000: episode: 10046, duration: 0.032s, episode steps: 6, steps per second: 185, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.002041, mae: 0.019426, mean_q: 0.032844
 73656/100000: episode: 10047, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001048, mae: 0.013960, mean_q: 0.023228
 73660/100000: episode: 10048, duration: 0.030s, episode steps: 4, steps per second: 135, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002323, mae: 0.020740, mean_q: 0.037778
 73664/100000: episode: 10049, duration: 0.026s, episode steps: 4, steps per second: 153, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000794, mae: 0.014586, mean_q: 0.039991
 73668/100000: episode: 10050, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001188, mae: 0.016616, mean_q: 0.030991
 73672/100000: episode: 10051, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001409, mae: 0.018683, mean_q: 0.035803
 73676/100000: episode: 10052, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001663, mae: 0.020606, mean_q: 0.041201
 73680/100000: episode: 10053, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000528, mae: 0.015089, mean_q: 0.033526
 73686/100000: episode: 10054, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000666, mae: 0.010687, mean_q: 0.017949
 73692/100000: episode: 10055, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001312, mae: 0.016320, mean_q: 0.028019
 73696/100000: episode: 10056, duration: 0.025s, episode steps: 4, steps per second: 163, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001535, mae: 0.018911, mean_q: 0.027294
 73700/100000: episode: 10057, duration: 0.027s, episode steps: 4, steps per second: 151, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000374, mae: 0.010369, mean_q: 0.019572
 73704/100000: episode: 10058, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001035, mae: 0.018857, mean_q: 0.030130
 73710/100000: episode: 10059, duration: 0.031s, episode steps: 6, steps per second: 193, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002318, mae: 0.021403, mean_q: 0.031857
 73714/100000: episode: 10060, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000272, mae: 0.013357, mean_q: 0.030419
 73718/100000: episode: 10061, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000829, mae: 0.016570, mean_q: 0.028088
 73724/100000: episode: 10062, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001255, mae: 0.017274, mean_q: 0.026479
 73728/100000: episode: 10063, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001235, mae: 0.013577, mean_q: 0.023886
 73732/100000: episode: 10064, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000155, mae: 0.010274, mean_q: 0.017561
 73736/100000: episode: 10065, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001003, mae: 0.016045, mean_q: 0.030071
 73740/100000: episode: 10066, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000889, mae: 0.014144, mean_q: 0.021527
 73744/100000: episode: 10067, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001499, mae: 0.016109, mean_q: 0.025215
 73748/100000: episode: 10068, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001026, mae: 0.013849, mean_q: 0.031180
 73754/100000: episode: 10069, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001311, mae: 0.014684, mean_q: 0.021806
 73758/100000: episode: 10070, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001269, mae: 0.015228, mean_q: 0.027028
 73762/100000: episode: 10071, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001544, mae: 0.015443, mean_q: 0.026548
 73768/100000: episode: 10072, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001115, mae: 0.014186, mean_q: 0.027208
 73774/100000: episode: 10073, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000764, mae: 0.011931, mean_q: 0.023880
 73780/100000: episode: 10074, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001304, mae: 0.015823, mean_q: 0.029961
 73784/100000: episode: 10075, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001019, mae: 0.015630, mean_q: 0.027591
 73788/100000: episode: 10076, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001022, mae: 0.013663, mean_q: 0.023014
 73794/100000: episode: 10077, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.002170, mae: 0.023219, mean_q: 0.041707
 73800/100000: episode: 10078, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001773, mae: 0.017768, mean_q: 0.030452
 73804/100000: episode: 10079, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001023, mae: 0.014006, mean_q: 0.028549
 73808/100000: episode: 10080, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001366, mae: 0.012204, mean_q: 0.023276
 73812/100000: episode: 10081, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000253, mae: 0.007910, mean_q: 0.013201
 73818/100000: episode: 10082, duration: 0.040s, episode steps: 6, steps per second: 151, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000703, mae: 0.011898, mean_q: 0.020187
 73824/100000: episode: 10083, duration: 0.037s, episode steps: 6, steps per second: 164, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001169, mae: 0.014677, mean_q: 0.026446
 73830/100000: episode: 10084, duration: 0.034s, episode steps: 6, steps per second: 176, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000913, mae: 0.013884, mean_q: 0.024946
 73836/100000: episode: 10085, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001109, mae: 0.015216, mean_q: 0.032492
 73840/100000: episode: 10086, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000543, mae: 0.011464, mean_q: 0.021867
 73844/100000: episode: 10087, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001384, mae: 0.015723, mean_q: 0.027986
 73848/100000: episode: 10088, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002379, mae: 0.027847, mean_q: 0.050804
 73852/100000: episode: 10089, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001616, mae: 0.022284, mean_q: 0.035278
 73856/100000: episode: 10090, duration: 0.028s, episode steps: 4, steps per second: 142, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.003210, mae: 0.024259, mean_q: 0.025960
 73860/100000: episode: 10091, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001216, mae: 0.015656, mean_q: 0.028436
 73864/100000: episode: 10092, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001245, mae: 0.019696, mean_q: 0.043632
 73868/100000: episode: 10093, duration: 0.034s, episode steps: 4, steps per second: 119, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001315, mae: 0.019752, mean_q: 0.040011
 73872/100000: episode: 10094, duration: 0.044s, episode steps: 4, steps per second: 92, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000716, mae: 0.015175, mean_q: 0.033282
 73876/100000: episode: 10095, duration: 0.032s, episode steps: 4, steps per second: 126, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000755, mae: 0.017321, mean_q: 0.032738
 73882/100000: episode: 10096, duration: 0.056s, episode steps: 6, steps per second: 108, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001852, mae: 0.022877, mean_q: 0.054207
 73888/100000: episode: 10097, duration: 0.055s, episode steps: 6, steps per second: 109, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000982, mae: 0.015790, mean_q: 0.026912
 73894/100000: episode: 10098, duration: 0.042s, episode steps: 6, steps per second: 141, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001203, mae: 0.017746, mean_q: 0.027139
 73898/100000: episode: 10099, duration: 0.031s, episode steps: 4, steps per second: 130, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000720, mae: 0.015223, mean_q: 0.017010
 73904/100000: episode: 10100, duration: 0.035s, episode steps: 6, steps per second: 171, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000957, mae: 0.017608, mean_q: 0.024449
 73910/100000: episode: 10101, duration: 0.034s, episode steps: 6, steps per second: 176, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001110, mae: 0.017305, mean_q: 0.037802
 73914/100000: episode: 10102, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000414, mae: 0.010673, mean_q: 0.021861
 73920/100000: episode: 10103, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.002875, mae: 0.023329, mean_q: 0.036076
 73926/100000: episode: 10104, duration: 0.032s, episode steps: 6, steps per second: 189, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001096, mae: 0.017225, mean_q: 0.032630
 73930/100000: episode: 10105, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001784, mae: 0.022482, mean_q: 0.045776
 73934/100000: episode: 10106, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000942, mae: 0.015470, mean_q: 0.033629
 73938/100000: episode: 10107, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001615, mae: 0.020927, mean_q: 0.038335
 73942/100000: episode: 10108, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000513, mae: 0.013864, mean_q: 0.035630
 73948/100000: episode: 10109, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001115, mae: 0.016225, mean_q: 0.032740
 73952/100000: episode: 10110, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001584, mae: 0.020239, mean_q: 0.035672
 73956/100000: episode: 10111, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000277, mae: 0.009255, mean_q: 0.014941
 73962/100000: episode: 10112, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001269, mae: 0.015683, mean_q: 0.032451
 73968/100000: episode: 10113, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002014, mae: 0.018633, mean_q: 0.028561
 73972/100000: episode: 10114, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000276, mae: 0.010467, mean_q: 0.025828
 73976/100000: episode: 10115, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000728, mae: 0.013113, mean_q: 0.023854
 73980/100000: episode: 10116, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001099, mae: 0.018641, mean_q: 0.036381
 73986/100000: episode: 10117, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001042, mae: 0.017825, mean_q: 0.040688
 73992/100000: episode: 10118, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001148, mae: 0.014519, mean_q: 0.028770
 73996/100000: episode: 10119, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000665, mae: 0.010549, mean_q: 0.014020
 74002/100000: episode: 10120, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001768, mae: 0.015153, mean_q: 0.023646
 74006/100000: episode: 10121, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001253, mae: 0.013738, mean_q: 0.020129
 74010/100000: episode: 10122, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001048, mae: 0.013418, mean_q: 0.024986
 74014/100000: episode: 10123, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002355, mae: 0.022992, mean_q: 0.038647
 74020/100000: episode: 10124, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000802, mae: 0.013383, mean_q: 0.025604
 74024/100000: episode: 10125, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000922, mae: 0.014233, mean_q: 0.027245
 74030/100000: episode: 10126, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001937, mae: 0.021547, mean_q: 0.040658
 74036/100000: episode: 10127, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000907, mae: 0.015692, mean_q: 0.030410
[Info] 2-TH LEVEL FOUND: 0.11239743232727051, Considering 17/100 traces
 74040/100000: episode: 10128, duration: 1.055s, episode steps: 4, steps per second: 4, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001426, mae: 0.019585, mean_q: 0.038201
 74045/100000: episode: 10129, duration: 0.039s, episode steps: 5, steps per second: 129, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000423, mae: 0.011196, mean_q: 0.030368
 74050/100000: episode: 10130, duration: 0.041s, episode steps: 5, steps per second: 121, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000646, mae: 0.012486, mean_q: 0.023845
 74055/100000: episode: 10131, duration: 0.053s, episode steps: 5, steps per second: 95, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000415, mae: 0.012258, mean_q: 0.021804
 74060/100000: episode: 10132, duration: 0.041s, episode steps: 5, steps per second: 121, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000958, mae: 0.014393, mean_q: 0.015955
 74065/100000: episode: 10133, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001598, mae: 0.019220, mean_q: 0.032150
 74070/100000: episode: 10134, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001537, mae: 0.019748, mean_q: 0.037079
 74075/100000: episode: 10135, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000565, mae: 0.015826, mean_q: 0.037117
 74080/100000: episode: 10136, duration: 0.029s, episode steps: 5, steps per second: 174, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002424, mae: 0.030385, mean_q: 0.059556
 74085/100000: episode: 10137, duration: 0.032s, episode steps: 5, steps per second: 158, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000835, mae: 0.013553, mean_q: 0.019827
 74090/100000: episode: 10138, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.003542, mae: 0.025396, mean_q: 0.038012
[Info] FALSIFICATION!
 74094/100000: episode: 10139, duration: 0.194s, episode steps: 4, steps per second: 21, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001025, mae: 0.016531, mean_q: 0.028321
 74099/100000: episode: 10140, duration: 0.040s, episode steps: 5, steps per second: 124, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000957, mae: 0.018493, mean_q: 0.033472
 74104/100000: episode: 10141, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001766, mae: 0.025028, mean_q: 0.058153
 74109/100000: episode: 10142, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.001736, mae: 0.019363, mean_q: 0.043250
 74114/100000: episode: 10143, duration: 0.039s, episode steps: 5, steps per second: 129, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001843, mae: 0.021690, mean_q: 0.038153
 74119/100000: episode: 10144, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000869, mae: 0.013520, mean_q: 0.021952
 74124/100000: episode: 10145, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001029, mae: 0.014655, mean_q: 0.026055
 74129/100000: episode: 10146, duration: 0.036s, episode steps: 5, steps per second: 137, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002225, mae: 0.023351, mean_q: 0.039559
 74134/100000: episode: 10147, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001256, mae: 0.015864, mean_q: 0.034460
 74139/100000: episode: 10148, duration: 0.030s, episode steps: 5, steps per second: 168, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002089, mae: 0.022808, mean_q: 0.043304
 74144/100000: episode: 10149, duration: 0.038s, episode steps: 5, steps per second: 132, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002132, mae: 0.021479, mean_q: 0.043586
 74149/100000: episode: 10150, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001631, mae: 0.019753, mean_q: 0.033183
[Info] FALSIFICATION!
 74153/100000: episode: 10151, duration: 0.206s, episode steps: 4, steps per second: 19, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000954, mae: 0.015645, mean_q: 0.028534
 74158/100000: episode: 10152, duration: 0.053s, episode steps: 5, steps per second: 94, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001790, mae: 0.019083, mean_q: 0.036528
 74163/100000: episode: 10153, duration: 0.036s, episode steps: 5, steps per second: 140, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001907, mae: 0.021055, mean_q: 0.032208
 74168/100000: episode: 10154, duration: 0.031s, episode steps: 5, steps per second: 163, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000952, mae: 0.014663, mean_q: 0.028941
 74173/100000: episode: 10155, duration: 0.029s, episode steps: 5, steps per second: 173, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001322, mae: 0.018857, mean_q: 0.037845
 74178/100000: episode: 10156, duration: 0.027s, episode steps: 5, steps per second: 189, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001211, mae: 0.017833, mean_q: 0.033403
 74183/100000: episode: 10157, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001689, mae: 0.022381, mean_q: 0.040119
 74188/100000: episode: 10158, duration: 0.032s, episode steps: 5, steps per second: 157, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001449, mae: 0.017619, mean_q: 0.035761
 74193/100000: episode: 10159, duration: 0.031s, episode steps: 5, steps per second: 162, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002508, mae: 0.024177, mean_q: 0.040440
 74198/100000: episode: 10160, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001450, mae: 0.016254, mean_q: 0.024601
 74203/100000: episode: 10161, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001560, mae: 0.019038, mean_q: 0.031950
 74208/100000: episode: 10162, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000982, mae: 0.015465, mean_q: 0.018918
 74213/100000: episode: 10163, duration: 0.040s, episode steps: 5, steps per second: 124, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000897, mae: 0.015954, mean_q: 0.023797
 74218/100000: episode: 10164, duration: 0.032s, episode steps: 5, steps per second: 156, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003347, mae: 0.024007, mean_q: 0.030362
 74223/100000: episode: 10165, duration: 0.030s, episode steps: 5, steps per second: 165, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001414, mae: 0.022003, mean_q: 0.039170
 74228/100000: episode: 10166, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000609, mae: 0.018705, mean_q: 0.034962
 74233/100000: episode: 10167, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001420, mae: 0.024594, mean_q: 0.043575
 74238/100000: episode: 10168, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001630, mae: 0.022515, mean_q: 0.043465
 74243/100000: episode: 10169, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001243, mae: 0.015855, mean_q: 0.029624
 74248/100000: episode: 10170, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000402, mae: 0.013541, mean_q: 0.024349
 74253/100000: episode: 10171, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.001052, mae: 0.018007, mean_q: 0.026859
 74258/100000: episode: 10172, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001516, mae: 0.020967, mean_q: 0.042771
 74263/100000: episode: 10173, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002938, mae: 0.027374, mean_q: 0.058723
 74268/100000: episode: 10174, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001057, mae: 0.016369, mean_q: 0.032703
 74273/100000: episode: 10175, duration: 0.062s, episode steps: 5, steps per second: 81, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001792, mae: 0.018236, mean_q: 0.029979
 74278/100000: episode: 10176, duration: 0.039s, episode steps: 5, steps per second: 129, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001363, mae: 0.018044, mean_q: 0.028044
 74283/100000: episode: 10177, duration: 0.042s, episode steps: 5, steps per second: 119, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001990, mae: 0.020587, mean_q: 0.036654
 74288/100000: episode: 10178, duration: 0.037s, episode steps: 5, steps per second: 137, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001098, mae: 0.016431, mean_q: 0.031562
 74293/100000: episode: 10179, duration: 0.032s, episode steps: 5, steps per second: 154, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001064, mae: 0.017060, mean_q: 0.033866
 74298/100000: episode: 10180, duration: 0.028s, episode steps: 5, steps per second: 182, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000804, mae: 0.014755, mean_q: 0.032129
 74303/100000: episode: 10181, duration: 0.045s, episode steps: 5, steps per second: 110, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000794, mae: 0.015518, mean_q: 0.027295
 74308/100000: episode: 10182, duration: 0.043s, episode steps: 5, steps per second: 117, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000330, mae: 0.012479, mean_q: 0.027578
 74313/100000: episode: 10183, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002287, mae: 0.024126, mean_q: 0.041684
[Info] FALSIFICATION!
 74317/100000: episode: 10184, duration: 0.243s, episode steps: 4, steps per second: 16, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000383, mae: 0.010646, mean_q: 0.026615
 74322/100000: episode: 10185, duration: 0.071s, episode steps: 5, steps per second: 70, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000707, mae: 0.016806, mean_q: 0.033655
 74327/100000: episode: 10186, duration: 0.050s, episode steps: 5, steps per second: 100, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001772, mae: 0.020473, mean_q: 0.043138
 74332/100000: episode: 10187, duration: 0.048s, episode steps: 5, steps per second: 104, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001096, mae: 0.018264, mean_q: 0.034189
 74337/100000: episode: 10188, duration: 0.041s, episode steps: 5, steps per second: 123, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001676, mae: 0.020583, mean_q: 0.035388
 74342/100000: episode: 10189, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000585, mae: 0.017217, mean_q: 0.025389
 74347/100000: episode: 10190, duration: 0.028s, episode steps: 5, steps per second: 179, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000488, mae: 0.014817, mean_q: 0.032929
 74352/100000: episode: 10191, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002251, mae: 0.022689, mean_q: 0.038641
 74357/100000: episode: 10192, duration: 0.033s, episode steps: 5, steps per second: 151, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001907, mae: 0.022524, mean_q: 0.039629
 74362/100000: episode: 10193, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000416, mae: 0.014785, mean_q: 0.026262
 74367/100000: episode: 10194, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000986, mae: 0.018956, mean_q: 0.034264
 74372/100000: episode: 10195, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001079, mae: 0.018058, mean_q: 0.033824
[Info] FALSIFICATION!
 74376/100000: episode: 10196, duration: 0.317s, episode steps: 4, steps per second: 13, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.002316, mae: 0.024083, mean_q: 0.031959
 74381/100000: episode: 10197, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000958, mae: 0.014735, mean_q: 0.025430
 74386/100000: episode: 10198, duration: 0.028s, episode steps: 5, steps per second: 179, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001087, mae: 0.015922, mean_q: 0.031089
 74391/100000: episode: 10199, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001250, mae: 0.016938, mean_q: 0.026402
 74396/100000: episode: 10200, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000640, mae: 0.014326, mean_q: 0.023127
 74401/100000: episode: 10201, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000874, mae: 0.014389, mean_q: 0.035746
 74406/100000: episode: 10202, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000604, mae: 0.014736, mean_q: 0.027124
 74411/100000: episode: 10203, duration: 0.031s, episode steps: 5, steps per second: 159, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001811, mae: 0.018971, mean_q: 0.033427
 74416/100000: episode: 10204, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001356, mae: 0.019469, mean_q: 0.033479
 74421/100000: episode: 10205, duration: 0.029s, episode steps: 5, steps per second: 171, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.002132, mae: 0.023226, mean_q: 0.049235
 74426/100000: episode: 10206, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000490, mae: 0.015659, mean_q: 0.029683
 74431/100000: episode: 10207, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001026, mae: 0.018166, mean_q: 0.029218
 74436/100000: episode: 10208, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000565, mae: 0.014830, mean_q: 0.034700
 74441/100000: episode: 10209, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001285, mae: 0.019678, mean_q: 0.034697
 74446/100000: episode: 10210, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001993, mae: 0.024602, mean_q: 0.041655
[Info] Complete ISplit Iteration
[Info] Levels: [0.051624335, 0.11239743, 1.1616541]
[Info] Cond. Prob: [0.11, 0.17, 0.07]
[Info] Error Prob: 0.0013090000000000003

 74451/100000: episode: 10211, duration: 0.787s, episode steps: 5, steps per second: 6, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002124, mae: 0.023405, mean_q: 0.043092
 74461/100000: episode: 10212, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001868, mae: 0.023518, mean_q: 0.042235
 74471/100000: episode: 10213, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001592, mae: 0.023440, mean_q: 0.046119
 74481/100000: episode: 10214, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001829, mae: 0.021864, mean_q: 0.048768
 74491/100000: episode: 10215, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001224, mae: 0.019951, mean_q: 0.044949
 74501/100000: episode: 10216, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001693, mae: 0.023833, mean_q: 0.041507
 74511/100000: episode: 10217, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001649, mae: 0.023808, mean_q: 0.040415
 74521/100000: episode: 10218, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000963, mae: 0.015921, mean_q: 0.032878
 74531/100000: episode: 10219, duration: 0.112s, episode steps: 10, steps per second: 89, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001705, mae: 0.024426, mean_q: 0.051771
 74541/100000: episode: 10220, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001525, mae: 0.020508, mean_q: 0.031857
 74551/100000: episode: 10221, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000771, mae: 0.015997, mean_q: 0.028062
 74561/100000: episode: 10222, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002010, mae: 0.023706, mean_q: 0.039040
 74571/100000: episode: 10223, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001490, mae: 0.021857, mean_q: 0.040872
 74581/100000: episode: 10224, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000855, mae: 0.016805, mean_q: 0.034134
 74591/100000: episode: 10225, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001207, mae: 0.021274, mean_q: 0.042252
 74601/100000: episode: 10226, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002037, mae: 0.022433, mean_q: 0.044078
 74611/100000: episode: 10227, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001853, mae: 0.021401, mean_q: 0.038828
 74621/100000: episode: 10228, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001353, mae: 0.018932, mean_q: 0.030799
 74631/100000: episode: 10229, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001626, mae: 0.018710, mean_q: 0.032383
 74641/100000: episode: 10230, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001390, mae: 0.021949, mean_q: 0.041957
 74651/100000: episode: 10231, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002091, mae: 0.026753, mean_q: 0.057057
 74661/100000: episode: 10232, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001727, mae: 0.021564, mean_q: 0.030032
 74671/100000: episode: 10233, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001187, mae: 0.015315, mean_q: 0.022416
 74681/100000: episode: 10234, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001627, mae: 0.021725, mean_q: 0.044806
 74691/100000: episode: 10235, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001732, mae: 0.020136, mean_q: 0.041218
 74701/100000: episode: 10236, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.002378, mae: 0.025622, mean_q: 0.046036
 74711/100000: episode: 10237, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000825, mae: 0.016341, mean_q: 0.031658
 74721/100000: episode: 10238, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001319, mae: 0.016652, mean_q: 0.023562
 74731/100000: episode: 10239, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001311, mae: 0.018375, mean_q: 0.030686
 74741/100000: episode: 10240, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000943, mae: 0.017709, mean_q: 0.035543
 74751/100000: episode: 10241, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001755, mae: 0.021881, mean_q: 0.040431
 74761/100000: episode: 10242, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001738, mae: 0.025122, mean_q: 0.041991
 74771/100000: episode: 10243, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001646, mae: 0.025338, mean_q: 0.056458
 74781/100000: episode: 10244, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002020, mae: 0.022053, mean_q: 0.035932
 74791/100000: episode: 10245, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002268, mae: 0.025129, mean_q: 0.044650
 74801/100000: episode: 10246, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002118, mae: 0.021344, mean_q: 0.040214
 74811/100000: episode: 10247, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001250, mae: 0.020068, mean_q: 0.031241
 74821/100000: episode: 10248, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002355, mae: 0.026429, mean_q: 0.041199
 74831/100000: episode: 10249, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002251, mae: 0.026348, mean_q: 0.046831
 74841/100000: episode: 10250, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001132, mae: 0.019245, mean_q: 0.039810
 74851/100000: episode: 10251, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000698, mae: 0.012845, mean_q: 0.029256
 74861/100000: episode: 10252, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002353, mae: 0.024530, mean_q: 0.039166
 74871/100000: episode: 10253, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002512, mae: 0.025349, mean_q: 0.043425
 74881/100000: episode: 10254, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001025, mae: 0.017533, mean_q: 0.035059
 74891/100000: episode: 10255, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001914, mae: 0.021539, mean_q: 0.039862
 74901/100000: episode: 10256, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001104, mae: 0.016218, mean_q: 0.025504
 74911/100000: episode: 10257, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001201, mae: 0.019485, mean_q: 0.042650
 74921/100000: episode: 10258, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001577, mae: 0.022773, mean_q: 0.043430
 74931/100000: episode: 10259, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001591, mae: 0.020086, mean_q: 0.028244
 74941/100000: episode: 10260, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001809, mae: 0.021118, mean_q: 0.040404
 74951/100000: episode: 10261, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001429, mae: 0.019553, mean_q: 0.038794
 74961/100000: episode: 10262, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001155, mae: 0.019435, mean_q: 0.042843
 74971/100000: episode: 10263, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001157, mae: 0.018260, mean_q: 0.023518
 74981/100000: episode: 10264, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001608, mae: 0.020776, mean_q: 0.037598
 74991/100000: episode: 10265, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000633, mae: 0.015299, mean_q: 0.034504
 75001/100000: episode: 10266, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000740, mae: 0.014093, mean_q: 0.021978
 75011/100000: episode: 10267, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002084, mae: 0.022787, mean_q: 0.045202
 75021/100000: episode: 10268, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001234, mae: 0.019945, mean_q: 0.031906
 75031/100000: episode: 10269, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001583, mae: 0.022877, mean_q: 0.046157
 75041/100000: episode: 10270, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001623, mae: 0.019939, mean_q: 0.040289
 75051/100000: episode: 10271, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001225, mae: 0.018139, mean_q: 0.030588
 75061/100000: episode: 10272, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001353, mae: 0.019680, mean_q: 0.040700
 75071/100000: episode: 10273, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.001306, mae: 0.016422, mean_q: 0.026055
 75081/100000: episode: 10274, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001478, mae: 0.019705, mean_q: 0.037129
 75091/100000: episode: 10275, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000647, mae: 0.014048, mean_q: 0.029980
 75101/100000: episode: 10276, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001894, mae: 0.020017, mean_q: 0.032704
 75111/100000: episode: 10277, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001180, mae: 0.016784, mean_q: 0.027128
 75121/100000: episode: 10278, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001074, mae: 0.015802, mean_q: 0.035870
 75131/100000: episode: 10279, duration: 0.104s, episode steps: 10, steps per second: 96, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001333, mae: 0.017042, mean_q: 0.026304
 75141/100000: episode: 10280, duration: 0.085s, episode steps: 10, steps per second: 117, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001366, mae: 0.017939, mean_q: 0.018814
 75151/100000: episode: 10281, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001767, mae: 0.018095, mean_q: 0.028830
 75161/100000: episode: 10282, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001068, mae: 0.016884, mean_q: 0.026831
 75171/100000: episode: 10283, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000677, mae: 0.015799, mean_q: 0.031071
 75181/100000: episode: 10284, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000800, mae: 0.012798, mean_q: 0.026030
 75191/100000: episode: 10285, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000827, mae: 0.011751, mean_q: 0.022880
 75201/100000: episode: 10286, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000921, mae: 0.013782, mean_q: 0.024075
 75211/100000: episode: 10287, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000608, mae: 0.012489, mean_q: 0.020415
 75221/100000: episode: 10288, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000491, mae: 0.010968, mean_q: 0.018710
 75231/100000: episode: 10289, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000560, mae: 0.011988, mean_q: 0.028772
 75241/100000: episode: 10290, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000816, mae: 0.016202, mean_q: 0.029895
 75251/100000: episode: 10291, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000746, mae: 0.013997, mean_q: 0.026003
 75261/100000: episode: 10292, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000897, mae: 0.014168, mean_q: 0.024275
 75271/100000: episode: 10293, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001193, mae: 0.014851, mean_q: 0.023758
 75281/100000: episode: 10294, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001016, mae: 0.014011, mean_q: 0.026829
 75291/100000: episode: 10295, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000562, mae: 0.011631, mean_q: 0.020882
 75301/100000: episode: 10296, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000922, mae: 0.015935, mean_q: 0.029019
 75311/100000: episode: 10297, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000452, mae: 0.011515, mean_q: 0.021774
 75321/100000: episode: 10298, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000660, mae: 0.012163, mean_q: 0.021114
 75331/100000: episode: 10299, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000273, mae: 0.010280, mean_q: 0.019471
 75341/100000: episode: 10300, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001234, mae: 0.015044, mean_q: 0.030416
 75351/100000: episode: 10301, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000530, mae: 0.012042, mean_q: 0.026454
 75361/100000: episode: 10302, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000690, mae: 0.012711, mean_q: 0.022824
 75371/100000: episode: 10303, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000617, mae: 0.011520, mean_q: 0.018762
 75381/100000: episode: 10304, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000577, mae: 0.011619, mean_q: 0.018497
 75391/100000: episode: 10305, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000219, mae: 0.010562, mean_q: 0.021438
 75401/100000: episode: 10306, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000326, mae: 0.009588, mean_q: 0.016457
 75411/100000: episode: 10307, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000291, mae: 0.009164, mean_q: 0.017748
 75421/100000: episode: 10308, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000211, mae: 0.008225, mean_q: 0.013570
 75431/100000: episode: 10309, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000459, mae: 0.010146, mean_q: 0.018235
 75441/100000: episode: 10310, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000385, mae: 0.009879, mean_q: 0.016504
[Info] 1-TH LEVEL FOUND: 0.03557771444320679, Considering 20/100 traces
 75451/100000: episode: 10311, duration: 0.656s, episode steps: 10, steps per second: 15, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000842, mae: 0.012552, mean_q: 0.026710
 75454/100000: episode: 10312, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000537, mae: 0.013459, mean_q: 0.030475
 75460/100000: episode: 10313, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000778, mae: 0.013024, mean_q: 0.026103
 75463/100000: episode: 10314, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000207, mae: 0.011113, mean_q: 0.019992
 75466/100000: episode: 10315, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000227, mae: 0.008991, mean_q: 0.016221
 75469/100000: episode: 10316, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000190, mae: 0.008187, mean_q: 0.012611
 75473/100000: episode: 10317, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000252, mae: 0.009817, mean_q: 0.015874
 75476/100000: episode: 10318, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000868, mae: 0.012562, mean_q: 0.021307
 75479/100000: episode: 10319, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000247, mae: 0.008922, mean_q: 0.015364
 75482/100000: episode: 10320, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000508, mae: 0.011532, mean_q: 0.023754
 75485/100000: episode: 10321, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000153, mae: 0.009366, mean_q: 0.017068
 75488/100000: episode: 10322, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000211, mae: 0.008819, mean_q: 0.021484
 75491/100000: episode: 10323, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000404, mae: 0.010896, mean_q: 0.017790
 75494/100000: episode: 10324, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000347, mae: 0.010054, mean_q: 0.017457
 75497/100000: episode: 10325, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000230, mae: 0.006631, mean_q: 0.008788
 75500/100000: episode: 10326, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000293, mae: 0.009898, mean_q: 0.015700
 75503/100000: episode: 10327, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000110, mae: 0.006813, mean_q: 0.011526
 75506/100000: episode: 10328, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000148, mae: 0.006627, mean_q: 0.011354
 75509/100000: episode: 10329, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000169, mae: 0.007132, mean_q: 0.012683
 75512/100000: episode: 10330, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000127, mae: 0.007793, mean_q: 0.011434
 75515/100000: episode: 10331, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000151, mae: 0.008823, mean_q: 0.014783
 75518/100000: episode: 10332, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000164, mae: 0.008330, mean_q: 0.015940
 75521/100000: episode: 10333, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000184, mae: 0.011150, mean_q: 0.020814
 75525/100000: episode: 10334, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000490, mae: 0.008646, mean_q: 0.013799
 75528/100000: episode: 10335, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000178, mae: 0.009616, mean_q: 0.016585
 75531/100000: episode: 10336, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000075, mae: 0.005872, mean_q: 0.010253
 75534/100000: episode: 10337, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000766, mae: 0.011810, mean_q: 0.017325
 75537/100000: episode: 10338, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000804, mae: 0.011437, mean_q: 0.019518
 75543/100000: episode: 10339, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000458, mae: 0.010403, mean_q: 0.016154
 75546/100000: episode: 10340, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000845, mae: 0.016733, mean_q: 0.029034
 75549/100000: episode: 10341, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000239, mae: 0.013322, mean_q: 0.020540
 75552/100000: episode: 10342, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000694, mae: 0.011902, mean_q: 0.020513
 75555/100000: episode: 10343, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000357, mae: 0.009920, mean_q: 0.023634
 75558/100000: episode: 10344, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000744, mae: 0.013679, mean_q: 0.022385
 75564/100000: episode: 10345, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000636, mae: 0.013673, mean_q: 0.022829
 75567/100000: episode: 10346, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001428, mae: 0.017019, mean_q: 0.029456
 75570/100000: episode: 10347, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000431, mae: 0.010895, mean_q: 0.018532
 75573/100000: episode: 10348, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000642, mae: 0.012314, mean_q: 0.021578
 75576/100000: episode: 10349, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000127, mae: 0.008040, mean_q: 0.015412
 75579/100000: episode: 10350, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000175, mae: 0.006499, mean_q: 0.017164
 75582/100000: episode: 10351, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000147, mae: 0.009540, mean_q: 0.017239
 75585/100000: episode: 10352, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000130, mae: 0.008155, mean_q: 0.014553
 75588/100000: episode: 10353, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002111, mae: 0.020044, mean_q: 0.036487
 75591/100000: episode: 10354, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000205, mae: 0.008703, mean_q: 0.010572
 75594/100000: episode: 10355, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000170, mae: 0.009160, mean_q: 0.015767
 75600/100000: episode: 10356, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000509, mae: 0.010648, mean_q: 0.022913
 75603/100000: episode: 10357, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000175, mae: 0.007955, mean_q: 0.014382
 75606/100000: episode: 10358, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000322, mae: 0.010048, mean_q: 0.017679
 75612/100000: episode: 10359, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000330, mae: 0.008144, mean_q: 0.015240
 75615/100000: episode: 10360, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000122, mae: 0.008727, mean_q: 0.016043
 75618/100000: episode: 10361, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000249, mae: 0.010875, mean_q: 0.025092
 75622/100000: episode: 10362, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000834, mae: 0.012964, mean_q: 0.027216
 75625/100000: episode: 10363, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000402, mae: 0.011934, mean_q: 0.019556
 75628/100000: episode: 10364, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000323, mae: 0.011104, mean_q: 0.016689
 75632/100000: episode: 10365, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000140, mae: 0.007764, mean_q: 0.014328
 75635/100000: episode: 10366, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000784, mae: 0.011487, mean_q: 0.017509
 75638/100000: episode: 10367, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000161, mae: 0.007918, mean_q: 0.014756
 75642/100000: episode: 10368, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000417, mae: 0.010876, mean_q: 0.020252
 75645/100000: episode: 10369, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000298, mae: 0.008854, mean_q: 0.016014
 75648/100000: episode: 10370, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000701, mae: 0.012889, mean_q: 0.022783
 75651/100000: episode: 10371, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000143, mae: 0.007166, mean_q: 0.013038
 75654/100000: episode: 10372, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000139, mae: 0.007443, mean_q: 0.013693
 75657/100000: episode: 10373, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000193, mae: 0.009985, mean_q: 0.011585
 75660/100000: episode: 10374, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000836, mae: 0.013374, mean_q: 0.025140
 75663/100000: episode: 10375, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000780, mae: 0.011853, mean_q: 0.018091
 75667/100000: episode: 10376, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000657, mae: 0.012867, mean_q: 0.021170
 75670/100000: episode: 10377, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000191, mae: 0.012351, mean_q: 0.022951
 75673/100000: episode: 10378, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000197, mae: 0.012512, mean_q: 0.022124
 75676/100000: episode: 10379, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000298, mae: 0.011187, mean_q: 0.020613
 75679/100000: episode: 10380, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000303, mae: 0.013013, mean_q: 0.022978
 75682/100000: episode: 10381, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000279, mae: 0.011465, mean_q: 0.019733
 75685/100000: episode: 10382, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000239, mae: 0.012139, mean_q: 0.023633
 75688/100000: episode: 10383, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000417, mae: 0.011414, mean_q: 0.018112
 75691/100000: episode: 10384, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000114, mae: 0.007194, mean_q: 0.013064
 75695/100000: episode: 10385, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000156, mae: 0.008954, mean_q: 0.013844
 75699/100000: episode: 10386, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000487, mae: 0.010849, mean_q: 0.019366
 75702/100000: episode: 10387, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000146, mae: 0.009449, mean_q: 0.017224
 75705/100000: episode: 10388, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000251, mae: 0.011851, mean_q: 0.021665
 75709/100000: episode: 10389, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000261, mae: 0.009374, mean_q: 0.016658
 75715/100000: episode: 10390, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000184, mae: 0.008897, mean_q: 0.017430
[Info] 2-TH LEVEL FOUND: 0.08999320864677429, Considering 10/100 traces
 75719/100000: episode: 10391, duration: 0.690s, episode steps: 4, steps per second: 6, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000290, mae: 0.009631, mean_q: 0.014731
 75722/100000: episode: 10392, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000650, mae: 0.010792, mean_q: 0.019655
 75727/100000: episode: 10393, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000647, mae: 0.012607, mean_q: 0.024081
 75730/100000: episode: 10394, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000273, mae: 0.013023, mean_q: 0.022529
 75733/100000: episode: 10395, duration: 0.022s, episode steps: 3, steps per second: 135, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000916, mae: 0.015870, mean_q: 0.023501
 75736/100000: episode: 10396, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000378, mae: 0.009569, mean_q: 0.020884
 75739/100000: episode: 10397, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000514, mae: 0.010390, mean_q: 0.018044
[Info] FALSIFICATION!
 75743/100000: episode: 10398, duration: 0.283s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000464, mae: 0.009183, mean_q: 0.010755
 75746/100000: episode: 10399, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002160, mae: 0.019985, mean_q: 0.028809
 75749/100000: episode: 10400, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000608, mae: 0.012591, mean_q: 0.021855
 75752/100000: episode: 10401, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000703, mae: 0.013752, mean_q: 0.022383
 75757/100000: episode: 10402, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000506, mae: 0.012572, mean_q: 0.022321
 75760/100000: episode: 10403, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000330, mae: 0.010809, mean_q: 0.018609
 75763/100000: episode: 10404, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000296, mae: 0.010386, mean_q: 0.016706
 75766/100000: episode: 10405, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000134, mae: 0.009073, mean_q: 0.016530
 75771/100000: episode: 10406, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000908, mae: 0.016022, mean_q: 0.029081
 75774/100000: episode: 10407, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000130, mae: 0.010053, mean_q: 0.018802
 75777/100000: episode: 10408, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000181, mae: 0.011511, mean_q: 0.021048
 75780/100000: episode: 10409, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000253, mae: 0.011828, mean_q: 0.022848
 75783/100000: episode: 10410, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001026, mae: 0.013394, mean_q: 0.028958
 75788/100000: episode: 10411, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001202, mae: 0.013781, mean_q: 0.022048
 75791/100000: episode: 10412, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001146, mae: 0.016289, mean_q: 0.030019
 75794/100000: episode: 10413, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000177, mae: 0.009336, mean_q: 0.014000
 75797/100000: episode: 10414, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000567, mae: 0.011075, mean_q: 0.013311
 75800/100000: episode: 10415, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000802, mae: 0.014503, mean_q: 0.025285
 75803/100000: episode: 10416, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000153, mae: 0.008425, mean_q: 0.008761
 75806/100000: episode: 10417, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000451, mae: 0.010489, mean_q: 0.011299
 75809/100000: episode: 10418, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000698, mae: 0.012363, mean_q: 0.017888
 75812/100000: episode: 10419, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000136, mae: 0.010044, mean_q: 0.014542
 75817/100000: episode: 10420, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000309, mae: 0.012439, mean_q: 0.024452
 75820/100000: episode: 10421, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002981, mae: 0.023957, mean_q: 0.031274
 75823/100000: episode: 10422, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000101, mae: 0.008938, mean_q: 0.017756
 75828/100000: episode: 10423, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000564, mae: 0.011695, mean_q: 0.028253
 75831/100000: episode: 10424, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000315, mae: 0.010473, mean_q: 0.016422
 75836/100000: episode: 10425, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000177, mae: 0.011461, mean_q: 0.019009
 75839/100000: episode: 10426, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000186, mae: 0.009815, mean_q: 0.018755
 75844/100000: episode: 10427, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000617, mae: 0.011391, mean_q: 0.018087
 75847/100000: episode: 10428, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000159, mae: 0.009738, mean_q: 0.016671
 75850/100000: episode: 10429, duration: 0.016s, episode steps: 3, steps per second: 188, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000323, mae: 0.012373, mean_q: 0.031170
 75855/100000: episode: 10430, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000627, mae: 0.009834, mean_q: 0.018034
 75860/100000: episode: 10431, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000390, mae: 0.011302, mean_q: 0.022148
 75865/100000: episode: 10432, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000580, mae: 0.012496, mean_q: 0.028451
 75868/100000: episode: 10433, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000124, mae: 0.008416, mean_q: 0.015281
 75871/100000: episode: 10434, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000509, mae: 0.011892, mean_q: 0.037698
 75874/100000: episode: 10435, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001555, mae: 0.019727, mean_q: 0.035606
 75877/100000: episode: 10436, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000401, mae: 0.011588, mean_q: 0.021222
 75880/100000: episode: 10437, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002302, mae: 0.017881, mean_q: 0.030893
 75883/100000: episode: 10438, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001704, mae: 0.017996, mean_q: 0.029023
 75886/100000: episode: 10439, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000648, mae: 0.015356, mean_q: 0.019972
 75889/100000: episode: 10440, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000812, mae: 0.012805, mean_q: 0.014758
 75894/100000: episode: 10441, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000852, mae: 0.016165, mean_q: 0.031119
 75897/100000: episode: 10442, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000851, mae: 0.011457, mean_q: 0.024861
 75900/100000: episode: 10443, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000463, mae: 0.013908, mean_q: 0.022882
 75905/100000: episode: 10444, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000455, mae: 0.013634, mean_q: 0.029738
 75908/100000: episode: 10445, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001018, mae: 0.016733, mean_q: 0.033041
 75913/100000: episode: 10446, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000132, mae: 0.009849, mean_q: 0.017228
 75916/100000: episode: 10447, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000162, mae: 0.010798, mean_q: 0.016949
 75919/100000: episode: 10448, duration: 0.016s, episode steps: 3, steps per second: 188, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000219, mae: 0.013973, mean_q: 0.028039
 75922/100000: episode: 10449, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000675, mae: 0.013263, mean_q: 0.020906
 75925/100000: episode: 10450, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000770, mae: 0.014708, mean_q: 0.024669
 75928/100000: episode: 10451, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000816, mae: 0.015355, mean_q: 0.032994
 75933/100000: episode: 10452, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000927, mae: 0.013495, mean_q: 0.022406
 75936/100000: episode: 10453, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000237, mae: 0.011868, mean_q: 0.023380
 75939/100000: episode: 10454, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000903, mae: 0.019914, mean_q: 0.043550
 75942/100000: episode: 10455, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000436, mae: 0.014177, mean_q: 0.023817
 75945/100000: episode: 10456, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000582, mae: 0.012592, mean_q: 0.024589
 75950/100000: episode: 10457, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000419, mae: 0.011362, mean_q: 0.020693
 75953/100000: episode: 10458, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003328, mae: 0.026663, mean_q: 0.050562
 75958/100000: episode: 10459, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000876, mae: 0.014919, mean_q: 0.022763
 75961/100000: episode: 10460, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001140, mae: 0.019787, mean_q: 0.041847
 75964/100000: episode: 10461, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000665, mae: 0.015702, mean_q: 0.035410
 75967/100000: episode: 10462, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001183, mae: 0.018814, mean_q: 0.036791
 75970/100000: episode: 10463, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001028, mae: 0.016135, mean_q: 0.027059
 75973/100000: episode: 10464, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000189, mae: 0.009033, mean_q: 0.017281
 75976/100000: episode: 10465, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000587, mae: 0.013179, mean_q: 0.019770
 75981/100000: episode: 10466, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000140, mae: 0.008581, mean_q: 0.015656
 75986/100000: episode: 10467, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000697, mae: 0.012895, mean_q: 0.020531
 75989/100000: episode: 10468, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000624, mae: 0.013187, mean_q: 0.019900
 75994/100000: episode: 10469, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000322, mae: 0.011303, mean_q: 0.025466
 75997/100000: episode: 10470, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000412, mae: 0.012497, mean_q: 0.020327
 76002/100000: episode: 10471, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000558, mae: 0.013075, mean_q: 0.020799
 76005/100000: episode: 10472, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000658, mae: 0.016652, mean_q: 0.028831
 76008/100000: episode: 10473, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000202, mae: 0.010875, mean_q: 0.021461
 76011/100000: episode: 10474, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000421, mae: 0.012863, mean_q: 0.021039
 76016/100000: episode: 10475, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000267, mae: 0.009457, mean_q: 0.015098
 76019/100000: episode: 10476, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000151, mae: 0.009868, mean_q: 0.019589
 76024/100000: episode: 10477, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001007, mae: 0.013723, mean_q: 0.020814
 76027/100000: episode: 10478, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001003, mae: 0.018675, mean_q: 0.032514
 76030/100000: episode: 10479, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001482, mae: 0.020515, mean_q: 0.035443
 76033/100000: episode: 10480, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000229, mae: 0.013579, mean_q: 0.030923
[Info] Complete ISplit Iteration
[Info] Levels: [0.035577714, 0.08999321, 1.3424194]
[Info] Cond. Prob: [0.2, 0.1, 0.01]
[Info] Error Prob: 0.00020000000000000004

 76036/100000: episode: 10481, duration: 0.950s, episode steps: 3, steps per second: 3, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000722, mae: 0.017837, mean_q: 0.035175
 76046/100000: episode: 10482, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000740, mae: 0.013641, mean_q: 0.024883
 76056/100000: episode: 10483, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000551, mae: 0.014204, mean_q: 0.018689
 76066/100000: episode: 10484, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000411, mae: 0.010922, mean_q: 0.018004
 76076/100000: episode: 10485, duration: 0.098s, episode steps: 10, steps per second: 102, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000523, mae: 0.011505, mean_q: 0.020067
 76086/100000: episode: 10486, duration: 0.077s, episode steps: 10, steps per second: 131, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000976, mae: 0.014827, mean_q: 0.022810
 76096/100000: episode: 10487, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000532, mae: 0.014480, mean_q: 0.024042
 76106/100000: episode: 10488, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000550, mae: 0.014474, mean_q: 0.026547
 76116/100000: episode: 10489, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000394, mae: 0.011349, mean_q: 0.021412
 76126/100000: episode: 10490, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000142, mae: 0.007736, mean_q: 0.014043
 76136/100000: episode: 10491, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000528, mae: 0.012257, mean_q: 0.021732
 76146/100000: episode: 10492, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001287, mae: 0.016892, mean_q: 0.033971
 76156/100000: episode: 10493, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000885, mae: 0.014938, mean_q: 0.025651
 76166/100000: episode: 10494, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000565, mae: 0.012905, mean_q: 0.025370
 76176/100000: episode: 10495, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000578, mae: 0.012810, mean_q: 0.021839
 76186/100000: episode: 10496, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001062, mae: 0.014427, mean_q: 0.028539
 76196/100000: episode: 10497, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000851, mae: 0.015348, mean_q: 0.025254
 76206/100000: episode: 10498, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000558, mae: 0.012460, mean_q: 0.021045
 76216/100000: episode: 10499, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001025, mae: 0.016424, mean_q: 0.022627
 76226/100000: episode: 10500, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000694, mae: 0.014008, mean_q: 0.029015
 76236/100000: episode: 10501, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000427, mae: 0.015058, mean_q: 0.025841
 76246/100000: episode: 10502, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000582, mae: 0.011158, mean_q: 0.019163
 76256/100000: episode: 10503, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001126, mae: 0.016814, mean_q: 0.023974
 76266/100000: episode: 10504, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000530, mae: 0.012941, mean_q: 0.025479
 76276/100000: episode: 10505, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000476, mae: 0.011908, mean_q: 0.023977
 76286/100000: episode: 10506, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001077, mae: 0.016085, mean_q: 0.035410
 76296/100000: episode: 10507, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000882, mae: 0.016365, mean_q: 0.030929
 76306/100000: episode: 10508, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001060, mae: 0.015719, mean_q: 0.031366
 76316/100000: episode: 10509, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000515, mae: 0.011078, mean_q: 0.016788
 76326/100000: episode: 10510, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000588, mae: 0.013243, mean_q: 0.019722
 76336/100000: episode: 10511, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000747, mae: 0.013167, mean_q: 0.025721
 76346/100000: episode: 10512, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000412, mae: 0.014372, mean_q: 0.027488
 76356/100000: episode: 10513, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000263, mae: 0.010533, mean_q: 0.023061
 76366/100000: episode: 10514, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001030, mae: 0.013569, mean_q: 0.023532
 76376/100000: episode: 10515, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000411, mae: 0.010590, mean_q: 0.015571
 76386/100000: episode: 10516, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000573, mae: 0.012742, mean_q: 0.024054
 76396/100000: episode: 10517, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000695, mae: 0.013422, mean_q: 0.025911
 76406/100000: episode: 10518, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000284, mae: 0.010566, mean_q: 0.016289
 76416/100000: episode: 10519, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000179, mae: 0.009096, mean_q: 0.014152
 76426/100000: episode: 10520, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001095, mae: 0.014061, mean_q: 0.022784
 76436/100000: episode: 10521, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000990, mae: 0.017008, mean_q: 0.032307
 76446/100000: episode: 10522, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000719, mae: 0.013855, mean_q: 0.023788
 76456/100000: episode: 10523, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000466, mae: 0.012073, mean_q: 0.023096
 76466/100000: episode: 10524, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000453, mae: 0.012061, mean_q: 0.023789
 76476/100000: episode: 10525, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000343, mae: 0.010615, mean_q: 0.019150
 76486/100000: episode: 10526, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000649, mae: 0.011518, mean_q: 0.023706
 76496/100000: episode: 10527, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000975, mae: 0.013679, mean_q: 0.023959
 76506/100000: episode: 10528, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000368, mae: 0.010473, mean_q: 0.018186
 76516/100000: episode: 10529, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000617, mae: 0.014405, mean_q: 0.025510
 76526/100000: episode: 10530, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001052, mae: 0.015846, mean_q: 0.030059
 76536/100000: episode: 10531, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000259, mae: 0.009629, mean_q: 0.020213
 76546/100000: episode: 10532, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000694, mae: 0.012130, mean_q: 0.023818
 76556/100000: episode: 10533, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001009, mae: 0.014176, mean_q: 0.024230
 76566/100000: episode: 10534, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000675, mae: 0.011246, mean_q: 0.018765
 76576/100000: episode: 10535, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000202, mae: 0.009882, mean_q: 0.016275
 76586/100000: episode: 10536, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000255, mae: 0.010964, mean_q: 0.019222
 76596/100000: episode: 10537, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000445, mae: 0.011115, mean_q: 0.019091
 76606/100000: episode: 10538, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000234, mae: 0.009003, mean_q: 0.018084
 76616/100000: episode: 10539, duration: 0.109s, episode steps: 10, steps per second: 91, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000620, mae: 0.011561, mean_q: 0.021300
 76626/100000: episode: 10540, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.001490, mae: 0.015612, mean_q: 0.024038
 76636/100000: episode: 10541, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001081, mae: 0.017819, mean_q: 0.034507
 76646/100000: episode: 10542, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000736, mae: 0.013626, mean_q: 0.024952
 76656/100000: episode: 10543, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001035, mae: 0.016080, mean_q: 0.024881
 76666/100000: episode: 10544, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001098, mae: 0.014403, mean_q: 0.026655
 76676/100000: episode: 10545, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000734, mae: 0.013975, mean_q: 0.025803
 76686/100000: episode: 10546, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001190, mae: 0.012820, mean_q: 0.013710
 76696/100000: episode: 10547, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000349, mae: 0.010991, mean_q: 0.017879
 76706/100000: episode: 10548, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000558, mae: 0.012135, mean_q: 0.020951
 76716/100000: episode: 10549, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000675, mae: 0.012539, mean_q: 0.025296
 76726/100000: episode: 10550, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000559, mae: 0.010681, mean_q: 0.019840
 76736/100000: episode: 10551, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000413, mae: 0.011327, mean_q: 0.020710
 76746/100000: episode: 10552, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000873, mae: 0.012199, mean_q: 0.020009
 76756/100000: episode: 10553, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000550, mae: 0.013645, mean_q: 0.024229
 76766/100000: episode: 10554, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000877, mae: 0.013844, mean_q: 0.025637
 76776/100000: episode: 10555, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000378, mae: 0.009141, mean_q: 0.016402
 76786/100000: episode: 10556, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000477, mae: 0.010472, mean_q: 0.019025
 76796/100000: episode: 10557, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000332, mae: 0.009220, mean_q: 0.016008
 76806/100000: episode: 10558, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001071, mae: 0.015212, mean_q: 0.024814
 76816/100000: episode: 10559, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000665, mae: 0.012856, mean_q: 0.020876
 76826/100000: episode: 10560, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001159, mae: 0.013354, mean_q: 0.022181
 76836/100000: episode: 10561, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001211, mae: 0.019061, mean_q: 0.026426
 76846/100000: episode: 10562, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000633, mae: 0.015289, mean_q: 0.028478
 76856/100000: episode: 10563, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000890, mae: 0.013692, mean_q: 0.020521
 76866/100000: episode: 10564, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000142, mae: 0.008407, mean_q: 0.016125
 76876/100000: episode: 10565, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000399, mae: 0.011382, mean_q: 0.019870
 76886/100000: episode: 10566, duration: 0.068s, episode steps: 10, steps per second: 146, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000899, mae: 0.013907, mean_q: 0.024567
 76896/100000: episode: 10567, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000231, mae: 0.009687, mean_q: 0.016262
 76906/100000: episode: 10568, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001146, mae: 0.016279, mean_q: 0.028745
 76916/100000: episode: 10569, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000476, mae: 0.011648, mean_q: 0.022239
 76926/100000: episode: 10570, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000677, mae: 0.012335, mean_q: 0.021534
 76936/100000: episode: 10571, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000256, mae: 0.009359, mean_q: 0.016702
 76946/100000: episode: 10572, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000813, mae: 0.013466, mean_q: 0.023266
 76956/100000: episode: 10573, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000332, mae: 0.010998, mean_q: 0.018086
 76966/100000: episode: 10574, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000291, mae: 0.009153, mean_q: 0.013052
 76976/100000: episode: 10575, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000821, mae: 0.012740, mean_q: 0.020697
 76986/100000: episode: 10576, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000353, mae: 0.013196, mean_q: 0.022507
 76996/100000: episode: 10577, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000686, mae: 0.010906, mean_q: 0.019583
 77006/100000: episode: 10578, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000555, mae: 0.010201, mean_q: 0.020235
 77016/100000: episode: 10579, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000933, mae: 0.012623, mean_q: 0.021908
 77026/100000: episode: 10580, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000617, mae: 0.011569, mean_q: 0.015441
[Info] 1-TH LEVEL FOUND: 0.03494299203157425, Considering 17/100 traces
 77036/100000: episode: 10581, duration: 0.847s, episode steps: 10, steps per second: 12, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001230, mae: 0.015469, mean_q: 0.024570
 77039/100000: episode: 10582, duration: 0.020s, episode steps: 3, steps per second: 151, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001043, mae: 0.015760, mean_q: 0.027421
 77042/100000: episode: 10583, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000296, mae: 0.009287, mean_q: 0.016004
 77045/100000: episode: 10584, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000399, mae: 0.011015, mean_q: 0.025790
 77049/100000: episode: 10585, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000466, mae: 0.012120, mean_q: 0.020177
 77052/100000: episode: 10586, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002040, mae: 0.013736, mean_q: 0.018935
 77055/100000: episode: 10587, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000129, mae: 0.007180, mean_q: 0.012595
 77058/100000: episode: 10588, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000106, mae: 0.006237, mean_q: 0.008844
 77064/100000: episode: 10589, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000331, mae: 0.010747, mean_q: 0.019907
 77067/100000: episode: 10590, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001494, mae: 0.020830, mean_q: 0.029846
 77070/100000: episode: 10591, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000535, mae: 0.012699, mean_q: 0.024036
 77073/100000: episode: 10592, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000146, mae: 0.009256, mean_q: 0.020984
 77076/100000: episode: 10593, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000352, mae: 0.011194, mean_q: 0.016753
 77079/100000: episode: 10594, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001414, mae: 0.014719, mean_q: 0.017051
 77082/100000: episode: 10595, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000147, mae: 0.009190, mean_q: 0.013657
 77086/100000: episode: 10596, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001125, mae: 0.014376, mean_q: 0.022846
 77090/100000: episode: 10597, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000587, mae: 0.009782, mean_q: 0.019306
 77093/100000: episode: 10598, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001167, mae: 0.013397, mean_q: 0.017092
 77096/100000: episode: 10599, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000843, mae: 0.012642, mean_q: 0.020267
 77099/100000: episode: 10600, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000584, mae: 0.016756, mean_q: 0.025868
 77102/100000: episode: 10601, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000173, mae: 0.011234, mean_q: 0.014328
 77105/100000: episode: 10602, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000168, mae: 0.009844, mean_q: 0.013797
 77108/100000: episode: 10603, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000559, mae: 0.013588, mean_q: 0.030059
 77111/100000: episode: 10604, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000128, mae: 0.009746, mean_q: 0.021283
 77114/100000: episode: 10605, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000588, mae: 0.010313, mean_q: 0.016712
 77117/100000: episode: 10606, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000107, mae: 0.008005, mean_q: 0.010351
 77123/100000: episode: 10607, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000828, mae: 0.015069, mean_q: 0.019224
 77126/100000: episode: 10608, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001616, mae: 0.016299, mean_q: 0.017214
 77129/100000: episode: 10609, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000141, mae: 0.009842, mean_q: 0.017605
 77132/100000: episode: 10610, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000130, mae: 0.007987, mean_q: 0.016441
 77138/100000: episode: 10611, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000148, mae: 0.007752, mean_q: 0.012717
 77141/100000: episode: 10612, duration: 0.018s, episode steps: 3, steps per second: 162, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000248, mae: 0.010291, mean_q: 0.020730
 77144/100000: episode: 10613, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000137, mae: 0.007913, mean_q: 0.020288
 77150/100000: episode: 10614, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000353, mae: 0.011765, mean_q: 0.022996
 77153/100000: episode: 10615, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000310, mae: 0.011372, mean_q: 0.019651
 77156/100000: episode: 10616, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000114, mae: 0.009611, mean_q: 0.022072
 77159/100000: episode: 10617, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000109, mae: 0.009461, mean_q: 0.017750
 77162/100000: episode: 10618, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000272, mae: 0.011173, mean_q: 0.026027
 77165/100000: episode: 10619, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000115, mae: 0.009520, mean_q: 0.023116
 77168/100000: episode: 10620, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000301, mae: 0.010745, mean_q: 0.021105
 77174/100000: episode: 10621, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000189, mae: 0.008305, mean_q: 0.014415
 77177/100000: episode: 10622, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000224, mae: 0.007211, mean_q: 0.013077
 77180/100000: episode: 10623, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000310, mae: 0.009451, mean_q: 0.018222
 77183/100000: episode: 10624, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000122, mae: 0.008109, mean_q: 0.017616
 77186/100000: episode: 10625, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000158, mae: 0.010298, mean_q: 0.020354
 77189/100000: episode: 10626, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000119, mae: 0.008360, mean_q: 0.016478
 77193/100000: episode: 10627, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001352, mae: 0.013576, mean_q: 0.017480
 77196/100000: episode: 10628, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000117, mae: 0.008669, mean_q: 0.016716
 77199/100000: episode: 10629, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000406, mae: 0.009583, mean_q: 0.022786
 77202/100000: episode: 10630, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000615, mae: 0.014020, mean_q: 0.025545
 77205/100000: episode: 10631, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000231, mae: 0.010694, mean_q: 0.025982
 77208/100000: episode: 10632, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001109, mae: 0.015962, mean_q: 0.028201
 77211/100000: episode: 10633, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000544, mae: 0.010543, mean_q: 0.017087
 77217/100000: episode: 10634, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001145, mae: 0.013940, mean_q: 0.019493
 77220/100000: episode: 10635, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001175, mae: 0.014990, mean_q: 0.023535
 77223/100000: episode: 10636, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000550, mae: 0.011944, mean_q: 0.022850
 77226/100000: episode: 10637, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000560, mae: 0.016333, mean_q: 0.035465
 77229/100000: episode: 10638, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000114, mae: 0.009286, mean_q: 0.019571
 77232/100000: episode: 10639, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000533, mae: 0.012880, mean_q: 0.020705
 77238/100000: episode: 10640, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000218, mae: 0.009260, mean_q: 0.021579
 77241/100000: episode: 10641, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002401, mae: 0.019735, mean_q: 0.033648
 77244/100000: episode: 10642, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001459, mae: 0.021254, mean_q: 0.040875
 77247/100000: episode: 10643, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000140, mae: 0.009160, mean_q: 0.019425
 77250/100000: episode: 10644, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001176, mae: 0.016212, mean_q: 0.028991
 77253/100000: episode: 10645, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000178, mae: 0.010268, mean_q: 0.020473
 77256/100000: episode: 10646, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000240, mae: 0.008181, mean_q: 0.016557
 77259/100000: episode: 10647, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002482, mae: 0.020839, mean_q: 0.038926
 77262/100000: episode: 10648, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000416, mae: 0.008946, mean_q: 0.017053
 77266/100000: episode: 10649, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000391, mae: 0.011004, mean_q: 0.020860
 77269/100000: episode: 10650, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001420, mae: 0.018488, mean_q: 0.028198
 77275/100000: episode: 10651, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000465, mae: 0.012924, mean_q: 0.020764
 77278/100000: episode: 10652, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000350, mae: 0.011504, mean_q: 0.016228
 77284/100000: episode: 10653, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000389, mae: 0.013054, mean_q: 0.017667
 77287/100000: episode: 10654, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003613, mae: 0.021465, mean_q: 0.029372
 77290/100000: episode: 10655, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000837, mae: 0.014010, mean_q: 0.026487
 77293/100000: episode: 10656, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001784, mae: 0.023126, mean_q: 0.036801
 77296/100000: episode: 10657, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001125, mae: 0.026421, mean_q: 0.031003
 77299/100000: episode: 10658, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000748, mae: 0.020208, mean_q: 0.027553
 77303/100000: episode: 10659, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000414, mae: 0.016483, mean_q: 0.020009
 77306/100000: episode: 10660, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000526, mae: 0.015343, mean_q: 0.026498
 77309/100000: episode: 10661, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000524, mae: 0.014559, mean_q: 0.026225
 77315/100000: episode: 10662, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001207, mae: 0.018844, mean_q: 0.025644
[Info] FALSIFICATION!
 77320/100000: episode: 10663, duration: 0.181s, episode steps: 5, steps per second: 28, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000637, mae: 0.018297, mean_q: 0.027567
[Info] Complete ISplit Iteration
[Info] Levels: [0.034942992, 1.4524735]
[Info] Cond. Prob: [0.17, 0.01]
[Info] Error Prob: 0.0017000000000000001

 77323/100000: episode: 10664, duration: 0.939s, episode steps: 3, steps per second: 3, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002487, mae: 0.025685, mean_q: 0.031062
 77333/100000: episode: 10665, duration: 0.070s, episode steps: 10, steps per second: 144, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000911, mae: 0.017324, mean_q: 0.032405
 77343/100000: episode: 10666, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001143, mae: 0.014350, mean_q: 0.020941
 77353/100000: episode: 10667, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000677, mae: 0.014260, mean_q: 0.029147
 77363/100000: episode: 10668, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001480, mae: 0.015528, mean_q: 0.029146
 77373/100000: episode: 10669, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000995, mae: 0.013764, mean_q: 0.024584
 77383/100000: episode: 10670, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000328, mae: 0.009244, mean_q: 0.015186
 77393/100000: episode: 10671, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000285, mae: 0.009412, mean_q: 0.019159
 77403/100000: episode: 10672, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000444, mae: 0.010339, mean_q: 0.019799
 77413/100000: episode: 10673, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000761, mae: 0.014810, mean_q: 0.027004
 77423/100000: episode: 10674, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000306, mae: 0.008308, mean_q: 0.013882
 77433/100000: episode: 10675, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000533, mae: 0.010234, mean_q: 0.017254
 77443/100000: episode: 10676, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000818, mae: 0.014265, mean_q: 0.028567
 77453/100000: episode: 10677, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000681, mae: 0.010793, mean_q: 0.019567
 77463/100000: episode: 10678, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000776, mae: 0.014584, mean_q: 0.025060
 77473/100000: episode: 10679, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000501, mae: 0.012255, mean_q: 0.028325
 77483/100000: episode: 10680, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000953, mae: 0.011784, mean_q: 0.018241
 77493/100000: episode: 10681, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000587, mae: 0.010444, mean_q: 0.022352
 77503/100000: episode: 10682, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000684, mae: 0.013159, mean_q: 0.031450
 77513/100000: episode: 10683, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000703, mae: 0.013072, mean_q: 0.026765
 77523/100000: episode: 10684, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000705, mae: 0.013283, mean_q: 0.025754
 77533/100000: episode: 10685, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000597, mae: 0.014389, mean_q: 0.033600
 77543/100000: episode: 10686, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000581, mae: 0.010533, mean_q: 0.021529
 77553/100000: episode: 10687, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000699, mae: 0.012732, mean_q: 0.018469
 77563/100000: episode: 10688, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000455, mae: 0.009959, mean_q: 0.013670
 77573/100000: episode: 10689, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000516, mae: 0.010555, mean_q: 0.017604
 77583/100000: episode: 10690, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001019, mae: 0.016171, mean_q: 0.027015
 77593/100000: episode: 10691, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000360, mae: 0.010047, mean_q: 0.017719
 77603/100000: episode: 10692, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000471, mae: 0.011367, mean_q: 0.020274
 77613/100000: episode: 10693, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000508, mae: 0.012412, mean_q: 0.027289
 77623/100000: episode: 10694, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000794, mae: 0.012173, mean_q: 0.020634
 77633/100000: episode: 10695, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000823, mae: 0.012910, mean_q: 0.025432
 77643/100000: episode: 10696, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000505, mae: 0.011908, mean_q: 0.023128
 77653/100000: episode: 10697, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000349, mae: 0.010977, mean_q: 0.021070
 77663/100000: episode: 10698, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001057, mae: 0.014626, mean_q: 0.025496
 77673/100000: episode: 10699, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001178, mae: 0.014003, mean_q: 0.020646
 77683/100000: episode: 10700, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001412, mae: 0.017529, mean_q: 0.029517
 77693/100000: episode: 10701, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001092, mae: 0.015231, mean_q: 0.025318
 77703/100000: episode: 10702, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001033, mae: 0.016513, mean_q: 0.033242
 77713/100000: episode: 10703, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000494, mae: 0.009670, mean_q: 0.016251
 77723/100000: episode: 10704, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000446, mae: 0.008771, mean_q: 0.015211
 77733/100000: episode: 10705, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001483, mae: 0.014439, mean_q: 0.025192
 77743/100000: episode: 10706, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000741, mae: 0.012964, mean_q: 0.023059
 77753/100000: episode: 10707, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000676, mae: 0.012072, mean_q: 0.017790
 77763/100000: episode: 10708, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000566, mae: 0.011809, mean_q: 0.018790
 77773/100000: episode: 10709, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000599, mae: 0.012808, mean_q: 0.019799
 77783/100000: episode: 10710, duration: 0.081s, episode steps: 10, steps per second: 124, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000527, mae: 0.012420, mean_q: 0.021872
 77793/100000: episode: 10711, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001029, mae: 0.013894, mean_q: 0.024918
 77803/100000: episode: 10712, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000632, mae: 0.013126, mean_q: 0.026018
 77813/100000: episode: 10713, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000519, mae: 0.013286, mean_q: 0.030945
 77823/100000: episode: 10714, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000486, mae: 0.013172, mean_q: 0.026046
 77833/100000: episode: 10715, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000764, mae: 0.013519, mean_q: 0.021966
 77843/100000: episode: 10716, duration: 0.093s, episode steps: 10, steps per second: 108, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000720, mae: 0.011879, mean_q: 0.017681
 77853/100000: episode: 10717, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000518, mae: 0.012934, mean_q: 0.021749
 77863/100000: episode: 10718, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000867, mae: 0.014953, mean_q: 0.024410
 77873/100000: episode: 10719, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001172, mae: 0.016298, mean_q: 0.025102
 77883/100000: episode: 10720, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000652, mae: 0.012605, mean_q: 0.020558
 77893/100000: episode: 10721, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001130, mae: 0.016821, mean_q: 0.031751
 77903/100000: episode: 10722, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000664, mae: 0.014332, mean_q: 0.026853
 77913/100000: episode: 10723, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000966, mae: 0.014068, mean_q: 0.024394
 77923/100000: episode: 10724, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001296, mae: 0.015947, mean_q: 0.028058
 77933/100000: episode: 10725, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000551, mae: 0.013080, mean_q: 0.019693
 77943/100000: episode: 10726, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000549, mae: 0.012146, mean_q: 0.020264
 77953/100000: episode: 10727, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001155, mae: 0.015256, mean_q: 0.027680
 77963/100000: episode: 10728, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000377, mae: 0.010934, mean_q: 0.017931
 77973/100000: episode: 10729, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000483, mae: 0.011507, mean_q: 0.021766
 77983/100000: episode: 10730, duration: 0.092s, episode steps: 10, steps per second: 108, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000477, mae: 0.011182, mean_q: 0.022030
 77993/100000: episode: 10731, duration: 0.067s, episode steps: 10, steps per second: 148, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000715, mae: 0.011862, mean_q: 0.021704
 78003/100000: episode: 10732, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000386, mae: 0.010969, mean_q: 0.018164
 78013/100000: episode: 10733, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000594, mae: 0.012320, mean_q: 0.019844
 78023/100000: episode: 10734, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000710, mae: 0.010155, mean_q: 0.017591
 78033/100000: episode: 10735, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000231, mae: 0.009016, mean_q: 0.018287
 78043/100000: episode: 10736, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000885, mae: 0.012998, mean_q: 0.022503
 78053/100000: episode: 10737, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000545, mae: 0.012097, mean_q: 0.014893
 78063/100000: episode: 10738, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001090, mae: 0.012202, mean_q: 0.016483
 78073/100000: episode: 10739, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000660, mae: 0.014501, mean_q: 0.024356
 78083/100000: episode: 10740, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000852, mae: 0.015249, mean_q: 0.029066
 78093/100000: episode: 10741, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000379, mae: 0.010047, mean_q: 0.013793
 78103/100000: episode: 10742, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000841, mae: 0.011895, mean_q: 0.015834
 78113/100000: episode: 10743, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000768, mae: 0.013719, mean_q: 0.024441
 78123/100000: episode: 10744, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000941, mae: 0.012939, mean_q: 0.023493
 78133/100000: episode: 10745, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000574, mae: 0.010913, mean_q: 0.020144
 78143/100000: episode: 10746, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000575, mae: 0.010083, mean_q: 0.018600
 78153/100000: episode: 10747, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000814, mae: 0.013650, mean_q: 0.025143
 78163/100000: episode: 10748, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000948, mae: 0.010453, mean_q: 0.016052
 78173/100000: episode: 10749, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000514, mae: 0.011958, mean_q: 0.020445
 78183/100000: episode: 10750, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000527, mae: 0.012935, mean_q: 0.025985
 78193/100000: episode: 10751, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000705, mae: 0.012309, mean_q: 0.020706
 78203/100000: episode: 10752, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000437, mae: 0.011898, mean_q: 0.018154
 78213/100000: episode: 10753, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000944, mae: 0.015426, mean_q: 0.024243
 78223/100000: episode: 10754, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000333, mae: 0.010905, mean_q: 0.018445
 78233/100000: episode: 10755, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000282, mae: 0.011044, mean_q: 0.019226
 78243/100000: episode: 10756, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000718, mae: 0.012987, mean_q: 0.021838
 78253/100000: episode: 10757, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000484, mae: 0.010420, mean_q: 0.018482
 78263/100000: episode: 10758, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000230, mae: 0.009271, mean_q: 0.018636
 78273/100000: episode: 10759, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000351, mae: 0.008398, mean_q: 0.016522
 78283/100000: episode: 10760, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001869, mae: 0.018717, mean_q: 0.027540
 78293/100000: episode: 10761, duration: 0.074s, episode steps: 10, steps per second: 136, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000413, mae: 0.010272, mean_q: 0.020085
 78303/100000: episode: 10762, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000450, mae: 0.010538, mean_q: 0.015846
 78313/100000: episode: 10763, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000213, mae: 0.007438, mean_q: 0.014275
[Info] 1-TH LEVEL FOUND: 0.03245865926146507, Considering 15/100 traces
 78323/100000: episode: 10764, duration: 0.851s, episode steps: 10, steps per second: 12, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000264, mae: 0.008147, mean_q: 0.014194
 78327/100000: episode: 10765, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000812, mae: 0.014586, mean_q: 0.029727
 78331/100000: episode: 10766, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000814, mae: 0.010814, mean_q: 0.016127
 78335/100000: episode: 10767, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000212, mae: 0.007953, mean_q: 0.014839
 78339/100000: episode: 10768, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000592, mae: 0.011731, mean_q: 0.028546
 78342/100000: episode: 10769, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000935, mae: 0.014486, mean_q: 0.036546
 78346/100000: episode: 10770, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000434, mae: 0.011730, mean_q: 0.020555
 78350/100000: episode: 10771, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000485, mae: 0.010528, mean_q: 0.021426
 78354/100000: episode: 10772, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002115, mae: 0.014313, mean_q: 0.015547
 78358/100000: episode: 10773, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001140, mae: 0.012903, mean_q: 0.015193
 78362/100000: episode: 10774, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000199, mae: 0.008505, mean_q: 0.013637
 78365/100000: episode: 10775, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000366, mae: 0.012216, mean_q: 0.020376
 78368/100000: episode: 10776, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001766, mae: 0.014300, mean_q: 0.028245
 78371/100000: episode: 10777, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001604, mae: 0.013872, mean_q: 0.018546
 78375/100000: episode: 10778, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001235, mae: 0.012861, mean_q: 0.019747
 78381/100000: episode: 10779, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000186, mae: 0.007872, mean_q: 0.016421
 78384/100000: episode: 10780, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000416, mae: 0.010804, mean_q: 0.016818
 78388/100000: episode: 10781, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000382, mae: 0.009594, mean_q: 0.015911
 78391/100000: episode: 10782, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000090, mae: 0.005639, mean_q: 0.010170
 78394/100000: episode: 10783, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001414, mae: 0.015041, mean_q: 0.023342
 78397/100000: episode: 10784, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000919, mae: 0.011745, mean_q: 0.018874
 78400/100000: episode: 10785, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001605, mae: 0.018049, mean_q: 0.026286
 78404/100000: episode: 10786, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000271, mae: 0.009878, mean_q: 0.019631
 78410/100000: episode: 10787, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000767, mae: 0.014018, mean_q: 0.027634
 78413/100000: episode: 10788, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001472, mae: 0.018160, mean_q: 0.041236
 78417/100000: episode: 10789, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000685, mae: 0.011524, mean_q: 0.018322
 78421/100000: episode: 10790, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001185, mae: 0.012630, mean_q: 0.017830
 78425/100000: episode: 10791, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000943, mae: 0.012484, mean_q: 0.024814
 78429/100000: episode: 10792, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001166, mae: 0.015863, mean_q: 0.028654
 78432/100000: episode: 10793, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000916, mae: 0.012200, mean_q: 0.026502
 78438/100000: episode: 10794, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000156, mae: 0.006984, mean_q: 0.013467
 78441/100000: episode: 10795, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000399, mae: 0.007997, mean_q: 0.012499
 78444/100000: episode: 10796, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000165, mae: 0.008837, mean_q: 0.015864
 78448/100000: episode: 10797, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000256, mae: 0.008725, mean_q: 0.012514
 78451/100000: episode: 10798, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000277, mae: 0.009014, mean_q: 0.012988
 78454/100000: episode: 10799, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000290, mae: 0.008096, mean_q: 0.011220
 78457/100000: episode: 10800, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001563, mae: 0.014896, mean_q: 0.024651
 78461/100000: episode: 10801, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001686, mae: 0.013063, mean_q: 0.018776
 78465/100000: episode: 10802, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000225, mae: 0.008462, mean_q: 0.019198
 78469/100000: episode: 10803, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000353, mae: 0.008287, mean_q: 0.014191
 78473/100000: episode: 10804, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000234, mae: 0.008392, mean_q: 0.022963
 78479/100000: episode: 10805, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000863, mae: 0.011871, mean_q: 0.018999
 78482/100000: episode: 10806, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000805, mae: 0.012392, mean_q: 0.024442
 78485/100000: episode: 10807, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000395, mae: 0.010342, mean_q: 0.019103
 78489/100000: episode: 10808, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000273, mae: 0.010534, mean_q: 0.019044
 78492/100000: episode: 10809, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000712, mae: 0.012557, mean_q: 0.021482
 78496/100000: episode: 10810, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000100, mae: 0.006750, mean_q: 0.012680
 78500/100000: episode: 10811, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001156, mae: 0.014257, mean_q: 0.020414
 78504/100000: episode: 10812, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000530, mae: 0.010732, mean_q: 0.019152
 78507/100000: episode: 10813, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000211, mae: 0.007953, mean_q: 0.012358
 78510/100000: episode: 10814, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000220, mae: 0.007235, mean_q: 0.014753
 78513/100000: episode: 10815, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000327, mae: 0.008168, mean_q: 0.015334
 78516/100000: episode: 10816, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001162, mae: 0.009114, mean_q: 0.012774
 78519/100000: episode: 10817, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000307, mae: 0.008673, mean_q: 0.016675
 78522/100000: episode: 10818, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001209, mae: 0.011452, mean_q: 0.017135
 78526/100000: episode: 10819, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000111, mae: 0.007686, mean_q: 0.013665
 78529/100000: episode: 10820, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000236, mae: 0.010275, mean_q: 0.020456
 78533/100000: episode: 10821, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000204, mae: 0.008703, mean_q: 0.016601
 78539/100000: episode: 10822, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000280, mae: 0.010436, mean_q: 0.017832
 78543/100000: episode: 10823, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000094, mae: 0.006706, mean_q: 0.012613
 78547/100000: episode: 10824, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000630, mae: 0.011365, mean_q: 0.017151
 78550/100000: episode: 10825, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000535, mae: 0.010239, mean_q: 0.015889
 78553/100000: episode: 10826, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001512, mae: 0.018371, mean_q: 0.029989
 78556/100000: episode: 10827, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000215, mae: 0.008560, mean_q: 0.014482
 78562/100000: episode: 10828, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000159, mae: 0.007786, mean_q: 0.017233
 78568/100000: episode: 10829, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000783, mae: 0.010681, mean_q: 0.018588
 78572/100000: episode: 10830, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001026, mae: 0.014137, mean_q: 0.030251
 78575/100000: episode: 10831, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000861, mae: 0.011964, mean_q: 0.019982
 78579/100000: episode: 10832, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000556, mae: 0.007820, mean_q: 0.021375
 78583/100000: episode: 10833, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000119, mae: 0.007167, mean_q: 0.013892
 78586/100000: episode: 10834, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000095, mae: 0.006337, mean_q: 0.008176
 78590/100000: episode: 10835, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000607, mae: 0.010485, mean_q: 0.013744
 78594/100000: episode: 10836, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000311, mae: 0.008003, mean_q: 0.013327
 78597/100000: episode: 10837, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000649, mae: 0.009324, mean_q: 0.013800
 78600/100000: episode: 10838, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000428, mae: 0.009103, mean_q: 0.025805
 78606/100000: episode: 10839, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000139, mae: 0.007899, mean_q: 0.012656
 78610/100000: episode: 10840, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000653, mae: 0.010674, mean_q: 0.016041
 78614/100000: episode: 10841, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000594, mae: 0.010435, mean_q: 0.017346
 78618/100000: episode: 10842, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000986, mae: 0.014582, mean_q: 0.016710
 78622/100000: episode: 10843, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000103, mae: 0.007810, mean_q: 0.015374
 78625/100000: episode: 10844, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000374, mae: 0.011973, mean_q: 0.023893
 78631/100000: episode: 10845, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000814, mae: 0.012462, mean_q: 0.021908
 78635/100000: episode: 10846, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001511, mae: 0.011225, mean_q: 0.013732
 78639/100000: episode: 10847, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000722, mae: 0.012184, mean_q: 0.018927
 78643/100000: episode: 10848, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000912, mae: 0.011970, mean_q: 0.020644
[Info] 2-TH LEVEL FOUND: 0.08934339135885239, Considering 37/100 traces
 78647/100000: episode: 10849, duration: 0.699s, episode steps: 4, steps per second: 6, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000157, mae: 0.008497, mean_q: 0.017247
 78650/100000: episode: 10850, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000158, mae: 0.009226, mean_q: 0.015932
 78655/100000: episode: 10851, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000157, mae: 0.007323, mean_q: 0.015424
 78658/100000: episode: 10852, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000129, mae: 0.008168, mean_q: 0.014438
 78661/100000: episode: 10853, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000171, mae: 0.007262, mean_q: 0.012398
 78664/100000: episode: 10854, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000175, mae: 0.006946, mean_q: 0.010162
 78667/100000: episode: 10855, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000641, mae: 0.009404, mean_q: 0.015260
 78670/100000: episode: 10856, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000185, mae: 0.008273, mean_q: 0.017913
 78675/100000: episode: 10857, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000060, mae: 0.005902, mean_q: 0.012782
 78678/100000: episode: 10858, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000089, mae: 0.006696, mean_q: 0.012621
 78681/100000: episode: 10859, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000116, mae: 0.007584, mean_q: 0.014326
 78686/100000: episode: 10860, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000752, mae: 0.009720, mean_q: 0.024291
 78689/100000: episode: 10861, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000085, mae: 0.006862, mean_q: 0.013897
 78692/100000: episode: 10862, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000228, mae: 0.008038, mean_q: 0.013982
 78695/100000: episode: 10863, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001499, mae: 0.013331, mean_q: 0.020724
[Info] FALSIFICATION!
 78699/100000: episode: 10864, duration: 0.187s, episode steps: 4, steps per second: 21, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000157, mae: 0.007163, mean_q: 0.013454
 78702/100000: episode: 10865, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000074, mae: 0.005283, mean_q: 0.008100
 78705/100000: episode: 10866, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001376, mae: 0.012327, mean_q: 0.019786
 78708/100000: episode: 10867, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000147, mae: 0.008332, mean_q: 0.017735
[Info] FALSIFICATION!
 78712/100000: episode: 10868, duration: 0.278s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000058, mae: 0.004557, mean_q: 0.012219
[Info] FALSIFICATION!
 78716/100000: episode: 10869, duration: 0.220s, episode steps: 4, steps per second: 18, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000839, mae: 0.011694, mean_q: 0.021722
 78719/100000: episode: 10870, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000173, mae: 0.008041, mean_q: 0.016372
 78722/100000: episode: 10871, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000987, mae: 0.013615, mean_q: 0.016987
 78725/100000: episode: 10872, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000084, mae: 0.005849, mean_q: 0.011514
 78728/100000: episode: 10873, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000716, mae: 0.011022, mean_q: 0.017510
 78731/100000: episode: 10874, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000096, mae: 0.005480, mean_q: 0.008568
 78734/100000: episode: 10875, duration: 0.022s, episode steps: 3, steps per second: 134, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000626, mae: 0.008067, mean_q: 0.015391
 78739/100000: episode: 10876, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000743, mae: 0.010791, mean_q: 0.015615
 78742/100000: episode: 10877, duration: 0.019s, episode steps: 3, steps per second: 157, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000088, mae: 0.006639, mean_q: 0.011086
 78745/100000: episode: 10878, duration: 0.040s, episode steps: 3, steps per second: 74, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000411, mae: 0.010790, mean_q: 0.021905
 78748/100000: episode: 10879, duration: 0.037s, episode steps: 3, steps per second: 81, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000854, mae: 0.012870, mean_q: 0.017821
 78751/100000: episode: 10880, duration: 0.027s, episode steps: 3, steps per second: 111, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000116, mae: 0.009474, mean_q: 0.018386
 78756/100000: episode: 10881, duration: 0.053s, episode steps: 5, steps per second: 94, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000817, mae: 0.013459, mean_q: 0.020932
 78759/100000: episode: 10882, duration: 0.024s, episode steps: 3, steps per second: 128, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000154, mae: 0.006934, mean_q: 0.018189
 78762/100000: episode: 10883, duration: 0.025s, episode steps: 3, steps per second: 119, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000305, mae: 0.008823, mean_q: 0.008224
 78765/100000: episode: 10884, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000154, mae: 0.008441, mean_q: 0.013801
 78768/100000: episode: 10885, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000107, mae: 0.006573, mean_q: 0.011334
 78771/100000: episode: 10886, duration: 0.020s, episode steps: 3, steps per second: 152, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000156, mae: 0.007367, mean_q: 0.012870
 78774/100000: episode: 10887, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000303, mae: 0.010783, mean_q: 0.018223
 78777/100000: episode: 10888, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000491, mae: 0.010101, mean_q: 0.023071
 78780/100000: episode: 10889, duration: 0.026s, episode steps: 3, steps per second: 116, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000179, mae: 0.008508, mean_q: 0.016315
 78783/100000: episode: 10890, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000400, mae: 0.010530, mean_q: 0.015760
 78786/100000: episode: 10891, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000833, mae: 0.013961, mean_q: 0.028600
 78791/100000: episode: 10892, duration: 0.032s, episode steps: 5, steps per second: 157, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000111, mae: 0.006605, mean_q: 0.014393
 78794/100000: episode: 10893, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000747, mae: 0.012577, mean_q: 0.018810
 78799/100000: episode: 10894, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000696, mae: 0.011864, mean_q: 0.017483
 78802/100000: episode: 10895, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000375, mae: 0.010542, mean_q: 0.018014
 78807/100000: episode: 10896, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000333, mae: 0.007866, mean_q: 0.012944
 78810/100000: episode: 10897, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000609, mae: 0.009662, mean_q: 0.013775
 78813/100000: episode: 10898, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000523, mae: 0.013394, mean_q: 0.016892
 78818/100000: episode: 10899, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000768, mae: 0.012977, mean_q: 0.021582
 78821/100000: episode: 10900, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000277, mae: 0.009973, mean_q: 0.018800
 78824/100000: episode: 10901, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000986, mae: 0.014002, mean_q: 0.027651
 78827/100000: episode: 10902, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000102, mae: 0.007938, mean_q: 0.016083
 78830/100000: episode: 10903, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000442, mae: 0.009492, mean_q: 0.023302
 78835/100000: episode: 10904, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000405, mae: 0.008484, mean_q: 0.025350
 78838/100000: episode: 10905, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000100, mae: 0.007070, mean_q: 0.012703
 78843/100000: episode: 10906, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001012, mae: 0.013328, mean_q: 0.021078
 78846/100000: episode: 10907, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000883, mae: 0.010268, mean_q: 0.015540
 78849/100000: episode: 10908, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000079, mae: 0.006372, mean_q: 0.011939
 78852/100000: episode: 10909, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000142, mae: 0.007818, mean_q: 0.017124
 78855/100000: episode: 10910, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000179, mae: 0.008431, mean_q: 0.022359
 78858/100000: episode: 10911, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000135, mae: 0.006577, mean_q: 0.016757
[Info] Complete ISplit Iteration
[Info] Levels: [0.03245866, 0.08934339, 1.3122839]
[Info] Cond. Prob: [0.15, 0.37, 0.03]
[Info] Error Prob: 0.001665

 78863/100000: episode: 10912, duration: 0.765s, episode steps: 5, steps per second: 7, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000738, mae: 0.011119, mean_q: 0.017300
 78873/100000: episode: 10913, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000787, mae: 0.013549, mean_q: 0.021112
 78883/100000: episode: 10914, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000101, mae: 0.006424, mean_q: 0.013587
 78893/100000: episode: 10915, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000408, mae: 0.008075, mean_q: 0.021033
 78903/100000: episode: 10916, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000674, mae: 0.011615, mean_q: 0.022183
 78913/100000: episode: 10917, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000229, mae: 0.008676, mean_q: 0.018768
 78923/100000: episode: 10918, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000569, mae: 0.009116, mean_q: 0.017634
 78933/100000: episode: 10919, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000801, mae: 0.012351, mean_q: 0.019795
 78943/100000: episode: 10920, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001132, mae: 0.013930, mean_q: 0.028704
 78953/100000: episode: 10921, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000822, mae: 0.010391, mean_q: 0.017751
 78963/100000: episode: 10922, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000529, mae: 0.008455, mean_q: 0.013438
 78973/100000: episode: 10923, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000328, mae: 0.008504, mean_q: 0.016449
 78983/100000: episode: 10924, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000412, mae: 0.008180, mean_q: 0.017517
 78993/100000: episode: 10925, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000848, mae: 0.012201, mean_q: 0.021406
 79003/100000: episode: 10926, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000699, mae: 0.009625, mean_q: 0.011678
 79013/100000: episode: 10927, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000287, mae: 0.008995, mean_q: 0.017906
 79023/100000: episode: 10928, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000659, mae: 0.010175, mean_q: 0.020255
 79033/100000: episode: 10929, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000376, mae: 0.009244, mean_q: 0.018679
 79043/100000: episode: 10930, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000490, mae: 0.009976, mean_q: 0.022912
 79053/100000: episode: 10931, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000501, mae: 0.009968, mean_q: 0.019831
 79063/100000: episode: 10932, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000695, mae: 0.010746, mean_q: 0.025068
 79073/100000: episode: 10933, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000169, mae: 0.007121, mean_q: 0.014437
 79083/100000: episode: 10934, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000265, mae: 0.006951, mean_q: 0.011853
 79093/100000: episode: 10935, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000258, mae: 0.007020, mean_q: 0.012934
 79103/100000: episode: 10936, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000112, mae: 0.007017, mean_q: 0.015984
 79113/100000: episode: 10937, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000859, mae: 0.009599, mean_q: 0.019746
 79123/100000: episode: 10938, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000470, mae: 0.008912, mean_q: 0.015511
 79133/100000: episode: 10939, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000449, mae: 0.009263, mean_q: 0.015896
 79143/100000: episode: 10940, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000419, mae: 0.008810, mean_q: 0.015763
 79153/100000: episode: 10941, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000283, mae: 0.008140, mean_q: 0.015497
 79163/100000: episode: 10942, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000440, mae: 0.008263, mean_q: 0.014364
 79173/100000: episode: 10943, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000872, mae: 0.011037, mean_q: 0.019945
 79183/100000: episode: 10944, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000660, mae: 0.012198, mean_q: 0.023932
 79193/100000: episode: 10945, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000353, mae: 0.010139, mean_q: 0.022269
 79203/100000: episode: 10946, duration: 0.120s, episode steps: 10, steps per second: 84, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000384, mae: 0.008470, mean_q: 0.014520
 79213/100000: episode: 10947, duration: 0.085s, episode steps: 10, steps per second: 117, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000571, mae: 0.009705, mean_q: 0.017396
 79223/100000: episode: 10948, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000475, mae: 0.010485, mean_q: 0.021780
 79233/100000: episode: 10949, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000722, mae: 0.011235, mean_q: 0.022809
 79243/100000: episode: 10950, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000356, mae: 0.008190, mean_q: 0.014457
 79253/100000: episode: 10951, duration: 0.069s, episode steps: 10, steps per second: 146, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000671, mae: 0.012134, mean_q: 0.024980
 79263/100000: episode: 10952, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000390, mae: 0.008021, mean_q: 0.016746
 79273/100000: episode: 10953, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000497, mae: 0.009430, mean_q: 0.019522
 79283/100000: episode: 10954, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000496, mae: 0.009513, mean_q: 0.019757
 79293/100000: episode: 10955, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000593, mae: 0.009406, mean_q: 0.015710
 79303/100000: episode: 10956, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000299, mae: 0.007946, mean_q: 0.015549
 79313/100000: episode: 10957, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000785, mae: 0.010890, mean_q: 0.020562
 79323/100000: episode: 10958, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000661, mae: 0.011794, mean_q: 0.020043
 79333/100000: episode: 10959, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000143, mae: 0.006821, mean_q: 0.015828
 79343/100000: episode: 10960, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000442, mae: 0.008703, mean_q: 0.014864
 79353/100000: episode: 10961, duration: 0.106s, episode steps: 10, steps per second: 95, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000491, mae: 0.009311, mean_q: 0.016183
 79363/100000: episode: 10962, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000379, mae: 0.008596, mean_q: 0.014837
 79373/100000: episode: 10963, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000168, mae: 0.007726, mean_q: 0.013151
 79383/100000: episode: 10964, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000534, mae: 0.010985, mean_q: 0.020652
 79393/100000: episode: 10965, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000218, mae: 0.006732, mean_q: 0.013405
 79403/100000: episode: 10966, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000284, mae: 0.008078, mean_q: 0.014251
 79413/100000: episode: 10967, duration: 0.092s, episode steps: 10, steps per second: 108, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000468, mae: 0.010026, mean_q: 0.019984
 79423/100000: episode: 10968, duration: 0.088s, episode steps: 10, steps per second: 114, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000265, mae: 0.006109, mean_q: 0.010902
 79433/100000: episode: 10969, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000506, mae: 0.009432, mean_q: 0.015953
 79443/100000: episode: 10970, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000206, mae: 0.008251, mean_q: 0.016227
 79453/100000: episode: 10971, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000646, mae: 0.009599, mean_q: 0.016580
 79463/100000: episode: 10972, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000633, mae: 0.009723, mean_q: 0.023691
 79473/100000: episode: 10973, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000710, mae: 0.010841, mean_q: 0.021399
 79483/100000: episode: 10974, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000274, mae: 0.008689, mean_q: 0.017274
 79493/100000: episode: 10975, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000337, mae: 0.008618, mean_q: 0.010720
 79503/100000: episode: 10976, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000097, mae: 0.006002, mean_q: 0.011515
 79513/100000: episode: 10977, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000526, mae: 0.011973, mean_q: 0.027904
 79523/100000: episode: 10978, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000223, mae: 0.008173, mean_q: 0.015827
 79533/100000: episode: 10979, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000221, mae: 0.008082, mean_q: 0.014764
 79543/100000: episode: 10980, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000132, mae: 0.007272, mean_q: 0.016904
 79553/100000: episode: 10981, duration: 0.081s, episode steps: 10, steps per second: 124, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000929, mae: 0.012423, mean_q: 0.019167
 79563/100000: episode: 10982, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000763, mae: 0.011499, mean_q: 0.022525
 79573/100000: episode: 10983, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000792, mae: 0.010559, mean_q: 0.022733
 79583/100000: episode: 10984, duration: 0.086s, episode steps: 10, steps per second: 117, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000655, mae: 0.010344, mean_q: 0.013484
 79593/100000: episode: 10985, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000366, mae: 0.007874, mean_q: 0.009553
 79603/100000: episode: 10986, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000440, mae: 0.011537, mean_q: 0.019581
 79613/100000: episode: 10987, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000579, mae: 0.010414, mean_q: 0.020052
 79623/100000: episode: 10988, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000667, mae: 0.010452, mean_q: 0.018699
 79633/100000: episode: 10989, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000459, mae: 0.009192, mean_q: 0.016538
 79643/100000: episode: 10990, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000532, mae: 0.010094, mean_q: 0.021197
 79653/100000: episode: 10991, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000372, mae: 0.008341, mean_q: 0.010005
 79663/100000: episode: 10992, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000329, mae: 0.007868, mean_q: 0.016460
 79673/100000: episode: 10993, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000617, mae: 0.010142, mean_q: 0.019115
 79683/100000: episode: 10994, duration: 0.073s, episode steps: 10, steps per second: 138, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000445, mae: 0.008234, mean_q: 0.013748
 79693/100000: episode: 10995, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000272, mae: 0.006614, mean_q: 0.010193
 79703/100000: episode: 10996, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000848, mae: 0.011223, mean_q: 0.017792
 79713/100000: episode: 10997, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001031, mae: 0.014127, mean_q: 0.026217
 79723/100000: episode: 10998, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000236, mae: 0.008513, mean_q: 0.017898
 79733/100000: episode: 10999, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000339, mae: 0.009121, mean_q: 0.018201
 79743/100000: episode: 11000, duration: 0.071s, episode steps: 10, steps per second: 142, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000820, mae: 0.012180, mean_q: 0.025714
 79753/100000: episode: 11001, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000597, mae: 0.009965, mean_q: 0.017606
 79763/100000: episode: 11002, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000342, mae: 0.009772, mean_q: 0.015733
 79773/100000: episode: 11003, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000152, mae: 0.007977, mean_q: 0.015395
 79783/100000: episode: 11004, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000621, mae: 0.009920, mean_q: 0.017999
 79793/100000: episode: 11005, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000457, mae: 0.008138, mean_q: 0.013527
 79803/100000: episode: 11006, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000336, mae: 0.007834, mean_q: 0.016613
 79813/100000: episode: 11007, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000516, mae: 0.010274, mean_q: 0.021252
 79823/100000: episode: 11008, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000272, mae: 0.008252, mean_q: 0.020816
 79833/100000: episode: 11009, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000826, mae: 0.014144, mean_q: 0.017496
 79843/100000: episode: 11010, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000653, mae: 0.011769, mean_q: 0.017340
 79853/100000: episode: 11011, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000656, mae: 0.009960, mean_q: 0.016702
[Info] 1-TH LEVEL FOUND: 0.0931265577673912, Considering 12/100 traces
 79863/100000: episode: 11012, duration: 0.796s, episode steps: 10, steps per second: 13, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000573, mae: 0.010691, mean_q: 0.018563
 79867/100000: episode: 11013, duration: 0.078s, episode steps: 4, steps per second: 51, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000309, mae: 0.011933, mean_q: 0.024968
 79871/100000: episode: 11014, duration: 0.042s, episode steps: 4, steps per second: 95, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000161, mae: 0.006666, mean_q: 0.017634
 79875/100000: episode: 11015, duration: 0.035s, episode steps: 4, steps per second: 113, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000209, mae: 0.008250, mean_q: 0.015866
[Info] FALSIFICATION!
 79879/100000: episode: 11016, duration: 0.276s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000094, mae: 0.006492, mean_q: 0.010667
 79883/100000: episode: 11017, duration: 0.028s, episode steps: 4, steps per second: 143, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000266, mae: 0.008658, mean_q: 0.016236
 79887/100000: episode: 11018, duration: 0.040s, episode steps: 4, steps per second: 100, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000326, mae: 0.009879, mean_q: 0.023997
 79891/100000: episode: 11019, duration: 0.040s, episode steps: 4, steps per second: 100, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001566, mae: 0.014848, mean_q: 0.026264
 79895/100000: episode: 11020, duration: 0.030s, episode steps: 4, steps per second: 132, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000102, mae: 0.006255, mean_q: 0.012029
 79899/100000: episode: 11021, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000160, mae: 0.007650, mean_q: 0.017776
 79903/100000: episode: 11022, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001123, mae: 0.012732, mean_q: 0.021836
 79907/100000: episode: 11023, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000476, mae: 0.010005, mean_q: 0.019943
 79911/100000: episode: 11024, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000127, mae: 0.006824, mean_q: 0.013050
 79915/100000: episode: 11025, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000149, mae: 0.006817, mean_q: 0.013307
 79919/100000: episode: 11026, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000778, mae: 0.012159, mean_q: 0.021288
 79923/100000: episode: 11027, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000281, mae: 0.010037, mean_q: 0.018421
 79927/100000: episode: 11028, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000207, mae: 0.008896, mean_q: 0.010409
 79931/100000: episode: 11029, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000213, mae: 0.009340, mean_q: 0.011585
 79935/100000: episode: 11030, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000152, mae: 0.007588, mean_q: 0.011942
 79939/100000: episode: 11031, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000139, mae: 0.008308, mean_q: 0.018293
 79944/100000: episode: 11032, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000763, mae: 0.011536, mean_q: 0.019354
 79948/100000: episode: 11033, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000099, mae: 0.007629, mean_q: 0.013891
 79952/100000: episode: 11034, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000917, mae: 0.011893, mean_q: 0.016753
 79956/100000: episode: 11035, duration: 0.044s, episode steps: 4, steps per second: 91, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000180, mae: 0.009989, mean_q: 0.020730
 79960/100000: episode: 11036, duration: 0.049s, episode steps: 4, steps per second: 81, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000163, mae: 0.008870, mean_q: 0.019428
 79964/100000: episode: 11037, duration: 0.036s, episode steps: 4, steps per second: 112, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000124, mae: 0.008052, mean_q: 0.015757
 79969/100000: episode: 11038, duration: 0.038s, episode steps: 5, steps per second: 132, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000139, mae: 0.007502, mean_q: 0.017921
 79973/100000: episode: 11039, duration: 0.030s, episode steps: 4, steps per second: 134, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000169, mae: 0.008505, mean_q: 0.016857
 79977/100000: episode: 11040, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000306, mae: 0.008763, mean_q: 0.011112
 79981/100000: episode: 11041, duration: 0.024s, episode steps: 4, steps per second: 167, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000180, mae: 0.007678, mean_q: 0.012950
 79985/100000: episode: 11042, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000516, mae: 0.008427, mean_q: 0.015679
 79989/100000: episode: 11043, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000240, mae: 0.007722, mean_q: 0.013837
 79993/100000: episode: 11044, duration: 0.036s, episode steps: 4, steps per second: 113, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000854, mae: 0.011755, mean_q: 0.022866
 79997/100000: episode: 11045, duration: 0.046s, episode steps: 4, steps per second: 87, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000169, mae: 0.008450, mean_q: 0.017751
 80001/100000: episode: 11046, duration: 0.044s, episode steps: 4, steps per second: 90, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000288, mae: 0.008708, mean_q: 0.021035
 80006/100000: episode: 11047, duration: 0.053s, episode steps: 5, steps per second: 94, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000153, mae: 0.006754, mean_q: 0.011170
 80010/100000: episode: 11048, duration: 0.038s, episode steps: 4, steps per second: 105, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000875, mae: 0.012546, mean_q: 0.015679
 80015/100000: episode: 11049, duration: 0.032s, episode steps: 5, steps per second: 156, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000990, mae: 0.013440, mean_q: 0.026940
 80019/100000: episode: 11050, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000343, mae: 0.009929, mean_q: 0.018068
 80023/100000: episode: 11051, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000537, mae: 0.010179, mean_q: 0.017074
 80027/100000: episode: 11052, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000191, mae: 0.010297, mean_q: 0.018467
 80031/100000: episode: 11053, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000113, mae: 0.007225, mean_q: 0.016314
 80035/100000: episode: 11054, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000159, mae: 0.007621, mean_q: 0.014560
 80039/100000: episode: 11055, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000147, mae: 0.007976, mean_q: 0.017334
 80043/100000: episode: 11056, duration: 0.026s, episode steps: 4, steps per second: 156, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000087, mae: 0.006409, mean_q: 0.012283
 80048/100000: episode: 11057, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000101, mae: 0.006966, mean_q: 0.010294
 80052/100000: episode: 11058, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000405, mae: 0.008268, mean_q: 0.015557
 80056/100000: episode: 11059, duration: 0.065s, episode steps: 4, steps per second: 62, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000433, mae: 0.008782, mean_q: 0.014620
 80060/100000: episode: 11060, duration: 0.043s, episode steps: 4, steps per second: 93, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000478, mae: 0.010092, mean_q: 0.020711
 80064/100000: episode: 11061, duration: 0.040s, episode steps: 4, steps per second: 100, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000388, mae: 0.008093, mean_q: 0.016247
 80068/100000: episode: 11062, duration: 0.044s, episode steps: 4, steps per second: 90, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000091, mae: 0.005425, mean_q: 0.008624
 80072/100000: episode: 11063, duration: 0.034s, episode steps: 4, steps per second: 116, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000892, mae: 0.010890, mean_q: 0.013867
 80076/100000: episode: 11064, duration: 0.034s, episode steps: 4, steps per second: 117, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000440, mae: 0.009881, mean_q: 0.021493
 80080/100000: episode: 11065, duration: 0.025s, episode steps: 4, steps per second: 160, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000107, mae: 0.007644, mean_q: 0.015989
 80084/100000: episode: 11066, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000953, mae: 0.015253, mean_q: 0.030436
 80088/100000: episode: 11067, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000173, mae: 0.009268, mean_q: 0.018163
 80092/100000: episode: 11068, duration: 0.027s, episode steps: 4, steps per second: 148, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000336, mae: 0.009252, mean_q: 0.022741
 80097/100000: episode: 11069, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000555, mae: 0.011583, mean_q: 0.020874
 80101/100000: episode: 11070, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000086, mae: 0.004921, mean_q: 0.009006
 80105/100000: episode: 11071, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000077, mae: 0.005207, mean_q: 0.008978
 80109/100000: episode: 11072, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000178, mae: 0.008132, mean_q: 0.017411
 80113/100000: episode: 11073, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000068, mae: 0.005573, mean_q: 0.012341
 80117/100000: episode: 11074, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000663, mae: 0.008719, mean_q: 0.015866
 80121/100000: episode: 11075, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000199, mae: 0.008301, mean_q: 0.019185
 80125/100000: episode: 11076, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000168, mae: 0.008250, mean_q: 0.015127
 80129/100000: episode: 11077, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000162, mae: 0.007330, mean_q: 0.015835
 80133/100000: episode: 11078, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000167, mae: 0.008568, mean_q: 0.017372
 80137/100000: episode: 11079, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000125, mae: 0.008015, mean_q: 0.018060
 80141/100000: episode: 11080, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000200, mae: 0.009638, mean_q: 0.018909
 80145/100000: episode: 11081, duration: 0.026s, episode steps: 4, steps per second: 151, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000717, mae: 0.010513, mean_q: 0.021467
 80149/100000: episode: 11082, duration: 0.039s, episode steps: 4, steps per second: 102, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000516, mae: 0.007616, mean_q: 0.011739
 80153/100000: episode: 11083, duration: 0.026s, episode steps: 4, steps per second: 151, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000118, mae: 0.007122, mean_q: 0.013685
 80158/100000: episode: 11084, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000471, mae: 0.011220, mean_q: 0.021946
 80162/100000: episode: 11085, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000097, mae: 0.006185, mean_q: 0.012747
 80166/100000: episode: 11086, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000179, mae: 0.008031, mean_q: 0.015150
 80170/100000: episode: 11087, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000997, mae: 0.013679, mean_q: 0.021932
 80174/100000: episode: 11088, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000391, mae: 0.008907, mean_q: 0.020344
 80178/100000: episode: 11089, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000567, mae: 0.008777, mean_q: 0.015265
 80182/100000: episode: 11090, duration: 0.027s, episode steps: 4, steps per second: 150, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000804, mae: 0.011476, mean_q: 0.022300
 80186/100000: episode: 11091, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000232, mae: 0.009102, mean_q: 0.016129
 80190/100000: episode: 11092, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000755, mae: 0.008906, mean_q: 0.016113
 80194/100000: episode: 11093, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000924, mae: 0.013725, mean_q: 0.027784
 80198/100000: episode: 11094, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000117, mae: 0.006497, mean_q: 0.010402
 80202/100000: episode: 11095, duration: 0.020s, episode steps: 4, steps per second: 199, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000379, mae: 0.009024, mean_q: 0.017835
 80206/100000: episode: 11096, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000218, mae: 0.009069, mean_q: 0.016694
 80210/100000: episode: 11097, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000510, mae: 0.010263, mean_q: 0.021803
 80214/100000: episode: 11098, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000401, mae: 0.009546, mean_q: 0.021060
 80218/100000: episode: 11099, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000346, mae: 0.008928, mean_q: 0.016535
[Info] Complete ISplit Iteration
[Info] Levels: [0.09312656, 1.2017965]
[Info] Cond. Prob: [0.12, 0.01]
[Info] Error Prob: 0.0012

 80222/100000: episode: 11100, duration: 1.081s, episode steps: 4, steps per second: 4, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000476, mae: 0.011732, mean_q: 0.019774
 80232/100000: episode: 11101, duration: 0.072s, episode steps: 10, steps per second: 138, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000765, mae: 0.012575, mean_q: 0.025277
 80242/100000: episode: 11102, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000392, mae: 0.009177, mean_q: 0.015158
 80252/100000: episode: 11103, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000191, mae: 0.007613, mean_q: 0.012873
 80262/100000: episode: 11104, duration: 0.077s, episode steps: 10, steps per second: 129, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000183, mae: 0.007218, mean_q: 0.012996
 80272/100000: episode: 11105, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000731, mae: 0.012200, mean_q: 0.022531
 80282/100000: episode: 11106, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000143, mae: 0.006545, mean_q: 0.012861
 80292/100000: episode: 11107, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000398, mae: 0.007574, mean_q: 0.013025
 80302/100000: episode: 11108, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000563, mae: 0.010168, mean_q: 0.019479
 80312/100000: episode: 11109, duration: 0.109s, episode steps: 10, steps per second: 92, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000496, mae: 0.009532, mean_q: 0.018029
 80322/100000: episode: 11110, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000340, mae: 0.008698, mean_q: 0.017504
 80332/100000: episode: 11111, duration: 0.068s, episode steps: 10, steps per second: 146, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000155, mae: 0.007085, mean_q: 0.011593
 80342/100000: episode: 11112, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000213, mae: 0.007412, mean_q: 0.014350
 80352/100000: episode: 11113, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000245, mae: 0.007095, mean_q: 0.013304
 80362/100000: episode: 11114, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000227, mae: 0.006391, mean_q: 0.012295
 80372/100000: episode: 11115, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000125, mae: 0.006993, mean_q: 0.011932
 80382/100000: episode: 11116, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000593, mae: 0.008549, mean_q: 0.014603
 80392/100000: episode: 11117, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000109, mae: 0.007191, mean_q: 0.013175
 80402/100000: episode: 11118, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000420, mae: 0.008001, mean_q: 0.017516
 80412/100000: episode: 11119, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000164, mae: 0.006459, mean_q: 0.011697
 80422/100000: episode: 11120, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000349, mae: 0.008868, mean_q: 0.015662
 80432/100000: episode: 11121, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000077, mae: 0.006098, mean_q: 0.011463
 80442/100000: episode: 11122, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000492, mae: 0.009318, mean_q: 0.021010
 80452/100000: episode: 11123, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000260, mae: 0.007965, mean_q: 0.020444
 80462/100000: episode: 11124, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000452, mae: 0.008167, mean_q: 0.016810
 80472/100000: episode: 11125, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000115, mae: 0.006094, mean_q: 0.012676
 80482/100000: episode: 11126, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000239, mae: 0.007283, mean_q: 0.014208
 80492/100000: episode: 11127, duration: 0.083s, episode steps: 10, steps per second: 120, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000468, mae: 0.008735, mean_q: 0.020457
 80502/100000: episode: 11128, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000513, mae: 0.010554, mean_q: 0.015184
 80512/100000: episode: 11129, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000405, mae: 0.011257, mean_q: 0.012489
 80522/100000: episode: 11130, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000182, mae: 0.007875, mean_q: 0.015275
 80532/100000: episode: 11131, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000316, mae: 0.009286, mean_q: 0.012669
 80542/100000: episode: 11132, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000182, mae: 0.009087, mean_q: 0.019046
 80552/100000: episode: 11133, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000267, mae: 0.007356, mean_q: 0.019887
 80562/100000: episode: 11134, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000557, mae: 0.009770, mean_q: 0.016038
 80572/100000: episode: 11135, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000089, mae: 0.006025, mean_q: 0.010593
 80582/100000: episode: 11136, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000434, mae: 0.007397, mean_q: 0.010943
 80592/100000: episode: 11137, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000408, mae: 0.009121, mean_q: 0.014341
 80602/100000: episode: 11138, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000144, mae: 0.007995, mean_q: 0.015215
 80612/100000: episode: 11139, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000151, mae: 0.006804, mean_q: 0.015161
 80622/100000: episode: 11140, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000236, mae: 0.007238, mean_q: 0.013421
 80632/100000: episode: 11141, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000098, mae: 0.007127, mean_q: 0.013634
 80642/100000: episode: 11142, duration: 0.080s, episode steps: 10, steps per second: 124, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000209, mae: 0.006986, mean_q: 0.012871
 80652/100000: episode: 11143, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000495, mae: 0.008027, mean_q: 0.014333
 80662/100000: episode: 11144, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000286, mae: 0.007331, mean_q: 0.016626
 80672/100000: episode: 11145, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000191, mae: 0.006625, mean_q: 0.011131
 80682/100000: episode: 11146, duration: 0.088s, episode steps: 10, steps per second: 114, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000451, mae: 0.009526, mean_q: 0.019069
 80692/100000: episode: 11147, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000139, mae: 0.007019, mean_q: 0.013586
 80702/100000: episode: 11148, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000681, mae: 0.009324, mean_q: 0.016610
 80712/100000: episode: 11149, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000209, mae: 0.006896, mean_q: 0.020297
 80722/100000: episode: 11150, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000298, mae: 0.009621, mean_q: 0.016132
 80732/100000: episode: 11151, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000599, mae: 0.009617, mean_q: 0.018079
 80742/100000: episode: 11152, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000657, mae: 0.009489, mean_q: 0.015278
 80752/100000: episode: 11153, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000180, mae: 0.006190, mean_q: 0.011613
 80762/100000: episode: 11154, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000435, mae: 0.008889, mean_q: 0.019516
 80772/100000: episode: 11155, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000520, mae: 0.009265, mean_q: 0.015387
 80782/100000: episode: 11156, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000316, mae: 0.007592, mean_q: 0.016468
 80792/100000: episode: 11157, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000343, mae: 0.007377, mean_q: 0.010369
 80802/100000: episode: 11158, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000242, mae: 0.008171, mean_q: 0.014836
 80812/100000: episode: 11159, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000255, mae: 0.005891, mean_q: 0.009775
 80822/100000: episode: 11160, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000134, mae: 0.006036, mean_q: 0.011049
 80832/100000: episode: 11161, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000226, mae: 0.007391, mean_q: 0.012972
 80842/100000: episode: 11162, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000608, mae: 0.008827, mean_q: 0.013400
 80852/100000: episode: 11163, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000133, mae: 0.008224, mean_q: 0.014186
 80862/100000: episode: 11164, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000619, mae: 0.012382, mean_q: 0.020903
 80872/100000: episode: 11165, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000127, mae: 0.007497, mean_q: 0.018904
 80882/100000: episode: 11166, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000198, mae: 0.007883, mean_q: 0.010569
 80892/100000: episode: 11167, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000492, mae: 0.008148, mean_q: 0.013205
 80902/100000: episode: 11168, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000111, mae: 0.007431, mean_q: 0.018611
 80912/100000: episode: 11169, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000586, mae: 0.010502, mean_q: 0.018921
 80922/100000: episode: 11170, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000514, mae: 0.008405, mean_q: 0.018951
 80932/100000: episode: 11171, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000396, mae: 0.008731, mean_q: 0.016302
 80942/100000: episode: 11172, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001128, mae: 0.011822, mean_q: 0.020262
 80952/100000: episode: 11173, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000080, mae: 0.005005, mean_q: 0.010093
 80962/100000: episode: 11174, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000325, mae: 0.008571, mean_q: 0.018334
 80972/100000: episode: 11175, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000534, mae: 0.009231, mean_q: 0.015429
 80982/100000: episode: 11176, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000229, mae: 0.006979, mean_q: 0.013718
 80992/100000: episode: 11177, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000437, mae: 0.009432, mean_q: 0.018875
 81002/100000: episode: 11178, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000212, mae: 0.007738, mean_q: 0.016197
 81012/100000: episode: 11179, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000433, mae: 0.007263, mean_q: 0.012287
 81022/100000: episode: 11180, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000405, mae: 0.008032, mean_q: 0.016482
 81032/100000: episode: 11181, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000120, mae: 0.007044, mean_q: 0.011043
 81042/100000: episode: 11182, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000090, mae: 0.006050, mean_q: 0.011321
 81052/100000: episode: 11183, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000214, mae: 0.008731, mean_q: 0.017394
 81062/100000: episode: 11184, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000502, mae: 0.010122, mean_q: 0.017434
 81072/100000: episode: 11185, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000325, mae: 0.007725, mean_q: 0.013013
 81082/100000: episode: 11186, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000473, mae: 0.008200, mean_q: 0.012708
 81092/100000: episode: 11187, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000226, mae: 0.008159, mean_q: 0.019006
 81102/100000: episode: 11188, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000386, mae: 0.007652, mean_q: 0.015452
 81112/100000: episode: 11189, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000489, mae: 0.008965, mean_q: 0.014404
 81122/100000: episode: 11190, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000522, mae: 0.010778, mean_q: 0.020156
 81132/100000: episode: 11191, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000755, mae: 0.009202, mean_q: 0.017964
 81142/100000: episode: 11192, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000593, mae: 0.009153, mean_q: 0.021127
 81152/100000: episode: 11193, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000461, mae: 0.007897, mean_q: 0.017261
 81162/100000: episode: 11194, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000088, mae: 0.006143, mean_q: 0.017751
 81172/100000: episode: 11195, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000401, mae: 0.007871, mean_q: 0.013590
 81182/100000: episode: 11196, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000314, mae: 0.008034, mean_q: 0.015470
 81192/100000: episode: 11197, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000245, mae: 0.008864, mean_q: 0.016089
 81202/100000: episode: 11198, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000640, mae: 0.008723, mean_q: 0.014741
 81212/100000: episode: 11199, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000585, mae: 0.009644, mean_q: 0.018251
[Info] 1-TH LEVEL FOUND: 0.03137161582708359, Considering 14/100 traces
 81222/100000: episode: 11200, duration: 0.670s, episode steps: 10, steps per second: 15, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000274, mae: 0.007701, mean_q: 0.013140
 81225/100000: episode: 11201, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000064, mae: 0.004639, mean_q: 0.007091
 81228/100000: episode: 11202, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000244, mae: 0.006739, mean_q: 0.011401
 81231/100000: episode: 11203, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000107, mae: 0.006398, mean_q: 0.012360
 81234/100000: episode: 11204, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000475, mae: 0.009040, mean_q: 0.017461
 81238/100000: episode: 11205, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000208, mae: 0.007072, mean_q: 0.013232
 81244/100000: episode: 11206, duration: 0.031s, episode steps: 6, steps per second: 197, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000202, mae: 0.007513, mean_q: 0.012366
 81247/100000: episode: 11207, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000262, mae: 0.008519, mean_q: 0.016503
 81250/100000: episode: 11208, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000070, mae: 0.006121, mean_q: 0.012050
 81254/100000: episode: 11209, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001029, mae: 0.010340, mean_q: 0.013317
 81257/100000: episode: 11210, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000092, mae: 0.007226, mean_q: 0.015666
 81260/100000: episode: 11211, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000199, mae: 0.008048, mean_q: 0.015511
 81263/100000: episode: 11212, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000126, mae: 0.008245, mean_q: 0.017961
 81267/100000: episode: 11213, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000028, mae: 0.004397, mean_q: 0.010687
 81270/100000: episode: 11214, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000209, mae: 0.007781, mean_q: 0.012859
 81273/100000: episode: 11215, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000233, mae: 0.008263, mean_q: 0.015373
 81276/100000: episode: 11216, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000241, mae: 0.009915, mean_q: 0.017521
 81279/100000: episode: 11217, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001227, mae: 0.013507, mean_q: 0.027998
 81282/100000: episode: 11218, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000097, mae: 0.005789, mean_q: 0.012572
 81285/100000: episode: 11219, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001687, mae: 0.015991, mean_q: 0.015788
 81289/100000: episode: 11220, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000078, mae: 0.005346, mean_q: 0.006458
 81293/100000: episode: 11221, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000189, mae: 0.006882, mean_q: 0.017018
 81296/100000: episode: 11222, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000244, mae: 0.009520, mean_q: 0.017090
 81300/100000: episode: 11223, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000091, mae: 0.007026, mean_q: 0.014133
 81303/100000: episode: 11224, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000092, mae: 0.007101, mean_q: 0.013043
 81307/100000: episode: 11225, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000300, mae: 0.008913, mean_q: 0.021036
 81310/100000: episode: 11226, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000111, mae: 0.006190, mean_q: 0.012133
 81314/100000: episode: 11227, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000232, mae: 0.009378, mean_q: 0.017716
 81318/100000: episode: 11228, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000092, mae: 0.006235, mean_q: 0.013771
 81321/100000: episode: 11229, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000062, mae: 0.005261, mean_q: 0.011998
 81324/100000: episode: 11230, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000055, mae: 0.004443, mean_q: 0.009200
 81328/100000: episode: 11231, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000225, mae: 0.008289, mean_q: 0.015856
 81331/100000: episode: 11232, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000735, mae: 0.008225, mean_q: 0.012565
 81334/100000: episode: 11233, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000103, mae: 0.006455, mean_q: 0.012935
 81338/100000: episode: 11234, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000091, mae: 0.006498, mean_q: 0.013664
 81341/100000: episode: 11235, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000202, mae: 0.007449, mean_q: 0.014239
 81344/100000: episode: 11236, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000111, mae: 0.006778, mean_q: 0.013834
 81347/100000: episode: 11237, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000178, mae: 0.006455, mean_q: 0.012230
 81351/100000: episode: 11238, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000311, mae: 0.009531, mean_q: 0.015929
 81354/100000: episode: 11239, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000609, mae: 0.009360, mean_q: 0.016625
 81357/100000: episode: 11240, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000826, mae: 0.009935, mean_q: 0.022050
 81360/100000: episode: 11241, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000123, mae: 0.006390, mean_q: 0.011446
 81364/100000: episode: 11242, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000272, mae: 0.007571, mean_q: 0.012688
 81367/100000: episode: 11243, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000435, mae: 0.008807, mean_q: 0.020449
 81370/100000: episode: 11244, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000186, mae: 0.006946, mean_q: 0.016144
 81373/100000: episode: 11245, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000150, mae: 0.008359, mean_q: 0.013403
 81377/100000: episode: 11246, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000053, mae: 0.005587, mean_q: 0.011758
 81383/100000: episode: 11247, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000164, mae: 0.009124, mean_q: 0.017548
 81386/100000: episode: 11248, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000126, mae: 0.009090, mean_q: 0.020403
 81390/100000: episode: 11249, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000504, mae: 0.011091, mean_q: 0.027826
 81393/100000: episode: 11250, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000086, mae: 0.005792, mean_q: 0.012662
 81399/100000: episode: 11251, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000090, mae: 0.006835, mean_q: 0.007131
 81405/100000: episode: 11252, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000525, mae: 0.008725, mean_q: 0.010705
 81409/100000: episode: 11253, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000503, mae: 0.010279, mean_q: 0.022634
 81412/100000: episode: 11254, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000257, mae: 0.010323, mean_q: 0.023964
 81415/100000: episode: 11255, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000258, mae: 0.008702, mean_q: 0.016502
 81418/100000: episode: 11256, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000108, mae: 0.007842, mean_q: 0.014375
 81422/100000: episode: 11257, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000176, mae: 0.006116, mean_q: 0.009446
 81425/100000: episode: 11258, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000730, mae: 0.010578, mean_q: 0.024435
 81428/100000: episode: 11259, duration: 0.016s, episode steps: 3, steps per second: 186, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001021, mae: 0.015985, mean_q: 0.021802
 81431/100000: episode: 11260, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000094, mae: 0.006511, mean_q: 0.013329
 81435/100000: episode: 11261, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000387, mae: 0.008787, mean_q: 0.016838
 81438/100000: episode: 11262, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000137, mae: 0.007118, mean_q: 0.014147
 81441/100000: episode: 11263, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000367, mae: 0.009863, mean_q: 0.016864
 81444/100000: episode: 11264, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000069, mae: 0.005718, mean_q: 0.007130
 81447/100000: episode: 11265, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000195, mae: 0.010199, mean_q: 0.004739
 81450/100000: episode: 11266, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000131, mae: 0.007265, mean_q: 0.007365
 81454/100000: episode: 11267, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000804, mae: 0.011171, mean_q: 0.018456
 81458/100000: episode: 11268, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001003, mae: 0.012815, mean_q: 0.017155
 81461/100000: episode: 11269, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000278, mae: 0.011075, mean_q: 0.018330
 81464/100000: episode: 11270, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000122, mae: 0.009249, mean_q: 0.017097
 81467/100000: episode: 11271, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000241, mae: 0.011450, mean_q: 0.019556
 81470/100000: episode: 11272, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000077, mae: 0.006043, mean_q: 0.010685
 81473/100000: episode: 11273, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000315, mae: 0.010255, mean_q: 0.014979
 81476/100000: episode: 11274, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000091, mae: 0.006827, mean_q: 0.006607
 81479/100000: episode: 11275, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000087, mae: 0.005201, mean_q: 0.006954
 81482/100000: episode: 11276, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000213, mae: 0.009860, mean_q: 0.018129
 81485/100000: episode: 11277, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000171, mae: 0.006127, mean_q: 0.010157
 81488/100000: episode: 11278, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001436, mae: 0.011967, mean_q: 0.016992
 81491/100000: episode: 11279, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000126, mae: 0.007875, mean_q: 0.016193
 81494/100000: episode: 11280, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000294, mae: 0.008990, mean_q: 0.020367
 81497/100000: episode: 11281, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000104, mae: 0.007571, mean_q: 0.015854
 81500/100000: episode: 11282, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000170, mae: 0.006264, mean_q: 0.012579
 81503/100000: episode: 11283, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000131, mae: 0.004729, mean_q: 0.006938
 81506/100000: episode: 11284, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000113, mae: 0.007849, mean_q: 0.013952
 81509/100000: episode: 11285, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001313, mae: 0.011836, mean_q: 0.014924
[Info] 2-TH LEVEL FOUND: 0.10358302295207977, Considering 17/100 traces
 81512/100000: episode: 11286, duration: 0.738s, episode steps: 3, steps per second: 4, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000126, mae: 0.006718, mean_q: 0.012946
 81515/100000: episode: 11287, duration: 0.030s, episode steps: 3, steps per second: 101, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000111, mae: 0.007635, mean_q: 0.015856
 81518/100000: episode: 11288, duration: 0.028s, episode steps: 3, steps per second: 106, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000227, mae: 0.009769, mean_q: 0.018887
 81521/100000: episode: 11289, duration: 0.035s, episode steps: 3, steps per second: 85, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000261, mae: 0.010523, mean_q: 0.018539
 81524/100000: episode: 11290, duration: 0.026s, episode steps: 3, steps per second: 117, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000074, mae: 0.005123, mean_q: 0.008345
 81529/100000: episode: 11291, duration: 0.037s, episode steps: 5, steps per second: 137, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000075, mae: 0.005366, mean_q: 0.009752
 81532/100000: episode: 11292, duration: 0.025s, episode steps: 3, steps per second: 119, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000181, mae: 0.009997, mean_q: 0.019702
 81535/100000: episode: 11293, duration: 0.022s, episode steps: 3, steps per second: 135, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000088, mae: 0.005867, mean_q: 0.012493
 81538/100000: episode: 11294, duration: 0.021s, episode steps: 3, steps per second: 144, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000090, mae: 0.006759, mean_q: 0.012132
 81541/100000: episode: 11295, duration: 0.025s, episode steps: 3, steps per second: 119, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000239, mae: 0.008986, mean_q: 0.016462
[Info] FALSIFICATION!
 81545/100000: episode: 11296, duration: 0.297s, episode steps: 4, steps per second: 13, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000169, mae: 0.008035, mean_q: 0.015608
 81548/100000: episode: 11297, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000097, mae: 0.006582, mean_q: 0.012729
 81551/100000: episode: 11298, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000192, mae: 0.007536, mean_q: 0.011128
 81554/100000: episode: 11299, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000112, mae: 0.007026, mean_q: 0.013640
 81557/100000: episode: 11300, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000271, mae: 0.010650, mean_q: 0.018605
 81560/100000: episode: 11301, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001368, mae: 0.014311, mean_q: 0.018527
 81563/100000: episode: 11302, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000120, mae: 0.008807, mean_q: 0.013106
 81566/100000: episode: 11303, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000093, mae: 0.008301, mean_q: 0.012223
 81569/100000: episode: 11304, duration: 0.016s, episode steps: 3, steps per second: 187, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000292, mae: 0.009527, mean_q: 0.023455
 81572/100000: episode: 11305, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001716, mae: 0.023004, mean_q: 0.049791
 81577/100000: episode: 11306, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000925, mae: 0.013005, mean_q: 0.023729
 81580/100000: episode: 11307, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000043, mae: 0.004502, mean_q: 0.006551
 81583/100000: episode: 11308, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000056, mae: 0.005595, mean_q: 0.010949
 81586/100000: episode: 11309, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000176, mae: 0.008750, mean_q: 0.016776
 81589/100000: episode: 11310, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000092, mae: 0.005500, mean_q: 0.010677
 81592/100000: episode: 11311, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000204, mae: 0.007308, mean_q: 0.017864
 81595/100000: episode: 11312, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000446, mae: 0.011165, mean_q: 0.027327
 81600/100000: episode: 11313, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000639, mae: 0.010234, mean_q: 0.019468
 81603/100000: episode: 11314, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000097, mae: 0.006619, mean_q: 0.016649
 81606/100000: episode: 11315, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000202, mae: 0.009197, mean_q: 0.019470
 81609/100000: episode: 11316, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000532, mae: 0.010354, mean_q: 0.019083
 81612/100000: episode: 11317, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000165, mae: 0.007429, mean_q: 0.014260
 81617/100000: episode: 11318, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000211, mae: 0.007130, mean_q: 0.014314
 81620/100000: episode: 11319, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000087, mae: 0.005814, mean_q: 0.022427
 81623/100000: episode: 11320, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000067, mae: 0.005397, mean_q: 0.010318
 81626/100000: episode: 11321, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000145, mae: 0.006919, mean_q: 0.017980
 81629/100000: episode: 11322, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000063, mae: 0.004764, mean_q: 0.011991
 81634/100000: episode: 11323, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000101, mae: 0.006464, mean_q: 0.014868
 81637/100000: episode: 11324, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000091, mae: 0.005834, mean_q: 0.012996
 81640/100000: episode: 11325, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000090, mae: 0.005816, mean_q: 0.019705
 81643/100000: episode: 11326, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001051, mae: 0.010121, mean_q: 0.015281
 81646/100000: episode: 11327, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000105, mae: 0.006418, mean_q: 0.012253
 81649/100000: episode: 11328, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000581, mae: 0.009431, mean_q: 0.029596
 81652/100000: episode: 11329, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001243, mae: 0.013109, mean_q: 0.019232
 81655/100000: episode: 11330, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000157, mae: 0.008092, mean_q: 0.014029
 81658/100000: episode: 11331, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000715, mae: 0.009130, mean_q: 0.014887
 81661/100000: episode: 11332, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000136, mae: 0.006359, mean_q: 0.013304
 81664/100000: episode: 11333, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001033, mae: 0.010865, mean_q: 0.017289
 81667/100000: episode: 11334, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000411, mae: 0.010688, mean_q: 0.017520
 81670/100000: episode: 11335, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000344, mae: 0.012286, mean_q: 0.025233
 81673/100000: episode: 11336, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000332, mae: 0.012360, mean_q: 0.021523
 81676/100000: episode: 11337, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000037, mae: 0.004434, mean_q: 0.007275
 81679/100000: episode: 11338, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000089, mae: 0.006621, mean_q: 0.011422
 81682/100000: episode: 11339, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000131, mae: 0.006210, mean_q: 0.013188
 81685/100000: episode: 11340, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000094, mae: 0.005365, mean_q: 0.009566
 81688/100000: episode: 11341, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000285, mae: 0.008869, mean_q: 0.014362
 81691/100000: episode: 11342, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000291, mae: 0.009832, mean_q: 0.016932
 81694/100000: episode: 11343, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000102, mae: 0.007386, mean_q: 0.017405
 81697/100000: episode: 11344, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000220, mae: 0.008825, mean_q: 0.026491
 81700/100000: episode: 11345, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000119, mae: 0.007924, mean_q: 0.015913
 81703/100000: episode: 11346, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001031, mae: 0.013837, mean_q: 0.031164
 81706/100000: episode: 11347, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000115, mae: 0.007014, mean_q: 0.010055
 81709/100000: episode: 11348, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000269, mae: 0.008001, mean_q: 0.009901
 81712/100000: episode: 11349, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000084, mae: 0.005866, mean_q: 0.008033
 81715/100000: episode: 11350, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000279, mae: 0.008701, mean_q: 0.019472
 81718/100000: episode: 11351, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000995, mae: 0.012393, mean_q: 0.019043
 81723/100000: episode: 11352, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000140, mae: 0.009216, mean_q: 0.017125
 81728/100000: episode: 11353, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000120, mae: 0.008906, mean_q: 0.019403
 81733/100000: episode: 11354, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000124, mae: 0.007927, mean_q: 0.016332
 81736/100000: episode: 11355, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000086, mae: 0.005314, mean_q: 0.009823
 81741/100000: episode: 11356, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000208, mae: 0.007908, mean_q: 0.015127
 81746/100000: episode: 11357, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000693, mae: 0.009758, mean_q: 0.021675
 81749/100000: episode: 11358, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000268, mae: 0.009759, mean_q: 0.019909
 81754/100000: episode: 11359, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000280, mae: 0.010863, mean_q: 0.021227
 81757/100000: episode: 11360, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000836, mae: 0.008739, mean_q: 0.016103
 81762/100000: episode: 11361, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000206, mae: 0.008217, mean_q: 0.016291
 81765/100000: episode: 11362, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000783, mae: 0.011818, mean_q: 0.025642
 81768/100000: episode: 11363, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000366, mae: 0.011382, mean_q: 0.027703
 81771/100000: episode: 11364, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000198, mae: 0.008405, mean_q: 0.017461
 81774/100000: episode: 11365, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000961, mae: 0.011881, mean_q: 0.019958
 81777/100000: episode: 11366, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000533, mae: 0.010252, mean_q: 0.019409
 81780/100000: episode: 11367, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000581, mae: 0.012562, mean_q: 0.038420
 81783/100000: episode: 11368, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000107, mae: 0.007277, mean_q: 0.014094
[Info] Complete ISplit Iteration
[Info] Levels: [0.031371616, 0.10358302, 1.5060225]
[Info] Cond. Prob: [0.14, 0.17, 0.02]
[Info] Error Prob: 0.00047600000000000013

 81786/100000: episode: 11369, duration: 1.025s, episode steps: 3, steps per second: 3, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000494, mae: 0.011916, mean_q: 0.029396
 81796/100000: episode: 11370, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000253, mae: 0.008198, mean_q: 0.016966
 81806/100000: episode: 11371, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000420, mae: 0.008313, mean_q: 0.014629
 81816/100000: episode: 11372, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000348, mae: 0.009843, mean_q: 0.014400
 81826/100000: episode: 11373, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000465, mae: 0.011938, mean_q: 0.021707
 81836/100000: episode: 11374, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000302, mae: 0.010486, mean_q: 0.020933
 81846/100000: episode: 11375, duration: 0.070s, episode steps: 10, steps per second: 144, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000198, mae: 0.007741, mean_q: 0.012048
 81856/100000: episode: 11376, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000575, mae: 0.009930, mean_q: 0.016362
 81866/100000: episode: 11377, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000586, mae: 0.011202, mean_q: 0.016913
 81876/100000: episode: 11378, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000276, mae: 0.011469, mean_q: 0.021569
 81886/100000: episode: 11379, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000140, mae: 0.009511, mean_q: 0.018359
 81896/100000: episode: 11380, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000308, mae: 0.008880, mean_q: 0.018365
 81906/100000: episode: 11381, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000174, mae: 0.007740, mean_q: 0.015835
 81916/100000: episode: 11382, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000165, mae: 0.007166, mean_q: 0.012742
 81926/100000: episode: 11383, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000369, mae: 0.009244, mean_q: 0.018790
 81936/100000: episode: 11384, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000257, mae: 0.008981, mean_q: 0.017626
 81946/100000: episode: 11385, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000660, mae: 0.008986, mean_q: 0.015628
 81956/100000: episode: 11386, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000249, mae: 0.009737, mean_q: 0.019590
 81966/100000: episode: 11387, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000276, mae: 0.008420, mean_q: 0.020338
 81976/100000: episode: 11388, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000499, mae: 0.009131, mean_q: 0.018756
 81986/100000: episode: 11389, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000174, mae: 0.008138, mean_q: 0.016957
 81996/100000: episode: 11390, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000520, mae: 0.008701, mean_q: 0.016167
 82006/100000: episode: 11391, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000714, mae: 0.012324, mean_q: 0.021547
 82016/100000: episode: 11392, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000616, mae: 0.011991, mean_q: 0.026777
 82026/100000: episode: 11393, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000157, mae: 0.007135, mean_q: 0.018171
 82036/100000: episode: 11394, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000519, mae: 0.009575, mean_q: 0.015409
 82046/100000: episode: 11395, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000540, mae: 0.010845, mean_q: 0.021785
 82056/100000: episode: 11396, duration: 0.110s, episode steps: 10, steps per second: 91, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000701, mae: 0.012025, mean_q: 0.026404
 82066/100000: episode: 11397, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000567, mae: 0.009299, mean_q: 0.014582
 82076/100000: episode: 11398, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000433, mae: 0.009109, mean_q: 0.017365
 82086/100000: episode: 11399, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000463, mae: 0.009452, mean_q: 0.019463
 82096/100000: episode: 11400, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000262, mae: 0.008010, mean_q: 0.021456
 82106/100000: episode: 11401, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000473, mae: 0.009965, mean_q: 0.019497
 82116/100000: episode: 11402, duration: 0.089s, episode steps: 10, steps per second: 113, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000795, mae: 0.012348, mean_q: 0.023439
 82126/100000: episode: 11403, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000604, mae: 0.011096, mean_q: 0.022932
 82136/100000: episode: 11404, duration: 0.095s, episode steps: 10, steps per second: 106, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000380, mae: 0.008740, mean_q: 0.019182
 82146/100000: episode: 11405, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000211, mae: 0.007304, mean_q: 0.012566
 82156/100000: episode: 11406, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000336, mae: 0.008997, mean_q: 0.017058
 82166/100000: episode: 11407, duration: 0.067s, episode steps: 10, steps per second: 148, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000442, mae: 0.010290, mean_q: 0.024169
 82176/100000: episode: 11408, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000528, mae: 0.009716, mean_q: 0.018660
 82186/100000: episode: 11409, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000956, mae: 0.013199, mean_q: 0.026431
 82196/100000: episode: 11410, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000463, mae: 0.009419, mean_q: 0.015786
 82206/100000: episode: 11411, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000483, mae: 0.010278, mean_q: 0.017668
 82216/100000: episode: 11412, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000135, mae: 0.009305, mean_q: 0.015971
 82226/100000: episode: 11413, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000407, mae: 0.010084, mean_q: 0.019257
 82236/100000: episode: 11414, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001180, mae: 0.012617, mean_q: 0.017136
 82246/100000: episode: 11415, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000457, mae: 0.011042, mean_q: 0.025823
 82256/100000: episode: 11416, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000243, mae: 0.008418, mean_q: 0.013976
 82266/100000: episode: 11417, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000241, mae: 0.009089, mean_q: 0.017576
 82276/100000: episode: 11418, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000344, mae: 0.009293, mean_q: 0.019616
 82286/100000: episode: 11419, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000376, mae: 0.009832, mean_q: 0.018639
 82296/100000: episode: 11420, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000501, mae: 0.009313, mean_q: 0.016303
 82306/100000: episode: 11421, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000605, mae: 0.010747, mean_q: 0.017204
 82316/100000: episode: 11422, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001536, mae: 0.018347, mean_q: 0.034040
 82326/100000: episode: 11423, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000710, mae: 0.010473, mean_q: 0.024840
 82336/100000: episode: 11424, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000254, mae: 0.009607, mean_q: 0.019889
 82346/100000: episode: 11425, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000572, mae: 0.008883, mean_q: 0.021769
 82356/100000: episode: 11426, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000310, mae: 0.008631, mean_q: 0.016735
 82366/100000: episode: 11427, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000201, mae: 0.008535, mean_q: 0.011703
 82376/100000: episode: 11428, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000567, mae: 0.011218, mean_q: 0.018078
 82386/100000: episode: 11429, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001200, mae: 0.013703, mean_q: 0.018111
 82396/100000: episode: 11430, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000361, mae: 0.010156, mean_q: 0.017829
 82406/100000: episode: 11431, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000282, mae: 0.008766, mean_q: 0.020628
 82416/100000: episode: 11432, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000762, mae: 0.011158, mean_q: 0.020585
 82426/100000: episode: 11433, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000281, mae: 0.008877, mean_q: 0.011302
 82436/100000: episode: 11434, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000324, mae: 0.008768, mean_q: 0.015965
 82446/100000: episode: 11435, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000236, mae: 0.007642, mean_q: 0.013431
 82456/100000: episode: 11436, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000151, mae: 0.008201, mean_q: 0.015552
 82466/100000: episode: 11437, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000768, mae: 0.013161, mean_q: 0.024657
 82476/100000: episode: 11438, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000504, mae: 0.010434, mean_q: 0.020243
 82486/100000: episode: 11439, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000492, mae: 0.010007, mean_q: 0.019237
 82496/100000: episode: 11440, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000391, mae: 0.009229, mean_q: 0.018236
 82506/100000: episode: 11441, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000098, mae: 0.006596, mean_q: 0.011880
 82516/100000: episode: 11442, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000254, mae: 0.008447, mean_q: 0.021858
 82526/100000: episode: 11443, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000266, mae: 0.010408, mean_q: 0.017249
 82536/100000: episode: 11444, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000588, mae: 0.010092, mean_q: 0.020945
 82546/100000: episode: 11445, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000573, mae: 0.009203, mean_q: 0.018728
 82556/100000: episode: 11446, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000845, mae: 0.011918, mean_q: 0.019228
 82566/100000: episode: 11447, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000369, mae: 0.010816, mean_q: 0.012677
 82576/100000: episode: 11448, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000364, mae: 0.010260, mean_q: 0.023919
 82586/100000: episode: 11449, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000529, mae: 0.008641, mean_q: 0.012131
 82596/100000: episode: 11450, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000581, mae: 0.012376, mean_q: 0.021959
 82606/100000: episode: 11451, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000299, mae: 0.010112, mean_q: 0.021068
 82616/100000: episode: 11452, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000267, mae: 0.009941, mean_q: 0.015692
 82626/100000: episode: 11453, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000271, mae: 0.008835, mean_q: 0.013653
 82636/100000: episode: 11454, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000219, mae: 0.008614, mean_q: 0.016030
 82646/100000: episode: 11455, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000169, mae: 0.008172, mean_q: 0.015907
 82656/100000: episode: 11456, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000207, mae: 0.008518, mean_q: 0.013950
 82666/100000: episode: 11457, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000582, mae: 0.010156, mean_q: 0.018911
 82676/100000: episode: 11458, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000108, mae: 0.006572, mean_q: 0.012762
 82686/100000: episode: 11459, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000546, mae: 0.010586, mean_q: 0.022402
 82696/100000: episode: 11460, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000162, mae: 0.007146, mean_q: 0.016524
 82706/100000: episode: 11461, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000167, mae: 0.006351, mean_q: 0.012797
 82716/100000: episode: 11462, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000231, mae: 0.007744, mean_q: 0.016945
 82726/100000: episode: 11463, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000488, mae: 0.010216, mean_q: 0.016623
 82736/100000: episode: 11464, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000368, mae: 0.010660, mean_q: 0.019261
 82746/100000: episode: 11465, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000450, mae: 0.009800, mean_q: 0.018259
 82756/100000: episode: 11466, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000084, mae: 0.005659, mean_q: 0.010437
 82766/100000: episode: 11467, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000390, mae: 0.009221, mean_q: 0.020525
 82776/100000: episode: 11468, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000549, mae: 0.010047, mean_q: 0.018310
[Info] 1-TH LEVEL FOUND: 0.015103423036634922, Considering 22/100 traces
 82786/100000: episode: 11469, duration: 0.765s, episode steps: 10, steps per second: 13, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000547, mae: 0.009775, mean_q: 0.014201
 82789/100000: episode: 11470, duration: 0.033s, episode steps: 3, steps per second: 92, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000310, mae: 0.010298, mean_q: 0.023247
 82792/100000: episode: 11471, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000276, mae: 0.010772, mean_q: 0.018325
 82795/100000: episode: 11472, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000750, mae: 0.012470, mean_q: 0.019074
 82801/100000: episode: 11473, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000405, mae: 0.012678, mean_q: 0.032102
 82807/100000: episode: 11474, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000234, mae: 0.010975, mean_q: 0.026878
 82810/100000: episode: 11475, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000334, mae: 0.010806, mean_q: 0.022308
 82814/100000: episode: 11476, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000104, mae: 0.007440, mean_q: 0.010094
 82818/100000: episode: 11477, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000139, mae: 0.007466, mean_q: 0.010281
 82824/100000: episode: 11478, duration: 0.032s, episode steps: 6, steps per second: 190, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000433, mae: 0.009484, mean_q: 0.015933
 82827/100000: episode: 11479, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000070, mae: 0.005301, mean_q: 0.007901
 82830/100000: episode: 11480, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000913, mae: 0.013998, mean_q: 0.028551
 82833/100000: episode: 11481, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000080, mae: 0.005042, mean_q: 0.014169
 82836/100000: episode: 11482, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000086, mae: 0.005457, mean_q: 0.010511
 82839/100000: episode: 11483, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000291, mae: 0.008154, mean_q: 0.020296
 82843/100000: episode: 11484, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000102, mae: 0.006637, mean_q: 0.013634
 82846/100000: episode: 11485, duration: 0.019s, episode steps: 3, steps per second: 162, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000474, mae: 0.011077, mean_q: 0.022261
 82849/100000: episode: 11486, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000098, mae: 0.007427, mean_q: 0.017087
 82852/100000: episode: 11487, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000121, mae: 0.007851, mean_q: 0.016195
 82855/100000: episode: 11488, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000098, mae: 0.006874, mean_q: 0.013925
 82858/100000: episode: 11489, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000081, mae: 0.005787, mean_q: 0.011521
 82861/100000: episode: 11490, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000377, mae: 0.010412, mean_q: 0.023854
 82864/100000: episode: 11491, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000044, mae: 0.004594, mean_q: 0.007471
 82868/100000: episode: 11492, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000223, mae: 0.009644, mean_q: 0.021737
 82871/100000: episode: 11493, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000100, mae: 0.007212, mean_q: 0.015837
 82874/100000: episode: 11494, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000519, mae: 0.009652, mean_q: 0.014891
 82877/100000: episode: 11495, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001021, mae: 0.012869, mean_q: 0.027203
 82880/100000: episode: 11496, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000109, mae: 0.007956, mean_q: 0.013356
 82883/100000: episode: 11497, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000198, mae: 0.008934, mean_q: 0.025001
 82886/100000: episode: 11498, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000158, mae: 0.009244, mean_q: 0.019606
 82892/100000: episode: 11499, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000112, mae: 0.006703, mean_q: 0.016169
 82895/100000: episode: 11500, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000243, mae: 0.007801, mean_q: 0.012499
 82898/100000: episode: 11501, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000108, mae: 0.006565, mean_q: 0.012090
 82904/100000: episode: 11502, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000420, mae: 0.008442, mean_q: 0.019778
 82908/100000: episode: 11503, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000068, mae: 0.005234, mean_q: 0.009904
 82911/100000: episode: 11504, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000483, mae: 0.010638, mean_q: 0.013869
 82914/100000: episode: 11505, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000086, mae: 0.005600, mean_q: 0.010152
 82917/100000: episode: 11506, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000143, mae: 0.008250, mean_q: 0.014833
 82923/100000: episode: 11507, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000273, mae: 0.008382, mean_q: 0.013648
 82926/100000: episode: 11508, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000046, mae: 0.004795, mean_q: 0.009825
 82932/100000: episode: 11509, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000320, mae: 0.010879, mean_q: 0.020938
 82935/100000: episode: 11510, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000124, mae: 0.007923, mean_q: 0.014548
 82941/100000: episode: 11511, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000160, mae: 0.009183, mean_q: 0.015715
 82944/100000: episode: 11512, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000072, mae: 0.005750, mean_q: 0.011573
 82947/100000: episode: 11513, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000774, mae: 0.012541, mean_q: 0.021992
 82950/100000: episode: 11514, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000110, mae: 0.007893, mean_q: 0.018446
 82954/100000: episode: 11515, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000195, mae: 0.007233, mean_q: 0.012280
 82960/100000: episode: 11516, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001221, mae: 0.013596, mean_q: 0.029644
 82963/100000: episode: 11517, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000082, mae: 0.004958, mean_q: 0.009691
 82967/100000: episode: 11518, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000695, mae: 0.008814, mean_q: 0.019967
 82970/100000: episode: 11519, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000767, mae: 0.011444, mean_q: 0.015644
 82973/100000: episode: 11520, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000643, mae: 0.010735, mean_q: 0.020805
 82976/100000: episode: 11521, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000533, mae: 0.008530, mean_q: 0.015186
 82979/100000: episode: 11522, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000106, mae: 0.007277, mean_q: 0.013623
 82982/100000: episode: 11523, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000149, mae: 0.006895, mean_q: 0.016186
 82986/100000: episode: 11524, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000081, mae: 0.005626, mean_q: 0.008889
 82992/100000: episode: 11525, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000075, mae: 0.005596, mean_q: 0.008206
 82995/100000: episode: 11526, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000234, mae: 0.006458, mean_q: 0.010928
 82998/100000: episode: 11527, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000329, mae: 0.009645, mean_q: 0.022670
 83001/100000: episode: 11528, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000103, mae: 0.008369, mean_q: 0.015572
 83004/100000: episode: 11529, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000435, mae: 0.009913, mean_q: 0.016938
 83007/100000: episode: 11530, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000079, mae: 0.007612, mean_q: 0.014769
 83013/100000: episode: 11531, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000464, mae: 0.012721, mean_q: 0.021649
 83016/100000: episode: 11532, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000134, mae: 0.008114, mean_q: 0.019192
 83022/100000: episode: 11533, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000355, mae: 0.009079, mean_q: 0.014911
 83028/100000: episode: 11534, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000065, mae: 0.005162, mean_q: 0.007095
 83031/100000: episode: 11535, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000097, mae: 0.007129, mean_q: 0.008986
 83035/100000: episode: 11536, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000391, mae: 0.008503, mean_q: 0.013654
 83039/100000: episode: 11537, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001219, mae: 0.012238, mean_q: 0.017246
 83042/100000: episode: 11538, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000180, mae: 0.009172, mean_q: 0.019527
 83045/100000: episode: 11539, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000064, mae: 0.005541, mean_q: 0.010289
 83051/100000: episode: 11540, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000062, mae: 0.005246, mean_q: 0.009150
 83054/100000: episode: 11541, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001161, mae: 0.011159, mean_q: 0.013294
 83057/100000: episode: 11542, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000349, mae: 0.010930, mean_q: 0.013379
 83060/100000: episode: 11543, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000104, mae: 0.008054, mean_q: 0.013768
 83066/100000: episode: 11544, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000111, mae: 0.008424, mean_q: 0.017966
 83069/100000: episode: 11545, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000080, mae: 0.006487, mean_q: 0.017768
 83072/100000: episode: 11546, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000132, mae: 0.007765, mean_q: 0.014477
[Info] 2-TH LEVEL FOUND: 0.09162995964288712, Considering 11/100 traces
 83076/100000: episode: 11547, duration: 0.697s, episode steps: 4, steps per second: 6, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000761, mae: 0.011581, mean_q: 0.019979
 83079/100000: episode: 11548, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000579, mae: 0.009293, mean_q: 0.015038
 83084/100000: episode: 11549, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000104, mae: 0.006271, mean_q: 0.014055
 83087/100000: episode: 11550, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000126, mae: 0.007151, mean_q: 0.015051
 83090/100000: episode: 11551, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000121, mae: 0.007726, mean_q: 0.013006
 83095/100000: episode: 11552, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000198, mae: 0.008367, mean_q: 0.015020
 83100/100000: episode: 11553, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000300, mae: 0.008070, mean_q: 0.018225
 83103/100000: episode: 11554, duration: 0.020s, episode steps: 3, steps per second: 149, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000119, mae: 0.006961, mean_q: 0.015133
 83108/100000: episode: 11555, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000290, mae: 0.008716, mean_q: 0.013800
 83113/100000: episode: 11556, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000459, mae: 0.010527, mean_q: 0.018562
 83116/100000: episode: 11557, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000103, mae: 0.006453, mean_q: 0.010942
 83119/100000: episode: 11558, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000063, mae: 0.004283, mean_q: 0.005843
 83124/100000: episode: 11559, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000447, mae: 0.009389, mean_q: 0.017132
 83129/100000: episode: 11560, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001448, mae: 0.011257, mean_q: 0.011552
 83134/100000: episode: 11561, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000204, mae: 0.010174, mean_q: 0.015234
 83139/100000: episode: 11562, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000224, mae: 0.010055, mean_q: 0.019039
 83142/100000: episode: 11563, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000221, mae: 0.009012, mean_q: 0.016171
 83145/100000: episode: 11564, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001281, mae: 0.012483, mean_q: 0.019312
 83148/100000: episode: 11565, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000127, mae: 0.006800, mean_q: 0.012693
 83153/100000: episode: 11566, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000100, mae: 0.006907, mean_q: 0.012765
 83156/100000: episode: 11567, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000221, mae: 0.009217, mean_q: 0.013970
 83159/100000: episode: 11568, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000117, mae: 0.006975, mean_q: 0.013522
 83164/100000: episode: 11569, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000081, mae: 0.005571, mean_q: 0.015047
[Info] FALSIFICATION!
 83168/100000: episode: 11570, duration: 0.235s, episode steps: 4, steps per second: 17, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000235, mae: 0.008273, mean_q: 0.014812
 83173/100000: episode: 11571, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000095, mae: 0.006144, mean_q: 0.012295
 83176/100000: episode: 11572, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000864, mae: 0.011863, mean_q: 0.019448
 83181/100000: episode: 11573, duration: 0.030s, episode steps: 5, steps per second: 165, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000094, mae: 0.006003, mean_q: 0.012773
 83184/100000: episode: 11574, duration: 0.024s, episode steps: 3, steps per second: 126, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000098, mae: 0.006604, mean_q: 0.015907
 83187/100000: episode: 11575, duration: 0.022s, episode steps: 3, steps per second: 138, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000124, mae: 0.007907, mean_q: 0.017769
 83190/100000: episode: 11576, duration: 0.023s, episode steps: 3, steps per second: 129, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000176, mae: 0.007619, mean_q: 0.021901
 83195/100000: episode: 11577, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000638, mae: 0.010118, mean_q: 0.016349
 83198/100000: episode: 11578, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000126, mae: 0.006746, mean_q: 0.021131
 83201/100000: episode: 11579, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000229, mae: 0.007488, mean_q: 0.012170
 83206/100000: episode: 11580, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000212, mae: 0.007651, mean_q: 0.015029
 83209/100000: episode: 11581, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001153, mae: 0.011837, mean_q: 0.024737
 83212/100000: episode: 11582, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000084, mae: 0.006023, mean_q: 0.011093
 83217/100000: episode: 11583, duration: 0.036s, episode steps: 5, steps per second: 137, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001064, mae: 0.015600, mean_q: 0.020474
 83222/100000: episode: 11584, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000179, mae: 0.009732, mean_q: 0.011924
 83225/100000: episode: 11585, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002499, mae: 0.019864, mean_q: 0.019262
 83228/100000: episode: 11586, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000267, mae: 0.008639, mean_q: 0.013978
 83233/100000: episode: 11587, duration: 0.035s, episode steps: 5, steps per second: 143, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000339, mae: 0.010702, mean_q: 0.020143
 83238/100000: episode: 11588, duration: 0.030s, episode steps: 5, steps per second: 165, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000687, mae: 0.012364, mean_q: 0.022813
 83243/100000: episode: 11589, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001058, mae: 0.013971, mean_q: 0.025561
 83248/100000: episode: 11590, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000170, mae: 0.007935, mean_q: 0.014117
[Info] FALSIFICATION!
 83252/100000: episode: 11591, duration: 0.182s, episode steps: 4, steps per second: 22, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000244, mae: 0.009938, mean_q: 0.020652
 83255/100000: episode: 11592, duration: 0.027s, episode steps: 3, steps per second: 110, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000448, mae: 0.010405, mean_q: 0.026141
 83258/100000: episode: 11593, duration: 0.033s, episode steps: 3, steps per second: 92, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001155, mae: 0.011226, mean_q: 0.023158
 83263/100000: episode: 11594, duration: 0.044s, episode steps: 5, steps per second: 113, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000117, mae: 0.007632, mean_q: 0.012144
 83268/100000: episode: 11595, duration: 0.046s, episode steps: 5, steps per second: 109, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000964, mae: 0.014742, mean_q: 0.029476
 83273/100000: episode: 11596, duration: 0.039s, episode steps: 5, steps per second: 130, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001124, mae: 0.014338, mean_q: 0.034092
 83276/100000: episode: 11597, duration: 0.025s, episode steps: 3, steps per second: 120, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000814, mae: 0.013932, mean_q: 0.039457
 83279/100000: episode: 11598, duration: 0.026s, episode steps: 3, steps per second: 116, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000698, mae: 0.010109, mean_q: 0.016632
 83282/100000: episode: 11599, duration: 0.030s, episode steps: 3, steps per second: 99, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003143, mae: 0.016821, mean_q: 0.042549
 83287/100000: episode: 11600, duration: 0.041s, episode steps: 5, steps per second: 122, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000891, mae: 0.011036, mean_q: 0.020236
 83290/100000: episode: 11601, duration: 0.026s, episode steps: 3, steps per second: 114, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000092, mae: 0.006495, mean_q: 0.009471
 83293/100000: episode: 11602, duration: 0.029s, episode steps: 3, steps per second: 104, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000393, mae: 0.011099, mean_q: 0.014697
 83298/100000: episode: 11603, duration: 0.030s, episode steps: 5, steps per second: 164, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001114, mae: 0.012941, mean_q: 0.016513
 83301/100000: episode: 11604, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000176, mae: 0.009621, mean_q: 0.010411
 83306/100000: episode: 11605, duration: 0.032s, episode steps: 5, steps per second: 154, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000241, mae: 0.010827, mean_q: 0.016370
 83309/100000: episode: 11606, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000089, mae: 0.008152, mean_q: 0.011549
 83314/100000: episode: 11607, duration: 0.030s, episode steps: 5, steps per second: 168, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.003549, mae: 0.019906, mean_q: 0.020751
 83317/100000: episode: 11608, duration: 0.030s, episode steps: 3, steps per second: 101, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001287, mae: 0.017094, mean_q: 0.024730
 83322/100000: episode: 11609, duration: 0.044s, episode steps: 5, steps per second: 112, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000286, mae: 0.012632, mean_q: 0.027880
 83325/100000: episode: 11610, duration: 0.020s, episode steps: 3, steps per second: 151, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002206, mae: 0.015067, mean_q: 0.025419
 83328/100000: episode: 11611, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000386, mae: 0.011635, mean_q: 0.026337
 83333/100000: episode: 11612, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001174, mae: 0.017049, mean_q: 0.025631
 83336/100000: episode: 11613, duration: 0.022s, episode steps: 3, steps per second: 135, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000243, mae: 0.008120, mean_q: 0.006434
 83341/100000: episode: 11614, duration: 0.030s, episode steps: 5, steps per second: 167, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000625, mae: 0.013279, mean_q: 0.012955
 83346/100000: episode: 11615, duration: 0.031s, episode steps: 5, steps per second: 161, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000901, mae: 0.016937, mean_q: 0.021435
 83349/100000: episode: 11616, duration: 0.032s, episode steps: 3, steps per second: 95, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002028, mae: 0.017117, mean_q: 0.021313
 83352/100000: episode: 11617, duration: 0.034s, episode steps: 3, steps per second: 89, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000259, mae: 0.012134, mean_q: 0.013954
 83357/100000: episode: 11618, duration: 0.059s, episode steps: 5, steps per second: 85, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000273, mae: 0.014332, mean_q: 0.020512
 83360/100000: episode: 11619, duration: 0.032s, episode steps: 3, steps per second: 93, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000443, mae: 0.016755, mean_q: 0.033760
 83365/100000: episode: 11620, duration: 0.038s, episode steps: 5, steps per second: 131, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001502, mae: 0.015511, mean_q: 0.026612
 83368/100000: episode: 11621, duration: 0.023s, episode steps: 3, steps per second: 131, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000110, mae: 0.007682, mean_q: 0.017029
[Info] FALSIFICATION!
 83372/100000: episode: 11622, duration: 0.285s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001405, mae: 0.015712, mean_q: 0.030087
 83377/100000: episode: 11623, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000535, mae: 0.010857, mean_q: 0.025062
 83380/100000: episode: 11624, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000200, mae: 0.007389, mean_q: 0.018380
 83383/100000: episode: 11625, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000137, mae: 0.008339, mean_q: 0.017807
 83386/100000: episode: 11626, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000752, mae: 0.012078, mean_q: 0.022215
 83391/100000: episode: 11627, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000195, mae: 0.009718, mean_q: 0.018950
[Info] FALSIFICATION!
 83395/100000: episode: 11628, duration: 0.295s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001509, mae: 0.016972, mean_q: 0.022698
 83400/100000: episode: 11629, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001398, mae: 0.012055, mean_q: 0.022659
 83405/100000: episode: 11630, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000416, mae: 0.009470, mean_q: 0.020147
 83408/100000: episode: 11631, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000514, mae: 0.011826, mean_q: 0.017200
 83413/100000: episode: 11632, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000920, mae: 0.011570, mean_q: 0.016363
 83416/100000: episode: 11633, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000213, mae: 0.008619, mean_q: 0.021255
 83419/100000: episode: 11634, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000993, mae: 0.020181, mean_q: 0.045561
 83424/100000: episode: 11635, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000936, mae: 0.015760, mean_q: 0.033942
[Info] Complete ISplit Iteration
[Info] Levels: [0.015103423, 0.09162996, 1.243904]
[Info] Cond. Prob: [0.22, 0.11, 0.09]
[Info] Error Prob: 0.002178

 83429/100000: episode: 11636, duration: 0.929s, episode steps: 5, steps per second: 5, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000186, mae: 0.007852, mean_q: 0.016269
 83439/100000: episode: 11637, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000988, mae: 0.010876, mean_q: 0.018786
 83449/100000: episode: 11638, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000793, mae: 0.011478, mean_q: 0.021791
 83459/100000: episode: 11639, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000940, mae: 0.011357, mean_q: 0.029690
 83469/100000: episode: 11640, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000312, mae: 0.010246, mean_q: 0.016704
 83479/100000: episode: 11641, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000801, mae: 0.013085, mean_q: 0.018333
 83489/100000: episode: 11642, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001861, mae: 0.015990, mean_q: 0.026076
 83499/100000: episode: 11643, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002955, mae: 0.020775, mean_q: 0.025118
 83509/100000: episode: 11644, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000979, mae: 0.016693, mean_q: 0.028456
 83519/100000: episode: 11645, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001708, mae: 0.013602, mean_q: 0.020058
 83529/100000: episode: 11646, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000388, mae: 0.009957, mean_q: 0.024421
 83539/100000: episode: 11647, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001704, mae: 0.012875, mean_q: 0.025599
 83549/100000: episode: 11648, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000555, mae: 0.014630, mean_q: 0.016417
 83559/100000: episode: 11649, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001124, mae: 0.014440, mean_q: 0.017371
 83569/100000: episode: 11650, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002327, mae: 0.018742, mean_q: 0.029244
 83579/100000: episode: 11651, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001555, mae: 0.016664, mean_q: 0.040450
 83589/100000: episode: 11652, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001186, mae: 0.016114, mean_q: 0.025762
 83599/100000: episode: 11653, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001189, mae: 0.015804, mean_q: 0.025560
 83609/100000: episode: 11654, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001244, mae: 0.015405, mean_q: 0.029442
 83619/100000: episode: 11655, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000280, mae: 0.010722, mean_q: 0.021415
 83629/100000: episode: 11656, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001066, mae: 0.012624, mean_q: 0.024432
 83639/100000: episode: 11657, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000322, mae: 0.009368, mean_q: 0.015696
 83649/100000: episode: 11658, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000741, mae: 0.011996, mean_q: 0.020443
 83659/100000: episode: 11659, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000901, mae: 0.013745, mean_q: 0.023467
 83669/100000: episode: 11660, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000908, mae: 0.013277, mean_q: 0.020763
 83679/100000: episode: 11661, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000729, mae: 0.013967, mean_q: 0.030182
 83689/100000: episode: 11662, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000668, mae: 0.009665, mean_q: 0.016407
 83699/100000: episode: 11663, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000355, mae: 0.008433, mean_q: 0.015106
 83709/100000: episode: 11664, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001112, mae: 0.010782, mean_q: 0.017045
 83719/100000: episode: 11665, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001742, mae: 0.017424, mean_q: 0.037038
 83729/100000: episode: 11666, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000644, mae: 0.014510, mean_q: 0.022172
 83739/100000: episode: 11667, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001082, mae: 0.015008, mean_q: 0.015366
 83749/100000: episode: 11668, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000465, mae: 0.012659, mean_q: 0.025067
 83759/100000: episode: 11669, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000912, mae: 0.014716, mean_q: 0.027931
 83769/100000: episode: 11670, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001212, mae: 0.016322, mean_q: 0.035630
 83779/100000: episode: 11671, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000521, mae: 0.009605, mean_q: 0.019205
 83789/100000: episode: 11672, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000487, mae: 0.010387, mean_q: 0.022989
 83799/100000: episode: 11673, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000726, mae: 0.013000, mean_q: 0.033225
 83809/100000: episode: 11674, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000786, mae: 0.014217, mean_q: 0.033216
 83819/100000: episode: 11675, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001430, mae: 0.015952, mean_q: 0.019451
 83829/100000: episode: 11676, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002091, mae: 0.021307, mean_q: 0.036307
 83839/100000: episode: 11677, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000762, mae: 0.012488, mean_q: 0.025667
 83849/100000: episode: 11678, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000215, mae: 0.010161, mean_q: 0.026328
 83859/100000: episode: 11679, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000591, mae: 0.010969, mean_q: 0.027857
 83869/100000: episode: 11680, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000852, mae: 0.009975, mean_q: 0.024355
 83879/100000: episode: 11681, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000627, mae: 0.009679, mean_q: 0.017041
 83889/100000: episode: 11682, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001366, mae: 0.013482, mean_q: 0.019750
 83899/100000: episode: 11683, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000802, mae: 0.012615, mean_q: 0.023865
 83909/100000: episode: 11684, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000510, mae: 0.009279, mean_q: 0.015619
 83919/100000: episode: 11685, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000698, mae: 0.011581, mean_q: 0.028029
 83929/100000: episode: 11686, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000969, mae: 0.014354, mean_q: 0.026042
 83939/100000: episode: 11687, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000601, mae: 0.011781, mean_q: 0.019417
 83949/100000: episode: 11688, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000866, mae: 0.013823, mean_q: 0.021706
 83959/100000: episode: 11689, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000829, mae: 0.014323, mean_q: 0.024833
 83969/100000: episode: 11690, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001057, mae: 0.013608, mean_q: 0.024255
 83979/100000: episode: 11691, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001115, mae: 0.013711, mean_q: 0.021429
 83989/100000: episode: 11692, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001513, mae: 0.018019, mean_q: 0.040241
 83999/100000: episode: 11693, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000854, mae: 0.012410, mean_q: 0.025848
 84009/100000: episode: 11694, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000728, mae: 0.011766, mean_q: 0.023667
 84019/100000: episode: 11695, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000922, mae: 0.013271, mean_q: 0.030907
 84029/100000: episode: 11696, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000545, mae: 0.011162, mean_q: 0.013797
 84039/100000: episode: 11697, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000676, mae: 0.010732, mean_q: 0.021439
 84049/100000: episode: 11698, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000388, mae: 0.010429, mean_q: 0.022245
 84059/100000: episode: 11699, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001096, mae: 0.015209, mean_q: 0.032560
 84069/100000: episode: 11700, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001837, mae: 0.017321, mean_q: 0.027180
 84079/100000: episode: 11701, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000421, mae: 0.009242, mean_q: 0.021974
 84089/100000: episode: 11702, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000558, mae: 0.011984, mean_q: 0.033332
 84099/100000: episode: 11703, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000762, mae: 0.013708, mean_q: 0.031817
 84109/100000: episode: 11704, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000567, mae: 0.013466, mean_q: 0.023573
 84119/100000: episode: 11705, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000496, mae: 0.009934, mean_q: 0.019866
 84129/100000: episode: 11706, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000646, mae: 0.011404, mean_q: 0.027926
 84139/100000: episode: 11707, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000519, mae: 0.011526, mean_q: 0.023235
 84149/100000: episode: 11708, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000980, mae: 0.011954, mean_q: 0.021856
 84159/100000: episode: 11709, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000714, mae: 0.012200, mean_q: 0.016418
 84169/100000: episode: 11710, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000953, mae: 0.013910, mean_q: 0.017270
 84179/100000: episode: 11711, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000577, mae: 0.013503, mean_q: 0.021801
 84189/100000: episode: 11712, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000766, mae: 0.011133, mean_q: 0.018851
 84199/100000: episode: 11713, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000790, mae: 0.013475, mean_q: 0.026175
 84209/100000: episode: 11714, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000323, mae: 0.010006, mean_q: 0.023606
 84219/100000: episode: 11715, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001011, mae: 0.013541, mean_q: 0.029223
 84229/100000: episode: 11716, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000591, mae: 0.010612, mean_q: 0.016404
 84239/100000: episode: 11717, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000614, mae: 0.010466, mean_q: 0.023211
 84249/100000: episode: 11718, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000292, mae: 0.009867, mean_q: 0.025931
 84259/100000: episode: 11719, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000495, mae: 0.011325, mean_q: 0.024674
 84269/100000: episode: 11720, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000832, mae: 0.013127, mean_q: 0.029909
 84279/100000: episode: 11721, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000668, mae: 0.010056, mean_q: 0.023622
 84289/100000: episode: 11722, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001158, mae: 0.013886, mean_q: 0.030884
 84299/100000: episode: 11723, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000988, mae: 0.014066, mean_q: 0.026673
 84309/100000: episode: 11724, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001114, mae: 0.015563, mean_q: 0.034256
 84319/100000: episode: 11725, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000282, mae: 0.008386, mean_q: 0.021827
 84329/100000: episode: 11726, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000636, mae: 0.010761, mean_q: 0.020649
 84339/100000: episode: 11727, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000770, mae: 0.010285, mean_q: 0.022308
 84349/100000: episode: 11728, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000176, mae: 0.007405, mean_q: 0.015593
 84359/100000: episode: 11729, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001563, mae: 0.018027, mean_q: 0.037769
 84369/100000: episode: 11730, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000756, mae: 0.009792, mean_q: 0.017045
 84379/100000: episode: 11731, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000700, mae: 0.011522, mean_q: 0.016965
 84389/100000: episode: 11732, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000625, mae: 0.012575, mean_q: 0.031138
 84399/100000: episode: 11733, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000515, mae: 0.008846, mean_q: 0.016849
 84409/100000: episode: 11734, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000683, mae: 0.009595, mean_q: 0.014956
 84419/100000: episode: 11735, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000702, mae: 0.010079, mean_q: 0.017844
[Info] 1-TH LEVEL FOUND: 0.036274503916502, Considering 16/100 traces
 84429/100000: episode: 11736, duration: 0.701s, episode steps: 10, steps per second: 14, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001376, mae: 0.016775, mean_q: 0.035833
 84433/100000: episode: 11737, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000148, mae: 0.007858, mean_q: 0.019808
 84437/100000: episode: 11738, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000344, mae: 0.011505, mean_q: 0.019188
 84443/100000: episode: 11739, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000982, mae: 0.013252, mean_q: 0.024622
 84449/100000: episode: 11740, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000721, mae: 0.013661, mean_q: 0.032638
 84455/100000: episode: 11741, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000333, mae: 0.007504, mean_q: 0.014825
 84458/100000: episode: 11742, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000377, mae: 0.008321, mean_q: 0.020097
 84464/100000: episode: 11743, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000162, mae: 0.007245, mean_q: 0.011404
 84470/100000: episode: 11744, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000593, mae: 0.008993, mean_q: 0.018954
 84473/100000: episode: 11745, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000731, mae: 0.013651, mean_q: 0.053475
 84477/100000: episode: 11746, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000290, mae: 0.008628, mean_q: 0.018051
 84481/100000: episode: 11747, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002997, mae: 0.019034, mean_q: 0.047291
 84485/100000: episode: 11748, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000464, mae: 0.012084, mean_q: 0.010600
 84489/100000: episode: 11749, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002954, mae: 0.019710, mean_q: 0.024914
 84495/100000: episode: 11750, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000169, mae: 0.007784, mean_q: 0.018235
 84498/100000: episode: 11751, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000973, mae: 0.010624, mean_q: 0.017067
 84501/100000: episode: 11752, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001253, mae: 0.017784, mean_q: 0.027187
 84504/100000: episode: 11753, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000319, mae: 0.011249, mean_q: 0.022811
 84510/100000: episode: 11754, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001541, mae: 0.015142, mean_q: 0.026301
 84513/100000: episode: 11755, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000165, mae: 0.009282, mean_q: 0.016644
 84517/100000: episode: 11756, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000531, mae: 0.010199, mean_q: 0.022662
 84521/100000: episode: 11757, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000751, mae: 0.010953, mean_q: 0.017492
 84525/100000: episode: 11758, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001489, mae: 0.014829, mean_q: 0.026626
 84531/100000: episode: 11759, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000831, mae: 0.011395, mean_q: 0.020172
 84535/100000: episode: 11760, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000387, mae: 0.011727, mean_q: 0.020111
 84539/100000: episode: 11761, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000382, mae: 0.010379, mean_q: 0.020235
 84543/100000: episode: 11762, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000791, mae: 0.013377, mean_q: 0.033028
 84546/100000: episode: 11763, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000236, mae: 0.008958, mean_q: 0.018934
 84550/100000: episode: 11764, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000315, mae: 0.009312, mean_q: 0.016910
 84554/100000: episode: 11765, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000568, mae: 0.009250, mean_q: 0.024021
 84558/100000: episode: 11766, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001142, mae: 0.012708, mean_q: 0.028722
 84561/100000: episode: 11767, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000250, mae: 0.007948, mean_q: 0.019409
 84564/100000: episode: 11768, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000532, mae: 0.009806, mean_q: 0.018190
 84567/100000: episode: 11769, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000631, mae: 0.010493, mean_q: 0.018751
 84570/100000: episode: 11770, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000186, mae: 0.005617, mean_q: 0.008428
 84573/100000: episode: 11771, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000522, mae: 0.009138, mean_q: 0.013261
 84577/100000: episode: 11772, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000233, mae: 0.007341, mean_q: 0.018330
 84580/100000: episode: 11773, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000121, mae: 0.006487, mean_q: 0.011020
 84583/100000: episode: 11774, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002643, mae: 0.023080, mean_q: 0.047295
 84587/100000: episode: 11775, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000184, mae: 0.007179, mean_q: 0.020067
 84593/100000: episode: 11776, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000122, mae: 0.006414, mean_q: 0.012672
 84596/100000: episode: 11777, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000792, mae: 0.011570, mean_q: 0.013601
 84602/100000: episode: 11778, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000455, mae: 0.011097, mean_q: 0.018639
 84605/100000: episode: 11779, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000635, mae: 0.011396, mean_q: 0.026914
 84608/100000: episode: 11780, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001157, mae: 0.015269, mean_q: 0.021062
 84611/100000: episode: 11781, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000848, mae: 0.013435, mean_q: 0.021693
 84614/100000: episode: 11782, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000600, mae: 0.011831, mean_q: 0.019279
 84620/100000: episode: 11783, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000783, mae: 0.010507, mean_q: 0.019096
 84624/100000: episode: 11784, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000507, mae: 0.011173, mean_q: 0.028488
[Info] FALSIFICATION!
 84629/100000: episode: 11785, duration: 0.276s, episode steps: 5, steps per second: 18, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000498, mae: 0.009027, mean_q: 0.015726
 84633/100000: episode: 11786, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000800, mae: 0.012179, mean_q: 0.021769
 84636/100000: episode: 11787, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000424, mae: 0.009414, mean_q: 0.026049
 84642/100000: episode: 11788, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000542, mae: 0.009853, mean_q: 0.018091
 84646/100000: episode: 11789, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000997, mae: 0.012251, mean_q: 0.021027
 84649/100000: episode: 11790, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000440, mae: 0.011554, mean_q: 0.019457
 84652/100000: episode: 11791, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000366, mae: 0.010577, mean_q: 0.018796
 84655/100000: episode: 11792, duration: 0.020s, episode steps: 3, steps per second: 153, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002276, mae: 0.015954, mean_q: 0.022511
 84659/100000: episode: 11793, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001017, mae: 0.012635, mean_q: 0.027148
 84663/100000: episode: 11794, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000414, mae: 0.010405, mean_q: 0.021435
 84666/100000: episode: 11795, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001360, mae: 0.015173, mean_q: 0.024510
 84670/100000: episode: 11796, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000532, mae: 0.010672, mean_q: 0.021717
 84673/100000: episode: 11797, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000348, mae: 0.009387, mean_q: 0.019055
 84676/100000: episode: 11798, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000645, mae: 0.012595, mean_q: 0.026056
 84679/100000: episode: 11799, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000714, mae: 0.013468, mean_q: 0.020102
 84683/100000: episode: 11800, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000394, mae: 0.010777, mean_q: 0.013180
 84687/100000: episode: 11801, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000141, mae: 0.006965, mean_q: 0.009760
 84690/100000: episode: 11802, duration: 0.017s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000694, mae: 0.010549, mean_q: 0.021906
 84694/100000: episode: 11803, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000166, mae: 0.007449, mean_q: 0.011496
 84697/100000: episode: 11804, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000527, mae: 0.010650, mean_q: 0.023252
 84700/100000: episode: 11805, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001276, mae: 0.019897, mean_q: 0.045448
 84704/100000: episode: 11806, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000307, mae: 0.009575, mean_q: 0.021529
 84707/100000: episode: 11807, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000592, mae: 0.012378, mean_q: 0.030008
 84713/100000: episode: 11808, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000789, mae: 0.009132, mean_q: 0.018567
 84717/100000: episode: 11809, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000339, mae: 0.011942, mean_q: 0.025080
 84723/100000: episode: 11810, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000563, mae: 0.010138, mean_q: 0.018388
 84726/100000: episode: 11811, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.003660, mae: 0.025480, mean_q: 0.045424
 84730/100000: episode: 11812, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000277, mae: 0.008494, mean_q: 0.024584
 84733/100000: episode: 11813, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000339, mae: 0.012302, mean_q: 0.027652
 84736/100000: episode: 11814, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000472, mae: 0.009671, mean_q: 0.017521
 84742/100000: episode: 11815, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000150, mae: 0.006416, mean_q: 0.023820
 84748/100000: episode: 11816, duration: 0.031s, episode steps: 6, steps per second: 191, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000818, mae: 0.013113, mean_q: 0.033981
 84752/100000: episode: 11817, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001294, mae: 0.010353, mean_q: 0.019314
 84755/100000: episode: 11818, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000560, mae: 0.012038, mean_q: 0.032407
 84761/100000: episode: 11819, duration: 0.034s, episode steps: 6, steps per second: 177, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000388, mae: 0.011088, mean_q: 0.025567
[Info] Complete ISplit Iteration
[Info] Levels: [0.036274504, 1.3179737]
[Info] Cond. Prob: [0.16, 0.01]
[Info] Error Prob: 0.0016

 84765/100000: episode: 11820, duration: 0.878s, episode steps: 4, steps per second: 5, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000879, mae: 0.014724, mean_q: 0.020282
 84775/100000: episode: 11821, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000587, mae: 0.011374, mean_q: 0.017410
 84785/100000: episode: 11822, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000458, mae: 0.012572, mean_q: 0.025388
 84795/100000: episode: 11823, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001145, mae: 0.016215, mean_q: 0.031573
 84805/100000: episode: 11824, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001329, mae: 0.015004, mean_q: 0.029725
 84815/100000: episode: 11825, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001520, mae: 0.019335, mean_q: 0.023479
 84825/100000: episode: 11826, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.002165, mae: 0.018928, mean_q: 0.028257
 84835/100000: episode: 11827, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000421, mae: 0.013099, mean_q: 0.029577
 84845/100000: episode: 11828, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000594, mae: 0.010020, mean_q: 0.020472
 84855/100000: episode: 11829, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000549, mae: 0.012203, mean_q: 0.023800
 84865/100000: episode: 11830, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000476, mae: 0.009922, mean_q: 0.026460
 84875/100000: episode: 11831, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000582, mae: 0.010063, mean_q: 0.023971
 84885/100000: episode: 11832, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000942, mae: 0.012953, mean_q: 0.029917
 84895/100000: episode: 11833, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000516, mae: 0.010906, mean_q: 0.023071
 84905/100000: episode: 11834, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001421, mae: 0.014296, mean_q: 0.027956
 84915/100000: episode: 11835, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000913, mae: 0.013419, mean_q: 0.020613
 84925/100000: episode: 11836, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000537, mae: 0.010898, mean_q: 0.021020
 84935/100000: episode: 11837, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000714, mae: 0.011115, mean_q: 0.016574
 84945/100000: episode: 11838, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001326, mae: 0.015667, mean_q: 0.026674
 84955/100000: episode: 11839, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000970, mae: 0.014385, mean_q: 0.035531
 84965/100000: episode: 11840, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001418, mae: 0.015480, mean_q: 0.028870
 84975/100000: episode: 11841, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000905, mae: 0.012936, mean_q: 0.027098
 84985/100000: episode: 11842, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001070, mae: 0.013692, mean_q: 0.029279
 84995/100000: episode: 11843, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000849, mae: 0.012031, mean_q: 0.022282
 85005/100000: episode: 11844, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001651, mae: 0.012672, mean_q: 0.017226
 85015/100000: episode: 11845, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000693, mae: 0.010639, mean_q: 0.019425
 85025/100000: episode: 11846, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000873, mae: 0.013674, mean_q: 0.027303
 85035/100000: episode: 11847, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000734, mae: 0.010671, mean_q: 0.019030
 85045/100000: episode: 11848, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000696, mae: 0.011095, mean_q: 0.020211
 85055/100000: episode: 11849, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000711, mae: 0.012112, mean_q: 0.020524
 85065/100000: episode: 11850, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000933, mae: 0.012970, mean_q: 0.028044
 85075/100000: episode: 11851, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001118, mae: 0.013686, mean_q: 0.019292
 85085/100000: episode: 11852, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000647, mae: 0.012174, mean_q: 0.021335
 85095/100000: episode: 11853, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000393, mae: 0.009277, mean_q: 0.024593
 85105/100000: episode: 11854, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000646, mae: 0.009409, mean_q: 0.026606
 85115/100000: episode: 11855, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000565, mae: 0.010043, mean_q: 0.020987
 85125/100000: episode: 11856, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000625, mae: 0.012729, mean_q: 0.029647
 85135/100000: episode: 11857, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000399, mae: 0.009258, mean_q: 0.024533
 85145/100000: episode: 11858, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000608, mae: 0.010813, mean_q: 0.021389
 85155/100000: episode: 11859, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000364, mae: 0.008470, mean_q: 0.020167
 85165/100000: episode: 11860, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000788, mae: 0.012621, mean_q: 0.025774
 85175/100000: episode: 11861, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001139, mae: 0.013767, mean_q: 0.028505
 85185/100000: episode: 11862, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000698, mae: 0.010521, mean_q: 0.019504
 85195/100000: episode: 11863, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000235, mae: 0.007988, mean_q: 0.015792
 85205/100000: episode: 11864, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000434, mae: 0.010399, mean_q: 0.020400
 85215/100000: episode: 11865, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001457, mae: 0.015259, mean_q: 0.032390
 85225/100000: episode: 11866, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000360, mae: 0.010111, mean_q: 0.023997
 85235/100000: episode: 11867, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000341, mae: 0.010195, mean_q: 0.025890
 85245/100000: episode: 11868, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001053, mae: 0.012169, mean_q: 0.025463
 85255/100000: episode: 11869, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000540, mae: 0.013050, mean_q: 0.018565
 85265/100000: episode: 11870, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000669, mae: 0.011721, mean_q: 0.027867
 85275/100000: episode: 11871, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001476, mae: 0.014565, mean_q: 0.024769
 85285/100000: episode: 11872, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001362, mae: 0.014222, mean_q: 0.027095
 85295/100000: episode: 11873, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000680, mae: 0.011360, mean_q: 0.019905
 85305/100000: episode: 11874, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000606, mae: 0.011363, mean_q: 0.021769
 85315/100000: episode: 11875, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000490, mae: 0.010537, mean_q: 0.019614
 85325/100000: episode: 11876, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000283, mae: 0.010595, mean_q: 0.021517
 85335/100000: episode: 11877, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000564, mae: 0.012615, mean_q: 0.028865
 85345/100000: episode: 11878, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000668, mae: 0.012566, mean_q: 0.023075
 85355/100000: episode: 11879, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000392, mae: 0.008814, mean_q: 0.017914
 85365/100000: episode: 11880, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000779, mae: 0.013519, mean_q: 0.024593
 85375/100000: episode: 11881, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001151, mae: 0.014998, mean_q: 0.026064
 85385/100000: episode: 11882, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001070, mae: 0.012760, mean_q: 0.025964
 85395/100000: episode: 11883, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002031, mae: 0.020492, mean_q: 0.038531
 85405/100000: episode: 11884, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002529, mae: 0.019181, mean_q: 0.024448
 85415/100000: episode: 11885, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000601, mae: 0.012400, mean_q: 0.020075
 85425/100000: episode: 11886, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000926, mae: 0.015566, mean_q: 0.025017
 85435/100000: episode: 11887, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000758, mae: 0.012877, mean_q: 0.022558
 85445/100000: episode: 11888, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000753, mae: 0.011248, mean_q: 0.022969
 85455/100000: episode: 11889, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000803, mae: 0.012025, mean_q: 0.028971
 85465/100000: episode: 11890, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000297, mae: 0.007700, mean_q: 0.016191
 85475/100000: episode: 11891, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000856, mae: 0.012634, mean_q: 0.030505
 85485/100000: episode: 11892, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000516, mae: 0.010740, mean_q: 0.022959
 85495/100000: episode: 11893, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000613, mae: 0.011200, mean_q: 0.021261
 85505/100000: episode: 11894, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000831, mae: 0.012224, mean_q: 0.023250
 85515/100000: episode: 11895, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001251, mae: 0.013525, mean_q: 0.023647
 85525/100000: episode: 11896, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000716, mae: 0.012612, mean_q: 0.022267
 85535/100000: episode: 11897, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000941, mae: 0.012157, mean_q: 0.028899
 85545/100000: episode: 11898, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000269, mae: 0.008486, mean_q: 0.021940
 85555/100000: episode: 11899, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000582, mae: 0.011493, mean_q: 0.022383
 85565/100000: episode: 11900, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000613, mae: 0.010746, mean_q: 0.023118
 85575/100000: episode: 11901, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000659, mae: 0.010863, mean_q: 0.024120
 85585/100000: episode: 11902, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001029, mae: 0.012193, mean_q: 0.026660
 85595/100000: episode: 11903, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000530, mae: 0.010374, mean_q: 0.016171
 85605/100000: episode: 11904, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000483, mae: 0.013389, mean_q: 0.026490
 85615/100000: episode: 11905, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000859, mae: 0.016290, mean_q: 0.033538
 85625/100000: episode: 11906, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000452, mae: 0.011248, mean_q: 0.030031
 85635/100000: episode: 11907, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000654, mae: 0.009947, mean_q: 0.020846
 85645/100000: episode: 11908, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000441, mae: 0.009528, mean_q: 0.024073
 85655/100000: episode: 11909, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000748, mae: 0.010677, mean_q: 0.020737
 85665/100000: episode: 11910, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000981, mae: 0.013503, mean_q: 0.025041
 85675/100000: episode: 11911, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000960, mae: 0.014872, mean_q: 0.026438
 85685/100000: episode: 11912, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000811, mae: 0.012873, mean_q: 0.021382
 85695/100000: episode: 11913, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001239, mae: 0.017875, mean_q: 0.035685
 85705/100000: episode: 11914, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000306, mae: 0.010085, mean_q: 0.024698
 85715/100000: episode: 11915, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000439, mae: 0.010012, mean_q: 0.022977
 85725/100000: episode: 11916, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000770, mae: 0.010458, mean_q: 0.019971
 85735/100000: episode: 11917, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001343, mae: 0.015222, mean_q: 0.023738
 85745/100000: episode: 11918, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.001099, mae: 0.012024, mean_q: 0.023093
 85755/100000: episode: 11919, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000661, mae: 0.012569, mean_q: 0.022661
[Info] 1-TH LEVEL FOUND: 0.02747083641588688, Considering 17/100 traces
 85765/100000: episode: 11920, duration: 0.717s, episode steps: 10, steps per second: 14, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000229, mae: 0.008271, mean_q: 0.013608
 85771/100000: episode: 11921, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000724, mae: 0.011663, mean_q: 0.023763
 85775/100000: episode: 11922, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001721, mae: 0.019231, mean_q: 0.034182
 85778/100000: episode: 11923, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002464, mae: 0.018422, mean_q: 0.029407
 85781/100000: episode: 11924, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000239, mae: 0.009638, mean_q: 0.017111
 85785/100000: episode: 11925, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000294, mae: 0.007015, mean_q: 0.015727
 85788/100000: episode: 11926, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000925, mae: 0.013870, mean_q: 0.021269
 85791/100000: episode: 11927, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000392, mae: 0.011326, mean_q: 0.020249
 85794/100000: episode: 11928, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000161, mae: 0.008860, mean_q: 0.022717
 85798/100000: episode: 11929, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000276, mae: 0.009255, mean_q: 0.014527
 85801/100000: episode: 11930, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002188, mae: 0.020418, mean_q: 0.032673
 85804/100000: episode: 11931, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001192, mae: 0.017841, mean_q: 0.035658
 85810/100000: episode: 11932, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000550, mae: 0.013750, mean_q: 0.031500
 85814/100000: episode: 11933, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000095, mae: 0.006930, mean_q: 0.012210
 85817/100000: episode: 11934, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000113, mae: 0.007146, mean_q: 0.017271
 85821/100000: episode: 11935, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000226, mae: 0.009893, mean_q: 0.020277
 85825/100000: episode: 11936, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000367, mae: 0.008330, mean_q: 0.013872
 85828/100000: episode: 11937, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000625, mae: 0.012011, mean_q: 0.028067
 85831/100000: episode: 11938, duration: 0.019s, episode steps: 3, steps per second: 154, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000706, mae: 0.011073, mean_q: 0.025580
 85835/100000: episode: 11939, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001568, mae: 0.012958, mean_q: 0.018613
 85841/100000: episode: 11940, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000858, mae: 0.011921, mean_q: 0.017419
 85847/100000: episode: 11941, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000847, mae: 0.014964, mean_q: 0.028322
 85851/100000: episode: 11942, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001349, mae: 0.016461, mean_q: 0.027331
 85855/100000: episode: 11943, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000884, mae: 0.011049, mean_q: 0.021146
 85859/100000: episode: 11944, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001101, mae: 0.018708, mean_q: 0.045730
 85862/100000: episode: 11945, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001201, mae: 0.019438, mean_q: 0.039339
 85866/100000: episode: 11946, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002935, mae: 0.024760, mean_q: 0.038468
 85869/100000: episode: 11947, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000110, mae: 0.007112, mean_q: 0.011359
 85872/100000: episode: 11948, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000499, mae: 0.012645, mean_q: 0.018863
 85878/100000: episode: 11949, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001153, mae: 0.016575, mean_q: 0.017876
 85884/100000: episode: 11950, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.002549, mae: 0.017412, mean_q: 0.013287
 85890/100000: episode: 11951, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001348, mae: 0.017106, mean_q: 0.025745
 85893/100000: episode: 11952, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000531, mae: 0.017444, mean_q: 0.034673
 85896/100000: episode: 11953, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000941, mae: 0.022804, mean_q: 0.045374
 85899/100000: episode: 11954, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001023, mae: 0.017230, mean_q: 0.030345
 85905/100000: episode: 11955, duration: 0.032s, episode steps: 6, steps per second: 186, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000801, mae: 0.012453, mean_q: 0.019201
 85908/100000: episode: 11956, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002218, mae: 0.017612, mean_q: 0.021149
 85912/100000: episode: 11957, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000422, mae: 0.011920, mean_q: 0.013104
 85915/100000: episode: 11958, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000696, mae: 0.008383, mean_q: 0.009764
 85918/100000: episode: 11959, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001444, mae: 0.014391, mean_q: 0.033567
 85922/100000: episode: 11960, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000872, mae: 0.013943, mean_q: 0.025514
 85926/100000: episode: 11961, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000703, mae: 0.015197, mean_q: 0.038909
 85930/100000: episode: 11962, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000510, mae: 0.010861, mean_q: 0.024779
 85933/100000: episode: 11963, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000624, mae: 0.010338, mean_q: 0.025559
 85936/100000: episode: 11964, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000416, mae: 0.009764, mean_q: 0.023608
 85939/100000: episode: 11965, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000876, mae: 0.012211, mean_q: 0.019513
 85942/100000: episode: 11966, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000349, mae: 0.009622, mean_q: 0.017620
 85945/100000: episode: 11967, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001311, mae: 0.011987, mean_q: 0.018043
 85949/100000: episode: 11968, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000933, mae: 0.015081, mean_q: 0.029498
 85952/100000: episode: 11969, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000809, mae: 0.010062, mean_q: 0.017450
 85955/100000: episode: 11970, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000687, mae: 0.011359, mean_q: 0.028117
 85959/100000: episode: 11971, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000813, mae: 0.014273, mean_q: 0.030491
 85963/100000: episode: 11972, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001833, mae: 0.015946, mean_q: 0.024861
 85967/100000: episode: 11973, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000429, mae: 0.011616, mean_q: 0.018760
 85971/100000: episode: 11974, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003051, mae: 0.020434, mean_q: 0.031846
 85974/100000: episode: 11975, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000824, mae: 0.011813, mean_q: 0.019593
 85977/100000: episode: 11976, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000064, mae: 0.004847, mean_q: 0.017502
 85980/100000: episode: 11977, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003844, mae: 0.019689, mean_q: 0.018168
 85983/100000: episode: 11978, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001463, mae: 0.014153, mean_q: 0.019849
 85986/100000: episode: 11979, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000059, mae: 0.005236, mean_q: 0.015700
 85990/100000: episode: 11980, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001091, mae: 0.012016, mean_q: 0.017137
 85993/100000: episode: 11981, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000448, mae: 0.012126, mean_q: 0.033580
 85997/100000: episode: 11982, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001418, mae: 0.012828, mean_q: 0.019558
 86001/100000: episode: 11983, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001249, mae: 0.016964, mean_q: 0.032330
 86005/100000: episode: 11984, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002148, mae: 0.022773, mean_q: 0.046409
 86011/100000: episode: 11985, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001320, mae: 0.015307, mean_q: 0.025988
 86015/100000: episode: 11986, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000270, mae: 0.008768, mean_q: 0.014432
 86018/100000: episode: 11987, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000343, mae: 0.008853, mean_q: 0.022007
 86021/100000: episode: 11988, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000360, mae: 0.009838, mean_q: 0.027945
 86024/100000: episode: 11989, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000354, mae: 0.008709, mean_q: 0.021469
 86027/100000: episode: 11990, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000677, mae: 0.012402, mean_q: 0.030963
 86033/100000: episode: 11991, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001101, mae: 0.012239, mean_q: 0.024269
 86037/100000: episode: 11992, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000288, mae: 0.008248, mean_q: 0.016017
 86040/100000: episode: 11993, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000244, mae: 0.008139, mean_q: 0.016572
 86043/100000: episode: 11994, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001475, mae: 0.014889, mean_q: 0.031940
 86047/100000: episode: 11995, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000281, mae: 0.008203, mean_q: 0.014173
 86051/100000: episode: 11996, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000354, mae: 0.008449, mean_q: 0.019296
 86057/100000: episode: 11997, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001242, mae: 0.013793, mean_q: 0.020029
 86061/100000: episode: 11998, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000288, mae: 0.007964, mean_q: 0.023066
 86064/100000: episode: 11999, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000427, mae: 0.008416, mean_q: 0.018057
 86068/100000: episode: 12000, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001354, mae: 0.016095, mean_q: 0.034443
 86074/100000: episode: 12001, duration: 0.031s, episode steps: 6, steps per second: 193, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000260, mae: 0.009261, mean_q: 0.016071
 86078/100000: episode: 12002, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000813, mae: 0.009972, mean_q: 0.018906
[Info] 2-TH LEVEL FOUND: 0.07301292568445206, Considering 23/100 traces
 86081/100000: episode: 12003, duration: 0.645s, episode steps: 3, steps per second: 5, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001636, mae: 0.015868, mean_q: 0.025228
 86086/100000: episode: 12004, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000405, mae: 0.009866, mean_q: 0.012364
 86089/100000: episode: 12005, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000382, mae: 0.011185, mean_q: 0.012311
 86094/100000: episode: 12006, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001011, mae: 0.013023, mean_q: 0.021277
 86097/100000: episode: 12007, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000753, mae: 0.015410, mean_q: 0.023243
 86100/100000: episode: 12008, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000372, mae: 0.008917, mean_q: 0.018777
 86103/100000: episode: 12009, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000204, mae: 0.009893, mean_q: 0.026031
 86108/100000: episode: 12010, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000680, mae: 0.015673, mean_q: 0.041921
 86113/100000: episode: 12011, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001630, mae: 0.015176, mean_q: 0.027529
 86116/100000: episode: 12012, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000949, mae: 0.013705, mean_q: 0.025155
 86119/100000: episode: 12013, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000332, mae: 0.011065, mean_q: 0.030520
 86124/100000: episode: 12014, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000298, mae: 0.009052, mean_q: 0.021183
 86127/100000: episode: 12015, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000449, mae: 0.013326, mean_q: 0.018571
 86130/100000: episode: 12016, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001886, mae: 0.021247, mean_q: 0.032409
 86133/100000: episode: 12017, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000935, mae: 0.015789, mean_q: 0.039174
 86136/100000: episode: 12018, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001048, mae: 0.012362, mean_q: 0.023513
 86141/100000: episode: 12019, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000525, mae: 0.010614, mean_q: 0.023399
[Info] FALSIFICATION!
 86145/100000: episode: 12020, duration: 0.279s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000457, mae: 0.012066, mean_q: 0.026340
 86148/100000: episode: 12021, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000458, mae: 0.012663, mean_q: 0.029480
 86151/100000: episode: 12022, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002192, mae: 0.012608, mean_q: 0.023604
 86154/100000: episode: 12023, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000759, mae: 0.012999, mean_q: 0.029833
 86157/100000: episode: 12024, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000766, mae: 0.011270, mean_q: 0.024345
 86160/100000: episode: 12025, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000756, mae: 0.013059, mean_q: 0.032542
 86165/100000: episode: 12026, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000180, mae: 0.006199, mean_q: 0.015064
 86170/100000: episode: 12027, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000882, mae: 0.014231, mean_q: 0.029690
 86175/100000: episode: 12028, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001919, mae: 0.020119, mean_q: 0.044138
 86180/100000: episode: 12029, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001817, mae: 0.018458, mean_q: 0.035107
 86183/100000: episode: 12030, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001742, mae: 0.016290, mean_q: 0.037015
 86188/100000: episode: 12031, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001019, mae: 0.015150, mean_q: 0.031274
 86191/100000: episode: 12032, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001702, mae: 0.015270, mean_q: 0.023775
 86194/100000: episode: 12033, duration: 0.020s, episode steps: 3, steps per second: 152, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000269, mae: 0.011051, mean_q: 0.012831
 86199/100000: episode: 12034, duration: 0.033s, episode steps: 5, steps per second: 152, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000549, mae: 0.012138, mean_q: 0.014231
 86204/100000: episode: 12035, duration: 0.041s, episode steps: 5, steps per second: 121, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000322, mae: 0.009320, mean_q: 0.012558
 86207/100000: episode: 12036, duration: 0.025s, episode steps: 3, steps per second: 122, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000311, mae: 0.009746, mean_q: 0.013931
 86212/100000: episode: 12037, duration: 0.030s, episode steps: 5, steps per second: 166, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000472, mae: 0.009420, mean_q: 0.023938
 86217/100000: episode: 12038, duration: 0.033s, episode steps: 5, steps per second: 150, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001035, mae: 0.014442, mean_q: 0.030631
[Info] FALSIFICATION!
 86221/100000: episode: 12039, duration: 0.288s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001187, mae: 0.012059, mean_q: 0.023450
 86224/100000: episode: 12040, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000281, mae: 0.008805, mean_q: 0.023180
 86229/100000: episode: 12041, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000485, mae: 0.011815, mean_q: 0.024023
 86234/100000: episode: 12042, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001841, mae: 0.016144, mean_q: 0.032541
 86237/100000: episode: 12043, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000827, mae: 0.013993, mean_q: 0.035367
 86240/100000: episode: 12044, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000553, mae: 0.013107, mean_q: 0.020159
 86243/100000: episode: 12045, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001455, mae: 0.013924, mean_q: 0.026007
 86246/100000: episode: 12046, duration: 0.018s, episode steps: 3, steps per second: 162, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000146, mae: 0.008229, mean_q: 0.012247
 86249/100000: episode: 12047, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000296, mae: 0.009976, mean_q: 0.014592
 86252/100000: episode: 12048, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000096, mae: 0.005870, mean_q: 0.005975
 86255/100000: episode: 12049, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000268, mae: 0.009234, mean_q: 0.015254
 86258/100000: episode: 12050, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000314, mae: 0.009594, mean_q: 0.023029
 86263/100000: episode: 12051, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001061, mae: 0.014428, mean_q: 0.027379
 86266/100000: episode: 12052, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000331, mae: 0.007587, mean_q: 0.016901
 86269/100000: episode: 12053, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000282, mae: 0.009459, mean_q: 0.017335
 86274/100000: episode: 12054, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000596, mae: 0.010109, mean_q: 0.025103
 86279/100000: episode: 12055, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000650, mae: 0.012548, mean_q: 0.027911
 86282/100000: episode: 12056, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001225, mae: 0.017145, mean_q: 0.028608
 86287/100000: episode: 12057, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000491, mae: 0.011894, mean_q: 0.025616
 86290/100000: episode: 12058, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000435, mae: 0.013306, mean_q: 0.029487
 86295/100000: episode: 12059, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000228, mae: 0.008921, mean_q: 0.015091
 86298/100000: episode: 12060, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000365, mae: 0.010650, mean_q: 0.019278
 86301/100000: episode: 12061, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001512, mae: 0.019468, mean_q: 0.034309
 86306/100000: episode: 12062, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002512, mae: 0.019843, mean_q: 0.034299
 86309/100000: episode: 12063, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000319, mae: 0.011900, mean_q: 0.020701
 86314/100000: episode: 12064, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001363, mae: 0.015967, mean_q: 0.029361
 86319/100000: episode: 12065, duration: 0.030s, episode steps: 5, steps per second: 168, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000307, mae: 0.009494, mean_q: 0.018819
 86324/100000: episode: 12066, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001012, mae: 0.013995, mean_q: 0.028156
 86329/100000: episode: 12067, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000686, mae: 0.014003, mean_q: 0.024102
 86332/100000: episode: 12068, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003569, mae: 0.026640, mean_q: 0.049785
 86335/100000: episode: 12069, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000615, mae: 0.013117, mean_q: 0.020526
 86338/100000: episode: 12070, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001129, mae: 0.014823, mean_q: 0.026393
 86343/100000: episode: 12071, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001370, mae: 0.015985, mean_q: 0.026367
 86346/100000: episode: 12072, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001628, mae: 0.016887, mean_q: 0.024792
 86349/100000: episode: 12073, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000432, mae: 0.011367, mean_q: 0.018140
 86352/100000: episode: 12074, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001722, mae: 0.018379, mean_q: 0.032061
 86355/100000: episode: 12075, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000653, mae: 0.014987, mean_q: 0.033100
 86358/100000: episode: 12076, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000855, mae: 0.017894, mean_q: 0.041217
 86363/100000: episode: 12077, duration: 0.025s, episode steps: 5, steps per second: 204, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000549, mae: 0.013975, mean_q: 0.032067
 86366/100000: episode: 12078, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002656, mae: 0.023805, mean_q: 0.076787
[Info] FALSIFICATION!
 86370/100000: episode: 12079, duration: 0.286s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000489, mae: 0.012705, mean_q: 0.014079
[Info] Complete ISplit Iteration
[Info] Levels: [0.027470836, 0.073012926, 1.1703844]
[Info] Cond. Prob: [0.17, 0.23, 0.05]
[Info] Error Prob: 0.001955

 86375/100000: episode: 12080, duration: 0.876s, episode steps: 5, steps per second: 6, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000661, mae: 0.015476, mean_q: 0.019309
 86385/100000: episode: 12081, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000766, mae: 0.014035, mean_q: 0.028995
 86395/100000: episode: 12082, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001313, mae: 0.018107, mean_q: 0.037716
 86405/100000: episode: 12083, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000576, mae: 0.012968, mean_q: 0.029592
 86415/100000: episode: 12084, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002115, mae: 0.020182, mean_q: 0.042159
 86425/100000: episode: 12085, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001629, mae: 0.017002, mean_q: 0.030222
 86435/100000: episode: 12086, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001340, mae: 0.016629, mean_q: 0.028800
 86445/100000: episode: 12087, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000907, mae: 0.013413, mean_q: 0.029146
 86455/100000: episode: 12088, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000758, mae: 0.011685, mean_q: 0.021892
 86465/100000: episode: 12089, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000834, mae: 0.011014, mean_q: 0.023311
 86475/100000: episode: 12090, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001312, mae: 0.016129, mean_q: 0.030468
 86485/100000: episode: 12091, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000666, mae: 0.012965, mean_q: 0.022692
 86495/100000: episode: 12092, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000762, mae: 0.012996, mean_q: 0.025310
 86505/100000: episode: 12093, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000427, mae: 0.010075, mean_q: 0.019881
 86515/100000: episode: 12094, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000898, mae: 0.013124, mean_q: 0.023653
 86525/100000: episode: 12095, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001242, mae: 0.015768, mean_q: 0.033631
 86535/100000: episode: 12096, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000340, mae: 0.011107, mean_q: 0.021614
 86545/100000: episode: 12097, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000759, mae: 0.012510, mean_q: 0.034177
 86555/100000: episode: 12098, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001140, mae: 0.014903, mean_q: 0.030145
 86565/100000: episode: 12099, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000708, mae: 0.012930, mean_q: 0.021298
 86575/100000: episode: 12100, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000533, mae: 0.009797, mean_q: 0.016782
 86585/100000: episode: 12101, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000918, mae: 0.013478, mean_q: 0.027192
 86595/100000: episode: 12102, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000589, mae: 0.011882, mean_q: 0.028073
 86605/100000: episode: 12103, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000613, mae: 0.012561, mean_q: 0.029559
 86615/100000: episode: 12104, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001260, mae: 0.015025, mean_q: 0.032673
 86625/100000: episode: 12105, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001352, mae: 0.013558, mean_q: 0.025621
 86635/100000: episode: 12106, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000486, mae: 0.011572, mean_q: 0.021883
 86645/100000: episode: 12107, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001349, mae: 0.014980, mean_q: 0.027917
 86655/100000: episode: 12108, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000770, mae: 0.011960, mean_q: 0.023941
 86665/100000: episode: 12109, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000349, mae: 0.010819, mean_q: 0.018897
 86675/100000: episode: 12110, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000431, mae: 0.012531, mean_q: 0.027683
 86685/100000: episode: 12111, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000853, mae: 0.014684, mean_q: 0.032489
 86695/100000: episode: 12112, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000617, mae: 0.011128, mean_q: 0.023070
 86705/100000: episode: 12113, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000465, mae: 0.009450, mean_q: 0.020908
 86715/100000: episode: 12114, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000579, mae: 0.011019, mean_q: 0.022405
 86725/100000: episode: 12115, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001529, mae: 0.017778, mean_q: 0.042227
 86735/100000: episode: 12116, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000656, mae: 0.013315, mean_q: 0.027544
 86745/100000: episode: 12117, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000472, mae: 0.010362, mean_q: 0.016351
 86755/100000: episode: 12118, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000880, mae: 0.013208, mean_q: 0.021816
 86765/100000: episode: 12119, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000779, mae: 0.013801, mean_q: 0.028126
 86775/100000: episode: 12120, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001204, mae: 0.014275, mean_q: 0.027118
 86785/100000: episode: 12121, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000961, mae: 0.014383, mean_q: 0.026679
 86795/100000: episode: 12122, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001079, mae: 0.014311, mean_q: 0.024870
 86805/100000: episode: 12123, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000630, mae: 0.012224, mean_q: 0.030173
 86815/100000: episode: 12124, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000925, mae: 0.014595, mean_q: 0.033569
 86825/100000: episode: 12125, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000411, mae: 0.009986, mean_q: 0.023065
 86835/100000: episode: 12126, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000754, mae: 0.012882, mean_q: 0.028591
 86845/100000: episode: 12127, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000908, mae: 0.013311, mean_q: 0.032095
 86855/100000: episode: 12128, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000662, mae: 0.013323, mean_q: 0.036251
 86865/100000: episode: 12129, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000726, mae: 0.013592, mean_q: 0.030728
 86875/100000: episode: 12130, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000972, mae: 0.012870, mean_q: 0.024447
 86885/100000: episode: 12131, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000809, mae: 0.016060, mean_q: 0.037357
 86895/100000: episode: 12132, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000921, mae: 0.014612, mean_q: 0.029109
 86905/100000: episode: 12133, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000953, mae: 0.016233, mean_q: 0.032693
 86915/100000: episode: 12134, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000742, mae: 0.014033, mean_q: 0.030303
 86925/100000: episode: 12135, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001466, mae: 0.016529, mean_q: 0.034826
 86935/100000: episode: 12136, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001058, mae: 0.013538, mean_q: 0.027738
 86945/100000: episode: 12137, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001391, mae: 0.015602, mean_q: 0.029855
 86955/100000: episode: 12138, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000580, mae: 0.010358, mean_q: 0.021641
 86965/100000: episode: 12139, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001904, mae: 0.015789, mean_q: 0.030072
 86975/100000: episode: 12140, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000462, mae: 0.010727, mean_q: 0.021927
 86985/100000: episode: 12141, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000692, mae: 0.010667, mean_q: 0.022291
 86995/100000: episode: 12142, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000842, mae: 0.013706, mean_q: 0.027492
 87005/100000: episode: 12143, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000524, mae: 0.011683, mean_q: 0.027099
 87015/100000: episode: 12144, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001025, mae: 0.015483, mean_q: 0.028275
 87025/100000: episode: 12145, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000710, mae: 0.012605, mean_q: 0.023856
 87035/100000: episode: 12146, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000332, mae: 0.010383, mean_q: 0.022925
 87045/100000: episode: 12147, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000780, mae: 0.015230, mean_q: 0.032010
 87055/100000: episode: 12148, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001013, mae: 0.014490, mean_q: 0.027957
 87065/100000: episode: 12149, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001406, mae: 0.015606, mean_q: 0.025892
 87075/100000: episode: 12150, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000450, mae: 0.012734, mean_q: 0.023453
 87085/100000: episode: 12151, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000634, mae: 0.014522, mean_q: 0.032757
 87095/100000: episode: 12152, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001405, mae: 0.016624, mean_q: 0.043788
 87105/100000: episode: 12153, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000448, mae: 0.010556, mean_q: 0.024562
 87115/100000: episode: 12154, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000664, mae: 0.012313, mean_q: 0.026688
 87125/100000: episode: 12155, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001018, mae: 0.016181, mean_q: 0.029780
 87135/100000: episode: 12156, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001320, mae: 0.016641, mean_q: 0.026672
 87145/100000: episode: 12157, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000371, mae: 0.011064, mean_q: 0.019556
 87155/100000: episode: 12158, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000964, mae: 0.016996, mean_q: 0.043575
 87165/100000: episode: 12159, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000907, mae: 0.015098, mean_q: 0.036017
 87175/100000: episode: 12160, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000994, mae: 0.014910, mean_q: 0.023599
 87185/100000: episode: 12161, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001503, mae: 0.017090, mean_q: 0.029717
 87195/100000: episode: 12162, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001417, mae: 0.018840, mean_q: 0.037042
 87205/100000: episode: 12163, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000511, mae: 0.012808, mean_q: 0.028306
 87215/100000: episode: 12164, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002284, mae: 0.019850, mean_q: 0.029067
 87225/100000: episode: 12165, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000991, mae: 0.013008, mean_q: 0.023847
 87235/100000: episode: 12166, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000594, mae: 0.013701, mean_q: 0.028420
 87245/100000: episode: 12167, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001143, mae: 0.014718, mean_q: 0.029047
 87255/100000: episode: 12168, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000609, mae: 0.011974, mean_q: 0.024403
 87265/100000: episode: 12169, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000877, mae: 0.013236, mean_q: 0.027070
 87275/100000: episode: 12170, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000872, mae: 0.015937, mean_q: 0.020863
 87285/100000: episode: 12171, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001504, mae: 0.013934, mean_q: 0.023169
 87295/100000: episode: 12172, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001018, mae: 0.017529, mean_q: 0.044629
 87305/100000: episode: 12173, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000356, mae: 0.010127, mean_q: 0.017748
 87315/100000: episode: 12174, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000828, mae: 0.013165, mean_q: 0.023828
 87325/100000: episode: 12175, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001071, mae: 0.015099, mean_q: 0.031336
 87335/100000: episode: 12176, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001004, mae: 0.013122, mean_q: 0.028608
 87345/100000: episode: 12177, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001050, mae: 0.015912, mean_q: 0.032755
 87355/100000: episode: 12178, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000655, mae: 0.012780, mean_q: 0.024997
 87365/100000: episode: 12179, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001532, mae: 0.019066, mean_q: 0.039580
[Info] 1-TH LEVEL FOUND: 0.039092764258384705, Considering 11/100 traces
 87375/100000: episode: 12180, duration: 0.820s, episode steps: 10, steps per second: 12, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000355, mae: 0.011349, mean_q: 0.026394
 87378/100000: episode: 12181, duration: 0.023s, episode steps: 3, steps per second: 133, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000575, mae: 0.010963, mean_q: 0.024064
 87381/100000: episode: 12182, duration: 0.023s, episode steps: 3, steps per second: 130, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000113, mae: 0.006729, mean_q: 0.013400
 87384/100000: episode: 12183, duration: 0.023s, episode steps: 3, steps per second: 130, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000827, mae: 0.013614, mean_q: 0.037451
 87388/100000: episode: 12184, duration: 0.028s, episode steps: 4, steps per second: 142, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000919, mae: 0.014893, mean_q: 0.030533
 87392/100000: episode: 12185, duration: 0.060s, episode steps: 4, steps per second: 66, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000748, mae: 0.014481, mean_q: 0.042006
 87396/100000: episode: 12186, duration: 0.028s, episode steps: 4, steps per second: 143, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000338, mae: 0.009060, mean_q: 0.024781
 87402/100000: episode: 12187, duration: 0.033s, episode steps: 6, steps per second: 183, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000792, mae: 0.011462, mean_q: 0.019596
 87408/100000: episode: 12188, duration: 0.031s, episode steps: 6, steps per second: 192, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000731, mae: 0.013116, mean_q: 0.024217
 87412/100000: episode: 12189, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001341, mae: 0.015961, mean_q: 0.030504
 87415/100000: episode: 12190, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001791, mae: 0.015412, mean_q: 0.030507
 87419/100000: episode: 12191, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000608, mae: 0.012529, mean_q: 0.027535
 87422/100000: episode: 12192, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000249, mae: 0.010562, mean_q: 0.021629
 87428/100000: episode: 12193, duration: 0.034s, episode steps: 6, steps per second: 176, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000439, mae: 0.011197, mean_q: 0.027388
 87431/100000: episode: 12194, duration: 0.020s, episode steps: 3, steps per second: 149, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000780, mae: 0.013939, mean_q: 0.030926
 87435/100000: episode: 12195, duration: 0.024s, episode steps: 4, steps per second: 166, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000555, mae: 0.011815, mean_q: 0.026772
 87439/100000: episode: 12196, duration: 0.027s, episode steps: 4, steps per second: 151, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001371, mae: 0.015309, mean_q: 0.026654
 87443/100000: episode: 12197, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000437, mae: 0.011043, mean_q: 0.024391
 87447/100000: episode: 12198, duration: 0.027s, episode steps: 4, steps per second: 147, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000644, mae: 0.013116, mean_q: 0.014121
 87451/100000: episode: 12199, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001128, mae: 0.017938, mean_q: 0.029217
 87454/100000: episode: 12200, duration: 0.019s, episode steps: 3, steps per second: 155, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001023, mae: 0.018533, mean_q: 0.025154
 87458/100000: episode: 12201, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001958, mae: 0.017636, mean_q: 0.018316
 87464/100000: episode: 12202, duration: 0.032s, episode steps: 6, steps per second: 189, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001713, mae: 0.017225, mean_q: 0.029284
 87470/100000: episode: 12203, duration: 0.034s, episode steps: 6, steps per second: 179, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000170, mae: 0.009594, mean_q: 0.018031
 87473/100000: episode: 12204, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001398, mae: 0.017517, mean_q: 0.027171
 87476/100000: episode: 12205, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001014, mae: 0.017940, mean_q: 0.034226
 87480/100000: episode: 12206, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000690, mae: 0.013446, mean_q: 0.028969
 87486/100000: episode: 12207, duration: 0.031s, episode steps: 6, steps per second: 191, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001016, mae: 0.014250, mean_q: 0.027952
 87489/100000: episode: 12208, duration: 0.020s, episode steps: 3, steps per second: 152, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001296, mae: 0.017317, mean_q: 0.041131
 87492/100000: episode: 12209, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000369, mae: 0.010944, mean_q: 0.018885
 87496/100000: episode: 12210, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000917, mae: 0.013893, mean_q: 0.031245
 87502/100000: episode: 12211, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001230, mae: 0.016046, mean_q: 0.031745
 87506/100000: episode: 12212, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000777, mae: 0.012524, mean_q: 0.031202
 87509/100000: episode: 12213, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001510, mae: 0.017050, mean_q: 0.032826
 87512/100000: episode: 12214, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001132, mae: 0.014866, mean_q: 0.029846
 87515/100000: episode: 12215, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000546, mae: 0.016467, mean_q: 0.035086
 87518/100000: episode: 12216, duration: 0.050s, episode steps: 3, steps per second: 60, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001136, mae: 0.015552, mean_q: 0.017425
 87521/100000: episode: 12217, duration: 0.050s, episode steps: 3, steps per second: 59, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001322, mae: 0.018617, mean_q: 0.035578
 87524/100000: episode: 12218, duration: 0.034s, episode steps: 3, steps per second: 89, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000242, mae: 0.010261, mean_q: 0.025843
 87528/100000: episode: 12219, duration: 0.039s, episode steps: 4, steps per second: 103, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002079, mae: 0.015746, mean_q: 0.023875
 87531/100000: episode: 12220, duration: 0.036s, episode steps: 3, steps per second: 84, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001550, mae: 0.019951, mean_q: 0.042459
 87534/100000: episode: 12221, duration: 0.066s, episode steps: 3, steps per second: 45, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000496, mae: 0.009558, mean_q: 0.021807
 87538/100000: episode: 12222, duration: 0.057s, episode steps: 4, steps per second: 70, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000423, mae: 0.011182, mean_q: 0.018859
 87541/100000: episode: 12223, duration: 0.042s, episode steps: 3, steps per second: 71, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000087, mae: 0.006459, mean_q: 0.013915
 87544/100000: episode: 12224, duration: 0.056s, episode steps: 3, steps per second: 54, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002767, mae: 0.020291, mean_q: 0.032224
 87548/100000: episode: 12225, duration: 0.047s, episode steps: 4, steps per second: 85, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000249, mae: 0.007612, mean_q: 0.016568
 87552/100000: episode: 12226, duration: 0.046s, episode steps: 4, steps per second: 86, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000154, mae: 0.005587, mean_q: 0.008702
 87556/100000: episode: 12227, duration: 0.048s, episode steps: 4, steps per second: 83, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000077, mae: 0.005481, mean_q: 0.009587
 87559/100000: episode: 12228, duration: 0.037s, episode steps: 3, steps per second: 81, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001715, mae: 0.015496, mean_q: 0.026197
 87563/100000: episode: 12229, duration: 0.040s, episode steps: 4, steps per second: 99, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000348, mae: 0.008630, mean_q: 0.021428
 87569/100000: episode: 12230, duration: 0.070s, episode steps: 6, steps per second: 86, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000594, mae: 0.011678, mean_q: 0.024508
 87572/100000: episode: 12231, duration: 0.047s, episode steps: 3, steps per second: 64, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000114, mae: 0.006333, mean_q: 0.015563
 87576/100000: episode: 12232, duration: 0.052s, episode steps: 4, steps per second: 77, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000337, mae: 0.008591, mean_q: 0.024138
 87579/100000: episode: 12233, duration: 0.047s, episode steps: 3, steps per second: 64, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000783, mae: 0.013574, mean_q: 0.030036
 87585/100000: episode: 12234, duration: 0.074s, episode steps: 6, steps per second: 81, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001113, mae: 0.013143, mean_q: 0.023232
 87589/100000: episode: 12235, duration: 0.061s, episode steps: 4, steps per second: 65, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000130, mae: 0.006516, mean_q: 0.010083
 87595/100000: episode: 12236, duration: 0.063s, episode steps: 6, steps per second: 96, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000623, mae: 0.011119, mean_q: 0.025538
 87598/100000: episode: 12237, duration: 0.037s, episode steps: 3, steps per second: 81, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000135, mae: 0.005653, mean_q: 0.018883
 87601/100000: episode: 12238, duration: 0.068s, episode steps: 3, steps per second: 44, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001386, mae: 0.014810, mean_q: 0.024216
 87607/100000: episode: 12239, duration: 0.074s, episode steps: 6, steps per second: 81, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000790, mae: 0.011823, mean_q: 0.019108
 87610/100000: episode: 12240, duration: 0.030s, episode steps: 3, steps per second: 98, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000497, mae: 0.010641, mean_q: 0.022072
 87613/100000: episode: 12241, duration: 0.035s, episode steps: 3, steps per second: 87, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001996, mae: 0.016226, mean_q: 0.027745
 87617/100000: episode: 12242, duration: 0.043s, episode steps: 4, steps per second: 93, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000560, mae: 0.010763, mean_q: 0.024711
 87621/100000: episode: 12243, duration: 0.058s, episode steps: 4, steps per second: 69, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000251, mae: 0.006997, mean_q: 0.013029
 87624/100000: episode: 12244, duration: 0.033s, episode steps: 3, steps per second: 91, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000666, mae: 0.011753, mean_q: 0.025140
 87628/100000: episode: 12245, duration: 0.052s, episode steps: 4, steps per second: 77, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001406, mae: 0.012865, mean_q: 0.023993
 87631/100000: episode: 12246, duration: 0.033s, episode steps: 3, steps per second: 90, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000236, mae: 0.008388, mean_q: 0.015756
 87635/100000: episode: 12247, duration: 0.052s, episode steps: 4, steps per second: 77, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001076, mae: 0.009931, mean_q: 0.024335
 87638/100000: episode: 12248, duration: 0.035s, episode steps: 3, steps per second: 85, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001312, mae: 0.011806, mean_q: 0.018562
 87642/100000: episode: 12249, duration: 0.041s, episode steps: 4, steps per second: 97, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000157, mae: 0.008495, mean_q: 0.015610
 87645/100000: episode: 12250, duration: 0.035s, episode steps: 3, steps per second: 87, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000299, mae: 0.009640, mean_q: 0.019231
 87648/100000: episode: 12251, duration: 0.022s, episode steps: 3, steps per second: 136, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001115, mae: 0.015389, mean_q: 0.019939
 87652/100000: episode: 12252, duration: 0.026s, episode steps: 4, steps per second: 151, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000956, mae: 0.017518, mean_q: 0.038043
 87656/100000: episode: 12253, duration: 0.031s, episode steps: 4, steps per second: 128, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000139, mae: 0.008001, mean_q: 0.016554
 87659/100000: episode: 12254, duration: 0.028s, episode steps: 3, steps per second: 108, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000400, mae: 0.010807, mean_q: 0.017598
 87662/100000: episode: 12255, duration: 0.030s, episode steps: 3, steps per second: 101, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000052, mae: 0.005339, mean_q: 0.009826
 87665/100000: episode: 12256, duration: 0.022s, episode steps: 3, steps per second: 134, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000394, mae: 0.010932, mean_q: 0.020116
 87669/100000: episode: 12257, duration: 0.025s, episode steps: 4, steps per second: 161, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000119, mae: 0.007795, mean_q: 0.014086
 87675/100000: episode: 12258, duration: 0.040s, episode steps: 6, steps per second: 152, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000251, mae: 0.007615, mean_q: 0.012567
 87679/100000: episode: 12259, duration: 0.030s, episode steps: 4, steps per second: 133, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000829, mae: 0.013290, mean_q: 0.033468
 87683/100000: episode: 12260, duration: 0.027s, episode steps: 4, steps per second: 147, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000150, mae: 0.008424, mean_q: 0.011626
 87687/100000: episode: 12261, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000374, mae: 0.008867, mean_q: 0.017711
 87691/100000: episode: 12262, duration: 0.025s, episode steps: 4, steps per second: 163, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001257, mae: 0.011170, mean_q: 0.015278
 87694/100000: episode: 12263, duration: 0.024s, episode steps: 3, steps per second: 124, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000240, mae: 0.007958, mean_q: 0.014279
 87698/100000: episode: 12264, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000127, mae: 0.008069, mean_q: 0.020501
 87704/100000: episode: 12265, duration: 0.033s, episode steps: 6, steps per second: 181, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000208, mae: 0.008919, mean_q: 0.022757
 87707/100000: episode: 12266, duration: 0.020s, episode steps: 3, steps per second: 154, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000141, mae: 0.007794, mean_q: 0.013233
 87711/100000: episode: 12267, duration: 0.040s, episode steps: 4, steps per second: 100, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000176, mae: 0.006829, mean_q: 0.016132
 87714/100000: episode: 12268, duration: 0.028s, episode steps: 3, steps per second: 106, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000434, mae: 0.008782, mean_q: 0.021449
[Info] 2-TH LEVEL FOUND: 0.13897103071212769, Considering 11/100 traces
 87718/100000: episode: 12269, duration: 1.080s, episode steps: 4, steps per second: 4, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000111, mae: 0.007494, mean_q: 0.013821
 87723/100000: episode: 12270, duration: 0.033s, episode steps: 5, steps per second: 150, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000609, mae: 0.011429, mean_q: 0.019297
 87728/100000: episode: 12271, duration: 0.040s, episode steps: 5, steps per second: 125, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000101, mae: 0.006317, mean_q: 0.008082
 87733/100000: episode: 12272, duration: 0.030s, episode steps: 5, steps per second: 165, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000206, mae: 0.009732, mean_q: 0.011120
 87738/100000: episode: 12273, duration: 0.034s, episode steps: 5, steps per second: 149, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000125, mae: 0.006859, mean_q: 0.009280
 87743/100000: episode: 12274, duration: 0.034s, episode steps: 5, steps per second: 149, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000111, mae: 0.005513, mean_q: 0.009546
 87748/100000: episode: 12275, duration: 0.034s, episode steps: 5, steps per second: 148, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000657, mae: 0.013149, mean_q: 0.023127
[Info] FALSIFICATION!
 87752/100000: episode: 12276, duration: 0.291s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000427, mae: 0.012463, mean_q: 0.021778
 87757/100000: episode: 12277, duration: 0.036s, episode steps: 5, steps per second: 140, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000466, mae: 0.012069, mean_q: 0.023700
 87762/100000: episode: 12278, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000438, mae: 0.010380, mean_q: 0.019592
 87767/100000: episode: 12279, duration: 0.032s, episode steps: 5, steps per second: 157, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000154, mae: 0.007555, mean_q: 0.015135
 87772/100000: episode: 12280, duration: 0.029s, episode steps: 5, steps per second: 171, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000187, mae: 0.008597, mean_q: 0.016674
 87777/100000: episode: 12281, duration: 0.033s, episode steps: 5, steps per second: 150, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000245, mae: 0.008562, mean_q: 0.019027
 87782/100000: episode: 12282, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000103, mae: 0.006528, mean_q: 0.010430
 87787/100000: episode: 12283, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000323, mae: 0.008978, mean_q: 0.014962
 87792/100000: episode: 12284, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001023, mae: 0.014440, mean_q: 0.025785
 87797/100000: episode: 12285, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000186, mae: 0.009681, mean_q: 0.020271
 87802/100000: episode: 12286, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000330, mae: 0.009380, mean_q: 0.027319
[Info] FALSIFICATION!
 87806/100000: episode: 12287, duration: 0.280s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000427, mae: 0.010974, mean_q: 0.018932
 87811/100000: episode: 12288, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001195, mae: 0.012988, mean_q: 0.026241
 87816/100000: episode: 12289, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000938, mae: 0.012081, mean_q: 0.023501
 87821/100000: episode: 12290, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000569, mae: 0.011259, mean_q: 0.024036
 87826/100000: episode: 12291, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001048, mae: 0.013012, mean_q: 0.027238
 87831/100000: episode: 12292, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000688, mae: 0.011092, mean_q: 0.022289
 87836/100000: episode: 12293, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000216, mae: 0.011142, mean_q: 0.019342
 87841/100000: episode: 12294, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001482, mae: 0.018581, mean_q: 0.027060
 87846/100000: episode: 12295, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000258, mae: 0.007179, mean_q: 0.012591
 87851/100000: episode: 12296, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000894, mae: 0.013779, mean_q: 0.026103
[Info] FALSIFICATION!
 87855/100000: episode: 12297, duration: 0.279s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000360, mae: 0.010287, mean_q: 0.016961
 87860/100000: episode: 12298, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000759, mae: 0.014399, mean_q: 0.027301
 87865/100000: episode: 12299, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000589, mae: 0.013413, mean_q: 0.025742
 87870/100000: episode: 12300, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000870, mae: 0.012434, mean_q: 0.027509
 87875/100000: episode: 12301, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000453, mae: 0.011984, mean_q: 0.026175
 87880/100000: episode: 12302, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001103, mae: 0.015970, mean_q: 0.029341
 87885/100000: episode: 12303, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000687, mae: 0.013830, mean_q: 0.029203
 87890/100000: episode: 12304, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001542, mae: 0.015595, mean_q: 0.028313
 87895/100000: episode: 12305, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000247, mae: 0.008391, mean_q: 0.019828
 87900/100000: episode: 12306, duration: 0.032s, episode steps: 5, steps per second: 158, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000195, mae: 0.009648, mean_q: 0.025637
 87905/100000: episode: 12307, duration: 0.029s, episode steps: 5, steps per second: 173, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000713, mae: 0.013645, mean_q: 0.023228
 87910/100000: episode: 12308, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000984, mae: 0.014652, mean_q: 0.025204
 87915/100000: episode: 12309, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002379, mae: 0.020915, mean_q: 0.032406
 87920/100000: episode: 12310, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000945, mae: 0.015079, mean_q: 0.029708
 87925/100000: episode: 12311, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001258, mae: 0.020702, mean_q: 0.049497
 87930/100000: episode: 12312, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001058, mae: 0.013853, mean_q: 0.027905
 87935/100000: episode: 12313, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000652, mae: 0.010424, mean_q: 0.022952
 87940/100000: episode: 12314, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001470, mae: 0.017635, mean_q: 0.022586
[Info] FALSIFICATION!
 87944/100000: episode: 12315, duration: 0.230s, episode steps: 4, steps per second: 17, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000490, mae: 0.009569, mean_q: 0.012253
 87949/100000: episode: 12316, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000637, mae: 0.011441, mean_q: 0.023589
 87954/100000: episode: 12317, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000699, mae: 0.014064, mean_q: 0.028880
 87959/100000: episode: 12318, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000230, mae: 0.008917, mean_q: 0.019945
 87964/100000: episode: 12319, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000121, mae: 0.007417, mean_q: 0.017022
 87969/100000: episode: 12320, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001545, mae: 0.015590, mean_q: 0.026922
 87974/100000: episode: 12321, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001316, mae: 0.015202, mean_q: 0.030360
 87979/100000: episode: 12322, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000909, mae: 0.013102, mean_q: 0.019400
 87984/100000: episode: 12323, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000983, mae: 0.016978, mean_q: 0.035452
 87989/100000: episode: 12324, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001327, mae: 0.018005, mean_q: 0.037387
 87994/100000: episode: 12325, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000714, mae: 0.008577, mean_q: 0.016686
 87999/100000: episode: 12326, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000779, mae: 0.010175, mean_q: 0.017606
 88004/100000: episode: 12327, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000206, mae: 0.008182, mean_q: 0.012017
 88009/100000: episode: 12328, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000571, mae: 0.014126, mean_q: 0.031916
 88014/100000: episode: 12329, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001635, mae: 0.017819, mean_q: 0.030114
 88019/100000: episode: 12330, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001167, mae: 0.017123, mean_q: 0.039882
 88024/100000: episode: 12331, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000845, mae: 0.015409, mean_q: 0.043941
 88029/100000: episode: 12332, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000695, mae: 0.013946, mean_q: 0.036036
 88034/100000: episode: 12333, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001059, mae: 0.013835, mean_q: 0.028379
 88039/100000: episode: 12334, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000408, mae: 0.011439, mean_q: 0.023029
 88044/100000: episode: 12335, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000704, mae: 0.012916, mean_q: 0.020496
 88049/100000: episode: 12336, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000734, mae: 0.014092, mean_q: 0.024890
 88054/100000: episode: 12337, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000626, mae: 0.009791, mean_q: 0.016766
 88059/100000: episode: 12338, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000266, mae: 0.010274, mean_q: 0.021272
 88064/100000: episode: 12339, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001466, mae: 0.016834, mean_q: 0.032722
 88069/100000: episode: 12340, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001800, mae: 0.018628, mean_q: 0.035051
 88074/100000: episode: 12341, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000484, mae: 0.011126, mean_q: 0.018421
 88079/100000: episode: 12342, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000534, mae: 0.012550, mean_q: 0.018450
 88084/100000: episode: 12343, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.001403, mae: 0.014685, mean_q: 0.019410
[Info] FALSIFICATION!
 88088/100000: episode: 12344, duration: 0.278s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000658, mae: 0.013301, mean_q: 0.025249
 88093/100000: episode: 12345, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000560, mae: 0.012465, mean_q: 0.020199
 88098/100000: episode: 12346, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001634, mae: 0.021808, mean_q: 0.040575
 88103/100000: episode: 12347, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001050, mae: 0.018228, mean_q: 0.030058
[Info] FALSIFICATION!
 88107/100000: episode: 12348, duration: 0.278s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000614, mae: 0.016369, mean_q: 0.038236
 88112/100000: episode: 12349, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001309, mae: 0.017115, mean_q: 0.034901
 88117/100000: episode: 12350, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001190, mae: 0.014876, mean_q: 0.028960
 88122/100000: episode: 12351, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001213, mae: 0.017202, mean_q: 0.029010
 88127/100000: episode: 12352, duration: 0.028s, episode steps: 5, steps per second: 176, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000895, mae: 0.016437, mean_q: 0.021511
 88132/100000: episode: 12353, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000675, mae: 0.012892, mean_q: 0.020854
 88137/100000: episode: 12354, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000291, mae: 0.009492, mean_q: 0.020347
 88142/100000: episode: 12355, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000262, mae: 0.009623, mean_q: 0.019171
 88147/100000: episode: 12356, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000982, mae: 0.013422, mean_q: 0.028802
 88152/100000: episode: 12357, duration: 0.030s, episode steps: 5, steps per second: 167, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000485, mae: 0.009356, mean_q: 0.018822
[Info] Complete ISplit Iteration
[Info] Levels: [0.039092764, 0.13897103, 1.1097499]
[Info] Cond. Prob: [0.11, 0.11, 0.09]
[Info] Error Prob: 0.001089

 88157/100000: episode: 12358, duration: 0.917s, episode steps: 5, steps per second: 5, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000825, mae: 0.014763, mean_q: 0.028442
 88167/100000: episode: 12359, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000449, mae: 0.010407, mean_q: 0.024374
 88177/100000: episode: 12360, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000784, mae: 0.014408, mean_q: 0.025291
 88187/100000: episode: 12361, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001774, mae: 0.021027, mean_q: 0.037975
 88197/100000: episode: 12362, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000913, mae: 0.015380, mean_q: 0.031942
 88207/100000: episode: 12363, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000898, mae: 0.014049, mean_q: 0.023122
 88217/100000: episode: 12364, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000538, mae: 0.012250, mean_q: 0.017353
 88227/100000: episode: 12365, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000599, mae: 0.010448, mean_q: 0.017146
 88237/100000: episode: 12366, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000525, mae: 0.013566, mean_q: 0.023942
 88247/100000: episode: 12367, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001457, mae: 0.017801, mean_q: 0.031367
 88257/100000: episode: 12368, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000725, mae: 0.014404, mean_q: 0.032939
 88267/100000: episode: 12369, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000798, mae: 0.014382, mean_q: 0.029640
 88277/100000: episode: 12370, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000602, mae: 0.011467, mean_q: 0.024498
 88287/100000: episode: 12371, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000891, mae: 0.012882, mean_q: 0.025175
 88297/100000: episode: 12372, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000726, mae: 0.013283, mean_q: 0.025332
 88307/100000: episode: 12373, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000557, mae: 0.013159, mean_q: 0.029614
 88317/100000: episode: 12374, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000991, mae: 0.014799, mean_q: 0.026592
 88327/100000: episode: 12375, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001435, mae: 0.017265, mean_q: 0.026393
 88337/100000: episode: 12376, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000711, mae: 0.014370, mean_q: 0.028985
 88347/100000: episode: 12377, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000814, mae: 0.013333, mean_q: 0.033717
 88357/100000: episode: 12378, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000807, mae: 0.013228, mean_q: 0.022263
 88367/100000: episode: 12379, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000821, mae: 0.014673, mean_q: 0.030827
 88377/100000: episode: 12380, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000609, mae: 0.012542, mean_q: 0.021938
 88387/100000: episode: 12381, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000725, mae: 0.013065, mean_q: 0.030739
 88397/100000: episode: 12382, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001349, mae: 0.016863, mean_q: 0.033291
 88407/100000: episode: 12383, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001160, mae: 0.013369, mean_q: 0.025002
 88417/100000: episode: 12384, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000593, mae: 0.012513, mean_q: 0.028780
 88427/100000: episode: 12385, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000619, mae: 0.011556, mean_q: 0.021032
 88437/100000: episode: 12386, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000559, mae: 0.013554, mean_q: 0.025521
 88447/100000: episode: 12387, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000995, mae: 0.015653, mean_q: 0.022490
 88457/100000: episode: 12388, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001188, mae: 0.014467, mean_q: 0.028743
 88467/100000: episode: 12389, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000994, mae: 0.016107, mean_q: 0.037571
 88477/100000: episode: 12390, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000580, mae: 0.012808, mean_q: 0.029554
 88487/100000: episode: 12391, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001108, mae: 0.017364, mean_q: 0.032266
 88497/100000: episode: 12392, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001056, mae: 0.014295, mean_q: 0.025782
 88507/100000: episode: 12393, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000590, mae: 0.013824, mean_q: 0.025778
 88517/100000: episode: 12394, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.002137, mae: 0.019053, mean_q: 0.033262
 88527/100000: episode: 12395, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000507, mae: 0.012312, mean_q: 0.024747
 88537/100000: episode: 12396, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000563, mae: 0.012021, mean_q: 0.018863
 88547/100000: episode: 12397, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000729, mae: 0.013016, mean_q: 0.020505
 88557/100000: episode: 12398, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001491, mae: 0.017312, mean_q: 0.031341
 88567/100000: episode: 12399, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001268, mae: 0.015775, mean_q: 0.032996
 88577/100000: episode: 12400, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001007, mae: 0.015405, mean_q: 0.024195
 88587/100000: episode: 12401, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000371, mae: 0.010746, mean_q: 0.017753
 88597/100000: episode: 12402, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000718, mae: 0.013834, mean_q: 0.030254
 88607/100000: episode: 12403, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001171, mae: 0.016177, mean_q: 0.032329
 88617/100000: episode: 12404, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001041, mae: 0.014114, mean_q: 0.029200
 88627/100000: episode: 12405, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000603, mae: 0.012085, mean_q: 0.021295
 88637/100000: episode: 12406, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000736, mae: 0.013309, mean_q: 0.024469
 88647/100000: episode: 12407, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000819, mae: 0.014909, mean_q: 0.028896
 88657/100000: episode: 12408, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001373, mae: 0.016674, mean_q: 0.029926
 88667/100000: episode: 12409, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001022, mae: 0.014846, mean_q: 0.034663
 88677/100000: episode: 12410, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001344, mae: 0.019610, mean_q: 0.028589
 88687/100000: episode: 12411, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000641, mae: 0.014194, mean_q: 0.018071
 88697/100000: episode: 12412, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001185, mae: 0.013683, mean_q: 0.019178
 88707/100000: episode: 12413, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001245, mae: 0.020300, mean_q: 0.040075
 88717/100000: episode: 12414, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001145, mae: 0.018805, mean_q: 0.039705
 88727/100000: episode: 12415, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000634, mae: 0.012604, mean_q: 0.024773
 88737/100000: episode: 12416, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001342, mae: 0.018248, mean_q: 0.035518
 88747/100000: episode: 12417, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001558, mae: 0.017851, mean_q: 0.037953
 88757/100000: episode: 12418, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000939, mae: 0.015049, mean_q: 0.023330
 88767/100000: episode: 12419, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000706, mae: 0.014030, mean_q: 0.026233
 88777/100000: episode: 12420, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000994, mae: 0.014671, mean_q: 0.029200
 88787/100000: episode: 12421, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001295, mae: 0.016867, mean_q: 0.033569
 88797/100000: episode: 12422, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000518, mae: 0.011935, mean_q: 0.023342
 88807/100000: episode: 12423, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000728, mae: 0.015957, mean_q: 0.029668
 88817/100000: episode: 12424, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002317, mae: 0.022793, mean_q: 0.045501
 88827/100000: episode: 12425, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000505, mae: 0.011162, mean_q: 0.020944
 88837/100000: episode: 12426, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001360, mae: 0.018548, mean_q: 0.041665
 88847/100000: episode: 12427, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001229, mae: 0.018336, mean_q: 0.038916
 88857/100000: episode: 12428, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001048, mae: 0.016171, mean_q: 0.023295
 88867/100000: episode: 12429, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000529, mae: 0.011440, mean_q: 0.021236
 88877/100000: episode: 12430, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000299, mae: 0.010379, mean_q: 0.020554
 88887/100000: episode: 12431, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000286, mae: 0.010977, mean_q: 0.019041
 88897/100000: episode: 12432, duration: 0.073s, episode steps: 10, steps per second: 138, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000576, mae: 0.012050, mean_q: 0.021998
 88907/100000: episode: 12433, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000691, mae: 0.014747, mean_q: 0.030588
 88917/100000: episode: 12434, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000669, mae: 0.015581, mean_q: 0.033029
 88927/100000: episode: 12435, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000864, mae: 0.013053, mean_q: 0.029025
 88937/100000: episode: 12436, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001403, mae: 0.017552, mean_q: 0.032624
 88947/100000: episode: 12437, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000510, mae: 0.012702, mean_q: 0.024234
 88957/100000: episode: 12438, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001624, mae: 0.017849, mean_q: 0.033910
 88967/100000: episode: 12439, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000800, mae: 0.015301, mean_q: 0.025926
 88977/100000: episode: 12440, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001172, mae: 0.016549, mean_q: 0.028378
 88987/100000: episode: 12441, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000706, mae: 0.013447, mean_q: 0.025809
 88997/100000: episode: 12442, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000950, mae: 0.017362, mean_q: 0.041588
 89007/100000: episode: 12443, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000180, mae: 0.009929, mean_q: 0.018666
 89017/100000: episode: 12444, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001261, mae: 0.017531, mean_q: 0.036828
 89027/100000: episode: 12445, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001402, mae: 0.015838, mean_q: 0.028230
 89037/100000: episode: 12446, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000933, mae: 0.014768, mean_q: 0.024681
 89047/100000: episode: 12447, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001010, mae: 0.015107, mean_q: 0.024883
 89057/100000: episode: 12448, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000683, mae: 0.011020, mean_q: 0.020736
 89067/100000: episode: 12449, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000424, mae: 0.010402, mean_q: 0.016054
 89077/100000: episode: 12450, duration: 0.055s, episode steps: 10, steps per second: 180, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000671, mae: 0.013202, mean_q: 0.022107
 89087/100000: episode: 12451, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000426, mae: 0.010893, mean_q: 0.023374
 89097/100000: episode: 12452, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001114, mae: 0.014175, mean_q: 0.024946
 89107/100000: episode: 12453, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000738, mae: 0.013625, mean_q: 0.023766
 89117/100000: episode: 12454, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001382, mae: 0.014593, mean_q: 0.026044
 89127/100000: episode: 12455, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000620, mae: 0.012758, mean_q: 0.017939
 89137/100000: episode: 12456, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000669, mae: 0.012502, mean_q: 0.015547
 89147/100000: episode: 12457, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001206, mae: 0.016242, mean_q: 0.024604
[Info] 1-TH LEVEL FOUND: 0.048736006021499634, Considering 19/100 traces
 89157/100000: episode: 12458, duration: 0.722s, episode steps: 10, steps per second: 14, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000406, mae: 0.012739, mean_q: 0.022986
 89160/100000: episode: 12459, duration: 0.028s, episode steps: 3, steps per second: 105, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001213, mae: 0.015496, mean_q: 0.033394
 89164/100000: episode: 12460, duration: 0.030s, episode steps: 4, steps per second: 134, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000491, mae: 0.010886, mean_q: 0.024807
 89170/100000: episode: 12461, duration: 0.041s, episode steps: 6, steps per second: 145, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000273, mae: 0.007966, mean_q: 0.018993
 89176/100000: episode: 12462, duration: 0.036s, episode steps: 6, steps per second: 167, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001281, mae: 0.013670, mean_q: 0.028095
 89182/100000: episode: 12463, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000884, mae: 0.012509, mean_q: 0.025472
 89185/100000: episode: 12464, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000513, mae: 0.013008, mean_q: 0.028760
 89191/100000: episode: 12465, duration: 0.033s, episode steps: 6, steps per second: 181, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001042, mae: 0.012893, mean_q: 0.022275
 89195/100000: episode: 12466, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000451, mae: 0.010615, mean_q: 0.019847
 89201/100000: episode: 12467, duration: 0.036s, episode steps: 6, steps per second: 166, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000996, mae: 0.014460, mean_q: 0.030690
 89207/100000: episode: 12468, duration: 0.042s, episode steps: 6, steps per second: 143, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000801, mae: 0.010711, mean_q: 0.018678
 89213/100000: episode: 12469, duration: 0.035s, episode steps: 6, steps per second: 173, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001197, mae: 0.014053, mean_q: 0.034544
 89217/100000: episode: 12470, duration: 0.027s, episode steps: 4, steps per second: 149, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000201, mae: 0.010041, mean_q: 0.021250
 89220/100000: episode: 12471, duration: 0.024s, episode steps: 3, steps per second: 125, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000166, mae: 0.009802, mean_q: 0.020163
 89226/100000: episode: 12472, duration: 0.037s, episode steps: 6, steps per second: 162, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000658, mae: 0.010521, mean_q: 0.021216
 89229/100000: episode: 12473, duration: 0.027s, episode steps: 3, steps per second: 113, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000262, mae: 0.012285, mean_q: 0.024360
 89232/100000: episode: 12474, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000223, mae: 0.011329, mean_q: 0.025112
 89235/100000: episode: 12475, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000119, mae: 0.008660, mean_q: 0.013001
 89238/100000: episode: 12476, duration: 0.020s, episode steps: 3, steps per second: 153, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001179, mae: 0.015334, mean_q: 0.021817
 89244/100000: episode: 12477, duration: 0.045s, episode steps: 6, steps per second: 134, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000644, mae: 0.010652, mean_q: 0.014429
 89247/100000: episode: 12478, duration: 0.021s, episode steps: 3, steps per second: 140, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001486, mae: 0.018141, mean_q: 0.035581
 89250/100000: episode: 12479, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000522, mae: 0.008880, mean_q: 0.014669
 89254/100000: episode: 12480, duration: 0.027s, episode steps: 4, steps per second: 151, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001137, mae: 0.013585, mean_q: 0.028192
 89257/100000: episode: 12481, duration: 0.019s, episode steps: 3, steps per second: 162, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000395, mae: 0.011689, mean_q: 0.024146
 89263/100000: episode: 12482, duration: 0.040s, episode steps: 6, steps per second: 149, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001187, mae: 0.014833, mean_q: 0.024016
 89266/100000: episode: 12483, duration: 0.024s, episode steps: 3, steps per second: 123, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000919, mae: 0.012242, mean_q: 0.021436
 89269/100000: episode: 12484, duration: 0.020s, episode steps: 3, steps per second: 150, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001665, mae: 0.013838, mean_q: 0.029451
 89272/100000: episode: 12485, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001469, mae: 0.017486, mean_q: 0.025717
 89275/100000: episode: 12486, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000796, mae: 0.009423, mean_q: 0.012089
 89281/100000: episode: 12487, duration: 0.032s, episode steps: 6, steps per second: 187, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001135, mae: 0.016820, mean_q: 0.027393
 89284/100000: episode: 12488, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000894, mae: 0.014412, mean_q: 0.025054
 89290/100000: episode: 12489, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000749, mae: 0.013775, mean_q: 0.028021
 89294/100000: episode: 12490, duration: 0.029s, episode steps: 4, steps per second: 138, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001075, mae: 0.016169, mean_q: 0.027649
 89297/100000: episode: 12491, duration: 0.027s, episode steps: 3, steps per second: 112, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000759, mae: 0.016984, mean_q: 0.032514
 89301/100000: episode: 12492, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001299, mae: 0.016929, mean_q: 0.029693
 89304/100000: episode: 12493, duration: 0.019s, episode steps: 3, steps per second: 162, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000319, mae: 0.010152, mean_q: 0.024811
 89310/100000: episode: 12494, duration: 0.031s, episode steps: 6, steps per second: 192, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000233, mae: 0.009249, mean_q: 0.014378
 89316/100000: episode: 12495, duration: 0.033s, episode steps: 6, steps per second: 184, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000141, mae: 0.008643, mean_q: 0.017542
 89319/100000: episode: 12496, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001026, mae: 0.015801, mean_q: 0.020272
 89323/100000: episode: 12497, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000837, mae: 0.013647, mean_q: 0.027047
 89326/100000: episode: 12498, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000810, mae: 0.013859, mean_q: 0.019248
 89329/100000: episode: 12499, duration: 0.025s, episode steps: 3, steps per second: 120, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000930, mae: 0.013301, mean_q: 0.021777
 89332/100000: episode: 12500, duration: 0.023s, episode steps: 3, steps per second: 131, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001232, mae: 0.014969, mean_q: 0.024364
 89335/100000: episode: 12501, duration: 0.025s, episode steps: 3, steps per second: 120, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000414, mae: 0.013555, mean_q: 0.025638
 89341/100000: episode: 12502, duration: 0.033s, episode steps: 6, steps per second: 180, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001614, mae: 0.017655, mean_q: 0.035224
 89345/100000: episode: 12503, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000837, mae: 0.012096, mean_q: 0.022278
 89349/100000: episode: 12504, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000290, mae: 0.009049, mean_q: 0.021126
 89353/100000: episode: 12505, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000772, mae: 0.014015, mean_q: 0.021201
 89356/100000: episode: 12506, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000718, mae: 0.010399, mean_q: 0.015319
 89359/100000: episode: 12507, duration: 0.019s, episode steps: 3, steps per second: 156, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001482, mae: 0.016840, mean_q: 0.027181
 89363/100000: episode: 12508, duration: 0.024s, episode steps: 4, steps per second: 167, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000966, mae: 0.015096, mean_q: 0.024459
 89366/100000: episode: 12509, duration: 0.019s, episode steps: 3, steps per second: 155, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000651, mae: 0.013655, mean_q: 0.031552
[Info] FALSIFICATION!
 89371/100000: episode: 12510, duration: 0.258s, episode steps: 5, steps per second: 19, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000616, mae: 0.014766, mean_q: 0.031915
 89377/100000: episode: 12511, duration: 0.045s, episode steps: 6, steps per second: 133, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001335, mae: 0.023643, mean_q: 0.049153
 89383/100000: episode: 12512, duration: 0.041s, episode steps: 6, steps per second: 146, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001024, mae: 0.013336, mean_q: 0.023377
 89389/100000: episode: 12513, duration: 0.032s, episode steps: 6, steps per second: 187, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000845, mae: 0.014917, mean_q: 0.030690
 89392/100000: episode: 12514, duration: 0.018s, episode steps: 3, steps per second: 162, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000659, mae: 0.013458, mean_q: 0.032740
 89396/100000: episode: 12515, duration: 0.026s, episode steps: 4, steps per second: 154, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000773, mae: 0.012609, mean_q: 0.034985
 89400/100000: episode: 12516, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001626, mae: 0.021134, mean_q: 0.055700
 89406/100000: episode: 12517, duration: 0.032s, episode steps: 6, steps per second: 186, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001840, mae: 0.018434, mean_q: 0.033113
 89409/100000: episode: 12518, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001965, mae: 0.021288, mean_q: 0.042854
 89412/100000: episode: 12519, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000755, mae: 0.011204, mean_q: 0.019778
 89415/100000: episode: 12520, duration: 0.020s, episode steps: 3, steps per second: 153, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001567, mae: 0.019698, mean_q: 0.045925
[Info] FALSIFICATION!
 89420/100000: episode: 12521, duration: 0.280s, episode steps: 5, steps per second: 18, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.001078, mae: 0.014543, mean_q: 0.022859
 89423/100000: episode: 12522, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000671, mae: 0.011195, mean_q: 0.019337
 89426/100000: episode: 12523, duration: 0.020s, episode steps: 3, steps per second: 150, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001532, mae: 0.019953, mean_q: 0.034851
 89430/100000: episode: 12524, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000199, mae: 0.009950, mean_q: 0.018782
 89433/100000: episode: 12525, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002078, mae: 0.018806, mean_q: 0.033160
 89439/100000: episode: 12526, duration: 0.035s, episode steps: 6, steps per second: 170, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000293, mae: 0.009683, mean_q: 0.015765
 89442/100000: episode: 12527, duration: 0.022s, episode steps: 3, steps per second: 135, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001136, mae: 0.013719, mean_q: 0.024816
 89446/100000: episode: 12528, duration: 0.025s, episode steps: 4, steps per second: 158, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000789, mae: 0.013869, mean_q: 0.026504
 89449/100000: episode: 12529, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001427, mae: 0.017084, mean_q: 0.027011
 89452/100000: episode: 12530, duration: 0.019s, episode steps: 3, steps per second: 156, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001317, mae: 0.018123, mean_q: 0.038105
 89458/100000: episode: 12531, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000264, mae: 0.012122, mean_q: 0.022434
 89462/100000: episode: 12532, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001303, mae: 0.019810, mean_q: 0.033943
 89468/100000: episode: 12533, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001276, mae: 0.018284, mean_q: 0.039216
 89471/100000: episode: 12534, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000356, mae: 0.011853, mean_q: 0.020410
 89474/100000: episode: 12535, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002147, mae: 0.017609, mean_q: 0.039407
 89477/100000: episode: 12536, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000673, mae: 0.015011, mean_q: 0.032218
 89481/100000: episode: 12537, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000224, mae: 0.008769, mean_q: 0.023313
 89487/100000: episode: 12538, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000332, mae: 0.010269, mean_q: 0.020138
[Info] Complete ISplit Iteration
[Info] Levels: [0.048736006, 1.2555218]
[Info] Cond. Prob: [0.19, 0.02]
[Info] Error Prob: 0.0038

 89493/100000: episode: 12539, duration: 0.839s, episode steps: 6, steps per second: 7, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000412, mae: 0.011268, mean_q: 0.029791
 89503/100000: episode: 12540, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001259, mae: 0.015289, mean_q: 0.028431
 89513/100000: episode: 12541, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000981, mae: 0.015418, mean_q: 0.025894
 89523/100000: episode: 12542, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.001021, mae: 0.015172, mean_q: 0.028132
 89533/100000: episode: 12543, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000903, mae: 0.016350, mean_q: 0.042002
 89543/100000: episode: 12544, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000682, mae: 0.013032, mean_q: 0.016963
 89553/100000: episode: 12545, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001288, mae: 0.018023, mean_q: 0.032179
 89563/100000: episode: 12546, duration: 0.103s, episode steps: 10, steps per second: 97, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000760, mae: 0.016719, mean_q: 0.043406
 89573/100000: episode: 12547, duration: 0.093s, episode steps: 10, steps per second: 108, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000489, mae: 0.012797, mean_q: 0.023556
 89583/100000: episode: 12548, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001522, mae: 0.018903, mean_q: 0.035729
 89593/100000: episode: 12549, duration: 0.115s, episode steps: 10, steps per second: 87, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001269, mae: 0.017309, mean_q: 0.029562
 89603/100000: episode: 12550, duration: 0.116s, episode steps: 10, steps per second: 86, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001643, mae: 0.018855, mean_q: 0.038109
 89613/100000: episode: 12551, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000861, mae: 0.014972, mean_q: 0.028645
 89623/100000: episode: 12552, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000993, mae: 0.014127, mean_q: 0.036387
 89633/100000: episode: 12553, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001584, mae: 0.018558, mean_q: 0.034590
 89643/100000: episode: 12554, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000846, mae: 0.015141, mean_q: 0.026308
 89653/100000: episode: 12555, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000769, mae: 0.016080, mean_q: 0.029778
 89663/100000: episode: 12556, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000299, mae: 0.009762, mean_q: 0.023087
 89673/100000: episode: 12557, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000762, mae: 0.012452, mean_q: 0.023884
 89683/100000: episode: 12558, duration: 0.088s, episode steps: 10, steps per second: 114, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000687, mae: 0.014368, mean_q: 0.025921
 89693/100000: episode: 12559, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001565, mae: 0.020540, mean_q: 0.038284
 89703/100000: episode: 12560, duration: 0.117s, episode steps: 10, steps per second: 85, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000404, mae: 0.012575, mean_q: 0.027544
 89713/100000: episode: 12561, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001739, mae: 0.021430, mean_q: 0.037302
 89723/100000: episode: 12562, duration: 0.108s, episode steps: 10, steps per second: 92, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002272, mae: 0.023054, mean_q: 0.038150
 89733/100000: episode: 12563, duration: 0.109s, episode steps: 10, steps per second: 92, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001119, mae: 0.016616, mean_q: 0.029347
 89743/100000: episode: 12564, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000567, mae: 0.010796, mean_q: 0.018777
 89753/100000: episode: 12565, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001644, mae: 0.019603, mean_q: 0.037979
 89763/100000: episode: 12566, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001087, mae: 0.014029, mean_q: 0.021369
 89773/100000: episode: 12567, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001061, mae: 0.014711, mean_q: 0.026344
 89783/100000: episode: 12568, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001041, mae: 0.016282, mean_q: 0.027089
 89793/100000: episode: 12569, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001380, mae: 0.016973, mean_q: 0.030648
 89803/100000: episode: 12570, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001148, mae: 0.015729, mean_q: 0.023663
 89813/100000: episode: 12571, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001876, mae: 0.019948, mean_q: 0.026855
 89823/100000: episode: 12572, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001099, mae: 0.019141, mean_q: 0.038452
 89833/100000: episode: 12573, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000608, mae: 0.016516, mean_q: 0.033715
 89843/100000: episode: 12574, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001085, mae: 0.014382, mean_q: 0.034277
 89853/100000: episode: 12575, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000423, mae: 0.010970, mean_q: 0.020155
 89863/100000: episode: 12576, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000718, mae: 0.012467, mean_q: 0.028537
 89873/100000: episode: 12577, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000518, mae: 0.012486, mean_q: 0.024573
 89883/100000: episode: 12578, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000592, mae: 0.013944, mean_q: 0.024651
 89893/100000: episode: 12579, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000595, mae: 0.014339, mean_q: 0.033053
 89903/100000: episode: 12580, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001763, mae: 0.019623, mean_q: 0.037423
 89913/100000: episode: 12581, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001356, mae: 0.018068, mean_q: 0.029887
 89923/100000: episode: 12582, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000474, mae: 0.012633, mean_q: 0.023082
 89933/100000: episode: 12583, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000755, mae: 0.016645, mean_q: 0.037511
 89943/100000: episode: 12584, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000453, mae: 0.011333, mean_q: 0.025705
 89953/100000: episode: 12585, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000728, mae: 0.012746, mean_q: 0.035272
 89963/100000: episode: 12586, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001885, mae: 0.017189, mean_q: 0.033658
 89973/100000: episode: 12587, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000689, mae: 0.011393, mean_q: 0.020939
 89983/100000: episode: 12588, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000893, mae: 0.015599, mean_q: 0.032812
 89993/100000: episode: 12589, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001239, mae: 0.017114, mean_q: 0.022997
 90003/100000: episode: 12590, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001112, mae: 0.015883, mean_q: 0.028611
 90013/100000: episode: 12591, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001174, mae: 0.017008, mean_q: 0.029668
 90023/100000: episode: 12592, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001143, mae: 0.012799, mean_q: 0.020483
 90033/100000: episode: 12593, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001279, mae: 0.016696, mean_q: 0.035882
 90043/100000: episode: 12594, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001201, mae: 0.016527, mean_q: 0.027653
 90053/100000: episode: 12595, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001018, mae: 0.017202, mean_q: 0.025683
 90063/100000: episode: 12596, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000736, mae: 0.013680, mean_q: 0.025699
 90073/100000: episode: 12597, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000912, mae: 0.015673, mean_q: 0.040455
 90083/100000: episode: 12598, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.001252, mae: 0.017806, mean_q: 0.033595
 90093/100000: episode: 12599, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000743, mae: 0.013159, mean_q: 0.029208
 90103/100000: episode: 12600, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000660, mae: 0.013926, mean_q: 0.028473
 90113/100000: episode: 12601, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001095, mae: 0.016890, mean_q: 0.032905
 90123/100000: episode: 12602, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001118, mae: 0.016267, mean_q: 0.029725
 90133/100000: episode: 12603, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001051, mae: 0.016284, mean_q: 0.018272
 90143/100000: episode: 12604, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000874, mae: 0.016607, mean_q: 0.025420
 90153/100000: episode: 12605, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001151, mae: 0.019444, mean_q: 0.035411
 90163/100000: episode: 12606, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000975, mae: 0.015649, mean_q: 0.029936
 90173/100000: episode: 12607, duration: 0.117s, episode steps: 10, steps per second: 86, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000964, mae: 0.015978, mean_q: 0.029124
 90183/100000: episode: 12608, duration: 0.107s, episode steps: 10, steps per second: 93, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000821, mae: 0.015129, mean_q: 0.025810
 90193/100000: episode: 12609, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000764, mae: 0.013309, mean_q: 0.029513
 90203/100000: episode: 12610, duration: 0.092s, episode steps: 10, steps per second: 108, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002366, mae: 0.022327, mean_q: 0.043881
 90213/100000: episode: 12611, duration: 0.117s, episode steps: 10, steps per second: 85, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001195, mae: 0.015692, mean_q: 0.033684
 90223/100000: episode: 12612, duration: 0.130s, episode steps: 10, steps per second: 77, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001980, mae: 0.021742, mean_q: 0.037545
 90233/100000: episode: 12613, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000626, mae: 0.015412, mean_q: 0.017344
 90243/100000: episode: 12614, duration: 0.093s, episode steps: 10, steps per second: 108, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001793, mae: 0.017648, mean_q: 0.023348
 90253/100000: episode: 12615, duration: 0.086s, episode steps: 10, steps per second: 117, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000728, mae: 0.016478, mean_q: 0.033493
 90263/100000: episode: 12616, duration: 0.092s, episode steps: 10, steps per second: 108, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000726, mae: 0.014615, mean_q: 0.028063
 90273/100000: episode: 12617, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001018, mae: 0.016417, mean_q: 0.033371
 90283/100000: episode: 12618, duration: 0.119s, episode steps: 10, steps per second: 84, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000755, mae: 0.012491, mean_q: 0.022282
 90293/100000: episode: 12619, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000761, mae: 0.014032, mean_q: 0.030225
 90303/100000: episode: 12620, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001085, mae: 0.014947, mean_q: 0.026307
 90313/100000: episode: 12621, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000443, mae: 0.011720, mean_q: 0.028064
 90323/100000: episode: 12622, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000784, mae: 0.012288, mean_q: 0.026596
 90333/100000: episode: 12623, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001034, mae: 0.014038, mean_q: 0.025028
 90343/100000: episode: 12624, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000671, mae: 0.014080, mean_q: 0.027685
 90353/100000: episode: 12625, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000603, mae: 0.012715, mean_q: 0.027237
 90363/100000: episode: 12626, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000410, mae: 0.011759, mean_q: 0.027361
 90373/100000: episode: 12627, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000915, mae: 0.012711, mean_q: 0.028094
 90383/100000: episode: 12628, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000311, mae: 0.009809, mean_q: 0.018777
 90393/100000: episode: 12629, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001181, mae: 0.016934, mean_q: 0.034859
 90403/100000: episode: 12630, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001144, mae: 0.014650, mean_q: 0.024626
 90413/100000: episode: 12631, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001248, mae: 0.016301, mean_q: 0.032937
 90423/100000: episode: 12632, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000841, mae: 0.013335, mean_q: 0.021932
 90433/100000: episode: 12633, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000769, mae: 0.013607, mean_q: 0.030136
 90443/100000: episode: 12634, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000689, mae: 0.015185, mean_q: 0.035273
 90453/100000: episode: 12635, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001333, mae: 0.013600, mean_q: 0.027543
 90463/100000: episode: 12636, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000708, mae: 0.014412, mean_q: 0.024354
 90473/100000: episode: 12637, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000776, mae: 0.011645, mean_q: 0.024931
 90483/100000: episode: 12638, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001288, mae: 0.016010, mean_q: 0.027734
[Info] 1-TH LEVEL FOUND: 0.04554564878344536, Considering 12/100 traces
 90493/100000: episode: 12639, duration: 0.860s, episode steps: 10, steps per second: 12, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001621, mae: 0.020217, mean_q: 0.046459
 90496/100000: episode: 12640, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000268, mae: 0.013416, mean_q: 0.035607
[Info] FALSIFICATION!
 90501/100000: episode: 12641, duration: 0.279s, episode steps: 5, steps per second: 18, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000716, mae: 0.012022, mean_q: 0.016873
 90504/100000: episode: 12642, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000768, mae: 0.013847, mean_q: 0.020503
 90507/100000: episode: 12643, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002042, mae: 0.017508, mean_q: 0.031599
 90513/100000: episode: 12644, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001720, mae: 0.018916, mean_q: 0.029200
 90516/100000: episode: 12645, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001400, mae: 0.015279, mean_q: 0.019382
 90522/100000: episode: 12646, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000225, mae: 0.008713, mean_q: 0.015998
 90528/100000: episode: 12647, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000252, mae: 0.009456, mean_q: 0.024555
 90531/100000: episode: 12648, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000604, mae: 0.010228, mean_q: 0.019190
 90537/100000: episode: 12649, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.001284, mae: 0.014978, mean_q: 0.026153
 90540/100000: episode: 12650, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002053, mae: 0.019184, mean_q: 0.034598
 90546/100000: episode: 12651, duration: 0.031s, episode steps: 6, steps per second: 193, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000450, mae: 0.009830, mean_q: 0.023771
 90549/100000: episode: 12652, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000492, mae: 0.011723, mean_q: 0.017292
 90552/100000: episode: 12653, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000725, mae: 0.010608, mean_q: 0.013139
 90555/100000: episode: 12654, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000407, mae: 0.008478, mean_q: 0.018847
 90561/100000: episode: 12655, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000338, mae: 0.011848, mean_q: 0.024534
 90564/100000: episode: 12656, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001033, mae: 0.015708, mean_q: 0.027431
 90567/100000: episode: 12657, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000104, mae: 0.006764, mean_q: 0.018702
 90570/100000: episode: 12658, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000392, mae: 0.010467, mean_q: 0.018267
 90573/100000: episode: 12659, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000096, mae: 0.006068, mean_q: 0.010971
[Info] FALSIFICATION!
 90578/100000: episode: 12660, duration: 0.277s, episode steps: 5, steps per second: 18, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000739, mae: 0.011750, mean_q: 0.018606
 90581/100000: episode: 12661, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001609, mae: 0.019674, mean_q: 0.031605
 90584/100000: episode: 12662, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000740, mae: 0.014657, mean_q: 0.027896
 90587/100000: episode: 12663, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000594, mae: 0.010294, mean_q: 0.018067
 90590/100000: episode: 12664, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001166, mae: 0.013878, mean_q: 0.029294
 90594/100000: episode: 12665, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000341, mae: 0.011465, mean_q: 0.027739
 90600/100000: episode: 12666, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000880, mae: 0.012665, mean_q: 0.025889
 90606/100000: episode: 12667, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001379, mae: 0.016381, mean_q: 0.027541
 90609/100000: episode: 12668, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002093, mae: 0.018174, mean_q: 0.039382
 90612/100000: episode: 12669, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000793, mae: 0.013046, mean_q: 0.019199
 90618/100000: episode: 12670, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001158, mae: 0.012649, mean_q: 0.023138
 90624/100000: episode: 12671, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001605, mae: 0.017602, mean_q: 0.031233
 90630/100000: episode: 12672, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000516, mae: 0.009200, mean_q: 0.018590
 90633/100000: episode: 12673, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000123, mae: 0.007564, mean_q: 0.013329
 90637/100000: episode: 12674, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000929, mae: 0.013698, mean_q: 0.032450
 90643/100000: episode: 12675, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000169, mae: 0.009264, mean_q: 0.021858
 90646/100000: episode: 12676, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001407, mae: 0.016748, mean_q: 0.033114
 90652/100000: episode: 12677, duration: 0.031s, episode steps: 6, steps per second: 191, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000463, mae: 0.011426, mean_q: 0.024125
 90655/100000: episode: 12678, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000641, mae: 0.010066, mean_q: 0.019298
 90658/100000: episode: 12679, duration: 0.019s, episode steps: 3, steps per second: 162, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001014, mae: 0.011956, mean_q: 0.023182
 90664/100000: episode: 12680, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000526, mae: 0.009274, mean_q: 0.020432
 90667/100000: episode: 12681, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001217, mae: 0.011828, mean_q: 0.020903
 90670/100000: episode: 12682, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001208, mae: 0.015689, mean_q: 0.027093
 90676/100000: episode: 12683, duration: 0.046s, episode steps: 6, steps per second: 131, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000109, mae: 0.005804, mean_q: 0.008455
 90682/100000: episode: 12684, duration: 0.033s, episode steps: 6, steps per second: 183, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001382, mae: 0.016550, mean_q: 0.023188
 90685/100000: episode: 12685, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000361, mae: 0.010633, mean_q: 0.023024
 90691/100000: episode: 12686, duration: 0.047s, episode steps: 6, steps per second: 126, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001151, mae: 0.012368, mean_q: 0.026477
 90697/100000: episode: 12687, duration: 0.049s, episode steps: 6, steps per second: 122, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000661, mae: 0.012086, mean_q: 0.017397
 90703/100000: episode: 12688, duration: 0.041s, episode steps: 6, steps per second: 148, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000467, mae: 0.009818, mean_q: 0.013392
 90706/100000: episode: 12689, duration: 0.022s, episode steps: 3, steps per second: 137, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000927, mae: 0.014383, mean_q: 0.019678
 90712/100000: episode: 12690, duration: 0.037s, episode steps: 6, steps per second: 164, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001497, mae: 0.016089, mean_q: 0.024543
 90718/100000: episode: 12691, duration: 0.036s, episode steps: 6, steps per second: 165, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000546, mae: 0.013192, mean_q: 0.021449
 90721/100000: episode: 12692, duration: 0.025s, episode steps: 3, steps per second: 119, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000927, mae: 0.014355, mean_q: 0.025124
 90727/100000: episode: 12693, duration: 0.037s, episode steps: 6, steps per second: 160, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000634, mae: 0.012951, mean_q: 0.024885
 90731/100000: episode: 12694, duration: 0.032s, episode steps: 4, steps per second: 123, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000727, mae: 0.011565, mean_q: 0.019977
 90734/100000: episode: 12695, duration: 0.023s, episode steps: 3, steps per second: 133, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000472, mae: 0.011260, mean_q: 0.023136
 90737/100000: episode: 12696, duration: 0.022s, episode steps: 3, steps per second: 136, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000119, mae: 0.007103, mean_q: 0.016633
 90740/100000: episode: 12697, duration: 0.022s, episode steps: 3, steps per second: 139, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000942, mae: 0.016172, mean_q: 0.034044
 90746/100000: episode: 12698, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000708, mae: 0.012308, mean_q: 0.028073
 90752/100000: episode: 12699, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000651, mae: 0.012994, mean_q: 0.023322
 90758/100000: episode: 12700, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001805, mae: 0.016766, mean_q: 0.031658
 90761/100000: episode: 12701, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000629, mae: 0.014142, mean_q: 0.036781
 90767/100000: episode: 12702, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001181, mae: 0.012859, mean_q: 0.021791
[Info] FALSIFICATION!
 90772/100000: episode: 12703, duration: 0.276s, episode steps: 5, steps per second: 18, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000968, mae: 0.014738, mean_q: 0.028994
 90775/100000: episode: 12704, duration: 0.019s, episode steps: 3, steps per second: 162, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000093, mae: 0.006746, mean_q: 0.012694
 90781/100000: episode: 12705, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000947, mae: 0.011305, mean_q: 0.022511
 90784/100000: episode: 12706, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000472, mae: 0.010304, mean_q: 0.023947
 90787/100000: episode: 12707, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000199, mae: 0.008015, mean_q: 0.012722
 90793/100000: episode: 12708, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000742, mae: 0.013121, mean_q: 0.023027
 90799/100000: episode: 12709, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001076, mae: 0.016247, mean_q: 0.042681
 90805/100000: episode: 12710, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000830, mae: 0.016165, mean_q: 0.029472
 90808/100000: episode: 12711, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001052, mae: 0.014835, mean_q: 0.032769
 90814/100000: episode: 12712, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.001005, mae: 0.013838, mean_q: 0.035860
 90820/100000: episode: 12713, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001222, mae: 0.017927, mean_q: 0.027154
 90823/100000: episode: 12714, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000332, mae: 0.010656, mean_q: 0.009848
 90829/100000: episode: 12715, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000584, mae: 0.011199, mean_q: 0.019485
 90835/100000: episode: 12716, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000853, mae: 0.012860, mean_q: 0.031744
 90841/100000: episode: 12717, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000957, mae: 0.015070, mean_q: 0.033585
 90847/100000: episode: 12718, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000998, mae: 0.015806, mean_q: 0.028827
 90850/100000: episode: 12719, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000500, mae: 0.013440, mean_q: 0.023416
 90853/100000: episode: 12720, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000305, mae: 0.008347, mean_q: 0.014571
 90857/100000: episode: 12721, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001097, mae: 0.015064, mean_q: 0.037742
 90863/100000: episode: 12722, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000259, mae: 0.009676, mean_q: 0.020623
 90866/100000: episode: 12723, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001761, mae: 0.013226, mean_q: 0.029863
 90872/100000: episode: 12724, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000944, mae: 0.011268, mean_q: 0.014363
 90875/100000: episode: 12725, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000147, mae: 0.008127, mean_q: 0.011968
 90878/100000: episode: 12726, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001231, mae: 0.014838, mean_q: 0.030526
[Info] Complete ISplit Iteration
[Info] Levels: [0.04554565, 1.2041354]
[Info] Cond. Prob: [0.12, 0.04]
[Info] Error Prob: 0.0048

 90884/100000: episode: 12727, duration: 0.850s, episode steps: 6, steps per second: 7, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000413, mae: 0.009538, mean_q: 0.014520
 90894/100000: episode: 12728, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000943, mae: 0.016821, mean_q: 0.028851
 90904/100000: episode: 12729, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000527, mae: 0.013376, mean_q: 0.028861
 90914/100000: episode: 12730, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000850, mae: 0.013029, mean_q: 0.021196
 90924/100000: episode: 12731, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000644, mae: 0.010600, mean_q: 0.016722
 90934/100000: episode: 12732, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000944, mae: 0.015507, mean_q: 0.026433
 90944/100000: episode: 12733, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001432, mae: 0.017119, mean_q: 0.026929
 90954/100000: episode: 12734, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001083, mae: 0.015434, mean_q: 0.029645
 90964/100000: episode: 12735, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001248, mae: 0.016618, mean_q: 0.032867
 90974/100000: episode: 12736, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000933, mae: 0.013251, mean_q: 0.024510
 90984/100000: episode: 12737, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000804, mae: 0.012700, mean_q: 0.016973
 90994/100000: episode: 12738, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000980, mae: 0.014474, mean_q: 0.026790
 91004/100000: episode: 12739, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000842, mae: 0.014570, mean_q: 0.028363
 91014/100000: episode: 12740, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001094, mae: 0.014365, mean_q: 0.031864
 91024/100000: episode: 12741, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001055, mae: 0.014693, mean_q: 0.020605
 91034/100000: episode: 12742, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000568, mae: 0.011950, mean_q: 0.019350
 91044/100000: episode: 12743, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000740, mae: 0.011560, mean_q: 0.017312
 91054/100000: episode: 12744, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000395, mae: 0.012293, mean_q: 0.018891
 91064/100000: episode: 12745, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001686, mae: 0.020468, mean_q: 0.030178
 91074/100000: episode: 12746, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001422, mae: 0.019186, mean_q: 0.036475
 91084/100000: episode: 12747, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000910, mae: 0.013487, mean_q: 0.023611
 91094/100000: episode: 12748, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000895, mae: 0.012287, mean_q: 0.026427
 91104/100000: episode: 12749, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001845, mae: 0.017054, mean_q: 0.024760
 91114/100000: episode: 12750, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001082, mae: 0.016391, mean_q: 0.030696
 91124/100000: episode: 12751, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001086, mae: 0.013587, mean_q: 0.021006
 91134/100000: episode: 12752, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000542, mae: 0.011640, mean_q: 0.014161
 91144/100000: episode: 12753, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000469, mae: 0.011856, mean_q: 0.021512
 91154/100000: episode: 12754, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000645, mae: 0.013383, mean_q: 0.023046
 91164/100000: episode: 12755, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000693, mae: 0.012299, mean_q: 0.022530
 91174/100000: episode: 12756, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001121, mae: 0.014956, mean_q: 0.026735
 91184/100000: episode: 12757, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001422, mae: 0.017220, mean_q: 0.031220
 91194/100000: episode: 12758, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000679, mae: 0.013617, mean_q: 0.025643
 91204/100000: episode: 12759, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000649, mae: 0.010319, mean_q: 0.017451
 91214/100000: episode: 12760, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000701, mae: 0.011292, mean_q: 0.024209
 91224/100000: episode: 12761, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001152, mae: 0.015252, mean_q: 0.026949
 91234/100000: episode: 12762, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001305, mae: 0.015876, mean_q: 0.028656
 91244/100000: episode: 12763, duration: 0.066s, episode steps: 10, steps per second: 153, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000564, mae: 0.012219, mean_q: 0.026918
 91254/100000: episode: 12764, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000880, mae: 0.013784, mean_q: 0.031965
 91264/100000: episode: 12765, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000785, mae: 0.011747, mean_q: 0.023900
 91274/100000: episode: 12766, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000780, mae: 0.012618, mean_q: 0.024463
 91284/100000: episode: 12767, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000470, mae: 0.012388, mean_q: 0.028852
 91294/100000: episode: 12768, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000594, mae: 0.011142, mean_q: 0.021106
 91304/100000: episode: 12769, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000901, mae: 0.014936, mean_q: 0.030106
 91314/100000: episode: 12770, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001089, mae: 0.015696, mean_q: 0.025647
 91324/100000: episode: 12771, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000818, mae: 0.013530, mean_q: 0.029019
 91334/100000: episode: 12772, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001190, mae: 0.015141, mean_q: 0.024637
 91344/100000: episode: 12773, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000601, mae: 0.012185, mean_q: 0.023834
 91354/100000: episode: 12774, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001169, mae: 0.015102, mean_q: 0.028062
 91364/100000: episode: 12775, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000693, mae: 0.013635, mean_q: 0.027622
 91374/100000: episode: 12776, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001493, mae: 0.018971, mean_q: 0.048316
 91384/100000: episode: 12777, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001700, mae: 0.016997, mean_q: 0.038624
 91394/100000: episode: 12778, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000988, mae: 0.016625, mean_q: 0.029337
 91404/100000: episode: 12779, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001064, mae: 0.015169, mean_q: 0.023574
 91414/100000: episode: 12780, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001207, mae: 0.012119, mean_q: 0.022641
 91424/100000: episode: 12781, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000565, mae: 0.011357, mean_q: 0.021879
 91434/100000: episode: 12782, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000623, mae: 0.012638, mean_q: 0.020957
 91444/100000: episode: 12783, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000623, mae: 0.012908, mean_q: 0.022046
 91454/100000: episode: 12784, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000692, mae: 0.012537, mean_q: 0.016468
 91464/100000: episode: 12785, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000532, mae: 0.013353, mean_q: 0.022900
 91474/100000: episode: 12786, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000754, mae: 0.013481, mean_q: 0.022585
 91484/100000: episode: 12787, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000699, mae: 0.013801, mean_q: 0.027713
 91494/100000: episode: 12788, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001069, mae: 0.011899, mean_q: 0.021837
 91504/100000: episode: 12789, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000646, mae: 0.012092, mean_q: 0.021717
 91514/100000: episode: 12790, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001076, mae: 0.016418, mean_q: 0.034233
 91524/100000: episode: 12791, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000764, mae: 0.014177, mean_q: 0.030259
 91534/100000: episode: 12792, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000691, mae: 0.012958, mean_q: 0.017102
 91544/100000: episode: 12793, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000620, mae: 0.013241, mean_q: 0.028527
 91554/100000: episode: 12794, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001428, mae: 0.016161, mean_q: 0.028565
 91564/100000: episode: 12795, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000772, mae: 0.011524, mean_q: 0.021884
 91574/100000: episode: 12796, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000353, mae: 0.010106, mean_q: 0.017198
 91584/100000: episode: 12797, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000806, mae: 0.013177, mean_q: 0.024930
 91594/100000: episode: 12798, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000428, mae: 0.011011, mean_q: 0.019557
 91604/100000: episode: 12799, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000808, mae: 0.012444, mean_q: 0.025082
 91614/100000: episode: 12800, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000899, mae: 0.010976, mean_q: 0.018918
 91624/100000: episode: 12801, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001216, mae: 0.016178, mean_q: 0.032769
 91634/100000: episode: 12802, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000975, mae: 0.015287, mean_q: 0.030737
 91644/100000: episode: 12803, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000668, mae: 0.011880, mean_q: 0.025090
 91654/100000: episode: 12804, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000647, mae: 0.013704, mean_q: 0.025673
 91664/100000: episode: 12805, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001116, mae: 0.016109, mean_q: 0.035239
 91674/100000: episode: 12806, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000903, mae: 0.014979, mean_q: 0.029451
 91684/100000: episode: 12807, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000779, mae: 0.013963, mean_q: 0.029543
 91694/100000: episode: 12808, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000965, mae: 0.014652, mean_q: 0.029625
 91704/100000: episode: 12809, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000403, mae: 0.010880, mean_q: 0.020925
 91714/100000: episode: 12810, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000948, mae: 0.015267, mean_q: 0.033795
 91724/100000: episode: 12811, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000530, mae: 0.012135, mean_q: 0.023063
 91734/100000: episode: 12812, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001005, mae: 0.015339, mean_q: 0.018666
 91744/100000: episode: 12813, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000713, mae: 0.011585, mean_q: 0.015988
 91754/100000: episode: 12814, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000607, mae: 0.014431, mean_q: 0.022752
 91764/100000: episode: 12815, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001089, mae: 0.018082, mean_q: 0.036598
 91774/100000: episode: 12816, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001018, mae: 0.014492, mean_q: 0.027921
 91784/100000: episode: 12817, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000738, mae: 0.011846, mean_q: 0.020329
 91794/100000: episode: 12818, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000837, mae: 0.011878, mean_q: 0.024937
 91804/100000: episode: 12819, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001042, mae: 0.015458, mean_q: 0.027980
 91814/100000: episode: 12820, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001482, mae: 0.018472, mean_q: 0.030761
 91824/100000: episode: 12821, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001023, mae: 0.017411, mean_q: 0.035010
 91834/100000: episode: 12822, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000662, mae: 0.012749, mean_q: 0.028909
 91844/100000: episode: 12823, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000761, mae: 0.013073, mean_q: 0.024763
 91854/100000: episode: 12824, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000947, mae: 0.014878, mean_q: 0.022284
 91864/100000: episode: 12825, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000678, mae: 0.013005, mean_q: 0.022296
 91874/100000: episode: 12826, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001167, mae: 0.016036, mean_q: 0.033200
[Info] 1-TH LEVEL FOUND: 0.03788965195417404, Considering 15/100 traces
 91884/100000: episode: 12827, duration: 0.770s, episode steps: 10, steps per second: 13, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001443, mae: 0.013556, mean_q: 0.020443
 91887/100000: episode: 12828, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000308, mae: 0.009710, mean_q: 0.016590
 91890/100000: episode: 12829, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000638, mae: 0.011827, mean_q: 0.017943
 91893/100000: episode: 12830, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000146, mae: 0.007720, mean_q: 0.020230
 91896/100000: episode: 12831, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001446, mae: 0.017554, mean_q: 0.041806
 91899/100000: episode: 12832, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000268, mae: 0.008400, mean_q: 0.015843
 91903/100000: episode: 12833, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000402, mae: 0.010443, mean_q: 0.024431
 91907/100000: episode: 12834, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000312, mae: 0.009459, mean_q: 0.016005
 91911/100000: episode: 12835, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000305, mae: 0.008740, mean_q: 0.023380
 91914/100000: episode: 12836, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000326, mae: 0.008509, mean_q: 0.015670
 91917/100000: episode: 12837, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001604, mae: 0.015302, mean_q: 0.026711
 91921/100000: episode: 12838, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000990, mae: 0.015192, mean_q: 0.031330
 91924/100000: episode: 12839, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000313, mae: 0.009092, mean_q: 0.023640
 91928/100000: episode: 12840, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001330, mae: 0.016180, mean_q: 0.021144
 91931/100000: episode: 12841, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001107, mae: 0.015988, mean_q: 0.022041
 91937/100000: episode: 12842, duration: 0.034s, episode steps: 6, steps per second: 178, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001516, mae: 0.020739, mean_q: 0.036137
 91941/100000: episode: 12843, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000131, mae: 0.008197, mean_q: 0.015228
 91945/100000: episode: 12844, duration: 0.026s, episode steps: 4, steps per second: 153, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001816, mae: 0.018398, mean_q: 0.029110
 91949/100000: episode: 12845, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001790, mae: 0.017663, mean_q: 0.028280
 91952/100000: episode: 12846, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000409, mae: 0.013426, mean_q: 0.020866
 91955/100000: episode: 12847, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000080, mae: 0.007598, mean_q: 0.010093
 91958/100000: episode: 12848, duration: 0.020s, episode steps: 3, steps per second: 149, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000592, mae: 0.012486, mean_q: 0.029345
 91964/100000: episode: 12849, duration: 0.032s, episode steps: 6, steps per second: 187, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000757, mae: 0.015170, mean_q: 0.024523
 91967/100000: episode: 12850, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000584, mae: 0.014460, mean_q: 0.023359
 91970/100000: episode: 12851, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001262, mae: 0.018907, mean_q: 0.038354
 91974/100000: episode: 12852, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000961, mae: 0.015157, mean_q: 0.024988
 91978/100000: episode: 12853, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000862, mae: 0.013762, mean_q: 0.028260
 91981/100000: episode: 12854, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001632, mae: 0.018852, mean_q: 0.029491
 91984/100000: episode: 12855, duration: 0.020s, episode steps: 3, steps per second: 150, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001944, mae: 0.019074, mean_q: 0.036199
 91987/100000: episode: 12856, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000471, mae: 0.011157, mean_q: 0.020443
 91991/100000: episode: 12857, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000718, mae: 0.011985, mean_q: 0.024144
 91995/100000: episode: 12858, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000284, mae: 0.009720, mean_q: 0.021242
 91999/100000: episode: 12859, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001505, mae: 0.018464, mean_q: 0.033083
 92002/100000: episode: 12860, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001425, mae: 0.016971, mean_q: 0.032185
 92005/100000: episode: 12861, duration: 0.019s, episode steps: 3, steps per second: 155, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001875, mae: 0.016856, mean_q: 0.035761
 92008/100000: episode: 12862, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000719, mae: 0.013387, mean_q: 0.040056
 92011/100000: episode: 12863, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000516, mae: 0.011055, mean_q: 0.022524
 92014/100000: episode: 12864, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000577, mae: 0.012127, mean_q: 0.034190
 92017/100000: episode: 12865, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001340, mae: 0.015222, mean_q: 0.033335
 92021/100000: episode: 12866, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000371, mae: 0.011092, mean_q: 0.020916
 92024/100000: episode: 12867, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000316, mae: 0.009211, mean_q: 0.021830
 92030/100000: episode: 12868, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000345, mae: 0.007633, mean_q: 0.014273
 92034/100000: episode: 12869, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001054, mae: 0.011500, mean_q: 0.019311
 92038/100000: episode: 12870, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000225, mae: 0.007537, mean_q: 0.011744
 92041/100000: episode: 12871, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001383, mae: 0.015895, mean_q: 0.036687
 92045/100000: episode: 12872, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001436, mae: 0.017349, mean_q: 0.030192
 92048/100000: episode: 12873, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000549, mae: 0.011422, mean_q: 0.028303
 92052/100000: episode: 12874, duration: 0.026s, episode steps: 4, steps per second: 155, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000633, mae: 0.012715, mean_q: 0.024165
 92055/100000: episode: 12875, duration: 0.021s, episode steps: 3, steps per second: 146, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000956, mae: 0.012763, mean_q: 0.023754
 92058/100000: episode: 12876, duration: 0.020s, episode steps: 3, steps per second: 147, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000390, mae: 0.011556, mean_q: 0.022507
 92062/100000: episode: 12877, duration: 0.027s, episode steps: 4, steps per second: 150, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000501, mae: 0.012800, mean_q: 0.021973
 92065/100000: episode: 12878, duration: 0.021s, episode steps: 3, steps per second: 145, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001000, mae: 0.016436, mean_q: 0.027977
 92068/100000: episode: 12879, duration: 0.021s, episode steps: 3, steps per second: 144, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000351, mae: 0.009521, mean_q: 0.029878
 92072/100000: episode: 12880, duration: 0.025s, episode steps: 4, steps per second: 161, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000508, mae: 0.009837, mean_q: 0.017420
 92075/100000: episode: 12881, duration: 0.021s, episode steps: 3, steps per second: 141, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000183, mae: 0.009757, mean_q: 0.021530
 92078/100000: episode: 12882, duration: 0.021s, episode steps: 3, steps per second: 142, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000711, mae: 0.012355, mean_q: 0.025144
 92081/100000: episode: 12883, duration: 0.020s, episode steps: 3, steps per second: 151, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000518, mae: 0.009989, mean_q: 0.021490
 92084/100000: episode: 12884, duration: 0.021s, episode steps: 3, steps per second: 141, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000610, mae: 0.013810, mean_q: 0.028442
 92087/100000: episode: 12885, duration: 0.023s, episode steps: 3, steps per second: 129, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000489, mae: 0.013003, mean_q: 0.022972
 92090/100000: episode: 12886, duration: 0.020s, episode steps: 3, steps per second: 147, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001376, mae: 0.013550, mean_q: 0.023087
 92093/100000: episode: 12887, duration: 0.021s, episode steps: 3, steps per second: 143, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000325, mae: 0.010120, mean_q: 0.017000
 92099/100000: episode: 12888, duration: 0.038s, episode steps: 6, steps per second: 158, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000843, mae: 0.015436, mean_q: 0.025944
 92105/100000: episode: 12889, duration: 0.036s, episode steps: 6, steps per second: 165, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000948, mae: 0.013382, mean_q: 0.025235
 92109/100000: episode: 12890, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001367, mae: 0.016048, mean_q: 0.026650
 92113/100000: episode: 12891, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001128, mae: 0.012101, mean_q: 0.026743
 92119/100000: episode: 12892, duration: 0.033s, episode steps: 6, steps per second: 182, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000903, mae: 0.013916, mean_q: 0.024400
 92125/100000: episode: 12893, duration: 0.028s, episode steps: 6, steps per second: 211, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000301, mae: 0.009623, mean_q: 0.015206
 92128/100000: episode: 12894, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001429, mae: 0.012502, mean_q: 0.018093
 92131/100000: episode: 12895, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000200, mae: 0.007900, mean_q: 0.012482
 92134/100000: episode: 12896, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000854, mae: 0.011064, mean_q: 0.015999
 92137/100000: episode: 12897, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001287, mae: 0.013892, mean_q: 0.018003
 92140/100000: episode: 12898, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000665, mae: 0.013462, mean_q: 0.031102
 92144/100000: episode: 12899, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000199, mae: 0.009625, mean_q: 0.016116
 92147/100000: episode: 12900, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000722, mae: 0.013885, mean_q: 0.021570
 92150/100000: episode: 12901, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000063, mae: 0.008029, mean_q: 0.017595
 92153/100000: episode: 12902, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000558, mae: 0.015098, mean_q: 0.034876
 92156/100000: episode: 12903, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000142, mae: 0.008364, mean_q: 0.014441
 92162/100000: episode: 12904, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000204, mae: 0.008716, mean_q: 0.019653
 92166/100000: episode: 12905, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001565, mae: 0.015818, mean_q: 0.025650
 92169/100000: episode: 12906, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000247, mae: 0.007725, mean_q: 0.018485
 92175/100000: episode: 12907, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001142, mae: 0.012315, mean_q: 0.016613
 92178/100000: episode: 12908, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001587, mae: 0.018924, mean_q: 0.038967
 92181/100000: episode: 12909, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000254, mae: 0.009361, mean_q: 0.024055
 92184/100000: episode: 12910, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001158, mae: 0.016459, mean_q: 0.026382
 92188/100000: episode: 12911, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000550, mae: 0.011553, mean_q: 0.020366
[Info] 2-TH LEVEL FOUND: 0.07581567019224167, Considering 39/100 traces
 92192/100000: episode: 12912, duration: 0.821s, episode steps: 4, steps per second: 5, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000670, mae: 0.014817, mean_q: 0.040504
 92196/100000: episode: 12913, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001188, mae: 0.014611, mean_q: 0.027788
 92200/100000: episode: 12914, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000133, mae: 0.006645, mean_q: 0.012555
 92204/100000: episode: 12915, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000304, mae: 0.009235, mean_q: 0.021711
 92208/100000: episode: 12916, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000715, mae: 0.013706, mean_q: 0.023555
 92212/100000: episode: 12917, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000176, mae: 0.007485, mean_q: 0.015160
 92216/100000: episode: 12918, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001104, mae: 0.012460, mean_q: 0.022487
 92220/100000: episode: 12919, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001887, mae: 0.018479, mean_q: 0.043268
 92224/100000: episode: 12920, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000187, mae: 0.008352, mean_q: 0.015270
 92228/100000: episode: 12921, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001798, mae: 0.015948, mean_q: 0.033142
 92232/100000: episode: 12922, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000117, mae: 0.007009, mean_q: 0.011798
 92236/100000: episode: 12923, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001007, mae: 0.012412, mean_q: 0.018831
 92240/100000: episode: 12924, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000321, mae: 0.011402, mean_q: 0.036580
 92245/100000: episode: 12925, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000113, mae: 0.007101, mean_q: 0.014023
 92249/100000: episode: 12926, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000092, mae: 0.006188, mean_q: 0.010838
 92253/100000: episode: 12927, duration: 0.029s, episode steps: 4, steps per second: 138, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000131, mae: 0.008070, mean_q: 0.014759
 92257/100000: episode: 12928, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000122, mae: 0.007651, mean_q: 0.015143
 92261/100000: episode: 12929, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000552, mae: 0.011069, mean_q: 0.016685
 92266/100000: episode: 12930, duration: 0.032s, episode steps: 5, steps per second: 158, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000586, mae: 0.011448, mean_q: 0.019554
 92270/100000: episode: 12931, duration: 0.028s, episode steps: 4, steps per second: 141, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000152, mae: 0.010008, mean_q: 0.021569
 92275/100000: episode: 12932, duration: 0.033s, episode steps: 5, steps per second: 150, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000317, mae: 0.013323, mean_q: 0.026077
 92279/100000: episode: 12933, duration: 0.026s, episode steps: 4, steps per second: 153, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000384, mae: 0.010699, mean_q: 0.020384
 92284/100000: episode: 12934, duration: 0.031s, episode steps: 5, steps per second: 163, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000921, mae: 0.014088, mean_q: 0.018458
 92288/100000: episode: 12935, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001251, mae: 0.017519, mean_q: 0.028571
 92292/100000: episode: 12936, duration: 0.023s, episode steps: 4, steps per second: 170, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000892, mae: 0.015586, mean_q: 0.025524
 92296/100000: episode: 12937, duration: 0.026s, episode steps: 4, steps per second: 152, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000547, mae: 0.011228, mean_q: 0.027016
 92300/100000: episode: 12938, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000193, mae: 0.009206, mean_q: 0.016900
 92304/100000: episode: 12939, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001307, mae: 0.015018, mean_q: 0.023539
 92309/100000: episode: 12940, duration: 0.030s, episode steps: 5, steps per second: 167, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000361, mae: 0.011931, mean_q: 0.021690
 92314/100000: episode: 12941, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000829, mae: 0.013634, mean_q: 0.023386
 92318/100000: episode: 12942, duration: 0.026s, episode steps: 4, steps per second: 152, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001283, mae: 0.011474, mean_q: 0.018093
 92322/100000: episode: 12943, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000459, mae: 0.010292, mean_q: 0.021448
 92327/100000: episode: 12944, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000222, mae: 0.010195, mean_q: 0.017760
 92331/100000: episode: 12945, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000332, mae: 0.007985, mean_q: 0.015510
 92335/100000: episode: 12946, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000134, mae: 0.007135, mean_q: 0.013106
 92339/100000: episode: 12947, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000993, mae: 0.009735, mean_q: 0.015243
 92343/100000: episode: 12948, duration: 0.024s, episode steps: 4, steps per second: 167, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000817, mae: 0.011116, mean_q: 0.014271
 92347/100000: episode: 12949, duration: 0.030s, episode steps: 4, steps per second: 134, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001172, mae: 0.016211, mean_q: 0.022185
 92352/100000: episode: 12950, duration: 0.032s, episode steps: 5, steps per second: 156, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000842, mae: 0.012958, mean_q: 0.017219
 92356/100000: episode: 12951, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000369, mae: 0.009282, mean_q: 0.013116
 92360/100000: episode: 12952, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000164, mae: 0.008640, mean_q: 0.013198
 92364/100000: episode: 12953, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000157, mae: 0.009921, mean_q: 0.018571
 92368/100000: episode: 12954, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001559, mae: 0.018811, mean_q: 0.035957
 92372/100000: episode: 12955, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000321, mae: 0.011274, mean_q: 0.019628
 92376/100000: episode: 12956, duration: 0.024s, episode steps: 4, steps per second: 170, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001224, mae: 0.017765, mean_q: 0.038442
 92381/100000: episode: 12957, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001124, mae: 0.013330, mean_q: 0.022559
 92385/100000: episode: 12958, duration: 0.027s, episode steps: 4, steps per second: 148, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000162, mae: 0.009726, mean_q: 0.018890
 92389/100000: episode: 12959, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000290, mae: 0.011288, mean_q: 0.018763
 92394/100000: episode: 12960, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000780, mae: 0.013771, mean_q: 0.025642
 92398/100000: episode: 12961, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001015, mae: 0.011575, mean_q: 0.017434
[Info] FALSIFICATION!
 92402/100000: episode: 12962, duration: 0.301s, episode steps: 4, steps per second: 13, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000453, mae: 0.012441, mean_q: 0.016838
 92406/100000: episode: 12963, duration: 0.028s, episode steps: 4, steps per second: 143, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000236, mae: 0.010746, mean_q: 0.013506
 92410/100000: episode: 12964, duration: 0.026s, episode steps: 4, steps per second: 154, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000688, mae: 0.011403, mean_q: 0.012316
 92414/100000: episode: 12965, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000103, mae: 0.006956, mean_q: 0.007339
 92418/100000: episode: 12966, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003876, mae: 0.024513, mean_q: 0.030134
 92422/100000: episode: 12967, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000110, mae: 0.007494, mean_q: 0.013089
 92426/100000: episode: 12968, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000898, mae: 0.012989, mean_q: 0.023859
 92430/100000: episode: 12969, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000420, mae: 0.011652, mean_q: 0.022189
 92435/100000: episode: 12970, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000469, mae: 0.011078, mean_q: 0.020438
 92439/100000: episode: 12971, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000209, mae: 0.007709, mean_q: 0.018845
 92443/100000: episode: 12972, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000122, mae: 0.007812, mean_q: 0.009331
[Info] Complete ISplit Iteration
[Info] Levels: [0.037889652, 0.07581567, 1.2358185]
[Info] Cond. Prob: [0.15, 0.39, 0.01]
[Info] Error Prob: 0.000585

 92447/100000: episode: 12973, duration: 0.919s, episode steps: 4, steps per second: 4, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002149, mae: 0.016266, mean_q: 0.020823
 92457/100000: episode: 12974, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000479, mae: 0.008742, mean_q: 0.009929
 92467/100000: episode: 12975, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000511, mae: 0.010408, mean_q: 0.016689
 92477/100000: episode: 12976, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000502, mae: 0.013067, mean_q: 0.023168
 92487/100000: episode: 12977, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000916, mae: 0.012959, mean_q: 0.025341
 92497/100000: episode: 12978, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000066, mae: 0.004840, mean_q: 0.008880
 92507/100000: episode: 12979, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000612, mae: 0.009953, mean_q: 0.018718
 92517/100000: episode: 12980, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000891, mae: 0.012730, mean_q: 0.019142
 92527/100000: episode: 12981, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000405, mae: 0.008872, mean_q: 0.012137
 92537/100000: episode: 12982, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000316, mae: 0.008516, mean_q: 0.013748
 92547/100000: episode: 12983, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000298, mae: 0.009436, mean_q: 0.013852
 92557/100000: episode: 12984, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000171, mae: 0.008720, mean_q: 0.015608
 92567/100000: episode: 12985, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000644, mae: 0.010581, mean_q: 0.020889
 92577/100000: episode: 12986, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000505, mae: 0.009762, mean_q: 0.018078
 92587/100000: episode: 12987, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000204, mae: 0.006998, mean_q: 0.012574
 92597/100000: episode: 12988, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000790, mae: 0.011031, mean_q: 0.017396
 92607/100000: episode: 12989, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000480, mae: 0.009128, mean_q: 0.019799
 92617/100000: episode: 12990, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000309, mae: 0.008580, mean_q: 0.016313
 92627/100000: episode: 12991, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000440, mae: 0.007491, mean_q: 0.011697
 92637/100000: episode: 12992, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000237, mae: 0.008137, mean_q: 0.017318
 92647/100000: episode: 12993, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000389, mae: 0.007569, mean_q: 0.013931
 92657/100000: episode: 12994, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000859, mae: 0.011508, mean_q: 0.017085
 92667/100000: episode: 12995, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000550, mae: 0.009003, mean_q: 0.016393
 92677/100000: episode: 12996, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000443, mae: 0.010006, mean_q: 0.017629
 92687/100000: episode: 12997, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000754, mae: 0.011860, mean_q: 0.028345
 92697/100000: episode: 12998, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000109, mae: 0.006323, mean_q: 0.015122
 92707/100000: episode: 12999, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000328, mae: 0.008466, mean_q: 0.017862
 92717/100000: episode: 13000, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000305, mae: 0.008724, mean_q: 0.015917
 92727/100000: episode: 13001, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000712, mae: 0.010324, mean_q: 0.018523
 92737/100000: episode: 13002, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000678, mae: 0.011865, mean_q: 0.023122
 92747/100000: episode: 13003, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000596, mae: 0.009521, mean_q: 0.016636
 92757/100000: episode: 13004, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000157, mae: 0.007198, mean_q: 0.014629
 92767/100000: episode: 13005, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000916, mae: 0.011217, mean_q: 0.016608
 92777/100000: episode: 13006, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000339, mae: 0.009474, mean_q: 0.010559
 92787/100000: episode: 13007, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000473, mae: 0.011071, mean_q: 0.017388
 92797/100000: episode: 13008, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000393, mae: 0.010538, mean_q: 0.018711
 92807/100000: episode: 13009, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000511, mae: 0.009966, mean_q: 0.016507
 92817/100000: episode: 13010, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000363, mae: 0.008773, mean_q: 0.017290
 92827/100000: episode: 13011, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000601, mae: 0.009562, mean_q: 0.020855
 92837/100000: episode: 13012, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000557, mae: 0.009814, mean_q: 0.020958
 92847/100000: episode: 13013, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000999, mae: 0.009722, mean_q: 0.013828
 92857/100000: episode: 13014, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000719, mae: 0.009309, mean_q: 0.009967
 92867/100000: episode: 13015, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000256, mae: 0.009168, mean_q: 0.020159
 92877/100000: episode: 13016, duration: 0.054s, episode steps: 10, steps per second: 183, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000293, mae: 0.007861, mean_q: 0.013732
 92887/100000: episode: 13017, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000463, mae: 0.009569, mean_q: 0.015390
 92897/100000: episode: 13018, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000489, mae: 0.010651, mean_q: 0.018214
 92907/100000: episode: 13019, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000713, mae: 0.012009, mean_q: 0.026638
 92917/100000: episode: 13020, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000292, mae: 0.008425, mean_q: 0.016153
 92927/100000: episode: 13021, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000410, mae: 0.009376, mean_q: 0.021370
 92937/100000: episode: 13022, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000753, mae: 0.008773, mean_q: 0.021855
 92947/100000: episode: 13023, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000518, mae: 0.009406, mean_q: 0.014994
 92957/100000: episode: 13024, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000087, mae: 0.005284, mean_q: 0.008986
 92967/100000: episode: 13025, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000332, mae: 0.008656, mean_q: 0.013349
 92977/100000: episode: 13026, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000093, mae: 0.006659, mean_q: 0.011490
 92987/100000: episode: 13027, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000956, mae: 0.011030, mean_q: 0.020277
 92997/100000: episode: 13028, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000713, mae: 0.008853, mean_q: 0.014840
 93007/100000: episode: 13029, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000358, mae: 0.008219, mean_q: 0.013011
 93017/100000: episode: 13030, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000343, mae: 0.007501, mean_q: 0.011226
 93027/100000: episode: 13031, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000743, mae: 0.010307, mean_q: 0.016530
 93037/100000: episode: 13032, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000684, mae: 0.010075, mean_q: 0.015983
 93047/100000: episode: 13033, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000342, mae: 0.009201, mean_q: 0.012926
 93057/100000: episode: 13034, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000467, mae: 0.011786, mean_q: 0.018057
 93067/100000: episode: 13035, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000533, mae: 0.011155, mean_q: 0.020996
 93077/100000: episode: 13036, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000151, mae: 0.008674, mean_q: 0.014989
 93087/100000: episode: 13037, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000359, mae: 0.009818, mean_q: 0.016006
 93097/100000: episode: 13038, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000541, mae: 0.009097, mean_q: 0.017974
 93107/100000: episode: 13039, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000732, mae: 0.011056, mean_q: 0.017575
 93117/100000: episode: 13040, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000734, mae: 0.011063, mean_q: 0.020632
 93127/100000: episode: 13041, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000520, mae: 0.009329, mean_q: 0.015267
 93137/100000: episode: 13042, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000224, mae: 0.007149, mean_q: 0.010744
 93147/100000: episode: 13043, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000162, mae: 0.007612, mean_q: 0.015204
 93157/100000: episode: 13044, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000320, mae: 0.009029, mean_q: 0.015413
 93167/100000: episode: 13045, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000109, mae: 0.007068, mean_q: 0.012905
 93177/100000: episode: 13046, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000290, mae: 0.007451, mean_q: 0.014406
 93187/100000: episode: 13047, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000736, mae: 0.012167, mean_q: 0.023446
 93197/100000: episode: 13048, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000548, mae: 0.008845, mean_q: 0.018599
 93207/100000: episode: 13049, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000579, mae: 0.010040, mean_q: 0.021358
 93217/100000: episode: 13050, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000131, mae: 0.007028, mean_q: 0.018247
 93227/100000: episode: 13051, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000280, mae: 0.008100, mean_q: 0.013416
 93237/100000: episode: 13052, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000087, mae: 0.005727, mean_q: 0.011593
 93247/100000: episode: 13053, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000306, mae: 0.009470, mean_q: 0.017053
 93257/100000: episode: 13054, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000338, mae: 0.008377, mean_q: 0.016884
 93267/100000: episode: 13055, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000310, mae: 0.007522, mean_q: 0.013459
 93277/100000: episode: 13056, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000228, mae: 0.007688, mean_q: 0.014879
 93287/100000: episode: 13057, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000265, mae: 0.008112, mean_q: 0.017108
 93297/100000: episode: 13058, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000696, mae: 0.008764, mean_q: 0.019101
 93307/100000: episode: 13059, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000506, mae: 0.009604, mean_q: 0.021559
 93317/100000: episode: 13060, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000549, mae: 0.009270, mean_q: 0.022054
 93327/100000: episode: 13061, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000092, mae: 0.005933, mean_q: 0.010866
 93337/100000: episode: 13062, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000332, mae: 0.007962, mean_q: 0.014592
 93347/100000: episode: 13063, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000199, mae: 0.007218, mean_q: 0.012532
 93357/100000: episode: 13064, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000187, mae: 0.007124, mean_q: 0.014560
 93367/100000: episode: 13065, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.001442, mae: 0.014441, mean_q: 0.021954
 93377/100000: episode: 13066, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000327, mae: 0.007418, mean_q: 0.014713
 93387/100000: episode: 13067, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000238, mae: 0.008845, mean_q: 0.018854
 93397/100000: episode: 13068, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000651, mae: 0.010392, mean_q: 0.023623
 93407/100000: episode: 13069, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000451, mae: 0.008795, mean_q: 0.012635
 93417/100000: episode: 13070, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000439, mae: 0.010278, mean_q: 0.016139
 93427/100000: episode: 13071, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000822, mae: 0.011408, mean_q: 0.021741
 93437/100000: episode: 13072, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000792, mae: 0.011161, mean_q: 0.024019
[Info] 1-TH LEVEL FOUND: 0.017508212476968765, Considering 14/100 traces
 93447/100000: episode: 13073, duration: 0.711s, episode steps: 10, steps per second: 14, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000450, mae: 0.007755, mean_q: 0.012855
 93451/100000: episode: 13074, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000294, mae: 0.007983, mean_q: 0.021551
 93454/100000: episode: 13075, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000067, mae: 0.005162, mean_q: 0.006850
 93458/100000: episode: 13076, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000839, mae: 0.013030, mean_q: 0.026897
 93464/100000: episode: 13077, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000812, mae: 0.011914, mean_q: 0.023436
 93467/100000: episode: 13078, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000130, mae: 0.007657, mean_q: 0.013062
 93470/100000: episode: 13079, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000088, mae: 0.005633, mean_q: 0.011335
 93474/100000: episode: 13080, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001596, mae: 0.013292, mean_q: 0.020501
 93480/100000: episode: 13081, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000516, mae: 0.008520, mean_q: 0.009496
 93486/100000: episode: 13082, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000144, mae: 0.008977, mean_q: 0.007715
 93489/100000: episode: 13083, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000141, mae: 0.008267, mean_q: 0.011610
 93492/100000: episode: 13084, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000986, mae: 0.011413, mean_q: 0.014057
 93495/100000: episode: 13085, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000672, mae: 0.012363, mean_q: 0.021916
 93501/100000: episode: 13086, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000518, mae: 0.013077, mean_q: 0.021551
 93507/100000: episode: 13087, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000749, mae: 0.012902, mean_q: 0.020565
 93513/100000: episode: 13088, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000266, mae: 0.007983, mean_q: 0.016608
 93517/100000: episode: 13089, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002266, mae: 0.020863, mean_q: 0.034126
 93523/100000: episode: 13090, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000618, mae: 0.010067, mean_q: 0.024521
 93527/100000: episode: 13091, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000155, mae: 0.008123, mean_q: 0.022428
 93530/100000: episode: 13092, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000391, mae: 0.009720, mean_q: 0.016085
 93534/100000: episode: 13093, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000113, mae: 0.008005, mean_q: 0.016231
 93537/100000: episode: 13094, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000159, mae: 0.009636, mean_q: 0.017998
 93541/100000: episode: 13095, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000278, mae: 0.007286, mean_q: 0.010085
 93547/100000: episode: 13096, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000280, mae: 0.008130, mean_q: 0.015729
 93550/100000: episode: 13097, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000113, mae: 0.007357, mean_q: 0.014052
 93554/100000: episode: 13098, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000345, mae: 0.009508, mean_q: 0.025911
 93558/100000: episode: 13099, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001097, mae: 0.011423, mean_q: 0.017743
 93561/100000: episode: 13100, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000132, mae: 0.008109, mean_q: 0.015711
 93565/100000: episode: 13101, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000535, mae: 0.011038, mean_q: 0.021017
 93568/100000: episode: 13102, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000309, mae: 0.007210, mean_q: 0.013514
 93571/100000: episode: 13103, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000093, mae: 0.007321, mean_q: 0.008541
 93575/100000: episode: 13104, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000140, mae: 0.007405, mean_q: 0.015237
 93579/100000: episode: 13105, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000171, mae: 0.007397, mean_q: 0.019879
 93585/100000: episode: 13106, duration: 0.032s, episode steps: 6, steps per second: 190, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000456, mae: 0.009135, mean_q: 0.017802
 93591/100000: episode: 13107, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000091, mae: 0.006447, mean_q: 0.011850
 93595/100000: episode: 13108, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000049, mae: 0.004963, mean_q: 0.008253
 93598/100000: episode: 13109, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000261, mae: 0.008052, mean_q: 0.019990
 93602/100000: episode: 13110, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000322, mae: 0.007709, mean_q: 0.009554
 93605/100000: episode: 13111, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000826, mae: 0.012376, mean_q: 0.026326
 93608/100000: episode: 13112, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000067, mae: 0.006285, mean_q: 0.011067
 93614/100000: episode: 13113, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000436, mae: 0.010812, mean_q: 0.018832
 93618/100000: episode: 13114, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001023, mae: 0.013389, mean_q: 0.022693
 93621/100000: episode: 13115, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000154, mae: 0.009888, mean_q: 0.017680
 93627/100000: episode: 13116, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000125, mae: 0.007334, mean_q: 0.011212
 93630/100000: episode: 13117, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000902, mae: 0.009926, mean_q: 0.013321
[Info] FALSIFICATION!
 93635/100000: episode: 13118, duration: 0.277s, episode steps: 5, steps per second: 18, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000127, mae: 0.006354, mean_q: 0.011881
 93638/100000: episode: 13119, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000531, mae: 0.009149, mean_q: 0.018424
 93641/100000: episode: 13120, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000127, mae: 0.008182, mean_q: 0.014733
 93644/100000: episode: 13121, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001888, mae: 0.015151, mean_q: 0.018096
 93647/100000: episode: 13122, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001024, mae: 0.010868, mean_q: 0.019971
 93650/100000: episode: 13123, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000198, mae: 0.008565, mean_q: 0.015028
 93654/100000: episode: 13124, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000312, mae: 0.010987, mean_q: 0.028523
 93658/100000: episode: 13125, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000089, mae: 0.005482, mean_q: 0.010985
 93662/100000: episode: 13126, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001140, mae: 0.013148, mean_q: 0.025208
 93668/100000: episode: 13127, duration: 0.031s, episode steps: 6, steps per second: 197, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000074, mae: 0.006564, mean_q: 0.012024
 93672/100000: episode: 13128, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000214, mae: 0.008809, mean_q: 0.011437
 93676/100000: episode: 13129, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000532, mae: 0.010180, mean_q: 0.022257
 93680/100000: episode: 13130, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000061, mae: 0.004991, mean_q: 0.006970
 93684/100000: episode: 13131, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000739, mae: 0.010373, mean_q: 0.015812
 93688/100000: episode: 13132, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000223, mae: 0.007014, mean_q: 0.014663
 93691/100000: episode: 13133, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000080, mae: 0.005617, mean_q: 0.009970
 93694/100000: episode: 13134, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000968, mae: 0.012587, mean_q: 0.020239
 93698/100000: episode: 13135, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000702, mae: 0.010198, mean_q: 0.015191
 93702/100000: episode: 13136, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000559, mae: 0.010669, mean_q: 0.015894
 93705/100000: episode: 13137, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000357, mae: 0.011157, mean_q: 0.017854
 93709/100000: episode: 13138, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000524, mae: 0.010468, mean_q: 0.016211
 93713/100000: episode: 13139, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001300, mae: 0.012947, mean_q: 0.035136
 93716/100000: episode: 13140, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000716, mae: 0.009021, mean_q: 0.016465
 93719/100000: episode: 13141, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000668, mae: 0.010606, mean_q: 0.026752
 93722/100000: episode: 13142, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000435, mae: 0.009862, mean_q: 0.013612
 93726/100000: episode: 13143, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000660, mae: 0.009597, mean_q: 0.013914
 93730/100000: episode: 13144, duration: 0.023s, episode steps: 4, steps per second: 178, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000792, mae: 0.012386, mean_q: 0.018852
 93736/100000: episode: 13145, duration: 0.032s, episode steps: 6, steps per second: 187, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000708, mae: 0.012455, mean_q: 0.019924
 93739/100000: episode: 13146, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000480, mae: 0.012025, mean_q: 0.034039
 93742/100000: episode: 13147, duration: 0.019s, episode steps: 3, steps per second: 155, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000870, mae: 0.010583, mean_q: 0.019230
 93745/100000: episode: 13148, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.003460, mae: 0.016112, mean_q: 0.015673
 93749/100000: episode: 13149, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000055, mae: 0.005264, mean_q: 0.010580
 93753/100000: episode: 13150, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000094, mae: 0.006719, mean_q: 0.014480
 93756/100000: episode: 13151, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000448, mae: 0.011456, mean_q: 0.026743
 93762/100000: episode: 13152, duration: 0.032s, episode steps: 6, steps per second: 187, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000496, mae: 0.011470, mean_q: 0.022266
 93766/100000: episode: 13153, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000859, mae: 0.011386, mean_q: 0.031753
 93769/100000: episode: 13154, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000071, mae: 0.005599, mean_q: 0.007021
 93773/100000: episode: 13155, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000212, mae: 0.008610, mean_q: 0.019969
 93776/100000: episode: 13156, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000166, mae: 0.006642, mean_q: 0.010572
 93779/100000: episode: 13157, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000541, mae: 0.009819, mean_q: 0.019296
 93783/100000: episode: 13158, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000646, mae: 0.012469, mean_q: 0.030083
[Info] Complete ISplit Iteration
[Info] Levels: [0.017508212, 1.3364674]
[Info] Cond. Prob: [0.14, 0.01]
[Info] Error Prob: 0.0014000000000000002

 93787/100000: episode: 13159, duration: 0.836s, episode steps: 4, steps per second: 5, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001388, mae: 0.014839, mean_q: 0.033367
 93797/100000: episode: 13160, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000260, mae: 0.008822, mean_q: 0.015390
 93807/100000: episode: 13161, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000177, mae: 0.007690, mean_q: 0.009008
 93817/100000: episode: 13162, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000552, mae: 0.009273, mean_q: 0.015240
 93827/100000: episode: 13163, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000516, mae: 0.010589, mean_q: 0.017434
 93837/100000: episode: 13164, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000585, mae: 0.011394, mean_q: 0.020098
 93847/100000: episode: 13165, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000288, mae: 0.007297, mean_q: 0.012089
 93857/100000: episode: 13166, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000258, mae: 0.008695, mean_q: 0.015972
 93867/100000: episode: 13167, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000352, mae: 0.009633, mean_q: 0.018487
 93877/100000: episode: 13168, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001135, mae: 0.012677, mean_q: 0.021118
 93887/100000: episode: 13169, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000307, mae: 0.008209, mean_q: 0.017823
 93897/100000: episode: 13170, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000596, mae: 0.009176, mean_q: 0.015759
 93907/100000: episode: 13171, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000516, mae: 0.009916, mean_q: 0.019470
 93917/100000: episode: 13172, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000155, mae: 0.008701, mean_q: 0.021980
 93927/100000: episode: 13173, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000604, mae: 0.008830, mean_q: 0.015893
 93937/100000: episode: 13174, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000290, mae: 0.009122, mean_q: 0.014326
 93947/100000: episode: 13175, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000177, mae: 0.007896, mean_q: 0.014861
 93957/100000: episode: 13176, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000610, mae: 0.008844, mean_q: 0.013793
 93967/100000: episode: 13177, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000338, mae: 0.008703, mean_q: 0.013944
 93977/100000: episode: 13178, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000092, mae: 0.006739, mean_q: 0.012005
 93987/100000: episode: 13179, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000416, mae: 0.008328, mean_q: 0.013094
 93997/100000: episode: 13180, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000491, mae: 0.008841, mean_q: 0.018534
 94007/100000: episode: 13181, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000455, mae: 0.008883, mean_q: 0.016587
 94017/100000: episode: 13182, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000333, mae: 0.007395, mean_q: 0.015897
 94027/100000: episode: 13183, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000743, mae: 0.009791, mean_q: 0.017369
 94037/100000: episode: 13184, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000694, mae: 0.008583, mean_q: 0.014763
 94047/100000: episode: 13185, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000185, mae: 0.006331, mean_q: 0.009858
 94057/100000: episode: 13186, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000279, mae: 0.008217, mean_q: 0.012645
 94067/100000: episode: 13187, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000327, mae: 0.007909, mean_q: 0.015458
 94077/100000: episode: 13188, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000161, mae: 0.006605, mean_q: 0.010689
 94087/100000: episode: 13189, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000380, mae: 0.008965, mean_q: 0.017948
 94097/100000: episode: 13190, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000331, mae: 0.008071, mean_q: 0.013335
 94107/100000: episode: 13191, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000273, mae: 0.006598, mean_q: 0.010164
 94117/100000: episode: 13192, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000310, mae: 0.007841, mean_q: 0.013928
 94127/100000: episode: 13193, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000575, mae: 0.010300, mean_q: 0.017495
 94137/100000: episode: 13194, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000171, mae: 0.008675, mean_q: 0.015747
 94147/100000: episode: 13195, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000457, mae: 0.009645, mean_q: 0.017135
 94157/100000: episode: 13196, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000190, mae: 0.006447, mean_q: 0.010748
 94167/100000: episode: 13197, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001237, mae: 0.010320, mean_q: 0.012554
 94177/100000: episode: 13198, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000376, mae: 0.011614, mean_q: 0.019642
 94187/100000: episode: 13199, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000449, mae: 0.011627, mean_q: 0.020799
 94197/100000: episode: 13200, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000135, mae: 0.007252, mean_q: 0.010580
 94207/100000: episode: 13201, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000612, mae: 0.009498, mean_q: 0.014288
 94217/100000: episode: 13202, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000310, mae: 0.008618, mean_q: 0.016921
 94227/100000: episode: 13203, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000244, mae: 0.007749, mean_q: 0.013932
 94237/100000: episode: 13204, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000402, mae: 0.010137, mean_q: 0.019724
 94247/100000: episode: 13205, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000395, mae: 0.008001, mean_q: 0.012926
 94257/100000: episode: 13206, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000426, mae: 0.008069, mean_q: 0.012510
 94267/100000: episode: 13207, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000433, mae: 0.009914, mean_q: 0.019230
 94277/100000: episode: 13208, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000153, mae: 0.006087, mean_q: 0.012036
 94287/100000: episode: 13209, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000511, mae: 0.009567, mean_q: 0.015743
 94297/100000: episode: 13210, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000096, mae: 0.006744, mean_q: 0.013594
 94307/100000: episode: 13211, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000224, mae: 0.007914, mean_q: 0.014089
 94317/100000: episode: 13212, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000746, mae: 0.011168, mean_q: 0.021335
 94327/100000: episode: 13213, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000193, mae: 0.008061, mean_q: 0.015987
 94337/100000: episode: 13214, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000302, mae: 0.008561, mean_q: 0.014524
 94347/100000: episode: 13215, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000441, mae: 0.009009, mean_q: 0.020641
 94357/100000: episode: 13216, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000516, mae: 0.009222, mean_q: 0.016522
 94367/100000: episode: 13217, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000376, mae: 0.009350, mean_q: 0.016597
 94377/100000: episode: 13218, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000460, mae: 0.009795, mean_q: 0.018576
 94387/100000: episode: 13219, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000349, mae: 0.008926, mean_q: 0.017152
 94397/100000: episode: 13220, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000203, mae: 0.006325, mean_q: 0.011502
 94407/100000: episode: 13221, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000354, mae: 0.008225, mean_q: 0.014698
 94417/100000: episode: 13222, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000120, mae: 0.007801, mean_q: 0.016801
 94427/100000: episode: 13223, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000480, mae: 0.009221, mean_q: 0.016957
 94437/100000: episode: 13224, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000206, mae: 0.005955, mean_q: 0.012048
 94447/100000: episode: 13225, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000292, mae: 0.007071, mean_q: 0.011741
 94457/100000: episode: 13226, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000373, mae: 0.008045, mean_q: 0.017583
 94467/100000: episode: 13227, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000347, mae: 0.010082, mean_q: 0.020530
 94477/100000: episode: 13228, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000647, mae: 0.009295, mean_q: 0.019763
 94487/100000: episode: 13229, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000209, mae: 0.007876, mean_q: 0.020342
 94497/100000: episode: 13230, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000082, mae: 0.006501, mean_q: 0.012985
 94507/100000: episode: 13231, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001275, mae: 0.010750, mean_q: 0.014751
 94517/100000: episode: 13232, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000448, mae: 0.009081, mean_q: 0.019180
 94527/100000: episode: 13233, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000862, mae: 0.009835, mean_q: 0.019330
 94537/100000: episode: 13234, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000325, mae: 0.008786, mean_q: 0.013744
 94547/100000: episode: 13235, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000372, mae: 0.008645, mean_q: 0.014224
 94557/100000: episode: 13236, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000605, mae: 0.010447, mean_q: 0.012741
 94567/100000: episode: 13237, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000177, mae: 0.008737, mean_q: 0.016510
 94577/100000: episode: 13238, duration: 0.069s, episode steps: 10, steps per second: 146, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000427, mae: 0.008451, mean_q: 0.017049
 94587/100000: episode: 13239, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000617, mae: 0.010510, mean_q: 0.014925
 94597/100000: episode: 13240, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000261, mae: 0.006758, mean_q: 0.010313
 94607/100000: episode: 13241, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000374, mae: 0.009452, mean_q: 0.017343
 94617/100000: episode: 13242, duration: 0.081s, episode steps: 10, steps per second: 124, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000248, mae: 0.008039, mean_q: 0.013531
 94627/100000: episode: 13243, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000187, mae: 0.006760, mean_q: 0.012759
 94637/100000: episode: 13244, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000341, mae: 0.009165, mean_q: 0.017353
 94647/100000: episode: 13245, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000309, mae: 0.008492, mean_q: 0.015514
 94657/100000: episode: 13246, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000452, mae: 0.009755, mean_q: 0.017766
 94667/100000: episode: 13247, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001081, mae: 0.009160, mean_q: 0.009708
 94677/100000: episode: 13248, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000474, mae: 0.009882, mean_q: 0.017204
 94687/100000: episode: 13249, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000472, mae: 0.009837, mean_q: 0.019897
 94697/100000: episode: 13250, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000791, mae: 0.010657, mean_q: 0.017873
 94707/100000: episode: 13251, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000320, mae: 0.008828, mean_q: 0.012647
 94717/100000: episode: 13252, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000679, mae: 0.013012, mean_q: 0.021002
 94727/100000: episode: 13253, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000228, mae: 0.010505, mean_q: 0.020247
 94737/100000: episode: 13254, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000244, mae: 0.007138, mean_q: 0.009761
 94747/100000: episode: 13255, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000166, mae: 0.007268, mean_q: 0.011693
 94757/100000: episode: 13256, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000340, mae: 0.009460, mean_q: 0.015773
 94767/100000: episode: 13257, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000340, mae: 0.010659, mean_q: 0.021098
 94777/100000: episode: 13258, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000495, mae: 0.008888, mean_q: 0.015078
[Info] 1-TH LEVEL FOUND: 0.04613955691456795, Considering 10/100 traces
 94787/100000: episode: 13259, duration: 0.741s, episode steps: 10, steps per second: 13, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000220, mae: 0.008172, mean_q: 0.015208
 94791/100000: episode: 13260, duration: 0.026s, episode steps: 4, steps per second: 151, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001412, mae: 0.011882, mean_q: 0.017907
 94795/100000: episode: 13261, duration: 0.027s, episode steps: 4, steps per second: 149, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000294, mae: 0.007087, mean_q: 0.010000
 94799/100000: episode: 13262, duration: 0.027s, episode steps: 4, steps per second: 150, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000997, mae: 0.011192, mean_q: 0.017185
 94803/100000: episode: 13263, duration: 0.026s, episode steps: 4, steps per second: 152, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000081, mae: 0.005588, mean_q: 0.008049
 94807/100000: episode: 13264, duration: 0.029s, episode steps: 4, steps per second: 137, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000955, mae: 0.011062, mean_q: 0.016504
 94811/100000: episode: 13265, duration: 0.029s, episode steps: 4, steps per second: 139, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000300, mae: 0.008676, mean_q: 0.014922
 94817/100000: episode: 13266, duration: 0.037s, episode steps: 6, steps per second: 162, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000620, mae: 0.011097, mean_q: 0.020481
 94821/100000: episode: 13267, duration: 0.027s, episode steps: 4, steps per second: 146, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000895, mae: 0.012114, mean_q: 0.026797
 94827/100000: episode: 13268, duration: 0.037s, episode steps: 6, steps per second: 162, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002146, mae: 0.015968, mean_q: 0.026591
 94831/100000: episode: 13269, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000290, mae: 0.007946, mean_q: 0.022312
 94837/100000: episode: 13270, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000384, mae: 0.008299, mean_q: 0.017540
[Info] FALSIFICATION!
 94842/100000: episode: 13271, duration: 0.280s, episode steps: 5, steps per second: 18, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000581, mae: 0.012931, mean_q: 0.016697
 94846/100000: episode: 13272, duration: 0.031s, episode steps: 4, steps per second: 128, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000498, mae: 0.008545, mean_q: 0.012543
 94850/100000: episode: 13273, duration: 0.025s, episode steps: 4, steps per second: 157, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001214, mae: 0.014740, mean_q: 0.021257
 94854/100000: episode: 13274, duration: 0.029s, episode steps: 4, steps per second: 138, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000084, mae: 0.006417, mean_q: 0.010343
 94858/100000: episode: 13275, duration: 0.027s, episode steps: 4, steps per second: 146, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000100, mae: 0.007043, mean_q: 0.007790
 94862/100000: episode: 13276, duration: 0.030s, episode steps: 4, steps per second: 133, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001233, mae: 0.014441, mean_q: 0.016521
 94868/100000: episode: 13277, duration: 0.037s, episode steps: 6, steps per second: 161, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000183, mae: 0.008278, mean_q: 0.013558
 94874/100000: episode: 13278, duration: 0.042s, episode steps: 6, steps per second: 144, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000198, mae: 0.009067, mean_q: 0.015251
 94880/100000: episode: 13279, duration: 0.043s, episode steps: 6, steps per second: 140, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000660, mae: 0.010452, mean_q: 0.018856
 94884/100000: episode: 13280, duration: 0.028s, episode steps: 4, steps per second: 144, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000533, mae: 0.008290, mean_q: 0.013481
 94890/100000: episode: 13281, duration: 0.035s, episode steps: 6, steps per second: 169, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000184, mae: 0.006874, mean_q: 0.010903
 94896/100000: episode: 13282, duration: 0.036s, episode steps: 6, steps per second: 168, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000232, mae: 0.007783, mean_q: 0.016564
 94900/100000: episode: 13283, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000407, mae: 0.010831, mean_q: 0.023545
 94906/100000: episode: 13284, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000778, mae: 0.011678, mean_q: 0.018645
[Info] FALSIFICATION!
 94911/100000: episode: 13285, duration: 0.278s, episode steps: 5, steps per second: 18, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000846, mae: 0.012524, mean_q: 0.028786
 94915/100000: episode: 13286, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001817, mae: 0.016976, mean_q: 0.041426
 94919/100000: episode: 13287, duration: 0.027s, episode steps: 4, steps per second: 148, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000067, mae: 0.005729, mean_q: 0.009205
 94923/100000: episode: 13288, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000084, mae: 0.005699, mean_q: 0.007988
 94927/100000: episode: 13289, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000370, mae: 0.008290, mean_q: 0.013853
[Info] FALSIFICATION!
 94932/100000: episode: 13290, duration: 0.284s, episode steps: 5, steps per second: 18, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000227, mae: 0.007342, mean_q: 0.020500
 94938/100000: episode: 13291, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000219, mae: 0.009196, mean_q: 0.019501
 94942/100000: episode: 13292, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000136, mae: 0.009014, mean_q: 0.020913
 94946/100000: episode: 13293, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000715, mae: 0.011947, mean_q: 0.021409
 94952/100000: episode: 13294, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000546, mae: 0.008110, mean_q: 0.015302
 94956/100000: episode: 13295, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000126, mae: 0.006036, mean_q: 0.008553
 94960/100000: episode: 13296, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000193, mae: 0.009257, mean_q: 0.019174
 94964/100000: episode: 13297, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000604, mae: 0.010929, mean_q: 0.019871
 94970/100000: episode: 13298, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000321, mae: 0.008015, mean_q: 0.014105
 94974/100000: episode: 13299, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001116, mae: 0.016475, mean_q: 0.029745
 94978/100000: episode: 13300, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000477, mae: 0.011929, mean_q: 0.025446
 94984/100000: episode: 13301, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000840, mae: 0.010827, mean_q: 0.022218
 94988/100000: episode: 13302, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000112, mae: 0.006166, mean_q: 0.019320
 94992/100000: episode: 13303, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000139, mae: 0.009112, mean_q: 0.017031
 94996/100000: episode: 13304, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000046, mae: 0.004455, mean_q: 0.011957
 95002/100000: episode: 13305, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000907, mae: 0.011973, mean_q: 0.012142
 95006/100000: episode: 13306, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000677, mae: 0.008351, mean_q: 0.010576
 95010/100000: episode: 13307, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000498, mae: 0.008248, mean_q: 0.018963
 95014/100000: episode: 13308, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000103, mae: 0.005848, mean_q: 0.009321
 95020/100000: episode: 13309, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000781, mae: 0.012445, mean_q: 0.025128
 95026/100000: episode: 13310, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000323, mae: 0.008425, mean_q: 0.014504
 95032/100000: episode: 13311, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000326, mae: 0.009639, mean_q: 0.019922
 95036/100000: episode: 13312, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001298, mae: 0.011534, mean_q: 0.018465
 95040/100000: episode: 13313, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000458, mae: 0.009077, mean_q: 0.013993
 95046/100000: episode: 13314, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000495, mae: 0.009290, mean_q: 0.010789
 95050/100000: episode: 13315, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000818, mae: 0.012787, mean_q: 0.026550
 95054/100000: episode: 13316, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000738, mae: 0.011086, mean_q: 0.018174
 95060/100000: episode: 13317, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000624, mae: 0.011035, mean_q: 0.022073
 95064/100000: episode: 13318, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000143, mae: 0.005615, mean_q: 0.014058
 95068/100000: episode: 13319, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000281, mae: 0.005492, mean_q: 0.005808
 95072/100000: episode: 13320, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000666, mae: 0.011595, mean_q: 0.017977
 95076/100000: episode: 13321, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000095, mae: 0.007674, mean_q: 0.014876
 95080/100000: episode: 13322, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000558, mae: 0.010467, mean_q: 0.019036
 95084/100000: episode: 13323, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000629, mae: 0.011462, mean_q: 0.024769
 95090/100000: episode: 13324, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000054, mae: 0.005524, mean_q: 0.009912
 95096/100000: episode: 13325, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001123, mae: 0.012543, mean_q: 0.021002
[Info] FALSIFICATION!
 95101/100000: episode: 13326, duration: 0.278s, episode steps: 5, steps per second: 18, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000446, mae: 0.009945, mean_q: 0.018577
 95105/100000: episode: 13327, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000108, mae: 0.005723, mean_q: 0.013906
 95109/100000: episode: 13328, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000450, mae: 0.009374, mean_q: 0.017850
 95115/100000: episode: 13329, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000267, mae: 0.009417, mean_q: 0.016939
 95119/100000: episode: 13330, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000130, mae: 0.008579, mean_q: 0.016229
 95123/100000: episode: 13331, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000137, mae: 0.007319, mean_q: 0.015481
 95127/100000: episode: 13332, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000931, mae: 0.013588, mean_q: 0.029543
 95131/100000: episode: 13333, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001121, mae: 0.011760, mean_q: 0.018070
 95135/100000: episode: 13334, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000091, mae: 0.006044, mean_q: 0.018801
 95139/100000: episode: 13335, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000453, mae: 0.009099, mean_q: 0.014411
 95145/100000: episode: 13336, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000498, mae: 0.010441, mean_q: 0.016409
 95149/100000: episode: 13337, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000156, mae: 0.008917, mean_q: 0.019335
 95153/100000: episode: 13338, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000963, mae: 0.009999, mean_q: 0.018718
 95157/100000: episode: 13339, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000284, mae: 0.006587, mean_q: 0.017560
 95163/100000: episode: 13340, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000103, mae: 0.006585, mean_q: 0.015608
 95167/100000: episode: 13341, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001350, mae: 0.014887, mean_q: 0.024594
 95173/100000: episode: 13342, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000339, mae: 0.009908, mean_q: 0.019773
 95177/100000: episode: 13343, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000098, mae: 0.006234, mean_q: 0.011406
 95181/100000: episode: 13344, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000093, mae: 0.006579, mean_q: 0.011407
 95185/100000: episode: 13345, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001413, mae: 0.015622, mean_q: 0.025896
 95191/100000: episode: 13346, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000263, mae: 0.009536, mean_q: 0.020545
 95197/100000: episode: 13347, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000046, mae: 0.004611, mean_q: 0.009267
 95203/100000: episode: 13348, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000753, mae: 0.009165, mean_q: 0.016795
[Info] Complete ISplit Iteration
[Info] Levels: [0.046139557, 1.309809]
[Info] Cond. Prob: [0.1, 0.04]
[Info] Error Prob: 0.004

 95207/100000: episode: 13349, duration: 0.839s, episode steps: 4, steps per second: 5, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000116, mae: 0.007302, mean_q: 0.013687
 95217/100000: episode: 13350, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000215, mae: 0.008276, mean_q: 0.012734
 95227/100000: episode: 13351, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000339, mae: 0.008807, mean_q: 0.018526
 95237/100000: episode: 13352, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000670, mae: 0.010156, mean_q: 0.020877
 95247/100000: episode: 13353, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000801, mae: 0.011651, mean_q: 0.024057
 95257/100000: episode: 13354, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000258, mae: 0.006950, mean_q: 0.014249
 95267/100000: episode: 13355, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000176, mae: 0.007086, mean_q: 0.015117
 95277/100000: episode: 13356, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000127, mae: 0.008006, mean_q: 0.017176
 95287/100000: episode: 13357, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000120, mae: 0.007796, mean_q: 0.012188
 95297/100000: episode: 13358, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000566, mae: 0.008760, mean_q: 0.010860
 95307/100000: episode: 13359, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000197, mae: 0.007327, mean_q: 0.011107
 95317/100000: episode: 13360, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000473, mae: 0.010401, mean_q: 0.017630
 95327/100000: episode: 13361, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000645, mae: 0.010502, mean_q: 0.018889
 95337/100000: episode: 13362, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000537, mae: 0.009524, mean_q: 0.015086
 95347/100000: episode: 13363, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000196, mae: 0.006621, mean_q: 0.008537
 95357/100000: episode: 13364, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000474, mae: 0.008628, mean_q: 0.015826
 95367/100000: episode: 13365, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000295, mae: 0.008283, mean_q: 0.016503
 95377/100000: episode: 13366, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000392, mae: 0.008753, mean_q: 0.012445
 95387/100000: episode: 13367, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000592, mae: 0.010321, mean_q: 0.015848
 95397/100000: episode: 13368, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000428, mae: 0.010070, mean_q: 0.017106
 95407/100000: episode: 13369, duration: 0.064s, episode steps: 10, steps per second: 155, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000177, mae: 0.008167, mean_q: 0.014993
 95417/100000: episode: 13370, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000632, mae: 0.011629, mean_q: 0.018093
 95427/100000: episode: 13371, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000556, mae: 0.011666, mean_q: 0.021581
 95437/100000: episode: 13372, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000510, mae: 0.009350, mean_q: 0.019877
 95447/100000: episode: 13373, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000462, mae: 0.008747, mean_q: 0.018047
 95457/100000: episode: 13374, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000242, mae: 0.007324, mean_q: 0.013343
 95467/100000: episode: 13375, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000235, mae: 0.007201, mean_q: 0.011909
 95477/100000: episode: 13376, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001265, mae: 0.012537, mean_q: 0.021018
 95487/100000: episode: 13377, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000350, mae: 0.007836, mean_q: 0.010061
 95497/100000: episode: 13378, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000194, mae: 0.007192, mean_q: 0.008221
 95507/100000: episode: 13379, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000212, mae: 0.008761, mean_q: 0.014073
 95517/100000: episode: 13380, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000310, mae: 0.010151, mean_q: 0.017342
 95527/100000: episode: 13381, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000513, mae: 0.010099, mean_q: 0.017892
 95537/100000: episode: 13382, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000349, mae: 0.010048, mean_q: 0.014976
 95547/100000: episode: 13383, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000206, mae: 0.009118, mean_q: 0.017492
 95557/100000: episode: 13384, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000100, mae: 0.006574, mean_q: 0.011333
 95567/100000: episode: 13385, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000157, mae: 0.007080, mean_q: 0.010153
 95577/100000: episode: 13386, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000377, mae: 0.008352, mean_q: 0.014039
 95587/100000: episode: 13387, duration: 0.071s, episode steps: 10, steps per second: 140, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000140, mae: 0.006770, mean_q: 0.012592
 95597/100000: episode: 13388, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000301, mae: 0.008744, mean_q: 0.015239
 95607/100000: episode: 13389, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000257, mae: 0.006693, mean_q: 0.011379
 95617/100000: episode: 13390, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000239, mae: 0.007628, mean_q: 0.012886
 95627/100000: episode: 13391, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000780, mae: 0.011395, mean_q: 0.019352
 95637/100000: episode: 13392, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000527, mae: 0.011488, mean_q: 0.019040
 95647/100000: episode: 13393, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000407, mae: 0.007776, mean_q: 0.012391
 95657/100000: episode: 13394, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000183, mae: 0.007151, mean_q: 0.013880
 95667/100000: episode: 13395, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000170, mae: 0.008573, mean_q: 0.021455
 95677/100000: episode: 13396, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000534, mae: 0.010197, mean_q: 0.021326
 95687/100000: episode: 13397, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000399, mae: 0.008195, mean_q: 0.009312
 95697/100000: episode: 13398, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000115, mae: 0.006853, mean_q: 0.010536
 95707/100000: episode: 13399, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000516, mae: 0.010929, mean_q: 0.021005
 95717/100000: episode: 13400, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000238, mae: 0.008602, mean_q: 0.016607
 95727/100000: episode: 13401, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000202, mae: 0.007997, mean_q: 0.011613
 95737/100000: episode: 13402, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000104, mae: 0.006543, mean_q: 0.014725
 95747/100000: episode: 13403, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000259, mae: 0.007088, mean_q: 0.011120
 95757/100000: episode: 13404, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000236, mae: 0.007161, mean_q: 0.013465
 95767/100000: episode: 13405, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000142, mae: 0.007212, mean_q: 0.014035
 95777/100000: episode: 13406, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000196, mae: 0.007360, mean_q: 0.014405
 95787/100000: episode: 13407, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000161, mae: 0.007263, mean_q: 0.012138
 95797/100000: episode: 13408, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000437, mae: 0.007871, mean_q: 0.015229
 95807/100000: episode: 13409, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000790, mae: 0.010941, mean_q: 0.018927
 95817/100000: episode: 13410, duration: 0.064s, episode steps: 10, steps per second: 155, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000354, mae: 0.007607, mean_q: 0.013656
 95827/100000: episode: 13411, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000656, mae: 0.010857, mean_q: 0.018946
 95837/100000: episode: 13412, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000413, mae: 0.010531, mean_q: 0.021357
 95847/100000: episode: 13413, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000122, mae: 0.005954, mean_q: 0.015174
 95857/100000: episode: 13414, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000172, mae: 0.008758, mean_q: 0.014254
 95867/100000: episode: 13415, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000109, mae: 0.007065, mean_q: 0.017386
 95877/100000: episode: 13416, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000582, mae: 0.008282, mean_q: 0.019115
 95887/100000: episode: 13417, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000331, mae: 0.008842, mean_q: 0.012014
 95897/100000: episode: 13418, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000340, mae: 0.008339, mean_q: 0.015105
 95907/100000: episode: 13419, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000613, mae: 0.011974, mean_q: 0.022251
 95917/100000: episode: 13420, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000144, mae: 0.005988, mean_q: 0.009523
 95927/100000: episode: 13421, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000173, mae: 0.008127, mean_q: 0.018632
 95937/100000: episode: 13422, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000077, mae: 0.005747, mean_q: 0.011401
 95947/100000: episode: 13423, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000285, mae: 0.008817, mean_q: 0.017804
 95957/100000: episode: 13424, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000459, mae: 0.009190, mean_q: 0.017832
 95967/100000: episode: 13425, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000275, mae: 0.008395, mean_q: 0.020958
 95977/100000: episode: 13426, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000191, mae: 0.006156, mean_q: 0.010644
 95987/100000: episode: 13427, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000486, mae: 0.010919, mean_q: 0.024516
 95997/100000: episode: 13428, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000666, mae: 0.009144, mean_q: 0.024121
 96007/100000: episode: 13429, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000148, mae: 0.005666, mean_q: 0.008997
 96017/100000: episode: 13430, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000347, mae: 0.009444, mean_q: 0.016741
 96027/100000: episode: 13431, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000512, mae: 0.007968, mean_q: 0.012094
 96037/100000: episode: 13432, duration: 0.072s, episode steps: 10, steps per second: 140, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000198, mae: 0.007442, mean_q: 0.013473
 96047/100000: episode: 13433, duration: 0.079s, episode steps: 10, steps per second: 126, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000424, mae: 0.009707, mean_q: 0.021590
 96057/100000: episode: 13434, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000092, mae: 0.006544, mean_q: 0.012383
 96067/100000: episode: 13435, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000191, mae: 0.006434, mean_q: 0.015217
 96077/100000: episode: 13436, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000445, mae: 0.009331, mean_q: 0.020045
 96087/100000: episode: 13437, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000571, mae: 0.008357, mean_q: 0.016935
 96097/100000: episode: 13438, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000552, mae: 0.009987, mean_q: 0.017083
 96107/100000: episode: 13439, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000332, mae: 0.008355, mean_q: 0.013514
 96117/100000: episode: 13440, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000240, mae: 0.008475, mean_q: 0.011899
 96127/100000: episode: 13441, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000479, mae: 0.010057, mean_q: 0.020562
 96137/100000: episode: 13442, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000116, mae: 0.006759, mean_q: 0.011693
 96147/100000: episode: 13443, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000646, mae: 0.011056, mean_q: 0.021250
 96157/100000: episode: 13444, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000284, mae: 0.010093, mean_q: 0.021801
 96167/100000: episode: 13445, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000668, mae: 0.010048, mean_q: 0.016597
 96177/100000: episode: 13446, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000483, mae: 0.011016, mean_q: 0.016518
 96187/100000: episode: 13447, duration: 0.055s, episode steps: 10, steps per second: 180, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000152, mae: 0.007973, mean_q: 0.022649
 96197/100000: episode: 13448, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000213, mae: 0.007614, mean_q: 0.010169
[Info] 1-TH LEVEL FOUND: 0.0029642940498888493, Considering 100/100 traces
 96207/100000: episode: 13449, duration: 0.731s, episode steps: 10, steps per second: 14, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000493, mae: 0.008859, mean_q: 0.012606
[Info] 2-TH LEVEL FOUND: 0.004930316936224699, Considering 100/100 traces
 96217/100000: episode: 13450, duration: 0.719s, episode steps: 10, steps per second: 14, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000376, mae: 0.008594, mean_q: 0.013636
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.004930316936224699
 96227/100000: episode: 13451, duration: 0.577s, episode steps: 10, steps per second: 17, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000382, mae: 0.008600, mean_q: 0.017529
 96237/100000: episode: 13452, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000161, mae: 0.007324, mean_q: 0.015775
 96247/100000: episode: 13453, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000243, mae: 0.007053, mean_q: 0.012951
 96257/100000: episode: 13454, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000479, mae: 0.008193, mean_q: 0.013076
 96267/100000: episode: 13455, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000321, mae: 0.008442, mean_q: 0.019531
 96277/100000: episode: 13456, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000131, mae: 0.007804, mean_q: 0.018372
 96287/100000: episode: 13457, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000492, mae: 0.010497, mean_q: 0.020218
 96297/100000: episode: 13458, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000629, mae: 0.010694, mean_q: 0.016282
 96307/100000: episode: 13459, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000693, mae: 0.010634, mean_q: 0.015502
 96317/100000: episode: 13460, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000317, mae: 0.009520, mean_q: 0.012138
 96327/100000: episode: 13461, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000298, mae: 0.010535, mean_q: 0.013533
 96337/100000: episode: 13462, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000369, mae: 0.011120, mean_q: 0.017921
 96347/100000: episode: 13463, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000222, mae: 0.006662, mean_q: 0.014296
 96357/100000: episode: 13464, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000644, mae: 0.008824, mean_q: 0.020463
 96367/100000: episode: 13465, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000183, mae: 0.007185, mean_q: 0.014125
 96377/100000: episode: 13466, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000158, mae: 0.007780, mean_q: 0.014247
 96387/100000: episode: 13467, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000117, mae: 0.006846, mean_q: 0.014896
 96397/100000: episode: 13468, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000082, mae: 0.005780, mean_q: 0.013214
 96407/100000: episode: 13469, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000142, mae: 0.005706, mean_q: 0.014630
 96417/100000: episode: 13470, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000737, mae: 0.010365, mean_q: 0.013954
 96427/100000: episode: 13471, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000358, mae: 0.009081, mean_q: 0.016133
 96437/100000: episode: 13472, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000205, mae: 0.007702, mean_q: 0.013655
 96447/100000: episode: 13473, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000101, mae: 0.006087, mean_q: 0.009843
 96457/100000: episode: 13474, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000079, mae: 0.005619, mean_q: 0.009401
 96467/100000: episode: 13475, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000777, mae: 0.009713, mean_q: 0.014773
 96477/100000: episode: 13476, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000237, mae: 0.008190, mean_q: 0.018156
 96487/100000: episode: 13477, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000658, mae: 0.008942, mean_q: 0.019465
 96497/100000: episode: 13478, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000446, mae: 0.007476, mean_q: 0.010513
 96507/100000: episode: 13479, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000121, mae: 0.007777, mean_q: 0.011641
 96517/100000: episode: 13480, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001054, mae: 0.013379, mean_q: 0.018531
 96527/100000: episode: 13481, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000088, mae: 0.006556, mean_q: 0.009957
 96537/100000: episode: 13482, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000167, mae: 0.007786, mean_q: 0.016094
 96547/100000: episode: 13483, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000148, mae: 0.006951, mean_q: 0.016219
 96557/100000: episode: 13484, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000566, mae: 0.010483, mean_q: 0.015017
 96567/100000: episode: 13485, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000428, mae: 0.007473, mean_q: 0.014952
 96577/100000: episode: 13486, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000243, mae: 0.007884, mean_q: 0.015968
 96587/100000: episode: 13487, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000080, mae: 0.005997, mean_q: 0.011866
 96597/100000: episode: 13488, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000405, mae: 0.008751, mean_q: 0.015327
 96607/100000: episode: 13489, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000170, mae: 0.007167, mean_q: 0.013085
 96617/100000: episode: 13490, duration: 0.060s, episode steps: 10, steps per second: 165, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000259, mae: 0.007578, mean_q: 0.012547
 96627/100000: episode: 13491, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000499, mae: 0.007639, mean_q: 0.014120
 96637/100000: episode: 13492, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000498, mae: 0.007729, mean_q: 0.009805
 96647/100000: episode: 13493, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000630, mae: 0.009150, mean_q: 0.015783
 96657/100000: episode: 13494, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000057, mae: 0.006607, mean_q: 0.010244
 96667/100000: episode: 13495, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000266, mae: 0.008758, mean_q: 0.022124
 96677/100000: episode: 13496, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000227, mae: 0.007435, mean_q: 0.013622
 96687/100000: episode: 13497, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000415, mae: 0.005902, mean_q: 0.009315
 96697/100000: episode: 13498, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000208, mae: 0.006210, mean_q: 0.008171
 96707/100000: episode: 13499, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000109, mae: 0.008326, mean_q: 0.015633
 96717/100000: episode: 13500, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000377, mae: 0.006497, mean_q: 0.013711
 96727/100000: episode: 13501, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000073, mae: 0.004949, mean_q: 0.009513
 96737/100000: episode: 13502, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000073, mae: 0.005347, mean_q: 0.008068
 96747/100000: episode: 13503, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000474, mae: 0.006850, mean_q: 0.015510
 96757/100000: episode: 13504, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000332, mae: 0.006689, mean_q: 0.010974
 96767/100000: episode: 13505, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000942, mae: 0.011615, mean_q: 0.016893
 96777/100000: episode: 13506, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000318, mae: 0.007348, mean_q: 0.013292
 96787/100000: episode: 13507, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000087, mae: 0.006184, mean_q: 0.007219
 96797/100000: episode: 13508, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000266, mae: 0.007514, mean_q: 0.010292
 96807/100000: episode: 13509, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000338, mae: 0.007290, mean_q: 0.011831
 96817/100000: episode: 13510, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000078, mae: 0.006405, mean_q: 0.012016
 96827/100000: episode: 13511, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000169, mae: 0.005947, mean_q: 0.010248
 96837/100000: episode: 13512, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000882, mae: 0.009638, mean_q: 0.013584
 96847/100000: episode: 13513, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000082, mae: 0.007400, mean_q: 0.012403
 96857/100000: episode: 13514, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000282, mae: 0.007720, mean_q: 0.012978
 96867/100000: episode: 13515, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000194, mae: 0.006146, mean_q: 0.014754
 96877/100000: episode: 13516, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000119, mae: 0.004727, mean_q: 0.008158
 96887/100000: episode: 13517, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000159, mae: 0.005944, mean_q: 0.011400
 96897/100000: episode: 13518, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000296, mae: 0.006659, mean_q: 0.007983
 96907/100000: episode: 13519, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000438, mae: 0.007231, mean_q: 0.009617
 96917/100000: episode: 13520, duration: 0.062s, episode steps: 10, steps per second: 163, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000749, mae: 0.012064, mean_q: 0.019652
 96927/100000: episode: 13521, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000065, mae: 0.006924, mean_q: 0.013841
 96937/100000: episode: 13522, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000046, mae: 0.004020, mean_q: 0.007059
 96947/100000: episode: 13523, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000202, mae: 0.006696, mean_q: 0.012094
 96957/100000: episode: 13524, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000213, mae: 0.006062, mean_q: 0.011427
 96967/100000: episode: 13525, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000161, mae: 0.006144, mean_q: 0.014363
 96977/100000: episode: 13526, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000516, mae: 0.008044, mean_q: 0.011802
 96987/100000: episode: 13527, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000303, mae: 0.006742, mean_q: 0.010486
 96997/100000: episode: 13528, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000447, mae: 0.011043, mean_q: 0.020238
 97007/100000: episode: 13529, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000148, mae: 0.006153, mean_q: 0.012397
 97017/100000: episode: 13530, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000152, mae: 0.005674, mean_q: 0.012387
 97027/100000: episode: 13531, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000712, mae: 0.008389, mean_q: 0.011435
 97037/100000: episode: 13532, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000696, mae: 0.009116, mean_q: 0.015819
 97047/100000: episode: 13533, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000149, mae: 0.005406, mean_q: 0.008462
 97057/100000: episode: 13534, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000388, mae: 0.006957, mean_q: 0.014907
 97067/100000: episode: 13535, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000888, mae: 0.008907, mean_q: 0.013320
 97077/100000: episode: 13536, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000085, mae: 0.005128, mean_q: 0.010704
 97087/100000: episode: 13537, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000215, mae: 0.005717, mean_q: 0.011566
 97097/100000: episode: 13538, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000066, mae: 0.005028, mean_q: 0.010870
 97107/100000: episode: 13539, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000338, mae: 0.008171, mean_q: 0.013468
 97117/100000: episode: 13540, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000303, mae: 0.007532, mean_q: 0.012351
 97127/100000: episode: 13541, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000231, mae: 0.006586, mean_q: 0.012698
 97137/100000: episode: 13542, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000131, mae: 0.005029, mean_q: 0.011128
 97147/100000: episode: 13543, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000258, mae: 0.005591, mean_q: 0.014060
 97157/100000: episode: 13544, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000229, mae: 0.006693, mean_q: 0.014547
 97167/100000: episode: 13545, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000586, mae: 0.007026, mean_q: 0.010479
 97177/100000: episode: 13546, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000545, mae: 0.007587, mean_q: 0.008328
 97187/100000: episode: 13547, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000396, mae: 0.008552, mean_q: 0.015451
 97197/100000: episode: 13548, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000075, mae: 0.006347, mean_q: 0.011425
 97207/100000: episode: 13549, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000172, mae: 0.005948, mean_q: 0.013959
 97217/100000: episode: 13550, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000117, mae: 0.004589, mean_q: 0.008240
[Info] 1-TH LEVEL FOUND: 0.022349338978528976, Considering 12/100 traces
 97227/100000: episode: 13551, duration: 0.704s, episode steps: 10, steps per second: 14, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000625, mae: 0.007211, mean_q: 0.012873
 97231/100000: episode: 13552, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000060, mae: 0.005426, mean_q: 0.006528
 97234/100000: episode: 13553, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000466, mae: 0.009780, mean_q: 0.012811
 97240/100000: episode: 13554, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000048, mae: 0.003808, mean_q: 0.006258
 97243/100000: episode: 13555, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000101, mae: 0.007059, mean_q: 0.012971
 97247/100000: episode: 13556, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000283, mae: 0.006996, mean_q: 0.021612
 97250/100000: episode: 13557, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001423, mae: 0.011111, mean_q: 0.017097
 97256/100000: episode: 13558, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000064, mae: 0.005012, mean_q: 0.008477
 97262/100000: episode: 13559, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000061, mae: 0.004030, mean_q: 0.006872
 97265/100000: episode: 13560, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000053, mae: 0.004372, mean_q: 0.005804
 97268/100000: episode: 13561, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000094, mae: 0.006682, mean_q: 0.010538
 97271/100000: episode: 13562, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000107, mae: 0.006828, mean_q: 0.011009
 97274/100000: episode: 13563, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000078, mae: 0.005368, mean_q: 0.008096
 97277/100000: episode: 13564, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000087, mae: 0.005477, mean_q: 0.018823
 97280/100000: episode: 13565, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000073, mae: 0.004683, mean_q: 0.017139
 97283/100000: episode: 13566, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000091, mae: 0.005290, mean_q: 0.018147
 97286/100000: episode: 13567, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000048, mae: 0.003944, mean_q: 0.005820
 97289/100000: episode: 13568, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000037, mae: 0.002723, mean_q: 0.004636
 97292/100000: episode: 13569, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000070, mae: 0.004997, mean_q: 0.006404
 97295/100000: episode: 13570, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000982, mae: 0.011789, mean_q: 0.020708
 97298/100000: episode: 13571, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000036, mae: 0.003008, mean_q: 0.005504
 97301/100000: episode: 13572, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000048, mae: 0.003795, mean_q: 0.004011
 97305/100000: episode: 13573, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000898, mae: 0.010747, mean_q: 0.014876
 97311/100000: episode: 13574, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000388, mae: 0.007108, mean_q: 0.009814
 97314/100000: episode: 13575, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000025, mae: 0.003538, mean_q: 0.006389
 97317/100000: episode: 13576, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000406, mae: 0.009140, mean_q: 0.011562
 97320/100000: episode: 13577, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000059, mae: 0.006072, mean_q: 0.008890
 97323/100000: episode: 13578, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000074, mae: 0.006453, mean_q: 0.009473
 97329/100000: episode: 13579, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000373, mae: 0.007123, mean_q: 0.011775
 97335/100000: episode: 13580, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000371, mae: 0.008926, mean_q: 0.015658
 97338/100000: episode: 13581, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000555, mae: 0.009108, mean_q: 0.017374
 97341/100000: episode: 13582, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000089, mae: 0.006159, mean_q: 0.012369
 97347/100000: episode: 13583, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000223, mae: 0.006738, mean_q: 0.011132
 97353/100000: episode: 13584, duration: 0.032s, episode steps: 6, steps per second: 189, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000053, mae: 0.003824, mean_q: 0.007245
 97356/100000: episode: 13585, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000073, mae: 0.004939, mean_q: 0.007265
 97362/100000: episode: 13586, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000048, mae: 0.003738, mean_q: 0.007858
 97365/100000: episode: 13587, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000128, mae: 0.006459, mean_q: 0.010688
 97368/100000: episode: 13588, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000034, mae: 0.003363, mean_q: 0.015269
 97374/100000: episode: 13589, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000042, mae: 0.003793, mean_q: 0.006831
 97380/100000: episode: 13590, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000090, mae: 0.005715, mean_q: 0.013053
 97383/100000: episode: 13591, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000060, mae: 0.004735, mean_q: 0.010168
 97386/100000: episode: 13592, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000070, mae: 0.005904, mean_q: 0.010079
 97392/100000: episode: 13593, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000081, mae: 0.006288, mean_q: 0.011211
 97395/100000: episode: 13594, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000064, mae: 0.005232, mean_q: 0.010917
 97398/100000: episode: 13595, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000065, mae: 0.005086, mean_q: 0.008675
 97401/100000: episode: 13596, duration: 0.023s, episode steps: 3, steps per second: 133, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000320, mae: 0.008865, mean_q: 0.019053
 97404/100000: episode: 13597, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000070, mae: 0.005605, mean_q: 0.010618
 97407/100000: episode: 13598, duration: 0.024s, episode steps: 3, steps per second: 127, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000042, mae: 0.004000, mean_q: 0.006293
 97411/100000: episode: 13599, duration: 0.027s, episode steps: 4, steps per second: 148, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000066, mae: 0.005283, mean_q: 0.006680
 97414/100000: episode: 13600, duration: 0.023s, episode steps: 3, steps per second: 131, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000047, mae: 0.004229, mean_q: 0.008970
 97417/100000: episode: 13601, duration: 0.021s, episode steps: 3, steps per second: 140, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000077, mae: 0.006152, mean_q: 0.010512
 97423/100000: episode: 13602, duration: 0.046s, episode steps: 6, steps per second: 132, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000070, mae: 0.005437, mean_q: 0.010448
 97427/100000: episode: 13603, duration: 0.029s, episode steps: 4, steps per second: 140, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000254, mae: 0.004794, mean_q: 0.008861
 97433/100000: episode: 13604, duration: 0.040s, episode steps: 6, steps per second: 150, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000060, mae: 0.004217, mean_q: 0.006599
 97437/100000: episode: 13605, duration: 0.029s, episode steps: 4, steps per second: 138, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000282, mae: 0.005604, mean_q: 0.015999
 97440/100000: episode: 13606, duration: 0.021s, episode steps: 3, steps per second: 140, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000467, mae: 0.009643, mean_q: 0.018015
 97443/100000: episode: 13607, duration: 0.024s, episode steps: 3, steps per second: 125, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000110, mae: 0.006583, mean_q: 0.020794
 97446/100000: episode: 13608, duration: 0.022s, episode steps: 3, steps per second: 138, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000078, mae: 0.005025, mean_q: 0.009771
 97449/100000: episode: 13609, duration: 0.021s, episode steps: 3, steps per second: 146, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000151, mae: 0.008164, mean_q: 0.016611
 97455/100000: episode: 13610, duration: 0.035s, episode steps: 6, steps per second: 170, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000154, mae: 0.005469, mean_q: 0.008545
 97458/100000: episode: 13611, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000429, mae: 0.007308, mean_q: 0.009872
 97461/100000: episode: 13612, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000055, mae: 0.004610, mean_q: 0.008358
 97467/100000: episode: 13613, duration: 0.031s, episode steps: 6, steps per second: 197, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000088, mae: 0.006703, mean_q: 0.011645
 97470/100000: episode: 13614, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000080, mae: 0.005811, mean_q: 0.010819
 97473/100000: episode: 13615, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000047, mae: 0.004285, mean_q: 0.010354
 97479/100000: episode: 13616, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000079, mae: 0.005512, mean_q: 0.007616
 97482/100000: episode: 13617, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000081, mae: 0.005919, mean_q: 0.008688
 97488/100000: episode: 13618, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000098, mae: 0.006658, mean_q: 0.013376
 97491/100000: episode: 13619, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000845, mae: 0.011023, mean_q: 0.017497
 97494/100000: episode: 13620, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000557, mae: 0.010798, mean_q: 0.022500
 97497/100000: episode: 13621, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000545, mae: 0.010213, mean_q: 0.013258
 97503/100000: episode: 13622, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000049, mae: 0.003895, mean_q: 0.005632
 97506/100000: episode: 13623, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000110, mae: 0.006251, mean_q: 0.007851
 97512/100000: episode: 13624, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000085, mae: 0.005489, mean_q: 0.010575
 97515/100000: episode: 13625, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000052, mae: 0.004708, mean_q: 0.006882
 97518/100000: episode: 13626, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000088, mae: 0.005933, mean_q: 0.011536
 97521/100000: episode: 13627, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000924, mae: 0.008987, mean_q: 0.013071
 97524/100000: episode: 13628, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001420, mae: 0.013079, mean_q: 0.018428
 97527/100000: episode: 13629, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001412, mae: 0.013849, mean_q: 0.023109
 97530/100000: episode: 13630, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000480, mae: 0.010290, mean_q: 0.013529
 97533/100000: episode: 13631, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000077, mae: 0.006704, mean_q: 0.014468
 97536/100000: episode: 13632, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000078, mae: 0.005546, mean_q: 0.009352
 97540/100000: episode: 13633, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000568, mae: 0.008282, mean_q: 0.012422
 97546/100000: episode: 13634, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000101, mae: 0.007076, mean_q: 0.012320
 97549/100000: episode: 13635, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000066, mae: 0.005648, mean_q: 0.008922
 97553/100000: episode: 13636, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000283, mae: 0.006716, mean_q: 0.009182
 97556/100000: episode: 13637, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000363, mae: 0.008641, mean_q: 0.014406
 97562/100000: episode: 13638, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000448, mae: 0.011342, mean_q: 0.022425
[Info] 2-TH LEVEL FOUND: 0.11148956418037415, Considering 13/100 traces
 97565/100000: episode: 13639, duration: 0.775s, episode steps: 3, steps per second: 4, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001397, mae: 0.014408, mean_q: 0.028310
 97570/100000: episode: 13640, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000337, mae: 0.009634, mean_q: 0.019468
 97572/100000: episode: 13641, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001828, mae: 0.021659, mean_q: 0.044936
 97577/100000: episode: 13642, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000071, mae: 0.005184, mean_q: 0.007660
 97582/100000: episode: 13643, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000412, mae: 0.008972, mean_q: 0.008714
 97584/100000: episode: 13644, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000086, mae: 0.007238, mean_q: 0.005793
[Info] FALSIFICATION!
 97588/100000: episode: 13645, duration: 0.317s, episode steps: 4, steps per second: 13, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000071, mae: 0.004835, mean_q: 0.007939
 97593/100000: episode: 13646, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001047, mae: 0.011925, mean_q: 0.020541
 97595/100000: episode: 13647, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000078, mae: 0.006622, mean_q: 0.011461
 97597/100000: episode: 13648, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000074, mae: 0.005872, mean_q: 0.009315
 97602/100000: episode: 13649, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000310, mae: 0.007822, mean_q: 0.014958
 97607/100000: episode: 13650, duration: 0.029s, episode steps: 5, steps per second: 173, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000148, mae: 0.007857, mean_q: 0.014238
 97612/100000: episode: 13651, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000059, mae: 0.004742, mean_q: 0.007956
[Info] FALSIFICATION!
 97616/100000: episode: 13652, duration: 0.203s, episode steps: 4, steps per second: 20, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000090, mae: 0.006481, mean_q: 0.010420
 97618/100000: episode: 13653, duration: 0.015s, episode steps: 2, steps per second: 135, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000507, mae: 0.009296, mean_q: 0.012782
 97620/100000: episode: 13654, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000629, mae: 0.010228, mean_q: 0.018872
 97625/100000: episode: 13655, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000424, mae: 0.010419, mean_q: 0.020363
 97630/100000: episode: 13656, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000301, mae: 0.008649, mean_q: 0.021628
 97635/100000: episode: 13657, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000876, mae: 0.009068, mean_q: 0.022544
 97640/100000: episode: 13658, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000220, mae: 0.008385, mean_q: 0.024246
 97645/100000: episode: 13659, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000393, mae: 0.009079, mean_q: 0.021799
[Info] FALSIFICATION!
 97649/100000: episode: 13660, duration: 0.283s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000067, mae: 0.005942, mean_q: 0.018867
[Info] FALSIFICATION!
 97653/100000: episode: 13661, duration: 0.292s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000326, mae: 0.006679, mean_q: 0.013504
 97658/100000: episode: 13662, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000149, mae: 0.008154, mean_q: 0.015594
 97663/100000: episode: 13663, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000281, mae: 0.007072, mean_q: 0.009816
 97668/100000: episode: 13664, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000143, mae: 0.006750, mean_q: 0.016200
 97673/100000: episode: 13665, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000169, mae: 0.008192, mean_q: 0.017740
 97678/100000: episode: 13666, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000663, mae: 0.010656, mean_q: 0.030289
 97680/100000: episode: 13667, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000182, mae: 0.007838, mean_q: 0.012611
 97685/100000: episode: 13668, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000213, mae: 0.007106, mean_q: 0.015224
 97690/100000: episode: 13669, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000703, mae: 0.014626, mean_q: 0.020091
 97692/100000: episode: 13670, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001802, mae: 0.019804, mean_q: 0.015746
 97697/100000: episode: 13671, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000873, mae: 0.015601, mean_q: 0.006598
 97702/100000: episode: 13672, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000476, mae: 0.010573, mean_q: 0.012765
 97707/100000: episode: 13673, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000366, mae: 0.012529, mean_q: 0.018390
 97712/100000: episode: 13674, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000162, mae: 0.010402, mean_q: 0.015333
 97717/100000: episode: 13675, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000573, mae: 0.012570, mean_q: 0.019618
 97722/100000: episode: 13676, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001084, mae: 0.018157, mean_q: 0.036695
 97727/100000: episode: 13677, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000318, mae: 0.010638, mean_q: 0.010994
 97729/100000: episode: 13678, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000879, mae: 0.013445, mean_q: 0.012149
 97734/100000: episode: 13679, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000174, mae: 0.009968, mean_q: 0.012838
 97736/100000: episode: 13680, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001177, mae: 0.018855, mean_q: 0.024379
 97741/100000: episode: 13681, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000998, mae: 0.019012, mean_q: 0.029079
 97746/100000: episode: 13682, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001483, mae: 0.020821, mean_q: 0.036726
 97748/100000: episode: 13683, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000570, mae: 0.014519, mean_q: 0.031353
 97753/100000: episode: 13684, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000927, mae: 0.014617, mean_q: 0.026818
[Info] FALSIFICATION!
 97757/100000: episode: 13685, duration: 0.189s, episode steps: 4, steps per second: 21, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000347, mae: 0.010349, mean_q: 0.014545
 97762/100000: episode: 13686, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000211, mae: 0.009659, mean_q: 0.016333
 97764/100000: episode: 13687, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002383, mae: 0.018085, mean_q: 0.026627
 97766/100000: episode: 13688, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000682, mae: 0.013834, mean_q: 0.017668
 97771/100000: episode: 13689, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000791, mae: 0.010977, mean_q: 0.017509
[Info] FALSIFICATION!
 97775/100000: episode: 13690, duration: 0.283s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001868, mae: 0.013049, mean_q: 0.019197
 97780/100000: episode: 13691, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000465, mae: 0.009451, mean_q: 0.017377
 97785/100000: episode: 13692, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000316, mae: 0.009449, mean_q: 0.011979
 97787/100000: episode: 13693, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000831, mae: 0.017912, mean_q: 0.037570
 97792/100000: episode: 13694, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001101, mae: 0.016082, mean_q: 0.027837
 97794/100000: episode: 13695, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000726, mae: 0.011641, mean_q: 0.018829
 97796/100000: episode: 13696, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001042, mae: 0.017567, mean_q: 0.027224
 97798/100000: episode: 13697, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000508, mae: 0.010908, mean_q: 0.010710
 97803/100000: episode: 13698, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000317, mae: 0.012115, mean_q: 0.027212
 97805/100000: episode: 13699, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001074, mae: 0.020330, mean_q: 0.030686
 97807/100000: episode: 13700, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001052, mae: 0.020590, mean_q: 0.032603
 97812/100000: episode: 13701, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000265, mae: 0.011097, mean_q: 0.017733
 97817/100000: episode: 13702, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000241, mae: 0.010730, mean_q: 0.018640
 97822/100000: episode: 13703, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.001724, mae: 0.015136, mean_q: 0.028411
 97827/100000: episode: 13704, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000194, mae: 0.010156, mean_q: 0.008059
 97829/100000: episode: 13705, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000695, mae: 0.015985, mean_q: 0.037678
 97834/100000: episode: 13706, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000475, mae: 0.010216, mean_q: 0.017957
 97836/100000: episode: 13707, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001423, mae: 0.017665, mean_q: 0.031409
 97841/100000: episode: 13708, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000197, mae: 0.009790, mean_q: 0.017832
 97846/100000: episode: 13709, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000110, mae: 0.009562, mean_q: 0.014114
 97851/100000: episode: 13710, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000349, mae: 0.013631, mean_q: 0.023373
 97853/100000: episode: 13711, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002347, mae: 0.017097, mean_q: 0.028127
 97858/100000: episode: 13712, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000316, mae: 0.010824, mean_q: 0.014295
 97860/100000: episode: 13713, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000558, mae: 0.011844, mean_q: 0.013002
 97865/100000: episode: 13714, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000339, mae: 0.012440, mean_q: 0.015663
 97867/100000: episode: 13715, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001570, mae: 0.024700, mean_q: 0.031962
 97869/100000: episode: 13716, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000149, mae: 0.009442, mean_q: 0.017354
 97874/100000: episode: 13717, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000172, mae: 0.010146, mean_q: 0.015296
 97876/100000: episode: 13718, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000092, mae: 0.006366, mean_q: 0.009467
 97878/100000: episode: 13719, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000218, mae: 0.010119, mean_q: 0.019653
[Info] FALSIFICATION!
 97882/100000: episode: 13720, duration: 0.291s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000573, mae: 0.012669, mean_q: 0.015543
 97884/100000: episode: 13721, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000884, mae: 0.011080, mean_q: 0.032087
 97886/100000: episode: 13722, duration: 0.014s, episode steps: 2, steps per second: 140, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000185, mae: 0.008776, mean_q: 0.012316
 97891/100000: episode: 13723, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000751, mae: 0.012928, mean_q: 0.025160
 97893/100000: episode: 13724, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001477, mae: 0.012667, mean_q: 0.019365
 97895/100000: episode: 13725, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001058, mae: 0.014855, mean_q: 0.022312
[Info] Complete ISplit Iteration
[Info] Levels: [0.022349339, 0.111489564, 1.2340733]
[Info] Cond. Prob: [0.12, 0.13, 0.07]
[Info] Error Prob: 0.001092

 97900/100000: episode: 13726, duration: 0.895s, episode steps: 5, steps per second: 6, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001602, mae: 0.018169, mean_q: 0.028356
 97910/100000: episode: 13727, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001051, mae: 0.013365, mean_q: 0.018351
 97920/100000: episode: 13728, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000679, mae: 0.011706, mean_q: 0.018566
 97930/100000: episode: 13729, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001110, mae: 0.015216, mean_q: 0.025679
 97940/100000: episode: 13730, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000771, mae: 0.013602, mean_q: 0.020536
 97950/100000: episode: 13731, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000784, mae: 0.011673, mean_q: 0.014781
 97960/100000: episode: 13732, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001654, mae: 0.016194, mean_q: 0.021143
 97970/100000: episode: 13733, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001111, mae: 0.019883, mean_q: 0.039254
 97980/100000: episode: 13734, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000573, mae: 0.012776, mean_q: 0.020003
 97990/100000: episode: 13735, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001268, mae: 0.015361, mean_q: 0.024978
 98000/100000: episode: 13736, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000880, mae: 0.013906, mean_q: 0.027593
 98010/100000: episode: 13737, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001323, mae: 0.015667, mean_q: 0.031638
 98020/100000: episode: 13738, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001072, mae: 0.013169, mean_q: 0.018504
 98030/100000: episode: 13739, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000365, mae: 0.012220, mean_q: 0.021685
 98040/100000: episode: 13740, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000649, mae: 0.014349, mean_q: 0.029719
 98050/100000: episode: 13741, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000561, mae: 0.010846, mean_q: 0.022014
 98060/100000: episode: 13742, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000463, mae: 0.010902, mean_q: 0.015431
 98070/100000: episode: 13743, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001641, mae: 0.016769, mean_q: 0.026381
 98080/100000: episode: 13744, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001124, mae: 0.016526, mean_q: 0.024632
 98090/100000: episode: 13745, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000606, mae: 0.013086, mean_q: 0.027454
 98100/100000: episode: 13746, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001469, mae: 0.014565, mean_q: 0.023066
 98110/100000: episode: 13747, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000696, mae: 0.013147, mean_q: 0.022202
 98120/100000: episode: 13748, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001560, mae: 0.017845, mean_q: 0.028799
 98130/100000: episode: 13749, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000973, mae: 0.014637, mean_q: 0.026052
 98140/100000: episode: 13750, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000272, mae: 0.009239, mean_q: 0.015523
 98150/100000: episode: 13751, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001737, mae: 0.015232, mean_q: 0.016938
 98160/100000: episode: 13752, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000319, mae: 0.010073, mean_q: 0.014631
 98170/100000: episode: 13753, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001080, mae: 0.018816, mean_q: 0.035006
 98180/100000: episode: 13754, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000967, mae: 0.014661, mean_q: 0.024523
 98190/100000: episode: 13755, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000489, mae: 0.009568, mean_q: 0.015904
 98200/100000: episode: 13756, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000738, mae: 0.010335, mean_q: 0.018883
 98210/100000: episode: 13757, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001566, mae: 0.016597, mean_q: 0.022839
 98220/100000: episode: 13758, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001033, mae: 0.017857, mean_q: 0.030232
 98230/100000: episode: 13759, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001251, mae: 0.013692, mean_q: 0.020304
 98240/100000: episode: 13760, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000426, mae: 0.012490, mean_q: 0.033399
 98250/100000: episode: 13761, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001451, mae: 0.015995, mean_q: 0.031961
 98260/100000: episode: 13762, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000858, mae: 0.013540, mean_q: 0.021201
 98270/100000: episode: 13763, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001201, mae: 0.012172, mean_q: 0.016867
 98280/100000: episode: 13764, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000385, mae: 0.013025, mean_q: 0.026238
 98290/100000: episode: 13765, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000619, mae: 0.010321, mean_q: 0.021332
 98300/100000: episode: 13766, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000971, mae: 0.012857, mean_q: 0.022516
 98310/100000: episode: 13767, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001948, mae: 0.021255, mean_q: 0.032585
 98320/100000: episode: 13768, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000636, mae: 0.013289, mean_q: 0.017943
 98330/100000: episode: 13769, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000728, mae: 0.012984, mean_q: 0.016391
 98340/100000: episode: 13770, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000678, mae: 0.014973, mean_q: 0.023504
 98350/100000: episode: 13771, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000764, mae: 0.014914, mean_q: 0.023606
 98360/100000: episode: 13772, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002068, mae: 0.022820, mean_q: 0.045254
 98370/100000: episode: 13773, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001495, mae: 0.014869, mean_q: 0.025504
 98380/100000: episode: 13774, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001028, mae: 0.015465, mean_q: 0.026220
 98390/100000: episode: 13775, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000499, mae: 0.011248, mean_q: 0.019237
 98400/100000: episode: 13776, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000958, mae: 0.015015, mean_q: 0.028170
 98410/100000: episode: 13777, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000938, mae: 0.013826, mean_q: 0.030406
 98420/100000: episode: 13778, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000661, mae: 0.011766, mean_q: 0.020191
 98430/100000: episode: 13779, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000442, mae: 0.009751, mean_q: 0.023727
 98440/100000: episode: 13780, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000726, mae: 0.012226, mean_q: 0.023239
 98450/100000: episode: 13781, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000566, mae: 0.010795, mean_q: 0.019808
 98460/100000: episode: 13782, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000639, mae: 0.011292, mean_q: 0.025964
 98470/100000: episode: 13783, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000912, mae: 0.012123, mean_q: 0.019620
 98480/100000: episode: 13784, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001101, mae: 0.015324, mean_q: 0.029624
 98490/100000: episode: 13785, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000912, mae: 0.013829, mean_q: 0.022675
 98500/100000: episode: 13786, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000684, mae: 0.012527, mean_q: 0.021569
 98510/100000: episode: 13787, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000564, mae: 0.011404, mean_q: 0.018714
 98520/100000: episode: 13788, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000426, mae: 0.009739, mean_q: 0.015411
 98530/100000: episode: 13789, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000779, mae: 0.013587, mean_q: 0.022219
 98540/100000: episode: 13790, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000622, mae: 0.014783, mean_q: 0.028895
 98550/100000: episode: 13791, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000782, mae: 0.013234, mean_q: 0.030723
 98560/100000: episode: 13792, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000584, mae: 0.011051, mean_q: 0.017172
 98570/100000: episode: 13793, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001579, mae: 0.014849, mean_q: 0.020866
 98580/100000: episode: 13794, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000603, mae: 0.008700, mean_q: 0.016746
 98590/100000: episode: 13795, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000444, mae: 0.011265, mean_q: 0.018246
 98600/100000: episode: 13796, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000359, mae: 0.010369, mean_q: 0.017486
 98610/100000: episode: 13797, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001277, mae: 0.017181, mean_q: 0.031555
 98620/100000: episode: 13798, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000654, mae: 0.009664, mean_q: 0.015037
 98630/100000: episode: 13799, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000958, mae: 0.012243, mean_q: 0.020986
 98640/100000: episode: 13800, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000864, mae: 0.015148, mean_q: 0.026156
 98650/100000: episode: 13801, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000474, mae: 0.012050, mean_q: 0.021120
 98660/100000: episode: 13802, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000887, mae: 0.015022, mean_q: 0.029720
 98670/100000: episode: 13803, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001207, mae: 0.013241, mean_q: 0.025468
 98680/100000: episode: 13804, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000751, mae: 0.014114, mean_q: 0.027845
 98690/100000: episode: 13805, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001227, mae: 0.014885, mean_q: 0.023066
 98700/100000: episode: 13806, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000515, mae: 0.011203, mean_q: 0.024895
 98710/100000: episode: 13807, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000918, mae: 0.011222, mean_q: 0.027729
 98720/100000: episode: 13808, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000828, mae: 0.012422, mean_q: 0.022336
 98730/100000: episode: 13809, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000541, mae: 0.011462, mean_q: 0.022022
 98740/100000: episode: 13810, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000770, mae: 0.011538, mean_q: 0.022767
 98750/100000: episode: 13811, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001303, mae: 0.015543, mean_q: 0.027274
 98760/100000: episode: 13812, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001156, mae: 0.015964, mean_q: 0.030774
 98770/100000: episode: 13813, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001021, mae: 0.011380, mean_q: 0.018788
 98780/100000: episode: 13814, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000970, mae: 0.012672, mean_q: 0.017672
 98790/100000: episode: 13815, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000900, mae: 0.014663, mean_q: 0.022403
 98800/100000: episode: 13816, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001123, mae: 0.017696, mean_q: 0.030992
 98810/100000: episode: 13817, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001405, mae: 0.015956, mean_q: 0.027043
 98820/100000: episode: 13818, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001430, mae: 0.016828, mean_q: 0.026913
 98830/100000: episode: 13819, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000939, mae: 0.012707, mean_q: 0.021824
 98840/100000: episode: 13820, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000763, mae: 0.013514, mean_q: 0.027599
 98850/100000: episode: 13821, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001103, mae: 0.011253, mean_q: 0.013203
 98860/100000: episode: 13822, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000293, mae: 0.011042, mean_q: 0.017796
 98870/100000: episode: 13823, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000552, mae: 0.013268, mean_q: 0.029685
 98880/100000: episode: 13824, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001342, mae: 0.015844, mean_q: 0.035938
 98890/100000: episode: 13825, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000436, mae: 0.010678, mean_q: 0.011851
[Info] 1-TH LEVEL FOUND: 0.007034221664071083, Considering 100/100 traces
 98900/100000: episode: 13826, duration: 0.864s, episode steps: 10, steps per second: 12, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000898, mae: 0.011494, mean_q: 0.017258
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.007034221664071083
 98910/100000: episode: 13827, duration: 0.617s, episode steps: 10, steps per second: 16, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000612, mae: 0.013524, mean_q: 0.024016
 98920/100000: episode: 13828, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000621, mae: 0.013053, mean_q: 0.023078
 98930/100000: episode: 13829, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000406, mae: 0.010146, mean_q: 0.019974
 98940/100000: episode: 13830, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000704, mae: 0.014260, mean_q: 0.024139
 98950/100000: episode: 13831, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000267, mae: 0.010898, mean_q: 0.024069
 98960/100000: episode: 13832, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000691, mae: 0.011314, mean_q: 0.019629
 98970/100000: episode: 13833, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000760, mae: 0.010763, mean_q: 0.018456
 98980/100000: episode: 13834, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002221, mae: 0.017779, mean_q: 0.028839
 98990/100000: episode: 13835, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000998, mae: 0.015501, mean_q: 0.027592
 99000/100000: episode: 13836, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000440, mae: 0.010454, mean_q: 0.018734
 99010/100000: episode: 13837, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000528, mae: 0.010550, mean_q: 0.020877
 99020/100000: episode: 13838, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000485, mae: 0.012678, mean_q: 0.025262
 99030/100000: episode: 13839, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000559, mae: 0.013527, mean_q: 0.031840
 99040/100000: episode: 13840, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000592, mae: 0.012208, mean_q: 0.024434
 99050/100000: episode: 13841, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001184, mae: 0.013756, mean_q: 0.024676
 99060/100000: episode: 13842, duration: 0.064s, episode steps: 10, steps per second: 155, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001481, mae: 0.016604, mean_q: 0.025832
 99070/100000: episode: 13843, duration: 0.078s, episode steps: 10, steps per second: 129, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000585, mae: 0.009623, mean_q: 0.014428
 99080/100000: episode: 13844, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001561, mae: 0.015880, mean_q: 0.025268
 99090/100000: episode: 13845, duration: 0.072s, episode steps: 10, steps per second: 140, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000741, mae: 0.011879, mean_q: 0.014567
 99100/100000: episode: 13846, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001354, mae: 0.017400, mean_q: 0.024996
 99110/100000: episode: 13847, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000465, mae: 0.014044, mean_q: 0.025384
 99120/100000: episode: 13848, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001309, mae: 0.014334, mean_q: 0.024382
 99130/100000: episode: 13849, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000680, mae: 0.013295, mean_q: 0.015135
 99140/100000: episode: 13850, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000353, mae: 0.007502, mean_q: 0.008383
 99150/100000: episode: 13851, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000683, mae: 0.011200, mean_q: 0.016935
 99160/100000: episode: 13852, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000450, mae: 0.013399, mean_q: 0.024682
 99170/100000: episode: 13853, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000617, mae: 0.013617, mean_q: 0.024038
 99180/100000: episode: 13854, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000820, mae: 0.012324, mean_q: 0.023929
 99190/100000: episode: 13855, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000440, mae: 0.009633, mean_q: 0.027397
 99200/100000: episode: 13856, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000271, mae: 0.007698, mean_q: 0.014024
 99210/100000: episode: 13857, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001550, mae: 0.018654, mean_q: 0.037199
 99220/100000: episode: 13858, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001141, mae: 0.014815, mean_q: 0.027987
 99230/100000: episode: 13859, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000452, mae: 0.011289, mean_q: 0.014429
 99240/100000: episode: 13860, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000540, mae: 0.013100, mean_q: 0.034530
 99250/100000: episode: 13861, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001581, mae: 0.018753, mean_q: 0.035528
 99260/100000: episode: 13862, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001186, mae: 0.016901, mean_q: 0.031451
 99270/100000: episode: 13863, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001006, mae: 0.013409, mean_q: 0.022583
 99280/100000: episode: 13864, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001081, mae: 0.013836, mean_q: 0.022147
 99290/100000: episode: 13865, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000235, mae: 0.009999, mean_q: 0.014729
 99300/100000: episode: 13866, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000619, mae: 0.012686, mean_q: 0.030725
 99310/100000: episode: 13867, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000441, mae: 0.008135, mean_q: 0.014963
 99320/100000: episode: 13868, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001307, mae: 0.014630, mean_q: 0.017770
 99330/100000: episode: 13869, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000474, mae: 0.008703, mean_q: 0.012652
 99340/100000: episode: 13870, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000763, mae: 0.012058, mean_q: 0.017700
 99350/100000: episode: 13871, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001006, mae: 0.014673, mean_q: 0.022146
 99360/100000: episode: 13872, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000765, mae: 0.012370, mean_q: 0.017620
 99370/100000: episode: 13873, duration: 0.069s, episode steps: 10, steps per second: 146, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000387, mae: 0.010478, mean_q: 0.016813
 99380/100000: episode: 13874, duration: 0.067s, episode steps: 10, steps per second: 148, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000267, mae: 0.009797, mean_q: 0.020484
 99390/100000: episode: 13875, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000390, mae: 0.009551, mean_q: 0.018146
 99400/100000: episode: 13876, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000562, mae: 0.010405, mean_q: 0.023289
 99410/100000: episode: 13877, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001154, mae: 0.013282, mean_q: 0.022659
 99420/100000: episode: 13878, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000480, mae: 0.007283, mean_q: 0.013609
 99430/100000: episode: 13879, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000191, mae: 0.006584, mean_q: 0.010946
 99440/100000: episode: 13880, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000814, mae: 0.012407, mean_q: 0.021049
 99450/100000: episode: 13881, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000804, mae: 0.015770, mean_q: 0.027749
 99460/100000: episode: 13882, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000594, mae: 0.012502, mean_q: 0.026352
 99470/100000: episode: 13883, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000930, mae: 0.012723, mean_q: 0.028548
 99480/100000: episode: 13884, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000892, mae: 0.011363, mean_q: 0.016922
 99490/100000: episode: 13885, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000828, mae: 0.011919, mean_q: 0.023117
 99500/100000: episode: 13886, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000304, mae: 0.007151, mean_q: 0.010272
 99510/100000: episode: 13887, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000989, mae: 0.013571, mean_q: 0.021281
 99520/100000: episode: 13888, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000840, mae: 0.011006, mean_q: 0.020629
 99530/100000: episode: 13889, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000813, mae: 0.007525, mean_q: 0.013163
 99540/100000: episode: 13890, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000893, mae: 0.014332, mean_q: 0.022700
 99550/100000: episode: 13891, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000666, mae: 0.012073, mean_q: 0.020896
 99560/100000: episode: 13892, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000831, mae: 0.011343, mean_q: 0.018161
 99570/100000: episode: 13893, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000869, mae: 0.010504, mean_q: 0.018987
 99580/100000: episode: 13894, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000583, mae: 0.009630, mean_q: 0.015095
 99590/100000: episode: 13895, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000629, mae: 0.009964, mean_q: 0.015831
 99600/100000: episode: 13896, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000397, mae: 0.009734, mean_q: 0.016052
 99610/100000: episode: 13897, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001114, mae: 0.014635, mean_q: 0.027822
 99620/100000: episode: 13898, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000346, mae: 0.007592, mean_q: 0.015843
 99630/100000: episode: 13899, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000256, mae: 0.006610, mean_q: 0.011899
 99640/100000: episode: 13900, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000141, mae: 0.005686, mean_q: 0.011977
 99650/100000: episode: 13901, duration: 0.060s, episode steps: 10, steps per second: 165, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000236, mae: 0.006596, mean_q: 0.011900
 99660/100000: episode: 13902, duration: 0.062s, episode steps: 10, steps per second: 163, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001657, mae: 0.015827, mean_q: 0.034313
 99670/100000: episode: 13903, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000294, mae: 0.008828, mean_q: 0.020076
 99680/100000: episode: 13904, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000707, mae: 0.010953, mean_q: 0.026556
 99690/100000: episode: 13905, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000674, mae: 0.008880, mean_q: 0.020957
 99700/100000: episode: 13906, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000887, mae: 0.011260, mean_q: 0.014037
 99710/100000: episode: 13907, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000231, mae: 0.005911, mean_q: 0.009017
 99720/100000: episode: 13908, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000461, mae: 0.007006, mean_q: 0.012301
 99730/100000: episode: 13909, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000272, mae: 0.007336, mean_q: 0.014456
 99740/100000: episode: 13910, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001227, mae: 0.012532, mean_q: 0.021769
 99750/100000: episode: 13911, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000881, mae: 0.011329, mean_q: 0.019677
 99760/100000: episode: 13912, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001036, mae: 0.012384, mean_q: 0.020143
 99770/100000: episode: 13913, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000768, mae: 0.012261, mean_q: 0.020267
 99780/100000: episode: 13914, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000927, mae: 0.011047, mean_q: 0.021587
 99790/100000: episode: 13915, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000490, mae: 0.007047, mean_q: 0.015025
 99800/100000: episode: 13916, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000836, mae: 0.010101, mean_q: 0.019261
 99810/100000: episode: 13917, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000431, mae: 0.008521, mean_q: 0.022070
 99820/100000: episode: 13918, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000647, mae: 0.011241, mean_q: 0.020020
 99830/100000: episode: 13919, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000612, mae: 0.010901, mean_q: 0.015483
 99840/100000: episode: 13920, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001710, mae: 0.012114, mean_q: 0.009533
 99850/100000: episode: 13921, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001006, mae: 0.012528, mean_q: 0.020186
 99860/100000: episode: 13922, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000303, mae: 0.011784, mean_q: 0.018427
 99870/100000: episode: 13923, duration: 0.064s, episode steps: 10, steps per second: 155, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000310, mae: 0.008450, mean_q: 0.021084
 99880/100000: episode: 13924, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000327, mae: 0.007848, mean_q: 0.018749
 99890/100000: episode: 13925, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001618, mae: 0.013498, mean_q: 0.026515
 99900/100000: episode: 13926, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000394, mae: 0.008869, mean_q: 0.016235
[Info] 1-TH LEVEL FOUND: 0.005721254274249077, Considering 100/100 traces
 99910/100000: episode: 13927, duration: 0.774s, episode steps: 10, steps per second: 13, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000938, mae: 0.010440, mean_q: 0.022275
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005721254274249077
 99920/100000: episode: 13928, duration: 0.525s, episode steps: 10, steps per second: 19, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000313, mae: 0.007697, mean_q: 0.016187
 99930/100000: episode: 13929, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000164, mae: 0.005160, mean_q: 0.013099
 99940/100000: episode: 13930, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000557, mae: 0.008975, mean_q: 0.017282
 99950/100000: episode: 13931, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001214, mae: 0.011672, mean_q: 0.025710
 99960/100000: episode: 13932, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000390, mae: 0.008280, mean_q: 0.017619
 99970/100000: episode: 13933, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001002, mae: 0.010798, mean_q: 0.020823
 99980/100000: episode: 13934, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000755, mae: 0.009750, mean_q: 0.017270
 99990/100000: episode: 13935, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001580, mae: 0.015625, mean_q: 0.025321
 100000/100000: episode: 13936, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000756, mae: 0.010938, mean_q: 0.020714
done, took 689.230 seconds
[Info] End Importance Splitting. Falsification occurred 149 times.
