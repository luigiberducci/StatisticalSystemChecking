Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          (None, 2)                 0         
_________________________________________________________________
dense_1 (Dense)              (None, 16)                48        
_________________________________________________________________
dense_2 (Dense)              (None, 8)                 136       
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 9         
=================================================================
Total params: 193
Trainable params: 193
Non-trainable params: 0
_________________________________________________________________
None
[Info] Start Importance Splitting on succruns-v1.
Training for 10000 steps ...
   10/10000: episode: 1, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   20/10000: episode: 2, duration: 0.005s, episode steps: 10, steps per second: 1919, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   30/10000: episode: 3, duration: 0.005s, episode steps: 10, steps per second: 2026, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   40/10000: episode: 4, duration: 0.005s, episode steps: 10, steps per second: 2166, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   50/10000: episode: 5, duration: 0.005s, episode steps: 10, steps per second: 2038, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   60/10000: episode: 6, duration: 0.005s, episode steps: 10, steps per second: 2049, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   70/10000: episode: 7, duration: 0.005s, episode steps: 10, steps per second: 2132, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   80/10000: episode: 8, duration: 0.005s, episode steps: 10, steps per second: 2072, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   90/10000: episode: 9, duration: 0.005s, episode steps: 10, steps per second: 2079, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  100/10000: episode: 10, duration: 0.005s, episode steps: 10, steps per second: 2081, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  110/10000: episode: 11, duration: 0.005s, episode steps: 10, steps per second: 2058, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  120/10000: episode: 12, duration: 0.005s, episode steps: 10, steps per second: 2122, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  130/10000: episode: 13, duration: 0.005s, episode steps: 10, steps per second: 2122, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  140/10000: episode: 14, duration: 0.005s, episode steps: 10, steps per second: 2106, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  150/10000: episode: 15, duration: 0.005s, episode steps: 10, steps per second: 2118, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  160/10000: episode: 16, duration: 0.005s, episode steps: 10, steps per second: 2140, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  170/10000: episode: 17, duration: 0.005s, episode steps: 10, steps per second: 2104, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  180/10000: episode: 18, duration: 0.005s, episode steps: 10, steps per second: 2137, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  190/10000: episode: 19, duration: 0.005s, episode steps: 10, steps per second: 2107, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  200/10000: episode: 20, duration: 0.005s, episode steps: 10, steps per second: 2160, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  210/10000: episode: 21, duration: 0.005s, episode steps: 10, steps per second: 2057, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  220/10000: episode: 22, duration: 0.005s, episode steps: 10, steps per second: 2222, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  230/10000: episode: 23, duration: 0.005s, episode steps: 10, steps per second: 2176, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  240/10000: episode: 24, duration: 0.005s, episode steps: 10, steps per second: 2217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  250/10000: episode: 25, duration: 0.005s, episode steps: 10, steps per second: 2165, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  260/10000: episode: 26, duration: 0.005s, episode steps: 10, steps per second: 2194, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  270/10000: episode: 27, duration: 0.005s, episode steps: 10, steps per second: 2089, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  280/10000: episode: 28, duration: 0.005s, episode steps: 10, steps per second: 2119, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  290/10000: episode: 29, duration: 0.005s, episode steps: 10, steps per second: 2124, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  300/10000: episode: 30, duration: 0.005s, episode steps: 10, steps per second: 2142, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  310/10000: episode: 31, duration: 0.005s, episode steps: 10, steps per second: 2121, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  320/10000: episode: 32, duration: 0.005s, episode steps: 10, steps per second: 2196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  330/10000: episode: 33, duration: 0.005s, episode steps: 10, steps per second: 2138, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  340/10000: episode: 34, duration: 0.005s, episode steps: 10, steps per second: 2105, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  350/10000: episode: 35, duration: 0.005s, episode steps: 10, steps per second: 2138, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  360/10000: episode: 36, duration: 0.005s, episode steps: 10, steps per second: 2159, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  370/10000: episode: 37, duration: 0.005s, episode steps: 10, steps per second: 2151, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  380/10000: episode: 38, duration: 0.005s, episode steps: 10, steps per second: 2183, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  390/10000: episode: 39, duration: 0.005s, episode steps: 10, steps per second: 2151, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  400/10000: episode: 40, duration: 0.005s, episode steps: 10, steps per second: 2155, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  410/10000: episode: 41, duration: 0.005s, episode steps: 10, steps per second: 2110, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  420/10000: episode: 42, duration: 0.005s, episode steps: 10, steps per second: 2133, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  430/10000: episode: 43, duration: 0.005s, episode steps: 10, steps per second: 2127, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  440/10000: episode: 44, duration: 0.005s, episode steps: 10, steps per second: 2197, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  450/10000: episode: 45, duration: 0.005s, episode steps: 10, steps per second: 2132, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  460/10000: episode: 46, duration: 0.005s, episode steps: 10, steps per second: 2192, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  470/10000: episode: 47, duration: 0.005s, episode steps: 10, steps per second: 2193, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  480/10000: episode: 48, duration: 0.005s, episode steps: 10, steps per second: 2134, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  490/10000: episode: 49, duration: 0.005s, episode steps: 10, steps per second: 2097, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  500/10000: episode: 50, duration: 0.005s, episode steps: 10, steps per second: 2092, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  510/10000: episode: 51, duration: 0.595s, episode steps: 10, steps per second: 17, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.010622, mae: 0.100041, mean_q: -0.045075
  520/10000: episode: 52, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.006476, mae: 0.075241, mean_q: -0.048015
  530/10000: episode: 53, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.003694, mae: 0.059570, mean_q: -0.036237
  540/10000: episode: 54, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003431, mae: 0.060565, mean_q: -0.025056
  550/10000: episode: 55, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001923, mae: 0.046880, mean_q: -0.042462
  560/10000: episode: 56, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002423, mae: 0.051896, mean_q: -0.036980
  570/10000: episode: 57, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001928, mae: 0.044944, mean_q: -0.038798
  580/10000: episode: 58, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001578, mae: 0.043844, mean_q: -0.030430
  590/10000: episode: 59, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001771, mae: 0.044455, mean_q: -0.037177
  600/10000: episode: 60, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001275, mae: 0.037248, mean_q: -0.026943
  610/10000: episode: 61, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001168, mae: 0.035700, mean_q: -0.031898
  620/10000: episode: 62, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001356, mae: 0.038193, mean_q: -0.029012
  630/10000: episode: 63, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000939, mae: 0.033560, mean_q: -0.017717
  640/10000: episode: 64, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000835, mae: 0.031523, mean_q: -0.022819
  650/10000: episode: 65, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000806, mae: 0.029589, mean_q: -0.026453
  660/10000: episode: 66, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000674, mae: 0.027402, mean_q: -0.022292
  670/10000: episode: 67, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000695, mae: 0.027164, mean_q: -0.019693
  680/10000: episode: 68, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000631, mae: 0.026286, mean_q: -0.019398
  690/10000: episode: 69, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000536, mae: 0.024310, mean_q: -0.016460
  700/10000: episode: 70, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000527, mae: 0.023611, mean_q: -0.009904
  710/10000: episode: 71, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000319, mae: 0.019247, mean_q: -0.016320
  720/10000: episode: 72, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000354, mae: 0.020046, mean_q: -0.014568
  730/10000: episode: 73, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000372, mae: 0.020317, mean_q: -0.014014
  740/10000: episode: 74, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000296, mae: 0.018377, mean_q: -0.009826
  750/10000: episode: 75, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000389, mae: 0.019656, mean_q: -0.007701
  760/10000: episode: 76, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000278, mae: 0.017515, mean_q: -0.012974
  770/10000: episode: 77, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000219, mae: 0.016177, mean_q: -0.007093
  780/10000: episode: 78, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000243, mae: 0.016727, mean_q: -0.009391
  790/10000: episode: 79, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000275, mae: 0.016633, mean_q: -0.003683
  800/10000: episode: 80, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000217, mae: 0.013864, mean_q: -0.007461
  810/10000: episode: 81, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000223, mae: 0.015403, mean_q: -0.005193
  820/10000: episode: 82, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000135, mae: 0.012090, mean_q: -0.006279
  830/10000: episode: 83, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000159, mae: 0.013330, mean_q: -0.006474
  840/10000: episode: 84, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000139, mae: 0.012924, mean_q: -0.003847
  850/10000: episode: 85, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000191, mae: 0.012864, mean_q: -0.005226
  860/10000: episode: 86, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000171, mae: 0.012871, mean_q: -0.003648
  870/10000: episode: 87, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000095, mae: 0.010835, mean_q: -0.003675
  880/10000: episode: 88, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000101, mae: 0.010516, mean_q: -0.003147
  890/10000: episode: 89, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000113, mae: 0.010487, mean_q: -0.001307
  900/10000: episode: 90, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000101, mae: 0.010399, mean_q: -0.002140
  910/10000: episode: 91, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000107, mae: 0.010245, mean_q: -0.000592
  920/10000: episode: 92, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000098, mae: 0.010562, mean_q: -0.003166
  930/10000: episode: 93, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000084, mae: 0.009668, mean_q: -0.000807
  940/10000: episode: 94, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000076, mae: 0.008817, mean_q: -0.000410
  950/10000: episode: 95, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000092, mae: 0.008968, mean_q: -0.000890
  960/10000: episode: 96, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000066, mae: 0.008628, mean_q: -0.001552
  970/10000: episode: 97, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000112, mae: 0.009178, mean_q: 0.002253
  980/10000: episode: 98, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000046, mae: 0.007189, mean_q: 0.001089
  990/10000: episode: 99, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000044, mae: 0.006989, mean_q: -0.000702
 1000/10000: episode: 100, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000044, mae: 0.007103, mean_q: -0.000120
 1010/10000: episode: 101, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000031, mae: 0.006123, mean_q: 0.001505
 1020/10000: episode: 102, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000046, mae: 0.006845, mean_q: 0.001956
 1030/10000: episode: 103, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000051, mae: 0.006710, mean_q: 0.002127
 1040/10000: episode: 104, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000042, mae: 0.006489, mean_q: -0.000082
 1050/10000: episode: 105, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000045, mae: 0.006386, mean_q: 0.001961
 1060/10000: episode: 106, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000042, mae: 0.006186, mean_q: 0.001881
 1070/10000: episode: 107, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000031, mae: 0.005208, mean_q: 0.001985
 1080/10000: episode: 108, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000053, mae: 0.005870, mean_q: 0.003133
 1090/10000: episode: 109, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000036, mae: 0.005955, mean_q: 0.001707
 1100/10000: episode: 110, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000060, mae: 0.005737, mean_q: 0.003179
 1110/10000: episode: 111, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000108, mae: 0.006866, mean_q: 0.004629
 1120/10000: episode: 112, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000024, mae: 0.004985, mean_q: 0.002419
 1130/10000: episode: 113, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000025, mae: 0.004963, mean_q: 0.001942
 1140/10000: episode: 114, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000032, mae: 0.005134, mean_q: 0.002628
 1150/10000: episode: 115, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000028, mae: 0.004712, mean_q: 0.003476
 1160/10000: episode: 116, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000026, mae: 0.004487, mean_q: 0.003320
 1170/10000: episode: 117, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000032, mae: 0.004579, mean_q: 0.004097
 1180/10000: episode: 118, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000044, mae: 0.004583, mean_q: 0.002995
 1190/10000: episode: 119, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000019, mae: 0.003629, mean_q: 0.002886
 1200/10000: episode: 120, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000060, mae: 0.005125, mean_q: 0.005369
 1210/10000: episode: 121, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000041, mae: 0.004585, mean_q: 0.002883
 1220/10000: episode: 122, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000021, mae: 0.004377, mean_q: 0.002880
 1230/10000: episode: 123, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000021, mae: 0.004210, mean_q: 0.002459
 1240/10000: episode: 124, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000032, mae: 0.004593, mean_q: 0.003842
 1250/10000: episode: 125, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000026, mae: 0.004399, mean_q: 0.003168
 1260/10000: episode: 126, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000020, mae: 0.003841, mean_q: 0.002654
 1270/10000: episode: 127, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000023, mae: 0.003512, mean_q: 0.003541
 1280/10000: episode: 128, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000014, mae: 0.003057, mean_q: 0.003097
 1290/10000: episode: 129, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000019, mae: 0.003590, mean_q: 0.002819
 1300/10000: episode: 130, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000012, mae: 0.003159, mean_q: 0.003363
 1310/10000: episode: 131, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000020, mae: 0.003891, mean_q: 0.004206
 1320/10000: episode: 132, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000014, mae: 0.003243, mean_q: 0.003207
 1330/10000: episode: 133, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000028, mae: 0.004486, mean_q: 0.004406
 1340/10000: episode: 134, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000050, mae: 0.004990, mean_q: 0.004366
 1350/10000: episode: 135, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000049, mae: 0.004606, mean_q: 0.004351
 1360/10000: episode: 136, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000028, mae: 0.004375, mean_q: 0.003926
 1370/10000: episode: 137, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000048, mae: 0.005435, mean_q: 0.006307
 1380/10000: episode: 138, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000020, mae: 0.004029, mean_q: 0.003871
 1390/10000: episode: 139, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000020, mae: 0.003617, mean_q: 0.002964
 1400/10000: episode: 140, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000017, mae: 0.003045, mean_q: 0.004191
 1410/10000: episode: 141, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000014, mae: 0.002967, mean_q: 0.003634
 1420/10000: episode: 142, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000017, mae: 0.003218, mean_q: 0.003102
 1430/10000: episode: 143, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000016, mae: 0.003121, mean_q: 0.003871
 1440/10000: episode: 144, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000030, mae: 0.005110, mean_q: 0.003489
 1450/10000: episode: 145, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000018, mae: 0.003418, mean_q: 0.005113
 1460/10000: episode: 146, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000023, mae: 0.003566, mean_q: 0.003194
 1470/10000: episode: 147, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000009, mae: 0.002475, mean_q: 0.003137
 1480/10000: episode: 148, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000010, mae: 0.002674, mean_q: 0.004217
 1490/10000: episode: 149, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000023, mae: 0.003787, mean_q: 0.004014
[Info] 1-TH LEVEL FOUND: 0.04639383777976036, Considering 100/100 traces
 1500/10000: episode: 150, duration: 1.064s, episode steps: 10, steps per second: 9, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000012, mae: 0.002956, mean_q: 0.004189
[Info] 2-TH LEVEL FOUND: 0.05165092647075653, Considering 100/100 traces
 1501/10000: episode: 151, duration: 0.658s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000246, mae: 0.006378, mean_q: 0.004030
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.05165092647075653
 1502/10000: episode: 152, duration: 0.442s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000044, mae: 0.006317, mean_q: 0.010242
 1512/10000: episode: 153, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000052, mae: 0.005403, mean_q: 0.003978
 1522/10000: episode: 154, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000062, mae: 0.005736, mean_q: 0.005220
 1532/10000: episode: 155, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000034, mae: 0.004986, mean_q: 0.004482
 1542/10000: episode: 156, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000036, mae: 0.005350, mean_q: 0.005133
 1552/10000: episode: 157, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000020, mae: 0.003676, mean_q: 0.002976
 1562/10000: episode: 158, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000062, mae: 0.006486, mean_q: 0.005499
 1572/10000: episode: 159, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000019, mae: 0.004124, mean_q: 0.004424
 1582/10000: episode: 160, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000040, mae: 0.003932, mean_q: 0.005132
 1592/10000: episode: 161, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000019, mae: 0.004001, mean_q: 0.004012
 1602/10000: episode: 162, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000018, mae: 0.003456, mean_q: 0.003984
 1612/10000: episode: 163, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000018, mae: 0.003918, mean_q: 0.004963
 1622/10000: episode: 164, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000021, mae: 0.003897, mean_q: 0.003413
 1632/10000: episode: 165, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000016, mae: 0.003518, mean_q: 0.003570
 1642/10000: episode: 166, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000023, mae: 0.003421, mean_q: 0.004188
 1652/10000: episode: 167, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000020, mae: 0.003315, mean_q: 0.003590
 1662/10000: episode: 168, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000018, mae: 0.003450, mean_q: 0.004407
 1672/10000: episode: 169, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000021, mae: 0.003502, mean_q: 0.003551
 1682/10000: episode: 170, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000016, mae: 0.002906, mean_q: 0.004644
 1692/10000: episode: 171, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000017, mae: 0.003215, mean_q: 0.003300
 1702/10000: episode: 172, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000020, mae: 0.002928, mean_q: 0.004310
 1712/10000: episode: 173, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000025, mae: 0.003808, mean_q: 0.004716
 1722/10000: episode: 174, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000014, mae: 0.003267, mean_q: 0.003405
 1732/10000: episode: 175, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000019, mae: 0.003507, mean_q: 0.004013
 1742/10000: episode: 176, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000052, mae: 0.005288, mean_q: 0.006048
 1752/10000: episode: 177, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000026, mae: 0.003832, mean_q: 0.003865
 1762/10000: episode: 178, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000022, mae: 0.003649, mean_q: 0.005179
 1772/10000: episode: 179, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000020, mae: 0.003716, mean_q: 0.003208
 1782/10000: episode: 180, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000031, mae: 0.004908, mean_q: 0.004702
 1792/10000: episode: 181, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000017, mae: 0.003493, mean_q: 0.004297
 1802/10000: episode: 182, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000024, mae: 0.003887, mean_q: 0.004450
 1812/10000: episode: 183, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000013, mae: 0.002812, mean_q: 0.003121
 1822/10000: episode: 184, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000030, mae: 0.004370, mean_q: 0.004962
 1832/10000: episode: 185, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000025, mae: 0.004421, mean_q: 0.003748
 1842/10000: episode: 186, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000034, mae: 0.003444, mean_q: 0.004616
 1852/10000: episode: 187, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000021, mae: 0.003482, mean_q: 0.003634
 1862/10000: episode: 188, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000029, mae: 0.004019, mean_q: 0.004084
 1872/10000: episode: 189, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000027, mae: 0.003922, mean_q: 0.004858
 1882/10000: episode: 190, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000019, mae: 0.003650, mean_q: 0.003812
 1892/10000: episode: 191, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000021, mae: 0.003877, mean_q: 0.005389
 1902/10000: episode: 192, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000019, mae: 0.003494, mean_q: 0.004160
 1912/10000: episode: 193, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000029, mae: 0.004589, mean_q: 0.004524
 1922/10000: episode: 194, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000021, mae: 0.003900, mean_q: 0.004039
 1932/10000: episode: 195, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000023, mae: 0.003539, mean_q: 0.003289
 1942/10000: episode: 196, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000050, mae: 0.005330, mean_q: 0.004219
 1952/10000: episode: 197, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000025, mae: 0.004062, mean_q: 0.004678
 1962/10000: episode: 198, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000027, mae: 0.004136, mean_q: 0.003849
 1972/10000: episode: 199, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000024, mae: 0.003961, mean_q: 0.004542
 1982/10000: episode: 200, duration: 0.045s, episode steps: 10, steps per second: 225, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000020, mae: 0.003655, mean_q: 0.004456
 1992/10000: episode: 201, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000017, mae: 0.003128, mean_q: 0.004209
 2002/10000: episode: 202, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000012, mae: 0.003139, mean_q: 0.002967
 2012/10000: episode: 203, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000014, mae: 0.002961, mean_q: 0.003833
 2022/10000: episode: 204, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000016, mae: 0.003349, mean_q: 0.004346
 2032/10000: episode: 205, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000024, mae: 0.004102, mean_q: 0.004563
 2042/10000: episode: 206, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000021, mae: 0.003263, mean_q: 0.004871
 2052/10000: episode: 207, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000016, mae: 0.003073, mean_q: 0.004267
 2062/10000: episode: 208, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000013, mae: 0.002631, mean_q: 0.003252
 2072/10000: episode: 209, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000047, mae: 0.004356, mean_q: 0.005458
 2082/10000: episode: 210, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000052, mae: 0.004504, mean_q: 0.003693
 2092/10000: episode: 211, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000047, mae: 0.005538, mean_q: 0.004746
 2102/10000: episode: 212, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000029, mae: 0.004641, mean_q: 0.005261
 2112/10000: episode: 213, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000038, mae: 0.006147, mean_q: 0.004086
 2122/10000: episode: 214, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000015, mae: 0.003545, mean_q: 0.003353
 2132/10000: episode: 215, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000032, mae: 0.004098, mean_q: 0.005404
 2142/10000: episode: 216, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000017, mae: 0.002886, mean_q: 0.004427
 2152/10000: episode: 217, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000021, mae: 0.003324, mean_q: 0.004863
 2162/10000: episode: 218, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000013, mae: 0.003037, mean_q: 0.004611
 2172/10000: episode: 219, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000021, mae: 0.003701, mean_q: 0.004429
 2182/10000: episode: 220, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000014, mae: 0.002993, mean_q: 0.004461
 2192/10000: episode: 221, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000028, mae: 0.004820, mean_q: 0.004015
 2202/10000: episode: 222, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000030, mae: 0.003984, mean_q: 0.005816
 2212/10000: episode: 223, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000050, mae: 0.004197, mean_q: 0.004179
 2222/10000: episode: 224, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000020, mae: 0.003572, mean_q: 0.004565
 2232/10000: episode: 225, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000035, mae: 0.004852, mean_q: 0.004899
 2242/10000: episode: 226, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000018, mae: 0.003965, mean_q: 0.003724
 2252/10000: episode: 227, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000016, mae: 0.003880, mean_q: 0.004083
 2262/10000: episode: 228, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000054, mae: 0.005588, mean_q: 0.005654
 2272/10000: episode: 229, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000028, mae: 0.004978, mean_q: 0.003041
 2282/10000: episode: 230, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000039, mae: 0.004428, mean_q: 0.005061
 2292/10000: episode: 231, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000048, mae: 0.004517, mean_q: 0.004741
 2302/10000: episode: 232, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000017, mae: 0.003133, mean_q: 0.003408
 2312/10000: episode: 233, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000024, mae: 0.004317, mean_q: 0.004646
 2322/10000: episode: 234, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000035, mae: 0.004921, mean_q: 0.003155
 2332/10000: episode: 235, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000051, mae: 0.006524, mean_q: 0.005743
 2342/10000: episode: 236, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000063, mae: 0.007827, mean_q: 0.005803
 2352/10000: episode: 237, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000120, mae: 0.009285, mean_q: 0.003612
 2362/10000: episode: 238, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000033, mae: 0.005413, mean_q: 0.003715
 2372/10000: episode: 239, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000024, mae: 0.004124, mean_q: 0.004702
 2382/10000: episode: 240, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000019, mae: 0.003207, mean_q: 0.003683
 2392/10000: episode: 241, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000026, mae: 0.004207, mean_q: 0.004094
 2402/10000: episode: 242, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000012, mae: 0.002698, mean_q: 0.003651
 2412/10000: episode: 243, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000043, mae: 0.003530, mean_q: 0.004621
 2422/10000: episode: 244, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000019, mae: 0.003730, mean_q: 0.003693
 2432/10000: episode: 245, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000027, mae: 0.004271, mean_q: 0.004454
 2442/10000: episode: 246, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000041, mae: 0.003447, mean_q: 0.004390
 2452/10000: episode: 247, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000016, mae: 0.003623, mean_q: 0.003524
 2462/10000: episode: 248, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000057, mae: 0.004308, mean_q: 0.006077
 2472/10000: episode: 249, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000043, mae: 0.003902, mean_q: 0.004808
 2482/10000: episode: 250, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000019, mae: 0.003488, mean_q: 0.004266
 2492/10000: episode: 251, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000040, mae: 0.003317, mean_q: 0.003989
[Info] 1-TH LEVEL FOUND: 0.02219691500067711, Considering 12/100 traces
 2502/10000: episode: 252, duration: 0.727s, episode steps: 10, steps per second: 14, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000031, mae: 0.004576, mean_q: 0.005746
 2506/10000: episode: 253, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000039, mae: 0.005969, mean_q: -0.000377
 2508/10000: episode: 254, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000018, mae: 0.004619, mean_q: 0.006263
 2512/10000: episode: 255, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000021, mae: 0.003294, mean_q: 0.004196
 2518/10000: episode: 256, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000018, mae: 0.003608, mean_q: 0.004932
 2522/10000: episode: 257, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000011, mae: 0.002547, mean_q: 0.003347
 2524/10000: episode: 258, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000012, mae: 0.002602, mean_q: 0.004872
 2526/10000: episode: 259, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000033, mae: 0.004230, mean_q: 0.006860
 2530/10000: episode: 260, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000016, mae: 0.003077, mean_q: 0.002845
 2534/10000: episode: 261, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000041, mae: 0.004709, mean_q: 0.006765
 2540/10000: episode: 262, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000043, mae: 0.005104, mean_q: 0.004829
 2544/10000: episode: 263, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000040, mae: 0.004990, mean_q: 0.006148
 2548/10000: episode: 264, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000039, mae: 0.005669, mean_q: 0.001382
 2552/10000: episode: 265, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000053, mae: 0.006260, mean_q: 0.010504
 2556/10000: episode: 266, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000089, mae: 0.005219, mean_q: 0.005847
 2560/10000: episode: 267, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000051, mae: 0.005635, mean_q: 0.004978
 2564/10000: episode: 268, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000042, mae: 0.005749, mean_q: 0.002174
 2566/10000: episode: 269, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000086, mae: 0.009653, mean_q: 0.012154
 2570/10000: episode: 270, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000027, mae: 0.004452, mean_q: 0.001036
 2572/10000: episode: 271, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000046, mae: 0.006451, mean_q: 0.009551
 2574/10000: episode: 272, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000047, mae: 0.006579, mean_q: -0.001239
 2578/10000: episode: 273, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000024, mae: 0.004378, mean_q: 0.007032
 2582/10000: episode: 274, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000020, mae: 0.003721, mean_q: 0.005141
 2586/10000: episode: 275, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000028, mae: 0.004340, mean_q: 0.003446
 2590/10000: episode: 276, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000009, mae: 0.002476, mean_q: 0.003352
 2594/10000: episode: 277, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000016, mae: 0.003586, mean_q: 0.002836
 2598/10000: episode: 278, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000023, mae: 0.003711, mean_q: 0.004039
 2602/10000: episode: 279, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000027, mae: 0.004307, mean_q: 0.004782
 2606/10000: episode: 280, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000065, mae: 0.005814, mean_q: 0.007362
 2610/10000: episode: 281, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000074, mae: 0.004618, mean_q: 0.003867
 2616/10000: episode: 282, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000051, mae: 0.005802, mean_q: 0.005049
 2622/10000: episode: 283, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000033, mae: 0.004369, mean_q: 0.006072
 2624/10000: episode: 284, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000019, mae: 0.003697, mean_q: 0.004734
 2628/10000: episode: 285, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000126, mae: 0.007433, mean_q: 0.007899
 2630/10000: episode: 286, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000159, mae: 0.006341, mean_q: 0.003141
 2636/10000: episode: 287, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000034, mae: 0.004700, mean_q: 0.005021
 2642/10000: episode: 288, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000089, mae: 0.007239, mean_q: 0.009969
 2648/10000: episode: 289, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000060, mae: 0.007214, mean_q: 0.007020
 2650/10000: episode: 290, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000192, mae: 0.009714, mean_q: -0.002717
 2656/10000: episode: 291, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000056, mae: 0.007365, mean_q: 0.007114
 2660/10000: episode: 292, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000116, mae: 0.008452, mean_q: 0.008658
 2664/10000: episode: 293, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000051, mae: 0.005656, mean_q: 0.003291
 2668/10000: episode: 294, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000148, mae: 0.007688, mean_q: 0.005791
 2670/10000: episode: 295, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000074, mae: 0.005974, mean_q: 0.006268
 2674/10000: episode: 296, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000034, mae: 0.004763, mean_q: 0.004100
 2676/10000: episode: 297, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000196, mae: 0.016393, mean_q: 0.021528
 2682/10000: episode: 298, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000102, mae: 0.010222, mean_q: -0.000331
 2688/10000: episode: 299, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000109, mae: 0.008289, mean_q: 0.004112
 2694/10000: episode: 300, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000039, mae: 0.005876, mean_q: 0.005276
 2700/10000: episode: 301, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000051, mae: 0.006046, mean_q: 0.007155
 2704/10000: episode: 302, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000094, mae: 0.006286, mean_q: 0.008164
 2708/10000: episode: 303, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000097, mae: 0.008572, mean_q: 0.006772
 2710/10000: episode: 304, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000028, mae: 0.004577, mean_q: 0.004391
 2714/10000: episode: 305, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000045, mae: 0.005693, mean_q: 0.007266
 2718/10000: episode: 306, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000048, mae: 0.005281, mean_q: 0.004650
 2722/10000: episode: 307, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000104, mae: 0.007127, mean_q: 0.009258
 2726/10000: episode: 308, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000061, mae: 0.006456, mean_q: 0.006043
 2732/10000: episode: 309, duration: 0.028s, episode steps: 6, steps per second: 212, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000034, mae: 0.004599, mean_q: 0.003824
 2738/10000: episode: 310, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000094, mae: 0.005775, mean_q: 0.006691
 2740/10000: episode: 311, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000039, mae: 0.006044, mean_q: 0.010351
 2746/10000: episode: 312, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000089, mae: 0.006052, mean_q: 0.005473
 2750/10000: episode: 313, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000217, mae: 0.015082, mean_q: 0.017768
 2752/10000: episode: 314, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000297, mae: 0.019996, mean_q: -0.012853
 2756/10000: episode: 315, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000220, mae: 0.013761, mean_q: 0.016220
 2762/10000: episode: 316, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000147, mae: 0.012855, mean_q: 0.008863
 2766/10000: episode: 317, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000069, mae: 0.006601, mean_q: 0.002494
 2768/10000: episode: 318, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000056, mae: 0.007651, mean_q: 0.012185
 2770/10000: episode: 319, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000170, mae: 0.008156, mean_q: 0.008510
 2772/10000: episode: 320, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000033, mae: 0.005048, mean_q: 0.001877
 2778/10000: episode: 321, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.002742, mae: 0.024192, mean_q: 0.023379
 2782/10000: episode: 322, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000787, mae: 0.031248, mean_q: -0.022371
 2788/10000: episode: 323, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000450, mae: 0.021745, mean_q: 0.013692
 2792/10000: episode: 324, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000209, mae: 0.014661, mean_q: 0.012887
 2798/10000: episode: 325, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000502, mae: 0.014828, mean_q: -0.000857
 2804/10000: episode: 326, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000429, mae: 0.015745, mean_q: 0.006777
 2808/10000: episode: 327, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000184, mae: 0.010663, mean_q: 0.013635
 2812/10000: episode: 328, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000114, mae: 0.009066, mean_q: 0.004477
 2814/10000: episode: 329, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000212, mae: 0.010095, mean_q: 0.006245
 2816/10000: episode: 330, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000145, mae: 0.011413, mean_q: 0.014768
 2818/10000: episode: 331, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000201, mae: 0.010021, mean_q: 0.001010
 2820/10000: episode: 332, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000055, mae: 0.007068, mean_q: 0.002927
 2824/10000: episode: 333, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000069, mae: 0.008273, mean_q: 0.011456
 2830/10000: episode: 334, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.002576, mae: 0.017977, mean_q: 0.015683
 2836/10000: episode: 335, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000464, mae: 0.023165, mean_q: -0.002696
 2840/10000: episode: 336, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000371, mae: 0.018366, mean_q: 0.024851
 2844/10000: episode: 337, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000244, mae: 0.014304, mean_q: -0.002793
 2848/10000: episode: 338, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000184, mae: 0.011741, mean_q: 0.014865
 2852/10000: episode: 339, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000135, mae: 0.011604, mean_q: -0.002383
[Info] 2-TH LEVEL FOUND: 0.07518693059682846, Considering 22/100 traces
 2856/10000: episode: 340, duration: 0.626s, episode steps: 4, steps per second: 6, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000203, mae: 0.013050, mean_q: 0.015522
 2860/10000: episode: 341, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000511, mae: 0.012044, mean_q: 0.011369
[Info] FALSIFICATION!
 2863/10000: episode: 342, duration: 0.335s, episode steps: 3, steps per second: 9, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000292, mae: 0.011819, mean_q: 0.007494
 2867/10000: episode: 343, duration: 0.029s, episode steps: 4, steps per second: 140, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000217, mae: 0.010501, mean_q: 0.012879
 2871/10000: episode: 344, duration: 0.031s, episode steps: 4, steps per second: 130, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.006220, mae: 0.030087, mean_q: 0.018164
 2873/10000: episode: 345, duration: 0.015s, episode steps: 2, steps per second: 134, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001721, mae: 0.043265, mean_q: 0.053394
 2875/10000: episode: 346, duration: 0.016s, episode steps: 2, steps per second: 126, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000789, mae: 0.034414, mean_q: -0.025793
 2879/10000: episode: 347, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000511, mae: 0.022423, mean_q: 0.000546
[Info] FALSIFICATION!
 2882/10000: episode: 348, duration: 0.169s, episode steps: 3, steps per second: 18, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000397, mae: 0.020419, mean_q: 0.026748
 2884/10000: episode: 349, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000369, mae: 0.019495, mean_q: -0.006649
 2888/10000: episode: 350, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000126, mae: 0.010821, mean_q: 0.006838
 2890/10000: episode: 351, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000269, mae: 0.017960, mean_q: 0.022328
 2894/10000: episode: 352, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000280, mae: 0.013542, mean_q: 0.003463
 2896/10000: episode: 353, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000025, mae: 0.005112, mean_q: 0.001534
 2898/10000: episode: 354, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000117, mae: 0.009577, mean_q: 0.012797
[Info] FALSIFICATION!
 2901/10000: episode: 355, duration: 0.255s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000079, mae: 0.007424, mean_q: 0.011754
 2903/10000: episode: 356, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000119, mae: 0.010548, mean_q: 0.002401
 2907/10000: episode: 357, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000186, mae: 0.009914, mean_q: 0.009655
 2909/10000: episode: 358, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000344, mae: 0.014976, mean_q: 0.023919
 2911/10000: episode: 359, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000092, mae: 0.010481, mean_q: 0.001442
 2913/10000: episode: 360, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001048, mae: 0.016240, mean_q: 0.008934
 2915/10000: episode: 361, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000898, mae: 0.019304, mean_q: 0.024585
 2917/10000: episode: 362, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000297, mae: 0.016119, mean_q: 0.024153
 2921/10000: episode: 363, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000164, mae: 0.013958, mean_q: -0.003811
 2925/10000: episode: 364, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000146, mae: 0.009301, mean_q: 0.012160
 2927/10000: episode: 365, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000128, mae: 0.007086, mean_q: 0.009614
 2929/10000: episode: 366, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006675, mae: 0.024624, mean_q: 0.001386
 2933/10000: episode: 367, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000671, mae: 0.024803, mean_q: 0.031968
 2935/10000: episode: 368, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000812, mae: 0.032128, mean_q: -0.018832
 2939/10000: episode: 369, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003079, mae: 0.032198, mean_q: 0.039008
 2941/10000: episode: 370, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001196, mae: 0.032906, mean_q: 0.043401
 2943/10000: episode: 371, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000681, mae: 0.030246, mean_q: -0.014048
 2947/10000: episode: 372, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000299, mae: 0.018340, mean_q: 0.001140
 2951/10000: episode: 373, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000383, mae: 0.016408, mean_q: 0.020789
 2953/10000: episode: 374, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000419, mae: 0.020963, mean_q: -0.012362
 2957/10000: episode: 375, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000186, mae: 0.012415, mean_q: 0.010539
[Info] FALSIFICATION!
 2960/10000: episode: 376, duration: 0.257s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000276, mae: 0.016651, mean_q: 0.017585
 2962/10000: episode: 377, duration: 0.017s, episode steps: 2, steps per second: 120, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000149, mae: 0.009880, mean_q: 0.005052
 2964/10000: episode: 378, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000304, mae: 0.013327, mean_q: 0.012466
 2968/10000: episode: 379, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000648, mae: 0.019456, mean_q: 0.023389
 2970/10000: episode: 380, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000989, mae: 0.015677, mean_q: 0.000129
[Info] FALSIFICATION!
 2973/10000: episode: 381, duration: 0.256s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001301, mae: 0.029754, mean_q: 0.034158
[Info] FALSIFICATION!
 2976/10000: episode: 382, duration: 0.259s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001411, mae: 0.031247, mean_q: 0.032047
 2978/10000: episode: 383, duration: 0.017s, episode steps: 2, steps per second: 121, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.013315, mae: 0.063093, mean_q: -0.014422
 2980/10000: episode: 384, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001787, mae: 0.036866, mean_q: 0.044159
[Info] FALSIFICATION!
 2983/10000: episode: 385, duration: 0.263s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001277, mae: 0.028683, mean_q: 0.033486
 2985/10000: episode: 386, duration: 0.015s, episode steps: 2, steps per second: 134, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000447, mae: 0.026022, mean_q: -0.011560
 2989/10000: episode: 387, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000636, mae: 0.019053, mean_q: 0.011183
 2991/10000: episode: 388, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000266, mae: 0.013211, mean_q: 0.024225
 2995/10000: episode: 389, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000201, mae: 0.013532, mean_q: -0.001505
 2997/10000: episode: 390, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000291, mae: 0.014555, mean_q: 0.016109
 2999/10000: episode: 391, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000318, mae: 0.019265, mean_q: 0.028371
 3001/10000: episode: 392, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006142, mae: 0.027891, mean_q: 0.022944
 3003/10000: episode: 393, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000455, mae: 0.015093, mean_q: 0.021238
 3005/10000: episode: 394, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000193, mae: 0.013357, mean_q: 0.007689
 3009/10000: episode: 395, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000329, mae: 0.015611, mean_q: 0.011468
 3011/10000: episode: 396, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000505, mae: 0.017774, mean_q: 0.005493
 3013/10000: episode: 397, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000215, mae: 0.012010, mean_q: 0.010188
 3015/10000: episode: 398, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000210, mae: 0.009385, mean_q: 0.006615
 3019/10000: episode: 399, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000223, mae: 0.011404, mean_q: 0.010326
 3021/10000: episode: 400, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000392, mae: 0.015098, mean_q: 0.009979
 3023/10000: episode: 401, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001105, mae: 0.019083, mean_q: 0.019427
 3025/10000: episode: 402, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000329, mae: 0.015442, mean_q: 0.021885
 3027/10000: episode: 403, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000404, mae: 0.015998, mean_q: 0.016720
 3029/10000: episode: 404, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000345, mae: 0.013434, mean_q: 0.004613
 3031/10000: episode: 405, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000170, mae: 0.010314, mean_q: 0.006390
 3033/10000: episode: 406, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000247, mae: 0.011223, mean_q: 0.012776
 3035/10000: episode: 407, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000302, mae: 0.012251, mean_q: 0.014795
 3039/10000: episode: 408, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.006350, mae: 0.040542, mean_q: 0.038941
 3041/10000: episode: 409, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001175, mae: 0.032392, mean_q: 0.043115
 3045/10000: episode: 410, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000929, mae: 0.030845, mean_q: -0.006383
[Info] FALSIFICATION!
 3048/10000: episode: 411, duration: 0.168s, episode steps: 3, steps per second: 18, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000470, mae: 0.023082, mean_q: -0.001419
 3052/10000: episode: 412, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.005160, mae: 0.034256, mean_q: 0.036073
[Info] FALSIFICATION!
 3055/10000: episode: 413, duration: 0.169s, episode steps: 3, steps per second: 18, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001184, mae: 0.027472, mean_q: 0.039793
 3059/10000: episode: 414, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000490, mae: 0.024036, mean_q: -0.001580
 3061/10000: episode: 415, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001523, mae: 0.034475, mean_q: 0.002008
 3065/10000: episode: 416, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003149, mae: 0.019430, mean_q: 0.016782
 3067/10000: episode: 417, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000953, mae: 0.026456, mean_q: 0.033307
[Info] Complete ISplit Iteration
[Info] Levels: [0.022196915, 0.07518693, 0.25883535]
[Info] Cond. Prob: [0.12, 0.22, 0.09]
[Info] Error Prob: 0.002376

 3071/10000: episode: 418, duration: 0.883s, episode steps: 4, steps per second: 5, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003338, mae: 0.031653, mean_q: 0.034418
 3081/10000: episode: 419, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001807, mae: 0.024960, mean_q: 0.014624
 3091/10000: episode: 420, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002605, mae: 0.024248, mean_q: 0.023815
 3101/10000: episode: 421, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.003500, mae: 0.027741, mean_q: 0.022325
 3111/10000: episode: 422, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002520, mae: 0.027371, mean_q: 0.016812
 3121/10000: episode: 423, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001842, mae: 0.028153, mean_q: 0.024267
 3131/10000: episode: 424, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001646, mae: 0.021800, mean_q: 0.011497
 3141/10000: episode: 425, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000502, mae: 0.016846, mean_q: 0.007790
 3151/10000: episode: 426, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000657, mae: 0.019471, mean_q: 0.016765
 3161/10000: episode: 427, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.004016, mae: 0.038966, mean_q: 0.036988
 3171/10000: episode: 428, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001574, mae: 0.039149, mean_q: -0.007227
 3181/10000: episode: 429, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.004078, mae: 0.033265, mean_q: 0.034540
 3191/10000: episode: 430, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001858, mae: 0.032577, mean_q: 0.004135
 3201/10000: episode: 431, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003982, mae: 0.033282, mean_q: 0.031876
 3211/10000: episode: 432, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.003215, mae: 0.022657, mean_q: 0.023958
 3221/10000: episode: 433, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002391, mae: 0.023466, mean_q: 0.020578
 3231/10000: episode: 434, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.003227, mae: 0.028392, mean_q: 0.027363
 3241/10000: episode: 435, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.001945, mae: 0.028944, mean_q: 0.011690
 3251/10000: episode: 436, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002822, mae: 0.027984, mean_q: 0.033054
 3261/10000: episode: 437, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001661, mae: 0.026878, mean_q: 0.013576
 3271/10000: episode: 438, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001773, mae: 0.023704, mean_q: 0.015538
 3281/10000: episode: 439, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.002298, mae: 0.020612, mean_q: 0.018672
 3291/10000: episode: 440, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000584, mae: 0.016644, mean_q: 0.012586
 3301/10000: episode: 441, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002807, mae: 0.032919, mean_q: 0.027508
 3311/10000: episode: 442, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.003682, mae: 0.034524, mean_q: 0.003512
 3321/10000: episode: 443, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002412, mae: 0.044301, mean_q: 0.032355
 3331/10000: episode: 444, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001819, mae: 0.031916, mean_q: 0.011267
 3341/10000: episode: 445, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000707, mae: 0.020666, mean_q: 0.009082
 3351/10000: episode: 446, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000463, mae: 0.015248, mean_q: 0.012982
 3361/10000: episode: 447, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001901, mae: 0.024647, mean_q: 0.025494
 3371/10000: episode: 448, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000719, mae: 0.019138, mean_q: 0.009698
 3381/10000: episode: 449, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000728, mae: 0.016511, mean_q: 0.020156
 3391/10000: episode: 450, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002599, mae: 0.027364, mean_q: 0.027659
 3401/10000: episode: 451, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001534, mae: 0.020882, mean_q: 0.017507
 3411/10000: episode: 452, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000499, mae: 0.021090, mean_q: 0.000067
 3421/10000: episode: 453, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001661, mae: 0.027789, mean_q: 0.029878
 3431/10000: episode: 454, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001724, mae: 0.023551, mean_q: 0.019374
 3441/10000: episode: 455, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.005953, mae: 0.038490, mean_q: 0.023218
 3451/10000: episode: 456, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002146, mae: 0.034173, mean_q: 0.015689
 3461/10000: episode: 457, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001039, mae: 0.023706, mean_q: 0.016876
 3471/10000: episode: 458, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.001596, mae: 0.024273, mean_q: 0.012308
 3481/10000: episode: 459, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000439, mae: 0.014733, mean_q: 0.012928
 3491/10000: episode: 460, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002643, mae: 0.024725, mean_q: 0.022535
 3501/10000: episode: 461, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001671, mae: 0.021119, mean_q: 0.006728
 3511/10000: episode: 462, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002277, mae: 0.024602, mean_q: 0.026628
 3521/10000: episode: 463, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001984, mae: 0.024280, mean_q: 0.027580
 3531/10000: episode: 464, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000665, mae: 0.024630, mean_q: -0.000408
 3541/10000: episode: 465, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001371, mae: 0.020236, mean_q: 0.017586
 3551/10000: episode: 466, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.003037, mae: 0.025341, mean_q: 0.016628
 3561/10000: episode: 467, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000578, mae: 0.021983, mean_q: 0.008042
 3571/10000: episode: 468, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001628, mae: 0.018788, mean_q: 0.017322
 3581/10000: episode: 469, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001793, mae: 0.016733, mean_q: 0.014618
 3591/10000: episode: 470, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000652, mae: 0.016927, mean_q: 0.008367
 3601/10000: episode: 471, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001236, mae: 0.015321, mean_q: 0.015604
 3611/10000: episode: 472, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000465, mae: 0.013293, mean_q: 0.013425
 3621/10000: episode: 473, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000371, mae: 0.011450, mean_q: 0.006721
 3631/10000: episode: 474, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002461, mae: 0.024921, mean_q: 0.028830
 3641/10000: episode: 475, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003477, mae: 0.028004, mean_q: 0.027782
 3651/10000: episode: 476, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001585, mae: 0.021700, mean_q: 0.019138
 3661/10000: episode: 477, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002007, mae: 0.024183, mean_q: 0.018511
 3671/10000: episode: 478, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.003250, mae: 0.024523, mean_q: 0.017370
 3681/10000: episode: 479, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002762, mae: 0.020677, mean_q: 0.019359
 3691/10000: episode: 480, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000704, mae: 0.017894, mean_q: 0.012368
 3701/10000: episode: 481, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001588, mae: 0.021602, mean_q: 0.020900
 3711/10000: episode: 482, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001583, mae: 0.019648, mean_q: 0.007076
 3721/10000: episode: 483, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000701, mae: 0.017381, mean_q: 0.018193
 3731/10000: episode: 484, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001238, mae: 0.018045, mean_q: 0.013726
 3741/10000: episode: 485, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000947, mae: 0.019613, mean_q: 0.018735
 3751/10000: episode: 486, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000458, mae: 0.014830, mean_q: 0.008233
 3761/10000: episode: 487, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000463, mae: 0.012783, mean_q: 0.011783
 3771/10000: episode: 488, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000511, mae: 0.013489, mean_q: 0.013721
 3781/10000: episode: 489, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001893, mae: 0.024299, mean_q: 0.023439
 3791/10000: episode: 490, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001479, mae: 0.018908, mean_q: 0.006956
 3801/10000: episode: 491, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002608, mae: 0.027662, mean_q: 0.027179
 3811/10000: episode: 492, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001956, mae: 0.020986, mean_q: 0.012115
 3821/10000: episode: 493, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002067, mae: 0.017354, mean_q: 0.015711
 3831/10000: episode: 494, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000535, mae: 0.017314, mean_q: 0.011235
 3841/10000: episode: 495, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001136, mae: 0.021155, mean_q: 0.016387
 3851/10000: episode: 496, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001331, mae: 0.016362, mean_q: 0.018447
 3861/10000: episode: 497, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001492, mae: 0.016448, mean_q: 0.011918
 3871/10000: episode: 498, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002793, mae: 0.025426, mean_q: 0.027151
 3881/10000: episode: 499, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.005674, mae: 0.035873, mean_q: 0.039894
 3891/10000: episode: 500, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001974, mae: 0.030425, mean_q: 0.013674
 3901/10000: episode: 501, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002847, mae: 0.023810, mean_q: 0.016166
 3911/10000: episode: 502, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001811, mae: 0.018078, mean_q: 0.021493
 3921/10000: episode: 503, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001976, mae: 0.021025, mean_q: 0.015677
 3931/10000: episode: 504, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001618, mae: 0.020206, mean_q: 0.020129
 3941/10000: episode: 505, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000833, mae: 0.023949, mean_q: 0.008304
 3951/10000: episode: 506, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001913, mae: 0.022470, mean_q: 0.013312
 3961/10000: episode: 507, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002466, mae: 0.022295, mean_q: 0.024394
 3971/10000: episode: 508, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000417, mae: 0.012432, mean_q: 0.013939
 3981/10000: episode: 509, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002243, mae: 0.022158, mean_q: 0.019807
 3991/10000: episode: 510, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001728, mae: 0.016095, mean_q: 0.016309
 4001/10000: episode: 511, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001842, mae: 0.017980, mean_q: 0.017981
 4011/10000: episode: 512, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001351, mae: 0.017166, mean_q: 0.020065
 4021/10000: episode: 513, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.003578, mae: 0.031398, mean_q: 0.021410
 4031/10000: episode: 514, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002261, mae: 0.025200, mean_q: 0.014357
 4041/10000: episode: 515, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000644, mae: 0.018421, mean_q: 0.006479
 4051/10000: episode: 516, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000674, mae: 0.016253, mean_q: 0.016356
 4061/10000: episode: 517, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001552, mae: 0.020819, mean_q: 0.020508
[Info] 1-TH LEVEL FOUND: 0.02194184809923172, Considering 14/100 traces
 4071/10000: episode: 518, duration: 0.698s, episode steps: 10, steps per second: 14, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000318, mae: 0.016595, mean_q: -0.003089
 4073/10000: episode: 519, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000179, mae: 0.010899, mean_q: 0.012622
 4081/10000: episode: 520, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.002055, mae: 0.018217, mean_q: 0.014662
 4083/10000: episode: 521, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001426, mae: 0.016650, mean_q: 0.017527
 4091/10000: episode: 522, duration: 0.039s, episode steps: 8, steps per second: 208, episode reward: 0.065, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000591, mae: 0.020546, mean_q: 0.028409
 4093/10000: episode: 523, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004439, mae: 0.030051, mean_q: 0.018011
 4101/10000: episode: 524, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.098, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000392, mae: 0.014228, mean_q: 0.005670
 4103/10000: episode: 525, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004742, mae: 0.030338, mean_q: 0.027016
 4105/10000: episode: 526, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000444, mae: 0.011769, mean_q: 0.013888
 4107/10000: episode: 527, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000233, mae: 0.008538, mean_q: 0.018297
 4109/10000: episode: 528, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000227, mae: 0.010036, mean_q: -0.000985
 4111/10000: episode: 529, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004124, mae: 0.023794, mean_q: 0.014416
 4114/10000: episode: 530, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002855, mae: 0.021517, mean_q: 0.024504
 4122/10000: episode: 531, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.002637, mae: 0.019269, mean_q: 0.020654
 4130/10000: episode: 532, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.875 [-1.000, 11.000], loss: 0.000473, mae: 0.015818, mean_q: 0.004899
 4138/10000: episode: 533, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 1.317, mean reward: 0.165 [0.002, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.312 [4.000, 11.000], loss: 0.000596, mae: 0.014935, mean_q: 0.011975
 4146/10000: episode: 534, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.039, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000883, mae: 0.017339, mean_q: 0.015826
 4154/10000: episode: 535, duration: 0.041s, episode steps: 8, steps per second: 194, episode reward: 0.044, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.001760, mae: 0.021643, mean_q: 0.025118
 4162/10000: episode: 536, duration: 0.041s, episode steps: 8, steps per second: 195, episode reward: 0.071, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000283, mae: 0.013688, mean_q: 0.013584
 4164/10000: episode: 537, duration: 0.014s, episode steps: 2, steps per second: 144, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005714, mae: 0.029220, mean_q: 0.001908
 4166/10000: episode: 538, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000975, mae: 0.016954, mean_q: 0.019440
 4174/10000: episode: 539, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000527, mae: 0.014138, mean_q: 0.010046
 4182/10000: episode: 540, duration: 0.039s, episode steps: 8, steps per second: 208, episode reward: 0.263, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.938 [-1.000, 11.000], loss: 0.004228, mae: 0.024985, mean_q: 0.018598
 4190/10000: episode: 541, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.002050, mae: 0.031923, mean_q: 0.012554
 4192/10000: episode: 542, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001148, mae: 0.034328, mean_q: -0.006444
 4200/10000: episode: 543, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.001554, mae: 0.019751, mean_q: 0.020875
 4202/10000: episode: 544, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000726, mae: 0.016755, mean_q: 0.018820
 4210/10000: episode: 545, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000440, mae: 0.012769, mean_q: 0.005090
 4218/10000: episode: 546, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000314, mae: 0.010311, mean_q: 0.012386
 4221/10000: episode: 547, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000426, mae: 0.009204, mean_q: 0.009503
 4229/10000: episode: 548, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.875 [-1.000, 11.000], loss: 0.000691, mae: 0.013669, mean_q: 0.014429
 4237/10000: episode: 549, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.263, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.938 [-1.000, 11.000], loss: 0.000474, mae: 0.012475, mean_q: 0.013376
 4245/10000: episode: 550, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.001307, mae: 0.013948, mean_q: 0.016113
 4253/10000: episode: 551, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.051, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000458, mae: 0.015105, mean_q: 0.006575
 4255/10000: episode: 552, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000228, mae: 0.006718, mean_q: 0.007340
 4263/10000: episode: 553, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.013, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000590, mae: 0.013644, mean_q: 0.015400
 4271/10000: episode: 554, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002852, mae: 0.019795, mean_q: 0.017277
 4273/10000: episode: 555, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000311, mae: 0.015318, mean_q: 0.022822
 4281/10000: episode: 556, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.001588, mae: 0.017457, mean_q: 0.015230
 4289/10000: episode: 557, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000638, mae: 0.014613, mean_q: 0.014426
 4297/10000: episode: 558, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000546, mae: 0.014680, mean_q: 0.006034
 4300/10000: episode: 559, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000197, mae: 0.012600, mean_q: 0.002769
 4308/10000: episode: 560, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.033, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.002453, mae: 0.024321, mean_q: 0.028262
 4316/10000: episode: 561, duration: 0.037s, episode steps: 8, steps per second: 216, episode reward: 0.098, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.001380, mae: 0.018918, mean_q: 0.002168
 4318/10000: episode: 562, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000930, mae: 0.018473, mean_q: 0.028042
 4326/10000: episode: 563, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.085, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001735, mae: 0.023952, mean_q: 0.033368
 4334/10000: episode: 564, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.130, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.003385, mae: 0.027104, mean_q: 0.028481
 4342/10000: episode: 565, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.002167, mae: 0.031706, mean_q: 0.001369
 4344/10000: episode: 566, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000979, mae: 0.019299, mean_q: 0.021159
 4352/10000: episode: 567, duration: 0.037s, episode steps: 8, steps per second: 216, episode reward: 0.020, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.001302, mae: 0.016643, mean_q: 0.012044
 4360/10000: episode: 568, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.055, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000785, mae: 0.017729, mean_q: 0.024134
 4362/10000: episode: 569, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000437, mae: 0.018664, mean_q: -0.000506
 4364/10000: episode: 570, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000652, mae: 0.020919, mean_q: -0.001921
 4372/10000: episode: 571, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000763, mae: 0.016776, mean_q: 0.019950
 4380/10000: episode: 572, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.033, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.001664, mae: 0.018059, mean_q: 0.010752
 4382/10000: episode: 573, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000663, mae: 0.026278, mean_q: 0.037806
 4384/10000: episode: 574, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000572, mae: 0.020893, mean_q: 0.028535
 4392/10000: episode: 575, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.013, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.001750, mae: 0.022925, mean_q: 0.007715
 4400/10000: episode: 576, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.128, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000618, mae: 0.015242, mean_q: 0.020710
 4408/10000: episode: 577, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.044, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000441, mae: 0.019834, mean_q: -0.003867
 4416/10000: episode: 578, duration: 0.037s, episode steps: 8, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002585, mae: 0.022386, mean_q: 0.023288
 4418/10000: episode: 579, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000438, mae: 0.019422, mean_q: 0.028977
 4420/10000: episode: 580, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000462, mae: 0.014777, mean_q: 0.009616
 4428/10000: episode: 581, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000385, mae: 0.013422, mean_q: 0.007734
 4430/10000: episode: 582, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003448, mae: 0.018683, mean_q: 0.017982
 4432/10000: episode: 583, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003627, mae: 0.025987, mean_q: 0.027203
 4435/10000: episode: 584, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.004928, mae: 0.038557, mean_q: 0.045422
 4443/10000: episode: 585, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.001324, mae: 0.019557, mean_q: 0.011375
 4445/10000: episode: 586, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000610, mae: 0.019788, mean_q: 0.011975
 4447/10000: episode: 587, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000167, mae: 0.010276, mean_q: 0.008391
 4449/10000: episode: 588, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000094, mae: 0.007972, mean_q: 0.009803
 4457/10000: episode: 589, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001312, mae: 0.017186, mean_q: 0.013186
 4465/10000: episode: 590, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.033, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000732, mae: 0.015932, mean_q: 0.017357
 4473/10000: episode: 591, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.055, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000657, mae: 0.017197, mean_q: 0.006121
 4475/10000: episode: 592, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000069, mae: 0.006239, mean_q: 0.006557
 4477/10000: episode: 593, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000309, mae: 0.011982, mean_q: 0.017646
 4479/10000: episode: 594, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000315, mae: 0.012098, mean_q: 0.012950
 4487/10000: episode: 595, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.051, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.001616, mae: 0.017810, mean_q: 0.017661
 4489/10000: episode: 596, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000753, mae: 0.021428, mean_q: 0.030350
 4497/10000: episode: 597, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.146, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.002216, mae: 0.020443, mean_q: 0.009616
 4499/10000: episode: 598, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000185, mae: 0.007143, mean_q: 0.005697
 4501/10000: episode: 599, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000963, mae: 0.020589, mean_q: 0.028104
 4509/10000: episode: 600, duration: 0.037s, episode steps: 8, steps per second: 217, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.002628, mae: 0.022346, mean_q: 0.018227
 4517/10000: episode: 601, duration: 0.039s, episode steps: 8, steps per second: 208, episode reward: 0.051, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000388, mae: 0.014258, mean_q: 0.022363
 4519/10000: episode: 602, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001314, mae: 0.024330, mean_q: 0.017815
 4522/10000: episode: 603, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000428, mae: 0.019650, mean_q: -0.006677
[Info] 2-TH LEVEL FOUND: 0.13563597202301025, Considering 12/100 traces
 4530/10000: episode: 604, duration: 0.705s, episode steps: 8, steps per second: 11, episode reward: 0.036, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.001436, mae: 0.018579, mean_q: 0.018887
 4536/10000: episode: 605, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.004209, mae: 0.028648, mean_q: 0.017486
 4542/10000: episode: 606, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.002567, mae: 0.031830, mean_q: 0.038584
 4548/10000: episode: 607, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001844, mae: 0.024885, mean_q: 0.003985
 4554/10000: episode: 608, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001995, mae: 0.023256, mean_q: 0.032603
 4560/10000: episode: 609, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.002694, mae: 0.033248, mean_q: 0.010784
 4566/10000: episode: 610, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000347, mae: 0.014191, mean_q: 0.004868
 4572/10000: episode: 611, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001005, mae: 0.023520, mean_q: 0.032743
 4578/10000: episode: 612, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000639, mae: 0.017920, mean_q: 0.002736
 4584/10000: episode: 613, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.002714, mae: 0.027530, mean_q: 0.033389
 4590/10000: episode: 614, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000595, mae: 0.017148, mean_q: 0.016484
 4596/10000: episode: 615, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000558, mae: 0.020590, mean_q: -0.001848
 4602/10000: episode: 616, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001975, mae: 0.022604, mean_q: 0.022963
 4608/10000: episode: 617, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.003899, mae: 0.023967, mean_q: 0.023587
 4614/10000: episode: 618, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000507, mae: 0.014073, mean_q: 0.020179
 4620/10000: episode: 619, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000461, mae: 0.017904, mean_q: 0.003990
 4626/10000: episode: 620, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001674, mae: 0.016518, mean_q: 0.020244
 4632/10000: episode: 621, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.002323, mae: 0.024511, mean_q: 0.027727
 4638/10000: episode: 622, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000663, mae: 0.019655, mean_q: -0.001499
 4644/10000: episode: 623, duration: 0.028s, episode steps: 6, steps per second: 215, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.003549, mae: 0.026460, mean_q: 0.022901
 4650/10000: episode: 624, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.003034, mae: 0.033193, mean_q: 0.042628
 4656/10000: episode: 625, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001621, mae: 0.024057, mean_q: -0.000183
 4662/10000: episode: 626, duration: 0.028s, episode steps: 6, steps per second: 212, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002222, mae: 0.018907, mean_q: 0.022877
 4668/10000: episode: 627, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000812, mae: 0.017870, mean_q: 0.016145
 4674/10000: episode: 628, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001744, mae: 0.020248, mean_q: 0.015841
 4680/10000: episode: 629, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000486, mae: 0.013943, mean_q: 0.013878
 4686/10000: episode: 630, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000336, mae: 0.013751, mean_q: 0.002397
 4692/10000: episode: 631, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000577, mae: 0.013197, mean_q: 0.019137
 4698/10000: episode: 632, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001895, mae: 0.018231, mean_q: 0.016496
 4704/10000: episode: 633, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.003005, mae: 0.020962, mean_q: 0.019810
[Info] FALSIFICATION!
 4709/10000: episode: 634, duration: 0.266s, episode steps: 5, steps per second: 19, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.002581, mae: 0.035283, mean_q: 0.042143
 4715/10000: episode: 635, duration: 0.033s, episode steps: 6, steps per second: 182, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001828, mae: 0.025622, mean_q: 0.011120
 4721/10000: episode: 636, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000856, mae: 0.022329, mean_q: 0.008406
 4727/10000: episode: 637, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001086, mae: 0.022194, mean_q: 0.028106
 4733/10000: episode: 638, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001801, mae: 0.026039, mean_q: -0.000513
 4739/10000: episode: 639, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001049, mae: 0.022638, mean_q: 0.029578
 4745/10000: episode: 640, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001972, mae: 0.024111, mean_q: 0.009184
 4751/10000: episode: 641, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.003387, mae: 0.024811, mean_q: 0.024058
 4757/10000: episode: 642, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001814, mae: 0.023541, mean_q: 0.025009
 4763/10000: episode: 643, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000656, mae: 0.022756, mean_q: 0.002688
 4769/10000: episode: 644, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001752, mae: 0.021586, mean_q: 0.022921
 4775/10000: episode: 645, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001791, mae: 0.018366, mean_q: 0.015609
 4781/10000: episode: 646, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000900, mae: 0.016045, mean_q: 0.021500
 4787/10000: episode: 647, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001842, mae: 0.018294, mean_q: 0.019618
 4793/10000: episode: 648, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001611, mae: 0.015917, mean_q: 0.022207
 4799/10000: episode: 649, duration: 0.028s, episode steps: 6, steps per second: 212, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000745, mae: 0.015433, mean_q: 0.014309
 4805/10000: episode: 650, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000531, mae: 0.013622, mean_q: 0.017601
 4811/10000: episode: 651, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000762, mae: 0.020458, mean_q: 0.008984
 4817/10000: episode: 652, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000194, mae: 0.012337, mean_q: 0.016301
 4823/10000: episode: 653, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000318, mae: 0.011572, mean_q: 0.012048
 4829/10000: episode: 654, duration: 0.028s, episode steps: 6, steps per second: 212, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.002831, mae: 0.026863, mean_q: 0.032389
 4835/10000: episode: 655, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002554, mae: 0.023305, mean_q: 0.034898
 4841/10000: episode: 656, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001014, mae: 0.029997, mean_q: 0.004767
 4847/10000: episode: 657, duration: 0.028s, episode steps: 6, steps per second: 212, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000497, mae: 0.016724, mean_q: 0.007064
 4853/10000: episode: 658, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.003895, mae: 0.031319, mean_q: 0.039987
 4859/10000: episode: 659, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000923, mae: 0.023196, mean_q: 0.013859
 4865/10000: episode: 660, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.002161, mae: 0.029756, mean_q: 0.017262
 4871/10000: episode: 661, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001407, mae: 0.032950, mean_q: 0.044614
 4877/10000: episode: 662, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001555, mae: 0.037137, mean_q: -0.006298
 4883/10000: episode: 663, duration: 0.029s, episode steps: 6, steps per second: 210, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001141, mae: 0.027890, mean_q: 0.040051
 4889/10000: episode: 664, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000635, mae: 0.022257, mean_q: 0.006148
 4895/10000: episode: 665, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001974, mae: 0.023034, mean_q: 0.022199
 4901/10000: episode: 666, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000620, mae: 0.018388, mean_q: 0.018777
 4907/10000: episode: 667, duration: 0.028s, episode steps: 6, steps per second: 212, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000830, mae: 0.019750, mean_q: 0.007584
[Info] FALSIFICATION!
 4912/10000: episode: 668, duration: 0.175s, episode steps: 5, steps per second: 29, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.003414, mae: 0.037121, mean_q: 0.048135
 4918/10000: episode: 669, duration: 0.031s, episode steps: 6, steps per second: 192, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002741, mae: 0.024205, mean_q: 0.019208
 4924/10000: episode: 670, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000767, mae: 0.017516, mean_q: 0.018093
 4930/10000: episode: 671, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000749, mae: 0.017862, mean_q: 0.014660
 4936/10000: episode: 672, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002028, mae: 0.021920, mean_q: 0.017701
 4942/10000: episode: 673, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.003552, mae: 0.033494, mean_q: 0.044300
 4948/10000: episode: 674, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001030, mae: 0.026959, mean_q: 0.008906
 4954/10000: episode: 675, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000672, mae: 0.024169, mean_q: 0.000503
 4960/10000: episode: 676, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002659, mae: 0.030029, mean_q: 0.038475
 4966/10000: episode: 677, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001106, mae: 0.027101, mean_q: -0.000344
 4972/10000: episode: 678, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.003387, mae: 0.030302, mean_q: 0.032681
 4978/10000: episode: 679, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.002979, mae: 0.028727, mean_q: 0.027699
 4984/10000: episode: 680, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000540, mae: 0.014406, mean_q: 0.019781
 4990/10000: episode: 681, duration: 0.028s, episode steps: 6, steps per second: 211, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.003054, mae: 0.028565, mean_q: 0.016472
 4996/10000: episode: 682, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002288, mae: 0.033777, mean_q: 0.045628
 5002/10000: episode: 683, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001016, mae: 0.031520, mean_q: -0.001398
 5008/10000: episode: 684, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000941, mae: 0.020851, mean_q: 0.023298
 5014/10000: episode: 685, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000803, mae: 0.019449, mean_q: 0.016840
 5020/10000: episode: 686, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.002252, mae: 0.026358, mean_q: 0.025253
 5026/10000: episode: 687, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002385, mae: 0.022414, mean_q: 0.023503
 5032/10000: episode: 688, duration: 0.029s, episode steps: 6, steps per second: 210, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000901, mae: 0.022044, mean_q: 0.008391
 5038/10000: episode: 689, duration: 0.029s, episode steps: 6, steps per second: 210, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000775, mae: 0.018983, mean_q: 0.026900
 5044/10000: episode: 690, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001053, mae: 0.026571, mean_q: 0.005899
 5050/10000: episode: 691, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000724, mae: 0.016973, mean_q: 0.022015
[Info] Complete ISplit Iteration
[Info] Levels: [0.021941848, 0.13563597, 0.36005577]
[Info] Cond. Prob: [0.14, 0.12, 0.02]
[Info] Error Prob: 0.00033600000000000004

 5056/10000: episode: 692, duration: 0.757s, episode steps: 6, steps per second: 8, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001687, mae: 0.016890, mean_q: 0.018415
 5066/10000: episode: 693, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002113, mae: 0.019908, mean_q: 0.021959
 5076/10000: episode: 694, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001685, mae: 0.019837, mean_q: 0.025902
 5086/10000: episode: 695, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000724, mae: 0.017846, mean_q: 0.014979
 5096/10000: episode: 696, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002636, mae: 0.020058, mean_q: 0.015361
 5106/10000: episode: 697, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000485, mae: 0.019828, mean_q: 0.015201
 5116/10000: episode: 698, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002321, mae: 0.026314, mean_q: 0.031498
 5126/10000: episode: 699, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002471, mae: 0.025783, mean_q: 0.022193
 5136/10000: episode: 700, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002159, mae: 0.022044, mean_q: 0.024618
 5146/10000: episode: 701, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001558, mae: 0.024718, mean_q: 0.015725
 5156/10000: episode: 702, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002238, mae: 0.025837, mean_q: 0.027734
 5166/10000: episode: 703, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000918, mae: 0.020491, mean_q: 0.024591
 5176/10000: episode: 704, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001505, mae: 0.019449, mean_q: 0.020439
 5186/10000: episode: 705, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002733, mae: 0.024477, mean_q: 0.028073
 5196/10000: episode: 706, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001508, mae: 0.028795, mean_q: 0.018121
 5206/10000: episode: 707, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002136, mae: 0.026726, mean_q: 0.029742
 5216/10000: episode: 708, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001501, mae: 0.022303, mean_q: 0.019544
 5226/10000: episode: 709, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002051, mae: 0.023979, mean_q: 0.026577
 5236/10000: episode: 710, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001082, mae: 0.021267, mean_q: 0.020303
 5246/10000: episode: 711, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002409, mae: 0.028544, mean_q: 0.036656
 5256/10000: episode: 712, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000860, mae: 0.023423, mean_q: 0.016097
 5266/10000: episode: 713, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000561, mae: 0.016828, mean_q: 0.015554
 5276/10000: episode: 714, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001954, mae: 0.019941, mean_q: 0.022378
 5286/10000: episode: 715, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001415, mae: 0.023299, mean_q: 0.029203
 5296/10000: episode: 716, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001504, mae: 0.025029, mean_q: 0.023968
 5306/10000: episode: 717, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002228, mae: 0.023843, mean_q: 0.022939
 5316/10000: episode: 718, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000925, mae: 0.016313, mean_q: 0.015793
 5326/10000: episode: 719, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000786, mae: 0.018907, mean_q: 0.026450
 5336/10000: episode: 720, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001472, mae: 0.015688, mean_q: 0.018113
 5346/10000: episode: 721, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.001844, mae: 0.023722, mean_q: 0.020837
 5356/10000: episode: 722, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000790, mae: 0.023253, mean_q: 0.016954
 5366/10000: episode: 723, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000802, mae: 0.021757, mean_q: 0.025339
 5376/10000: episode: 724, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002125, mae: 0.026622, mean_q: 0.032200
 5386/10000: episode: 725, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000539, mae: 0.020304, mean_q: 0.012985
 5396/10000: episode: 726, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001994, mae: 0.020941, mean_q: 0.026535
 5406/10000: episode: 727, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001295, mae: 0.022659, mean_q: 0.011097
 5416/10000: episode: 728, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000754, mae: 0.019918, mean_q: 0.025320
 5426/10000: episode: 729, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001842, mae: 0.019546, mean_q: 0.015531
 5436/10000: episode: 730, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.004803, mae: 0.031112, mean_q: 0.025188
 5446/10000: episode: 731, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001942, mae: 0.031275, mean_q: 0.033136
 5456/10000: episode: 732, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.003349, mae: 0.033869, mean_q: 0.029690
 5466/10000: episode: 733, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001673, mae: 0.027475, mean_q: 0.000414
 5476/10000: episode: 734, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002304, mae: 0.032404, mean_q: 0.039527
 5486/10000: episode: 735, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002547, mae: 0.025709, mean_q: 0.026977
 5496/10000: episode: 736, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001165, mae: 0.019836, mean_q: 0.011051
 5506/10000: episode: 737, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001199, mae: 0.022044, mean_q: 0.018094
 5516/10000: episode: 738, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001511, mae: 0.021492, mean_q: 0.020530
 5526/10000: episode: 739, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000837, mae: 0.019892, mean_q: 0.023932
 5536/10000: episode: 740, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001219, mae: 0.018399, mean_q: 0.021012
 5546/10000: episode: 741, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001394, mae: 0.022712, mean_q: 0.021889
 5556/10000: episode: 742, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001342, mae: 0.020440, mean_q: 0.021393
 5566/10000: episode: 743, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002491, mae: 0.022270, mean_q: 0.027107
 5576/10000: episode: 744, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001148, mae: 0.019471, mean_q: 0.013829
 5586/10000: episode: 745, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000687, mae: 0.018383, mean_q: 0.013477
 5596/10000: episode: 746, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001585, mae: 0.020397, mean_q: 0.026159
 5606/10000: episode: 747, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000598, mae: 0.016512, mean_q: 0.019654
 5616/10000: episode: 748, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.004045, mae: 0.027456, mean_q: 0.028867
 5626/10000: episode: 749, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000939, mae: 0.026486, mean_q: 0.013990
 5636/10000: episode: 750, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001215, mae: 0.020033, mean_q: 0.018503
 5646/10000: episode: 751, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000585, mae: 0.016467, mean_q: 0.016692
 5656/10000: episode: 752, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001419, mae: 0.018743, mean_q: 0.018521
 5666/10000: episode: 753, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002427, mae: 0.025567, mean_q: 0.028515
 5676/10000: episode: 754, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.003279, mae: 0.031299, mean_q: 0.033801
 5686/10000: episode: 755, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000736, mae: 0.019611, mean_q: 0.021065
 5696/10000: episode: 756, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001654, mae: 0.020919, mean_q: 0.029975
 5706/10000: episode: 757, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001960, mae: 0.023986, mean_q: 0.016290
 5716/10000: episode: 758, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002357, mae: 0.023099, mean_q: 0.035229
 5726/10000: episode: 759, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002763, mae: 0.021307, mean_q: 0.021265
 5736/10000: episode: 760, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001394, mae: 0.024255, mean_q: 0.015089
 5746/10000: episode: 761, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001330, mae: 0.019531, mean_q: 0.021726
 5756/10000: episode: 762, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000916, mae: 0.020451, mean_q: 0.027245
 5766/10000: episode: 763, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002409, mae: 0.024686, mean_q: 0.028814
 5776/10000: episode: 764, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001895, mae: 0.021282, mean_q: 0.014924
 5786/10000: episode: 765, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000567, mae: 0.015797, mean_q: 0.019389
 5796/10000: episode: 766, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001170, mae: 0.020714, mean_q: 0.030040
 5806/10000: episode: 767, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002316, mae: 0.022116, mean_q: 0.024923
 5816/10000: episode: 768, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000772, mae: 0.021525, mean_q: 0.010809
 5826/10000: episode: 769, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001715, mae: 0.019848, mean_q: 0.028467
 5836/10000: episode: 770, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000589, mae: 0.019086, mean_q: 0.009624
 5846/10000: episode: 771, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002509, mae: 0.025725, mean_q: 0.028420
 5856/10000: episode: 772, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002265, mae: 0.029211, mean_q: 0.039539
 5866/10000: episode: 773, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000537, mae: 0.020729, mean_q: 0.009959
 5876/10000: episode: 774, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000857, mae: 0.019354, mean_q: 0.029834
 5886/10000: episode: 775, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001415, mae: 0.021384, mean_q: 0.019187
 5896/10000: episode: 776, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002396, mae: 0.024757, mean_q: 0.024696
 5906/10000: episode: 777, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001590, mae: 0.020189, mean_q: 0.027032
 5916/10000: episode: 778, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000763, mae: 0.018165, mean_q: 0.012665
 5926/10000: episode: 779, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002471, mae: 0.024573, mean_q: 0.023302
 5936/10000: episode: 780, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001895, mae: 0.017808, mean_q: 0.017016
 5946/10000: episode: 781, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000594, mae: 0.019976, mean_q: 0.031445
 5956/10000: episode: 782, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001251, mae: 0.022654, mean_q: 0.016135
 5966/10000: episode: 783, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001688, mae: 0.021574, mean_q: 0.016563
 5976/10000: episode: 784, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002832, mae: 0.027777, mean_q: 0.040174
 5986/10000: episode: 785, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001456, mae: 0.027755, mean_q: 0.010629
 5996/10000: episode: 786, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.002525, mae: 0.030904, mean_q: 0.038298
 6006/10000: episode: 787, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.003007, mae: 0.034690, mean_q: 0.040045
 6016/10000: episode: 788, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001278, mae: 0.030121, mean_q: 0.009331
 6026/10000: episode: 789, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001257, mae: 0.021585, mean_q: 0.022193
 6036/10000: episode: 790, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000631, mae: 0.018741, mean_q: 0.023992
 6046/10000: episode: 791, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001168, mae: 0.020125, mean_q: 0.014192
[Info] 1-TH LEVEL FOUND: 0.032514166086912155, Considering 11/100 traces
 6056/10000: episode: 792, duration: 0.656s, episode steps: 10, steps per second: 15, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000653, mae: 0.017087, mean_q: 0.027650
 6060/10000: episode: 793, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000350, mae: 0.015509, mean_q: 0.003307
 6064/10000: episode: 794, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001304, mae: 0.021264, mean_q: 0.025849
 6068/10000: episode: 795, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000638, mae: 0.019098, mean_q: 0.029948
 6072/10000: episode: 796, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.003135, mae: 0.024176, mean_q: 0.030467
 6076/10000: episode: 797, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000530, mae: 0.016182, mean_q: 0.024252
 6080/10000: episode: 798, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002062, mae: 0.030145, mean_q: 0.014200
 6084/10000: episode: 799, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001736, mae: 0.021097, mean_q: 0.026399
 6090/10000: episode: 800, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000843, mae: 0.024575, mean_q: 0.016074
 6094/10000: episode: 801, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002211, mae: 0.022605, mean_q: 0.014278
 6098/10000: episode: 802, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000877, mae: 0.027677, mean_q: 0.037749
 6102/10000: episode: 803, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000474, mae: 0.016053, mean_q: 0.015020
 6106/10000: episode: 804, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000951, mae: 0.027120, mean_q: 0.009705
 6112/10000: episode: 805, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002578, mae: 0.038277, mean_q: 0.047290
 6118/10000: episode: 806, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001990, mae: 0.029294, mean_q: 0.018052
 6122/10000: episode: 807, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000932, mae: 0.022874, mean_q: 0.021777
 6126/10000: episode: 808, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002027, mae: 0.023499, mean_q: 0.034242
 6130/10000: episode: 809, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000890, mae: 0.017543, mean_q: 0.019140
 6134/10000: episode: 810, duration: 0.020s, episode steps: 4, steps per second: 199, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000473, mae: 0.013613, mean_q: 0.012967
 6138/10000: episode: 811, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002918, mae: 0.022891, mean_q: 0.029253
 6142/10000: episode: 812, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004146, mae: 0.032580, mean_q: 0.037367
 6148/10000: episode: 813, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000675, mae: 0.021054, mean_q: 0.027704
 6152/10000: episode: 814, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003866, mae: 0.035991, mean_q: 0.006984
 6156/10000: episode: 815, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002033, mae: 0.025815, mean_q: 0.037821
 6160/10000: episode: 816, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001517, mae: 0.019225, mean_q: 0.029186
 6164/10000: episode: 817, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003845, mae: 0.030432, mean_q: 0.032380
 6168/10000: episode: 818, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002622, mae: 0.028030, mean_q: 0.037538
 6174/10000: episode: 819, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000817, mae: 0.018976, mean_q: 0.014977
 6180/10000: episode: 820, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001402, mae: 0.021047, mean_q: 0.032613
 6184/10000: episode: 821, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000842, mae: 0.022902, mean_q: 0.043549
 6188/10000: episode: 822, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000587, mae: 0.016014, mean_q: 0.022426
 6192/10000: episode: 823, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001027, mae: 0.026268, mean_q: 0.014239
 6196/10000: episode: 824, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000636, mae: 0.019857, mean_q: 0.015303
 6202/10000: episode: 825, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000645, mae: 0.017561, mean_q: 0.026482
 6206/10000: episode: 826, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000901, mae: 0.022186, mean_q: 0.025709
 6210/10000: episode: 827, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003632, mae: 0.023454, mean_q: 0.019290
 6214/10000: episode: 828, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002118, mae: 0.028541, mean_q: 0.034867
 6218/10000: episode: 829, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000672, mae: 0.018096, mean_q: 0.029917
 6224/10000: episode: 830, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.002471, mae: 0.022626, mean_q: 0.017319
 6228/10000: episode: 831, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000479, mae: 0.016222, mean_q: 0.012841
 6232/10000: episode: 832, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000756, mae: 0.020715, mean_q: 0.016462
 6236/10000: episode: 833, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001962, mae: 0.024155, mean_q: 0.016348
 6240/10000: episode: 834, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000638, mae: 0.016571, mean_q: 0.022458
 6244/10000: episode: 835, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004815, mae: 0.034116, mean_q: 0.035269
 6248/10000: episode: 836, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001514, mae: 0.018035, mean_q: 0.024048
[Info] FALSIFICATION!
 6253/10000: episode: 837, duration: 0.257s, episode steps: 5, steps per second: 19, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.001515, mae: 0.020772, mean_q: 0.019338
 6259/10000: episode: 838, duration: 0.034s, episode steps: 6, steps per second: 176, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001292, mae: 0.018898, mean_q: 0.021536
 6265/10000: episode: 839, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000713, mae: 0.017538, mean_q: 0.013772
 6271/10000: episode: 840, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001632, mae: 0.022358, mean_q: 0.033861
 6275/10000: episode: 841, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001983, mae: 0.023617, mean_q: 0.028821
 6279/10000: episode: 842, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000704, mae: 0.019013, mean_q: 0.017634
 6283/10000: episode: 843, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001294, mae: 0.023928, mean_q: 0.025431
 6287/10000: episode: 844, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002330, mae: 0.026237, mean_q: 0.022228
 6293/10000: episode: 845, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000371, mae: 0.015765, mean_q: 0.026263
 6297/10000: episode: 846, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003720, mae: 0.026314, mean_q: 0.016128
 6301/10000: episode: 847, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000547, mae: 0.018164, mean_q: 0.023773
 6305/10000: episode: 848, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000672, mae: 0.016851, mean_q: 0.019658
 6309/10000: episode: 849, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000619, mae: 0.021304, mean_q: 0.006724
 6313/10000: episode: 850, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000885, mae: 0.018133, mean_q: 0.014844
 6317/10000: episode: 851, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.004104, mae: 0.032980, mean_q: 0.040368
 6321/10000: episode: 852, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001633, mae: 0.027538, mean_q: 0.029471
 6327/10000: episode: 853, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000494, mae: 0.016246, mean_q: 0.018395
 6331/10000: episode: 854, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001702, mae: 0.020211, mean_q: 0.011682
 6337/10000: episode: 855, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000718, mae: 0.018936, mean_q: 0.028552
 6343/10000: episode: 856, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000495, mae: 0.014859, mean_q: 0.018045
 6347/10000: episode: 857, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000874, mae: 0.018481, mean_q: 0.028983
 6353/10000: episode: 858, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001439, mae: 0.018330, mean_q: 0.028670
 6359/10000: episode: 859, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000590, mae: 0.019430, mean_q: 0.011166
 6365/10000: episode: 860, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003403, mae: 0.028119, mean_q: 0.029915
 6371/10000: episode: 861, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001316, mae: 0.025112, mean_q: 0.039144
 6375/10000: episode: 862, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001809, mae: 0.023493, mean_q: 0.023658
 6379/10000: episode: 863, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001231, mae: 0.027887, mean_q: 0.027959
 6383/10000: episode: 864, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004096, mae: 0.040359, mean_q: -0.003585
 6389/10000: episode: 865, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001686, mae: 0.030660, mean_q: 0.043058
 6395/10000: episode: 866, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.003694, mae: 0.029615, mean_q: 0.016837
 6401/10000: episode: 867, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002826, mae: 0.031597, mean_q: 0.043529
 6405/10000: episode: 868, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001054, mae: 0.023353, mean_q: 0.034826
 6409/10000: episode: 869, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000546, mae: 0.026447, mean_q: -0.001206
 6415/10000: episode: 870, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000733, mae: 0.017597, mean_q: 0.022849
 6419/10000: episode: 871, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000956, mae: 0.021862, mean_q: 0.028050
 6425/10000: episode: 872, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000777, mae: 0.019732, mean_q: 0.012406
 6429/10000: episode: 873, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001656, mae: 0.035349, mean_q: 0.045178
 6433/10000: episode: 874, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000540, mae: 0.019886, mean_q: 0.031876
 6439/10000: episode: 875, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003012, mae: 0.029074, mean_q: 0.013331
 6445/10000: episode: 876, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002728, mae: 0.025222, mean_q: 0.034046
 6451/10000: episode: 877, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001082, mae: 0.017551, mean_q: 0.018367
 6457/10000: episode: 878, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000921, mae: 0.019773, mean_q: 0.030856
 6461/10000: episode: 879, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001508, mae: 0.021051, mean_q: 0.020204
 6465/10000: episode: 880, duration: 0.020s, episode steps: 4, steps per second: 202, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000867, mae: 0.021282, mean_q: 0.019423
[Info] FALSIFICATION!
[Info] Complete ISplit Iteration
[Info] Levels: [0.032514166, 0.55286217]
[Info] Cond. Prob: [0.11, 0.02]
[Info] Error Prob: 0.0022

 6470/10000: episode: 881, duration: 1.043s, episode steps: 5, steps per second: 5, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000970, mae: 0.021207, mean_q: 0.022008
 6480/10000: episode: 882, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001522, mae: 0.024654, mean_q: 0.029572
 6490/10000: episode: 883, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000701, mae: 0.020407, mean_q: 0.020087
 6500/10000: episode: 884, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.002474, mae: 0.025256, mean_q: 0.034603
 6510/10000: episode: 885, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000980, mae: 0.021462, mean_q: 0.025534
 6520/10000: episode: 886, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001452, mae: 0.024809, mean_q: 0.028796
 6530/10000: episode: 887, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001254, mae: 0.024594, mean_q: 0.036078
 6540/10000: episode: 888, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000798, mae: 0.021074, mean_q: 0.023446
 6550/10000: episode: 889, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001924, mae: 0.021880, mean_q: 0.025088
 6560/10000: episode: 890, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001880, mae: 0.020895, mean_q: 0.026254
 6570/10000: episode: 891, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000814, mae: 0.020113, mean_q: 0.022435
 6580/10000: episode: 892, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.003054, mae: 0.029293, mean_q: 0.031769
 6590/10000: episode: 893, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001285, mae: 0.022398, mean_q: 0.023901
 6600/10000: episode: 894, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000793, mae: 0.021875, mean_q: 0.018765
 6610/10000: episode: 895, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001412, mae: 0.021357, mean_q: 0.026199
 6620/10000: episode: 896, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002397, mae: 0.022642, mean_q: 0.027126
 6630/10000: episode: 897, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001784, mae: 0.022846, mean_q: 0.026692
 6640/10000: episode: 898, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000969, mae: 0.023945, mean_q: 0.018847
 6650/10000: episode: 899, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.004999, mae: 0.051140, mean_q: 0.066658
 6660/10000: episode: 900, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001634, mae: 0.033217, mean_q: 0.007683
 6670/10000: episode: 901, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003025, mae: 0.032717, mean_q: 0.035278
 6680/10000: episode: 902, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001955, mae: 0.022592, mean_q: 0.030502
 6690/10000: episode: 903, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001847, mae: 0.021272, mean_q: 0.012708
 6700/10000: episode: 904, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001523, mae: 0.022732, mean_q: 0.025993
 6710/10000: episode: 905, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.002329, mae: 0.026732, mean_q: 0.034697
 6720/10000: episode: 906, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001562, mae: 0.033652, mean_q: 0.023331
 6730/10000: episode: 907, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001046, mae: 0.024577, mean_q: 0.032727
 6740/10000: episode: 908, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001761, mae: 0.023977, mean_q: 0.024381
 6750/10000: episode: 909, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000856, mae: 0.021316, mean_q: 0.016767
 6760/10000: episode: 910, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001666, mae: 0.029720, mean_q: 0.032298
 6770/10000: episode: 911, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001116, mae: 0.019936, mean_q: 0.020638
 6780/10000: episode: 912, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002614, mae: 0.023163, mean_q: 0.031889
 6790/10000: episode: 913, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002344, mae: 0.035012, mean_q: 0.025217
 6800/10000: episode: 914, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001580, mae: 0.027113, mean_q: 0.037422
 6810/10000: episode: 915, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002579, mae: 0.031384, mean_q: 0.032113
 6820/10000: episode: 916, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001679, mae: 0.027625, mean_q: 0.016875
 6830/10000: episode: 917, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000905, mae: 0.023196, mean_q: 0.026285
 6840/10000: episode: 918, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001646, mae: 0.026232, mean_q: 0.039828
 6850/10000: episode: 919, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002770, mae: 0.032687, mean_q: 0.021680
 6860/10000: episode: 920, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002128, mae: 0.033396, mean_q: 0.039589
 6870/10000: episode: 921, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001975, mae: 0.031736, mean_q: 0.040389
 6880/10000: episode: 922, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001046, mae: 0.020567, mean_q: 0.021798
 6890/10000: episode: 923, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000729, mae: 0.019236, mean_q: 0.013876
 6900/10000: episode: 924, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002494, mae: 0.023911, mean_q: 0.026958
 6910/10000: episode: 925, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000719, mae: 0.019058, mean_q: 0.026330
 6920/10000: episode: 926, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001675, mae: 0.019268, mean_q: 0.012914
 6930/10000: episode: 927, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001404, mae: 0.026198, mean_q: 0.032774
 6940/10000: episode: 928, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001023, mae: 0.026546, mean_q: 0.014172
 6950/10000: episode: 929, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000851, mae: 0.023690, mean_q: 0.019462
 6960/10000: episode: 930, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000858, mae: 0.021344, mean_q: 0.025061
 6970/10000: episode: 931, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001172, mae: 0.018685, mean_q: 0.020102
 6980/10000: episode: 932, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000868, mae: 0.020960, mean_q: 0.028086
 6990/10000: episode: 933, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000762, mae: 0.019513, mean_q: 0.019054
 7000/10000: episode: 934, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001193, mae: 0.020359, mean_q: 0.029061
 7010/10000: episode: 935, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000416, mae: 0.013049, mean_q: 0.012984
 7020/10000: episode: 936, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000947, mae: 0.017620, mean_q: 0.025962
 7030/10000: episode: 937, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000748, mae: 0.015834, mean_q: 0.025020
 7040/10000: episode: 938, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000590, mae: 0.017470, mean_q: 0.013214
 7050/10000: episode: 939, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000737, mae: 0.022708, mean_q: 0.029919
 7060/10000: episode: 940, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001781, mae: 0.031296, mean_q: 0.022325
 7070/10000: episode: 941, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000982, mae: 0.021431, mean_q: 0.013127
 7080/10000: episode: 942, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001189, mae: 0.019057, mean_q: 0.031047
 7090/10000: episode: 943, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001479, mae: 0.020611, mean_q: 0.020108
 7100/10000: episode: 944, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001431, mae: 0.020094, mean_q: 0.023595
 7110/10000: episode: 945, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000783, mae: 0.017385, mean_q: 0.024888
 7120/10000: episode: 946, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001059, mae: 0.021204, mean_q: 0.021399
 7130/10000: episode: 947, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000682, mae: 0.017219, mean_q: 0.021565
 7140/10000: episode: 948, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001289, mae: 0.021881, mean_q: 0.026299
 7150/10000: episode: 949, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001279, mae: 0.021745, mean_q: 0.027199
 7160/10000: episode: 950, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001604, mae: 0.021731, mean_q: 0.031249
 7170/10000: episode: 951, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001387, mae: 0.023360, mean_q: 0.014932
 7180/10000: episode: 952, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002168, mae: 0.027388, mean_q: 0.041994
 7190/10000: episode: 953, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000513, mae: 0.019969, mean_q: 0.003180
 7200/10000: episode: 954, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000648, mae: 0.017504, mean_q: 0.025885
 7210/10000: episode: 955, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001097, mae: 0.019973, mean_q: 0.027547
 7220/10000: episode: 956, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002781, mae: 0.025175, mean_q: 0.027969
 7230/10000: episode: 957, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001476, mae: 0.028993, mean_q: 0.015641
 7240/10000: episode: 958, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001367, mae: 0.028267, mean_q: 0.037663
 7250/10000: episode: 959, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000782, mae: 0.021377, mean_q: 0.014180
 7260/10000: episode: 960, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001885, mae: 0.022850, mean_q: 0.032508
 7270/10000: episode: 961, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001949, mae: 0.025118, mean_q: 0.026816
 7280/10000: episode: 962, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000888, mae: 0.021115, mean_q: 0.014834
 7290/10000: episode: 963, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000531, mae: 0.014232, mean_q: 0.015971
 7300/10000: episode: 964, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000495, mae: 0.013184, mean_q: 0.010851
 7310/10000: episode: 965, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001591, mae: 0.023778, mean_q: 0.030441
 7320/10000: episode: 966, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.001392, mae: 0.022812, mean_q: 0.016902
 7330/10000: episode: 967, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000735, mae: 0.017594, mean_q: 0.033895
 7340/10000: episode: 968, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000919, mae: 0.020247, mean_q: 0.008535
 7350/10000: episode: 969, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001802, mae: 0.023750, mean_q: 0.030540
 7360/10000: episode: 970, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000954, mae: 0.019356, mean_q: 0.013428
 7370/10000: episode: 971, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.000966, mae: 0.025532, mean_q: 0.025136
 7380/10000: episode: 972, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000795, mae: 0.024221, mean_q: 0.018329
 7390/10000: episode: 973, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000626, mae: 0.017676, mean_q: 0.009869
 7400/10000: episode: 974, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001174, mae: 0.017689, mean_q: 0.022092
 7410/10000: episode: 975, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000418, mae: 0.012626, mean_q: 0.017332
 7420/10000: episode: 976, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000589, mae: 0.014398, mean_q: 0.021800
 7430/10000: episode: 977, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001477, mae: 0.020761, mean_q: 0.018557
 7440/10000: episode: 978, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000699, mae: 0.022165, mean_q: 0.016277
 7450/10000: episode: 979, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000876, mae: 0.016780, mean_q: 0.020489
 7460/10000: episode: 980, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001347, mae: 0.017502, mean_q: 0.023521
[Info] 1-TH LEVEL FOUND: 0.027454828843474388, Considering 11/100 traces
 7470/10000: episode: 981, duration: 0.681s, episode steps: 10, steps per second: 15, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000710, mae: 0.015943, mean_q: 0.017697
 7477/10000: episode: 982, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001003, mae: 0.018790, mean_q: 0.018142
 7484/10000: episode: 983, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000723, mae: 0.015794, mean_q: 0.017158
 7491/10000: episode: 984, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000473, mae: 0.013261, mean_q: 0.014299
 7495/10000: episode: 985, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000361, mae: 0.015617, mean_q: 0.020829
 7502/10000: episode: 986, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000472, mae: 0.012153, mean_q: 0.011906
 7509/10000: episode: 987, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000270, mae: 0.011494, mean_q: 0.017784
 7516/10000: episode: 988, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001244, mae: 0.016999, mean_q: 0.013771
 7523/10000: episode: 989, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000492, mae: 0.015376, mean_q: 0.021303
 7530/10000: episode: 990, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000313, mae: 0.010813, mean_q: 0.014753
 7537/10000: episode: 991, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001464, mae: 0.017836, mean_q: 0.023446
 7544/10000: episode: 992, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000393, mae: 0.014983, mean_q: 0.019251
 7551/10000: episode: 993, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000560, mae: 0.020015, mean_q: 0.002302
 7558/10000: episode: 994, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000871, mae: 0.014668, mean_q: 0.020414
 7565/10000: episode: 995, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001413, mae: 0.019524, mean_q: 0.027941
 7572/10000: episode: 996, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000337, mae: 0.014330, mean_q: 0.004678
 7579/10000: episode: 997, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000821, mae: 0.014722, mean_q: 0.018564
 7586/10000: episode: 998, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000285, mae: 0.012017, mean_q: 0.019484
 7593/10000: episode: 999, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000701, mae: 0.014726, mean_q: 0.021969
 7600/10000: episode: 1000, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000294, mae: 0.011072, mean_q: 0.009458
 7607/10000: episode: 1001, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000433, mae: 0.013466, mean_q: 0.020668
 7614/10000: episode: 1002, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000524, mae: 0.015176, mean_q: 0.008636
 7621/10000: episode: 1003, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000327, mae: 0.012676, mean_q: 0.019509
 7628/10000: episode: 1004, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000569, mae: 0.015431, mean_q: 0.013577
 7635/10000: episode: 1005, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001701, mae: 0.025227, mean_q: 0.034480
 7642/10000: episode: 1006, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000670, mae: 0.018745, mean_q: 0.010745
 7649/10000: episode: 1007, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001009, mae: 0.016947, mean_q: 0.019792
 7656/10000: episode: 1008, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000512, mae: 0.014287, mean_q: 0.013936
 7663/10000: episode: 1009, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000415, mae: 0.014381, mean_q: 0.012574
 7670/10000: episode: 1010, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000426, mae: 0.013740, mean_q: 0.018134
 7674/10000: episode: 1011, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000475, mae: 0.014086, mean_q: 0.018463
 7678/10000: episode: 1012, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000575, mae: 0.013462, mean_q: 0.015927
 7682/10000: episode: 1013, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000428, mae: 0.014035, mean_q: 0.021140
 7689/10000: episode: 1014, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000957, mae: 0.013415, mean_q: 0.018980
 7696/10000: episode: 1015, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001024, mae: 0.016715, mean_q: 0.021124
 7703/10000: episode: 1016, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000320, mae: 0.012104, mean_q: 0.011552
 7707/10000: episode: 1017, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000362, mae: 0.010820, mean_q: 0.012013
 7714/10000: episode: 1018, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000168, mae: 0.008845, mean_q: 0.012796
 7721/10000: episode: 1019, duration: 0.033s, episode steps: 7, steps per second: 215, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000393, mae: 0.014867, mean_q: 0.009861
 7728/10000: episode: 1020, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000437, mae: 0.014876, mean_q: 0.023119
 7735/10000: episode: 1021, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001348, mae: 0.019819, mean_q: 0.015272
 7742/10000: episode: 1022, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000593, mae: 0.023681, mean_q: 0.030316
 7749/10000: episode: 1023, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000200, mae: 0.013318, mean_q: 0.004630
 7756/10000: episode: 1024, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000658, mae: 0.014955, mean_q: 0.025810
 7763/10000: episode: 1025, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000374, mae: 0.012874, mean_q: 0.014196
 7770/10000: episode: 1026, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000449, mae: 0.013738, mean_q: 0.019065
 7777/10000: episode: 1027, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000907, mae: 0.014779, mean_q: 0.022787
 7784/10000: episode: 1028, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000506, mae: 0.015992, mean_q: 0.019489
 7791/10000: episode: 1029, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000419, mae: 0.014268, mean_q: 0.011434
 7795/10000: episode: 1030, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000492, mae: 0.015722, mean_q: 0.022169
 7802/10000: episode: 1031, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000189, mae: 0.008942, mean_q: 0.012062
 7806/10000: episode: 1032, duration: 0.020s, episode steps: 4, steps per second: 200, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000253, mae: 0.011503, mean_q: 0.015328
 7813/10000: episode: 1033, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000371, mae: 0.013348, mean_q: 0.019312
 7820/10000: episode: 1034, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000530, mae: 0.015044, mean_q: 0.017798
 7824/10000: episode: 1035, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000668, mae: 0.014839, mean_q: 0.021211
 7828/10000: episode: 1036, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000782, mae: 0.015653, mean_q: 0.018970
 7832/10000: episode: 1037, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000555, mae: 0.017350, mean_q: 0.023262
 7839/10000: episode: 1038, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000468, mae: 0.013876, mean_q: 0.014688
 7846/10000: episode: 1039, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000531, mae: 0.015224, mean_q: 0.016247
 7853/10000: episode: 1040, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000639, mae: 0.017893, mean_q: 0.021793
 7860/10000: episode: 1041, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000424, mae: 0.015681, mean_q: 0.017326
 7864/10000: episode: 1042, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000220, mae: 0.010946, mean_q: 0.015241
[Info] FALSIFICATION!
 7870/10000: episode: 1043, duration: 0.173s, episode steps: 6, steps per second: 35, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000530, mae: 0.014302, mean_q: 0.021492
 7874/10000: episode: 1044, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000466, mae: 0.015396, mean_q: 0.016032
 7881/10000: episode: 1045, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000340, mae: 0.013241, mean_q: 0.015515
 7888/10000: episode: 1046, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000670, mae: 0.016012, mean_q: 0.021000
 7895/10000: episode: 1047, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001559, mae: 0.023377, mean_q: 0.031663
 7899/10000: episode: 1048, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001700, mae: 0.020826, mean_q: 0.027852
 7906/10000: episode: 1049, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000414, mae: 0.015886, mean_q: 0.012640
 7913/10000: episode: 1050, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000451, mae: 0.015068, mean_q: 0.014648
 7920/10000: episode: 1051, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000430, mae: 0.014024, mean_q: 0.017596
 7924/10000: episode: 1052, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000342, mae: 0.014057, mean_q: 0.020204
 7931/10000: episode: 1053, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000424, mae: 0.013730, mean_q: 0.014314
 7938/10000: episode: 1054, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000191, mae: 0.010783, mean_q: 0.017502
 7945/10000: episode: 1055, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000362, mae: 0.012861, mean_q: 0.013481
 7952/10000: episode: 1056, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000500, mae: 0.011423, mean_q: 0.017303
 7956/10000: episode: 1057, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000662, mae: 0.013324, mean_q: 0.017347
 7963/10000: episode: 1058, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000341, mae: 0.012181, mean_q: 0.014373
 7970/10000: episode: 1059, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000648, mae: 0.015343, mean_q: 0.018858
 7977/10000: episode: 1060, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000317, mae: 0.012519, mean_q: 0.016016
 7984/10000: episode: 1061, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000964, mae: 0.015066, mean_q: 0.020135
 7991/10000: episode: 1062, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001070, mae: 0.016618, mean_q: 0.023248
 7998/10000: episode: 1063, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000265, mae: 0.011980, mean_q: 0.015115
 8005/10000: episode: 1064, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000778, mae: 0.016940, mean_q: 0.022961
 8012/10000: episode: 1065, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000980, mae: 0.016661, mean_q: 0.024203
 8016/10000: episode: 1066, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000365, mae: 0.017736, mean_q: 0.027332
 8023/10000: episode: 1067, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 1.947, mean reward: 0.278 [0.007, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 7.857 [5.000, 11.000], loss: 0.000974, mae: 0.017381, mean_q: 0.016942
 8030/10000: episode: 1068, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000407, mae: 0.016228, mean_q: 0.029083
 8037/10000: episode: 1069, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000888, mae: 0.023797, mean_q: 0.010013
[Info] Complete ISplit Iteration
[Info] Levels: [0.027454829, 0.5987504]
[Info] Cond. Prob: [0.11, 0.01]
[Info] Error Prob: 0.0011

 8044/10000: episode: 1070, duration: 0.821s, episode steps: 7, steps per second: 9, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000608, mae: 0.019721, mean_q: 0.026664
 8054/10000: episode: 1071, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000709, mae: 0.015317, mean_q: 0.008833
 8064/10000: episode: 1072, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000402, mae: 0.017443, mean_q: 0.018286
 8074/10000: episode: 1073, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000454, mae: 0.017507, mean_q: 0.024511
 8084/10000: episode: 1074, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000864, mae: 0.015999, mean_q: 0.018771
 8094/10000: episode: 1075, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000445, mae: 0.016220, mean_q: 0.020121
 8104/10000: episode: 1076, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000465, mae: 0.014361, mean_q: 0.015549
 8114/10000: episode: 1077, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000585, mae: 0.014558, mean_q: 0.018294
 8124/10000: episode: 1078, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000613, mae: 0.017987, mean_q: 0.022696
 8134/10000: episode: 1079, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000400, mae: 0.015335, mean_q: 0.022442
 8144/10000: episode: 1080, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000403, mae: 0.012586, mean_q: 0.014889
 8154/10000: episode: 1081, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000559, mae: 0.014467, mean_q: 0.020359
 8164/10000: episode: 1082, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000756, mae: 0.017118, mean_q: 0.023046
 8174/10000: episode: 1083, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001138, mae: 0.020221, mean_q: 0.029585
 8184/10000: episode: 1084, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000819, mae: 0.016477, mean_q: 0.018667
 8194/10000: episode: 1085, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000698, mae: 0.019799, mean_q: 0.015505
 8204/10000: episode: 1086, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000479, mae: 0.016145, mean_q: 0.022632
 8214/10000: episode: 1087, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000461, mae: 0.016274, mean_q: 0.013906
 8224/10000: episode: 1088, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001107, mae: 0.017609, mean_q: 0.024759
 8234/10000: episode: 1089, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001325, mae: 0.014691, mean_q: 0.021064
 8244/10000: episode: 1090, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000672, mae: 0.018651, mean_q: 0.013386
 8254/10000: episode: 1091, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000526, mae: 0.016201, mean_q: 0.019450
 8264/10000: episode: 1092, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001412, mae: 0.020184, mean_q: 0.025905
 8274/10000: episode: 1093, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000987, mae: 0.021470, mean_q: 0.026293
 8284/10000: episode: 1094, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000828, mae: 0.018906, mean_q: 0.021574
 8294/10000: episode: 1095, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000475, mae: 0.017398, mean_q: 0.012530
 8304/10000: episode: 1096, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000920, mae: 0.017821, mean_q: 0.024324
 8314/10000: episode: 1097, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000516, mae: 0.016858, mean_q: 0.015709
 8324/10000: episode: 1098, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000788, mae: 0.019502, mean_q: 0.023244
 8334/10000: episode: 1099, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000412, mae: 0.016650, mean_q: 0.016253
 8344/10000: episode: 1100, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000554, mae: 0.016137, mean_q: 0.018773
 8354/10000: episode: 1101, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000316, mae: 0.013578, mean_q: 0.017106
 8364/10000: episode: 1102, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000340, mae: 0.013315, mean_q: 0.015028
 8374/10000: episode: 1103, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000645, mae: 0.015806, mean_q: 0.020599
 8384/10000: episode: 1104, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000772, mae: 0.018819, mean_q: 0.028975
 8394/10000: episode: 1105, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000423, mae: 0.014864, mean_q: 0.012780
 8404/10000: episode: 1106, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000796, mae: 0.016941, mean_q: 0.016064
 8414/10000: episode: 1107, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000777, mae: 0.018932, mean_q: 0.029121
 8424/10000: episode: 1108, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000597, mae: 0.016876, mean_q: 0.021372
 8434/10000: episode: 1109, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000468, mae: 0.015294, mean_q: 0.018149
 8444/10000: episode: 1110, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000434, mae: 0.012377, mean_q: 0.015968
 8454/10000: episode: 1111, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000408, mae: 0.013771, mean_q: 0.020954
 8464/10000: episode: 1112, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000459, mae: 0.014233, mean_q: 0.020442
 8474/10000: episode: 1113, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000435, mae: 0.013680, mean_q: 0.018876
 8484/10000: episode: 1114, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001005, mae: 0.020282, mean_q: 0.032613
 8494/10000: episode: 1115, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000259, mae: 0.012498, mean_q: 0.007608
 8504/10000: episode: 1116, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000619, mae: 0.017977, mean_q: 0.023856
 8514/10000: episode: 1117, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000884, mae: 0.015957, mean_q: 0.021225
 8524/10000: episode: 1118, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000671, mae: 0.020379, mean_q: 0.018398
 8534/10000: episode: 1119, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000393, mae: 0.012892, mean_q: 0.017561
 8544/10000: episode: 1120, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000416, mae: 0.016323, mean_q: 0.018918
 8554/10000: episode: 1121, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000787, mae: 0.019984, mean_q: 0.024414
 8564/10000: episode: 1122, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000523, mae: 0.016158, mean_q: 0.011882
 8574/10000: episode: 1123, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000376, mae: 0.016448, mean_q: 0.018538
 8584/10000: episode: 1124, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000800, mae: 0.024051, mean_q: 0.030024
 8594/10000: episode: 1125, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000490, mae: 0.015522, mean_q: 0.016832
 8604/10000: episode: 1126, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000422, mae: 0.016025, mean_q: 0.017939
 8614/10000: episode: 1127, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000487, mae: 0.014519, mean_q: 0.022206
 8624/10000: episode: 1128, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001155, mae: 0.020430, mean_q: 0.023870
 8634/10000: episode: 1129, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000601, mae: 0.014697, mean_q: 0.020738
 8644/10000: episode: 1130, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000383, mae: 0.015007, mean_q: 0.010270
 8654/10000: episode: 1131, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001276, mae: 0.019649, mean_q: 0.027503
 8664/10000: episode: 1132, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000548, mae: 0.014862, mean_q: 0.016434
 8674/10000: episode: 1133, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000890, mae: 0.016990, mean_q: 0.018401
 8684/10000: episode: 1134, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000345, mae: 0.014128, mean_q: 0.016514
 8694/10000: episode: 1135, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000685, mae: 0.016489, mean_q: 0.021427
 8704/10000: episode: 1136, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001182, mae: 0.022720, mean_q: 0.028539
 8714/10000: episode: 1137, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000410, mae: 0.017668, mean_q: 0.012153
 8724/10000: episode: 1138, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000560, mae: 0.016941, mean_q: 0.015005
 8734/10000: episode: 1139, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000459, mae: 0.012141, mean_q: 0.016523
 8744/10000: episode: 1140, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001297, mae: 0.021601, mean_q: 0.033509
 8754/10000: episode: 1141, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000314, mae: 0.014255, mean_q: 0.009206
 8764/10000: episode: 1142, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000714, mae: 0.018594, mean_q: 0.019959
 8774/10000: episode: 1143, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002246, mae: 0.024329, mean_q: 0.031076
 8784/10000: episode: 1144, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000674, mae: 0.017375, mean_q: 0.016495
 8794/10000: episode: 1145, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000385, mae: 0.014852, mean_q: 0.010198
 8804/10000: episode: 1146, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000347, mae: 0.014723, mean_q: 0.015873
 8814/10000: episode: 1147, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001393, mae: 0.019950, mean_q: 0.026397
 8824/10000: episode: 1148, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000457, mae: 0.017403, mean_q: 0.012701
 8834/10000: episode: 1149, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001165, mae: 0.019838, mean_q: 0.027493
 8844/10000: episode: 1150, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000705, mae: 0.018350, mean_q: 0.018745
 8854/10000: episode: 1151, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000376, mae: 0.013064, mean_q: 0.015918
 8864/10000: episode: 1152, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001031, mae: 0.018319, mean_q: 0.022958
 8874/10000: episode: 1153, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000502, mae: 0.016816, mean_q: 0.021212
 8884/10000: episode: 1154, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000261, mae: 0.012039, mean_q: 0.017252
 8894/10000: episode: 1155, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000616, mae: 0.017476, mean_q: 0.022702
 8904/10000: episode: 1156, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000663, mae: 0.016798, mean_q: 0.023059
 8914/10000: episode: 1157, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000424, mae: 0.012814, mean_q: 0.017668
 8924/10000: episode: 1158, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000854, mae: 0.014714, mean_q: 0.020798
 8934/10000: episode: 1159, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000996, mae: 0.018618, mean_q: 0.021058
 8944/10000: episode: 1160, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000431, mae: 0.016868, mean_q: 0.016722
 8954/10000: episode: 1161, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000265, mae: 0.010882, mean_q: 0.011331
 8964/10000: episode: 1162, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000401, mae: 0.016325, mean_q: 0.023276
 8974/10000: episode: 1163, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000498, mae: 0.013908, mean_q: 0.019776
 8984/10000: episode: 1164, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000790, mae: 0.015090, mean_q: 0.020675
 8994/10000: episode: 1165, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001323, mae: 0.020570, mean_q: 0.028867
 9004/10000: episode: 1166, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000575, mae: 0.016713, mean_q: 0.014746
 9014/10000: episode: 1167, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000567, mae: 0.013585, mean_q: 0.014571
 9024/10000: episode: 1168, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000247, mae: 0.011593, mean_q: 0.015432
 9034/10000: episode: 1169, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001182, mae: 0.019329, mean_q: 0.025729
[Info] 1-TH LEVEL FOUND: 0.046455495059490204, Considering 11/100 traces
 9044/10000: episode: 1170, duration: 0.695s, episode steps: 10, steps per second: 14, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000789, mae: 0.017015, mean_q: 0.021413
 9048/10000: episode: 1171, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000282, mae: 0.015155, mean_q: 0.010643
 9054/10000: episode: 1172, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001095, mae: 0.021231, mean_q: 0.015303
 9058/10000: episode: 1173, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001598, mae: 0.027114, mean_q: 0.042023
 9062/10000: episode: 1174, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000685, mae: 0.018886, mean_q: 0.014713
 9064/10000: episode: 1175, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000877, mae: 0.024047, mean_q: 0.013281
 9066/10000: episode: 1176, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000259, mae: 0.009960, mean_q: 0.008231
 9072/10000: episode: 1177, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.001127, mae: 0.021831, mean_q: 0.032184
 9076/10000: episode: 1178, duration: 0.020s, episode steps: 4, steps per second: 198, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001626, mae: 0.018834, mean_q: 0.028945
 9082/10000: episode: 1179, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000611, mae: 0.015117, mean_q: 0.024230
 9088/10000: episode: 1180, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000332, mae: 0.017596, mean_q: 0.001787
 9094/10000: episode: 1181, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000563, mae: 0.017897, mean_q: 0.031627
 9098/10000: episode: 1182, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000757, mae: 0.018018, mean_q: 0.006894
 9104/10000: episode: 1183, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000298, mae: 0.016341, mean_q: 0.024669
 9110/10000: episode: 1184, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000281, mae: 0.014015, mean_q: 0.021162
 9114/10000: episode: 1185, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000817, mae: 0.016913, mean_q: 0.021999
 9120/10000: episode: 1186, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000355, mae: 0.013409, mean_q: 0.009229
 9126/10000: episode: 1187, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000545, mae: 0.014089, mean_q: 0.012546
 9132/10000: episode: 1188, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000545, mae: 0.016609, mean_q: 0.022180
 9134/10000: episode: 1189, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000178, mae: 0.013464, mean_q: 0.018419
 9136/10000: episode: 1190, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002722, mae: 0.020296, mean_q: 0.019143
 9142/10000: episode: 1191, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000674, mae: 0.020515, mean_q: 0.031572
 9148/10000: episode: 1192, duration: 0.028s, episode steps: 6, steps per second: 211, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000324, mae: 0.012366, mean_q: 0.020212
 9154/10000: episode: 1193, duration: 0.029s, episode steps: 6, steps per second: 210, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000520, mae: 0.014753, mean_q: 0.014230
 9156/10000: episode: 1194, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000837, mae: 0.021501, mean_q: 0.012937
 9162/10000: episode: 1195, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000506, mae: 0.016321, mean_q: 0.017483
 9164/10000: episode: 1196, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000936, mae: 0.023593, mean_q: 0.032966
 9166/10000: episode: 1197, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000857, mae: 0.017075, mean_q: 0.024554
 9170/10000: episode: 1198, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000373, mae: 0.012589, mean_q: 0.016291
 9172/10000: episode: 1199, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002734, mae: 0.023787, mean_q: 0.026793
 9174/10000: episode: 1200, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000305, mae: 0.009940, mean_q: 0.013099
 9180/10000: episode: 1201, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001145, mae: 0.020002, mean_q: 0.029565
 9184/10000: episode: 1202, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001538, mae: 0.023475, mean_q: 0.026657
 9190/10000: episode: 1203, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000735, mae: 0.016494, mean_q: 0.021782
 9192/10000: episode: 1204, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000746, mae: 0.020274, mean_q: 0.008813
 9198/10000: episode: 1205, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000617, mae: 0.018350, mean_q: 0.010490
 9204/10000: episode: 1206, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000301, mae: 0.012122, mean_q: 0.014751
 9206/10000: episode: 1207, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000992, mae: 0.016851, mean_q: 0.018533
 9212/10000: episode: 1208, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000386, mae: 0.013207, mean_q: 0.018745
 9218/10000: episode: 1209, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000441, mae: 0.013356, mean_q: 0.019415
 9220/10000: episode: 1210, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000995, mae: 0.025226, mean_q: 0.033303
 9222/10000: episode: 1211, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000287, mae: 0.011710, mean_q: 0.013388
 9224/10000: episode: 1212, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000623, mae: 0.015674, mean_q: 0.012859
 9230/10000: episode: 1213, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000362, mae: 0.012967, mean_q: 0.015220
 9236/10000: episode: 1214, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000375, mae: 0.012472, mean_q: 0.015938
 9238/10000: episode: 1215, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000581, mae: 0.013898, mean_q: 0.014901
 9242/10000: episode: 1216, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001460, mae: 0.018269, mean_q: 0.024322
 9246/10000: episode: 1217, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001355, mae: 0.015961, mean_q: 0.025936
 9248/10000: episode: 1218, duration: 0.012s, episode steps: 2, steps per second: 166, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000784, mae: 0.016564, mean_q: 0.026972
 9250/10000: episode: 1219, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000508, mae: 0.014898, mean_q: 0.017955
 9252/10000: episode: 1220, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000286, mae: 0.013699, mean_q: 0.007248
 9254/10000: episode: 1221, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001757, mae: 0.014023, mean_q: 0.020968
 9260/10000: episode: 1222, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000830, mae: 0.019842, mean_q: 0.033363
 9266/10000: episode: 1223, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000750, mae: 0.017484, mean_q: 0.015217
 9272/10000: episode: 1224, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000600, mae: 0.015477, mean_q: 0.024739
 9276/10000: episode: 1225, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000573, mae: 0.013471, mean_q: 0.022582
 9280/10000: episode: 1226, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000513, mae: 0.015969, mean_q: 0.008955
 9286/10000: episode: 1227, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000452, mae: 0.011858, mean_q: 0.019522
 9292/10000: episode: 1228, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000339, mae: 0.011776, mean_q: 0.012859
 9296/10000: episode: 1229, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000254, mae: 0.013237, mean_q: 0.020658
 9302/10000: episode: 1230, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000580, mae: 0.017733, mean_q: 0.006344
 9306/10000: episode: 1231, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000877, mae: 0.022970, mean_q: 0.030660
 9308/10000: episode: 1232, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000286, mae: 0.015995, mean_q: 0.023665
 9312/10000: episode: 1233, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000814, mae: 0.019412, mean_q: 0.009507
 9316/10000: episode: 1234, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001301, mae: 0.019419, mean_q: 0.024148
 9322/10000: episode: 1235, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002843, mae: 0.022140, mean_q: 0.024712
 9326/10000: episode: 1236, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000362, mae: 0.015847, mean_q: 0.026287
 9328/10000: episode: 1237, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001262, mae: 0.020060, mean_q: 0.024931
 9330/10000: episode: 1238, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000985, mae: 0.026991, mean_q: 0.003977
 9332/10000: episode: 1239, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000642, mae: 0.024602, mean_q: -0.011527
 9334/10000: episode: 1240, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001914, mae: 0.019511, mean_q: 0.028327
 9336/10000: episode: 1241, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000400, mae: 0.019918, mean_q: 0.028626
 9340/10000: episode: 1242, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000863, mae: 0.020937, mean_q: 0.026110
 9344/10000: episode: 1243, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000637, mae: 0.020956, mean_q: 0.002255
 9346/10000: episode: 1244, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001111, mae: 0.016046, mean_q: 0.021080
 9350/10000: episode: 1245, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000633, mae: 0.018233, mean_q: 0.025162
 9352/10000: episode: 1246, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000174, mae: 0.008609, mean_q: 0.011625
 9358/10000: episode: 1247, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000234, mae: 0.011940, mean_q: 0.006008
 9364/10000: episode: 1248, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001135, mae: 0.019624, mean_q: 0.024681
 9370/10000: episode: 1249, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000571, mae: 0.016664, mean_q: 0.024166
 9372/10000: episode: 1250, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000267, mae: 0.013292, mean_q: 0.006179
 9376/10000: episode: 1251, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000555, mae: 0.012107, mean_q: 0.013018
 9378/10000: episode: 1252, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000399, mae: 0.014490, mean_q: 0.022727
 9382/10000: episode: 1253, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000599, mae: 0.014503, mean_q: 0.011290
 9388/10000: episode: 1254, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000270, mae: 0.009815, mean_q: 0.010366
 9392/10000: episode: 1255, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000205, mae: 0.011782, mean_q: 0.017351
 9398/10000: episode: 1256, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000319, mae: 0.011094, mean_q: 0.010429
 9400/10000: episode: 1257, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000612, mae: 0.019044, mean_q: 0.015673
 9404/10000: episode: 1258, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000481, mae: 0.017915, mean_q: 0.026694
[Info] 2-TH LEVEL FOUND: 0.14413826167583466, Considering 14/100 traces
 9410/10000: episode: 1259, duration: 0.695s, episode steps: 6, steps per second: 9, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000502, mae: 0.013248, mean_q: 0.010605
 9415/10000: episode: 1260, duration: 0.035s, episode steps: 5, steps per second: 144, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000910, mae: 0.014779, mean_q: 0.022148
 9420/10000: episode: 1261, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000353, mae: 0.013427, mean_q: 0.017931
 9425/10000: episode: 1262, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000626, mae: 0.020007, mean_q: 0.000798
 9430/10000: episode: 1263, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000931, mae: 0.025971, mean_q: 0.039557
 9435/10000: episode: 1264, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.004787, mae: 0.023573, mean_q: 0.026098
 9440/10000: episode: 1265, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001083, mae: 0.021311, mean_q: 0.030962
 9445/10000: episode: 1266, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000947, mae: 0.027075, mean_q: -0.001389
 9450/10000: episode: 1267, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000269, mae: 0.014013, mean_q: 0.012995
 9455/10000: episode: 1268, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001017, mae: 0.018627, mean_q: 0.025600
 9460/10000: episode: 1269, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.004257, mae: 0.037373, mean_q: 0.046963
[Info] FALSIFICATION!
 9464/10000: episode: 1270, duration: 0.259s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.003479, mae: 0.033148, mean_q: 0.025366
 9469/10000: episode: 1271, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000719, mae: 0.024628, mean_q: -0.002259
 9474/10000: episode: 1272, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001259, mae: 0.020033, mean_q: 0.032787
 9479/10000: episode: 1273, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000460, mae: 0.016572, mean_q: 0.004595
 9484/10000: episode: 1274, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.002382, mae: 0.017675, mean_q: 0.016366
 9489/10000: episode: 1275, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000650, mae: 0.022046, mean_q: 0.034070
 9494/10000: episode: 1276, duration: 0.024s, episode steps: 5, steps per second: 205, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000420, mae: 0.012485, mean_q: 0.014635
 9499/10000: episode: 1277, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000394, mae: 0.013508, mean_q: 0.010622
 9504/10000: episode: 1278, duration: 0.024s, episode steps: 5, steps per second: 207, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001007, mae: 0.017808, mean_q: 0.027985
[Info] FALSIFICATION!
 9508/10000: episode: 1279, duration: 0.260s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000577, mae: 0.014714, mean_q: 0.024583
 9513/10000: episode: 1280, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000877, mae: 0.017238, mean_q: 0.024538
 9518/10000: episode: 1281, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000551, mae: 0.014263, mean_q: 0.028083
 9523/10000: episode: 1282, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000559, mae: 0.015306, mean_q: 0.010997
 9528/10000: episode: 1283, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000473, mae: 0.013738, mean_q: 0.025432
 9533/10000: episode: 1284, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000758, mae: 0.016466, mean_q: 0.021663
 9538/10000: episode: 1285, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000514, mae: 0.018808, mean_q: 0.009745
 9543/10000: episode: 1286, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000448, mae: 0.018653, mean_q: 0.027062
 9548/10000: episode: 1287, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000529, mae: 0.014401, mean_q: 0.028718
 9553/10000: episode: 1288, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000672, mae: 0.020467, mean_q: 0.014384
 9558/10000: episode: 1289, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000211, mae: 0.012301, mean_q: 0.007850
 9563/10000: episode: 1290, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000256, mae: 0.012446, mean_q: 0.017461
[Info] FALSIFICATION!
 9567/10000: episode: 1291, duration: 0.261s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000397, mae: 0.014155, mean_q: 0.008062
 9572/10000: episode: 1292, duration: 0.032s, episode steps: 5, steps per second: 158, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001491, mae: 0.019713, mean_q: 0.021128
 9577/10000: episode: 1293, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000568, mae: 0.018535, mean_q: 0.020424
 9582/10000: episode: 1294, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000341, mae: 0.014764, mean_q: 0.013735
 9587/10000: episode: 1295, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000536, mae: 0.020271, mean_q: 0.031401
 9592/10000: episode: 1296, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000654, mae: 0.020325, mean_q: 0.003461
 9597/10000: episode: 1297, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.004133, mae: 0.034792, mean_q: 0.038301
[Info] FALSIFICATION!
 9601/10000: episode: 1298, duration: 0.260s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000962, mae: 0.024334, mean_q: 0.032037
[Info] FALSIFICATION!
 9605/10000: episode: 1299, duration: 0.264s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000361, mae: 0.019735, mean_q: 0.000985
 9610/10000: episode: 1300, duration: 0.029s, episode steps: 5, steps per second: 171, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000761, mae: 0.016075, mean_q: 0.028726
 9615/10000: episode: 1301, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001357, mae: 0.028930, mean_q: 0.020432
 9620/10000: episode: 1302, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000530, mae: 0.015578, mean_q: 0.025029
[Info] FALSIFICATION!
 9624/10000: episode: 1303, duration: 0.249s, episode steps: 4, steps per second: 16, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000562, mae: 0.017311, mean_q: 0.023303
 9629/10000: episode: 1304, duration: 0.029s, episode steps: 5, steps per second: 170, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000632, mae: 0.014609, mean_q: 0.014459
 9634/10000: episode: 1305, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001745, mae: 0.020836, mean_q: 0.030091
 9639/10000: episode: 1306, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001273, mae: 0.021694, mean_q: 0.036597
 9644/10000: episode: 1307, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.003354, mae: 0.028700, mean_q: 0.043333
 9649/10000: episode: 1308, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000897, mae: 0.016399, mean_q: 0.020429
 9654/10000: episode: 1309, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001093, mae: 0.019767, mean_q: 0.012726
 9659/10000: episode: 1310, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000890, mae: 0.018521, mean_q: 0.026792
 9664/10000: episode: 1311, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000968, mae: 0.016268, mean_q: 0.025893
 9669/10000: episode: 1312, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001399, mae: 0.021363, mean_q: 0.021144
 9674/10000: episode: 1313, duration: 0.024s, episode steps: 5, steps per second: 207, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001579, mae: 0.032806, mean_q: 0.050708
 9679/10000: episode: 1314, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000992, mae: 0.029427, mean_q: -0.005535
 9684/10000: episode: 1315, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002291, mae: 0.033640, mean_q: 0.042428
 9689/10000: episode: 1316, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000669, mae: 0.023163, mean_q: 0.024497
 9694/10000: episode: 1317, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000838, mae: 0.021615, mean_q: 0.012921
 9699/10000: episode: 1318, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000647, mae: 0.019624, mean_q: 0.030864
 9704/10000: episode: 1319, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000766, mae: 0.021544, mean_q: 0.008486
 9709/10000: episode: 1320, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000827, mae: 0.021485, mean_q: 0.018825
 9714/10000: episode: 1321, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001515, mae: 0.025753, mean_q: 0.036597
 9719/10000: episode: 1322, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002736, mae: 0.026007, mean_q: 0.029462
 9724/10000: episode: 1323, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000701, mae: 0.023239, mean_q: 0.040208
 9729/10000: episode: 1324, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001130, mae: 0.031549, mean_q: 0.010733
 9734/10000: episode: 1325, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001536, mae: 0.023771, mean_q: 0.037779
 9739/10000: episode: 1326, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001062, mae: 0.023793, mean_q: 0.042835
 9744/10000: episode: 1327, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000755, mae: 0.026721, mean_q: 0.003182
 9749/10000: episode: 1328, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001143, mae: 0.026002, mean_q: 0.038770
 9754/10000: episode: 1329, duration: 0.024s, episode steps: 5, steps per second: 205, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000741, mae: 0.019128, mean_q: 0.026524
 9759/10000: episode: 1330, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001350, mae: 0.020189, mean_q: 0.029223
 9764/10000: episode: 1331, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001379, mae: 0.027102, mean_q: 0.035104
 9769/10000: episode: 1332, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001699, mae: 0.027467, mean_q: 0.042983
 9774/10000: episode: 1333, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002783, mae: 0.025455, mean_q: 0.025810
 9779/10000: episode: 1334, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001547, mae: 0.024891, mean_q: 0.025362
 9784/10000: episode: 1335, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003267, mae: 0.028016, mean_q: 0.024828
 9789/10000: episode: 1336, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000758, mae: 0.022661, mean_q: 0.041287
 9794/10000: episode: 1337, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001002, mae: 0.021340, mean_q: 0.018570
 9799/10000: episode: 1338, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000533, mae: 0.015749, mean_q: 0.023679
 9804/10000: episode: 1339, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000353, mae: 0.014706, mean_q: 0.020424
 9809/10000: episode: 1340, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.003124, mae: 0.028871, mean_q: 0.041894
 9814/10000: episode: 1341, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000760, mae: 0.021424, mean_q: 0.016341
 9819/10000: episode: 1342, duration: 0.025s, episode steps: 5, steps per second: 204, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002026, mae: 0.027848, mean_q: 0.037544
 9824/10000: episode: 1343, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001909, mae: 0.024789, mean_q: 0.029656
[Info] FALSIFICATION!
 9828/10000: episode: 1344, duration: 0.262s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000838, mae: 0.026409, mean_q: 0.046114
[Info] Complete ISplit Iteration
[Info] Levels: [0.046455495, 0.14413826, 0.7860833]
[Info] Cond. Prob: [0.11, 0.14, 0.07]
[Info] Error Prob: 0.0010780000000000002

 9833/10000: episode: 1345, duration: 0.765s, episode steps: 5, steps per second: 7, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.002993, mae: 0.028304, mean_q: 0.040448
 9843/10000: episode: 1346, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001384, mae: 0.025580, mean_q: 0.019303
 9853/10000: episode: 1347, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002063, mae: 0.024835, mean_q: 0.034147
 9863/10000: episode: 1348, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001257, mae: 0.021579, mean_q: 0.034489
 9873/10000: episode: 1349, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001764, mae: 0.019758, mean_q: 0.031224
 9883/10000: episode: 1350, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001289, mae: 0.024251, mean_q: 0.030062
 9893/10000: episode: 1351, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000913, mae: 0.021112, mean_q: 0.034819
 9903/10000: episode: 1352, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001305, mae: 0.024205, mean_q: 0.023311
 9913/10000: episode: 1353, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.003108, mae: 0.032827, mean_q: 0.047280
 9923/10000: episode: 1354, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000844, mae: 0.022181, mean_q: 0.017423
 9933/10000: episode: 1355, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001319, mae: 0.023205, mean_q: 0.025887
[Info] FALSIFICATION!
 9943/10000: episode: 1356, duration: 0.222s, episode steps: 10, steps per second: 45, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.001034, mae: 0.022881, mean_q: 0.033818
 9953/10000: episode: 1357, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001454, mae: 0.026231, mean_q: 0.032940
 9963/10000: episode: 1358, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000812, mae: 0.021943, mean_q: 0.015249
 9973/10000: episode: 1359, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001156, mae: 0.019850, mean_q: 0.026598
 9983/10000: episode: 1360, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000635, mae: 0.021775, mean_q: 0.021843
 9993/10000: episode: 1361, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001550, mae: 0.028523, mean_q: 0.037750
done, took 62.800 seconds
[Info] End Importance Splitting. Falsification occurred 22 times.
