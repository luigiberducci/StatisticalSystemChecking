Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          (None, 2)                 0         
_________________________________________________________________
dense_1 (Dense)              (None, 16)                48        
_________________________________________________________________
dense_2 (Dense)              (None, 8)                 136       
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 9         
=================================================================
Total params: 193
Trainable params: 193
Non-trainable params: 0
_________________________________________________________________
None
[Info] Start Importance Splitting on succruns-v1.
Training for 100000 steps ...
    10/100000: episode: 1, duration: 0.066s, episode steps: 10, steps per second: 153, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    20/100000: episode: 2, duration: 0.005s, episode steps: 10, steps per second: 1975, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    30/100000: episode: 3, duration: 0.005s, episode steps: 10, steps per second: 1914, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    40/100000: episode: 4, duration: 0.005s, episode steps: 10, steps per second: 1978, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    50/100000: episode: 5, duration: 0.005s, episode steps: 10, steps per second: 2046, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    60/100000: episode: 6, duration: 0.006s, episode steps: 10, steps per second: 1798, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    70/100000: episode: 7, duration: 0.005s, episode steps: 10, steps per second: 1941, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    80/100000: episode: 8, duration: 0.005s, episode steps: 10, steps per second: 1924, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    90/100000: episode: 9, duration: 0.005s, episode steps: 10, steps per second: 2052, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   100/100000: episode: 10, duration: 0.005s, episode steps: 10, steps per second: 1945, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   110/100000: episode: 11, duration: 0.005s, episode steps: 10, steps per second: 1925, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   120/100000: episode: 12, duration: 0.004s, episode steps: 10, steps per second: 2226, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   130/100000: episode: 13, duration: 0.005s, episode steps: 10, steps per second: 1900, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   140/100000: episode: 14, duration: 0.005s, episode steps: 10, steps per second: 1943, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   150/100000: episode: 15, duration: 0.005s, episode steps: 10, steps per second: 2143, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   160/100000: episode: 16, duration: 0.005s, episode steps: 10, steps per second: 1988, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   170/100000: episode: 17, duration: 0.005s, episode steps: 10, steps per second: 1954, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   180/100000: episode: 18, duration: 0.005s, episode steps: 10, steps per second: 2076, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   190/100000: episode: 19, duration: 0.005s, episode steps: 10, steps per second: 2074, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   200/100000: episode: 20, duration: 0.005s, episode steps: 10, steps per second: 1936, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   210/100000: episode: 21, duration: 0.005s, episode steps: 10, steps per second: 2165, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   220/100000: episode: 22, duration: 0.005s, episode steps: 10, steps per second: 2027, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   230/100000: episode: 23, duration: 0.005s, episode steps: 10, steps per second: 1943, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   240/100000: episode: 24, duration: 0.005s, episode steps: 10, steps per second: 1956, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   250/100000: episode: 25, duration: 0.005s, episode steps: 10, steps per second: 2077, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   260/100000: episode: 26, duration: 0.005s, episode steps: 10, steps per second: 1948, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   270/100000: episode: 27, duration: 0.005s, episode steps: 10, steps per second: 1985, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   280/100000: episode: 28, duration: 0.005s, episode steps: 10, steps per second: 2174, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   290/100000: episode: 29, duration: 0.005s, episode steps: 10, steps per second: 1945, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   300/100000: episode: 30, duration: 0.005s, episode steps: 10, steps per second: 1936, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   310/100000: episode: 31, duration: 0.005s, episode steps: 10, steps per second: 2103, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   320/100000: episode: 32, duration: 0.005s, episode steps: 10, steps per second: 1916, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   330/100000: episode: 33, duration: 0.005s, episode steps: 10, steps per second: 1927, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   340/100000: episode: 34, duration: 0.005s, episode steps: 10, steps per second: 2186, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   350/100000: episode: 35, duration: 0.005s, episode steps: 10, steps per second: 2074, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   360/100000: episode: 36, duration: 0.005s, episode steps: 10, steps per second: 2042, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   370/100000: episode: 37, duration: 0.005s, episode steps: 10, steps per second: 2106, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   380/100000: episode: 38, duration: 0.005s, episode steps: 10, steps per second: 2122, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   390/100000: episode: 39, duration: 0.004s, episode steps: 10, steps per second: 2247, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   400/100000: episode: 40, duration: 0.005s, episode steps: 10, steps per second: 2009, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   410/100000: episode: 41, duration: 0.005s, episode steps: 10, steps per second: 2124, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   420/100000: episode: 42, duration: 0.005s, episode steps: 10, steps per second: 2112, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   430/100000: episode: 43, duration: 0.005s, episode steps: 10, steps per second: 2145, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   440/100000: episode: 44, duration: 0.005s, episode steps: 10, steps per second: 2000, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   450/100000: episode: 45, duration: 0.005s, episode steps: 10, steps per second: 2082, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   460/100000: episode: 46, duration: 0.005s, episode steps: 10, steps per second: 2172, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   470/100000: episode: 47, duration: 0.005s, episode steps: 10, steps per second: 1944, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   480/100000: episode: 48, duration: 0.005s, episode steps: 10, steps per second: 1968, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   490/100000: episode: 49, duration: 0.005s, episode steps: 10, steps per second: 2193, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   500/100000: episode: 50, duration: 0.005s, episode steps: 10, steps per second: 1907, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   510/100000: episode: 51, duration: 0.836s, episode steps: 10, steps per second: 12, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.071900, mae: 0.268733, mean_q: -0.213313
   520/100000: episode: 52, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.059853, mae: 0.252190, mean_q: -0.040266
   530/100000: episode: 53, duration: 0.107s, episode steps: 10, steps per second: 93, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.041996, mae: 0.205472, mean_q: -0.168482
   540/100000: episode: 54, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.035241, mae: 0.191903, mean_q: -0.112710
   550/100000: episode: 55, duration: 0.107s, episode steps: 10, steps per second: 94, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.021988, mae: 0.155564, mean_q: -0.134025
   560/100000: episode: 56, duration: 0.088s, episode steps: 10, steps per second: 114, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.018639, mae: 0.144761, mean_q: -0.144313
   570/100000: episode: 57, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.023278, mae: 0.157529, mean_q: -0.105176
   580/100000: episode: 58, duration: 0.080s, episode steps: 10, steps per second: 126, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.012453, mae: 0.120817, mean_q: -0.103308
   590/100000: episode: 59, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.017252, mae: 0.136592, mean_q: -0.086723
   600/100000: episode: 60, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.009443, mae: 0.111837, mean_q: -0.089002
   610/100000: episode: 61, duration: 0.084s, episode steps: 10, steps per second: 120, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.010711, mae: 0.111618, mean_q: -0.105283
   620/100000: episode: 62, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.009708, mae: 0.109927, mean_q: -0.058104
   630/100000: episode: 63, duration: 0.072s, episode steps: 10, steps per second: 138, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.005671, mae: 0.092321, mean_q: -0.076796
   640/100000: episode: 64, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.008401, mae: 0.101053, mean_q: -0.052706
   650/100000: episode: 65, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.005019, mae: 0.085564, mean_q: -0.059411
   660/100000: episode: 66, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.005071, mae: 0.082616, mean_q: -0.067576
   670/100000: episode: 67, duration: 0.074s, episode steps: 10, steps per second: 134, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.004465, mae: 0.080179, mean_q: -0.046827
   680/100000: episode: 68, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.003846, mae: 0.074322, mean_q: -0.049613
   690/100000: episode: 69, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.004005, mae: 0.070706, mean_q: -0.062443
   700/100000: episode: 70, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002896, mae: 0.066158, mean_q: -0.054093
   710/100000: episode: 71, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.002446, mae: 0.058082, mean_q: -0.051350
   720/100000: episode: 72, duration: 0.088s, episode steps: 10, steps per second: 114, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002504, mae: 0.059772, mean_q: -0.054386
   730/100000: episode: 73, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002239, mae: 0.057362, mean_q: -0.043764
   740/100000: episode: 74, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001789, mae: 0.051245, mean_q: -0.028877
   750/100000: episode: 75, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002211, mae: 0.052922, mean_q: -0.041176
   760/100000: episode: 76, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001610, mae: 0.047488, mean_q: -0.023321
   770/100000: episode: 77, duration: 0.081s, episode steps: 10, steps per second: 124, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001957, mae: 0.048384, mean_q: -0.032277
   780/100000: episode: 78, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001516, mae: 0.044040, mean_q: -0.022304
   790/100000: episode: 79, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001382, mae: 0.041074, mean_q: -0.022327
   800/100000: episode: 80, duration: 0.076s, episode steps: 10, steps per second: 131, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001218, mae: 0.038719, mean_q: -0.031086
   810/100000: episode: 81, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000965, mae: 0.035752, mean_q: -0.023191
   820/100000: episode: 82, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001252, mae: 0.037145, mean_q: -0.017996
   830/100000: episode: 83, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001015, mae: 0.033370, mean_q: -0.017077
   840/100000: episode: 84, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001050, mae: 0.033183, mean_q: -0.019546
   850/100000: episode: 85, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000774, mae: 0.030665, mean_q: -0.007027
   860/100000: episode: 86, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000640, mae: 0.028047, mean_q: -0.016366
   870/100000: episode: 87, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000492, mae: 0.024052, mean_q: -0.011463
   880/100000: episode: 88, duration: 0.072s, episode steps: 10, steps per second: 140, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000408, mae: 0.022897, mean_q: -0.011958
   890/100000: episode: 89, duration: 0.072s, episode steps: 10, steps per second: 138, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000514, mae: 0.024656, mean_q: -0.012971
   900/100000: episode: 90, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000500, mae: 0.023170, mean_q: -0.010763
   910/100000: episode: 91, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000488, mae: 0.023115, mean_q: -0.011061
   920/100000: episode: 92, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000380, mae: 0.020472, mean_q: -0.007375
   930/100000: episode: 93, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000404, mae: 0.020753, mean_q: -0.004151
   940/100000: episode: 94, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000274, mae: 0.016721, mean_q: -0.007471
   950/100000: episode: 95, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000253, mae: 0.016134, mean_q: -0.005925
   960/100000: episode: 96, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000316, mae: 0.017453, mean_q: -0.002873
   970/100000: episode: 97, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000215, mae: 0.015055, mean_q: -0.006026
   980/100000: episode: 98, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000280, mae: 0.015980, mean_q: 0.000341
   990/100000: episode: 99, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000267, mae: 0.014836, mean_q: -0.007034
  1000/100000: episode: 100, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000254, mae: 0.014604, mean_q: -0.003897
  1010/100000: episode: 101, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000243, mae: 0.013982, mean_q: -0.000184
  1020/100000: episode: 102, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000188, mae: 0.012470, mean_q: -0.001210
  1030/100000: episode: 103, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000160, mae: 0.012187, mean_q: -0.004104
  1040/100000: episode: 104, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000232, mae: 0.012935, mean_q: -0.002723
  1050/100000: episode: 105, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000138, mae: 0.010621, mean_q: 0.000128
  1060/100000: episode: 106, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000189, mae: 0.012026, mean_q: -0.000140
  1070/100000: episode: 107, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000210, mae: 0.011563, mean_q: 0.000813
  1080/100000: episode: 108, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000110, mae: 0.009450, mean_q: 0.000135
  1090/100000: episode: 109, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000154, mae: 0.010176, mean_q: -0.000641
  1100/100000: episode: 110, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000127, mae: 0.009578, mean_q: -0.000678
  1110/100000: episode: 111, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000185, mae: 0.010626, mean_q: 0.003021
  1120/100000: episode: 112, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000106, mae: 0.008432, mean_q: 0.000633
  1130/100000: episode: 113, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000127, mae: 0.008237, mean_q: 0.000085
  1140/100000: episode: 114, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000128, mae: 0.008767, mean_q: 0.002279
  1150/100000: episode: 115, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000138, mae: 0.008504, mean_q: 0.003317
  1160/100000: episode: 116, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000127, mae: 0.008496, mean_q: 0.002259
  1170/100000: episode: 117, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000173, mae: 0.008435, mean_q: 0.001435
  1180/100000: episode: 118, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000086, mae: 0.007609, mean_q: 0.000806
  1190/100000: episode: 119, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000082, mae: 0.007109, mean_q: 0.002761
  1200/100000: episode: 120, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000131, mae: 0.008701, mean_q: 0.002378
  1210/100000: episode: 121, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000109, mae: 0.006831, mean_q: 0.001552
  1220/100000: episode: 122, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000092, mae: 0.007457, mean_q: 0.002331
  1230/100000: episode: 123, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000126, mae: 0.008596, mean_q: 0.004651
  1240/100000: episode: 124, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000134, mae: 0.007491, mean_q: 0.003208
  1250/100000: episode: 125, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000095, mae: 0.006407, mean_q: 0.001485
  1260/100000: episode: 126, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000087, mae: 0.006310, mean_q: 0.002930
  1270/100000: episode: 127, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000074, mae: 0.006204, mean_q: 0.002360
  1280/100000: episode: 128, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000139, mae: 0.007420, mean_q: 0.004336
  1290/100000: episode: 129, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000080, mae: 0.005785, mean_q: 0.001890
  1300/100000: episode: 130, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000077, mae: 0.005628, mean_q: 0.003098
  1310/100000: episode: 131, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000078, mae: 0.006668, mean_q: 0.004483
  1320/100000: episode: 132, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000050, mae: 0.005123, mean_q: 0.003381
  1330/100000: episode: 133, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000106, mae: 0.007230, mean_q: 0.004987
  1340/100000: episode: 134, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000132, mae: 0.006691, mean_q: 0.001804
  1350/100000: episode: 135, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000112, mae: 0.007476, mean_q: 0.002190
  1360/100000: episode: 136, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000077, mae: 0.006212, mean_q: 0.001489
  1370/100000: episode: 137, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000079, mae: 0.006706, mean_q: 0.003537
  1380/100000: episode: 138, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000079, mae: 0.006336, mean_q: 0.004057
  1390/100000: episode: 139, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000060, mae: 0.005757, mean_q: 0.003405
  1400/100000: episode: 140, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000090, mae: 0.005620, mean_q: 0.004226
  1410/100000: episode: 141, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000096, mae: 0.005854, mean_q: 0.005808
  1420/100000: episode: 142, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000064, mae: 0.006006, mean_q: 0.003957
  1430/100000: episode: 143, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000070, mae: 0.005506, mean_q: 0.004425
  1440/100000: episode: 144, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000108, mae: 0.005100, mean_q: 0.005086
  1450/100000: episode: 145, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000064, mae: 0.005299, mean_q: 0.003350
  1460/100000: episode: 146, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000129, mae: 0.007134, mean_q: 0.005346
  1470/100000: episode: 147, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000041, mae: 0.004791, mean_q: 0.002631
  1480/100000: episode: 148, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000046, mae: 0.004268, mean_q: 0.004060
  1490/100000: episode: 149, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000035, mae: 0.004271, mean_q: 0.003094
[Info] 1-TH LEVEL FOUND: 0.017242439091205597, Considering 10/100 traces
  1500/100000: episode: 150, duration: 1.101s, episode steps: 10, steps per second: 9, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000045, mae: 0.004128, mean_q: 0.002648
  1508/100000: episode: 151, duration: 0.048s, episode steps: 8, steps per second: 167, episode reward: 0.044, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000054, mae: 0.005434, mean_q: 0.005111
  1516/100000: episode: 152, duration: 0.048s, episode steps: 8, steps per second: 166, episode reward: 0.085, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000216, mae: 0.006932, mean_q: 0.003891
  1524/100000: episode: 153, duration: 0.056s, episode steps: 8, steps per second: 144, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000068, mae: 0.006762, mean_q: 0.002486
  1532/100000: episode: 154, duration: 0.053s, episode steps: 8, steps per second: 151, episode reward: 0.071, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000039, mae: 0.006168, mean_q: 0.006281
  1540/100000: episode: 155, duration: 0.052s, episode steps: 8, steps per second: 154, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000046, mae: 0.005460, mean_q: 0.003760
  1548/100000: episode: 156, duration: 0.088s, episode steps: 8, steps per second: 91, episode reward: 0.214, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000213, mae: 0.007708, mean_q: 0.000968
  1556/100000: episode: 157, duration: 0.079s, episode steps: 8, steps per second: 101, episode reward: 0.023, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000117, mae: 0.008922, mean_q: 0.008536
  1564/100000: episode: 158, duration: 0.051s, episode steps: 8, steps per second: 157, episode reward: 0.146, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000278, mae: 0.010206, mean_q: 0.008268
  1572/100000: episode: 159, duration: 0.054s, episode steps: 8, steps per second: 148, episode reward: 0.348, mean reward: 0.044 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000354, mae: 0.010655, mean_q: 0.005361
  1580/100000: episode: 160, duration: 0.061s, episode steps: 8, steps per second: 131, episode reward: 0.102, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000270, mae: 0.010896, mean_q: 0.003870
  1588/100000: episode: 161, duration: 0.098s, episode steps: 8, steps per second: 82, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.812 [-1.000, 11.000], loss: 0.000413, mae: 0.013064, mean_q: 0.008516
  1596/100000: episode: 162, duration: 0.071s, episode steps: 8, steps per second: 113, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000276, mae: 0.011641, mean_q: 0.002810
  1604/100000: episode: 163, duration: 0.061s, episode steps: 8, steps per second: 132, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000260, mae: 0.011339, mean_q: 0.004233
  1612/100000: episode: 164, duration: 0.074s, episode steps: 8, steps per second: 108, episode reward: 1.317, mean reward: 0.165 [0.002, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.312 [4.000, 11.000], loss: 0.000526, mae: 0.016347, mean_q: 0.010479
  1620/100000: episode: 165, duration: 0.068s, episode steps: 8, steps per second: 118, episode reward: 0.059, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000704, mae: 0.016597, mean_q: 0.006812
  1628/100000: episode: 166, duration: 0.089s, episode steps: 8, steps per second: 90, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000256, mae: 0.013237, mean_q: -0.000983
  1636/100000: episode: 167, duration: 0.074s, episode steps: 8, steps per second: 108, episode reward: 1.317, mean reward: 0.165 [0.002, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.312 [4.000, 11.000], loss: 0.000256, mae: 0.009583, mean_q: 0.004912
  1644/100000: episode: 168, duration: 0.071s, episode steps: 8, steps per second: 113, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001045, mae: 0.017980, mean_q: 0.011657
  1652/100000: episode: 169, duration: 0.072s, episode steps: 8, steps per second: 110, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000894, mae: 0.015253, mean_q: 0.006843
  1660/100000: episode: 170, duration: 0.066s, episode steps: 8, steps per second: 121, episode reward: 0.054, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000388, mae: 0.009477, mean_q: 0.007457
  1668/100000: episode: 171, duration: 0.062s, episode steps: 8, steps per second: 129, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000715, mae: 0.016323, mean_q: 0.013958
  1676/100000: episode: 172, duration: 0.063s, episode steps: 8, steps per second: 126, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000350, mae: 0.017331, mean_q: -0.003365
  1684/100000: episode: 173, duration: 0.081s, episode steps: 8, steps per second: 98, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000614, mae: 0.017363, mean_q: 0.003885
  1692/100000: episode: 174, duration: 0.062s, episode steps: 8, steps per second: 130, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000776, mae: 0.018084, mean_q: 0.011269
  1700/100000: episode: 175, duration: 0.057s, episode steps: 8, steps per second: 140, episode reward: 0.039, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000718, mae: 0.017583, mean_q: 0.011125
  1708/100000: episode: 176, duration: 0.066s, episode steps: 8, steps per second: 121, episode reward: 0.030, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000446, mae: 0.012893, mean_q: 0.003056
  1716/100000: episode: 177, duration: 0.070s, episode steps: 8, steps per second: 114, episode reward: 0.055, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000390, mae: 0.011716, mean_q: 0.008653
  1724/100000: episode: 178, duration: 0.052s, episode steps: 8, steps per second: 155, episode reward: 0.039, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000475, mae: 0.013226, mean_q: 0.007723
  1732/100000: episode: 179, duration: 0.061s, episode steps: 8, steps per second: 130, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000181, mae: 0.010164, mean_q: 0.004402
  1740/100000: episode: 180, duration: 0.044s, episode steps: 8, steps per second: 180, episode reward: 0.049, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000430, mae: 0.013269, mean_q: 0.006873
  1748/100000: episode: 181, duration: 0.051s, episode steps: 8, steps per second: 157, episode reward: 0.215, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000318, mae: 0.012777, mean_q: 0.005004
  1756/100000: episode: 182, duration: 0.056s, episode steps: 8, steps per second: 142, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000297, mae: 0.014856, mean_q: 0.003743
  1764/100000: episode: 183, duration: 0.071s, episode steps: 8, steps per second: 112, episode reward: 0.177, mean reward: 0.022 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.000323, mae: 0.017099, mean_q: 0.007108
  1772/100000: episode: 184, duration: 0.067s, episode steps: 8, steps per second: 119, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000324, mae: 0.014186, mean_q: 0.006266
  1780/100000: episode: 185, duration: 0.056s, episode steps: 8, steps per second: 143, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000316, mae: 0.013513, mean_q: 0.008848
  1788/100000: episode: 186, duration: 0.044s, episode steps: 8, steps per second: 184, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000122, mae: 0.009175, mean_q: 0.006936
  1796/100000: episode: 187, duration: 0.053s, episode steps: 8, steps per second: 150, episode reward: 0.049, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000481, mae: 0.013629, mean_q: 0.007005
  1804/100000: episode: 188, duration: 0.050s, episode steps: 8, steps per second: 160, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000234, mae: 0.011915, mean_q: 0.007283
  1812/100000: episode: 189, duration: 0.061s, episode steps: 8, steps per second: 131, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000604, mae: 0.015610, mean_q: 0.009505
  1820/100000: episode: 190, duration: 0.076s, episode steps: 8, steps per second: 105, episode reward: 0.348, mean reward: 0.044 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000472, mae: 0.017327, mean_q: 0.011201
  1828/100000: episode: 191, duration: 0.055s, episode steps: 8, steps per second: 146, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000506, mae: 0.015691, mean_q: 0.009280
  1836/100000: episode: 192, duration: 0.043s, episode steps: 8, steps per second: 188, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000258, mae: 0.014914, mean_q: 0.005010
  1844/100000: episode: 193, duration: 0.052s, episode steps: 8, steps per second: 153, episode reward: 0.087, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000459, mae: 0.014586, mean_q: 0.004275
  1852/100000: episode: 194, duration: 0.061s, episode steps: 8, steps per second: 130, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000219, mae: 0.012652, mean_q: 0.011969
  1860/100000: episode: 195, duration: 0.078s, episode steps: 8, steps per second: 102, episode reward: 0.067, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000205, mae: 0.012470, mean_q: 0.007378
  1868/100000: episode: 196, duration: 0.041s, episode steps: 8, steps per second: 193, episode reward: 0.054, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000363, mae: 0.012901, mean_q: 0.007524
  1876/100000: episode: 197, duration: 0.041s, episode steps: 8, steps per second: 194, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000299, mae: 0.014665, mean_q: 0.005113
  1884/100000: episode: 198, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.032, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000585, mae: 0.018146, mean_q: 0.014412
  1892/100000: episode: 199, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.032, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000297, mae: 0.016825, mean_q: 0.014802
  1900/100000: episode: 200, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.348, mean reward: 0.044 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000286, mae: 0.012823, mean_q: 0.009299
  1908/100000: episode: 201, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.032, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000278, mae: 0.012291, mean_q: 0.007851
  1916/100000: episode: 202, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.055, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000397, mae: 0.013217, mean_q: 0.011879
  1924/100000: episode: 203, duration: 0.049s, episode steps: 8, steps per second: 164, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000275, mae: 0.011710, mean_q: 0.007806
  1932/100000: episode: 204, duration: 0.051s, episode steps: 8, steps per second: 158, episode reward: 0.051, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000346, mae: 0.012417, mean_q: 0.007304
  1940/100000: episode: 205, duration: 0.044s, episode steps: 8, steps per second: 181, episode reward: 0.071, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000390, mae: 0.012218, mean_q: 0.010450
  1948/100000: episode: 206, duration: 0.040s, episode steps: 8, steps per second: 198, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000360, mae: 0.014113, mean_q: 0.003249
  1956/100000: episode: 207, duration: 0.040s, episode steps: 8, steps per second: 199, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000159, mae: 0.010957, mean_q: 0.006844
  1964/100000: episode: 208, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.214, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000418, mae: 0.013380, mean_q: 0.012160
  1972/100000: episode: 209, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.022, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000256, mae: 0.013260, mean_q: 0.009413
  1980/100000: episode: 210, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000596, mae: 0.016469, mean_q: 0.014828
  1988/100000: episode: 211, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.146, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000240, mae: 0.016541, mean_q: 0.006312
  1996/100000: episode: 212, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000164, mae: 0.011620, mean_q: 0.005352
  2004/100000: episode: 213, duration: 0.039s, episode steps: 8, steps per second: 208, episode reward: 0.032, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000551, mae: 0.013275, mean_q: 0.011734
  2012/100000: episode: 214, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.028, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000242, mae: 0.012591, mean_q: 0.006666
  2020/100000: episode: 215, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.044, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000327, mae: 0.013188, mean_q: 0.010099
  2028/100000: episode: 216, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.023, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000857, mae: 0.017802, mean_q: 0.019866
  2036/100000: episode: 217, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.020, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000451, mae: 0.013375, mean_q: 0.009668
  2044/100000: episode: 218, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.015, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000716, mae: 0.016172, mean_q: 0.011511
  2052/100000: episode: 219, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.030, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000237, mae: 0.013041, mean_q: 0.007577
  2060/100000: episode: 220, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.036, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000155, mae: 0.010265, mean_q: 0.006615
  2068/100000: episode: 221, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.082, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000460, mae: 0.014789, mean_q: 0.012397
  2076/100000: episode: 222, duration: 0.040s, episode steps: 8, steps per second: 202, episode reward: 0.020, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000183, mae: 0.012105, mean_q: 0.012164
  2084/100000: episode: 223, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.146, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000253, mae: 0.012400, mean_q: 0.009869
  2092/100000: episode: 224, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.214, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000211, mae: 0.011177, mean_q: 0.007763
  2100/100000: episode: 225, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.348, mean reward: 0.044 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000113, mae: 0.008970, mean_q: 0.007057
  2108/100000: episode: 226, duration: 0.040s, episode steps: 8, steps per second: 201, episode reward: 0.023, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000486, mae: 0.014227, mean_q: 0.012305
  2116/100000: episode: 227, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.015, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000283, mae: 0.010937, mean_q: 0.012883
  2124/100000: episode: 228, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.097, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000253, mae: 0.013157, mean_q: 0.011432
  2132/100000: episode: 229, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.015, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000451, mae: 0.014440, mean_q: 0.011050
  2140/100000: episode: 230, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.051, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000435, mae: 0.015296, mean_q: 0.006108
  2148/100000: episode: 231, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000291, mae: 0.014000, mean_q: 0.009062
  2156/100000: episode: 232, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000177, mae: 0.009671, mean_q: 0.010639
  2164/100000: episode: 233, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.032, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000224, mae: 0.011207, mean_q: 0.007627
  2172/100000: episode: 234, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.036, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000197, mae: 0.010081, mean_q: 0.006751
  2180/100000: episode: 235, duration: 0.039s, episode steps: 8, steps per second: 208, episode reward: 0.067, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000118, mae: 0.009261, mean_q: 0.007315
  2188/100000: episode: 236, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.044, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000189, mae: 0.009799, mean_q: 0.008919
  2196/100000: episode: 237, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.030, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000617, mae: 0.018886, mean_q: 0.013389
  2204/100000: episode: 238, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000374, mae: 0.013687, mean_q: 0.016069
  2212/100000: episode: 239, duration: 0.041s, episode steps: 8, steps per second: 197, episode reward: 0.065, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000109, mae: 0.008836, mean_q: 0.006011
[Info] 2-TH LEVEL FOUND: 0.08475734293460846, Considering 14/100 traces
  2220/100000: episode: 240, duration: 0.696s, episode steps: 8, steps per second: 11, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000121, mae: 0.010655, mean_q: 0.008955
  2225/100000: episode: 241, duration: 0.030s, episode steps: 5, steps per second: 164, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000906, mae: 0.020018, mean_q: 0.019448
  2230/100000: episode: 242, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000344, mae: 0.014999, mean_q: 0.001201
  2235/100000: episode: 243, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000422, mae: 0.013415, mean_q: 0.016725
  2240/100000: episode: 244, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000127, mae: 0.011346, mean_q: 0.003651
  2245/100000: episode: 245, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000108, mae: 0.008949, mean_q: 0.015955
  2250/100000: episode: 246, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000545, mae: 0.014132, mean_q: 0.007185
  2255/100000: episode: 247, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000409, mae: 0.018066, mean_q: 0.018115
  2260/100000: episode: 248, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000177, mae: 0.013689, mean_q: 0.003512
[Info] FALSIFICATION!
  2264/100000: episode: 249, duration: 0.447s, episode steps: 4, steps per second: 9, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000367, mae: 0.014299, mean_q: 0.005831
  2269/100000: episode: 250, duration: 0.034s, episode steps: 5, steps per second: 148, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000145, mae: 0.010850, mean_q: 0.015129
  2274/100000: episode: 251, duration: 0.033s, episode steps: 5, steps per second: 153, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000164, mae: 0.011483, mean_q: 0.006049
  2279/100000: episode: 252, duration: 0.042s, episode steps: 5, steps per second: 119, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000475, mae: 0.013041, mean_q: 0.005518
  2284/100000: episode: 253, duration: 0.029s, episode steps: 5, steps per second: 170, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002545, mae: 0.023941, mean_q: 0.027170
  2289/100000: episode: 254, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000361, mae: 0.015457, mean_q: 0.006595
  2294/100000: episode: 255, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000247, mae: 0.013367, mean_q: 0.011649
  2299/100000: episode: 256, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000460, mae: 0.015674, mean_q: 0.017469
  2304/100000: episode: 257, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000363, mae: 0.017848, mean_q: 0.002507
  2309/100000: episode: 258, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000221, mae: 0.012579, mean_q: 0.016594
  2314/100000: episode: 259, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000154, mae: 0.013317, mean_q: -0.000133
  2319/100000: episode: 260, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000544, mae: 0.014017, mean_q: 0.010197
  2324/100000: episode: 261, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000192, mae: 0.009651, mean_q: 0.013751
  2329/100000: episode: 262, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000337, mae: 0.012560, mean_q: 0.015289
  2334/100000: episode: 263, duration: 0.034s, episode steps: 5, steps per second: 146, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000377, mae: 0.009843, mean_q: 0.007148
  2339/100000: episode: 264, duration: 0.035s, episode steps: 5, steps per second: 144, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000771, mae: 0.014542, mean_q: 0.016508
  2344/100000: episode: 265, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000211, mae: 0.012124, mean_q: 0.012834
  2349/100000: episode: 266, duration: 0.037s, episode steps: 5, steps per second: 134, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.003020, mae: 0.032589, mean_q: 0.029744
[Info] FALSIFICATION!
  2353/100000: episode: 267, duration: 0.260s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000607, mae: 0.025321, mean_q: -0.004179
  2358/100000: episode: 268, duration: 0.044s, episode steps: 5, steps per second: 114, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000376, mae: 0.017560, mean_q: 0.026458
  2363/100000: episode: 269, duration: 0.035s, episode steps: 5, steps per second: 143, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000492, mae: 0.023242, mean_q: 0.000799
  2368/100000: episode: 270, duration: 0.033s, episode steps: 5, steps per second: 152, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000529, mae: 0.014709, mean_q: 0.014705
  2373/100000: episode: 271, duration: 0.028s, episode steps: 5, steps per second: 179, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000586, mae: 0.013958, mean_q: 0.018244
  2378/100000: episode: 272, duration: 0.032s, episode steps: 5, steps per second: 154, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.003191, mae: 0.022708, mean_q: 0.020062
  2383/100000: episode: 273, duration: 0.037s, episode steps: 5, steps per second: 135, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000789, mae: 0.026769, mean_q: 0.031631
  2388/100000: episode: 274, duration: 0.040s, episode steps: 5, steps per second: 127, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001408, mae: 0.035218, mean_q: 0.015675
  2393/100000: episode: 275, duration: 0.030s, episode steps: 5, steps per second: 168, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002395, mae: 0.028595, mean_q: 0.015191
  2398/100000: episode: 276, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000505, mae: 0.018874, mean_q: 0.022429
  2403/100000: episode: 277, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000595, mae: 0.018533, mean_q: 0.006966
  2408/100000: episode: 278, duration: 0.033s, episode steps: 5, steps per second: 152, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000956, mae: 0.024625, mean_q: 0.033385
  2413/100000: episode: 279, duration: 0.030s, episode steps: 5, steps per second: 165, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002583, mae: 0.030033, mean_q: 0.034399
  2418/100000: episode: 280, duration: 0.034s, episode steps: 5, steps per second: 145, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000861, mae: 0.033362, mean_q: -0.002998
  2423/100000: episode: 281, duration: 0.034s, episode steps: 5, steps per second: 147, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000652, mae: 0.024712, mean_q: 0.032450
  2428/100000: episode: 282, duration: 0.040s, episode steps: 5, steps per second: 126, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000886, mae: 0.024837, mean_q: 0.010178
  2433/100000: episode: 283, duration: 0.029s, episode steps: 5, steps per second: 171, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000389, mae: 0.016972, mean_q: 0.008813
  2438/100000: episode: 284, duration: 0.031s, episode steps: 5, steps per second: 164, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000833, mae: 0.018152, mean_q: 0.019305
  2443/100000: episode: 285, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002993, mae: 0.029075, mean_q: 0.035412
  2448/100000: episode: 286, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000731, mae: 0.023970, mean_q: 0.002320
  2453/100000: episode: 287, duration: 0.036s, episode steps: 5, steps per second: 137, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.004746, mae: 0.037015, mean_q: 0.045360
  2458/100000: episode: 288, duration: 0.042s, episode steps: 5, steps per second: 119, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000822, mae: 0.031418, mean_q: 0.000048
  2463/100000: episode: 289, duration: 0.033s, episode steps: 5, steps per second: 152, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000845, mae: 0.025453, mean_q: 0.034100
  2468/100000: episode: 290, duration: 0.032s, episode steps: 5, steps per second: 159, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000630, mae: 0.023012, mean_q: 0.002427
  2473/100000: episode: 291, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000555, mae: 0.018247, mean_q: 0.015635
  2478/100000: episode: 292, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000515, mae: 0.015158, mean_q: 0.021292
  2483/100000: episode: 293, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000549, mae: 0.015790, mean_q: 0.020770
  2488/100000: episode: 294, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000685, mae: 0.021858, mean_q: 0.024900
  2493/100000: episode: 295, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000626, mae: 0.018807, mean_q: 0.022025
  2498/100000: episode: 296, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000854, mae: 0.020059, mean_q: 0.012393
  2503/100000: episode: 297, duration: 0.035s, episode steps: 5, steps per second: 142, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000815, mae: 0.019211, mean_q: 0.028655
  2508/100000: episode: 298, duration: 0.048s, episode steps: 5, steps per second: 105, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000310, mae: 0.016257, mean_q: 0.015517
  2513/100000: episode: 299, duration: 0.055s, episode steps: 5, steps per second: 90, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001098, mae: 0.023166, mean_q: 0.027213
  2518/100000: episode: 300, duration: 0.034s, episode steps: 5, steps per second: 147, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000582, mae: 0.018395, mean_q: 0.017866
  2523/100000: episode: 301, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000765, mae: 0.020053, mean_q: 0.025272
  2528/100000: episode: 302, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000760, mae: 0.017490, mean_q: 0.019315
  2533/100000: episode: 303, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001103, mae: 0.023886, mean_q: 0.023447
  2538/100000: episode: 304, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002756, mae: 0.039970, mean_q: 0.037084
  2543/100000: episode: 305, duration: 0.041s, episode steps: 5, steps per second: 123, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001486, mae: 0.035445, mean_q: 0.017289
  2548/100000: episode: 306, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001107, mae: 0.035062, mean_q: -0.006431
  2553/100000: episode: 307, duration: 0.045s, episode steps: 5, steps per second: 110, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.003271, mae: 0.040406, mean_q: 0.055238
  2558/100000: episode: 308, duration: 0.057s, episode steps: 5, steps per second: 88, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.003093, mae: 0.024598, mean_q: 0.028875
  2563/100000: episode: 309, duration: 0.041s, episode steps: 5, steps per second: 122, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.003026, mae: 0.032342, mean_q: 0.020927
  2568/100000: episode: 310, duration: 0.054s, episode steps: 5, steps per second: 93, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000987, mae: 0.024331, mean_q: 0.022825
  2573/100000: episode: 311, duration: 0.029s, episode steps: 5, steps per second: 170, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003087, mae: 0.031318, mean_q: 0.012178
  2578/100000: episode: 312, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001366, mae: 0.033016, mean_q: 0.027726
  2583/100000: episode: 313, duration: 0.032s, episode steps: 5, steps per second: 154, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001648, mae: 0.037101, mean_q: 0.034845
  2588/100000: episode: 314, duration: 0.031s, episode steps: 5, steps per second: 160, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.001160, mae: 0.033470, mean_q: -0.002154
  2593/100000: episode: 315, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001701, mae: 0.035531, mean_q: 0.049672
  2598/100000: episode: 316, duration: 0.032s, episode steps: 5, steps per second: 156, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001428, mae: 0.028319, mean_q: 0.010031
[Info] FALSIFICATION!
  2602/100000: episode: 317, duration: 0.377s, episode steps: 4, steps per second: 11, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000650, mae: 0.021474, mean_q: 0.030898
  2607/100000: episode: 318, duration: 0.036s, episode steps: 5, steps per second: 139, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000522, mae: 0.023976, mean_q: 0.010583
  2612/100000: episode: 319, duration: 0.034s, episode steps: 5, steps per second: 148, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000537, mae: 0.022008, mean_q: 0.026866
  2617/100000: episode: 320, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001259, mae: 0.032426, mean_q: 0.025368
  2622/100000: episode: 321, duration: 0.057s, episode steps: 5, steps per second: 88, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002817, mae: 0.030041, mean_q: 0.021550
[Info] FALSIFICATION!
  2626/100000: episode: 322, duration: 0.383s, episode steps: 4, steps per second: 10, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001061, mae: 0.020964, mean_q: 0.029012
  2631/100000: episode: 323, duration: 0.055s, episode steps: 5, steps per second: 90, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000939, mae: 0.018506, mean_q: 0.025595
  2636/100000: episode: 324, duration: 0.031s, episode steps: 5, steps per second: 163, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000421, mae: 0.015043, mean_q: 0.019265
  2641/100000: episode: 325, duration: 0.033s, episode steps: 5, steps per second: 151, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001530, mae: 0.029010, mean_q: 0.030493
[Info] Complete ISplit Iteration
[Info] Levels: [0.01724244, 0.08475734, 0.36065397]
[Info] Cond. Prob: [0.1, 0.14, 0.04]
[Info] Error Prob: 0.0005600000000000001

  2646/100000: episode: 326, duration: 1.388s, episode steps: 5, steps per second: 4, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002969, mae: 0.024557, mean_q: 0.031707
  2656/100000: episode: 327, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001001, mae: 0.031743, mean_q: 0.014642
  2666/100000: episode: 328, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001321, mae: 0.032579, mean_q: 0.025676
  2676/100000: episode: 329, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000414, mae: 0.016698, mean_q: 0.015631
  2686/100000: episode: 330, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.002013, mae: 0.023775, mean_q: 0.027753
  2696/100000: episode: 331, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001211, mae: 0.026897, mean_q: 0.030077
  2706/100000: episode: 332, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002505, mae: 0.040657, mean_q: 0.036625
  2716/100000: episode: 333, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001125, mae: 0.028987, mean_q: 0.022153
  2726/100000: episode: 334, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001112, mae: 0.027004, mean_q: 0.024854
  2736/100000: episode: 335, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001403, mae: 0.022061, mean_q: 0.019412
  2746/100000: episode: 336, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000924, mae: 0.021377, mean_q: 0.023367
  2756/100000: episode: 337, duration: 0.106s, episode steps: 10, steps per second: 94, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002354, mae: 0.030228, mean_q: 0.034287
  2766/100000: episode: 338, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001141, mae: 0.033179, mean_q: 0.021221
  2776/100000: episode: 339, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000820, mae: 0.023451, mean_q: 0.021461
  2786/100000: episode: 340, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000780, mae: 0.021443, mean_q: 0.025215
  2796/100000: episode: 341, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001818, mae: 0.027295, mean_q: 0.026033
  2806/100000: episode: 342, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002124, mae: 0.029672, mean_q: 0.030234
  2816/100000: episode: 343, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001987, mae: 0.029301, mean_q: 0.027386
  2826/100000: episode: 344, duration: 0.097s, episode steps: 10, steps per second: 104, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.003061, mae: 0.035503, mean_q: 0.032170
  2836/100000: episode: 345, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.002277, mae: 0.038124, mean_q: 0.021391
  2846/100000: episode: 346, duration: 0.107s, episode steps: 10, steps per second: 94, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002058, mae: 0.027533, mean_q: 0.026576
  2856/100000: episode: 347, duration: 0.078s, episode steps: 10, steps per second: 127, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.003024, mae: 0.029883, mean_q: 0.031169
  2866/100000: episode: 348, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001079, mae: 0.028820, mean_q: 0.019696
  2876/100000: episode: 349, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000664, mae: 0.021655, mean_q: 0.018668
  2886/100000: episode: 350, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.002196, mae: 0.031748, mean_q: 0.039047
  2896/100000: episode: 351, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001073, mae: 0.030298, mean_q: 0.019529
  2906/100000: episode: 352, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001257, mae: 0.023439, mean_q: 0.021941
  2916/100000: episode: 353, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001720, mae: 0.022247, mean_q: 0.020487
  2926/100000: episode: 354, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001379, mae: 0.020451, mean_q: 0.026044
  2936/100000: episode: 355, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001828, mae: 0.022475, mean_q: 0.021128
  2946/100000: episode: 356, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001011, mae: 0.023423, mean_q: 0.029467
  2956/100000: episode: 357, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002755, mae: 0.035514, mean_q: 0.028186
  2966/100000: episode: 358, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000969, mae: 0.024664, mean_q: 0.022886
  2976/100000: episode: 359, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002099, mae: 0.026610, mean_q: 0.027923
  2986/100000: episode: 360, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000824, mae: 0.023423, mean_q: 0.026217
  2996/100000: episode: 361, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000716, mae: 0.022341, mean_q: 0.012153
  3006/100000: episode: 362, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001045, mae: 0.023633, mean_q: 0.023393
  3016/100000: episode: 363, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.003847, mae: 0.031021, mean_q: 0.037823
  3026/100000: episode: 364, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.003664, mae: 0.030371, mean_q: 0.021614
  3036/100000: episode: 365, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000962, mae: 0.026342, mean_q: 0.019188
  3046/100000: episode: 366, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001145, mae: 0.028244, mean_q: 0.024743
  3056/100000: episode: 367, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.003677, mae: 0.031303, mean_q: 0.022325
  3066/100000: episode: 368, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001761, mae: 0.029656, mean_q: 0.022667
  3076/100000: episode: 369, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.003038, mae: 0.033872, mean_q: 0.016670
  3086/100000: episode: 370, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001181, mae: 0.034674, mean_q: 0.019414
  3096/100000: episode: 371, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.003078, mae: 0.037652, mean_q: 0.033826
  3106/100000: episode: 372, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001235, mae: 0.029974, mean_q: 0.020029
  3116/100000: episode: 373, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.005340, mae: 0.041003, mean_q: 0.040469
  3126/100000: episode: 374, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.003925, mae: 0.036913, mean_q: 0.029706
  3136/100000: episode: 375, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001795, mae: 0.024586, mean_q: 0.020888
  3146/100000: episode: 376, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002078, mae: 0.032648, mean_q: 0.029764
  3156/100000: episode: 377, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001938, mae: 0.027246, mean_q: 0.016226
  3166/100000: episode: 378, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002569, mae: 0.032181, mean_q: 0.024992
  3176/100000: episode: 379, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000759, mae: 0.024560, mean_q: 0.010515
  3186/100000: episode: 380, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002652, mae: 0.032479, mean_q: 0.036196
  3196/100000: episode: 381, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002730, mae: 0.029466, mean_q: 0.024383
  3206/100000: episode: 382, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001768, mae: 0.033645, mean_q: 0.033148
  3216/100000: episode: 383, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.003296, mae: 0.034500, mean_q: 0.038481
  3226/100000: episode: 384, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001566, mae: 0.027635, mean_q: 0.015109
  3236/100000: episode: 385, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.001592, mae: 0.024080, mean_q: 0.020906
  3246/100000: episode: 386, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000662, mae: 0.021069, mean_q: 0.018238
  3256/100000: episode: 387, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001452, mae: 0.021771, mean_q: 0.024905
  3266/100000: episode: 388, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001730, mae: 0.029785, mean_q: 0.019776
  3276/100000: episode: 389, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001674, mae: 0.026615, mean_q: 0.025086
  3286/100000: episode: 390, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001632, mae: 0.019915, mean_q: 0.018356
  3296/100000: episode: 391, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000866, mae: 0.024678, mean_q: 0.021649
  3306/100000: episode: 392, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000864, mae: 0.023561, mean_q: 0.020520
  3316/100000: episode: 393, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001710, mae: 0.022795, mean_q: 0.016788
  3326/100000: episode: 394, duration: 0.083s, episode steps: 10, steps per second: 121, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001810, mae: 0.022942, mean_q: 0.020435
  3336/100000: episode: 395, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002443, mae: 0.027331, mean_q: 0.031201
  3346/100000: episode: 396, duration: 0.073s, episode steps: 10, steps per second: 138, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000569, mae: 0.017752, mean_q: 0.018468
  3356/100000: episode: 397, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000838, mae: 0.022150, mean_q: 0.027319
  3366/100000: episode: 398, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000879, mae: 0.023094, mean_q: 0.025859
  3376/100000: episode: 399, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002125, mae: 0.028027, mean_q: 0.019005
  3386/100000: episode: 400, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000629, mae: 0.022058, mean_q: 0.020171
  3396/100000: episode: 401, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001673, mae: 0.024469, mean_q: 0.026837
  3406/100000: episode: 402, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002246, mae: 0.030035, mean_q: 0.033464
  3416/100000: episode: 403, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000803, mae: 0.025499, mean_q: 0.018054
  3426/100000: episode: 404, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000815, mae: 0.022240, mean_q: 0.021645
  3436/100000: episode: 405, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000772, mae: 0.019440, mean_q: 0.014711
  3446/100000: episode: 406, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000473, mae: 0.016037, mean_q: 0.016945
  3456/100000: episode: 407, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000901, mae: 0.026437, mean_q: 0.018208
  3466/100000: episode: 408, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002268, mae: 0.026946, mean_q: 0.031565
  3476/100000: episode: 409, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001449, mae: 0.021235, mean_q: 0.023717
  3486/100000: episode: 410, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000739, mae: 0.021468, mean_q: 0.015173
  3496/100000: episode: 411, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001665, mae: 0.020372, mean_q: 0.024698
  3506/100000: episode: 412, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000643, mae: 0.020598, mean_q: 0.016960
  3516/100000: episode: 413, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001315, mae: 0.020588, mean_q: 0.017168
  3526/100000: episode: 414, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000555, mae: 0.017994, mean_q: 0.013350
  3536/100000: episode: 415, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001866, mae: 0.025139, mean_q: 0.031382
  3546/100000: episode: 416, duration: 0.107s, episode steps: 10, steps per second: 93, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000887, mae: 0.025928, mean_q: 0.014695
  3556/100000: episode: 417, duration: 0.098s, episode steps: 10, steps per second: 102, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001662, mae: 0.024070, mean_q: 0.020326
  3566/100000: episode: 418, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001720, mae: 0.023029, mean_q: 0.021786
  3576/100000: episode: 419, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001490, mae: 0.022589, mean_q: 0.026052
  3586/100000: episode: 420, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000909, mae: 0.024071, mean_q: 0.019354
  3596/100000: episode: 421, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000906, mae: 0.024533, mean_q: 0.025442
  3606/100000: episode: 422, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000664, mae: 0.019381, mean_q: 0.017184
  3616/100000: episode: 423, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001511, mae: 0.019087, mean_q: 0.020943
  3626/100000: episode: 424, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000654, mae: 0.019335, mean_q: 0.022509
  3636/100000: episode: 425, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000741, mae: 0.017479, mean_q: 0.024588
[Info] 1-TH LEVEL FOUND: 0.049212172627449036, Considering 10/100 traces
  3646/100000: episode: 426, duration: 0.801s, episode steps: 10, steps per second: 12, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001661, mae: 0.021803, mean_q: 0.026533
  3653/100000: episode: 427, duration: 0.124s, episode steps: 7, steps per second: 56, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000269, mae: 0.015542, mean_q: -0.000456
  3660/100000: episode: 428, duration: 0.062s, episode steps: 7, steps per second: 114, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000679, mae: 0.018843, mean_q: 0.023419
  3667/100000: episode: 429, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000604, mae: 0.018413, mean_q: 0.024004
  3671/100000: episode: 430, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000659, mae: 0.015523, mean_q: 0.021648
  3678/100000: episode: 431, duration: 0.051s, episode steps: 7, steps per second: 137, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000624, mae: 0.015361, mean_q: 0.019121
  3685/100000: episode: 432, duration: 0.065s, episode steps: 7, steps per second: 107, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000511, mae: 0.014836, mean_q: 0.020413
  3689/100000: episode: 433, duration: 0.031s, episode steps: 4, steps per second: 129, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000899, mae: 0.020050, mean_q: 0.013281
  3696/100000: episode: 434, duration: 0.044s, episode steps: 7, steps per second: 158, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000557, mae: 0.014128, mean_q: 0.015269
  3703/100000: episode: 435, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001711, mae: 0.016686, mean_q: 0.016265
  3707/100000: episode: 436, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.005964, mae: 0.035061, mean_q: 0.034138
  3714/100000: episode: 437, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.001886, mae: 0.029845, mean_q: 0.025668
  3718/100000: episode: 438, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.004185, mae: 0.032423, mean_q: 0.009848
  3725/100000: episode: 439, duration: 0.040s, episode steps: 7, steps per second: 174, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002630, mae: 0.036604, mean_q: 0.040362
  3732/100000: episode: 440, duration: 0.037s, episode steps: 7, steps per second: 191, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000992, mae: 0.025232, mean_q: 0.018842
  3736/100000: episode: 441, duration: 0.026s, episode steps: 4, steps per second: 153, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000524, mae: 0.019482, mean_q: 0.008260
  3743/100000: episode: 442, duration: 0.080s, episode steps: 7, steps per second: 87, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000563, mae: 0.019619, mean_q: 0.020008
  3750/100000: episode: 443, duration: 0.050s, episode steps: 7, steps per second: 141, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.002442, mae: 0.024517, mean_q: 0.019015
  3757/100000: episode: 444, duration: 0.054s, episode steps: 7, steps per second: 129, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001092, mae: 0.028844, mean_q: 0.021952
  3761/100000: episode: 445, duration: 0.032s, episode steps: 4, steps per second: 126, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000546, mae: 0.019533, mean_q: 0.023177
  3768/100000: episode: 446, duration: 0.041s, episode steps: 7, steps per second: 170, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002345, mae: 0.022715, mean_q: 0.018167
  3775/100000: episode: 447, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000822, mae: 0.024401, mean_q: 0.024879
[Info] FALSIFICATION!
  3781/100000: episode: 448, duration: 0.267s, episode steps: 6, steps per second: 22, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000682, mae: 0.018485, mean_q: 0.021360
  3788/100000: episode: 449, duration: 0.039s, episode steps: 7, steps per second: 180, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000566, mae: 0.016892, mean_q: 0.013460
  3795/100000: episode: 450, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000901, mae: 0.020317, mean_q: 0.024755
  3802/100000: episode: 451, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000528, mae: 0.016501, mean_q: 0.024352
  3809/100000: episode: 452, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.001068, mae: 0.020391, mean_q: 0.024681
  3813/100000: episode: 453, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000997, mae: 0.025074, mean_q: 0.020174
  3820/100000: episode: 454, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000372, mae: 0.013911, mean_q: 0.015538
  3827/100000: episode: 455, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000515, mae: 0.016887, mean_q: 0.014107
  3834/100000: episode: 456, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002191, mae: 0.027757, mean_q: 0.037719
  3841/100000: episode: 457, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000496, mae: 0.022697, mean_q: -0.001074
  3848/100000: episode: 458, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.002056, mae: 0.022859, mean_q: 0.023743
  3852/100000: episode: 459, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000436, mae: 0.018480, mean_q: 0.006497
  3859/100000: episode: 460, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.002171, mae: 0.021465, mean_q: 0.024181
  3863/100000: episode: 461, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003387, mae: 0.025912, mean_q: 0.011793
  3870/100000: episode: 462, duration: 0.042s, episode steps: 7, steps per second: 165, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001012, mae: 0.024536, mean_q: 0.024253
  3877/100000: episode: 463, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000516, mae: 0.016630, mean_q: 0.016867
  3884/100000: episode: 464, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000912, mae: 0.021085, mean_q: 0.020928
  3888/100000: episode: 465, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002971, mae: 0.019519, mean_q: 0.012961
  3895/100000: episode: 466, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001524, mae: 0.020594, mean_q: 0.029380
  3902/100000: episode: 467, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.002174, mae: 0.026639, mean_q: 0.031712
  3909/100000: episode: 468, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000435, mae: 0.016881, mean_q: 0.010585
  3913/100000: episode: 469, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000473, mae: 0.016936, mean_q: 0.021714
  3920/100000: episode: 470, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.002699, mae: 0.022451, mean_q: 0.018347
  3927/100000: episode: 471, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000579, mae: 0.018049, mean_q: 0.019488
  3934/100000: episode: 472, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.002338, mae: 0.026297, mean_q: 0.033717
  3941/100000: episode: 473, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001503, mae: 0.030741, mean_q: 0.025151
  3948/100000: episode: 474, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000936, mae: 0.024453, mean_q: 0.009455
  3955/100000: episode: 475, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000649, mae: 0.023618, mean_q: 0.020950
  3962/100000: episode: 476, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.002020, mae: 0.029247, mean_q: 0.034882
  3969/100000: episode: 477, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.002079, mae: 0.028070, mean_q: 0.027734
  3973/100000: episode: 478, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000517, mae: 0.022953, mean_q: 0.017060
  3980/100000: episode: 479, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.003648, mae: 0.034761, mean_q: 0.036462
  3987/100000: episode: 480, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000741, mae: 0.023602, mean_q: 0.006905
  3994/100000: episode: 481, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000551, mae: 0.018259, mean_q: 0.021373
  3998/100000: episode: 482, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003400, mae: 0.027086, mean_q: 0.016095
  4002/100000: episode: 483, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001193, mae: 0.030739, mean_q: 0.042739
  4009/100000: episode: 484, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.002337, mae: 0.029846, mean_q: 0.034683
  4016/100000: episode: 485, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001094, mae: 0.031682, mean_q: 0.004207
  4023/100000: episode: 486, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000717, mae: 0.023298, mean_q: 0.022877
  4030/100000: episode: 487, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.001239, mae: 0.025429, mean_q: 0.025501
  4037/100000: episode: 488, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.002440, mae: 0.030932, mean_q: 0.033778
  4041/100000: episode: 489, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001038, mae: 0.030554, mean_q: 0.000993
  4048/100000: episode: 490, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000820, mae: 0.024442, mean_q: 0.027364
  4055/100000: episode: 491, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001233, mae: 0.025141, mean_q: 0.014669
  4059/100000: episode: 492, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000960, mae: 0.027205, mean_q: 0.038509
  4066/100000: episode: 493, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.002122, mae: 0.033019, mean_q: 0.013212
  4070/100000: episode: 494, duration: 0.020s, episode steps: 4, steps per second: 198, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001140, mae: 0.035214, mean_q: 0.048524
  4074/100000: episode: 495, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003930, mae: 0.042018, mean_q: 0.000189
  4081/100000: episode: 496, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.002099, mae: 0.037133, mean_q: 0.041668
  4088/100000: episode: 497, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.002352, mae: 0.031967, mean_q: 0.019568
  4095/100000: episode: 498, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.003302, mae: 0.028471, mean_q: 0.020053
  4102/100000: episode: 499, duration: 0.033s, episode steps: 7, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.002113, mae: 0.025683, mean_q: 0.033117
  4109/100000: episode: 500, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001912, mae: 0.025201, mean_q: 0.027222
  4116/100000: episode: 501, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000887, mae: 0.025650, mean_q: 0.005208
  4120/100000: episode: 502, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001186, mae: 0.024538, mean_q: 0.025927
  4127/100000: episode: 503, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000649, mae: 0.020785, mean_q: 0.016251
  4134/100000: episode: 504, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001866, mae: 0.022521, mean_q: 0.019125
  4138/100000: episode: 505, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000617, mae: 0.020156, mean_q: 0.016210
  4142/100000: episode: 506, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002600, mae: 0.022177, mean_q: 0.022779
  4146/100000: episode: 507, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000766, mae: 0.021941, mean_q: 0.030533
  4153/100000: episode: 508, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001958, mae: 0.024205, mean_q: 0.025968
  4160/100000: episode: 509, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001059, mae: 0.024978, mean_q: 0.012721
  4167/100000: episode: 510, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000458, mae: 0.016001, mean_q: 0.019561
  4174/100000: episode: 511, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.002272, mae: 0.025989, mean_q: 0.033816
  4178/100000: episode: 512, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.005258, mae: 0.035033, mean_q: 0.013951
  4185/100000: episode: 513, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.002871, mae: 0.047122, mean_q: 0.049341
  4192/100000: episode: 514, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.001607, mae: 0.037884, mean_q: 0.023537
  4199/100000: episode: 515, duration: 0.037s, episode steps: 7, steps per second: 192, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.002102, mae: 0.033578, mean_q: 0.008743
[Info] Complete ISplit Iteration
[Info] Levels: [0.049212173, 0.37422526]
[Info] Cond. Prob: [0.1, 0.01]
[Info] Error Prob: 0.001

  4206/100000: episode: 516, duration: 0.860s, episode steps: 7, steps per second: 8, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000830, mae: 0.021963, mean_q: 0.027358
  4216/100000: episode: 517, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001622, mae: 0.032162, mean_q: 0.034150
  4226/100000: episode: 518, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002150, mae: 0.039430, mean_q: 0.030941
  4236/100000: episode: 519, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001361, mae: 0.028332, mean_q: 0.023878
  4246/100000: episode: 520, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001800, mae: 0.026778, mean_q: 0.032138
  4256/100000: episode: 521, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001927, mae: 0.030396, mean_q: 0.021511
  4266/100000: episode: 522, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.001172, mae: 0.033246, mean_q: 0.011787
  4276/100000: episode: 523, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000502, mae: 0.019191, mean_q: 0.019439
  4286/100000: episode: 524, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001907, mae: 0.028543, mean_q: 0.030591
  4296/100000: episode: 525, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001021, mae: 0.022677, mean_q: 0.031449
  4306/100000: episode: 526, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002966, mae: 0.027987, mean_q: 0.031339
  4316/100000: episode: 527, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000744, mae: 0.022526, mean_q: 0.016926
  4326/100000: episode: 528, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000635, mae: 0.022443, mean_q: 0.016958
  4336/100000: episode: 529, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000695, mae: 0.023316, mean_q: 0.016493
  4346/100000: episode: 530, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001429, mae: 0.024779, mean_q: 0.016958
  4356/100000: episode: 531, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.003737, mae: 0.031166, mean_q: 0.034534
  4366/100000: episode: 532, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001972, mae: 0.032347, mean_q: 0.012537
  4376/100000: episode: 533, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001324, mae: 0.033274, mean_q: 0.024060
  4386/100000: episode: 534, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000901, mae: 0.023997, mean_q: 0.019846
  4396/100000: episode: 535, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001557, mae: 0.022516, mean_q: 0.021147
  4406/100000: episode: 536, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001591, mae: 0.023557, mean_q: 0.028280
  4416/100000: episode: 537, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001433, mae: 0.020031, mean_q: 0.021529
  4426/100000: episode: 538, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001032, mae: 0.028122, mean_q: 0.011012
  4436/100000: episode: 539, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000369, mae: 0.016470, mean_q: 0.014085
  4446/100000: episode: 540, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000982, mae: 0.021084, mean_q: 0.023206
  4456/100000: episode: 541, duration: 0.071s, episode steps: 10, steps per second: 142, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001622, mae: 0.021530, mean_q: 0.022412
  4466/100000: episode: 542, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002423, mae: 0.023750, mean_q: 0.017128
  4476/100000: episode: 543, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000489, mae: 0.015617, mean_q: 0.019854
  4486/100000: episode: 544, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000798, mae: 0.019601, mean_q: 0.018679
  4496/100000: episode: 545, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000772, mae: 0.020390, mean_q: 0.014933
  4506/100000: episode: 546, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001395, mae: 0.022431, mean_q: 0.022637
  4516/100000: episode: 547, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002538, mae: 0.027969, mean_q: 0.021368
  4526/100000: episode: 548, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001017, mae: 0.024467, mean_q: 0.023202
  4536/100000: episode: 549, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001246, mae: 0.017089, mean_q: 0.021050
  4546/100000: episode: 550, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002197, mae: 0.023621, mean_q: 0.021442
  4556/100000: episode: 551, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000758, mae: 0.018002, mean_q: 0.019736
  4566/100000: episode: 552, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001708, mae: 0.021599, mean_q: 0.026335
  4576/100000: episode: 553, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000609, mae: 0.016632, mean_q: 0.012901
  4586/100000: episode: 554, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000663, mae: 0.023100, mean_q: 0.015736
  4596/100000: episode: 555, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002472, mae: 0.022389, mean_q: 0.026675
  4606/100000: episode: 556, duration: 0.104s, episode steps: 10, steps per second: 96, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001957, mae: 0.025354, mean_q: 0.030098
  4616/100000: episode: 557, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002351, mae: 0.025427, mean_q: 0.025205
  4626/100000: episode: 558, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000751, mae: 0.019381, mean_q: 0.019828
  4636/100000: episode: 559, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000680, mae: 0.019476, mean_q: 0.022652
  4646/100000: episode: 560, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001238, mae: 0.019928, mean_q: 0.024049
  4656/100000: episode: 561, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001749, mae: 0.022487, mean_q: 0.019393
  4666/100000: episode: 562, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000716, mae: 0.015630, mean_q: 0.019038
  4676/100000: episode: 563, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001773, mae: 0.022901, mean_q: 0.024868
  4686/100000: episode: 564, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000922, mae: 0.019963, mean_q: 0.018708
  4696/100000: episode: 565, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001330, mae: 0.020705, mean_q: 0.025787
  4706/100000: episode: 566, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001415, mae: 0.023797, mean_q: 0.020123
  4716/100000: episode: 567, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000701, mae: 0.025091, mean_q: 0.009761
  4726/100000: episode: 568, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000465, mae: 0.014889, mean_q: 0.011011
  4736/100000: episode: 569, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001741, mae: 0.021318, mean_q: 0.022991
  4746/100000: episode: 570, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000665, mae: 0.018715, mean_q: 0.018518
  4756/100000: episode: 571, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000546, mae: 0.018838, mean_q: 0.012760
  4766/100000: episode: 572, duration: 0.055s, episode steps: 10, steps per second: 180, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002372, mae: 0.024315, mean_q: 0.027345
  4776/100000: episode: 573, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000985, mae: 0.025202, mean_q: 0.021660
  4786/100000: episode: 574, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001574, mae: 0.022125, mean_q: 0.026679
  4796/100000: episode: 575, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.001784, mae: 0.023290, mean_q: 0.015482
  4806/100000: episode: 576, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001568, mae: 0.019771, mean_q: 0.023174
  4816/100000: episode: 577, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000637, mae: 0.019149, mean_q: 0.016957
  4826/100000: episode: 578, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000776, mae: 0.022745, mean_q: 0.018130
  4836/100000: episode: 579, duration: 0.084s, episode steps: 10, steps per second: 118, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000606, mae: 0.015514, mean_q: 0.015567
  4846/100000: episode: 580, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001759, mae: 0.021465, mean_q: 0.014579
  4856/100000: episode: 581, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001452, mae: 0.027183, mean_q: 0.033904
  4866/100000: episode: 582, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000738, mae: 0.019825, mean_q: 0.016271
  4876/100000: episode: 583, duration: 0.107s, episode steps: 10, steps per second: 94, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000662, mae: 0.019492, mean_q: 0.014139
  4886/100000: episode: 584, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000642, mae: 0.019555, mean_q: 0.019741
  4896/100000: episode: 585, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001601, mae: 0.022491, mean_q: 0.023677
  4906/100000: episode: 586, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000705, mae: 0.017194, mean_q: 0.024462
  4916/100000: episode: 587, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000573, mae: 0.015861, mean_q: 0.018104
  4926/100000: episode: 588, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001780, mae: 0.020813, mean_q: 0.024416
  4936/100000: episode: 589, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000479, mae: 0.018829, mean_q: 0.006715
  4946/100000: episode: 590, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001659, mae: 0.027181, mean_q: 0.026856
  4956/100000: episode: 591, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000435, mae: 0.015698, mean_q: 0.022430
  4966/100000: episode: 592, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000581, mae: 0.017560, mean_q: 0.018692
  4976/100000: episode: 593, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001808, mae: 0.025600, mean_q: 0.019157
  4986/100000: episode: 594, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000980, mae: 0.027022, mean_q: 0.019586
  4996/100000: episode: 595, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000735, mae: 0.020518, mean_q: 0.013893
  5006/100000: episode: 596, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000530, mae: 0.018902, mean_q: 0.015048
  5016/100000: episode: 597, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001578, mae: 0.019969, mean_q: 0.022469
  5026/100000: episode: 598, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000504, mae: 0.016795, mean_q: 0.016508
  5036/100000: episode: 599, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.003358, mae: 0.027048, mean_q: 0.028350
  5046/100000: episode: 600, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.004060, mae: 0.034799, mean_q: 0.027462
  5056/100000: episode: 601, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000985, mae: 0.033287, mean_q: 0.012114
  5066/100000: episode: 602, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001319, mae: 0.020795, mean_q: 0.021052
  5076/100000: episode: 603, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000892, mae: 0.021121, mean_q: 0.020819
  5086/100000: episode: 604, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001565, mae: 0.021362, mean_q: 0.019906
  5096/100000: episode: 605, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.003653, mae: 0.024786, mean_q: 0.026393
  5106/100000: episode: 606, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001996, mae: 0.031809, mean_q: 0.025264
  5116/100000: episode: 607, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001314, mae: 0.035519, mean_q: 0.019079
  5126/100000: episode: 608, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001976, mae: 0.032120, mean_q: 0.027984
  5136/100000: episode: 609, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002468, mae: 0.027078, mean_q: 0.024086
  5146/100000: episode: 610, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002206, mae: 0.027225, mean_q: 0.029559
  5156/100000: episode: 611, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001275, mae: 0.029349, mean_q: 0.013316
  5166/100000: episode: 612, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001513, mae: 0.027424, mean_q: 0.025575
  5176/100000: episode: 613, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001453, mae: 0.022813, mean_q: 0.030305
  5186/100000: episode: 614, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001121, mae: 0.022316, mean_q: 0.022276
  5196/100000: episode: 615, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000789, mae: 0.024336, mean_q: 0.017520
[Info] 1-TH LEVEL FOUND: 0.02910425141453743, Considering 10/100 traces
  5206/100000: episode: 616, duration: 1.073s, episode steps: 10, steps per second: 9, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000507, mae: 0.016046, mean_q: 0.017388
  5213/100000: episode: 617, duration: 0.101s, episode steps: 7, steps per second: 70, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000498, mae: 0.014899, mean_q: 0.012638
  5216/100000: episode: 618, duration: 0.043s, episode steps: 3, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.833 [-1.000, 11.000], loss: 0.000403, mae: 0.015621, mean_q: 0.016779
  5219/100000: episode: 619, duration: 0.031s, episode steps: 3, steps per second: 97, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000785, mae: 0.022071, mean_q: 0.011315
  5226/100000: episode: 620, duration: 0.068s, episode steps: 7, steps per second: 103, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.001712, mae: 0.021911, mean_q: 0.025144
  5233/100000: episode: 621, duration: 0.052s, episode steps: 7, steps per second: 134, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000650, mae: 0.022338, mean_q: 0.008708
  5240/100000: episode: 622, duration: 0.060s, episode steps: 7, steps per second: 116, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001809, mae: 0.023985, mean_q: 0.027925
  5247/100000: episode: 623, duration: 0.038s, episode steps: 7, steps per second: 185, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.003099, mae: 0.021080, mean_q: 0.020356
  5254/100000: episode: 624, duration: 0.050s, episode steps: 7, steps per second: 141, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000969, mae: 0.027347, mean_q: 0.020423
  5261/100000: episode: 625, duration: 0.053s, episode steps: 7, steps per second: 133, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000971, mae: 0.022871, mean_q: 0.031812
  5264/100000: episode: 626, duration: 0.020s, episode steps: 3, steps per second: 147, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000990, mae: 0.025262, mean_q: 0.005015
  5267/100000: episode: 627, duration: 0.023s, episode steps: 3, steps per second: 132, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.667 [-1.000, 11.000], loss: 0.000516, mae: 0.018946, mean_q: 0.014655
  5274/100000: episode: 628, duration: 0.053s, episode steps: 7, steps per second: 133, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000514, mae: 0.018245, mean_q: 0.010689
  5281/100000: episode: 629, duration: 0.051s, episode steps: 7, steps per second: 138, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000576, mae: 0.014725, mean_q: 0.016654
  5284/100000: episode: 630, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.667 [-1.000, 11.000], loss: 0.000727, mae: 0.016064, mean_q: 0.026569
  5287/100000: episode: 631, duration: 0.020s, episode steps: 3, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.667 [-1.000, 11.000], loss: 0.000458, mae: 0.014316, mean_q: 0.021170
  5294/100000: episode: 632, duration: 0.043s, episode steps: 7, steps per second: 162, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000741, mae: 0.021229, mean_q: 0.013843
  5301/100000: episode: 633, duration: 0.049s, episode steps: 7, steps per second: 143, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001898, mae: 0.022801, mean_q: 0.027015
  5308/100000: episode: 634, duration: 0.058s, episode steps: 7, steps per second: 120, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000747, mae: 0.018816, mean_q: 0.016828
  5311/100000: episode: 635, duration: 0.024s, episode steps: 3, steps per second: 122, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000683, mae: 0.019288, mean_q: 0.021360
  5314/100000: episode: 636, duration: 0.023s, episode steps: 3, steps per second: 131, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.833 [-1.000, 11.000], loss: 0.000672, mae: 0.017658, mean_q: 0.020791
  5317/100000: episode: 637, duration: 0.023s, episode steps: 3, steps per second: 131, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000582, mae: 0.014812, mean_q: 0.015627
  5324/100000: episode: 638, duration: 0.040s, episode steps: 7, steps per second: 176, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000762, mae: 0.017612, mean_q: 0.022932
  5327/100000: episode: 639, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.667 [-1.000, 11.000], loss: 0.000577, mae: 0.017989, mean_q: 0.026521
  5334/100000: episode: 640, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002304, mae: 0.023558, mean_q: 0.031775
  5341/100000: episode: 641, duration: 0.037s, episode steps: 7, steps per second: 188, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.001113, mae: 0.028897, mean_q: 0.019055
  5348/100000: episode: 642, duration: 0.038s, episode steps: 7, steps per second: 186, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.001184, mae: 0.027357, mean_q: 0.031290
  5355/100000: episode: 643, duration: 0.038s, episode steps: 7, steps per second: 186, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001080, mae: 0.030558, mean_q: 0.008273
  5362/100000: episode: 644, duration: 0.042s, episode steps: 7, steps per second: 165, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000725, mae: 0.016737, mean_q: 0.021437
  5369/100000: episode: 645, duration: 0.039s, episode steps: 7, steps per second: 181, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000528, mae: 0.016273, mean_q: 0.021465
  5376/100000: episode: 646, duration: 0.037s, episode steps: 7, steps per second: 191, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001588, mae: 0.022052, mean_q: 0.023462
  5383/100000: episode: 647, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001691, mae: 0.022498, mean_q: 0.015457
  5390/100000: episode: 648, duration: 0.037s, episode steps: 7, steps per second: 188, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000538, mae: 0.017076, mean_q: 0.022385
  5397/100000: episode: 649, duration: 0.040s, episode steps: 7, steps per second: 177, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.001853, mae: 0.024503, mean_q: 0.029614
  5404/100000: episode: 650, duration: 0.041s, episode steps: 7, steps per second: 171, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000619, mae: 0.017466, mean_q: 0.018077
  5407/100000: episode: 651, duration: 0.021s, episode steps: 3, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.667 [-1.000, 11.000], loss: 0.000864, mae: 0.027987, mean_q: 0.046942
  5414/100000: episode: 652, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001088, mae: 0.026200, mean_q: 0.011965
  5421/100000: episode: 653, duration: 0.040s, episode steps: 7, steps per second: 175, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000811, mae: 0.020227, mean_q: 0.029962
  5428/100000: episode: 654, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000687, mae: 0.018863, mean_q: 0.027414
  5431/100000: episode: 655, duration: 0.018s, episode steps: 3, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.667 [-1.000, 11.000], loss: 0.001222, mae: 0.019892, mean_q: 0.021264
  5434/100000: episode: 656, duration: 0.019s, episode steps: 3, steps per second: 157, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000614, mae: 0.017310, mean_q: 0.029164
  5437/100000: episode: 657, duration: 0.019s, episode steps: 3, steps per second: 155, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000276, mae: 0.018761, mean_q: 0.005644
  5440/100000: episode: 658, duration: 0.023s, episode steps: 3, steps per second: 130, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.833 [-1.000, 11.000], loss: 0.001826, mae: 0.034009, mean_q: 0.046837
  5443/100000: episode: 659, duration: 0.022s, episode steps: 3, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.667 [-1.000, 11.000], loss: 0.000706, mae: 0.024236, mean_q: 0.008190
  5450/100000: episode: 660, duration: 0.041s, episode steps: 7, steps per second: 169, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001105, mae: 0.025708, mean_q: 0.033013
  5457/100000: episode: 661, duration: 0.040s, episode steps: 7, steps per second: 176, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000527, mae: 0.020925, mean_q: 0.010423
  5464/100000: episode: 662, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000778, mae: 0.021517, mean_q: 0.018987
  5467/100000: episode: 663, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001063, mae: 0.023040, mean_q: 0.028483
  5470/100000: episode: 664, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.667 [-1.000, 11.000], loss: 0.000788, mae: 0.022952, mean_q: 0.028434
  5477/100000: episode: 665, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000592, mae: 0.020955, mean_q: 0.016211
  5484/100000: episode: 666, duration: 0.036s, episode steps: 7, steps per second: 192, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.002235, mae: 0.021397, mean_q: 0.024548
  5487/100000: episode: 667, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.667 [-1.000, 11.000], loss: 0.004175, mae: 0.040364, mean_q: 0.017211
  5494/100000: episode: 668, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.002258, mae: 0.024844, mean_q: 0.028166
  5497/100000: episode: 669, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.833 [-1.000, 11.000], loss: 0.004529, mae: 0.028645, mean_q: 0.022025
  5504/100000: episode: 670, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001019, mae: 0.023428, mean_q: 0.027884
  5511/100000: episode: 671, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000916, mae: 0.022118, mean_q: 0.032455
  5518/100000: episode: 672, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000897, mae: 0.025629, mean_q: 0.015889
  5521/100000: episode: 673, duration: 0.019s, episode steps: 3, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.667 [-1.000, 11.000], loss: 0.000470, mae: 0.016754, mean_q: 0.011728
  5528/100000: episode: 674, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.002105, mae: 0.026986, mean_q: 0.031886
  5535/100000: episode: 675, duration: 0.037s, episode steps: 7, steps per second: 188, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.003597, mae: 0.030926, mean_q: 0.026577
  5538/100000: episode: 676, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001832, mae: 0.041752, mean_q: 0.059338
  5545/100000: episode: 677, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.002807, mae: 0.039960, mean_q: 0.016296
  5548/100000: episode: 678, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.833 [-1.000, 11.000], loss: 0.000592, mae: 0.021866, mean_q: 0.022657
  5555/100000: episode: 679, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001014, mae: 0.033278, mean_q: 0.019350
  5562/100000: episode: 680, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000756, mae: 0.028957, mean_q: 0.004669
  5569/100000: episode: 681, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000880, mae: 0.029001, mean_q: 0.030323
  5576/100000: episode: 682, duration: 0.036s, episode steps: 7, steps per second: 192, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001159, mae: 0.027019, mean_q: 0.029547
  5583/100000: episode: 683, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000726, mae: 0.020743, mean_q: 0.017390
  5586/100000: episode: 684, duration: 0.019s, episode steps: 3, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.833 [-1.000, 11.000], loss: 0.000757, mae: 0.020515, mean_q: 0.031280
  5593/100000: episode: 685, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001991, mae: 0.026132, mean_q: 0.021893
  5596/100000: episode: 686, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.667 [-1.000, 11.000], loss: 0.000900, mae: 0.019695, mean_q: 0.027972
  5603/100000: episode: 687, duration: 0.038s, episode steps: 7, steps per second: 186, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000757, mae: 0.022863, mean_q: 0.019812
  5606/100000: episode: 688, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.667 [-1.000, 11.000], loss: 0.000441, mae: 0.015520, mean_q: 0.026463
  5613/100000: episode: 689, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000849, mae: 0.020739, mean_q: 0.018155
  5620/100000: episode: 690, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.002238, mae: 0.024278, mean_q: 0.025288
  5627/100000: episode: 691, duration: 0.037s, episode steps: 7, steps per second: 192, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001030, mae: 0.025403, mean_q: 0.015375
  5634/100000: episode: 692, duration: 0.045s, episode steps: 7, steps per second: 156, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000914, mae: 0.025870, mean_q: 0.020985
  5637/100000: episode: 693, duration: 0.022s, episode steps: 3, steps per second: 136, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.667 [-1.000, 11.000], loss: 0.000563, mae: 0.018544, mean_q: 0.023637
  5640/100000: episode: 694, duration: 0.020s, episode steps: 3, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.833 [-1.000, 11.000], loss: 0.000634, mae: 0.020806, mean_q: 0.022746
  5647/100000: episode: 695, duration: 0.043s, episode steps: 7, steps per second: 163, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000947, mae: 0.022405, mean_q: 0.024588
  5654/100000: episode: 696, duration: 0.041s, episode steps: 7, steps per second: 171, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001901, mae: 0.026119, mean_q: 0.016239
  5661/100000: episode: 697, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002208, mae: 0.028838, mean_q: 0.027180
  5664/100000: episode: 698, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.667 [-1.000, 11.000], loss: 0.000778, mae: 0.019189, mean_q: 0.030912
  5671/100000: episode: 699, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000647, mae: 0.016555, mean_q: 0.017180
  5678/100000: episode: 700, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000812, mae: 0.018600, mean_q: 0.020706
  5681/100000: episode: 701, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001108, mae: 0.022397, mean_q: 0.026035
  5688/100000: episode: 702, duration: 0.037s, episode steps: 7, steps per second: 191, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000839, mae: 0.019530, mean_q: 0.023746
  5691/100000: episode: 703, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004096, mae: 0.031065, mean_q: 0.028053
  5694/100000: episode: 704, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001255, mae: 0.030343, mean_q: 0.036710
  5697/100000: episode: 705, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001185, mae: 0.028477, mean_q: 0.019607
[Info] 2-TH LEVEL FOUND: 0.14497464895248413, Considering 15/100 traces
  5704/100000: episode: 706, duration: 0.745s, episode steps: 7, steps per second: 9, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.002498, mae: 0.029280, mean_q: 0.033450
  5709/100000: episode: 707, duration: 0.055s, episode steps: 5, steps per second: 92, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000726, mae: 0.021331, mean_q: 0.017371
  5714/100000: episode: 708, duration: 0.037s, episode steps: 5, steps per second: 135, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002127, mae: 0.024409, mean_q: 0.015792
  5719/100000: episode: 709, duration: 0.035s, episode steps: 5, steps per second: 144, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001354, mae: 0.026970, mean_q: 0.033825
  5724/100000: episode: 710, duration: 0.028s, episode steps: 5, steps per second: 176, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001009, mae: 0.023749, mean_q: 0.014531
  5729/100000: episode: 711, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000659, mae: 0.022471, mean_q: 0.017795
  5734/100000: episode: 712, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001074, mae: 0.026890, mean_q: 0.029681
  5739/100000: episode: 713, duration: 0.032s, episode steps: 5, steps per second: 157, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000584, mae: 0.022364, mean_q: 0.011157
  5744/100000: episode: 714, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000918, mae: 0.022673, mean_q: 0.032418
  5749/100000: episode: 715, duration: 0.046s, episode steps: 5, steps per second: 109, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002679, mae: 0.021476, mean_q: 0.025686
  5754/100000: episode: 716, duration: 0.040s, episode steps: 5, steps per second: 126, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000869, mae: 0.022551, mean_q: 0.011570
  5759/100000: episode: 717, duration: 0.056s, episode steps: 5, steps per second: 89, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000452, mae: 0.016655, mean_q: 0.021888
  5764/100000: episode: 718, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002364, mae: 0.026708, mean_q: 0.019959
  5769/100000: episode: 719, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001058, mae: 0.029171, mean_q: 0.033384
  5774/100000: episode: 720, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.002351, mae: 0.028266, mean_q: 0.032566
  5779/100000: episode: 721, duration: 0.028s, episode steps: 5, steps per second: 182, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002819, mae: 0.023039, mean_q: 0.013419
  5784/100000: episode: 722, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000649, mae: 0.022664, mean_q: 0.026158
  5789/100000: episode: 723, duration: 0.042s, episode steps: 5, steps per second: 120, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001201, mae: 0.025932, mean_q: 0.018277
  5794/100000: episode: 724, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002496, mae: 0.025136, mean_q: 0.021888
  5799/100000: episode: 725, duration: 0.048s, episode steps: 5, steps per second: 104, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001356, mae: 0.029207, mean_q: 0.044274
  5804/100000: episode: 726, duration: 0.059s, episode steps: 5, steps per second: 85, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000660, mae: 0.023876, mean_q: 0.007006
  5809/100000: episode: 727, duration: 0.033s, episode steps: 5, steps per second: 150, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001171, mae: 0.030429, mean_q: 0.044403
  5814/100000: episode: 728, duration: 0.032s, episode steps: 5, steps per second: 156, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002543, mae: 0.031388, mean_q: 0.018177
  5819/100000: episode: 729, duration: 0.035s, episode steps: 5, steps per second: 144, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002873, mae: 0.027580, mean_q: 0.025230
  5824/100000: episode: 730, duration: 0.033s, episode steps: 5, steps per second: 151, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003420, mae: 0.032781, mean_q: 0.037011
  5829/100000: episode: 731, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000713, mae: 0.020528, mean_q: 0.018694
  5834/100000: episode: 732, duration: 0.036s, episode steps: 5, steps per second: 139, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002912, mae: 0.036088, mean_q: 0.041744
  5839/100000: episode: 733, duration: 0.042s, episode steps: 5, steps per second: 120, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000957, mae: 0.029081, mean_q: 0.015578
  5844/100000: episode: 734, duration: 0.032s, episode steps: 5, steps per second: 154, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002950, mae: 0.032073, mean_q: 0.040818
  5849/100000: episode: 735, duration: 0.089s, episode steps: 5, steps per second: 56, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002801, mae: 0.028216, mean_q: 0.023435
  5854/100000: episode: 736, duration: 0.061s, episode steps: 5, steps per second: 82, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001130, mae: 0.029147, mean_q: 0.019375
  5859/100000: episode: 737, duration: 0.065s, episode steps: 5, steps per second: 77, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000811, mae: 0.023638, mean_q: 0.032663
  5864/100000: episode: 738, duration: 0.052s, episode steps: 5, steps per second: 97, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000515, mae: 0.017944, mean_q: 0.013804
  5869/100000: episode: 739, duration: 0.048s, episode steps: 5, steps per second: 104, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001443, mae: 0.030803, mean_q: 0.045090
  5874/100000: episode: 740, duration: 0.041s, episode steps: 5, steps per second: 121, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001396, mae: 0.028416, mean_q: 0.019332
  5879/100000: episode: 741, duration: 0.048s, episode steps: 5, steps per second: 105, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000824, mae: 0.024921, mean_q: 0.024650
  5884/100000: episode: 742, duration: 0.054s, episode steps: 5, steps per second: 93, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000712, mae: 0.019920, mean_q: 0.020142
  5889/100000: episode: 743, duration: 0.039s, episode steps: 5, steps per second: 130, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002534, mae: 0.029130, mean_q: 0.038455
  5894/100000: episode: 744, duration: 0.032s, episode steps: 5, steps per second: 156, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001309, mae: 0.031716, mean_q: 0.023142
  5899/100000: episode: 745, duration: 0.053s, episode steps: 5, steps per second: 93, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000866, mae: 0.023206, mean_q: 0.039827
  5904/100000: episode: 746, duration: 0.043s, episode steps: 5, steps per second: 117, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001024, mae: 0.030634, mean_q: 0.004451
  5909/100000: episode: 747, duration: 0.030s, episode steps: 5, steps per second: 165, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000785, mae: 0.026809, mean_q: 0.032787
  5914/100000: episode: 748, duration: 0.051s, episode steps: 5, steps per second: 99, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002816, mae: 0.027108, mean_q: 0.016779
  5919/100000: episode: 749, duration: 0.040s, episode steps: 5, steps per second: 125, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001173, mae: 0.027808, mean_q: 0.036103
  5924/100000: episode: 750, duration: 0.049s, episode steps: 5, steps per second: 103, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003238, mae: 0.033955, mean_q: 0.030850
  5929/100000: episode: 751, duration: 0.038s, episode steps: 5, steps per second: 131, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000962, mae: 0.028294, mean_q: 0.027202
  5934/100000: episode: 752, duration: 0.042s, episode steps: 5, steps per second: 120, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.005994, mae: 0.050222, mean_q: 0.041606
  5939/100000: episode: 753, duration: 0.051s, episode steps: 5, steps per second: 99, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001356, mae: 0.035866, mean_q: 0.011258
  5944/100000: episode: 754, duration: 0.047s, episode steps: 5, steps per second: 107, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002878, mae: 0.035442, mean_q: 0.045729
  5949/100000: episode: 755, duration: 0.033s, episode steps: 5, steps per second: 150, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002869, mae: 0.033641, mean_q: 0.018021
  5954/100000: episode: 756, duration: 0.032s, episode steps: 5, steps per second: 154, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002970, mae: 0.028736, mean_q: 0.043010
  5959/100000: episode: 757, duration: 0.028s, episode steps: 5, steps per second: 175, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.004747, mae: 0.042107, mean_q: 0.053811
  5964/100000: episode: 758, duration: 0.042s, episode steps: 5, steps per second: 118, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.002645, mae: 0.038450, mean_q: 0.017135
  5969/100000: episode: 759, duration: 0.050s, episode steps: 5, steps per second: 99, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001013, mae: 0.026356, mean_q: 0.033382
  5974/100000: episode: 760, duration: 0.030s, episode steps: 5, steps per second: 165, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001378, mae: 0.033143, mean_q: 0.013940
  5979/100000: episode: 761, duration: 0.033s, episode steps: 5, steps per second: 153, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001153, mae: 0.030113, mean_q: 0.037655
  5984/100000: episode: 762, duration: 0.045s, episode steps: 5, steps per second: 111, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001629, mae: 0.034419, mean_q: 0.023609
  5989/100000: episode: 763, duration: 0.036s, episode steps: 5, steps per second: 137, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001602, mae: 0.038843, mean_q: 0.053511
  5994/100000: episode: 764, duration: 0.035s, episode steps: 5, steps per second: 145, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001584, mae: 0.036874, mean_q: 0.010940
  5999/100000: episode: 765, duration: 0.049s, episode steps: 5, steps per second: 102, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002420, mae: 0.036869, mean_q: 0.049189
  6004/100000: episode: 766, duration: 0.058s, episode steps: 5, steps per second: 87, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001466, mae: 0.035500, mean_q: 0.015119
  6009/100000: episode: 767, duration: 0.061s, episode steps: 5, steps per second: 82, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002623, mae: 0.032608, mean_q: 0.043792
  6014/100000: episode: 768, duration: 0.049s, episode steps: 5, steps per second: 102, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000931, mae: 0.020105, mean_q: 0.022799
  6019/100000: episode: 769, duration: 0.045s, episode steps: 5, steps per second: 111, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001266, mae: 0.027716, mean_q: 0.021738
  6024/100000: episode: 770, duration: 0.034s, episode steps: 5, steps per second: 148, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001290, mae: 0.029541, mean_q: 0.039832
  6029/100000: episode: 771, duration: 0.029s, episode steps: 5, steps per second: 171, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001267, mae: 0.031457, mean_q: 0.010338
  6034/100000: episode: 772, duration: 0.033s, episode steps: 5, steps per second: 151, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001161, mae: 0.033847, mean_q: 0.047777
  6039/100000: episode: 773, duration: 0.060s, episode steps: 5, steps per second: 83, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001234, mae: 0.035687, mean_q: 0.012334
  6044/100000: episode: 774, duration: 0.067s, episode steps: 5, steps per second: 75, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.005090, mae: 0.041826, mean_q: 0.050972
  6049/100000: episode: 775, duration: 0.072s, episode steps: 5, steps per second: 70, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002494, mae: 0.028351, mean_q: 0.030358
  6054/100000: episode: 776, duration: 0.038s, episode steps: 5, steps per second: 132, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001248, mae: 0.024934, mean_q: 0.027883
  6059/100000: episode: 777, duration: 0.034s, episode steps: 5, steps per second: 148, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.006082, mae: 0.045568, mean_q: 0.057242
  6064/100000: episode: 778, duration: 0.047s, episode steps: 5, steps per second: 107, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.003545, mae: 0.041967, mean_q: 0.017279
  6069/100000: episode: 779, duration: 0.042s, episode steps: 5, steps per second: 118, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001674, mae: 0.035150, mean_q: 0.047685
  6074/100000: episode: 780, duration: 0.045s, episode steps: 5, steps per second: 112, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.007204, mae: 0.056255, mean_q: 0.032287
  6079/100000: episode: 781, duration: 0.038s, episode steps: 5, steps per second: 130, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.003838, mae: 0.045578, mean_q: 0.047807
  6084/100000: episode: 782, duration: 0.034s, episode steps: 5, steps per second: 148, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001628, mae: 0.039954, mean_q: 0.011566
  6089/100000: episode: 783, duration: 0.056s, episode steps: 5, steps per second: 90, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000927, mae: 0.024864, mean_q: 0.021697
  6094/100000: episode: 784, duration: 0.033s, episode steps: 5, steps per second: 153, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002517, mae: 0.032054, mean_q: 0.022395
  6099/100000: episode: 785, duration: 0.033s, episode steps: 5, steps per second: 152, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000997, mae: 0.025740, mean_q: 0.016521
  6104/100000: episode: 786, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.004515, mae: 0.040652, mean_q: 0.046648
  6109/100000: episode: 787, duration: 0.040s, episode steps: 5, steps per second: 126, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.003595, mae: 0.039786, mean_q: 0.033281
  6114/100000: episode: 788, duration: 0.071s, episode steps: 5, steps per second: 70, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001203, mae: 0.026024, mean_q: 0.039362
  6119/100000: episode: 789, duration: 0.062s, episode steps: 5, steps per second: 81, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001105, mae: 0.026171, mean_q: 0.023648
  6124/100000: episode: 790, duration: 0.034s, episode steps: 5, steps per second: 146, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001274, mae: 0.026927, mean_q: 0.030513
[Info] 3-TH LEVEL FOUND: 0.27665597200393677, Considering 21/100 traces
  6129/100000: episode: 791, duration: 0.905s, episode steps: 5, steps per second: 6, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000928, mae: 0.022257, mean_q: 0.023468
  6132/100000: episode: 792, duration: 0.021s, episode steps: 3, steps per second: 141, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003763, mae: 0.035637, mean_q: 0.047836
  6135/100000: episode: 793, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 1.104, mean reward: 0.368 [0.368, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 11.000], loss: 0.001023, mae: 0.024821, mean_q: 0.037307
  6138/100000: episode: 794, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 1.104, mean reward: 0.368 [0.368, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 11.000], loss: 0.000991, mae: 0.027567, mean_q: 0.017982
[Info] FALSIFICATION!
  6140/100000: episode: 795, duration: 0.200s, episode steps: 2, steps per second: 10, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.001794, mae: 0.026538, mean_q: 0.037938
  6143/100000: episode: 796, duration: 0.026s, episode steps: 3, steps per second: 117, episode reward: 1.104, mean reward: 0.368 [0.368, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 11.000], loss: 0.001368, mae: 0.026515, mean_q: 0.039068
[Info] FALSIFICATION!
  6145/100000: episode: 797, duration: 0.307s, episode steps: 2, steps per second: 7, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.005698, mae: 0.030328, mean_q: 0.032765
[Info] FALSIFICATION!
  6147/100000: episode: 798, duration: 0.187s, episode steps: 2, steps per second: 11, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.004787, mae: 0.044350, mean_q: 0.055044
  6150/100000: episode: 799, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 1.737, mean reward: 0.579 [0.368, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.667 [9.000, 11.000], loss: 0.001116, mae: 0.028442, mean_q: 0.029846
  6153/100000: episode: 800, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001243, mae: 0.033134, mean_q: 0.019437
[Info] FALSIFICATION!
  6155/100000: episode: 801, duration: 0.178s, episode steps: 2, steps per second: 11, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.001949, mae: 0.037271, mean_q: 0.065229
[Info] FALSIFICATION!
  6157/100000: episode: 802, duration: 0.180s, episode steps: 2, steps per second: 11, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.004836, mae: 0.038602, mean_q: 0.049321
  6160/100000: episode: 803, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 1.737, mean reward: 0.579 [0.368, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.667 [9.000, 11.000], loss: 0.004682, mae: 0.030919, mean_q: 0.032227
  6163/100000: episode: 804, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001214, mae: 0.028478, mean_q: 0.044982
  6166/100000: episode: 805, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000763, mae: 0.025266, mean_q: 0.029395
[Info] FALSIFICATION!
  6168/100000: episode: 806, duration: 0.195s, episode steps: 2, steps per second: 10, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.002004, mae: 0.033953, mean_q: 0.034286
  6171/100000: episode: 807, duration: 0.022s, episode steps: 3, steps per second: 137, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000819, mae: 0.020889, mean_q: 0.013216
  6174/100000: episode: 808, duration: 0.020s, episode steps: 3, steps per second: 153, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001729, mae: 0.035850, mean_q: 0.050910
  6177/100000: episode: 809, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 1.737, mean reward: 0.579 [0.368, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.667 [9.000, 11.000], loss: 0.001618, mae: 0.029225, mean_q: 0.042984
[Info] FALSIFICATION!
  6179/100000: episode: 810, duration: 0.269s, episode steps: 2, steps per second: 7, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.006491, mae: 0.042017, mean_q: 0.044338
  6182/100000: episode: 811, duration: 0.023s, episode steps: 3, steps per second: 129, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001661, mae: 0.033126, mean_q: 0.048291
  6185/100000: episode: 812, duration: 0.019s, episode steps: 3, steps per second: 162, episode reward: 1.104, mean reward: 0.368 [0.368, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 11.000], loss: 0.004552, mae: 0.040983, mean_q: 0.020648
  6188/100000: episode: 813, duration: 0.019s, episode steps: 3, steps per second: 162, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003964, mae: 0.048066, mean_q: 0.071689
  6191/100000: episode: 814, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001856, mae: 0.039227, mean_q: 0.050119
  6194/100000: episode: 815, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002180, mae: 0.055600, mean_q: -0.012781
  6197/100000: episode: 816, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.005060, mae: 0.046850, mean_q: 0.047250
  6200/100000: episode: 817, duration: 0.019s, episode steps: 3, steps per second: 157, episode reward: 1.104, mean reward: 0.368 [0.368, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 11.000], loss: 0.001469, mae: 0.032186, mean_q: 0.050319
[Info] FALSIFICATION!
  6202/100000: episode: 818, duration: 0.274s, episode steps: 2, steps per second: 7, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.001511, mae: 0.033983, mean_q: 0.016929
  6205/100000: episode: 819, duration: 0.022s, episode steps: 3, steps per second: 138, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001957, mae: 0.036615, mean_q: 0.017391
  6208/100000: episode: 820, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 1.104, mean reward: 0.368 [0.368, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 11.000], loss: 0.000790, mae: 0.030510, mean_q: 0.047455
  6211/100000: episode: 821, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001446, mae: 0.030836, mean_q: 0.012865
  6214/100000: episode: 822, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.007366, mae: 0.050689, mean_q: 0.016637
  6217/100000: episode: 823, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001270, mae: 0.036072, mean_q: 0.050801
[Info] FALSIFICATION!
  6219/100000: episode: 824, duration: 0.270s, episode steps: 2, steps per second: 7, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.000992, mae: 0.024730, mean_q: 0.039174
[Info] FALSIFICATION!
  6221/100000: episode: 825, duration: 0.291s, episode steps: 2, steps per second: 7, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.001307, mae: 0.032643, mean_q: 0.010930
  6224/100000: episode: 826, duration: 0.036s, episode steps: 3, steps per second: 83, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.009203, mae: 0.053017, mean_q: 0.044613
  6227/100000: episode: 827, duration: 0.042s, episode steps: 3, steps per second: 71, episode reward: 1.104, mean reward: 0.368 [0.368, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 11.000], loss: 0.002294, mae: 0.041069, mean_q: 0.059488
  6230/100000: episode: 828, duration: 0.031s, episode steps: 3, steps per second: 97, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003492, mae: 0.036806, mean_q: 0.023251
[Info] FALSIFICATION!
  6232/100000: episode: 829, duration: 0.323s, episode steps: 2, steps per second: 6, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.001094, mae: 0.030078, mean_q: 0.050496
[Info] FALSIFICATION!
  6234/100000: episode: 830, duration: 0.295s, episode steps: 2, steps per second: 7, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.001359, mae: 0.031092, mean_q: 0.045847
  6237/100000: episode: 831, duration: 0.032s, episode steps: 3, steps per second: 93, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001588, mae: 0.032293, mean_q: 0.029027
  6240/100000: episode: 832, duration: 0.039s, episode steps: 3, steps per second: 78, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001358, mae: 0.031284, mean_q: 0.022659
  6243/100000: episode: 833, duration: 0.029s, episode steps: 3, steps per second: 104, episode reward: 1.104, mean reward: 0.368 [0.368, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 11.000], loss: 0.003951, mae: 0.045931, mean_q: 0.066992
  6246/100000: episode: 834, duration: 0.030s, episode steps: 3, steps per second: 99, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004262, mae: 0.044035, mean_q: 0.038198
[Info] FALSIFICATION!
  6248/100000: episode: 835, duration: 0.309s, episode steps: 2, steps per second: 6, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.000823, mae: 0.026948, mean_q: 0.006658
  6251/100000: episode: 836, duration: 0.024s, episode steps: 3, steps per second: 127, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001214, mae: 0.027589, mean_q: 0.037706
  6254/100000: episode: 837, duration: 0.023s, episode steps: 3, steps per second: 133, episode reward: 1.104, mean reward: 0.368 [0.368, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 11.000], loss: 0.004148, mae: 0.039308, mean_q: 0.042914
  6257/100000: episode: 838, duration: 0.023s, episode steps: 3, steps per second: 130, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001610, mae: 0.033296, mean_q: 0.045478
[Info] FALSIFICATION!
  6259/100000: episode: 839, duration: 0.314s, episode steps: 2, steps per second: 6, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.006406, mae: 0.038432, mean_q: 0.038619
[Info] FALSIFICATION!
  6261/100000: episode: 840, duration: 0.297s, episode steps: 2, steps per second: 7, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.001217, mae: 0.029150, mean_q: 0.031631
  6264/100000: episode: 841, duration: 0.021s, episode steps: 3, steps per second: 145, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001039, mae: 0.025922, mean_q: 0.038314
  6267/100000: episode: 842, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003379, mae: 0.031243, mean_q: 0.051979
[Info] FALSIFICATION!
  6269/100000: episode: 843, duration: 0.282s, episode steps: 2, steps per second: 7, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.001514, mae: 0.033568, mean_q: 0.054328
[Info] FALSIFICATION!
  6271/100000: episode: 844, duration: 0.339s, episode steps: 2, steps per second: 6, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.006476, mae: 0.045804, mean_q: 0.040477
  6274/100000: episode: 845, duration: 0.047s, episode steps: 3, steps per second: 64, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004984, mae: 0.049029, mean_q: 0.067551
  6277/100000: episode: 846, duration: 0.038s, episode steps: 3, steps per second: 78, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001662, mae: 0.038788, mean_q: 0.069522
  6280/100000: episode: 847, duration: 0.033s, episode steps: 3, steps per second: 91, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001624, mae: 0.043354, mean_q: 0.021747
  6283/100000: episode: 848, duration: 0.037s, episode steps: 3, steps per second: 82, episode reward: 1.104, mean reward: 0.368 [0.368, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 11.000], loss: 0.004694, mae: 0.049605, mean_q: 0.039989
  6286/100000: episode: 849, duration: 0.035s, episode steps: 3, steps per second: 87, episode reward: 1.737, mean reward: 0.579 [0.368, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.667 [9.000, 11.000], loss: 0.004961, mae: 0.065977, mean_q: 0.097486
[Info] FALSIFICATION!
  6288/100000: episode: 850, duration: 0.365s, episode steps: 2, steps per second: 5, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.001045, mae: 0.027040, mean_q: 0.015630
[Info] FALSIFICATION!
  6290/100000: episode: 851, duration: 0.288s, episode steps: 2, steps per second: 7, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.005411, mae: 0.059731, mean_q: -0.008458
[Info] FALSIFICATION!
  6292/100000: episode: 852, duration: 0.387s, episode steps: 2, steps per second: 5, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.005721, mae: 0.045321, mean_q: 0.054039
[Info] FALSIFICATION!
  6294/100000: episode: 853, duration: 0.347s, episode steps: 2, steps per second: 6, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.004411, mae: 0.058500, mean_q: 0.094009
[Info] FALSIFICATION!
  6296/100000: episode: 854, duration: 0.332s, episode steps: 2, steps per second: 6, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.008365, mae: 0.060782, mean_q: 0.063746
  6299/100000: episode: 855, duration: 0.028s, episode steps: 3, steps per second: 106, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.006612, mae: 0.065448, mean_q: 0.017379
  6302/100000: episode: 856, duration: 0.027s, episode steps: 3, steps per second: 112, episode reward: 1.104, mean reward: 0.368 [0.368, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 11.000], loss: 0.004305, mae: 0.046625, mean_q: 0.054826
  6305/100000: episode: 857, duration: 0.020s, episode steps: 3, steps per second: 152, episode reward: 1.104, mean reward: 0.368 [0.368, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 11.000], loss: 0.005577, mae: 0.049393, mean_q: 0.048466
  6308/100000: episode: 858, duration: 0.037s, episode steps: 3, steps per second: 80, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001357, mae: 0.036646, mean_q: -0.000500
  6311/100000: episode: 859, duration: 0.030s, episode steps: 3, steps per second: 99, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003945, mae: 0.034997, mean_q: 0.045419
  6314/100000: episode: 860, duration: 0.022s, episode steps: 3, steps per second: 134, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002499, mae: 0.044484, mean_q: 0.066751
  6317/100000: episode: 861, duration: 0.021s, episode steps: 3, steps per second: 141, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.005123, mae: 0.062582, mean_q: 0.014219
[Info] FALSIFICATION!
  6319/100000: episode: 862, duration: 0.289s, episode steps: 2, steps per second: 7, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.002138, mae: 0.036941, mean_q: 0.051540
  6322/100000: episode: 863, duration: 0.048s, episode steps: 3, steps per second: 62, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.005765, mae: 0.045945, mean_q: 0.051651
  6325/100000: episode: 864, duration: 0.041s, episode steps: 3, steps per second: 73, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001114, mae: 0.021639, mean_q: 0.026080
  6328/100000: episode: 865, duration: 0.028s, episode steps: 3, steps per second: 105, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002199, mae: 0.037750, mean_q: 0.038243
[Info] FALSIFICATION!
  6330/100000: episode: 866, duration: 0.306s, episode steps: 2, steps per second: 7, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.006291, mae: 0.042546, mean_q: 0.056309
  6333/100000: episode: 867, duration: 0.023s, episode steps: 3, steps per second: 130, episode reward: 1.737, mean reward: 0.579 [0.368, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.667 [9.000, 11.000], loss: 0.001123, mae: 0.028414, mean_q: 0.050844
  6336/100000: episode: 868, duration: 0.029s, episode steps: 3, steps per second: 105, episode reward: 1.104, mean reward: 0.368 [0.368, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 11.000], loss: 0.002065, mae: 0.038524, mean_q: 0.043245
  6339/100000: episode: 869, duration: 0.040s, episode steps: 3, steps per second: 74, episode reward: 1.104, mean reward: 0.368 [0.368, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 11.000], loss: 0.008166, mae: 0.064317, mean_q: 0.070616
[Info] FALSIFICATION!
[Info] Complete ISplit Iteration
[Info] Levels: [0.029104251, 0.14497465, 0.27665597, 0.43433347]
[Info] Cond. Prob: [0.1, 0.15, 0.21, 0.25]
[Info] Error Prob: 0.0007874999999999999

  6341/100000: episode: 870, duration: 1.819s, episode steps: 2, steps per second: 1, episode reward: 1.368, mean reward: 0.684 [0.368, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.500 [9.000, 10.000], loss: 0.005682, mae: 0.059634, mean_q: 0.087130
  6351/100000: episode: 871, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002215, mae: 0.040947, mean_q: 0.028084
  6361/100000: episode: 872, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.003439, mae: 0.041813, mean_q: 0.050862
  6371/100000: episode: 873, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.003456, mae: 0.038940, mean_q: 0.041874
  6381/100000: episode: 874, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.005049, mae: 0.052677, mean_q: 0.065258
  6391/100000: episode: 875, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002241, mae: 0.033472, mean_q: 0.044876
  6401/100000: episode: 876, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.005063, mae: 0.053938, mean_q: 0.063298
  6411/100000: episode: 877, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.004268, mae: 0.049855, mean_q: 0.046417
  6421/100000: episode: 878, duration: 0.086s, episode steps: 10, steps per second: 117, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.005851, mae: 0.050409, mean_q: 0.050078
  6431/100000: episode: 879, duration: 0.113s, episode steps: 10, steps per second: 89, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.004369, mae: 0.048172, mean_q: 0.041126
  6441/100000: episode: 880, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.003943, mae: 0.042390, mean_q: 0.047286
  6451/100000: episode: 881, duration: 0.093s, episode steps: 10, steps per second: 108, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002959, mae: 0.031176, mean_q: 0.042383
  6461/100000: episode: 882, duration: 0.089s, episode steps: 10, steps per second: 113, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.003816, mae: 0.043161, mean_q: 0.041494
  6471/100000: episode: 883, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.004111, mae: 0.047791, mean_q: 0.043768
  6481/100000: episode: 884, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002509, mae: 0.036491, mean_q: 0.039557
  6491/100000: episode: 885, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.004759, mae: 0.045948, mean_q: 0.055257
  6501/100000: episode: 886, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.004588, mae: 0.047056, mean_q: 0.060006
  6511/100000: episode: 887, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002460, mae: 0.037064, mean_q: 0.036716
  6521/100000: episode: 888, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.003863, mae: 0.040820, mean_q: 0.050472
  6531/100000: episode: 889, duration: 0.072s, episode steps: 10, steps per second: 138, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.005578, mae: 0.052134, mean_q: 0.053749
  6541/100000: episode: 890, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.003649, mae: 0.040356, mean_q: 0.042798
  6551/100000: episode: 891, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.003208, mae: 0.040433, mean_q: 0.036514
  6561/100000: episode: 892, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.003279, mae: 0.042903, mean_q: 0.057632
  6571/100000: episode: 893, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.003414, mae: 0.042907, mean_q: 0.048376
  6581/100000: episode: 894, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.003837, mae: 0.050989, mean_q: 0.037554
  6591/100000: episode: 895, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.003969, mae: 0.043692, mean_q: 0.040085
  6601/100000: episode: 896, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003882, mae: 0.042676, mean_q: 0.039054
  6611/100000: episode: 897, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.003256, mae: 0.045704, mean_q: 0.055560
  6621/100000: episode: 898, duration: 0.060s, episode steps: 10, steps per second: 165, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.003534, mae: 0.041181, mean_q: 0.056317
  6631/100000: episode: 899, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.003008, mae: 0.037223, mean_q: 0.044148
  6641/100000: episode: 900, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003068, mae: 0.043602, mean_q: 0.039007
  6651/100000: episode: 901, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002671, mae: 0.037736, mean_q: 0.051786
  6661/100000: episode: 902, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.004436, mae: 0.045275, mean_q: 0.063470
  6671/100000: episode: 903, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.006318, mae: 0.055878, mean_q: 0.067618
  6681/100000: episode: 904, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.004786, mae: 0.044616, mean_q: 0.059018
  6691/100000: episode: 905, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.006690, mae: 0.063969, mean_q: 0.075880
  6701/100000: episode: 906, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.004925, mae: 0.054852, mean_q: 0.042033
  6711/100000: episode: 907, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.004147, mae: 0.048765, mean_q: 0.037205
  6721/100000: episode: 908, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.004063, mae: 0.052027, mean_q: 0.053255
  6731/100000: episode: 909, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.003392, mae: 0.044871, mean_q: 0.057988
  6741/100000: episode: 910, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.003918, mae: 0.038258, mean_q: 0.048155
  6751/100000: episode: 911, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.006340, mae: 0.050592, mean_q: 0.066306
  6761/100000: episode: 912, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.004332, mae: 0.043837, mean_q: 0.033350
  6771/100000: episode: 913, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.003073, mae: 0.045079, mean_q: 0.031299
  6781/100000: episode: 914, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002029, mae: 0.030691, mean_q: 0.042527
  6791/100000: episode: 915, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002668, mae: 0.036131, mean_q: 0.037729
  6801/100000: episode: 916, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.003300, mae: 0.043708, mean_q: 0.045867
  6811/100000: episode: 917, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.003033, mae: 0.041328, mean_q: 0.049992
  6821/100000: episode: 918, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.006305, mae: 0.055167, mean_q: 0.066216
  6831/100000: episode: 919, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002593, mae: 0.041486, mean_q: 0.033069
  6841/100000: episode: 920, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001894, mae: 0.039396, mean_q: 0.020044
  6851/100000: episode: 921, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002161, mae: 0.033411, mean_q: 0.025179
  6861/100000: episode: 922, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.003358, mae: 0.039794, mean_q: 0.039967
  6871/100000: episode: 923, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.003940, mae: 0.033642, mean_q: 0.041797
  6881/100000: episode: 924, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002386, mae: 0.032436, mean_q: 0.044615
  6891/100000: episode: 925, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.004508, mae: 0.042833, mean_q: 0.041847
  6901/100000: episode: 926, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.003131, mae: 0.044902, mean_q: 0.044850
  6911/100000: episode: 927, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001999, mae: 0.035658, mean_q: 0.050121
  6921/100000: episode: 928, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002640, mae: 0.035552, mean_q: 0.041506
  6931/100000: episode: 929, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002266, mae: 0.031432, mean_q: 0.038418
  6941/100000: episode: 930, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.003392, mae: 0.037824, mean_q: 0.043544
  6951/100000: episode: 931, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002085, mae: 0.032669, mean_q: 0.045219
  6961/100000: episode: 932, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.006412, mae: 0.058956, mean_q: 0.067135
  6971/100000: episode: 933, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002392, mae: 0.042263, mean_q: 0.018709
  6981/100000: episode: 934, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.004249, mae: 0.040877, mean_q: 0.047568
  6991/100000: episode: 935, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002438, mae: 0.031063, mean_q: 0.027731
  7001/100000: episode: 936, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.004533, mae: 0.039399, mean_q: 0.052131
  7011/100000: episode: 937, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.003840, mae: 0.035833, mean_q: 0.051773
  7021/100000: episode: 938, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.004940, mae: 0.039828, mean_q: 0.046138
  7031/100000: episode: 939, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001752, mae: 0.032561, mean_q: 0.020218
  7041/100000: episode: 940, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002388, mae: 0.035941, mean_q: 0.045780
  7051/100000: episode: 941, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002274, mae: 0.027279, mean_q: 0.026999
  7061/100000: episode: 942, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.003524, mae: 0.031390, mean_q: 0.049447
  7071/100000: episode: 943, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.003217, mae: 0.034051, mean_q: 0.033599
  7081/100000: episode: 944, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.003446, mae: 0.035417, mean_q: 0.040256
  7091/100000: episode: 945, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001505, mae: 0.028430, mean_q: 0.022859
  7101/100000: episode: 946, duration: 0.064s, episode steps: 10, steps per second: 155, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.003321, mae: 0.041586, mean_q: 0.051299
  7111/100000: episode: 947, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.004536, mae: 0.054878, mean_q: 0.049738
  7121/100000: episode: 948, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002981, mae: 0.044081, mean_q: 0.027522
  7131/100000: episode: 949, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002814, mae: 0.039392, mean_q: 0.026322
  7141/100000: episode: 950, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.003001, mae: 0.044507, mean_q: 0.045172
  7151/100000: episode: 951, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.002576, mae: 0.036259, mean_q: 0.044978
  7161/100000: episode: 952, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002908, mae: 0.030227, mean_q: 0.030648
  7171/100000: episode: 953, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.003340, mae: 0.033903, mean_q: 0.041359
  7181/100000: episode: 954, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.004447, mae: 0.033678, mean_q: 0.045023
  7191/100000: episode: 955, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001586, mae: 0.030398, mean_q: 0.024390
  7201/100000: episode: 956, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002658, mae: 0.031233, mean_q: 0.037616
  7211/100000: episode: 957, duration: 0.084s, episode steps: 10, steps per second: 118, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002529, mae: 0.034423, mean_q: 0.028952
  7221/100000: episode: 958, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002734, mae: 0.034381, mean_q: 0.043790
  7231/100000: episode: 959, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.003037, mae: 0.031354, mean_q: 0.032833
  7241/100000: episode: 960, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001540, mae: 0.022101, mean_q: 0.023169
  7251/100000: episode: 961, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002925, mae: 0.030272, mean_q: 0.038325
  7261/100000: episode: 962, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001837, mae: 0.025931, mean_q: 0.036557
  7271/100000: episode: 963, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002789, mae: 0.034130, mean_q: 0.048290
  7281/100000: episode: 964, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.003110, mae: 0.034997, mean_q: 0.035570
  7291/100000: episode: 965, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.002421, mae: 0.033009, mean_q: 0.042447
  7301/100000: episode: 966, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002752, mae: 0.039121, mean_q: 0.038526
  7311/100000: episode: 967, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.003044, mae: 0.038363, mean_q: 0.042313
  7321/100000: episode: 968, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.003413, mae: 0.033710, mean_q: 0.029847
  7331/100000: episode: 969, duration: 0.060s, episode steps: 10, steps per second: 165, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002524, mae: 0.031175, mean_q: 0.028922
[Info] 1-TH LEVEL FOUND: 0.04278924688696861, Considering 11/100 traces
  7341/100000: episode: 970, duration: 0.840s, episode steps: 10, steps per second: 12, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.003275, mae: 0.035787, mean_q: 0.051159
  7344/100000: episode: 971, duration: 0.036s, episode steps: 3, steps per second: 83, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001442, mae: 0.025024, mean_q: 0.035893
  7347/100000: episode: 972, duration: 0.036s, episode steps: 3, steps per second: 82, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001294, mae: 0.028051, mean_q: 0.022531
  7349/100000: episode: 973, duration: 0.018s, episode steps: 2, steps per second: 110, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002349, mae: 0.031548, mean_q: 0.037828
  7356/100000: episode: 974, duration: 0.049s, episode steps: 7, steps per second: 142, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.002162, mae: 0.029805, mean_q: 0.044752
  7358/100000: episode: 975, duration: 0.032s, episode steps: 2, steps per second: 62, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003868, mae: 0.036472, mean_q: 0.025069
  7361/100000: episode: 976, duration: 0.028s, episode steps: 3, steps per second: 106, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001617, mae: 0.029512, mean_q: 0.029817
  7363/100000: episode: 977, duration: 0.016s, episode steps: 2, steps per second: 122, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004438, mae: 0.045424, mean_q: 0.086731
  7366/100000: episode: 978, duration: 0.026s, episode steps: 3, steps per second: 113, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001386, mae: 0.024446, mean_q: 0.036820
  7373/100000: episode: 979, duration: 0.062s, episode steps: 7, steps per second: 113, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001291, mae: 0.028293, mean_q: 0.015614
  7376/100000: episode: 980, duration: 0.023s, episode steps: 3, steps per second: 131, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003279, mae: 0.037550, mean_q: 0.053552
  7378/100000: episode: 981, duration: 0.021s, episode steps: 2, steps per second: 93, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001489, mae: 0.025874, mean_q: 0.033516
  7380/100000: episode: 982, duration: 0.017s, episode steps: 2, steps per second: 118, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001275, mae: 0.032918, mean_q: 0.007643
  7387/100000: episode: 983, duration: 0.050s, episode steps: 7, steps per second: 140, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.002582, mae: 0.029011, mean_q: 0.030875
  7389/100000: episode: 984, duration: 0.014s, episode steps: 2, steps per second: 144, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001049, mae: 0.028587, mean_q: 0.045683
  7392/100000: episode: 985, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002721, mae: 0.031276, mean_q: 0.034832
  7399/100000: episode: 986, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.002949, mae: 0.033350, mean_q: 0.034232
  7401/100000: episode: 987, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001451, mae: 0.024056, mean_q: 0.033785
  7404/100000: episode: 988, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001348, mae: 0.025280, mean_q: 0.020290
  7407/100000: episode: 989, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001187, mae: 0.024243, mean_q: 0.029889
  7414/100000: episode: 990, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.004688, mae: 0.036191, mean_q: 0.046165
  7417/100000: episode: 991, duration: 0.025s, episode steps: 3, steps per second: 118, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001951, mae: 0.032056, mean_q: 0.034925
  7424/100000: episode: 992, duration: 0.060s, episode steps: 7, steps per second: 116, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.005056, mae: 0.043908, mean_q: 0.057428
  7426/100000: episode: 993, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001846, mae: 0.033400, mean_q: 0.031964
  7428/100000: episode: 994, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001292, mae: 0.022757, mean_q: 0.022716
  7430/100000: episode: 995, duration: 0.016s, episode steps: 2, steps per second: 125, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000925, mae: 0.026808, mean_q: 0.046260
  7432/100000: episode: 996, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001002, mae: 0.021274, mean_q: 0.023431
  7439/100000: episode: 997, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001908, mae: 0.033477, mean_q: 0.043583
  7446/100000: episode: 998, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.003397, mae: 0.032568, mean_q: 0.046357
  7453/100000: episode: 999, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.002168, mae: 0.030103, mean_q: 0.033880
  7456/100000: episode: 1000, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003495, mae: 0.045229, mean_q: 0.073877
  7463/100000: episode: 1001, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.003265, mae: 0.037485, mean_q: 0.034754
  7470/100000: episode: 1002, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001852, mae: 0.029007, mean_q: 0.034543
  7472/100000: episode: 1003, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001367, mae: 0.031574, mean_q: 0.006452
  7479/100000: episode: 1004, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.004409, mae: 0.040054, mean_q: 0.051603
  7486/100000: episode: 1005, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.005438, mae: 0.042171, mean_q: 0.037474
  7488/100000: episode: 1006, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001966, mae: 0.033480, mean_q: 0.055577
  7495/100000: episode: 1007, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002834, mae: 0.032490, mean_q: 0.032218
  7502/100000: episode: 1008, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.004163, mae: 0.041856, mean_q: 0.060741
  7504/100000: episode: 1009, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002398, mae: 0.037385, mean_q: 0.036237
  7511/100000: episode: 1010, duration: 0.037s, episode steps: 7, steps per second: 192, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.002252, mae: 0.038855, mean_q: 0.032893
  7518/100000: episode: 1011, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.001554, mae: 0.032247, mean_q: 0.038345
  7521/100000: episode: 1012, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001081, mae: 0.026299, mean_q: 0.021759
  7523/100000: episode: 1013, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002049, mae: 0.033261, mean_q: 0.051875
  7525/100000: episode: 1014, duration: 0.015s, episode steps: 2, steps per second: 130, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001299, mae: 0.025212, mean_q: 0.027056
  7527/100000: episode: 1015, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003528, mae: 0.029858, mean_q: 0.036390
  7534/100000: episode: 1016, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.003296, mae: 0.030010, mean_q: 0.032959
  7537/100000: episode: 1017, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000945, mae: 0.018000, mean_q: 0.022620
  7544/100000: episode: 1018, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002317, mae: 0.031084, mean_q: 0.040907
  7551/100000: episode: 1019, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002928, mae: 0.037427, mean_q: 0.047586
  7554/100000: episode: 1020, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.004802, mae: 0.037565, mean_q: 0.039860
  7561/100000: episode: 1021, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001981, mae: 0.030506, mean_q: 0.037061
  7563/100000: episode: 1022, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001217, mae: 0.020029, mean_q: 0.038605
  7566/100000: episode: 1023, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001422, mae: 0.027336, mean_q: 0.038676
  7573/100000: episode: 1024, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.004168, mae: 0.040600, mean_q: 0.040180
  7575/100000: episode: 1025, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004080, mae: 0.041682, mean_q: 0.059231
  7582/100000: episode: 1026, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001660, mae: 0.031476, mean_q: 0.033522
  7584/100000: episode: 1027, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004943, mae: 0.030543, mean_q: 0.011162
  7586/100000: episode: 1028, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001103, mae: 0.026380, mean_q: 0.039546
  7589/100000: episode: 1029, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001295, mae: 0.028357, mean_q: 0.032325
  7596/100000: episode: 1030, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.003024, mae: 0.032992, mean_q: 0.027755
  7598/100000: episode: 1031, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004314, mae: 0.043077, mean_q: 0.057398
  7600/100000: episode: 1032, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006112, mae: 0.049997, mean_q: 0.057416
  7607/100000: episode: 1033, duration: 0.075s, episode steps: 7, steps per second: 93, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.004381, mae: 0.039948, mean_q: 0.038328
  7609/100000: episode: 1034, duration: 0.025s, episode steps: 2, steps per second: 80, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001927, mae: 0.030676, mean_q: 0.043762
  7616/100000: episode: 1035, duration: 0.052s, episode steps: 7, steps per second: 134, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.004238, mae: 0.038197, mean_q: 0.044934
  7618/100000: episode: 1036, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002416, mae: 0.036574, mean_q: 0.068365
  7621/100000: episode: 1037, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002349, mae: 0.042997, mean_q: 0.035719
  7623/100000: episode: 1038, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002262, mae: 0.038890, mean_q: 0.016983
  7630/100000: episode: 1039, duration: 0.071s, episode steps: 7, steps per second: 99, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.005538, mae: 0.049811, mean_q: 0.065557
  7637/100000: episode: 1040, duration: 0.050s, episode steps: 7, steps per second: 139, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002929, mae: 0.039490, mean_q: 0.016290
  7639/100000: episode: 1041, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001781, mae: 0.032100, mean_q: 0.061649
  7646/100000: episode: 1042, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.004176, mae: 0.042575, mean_q: 0.023267
  7653/100000: episode: 1043, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.002605, mae: 0.042079, mean_q: 0.048336
  7655/100000: episode: 1044, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001754, mae: 0.039638, mean_q: 0.020544
  7658/100000: episode: 1045, duration: 0.021s, episode steps: 3, steps per second: 141, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002160, mae: 0.039040, mean_q: 0.055374
  7660/100000: episode: 1046, duration: 0.014s, episode steps: 2, steps per second: 143, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001600, mae: 0.034175, mean_q: 0.048377
  7662/100000: episode: 1047, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002182, mae: 0.036111, mean_q: 0.044943
  7664/100000: episode: 1048, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.007499, mae: 0.057483, mean_q: 0.009385
  7666/100000: episode: 1049, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002232, mae: 0.045103, mean_q: 0.084956
  7668/100000: episode: 1050, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004790, mae: 0.064830, mean_q: 0.101706
  7675/100000: episode: 1051, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.004276, mae: 0.051624, mean_q: 0.019301
  7682/100000: episode: 1052, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002447, mae: 0.040770, mean_q: 0.054500
  7684/100000: episode: 1053, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002430, mae: 0.050041, mean_q: 0.009474
  7691/100000: episode: 1054, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002637, mae: 0.037689, mean_q: 0.046895
  7698/100000: episode: 1055, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.005417, mae: 0.044844, mean_q: 0.048818
  7705/100000: episode: 1056, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003578, mae: 0.045180, mean_q: 0.040141
  7712/100000: episode: 1057, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000992, mae: 0.023857, mean_q: 0.035622
  7715/100000: episode: 1058, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001461, mae: 0.027485, mean_q: 0.025496
[Info] 2-TH LEVEL FOUND: 0.1933029592037201, Considering 20/100 traces
  7722/100000: episode: 1059, duration: 0.710s, episode steps: 7, steps per second: 10, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.003727, mae: 0.035415, mean_q: 0.045202
  7727/100000: episode: 1060, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003135, mae: 0.033609, mean_q: 0.031114
  7729/100000: episode: 1061, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001396, mae: 0.023487, mean_q: 0.036925
  7734/100000: episode: 1062, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.003351, mae: 0.034071, mean_q: 0.021763
  7739/100000: episode: 1063, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002827, mae: 0.037182, mean_q: 0.044547
  7744/100000: episode: 1064, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002282, mae: 0.035203, mean_q: 0.012628
  7746/100000: episode: 1065, duration: 0.014s, episode steps: 2, steps per second: 139, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001491, mae: 0.034068, mean_q: 0.051383
  7748/100000: episode: 1066, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004717, mae: 0.057884, mean_q: 0.079504
  7753/100000: episode: 1067, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.003560, mae: 0.043298, mean_q: 0.039242
  7758/100000: episode: 1068, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.005888, mae: 0.052861, mean_q: 0.047478
  7760/100000: episode: 1069, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002601, mae: 0.025219, mean_q: 0.036163
  7765/100000: episode: 1070, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.004688, mae: 0.037690, mean_q: 0.031989
  7767/100000: episode: 1071, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001789, mae: 0.030747, mean_q: 0.050706
  7769/100000: episode: 1072, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002088, mae: 0.031923, mean_q: 0.067039
  7771/100000: episode: 1073, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001504, mae: 0.027939, mean_q: 0.032577
  7773/100000: episode: 1074, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005012, mae: 0.036434, mean_q: 0.047128
  7778/100000: episode: 1075, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002360, mae: 0.029946, mean_q: 0.051253
  7780/100000: episode: 1076, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005551, mae: 0.046582, mean_q: 0.052173
  7785/100000: episode: 1077, duration: 0.038s, episode steps: 5, steps per second: 133, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.004347, mae: 0.045542, mean_q: 0.045208
  7790/100000: episode: 1078, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.004400, mae: 0.050191, mean_q: 0.035483
  7792/100000: episode: 1079, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001306, mae: 0.032726, mean_q: 0.031943
  7797/100000: episode: 1080, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.004306, mae: 0.045780, mean_q: 0.056512
  7799/100000: episode: 1081, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001599, mae: 0.022235, mean_q: 0.021187
  7801/100000: episode: 1082, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002049, mae: 0.041474, mean_q: 0.083924
  7806/100000: episode: 1083, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002883, mae: 0.038569, mean_q: 0.028863
  7808/100000: episode: 1084, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004204, mae: 0.037480, mean_q: 0.030503
  7813/100000: episode: 1085, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.004108, mae: 0.047448, mean_q: 0.069212
  7815/100000: episode: 1086, duration: 0.015s, episode steps: 2, steps per second: 130, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001134, mae: 0.026853, mean_q: 0.021246
  7817/100000: episode: 1087, duration: 0.019s, episode steps: 2, steps per second: 103, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000818, mae: 0.022379, mean_q: 0.005466
  7819/100000: episode: 1088, duration: 0.022s, episode steps: 2, steps per second: 93, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003586, mae: 0.029718, mean_q: 0.039567
  7824/100000: episode: 1089, duration: 0.029s, episode steps: 5, steps per second: 173, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002855, mae: 0.032219, mean_q: 0.040497
  7826/100000: episode: 1090, duration: 0.015s, episode steps: 2, steps per second: 133, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002432, mae: 0.034848, mean_q: 0.045061
  7831/100000: episode: 1091, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.003306, mae: 0.042479, mean_q: 0.058879
  7836/100000: episode: 1092, duration: 0.036s, episode steps: 5, steps per second: 138, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001989, mae: 0.038676, mean_q: 0.019153
  7838/100000: episode: 1093, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001353, mae: 0.024705, mean_q: 0.033042
[Info] FALSIFICATION!
  7842/100000: episode: 1094, duration: 0.276s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.005914, mae: 0.050142, mean_q: 0.055888
  7844/100000: episode: 1095, duration: 0.015s, episode steps: 2, steps per second: 132, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001323, mae: 0.033870, mean_q: 0.015957
  7849/100000: episode: 1096, duration: 0.035s, episode steps: 5, steps per second: 142, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.003246, mae: 0.036748, mean_q: 0.018332
  7854/100000: episode: 1097, duration: 0.053s, episode steps: 5, steps per second: 95, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002444, mae: 0.036365, mean_q: 0.047593
  7856/100000: episode: 1098, duration: 0.024s, episode steps: 2, steps per second: 84, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001751, mae: 0.033241, mean_q: 0.025937
  7861/100000: episode: 1099, duration: 0.043s, episode steps: 5, steps per second: 116, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001262, mae: 0.024341, mean_q: 0.024278
  7863/100000: episode: 1100, duration: 0.017s, episode steps: 2, steps per second: 119, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002736, mae: 0.042753, mean_q: 0.061931
  7868/100000: episode: 1101, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.004129, mae: 0.033564, mean_q: 0.039924
  7870/100000: episode: 1102, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.007148, mae: 0.050994, mean_q: 0.055875
  7872/100000: episode: 1103, duration: 0.015s, episode steps: 2, steps per second: 130, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000713, mae: 0.020900, mean_q: 0.013263
  7877/100000: episode: 1104, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002512, mae: 0.033691, mean_q: 0.051559
  7879/100000: episode: 1105, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002013, mae: 0.036314, mean_q: 0.034235
  7881/100000: episode: 1106, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001504, mae: 0.035713, mean_q: 0.020074
  7886/100000: episode: 1107, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.003056, mae: 0.030816, mean_q: 0.038237
  7888/100000: episode: 1108, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000399, mae: 0.015300, mean_q: 0.027782
  7890/100000: episode: 1109, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001712, mae: 0.026949, mean_q: 0.035745
  7892/100000: episode: 1110, duration: 0.021s, episode steps: 2, steps per second: 94, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002456, mae: 0.038009, mean_q: 0.043014
  7894/100000: episode: 1111, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001588, mae: 0.028398, mean_q: 0.028889
  7899/100000: episode: 1112, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.004050, mae: 0.045057, mean_q: 0.048885
  7901/100000: episode: 1113, duration: 0.015s, episode steps: 2, steps per second: 132, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003731, mae: 0.063042, mean_q: 0.078414
  7903/100000: episode: 1114, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003837, mae: 0.033106, mean_q: 0.038680
  7905/100000: episode: 1115, duration: 0.028s, episode steps: 2, steps per second: 71, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001920, mae: 0.039865, mean_q: 0.004124
  7907/100000: episode: 1116, duration: 0.046s, episode steps: 2, steps per second: 43, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001404, mae: 0.030169, mean_q: 0.032031
  7912/100000: episode: 1117, duration: 0.046s, episode steps: 5, steps per second: 108, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.004471, mae: 0.042191, mean_q: 0.063979
  7917/100000: episode: 1118, duration: 0.034s, episode steps: 5, steps per second: 147, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.004652, mae: 0.041531, mean_q: 0.053224
  7919/100000: episode: 1119, duration: 0.017s, episode steps: 2, steps per second: 117, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002059, mae: 0.033162, mean_q: 0.045490
  7924/100000: episode: 1120, duration: 0.039s, episode steps: 5, steps per second: 129, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.003443, mae: 0.040722, mean_q: 0.040537
  7929/100000: episode: 1121, duration: 0.036s, episode steps: 5, steps per second: 139, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.004459, mae: 0.045131, mean_q: 0.055049
  7931/100000: episode: 1122, duration: 0.015s, episode steps: 2, steps per second: 131, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001827, mae: 0.036945, mean_q: 0.057501
  7933/100000: episode: 1123, duration: 0.021s, episode steps: 2, steps per second: 96, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003569, mae: 0.033691, mean_q: 0.032235
  7935/100000: episode: 1124, duration: 0.021s, episode steps: 2, steps per second: 97, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.007804, mae: 0.062416, mean_q: 0.035561
  7937/100000: episode: 1125, duration: 0.022s, episode steps: 2, steps per second: 93, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006500, mae: 0.050696, mean_q: 0.063877
  7939/100000: episode: 1126, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.007293, mae: 0.051833, mean_q: 0.068795
  7944/100000: episode: 1127, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.004643, mae: 0.043659, mean_q: 0.056772
  7946/100000: episode: 1128, duration: 0.017s, episode steps: 2, steps per second: 120, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.007598, mae: 0.048304, mean_q: 0.076888
  7951/100000: episode: 1129, duration: 0.033s, episode steps: 5, steps per second: 149, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002385, mae: 0.031060, mean_q: 0.046632
  7956/100000: episode: 1130, duration: 0.038s, episode steps: 5, steps per second: 132, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002497, mae: 0.032957, mean_q: 0.036604
  7961/100000: episode: 1131, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001572, mae: 0.028167, mean_q: 0.047925
  7966/100000: episode: 1132, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002283, mae: 0.042285, mean_q: 0.025429
  7968/100000: episode: 1133, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002726, mae: 0.046483, mean_q: 0.074117
  7970/100000: episode: 1134, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004351, mae: 0.040119, mean_q: 0.056401
  7972/100000: episode: 1135, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.007589, mae: 0.060592, mean_q: 0.045853
  7977/100000: episode: 1136, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002545, mae: 0.033482, mean_q: 0.036928
  7979/100000: episode: 1137, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003817, mae: 0.040562, mean_q: 0.052759
  7984/100000: episode: 1138, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.004740, mae: 0.043229, mean_q: 0.051887
[Info] Complete ISplit Iteration
[Info] Levels: [0.042789247, 0.19330296, 0.53060836]
[Info] Cond. Prob: [0.11, 0.2, 0.01]
[Info] Error Prob: 0.00022000000000000003

  7989/100000: episode: 1139, duration: 0.850s, episode steps: 5, steps per second: 6, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.005100, mae: 0.046030, mean_q: 0.054996
  7999/100000: episode: 1140, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003190, mae: 0.039086, mean_q: 0.043599
  8009/100000: episode: 1141, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.003413, mae: 0.043057, mean_q: 0.037851
  8019/100000: episode: 1142, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.004421, mae: 0.048084, mean_q: 0.044753
  8029/100000: episode: 1143, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003640, mae: 0.039467, mean_q: 0.047704
  8039/100000: episode: 1144, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002775, mae: 0.040497, mean_q: 0.044208
  8049/100000: episode: 1145, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001598, mae: 0.029226, mean_q: 0.038848
  8059/100000: episode: 1146, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001817, mae: 0.033891, mean_q: 0.037088
  8069/100000: episode: 1147, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002817, mae: 0.037481, mean_q: 0.040357
  8079/100000: episode: 1148, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.003538, mae: 0.038466, mean_q: 0.041874
  8089/100000: episode: 1149, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001695, mae: 0.031260, mean_q: 0.033451
  8099/100000: episode: 1150, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002883, mae: 0.032703, mean_q: 0.027374
  8109/100000: episode: 1151, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.004357, mae: 0.041643, mean_q: 0.046377
  8119/100000: episode: 1152, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.003114, mae: 0.036456, mean_q: 0.047484
  8129/100000: episode: 1153, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.003828, mae: 0.033624, mean_q: 0.044975
  8139/100000: episode: 1154, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001798, mae: 0.030015, mean_q: 0.029224
  8149/100000: episode: 1155, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.003996, mae: 0.036954, mean_q: 0.043356
  8159/100000: episode: 1156, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.003734, mae: 0.034220, mean_q: 0.040226
  8169/100000: episode: 1157, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002244, mae: 0.031205, mean_q: 0.039502
  8179/100000: episode: 1158, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.004240, mae: 0.037814, mean_q: 0.045525
  8189/100000: episode: 1159, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.004350, mae: 0.038219, mean_q: 0.052745
  8199/100000: episode: 1160, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.005114, mae: 0.039846, mean_q: 0.053025
  8209/100000: episode: 1161, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003810, mae: 0.044845, mean_q: 0.034766
  8219/100000: episode: 1162, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.005583, mae: 0.045537, mean_q: 0.051939
  8229/100000: episode: 1163, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002403, mae: 0.036249, mean_q: 0.043182
  8239/100000: episode: 1164, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.004919, mae: 0.041455, mean_q: 0.043877
  8249/100000: episode: 1165, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002204, mae: 0.031185, mean_q: 0.040420
  8259/100000: episode: 1166, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.003499, mae: 0.043910, mean_q: 0.046070
  8269/100000: episode: 1167, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002769, mae: 0.039372, mean_q: 0.036946
  8279/100000: episode: 1168, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.004012, mae: 0.043612, mean_q: 0.040184
  8289/100000: episode: 1169, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002996, mae: 0.040878, mean_q: 0.036424
  8299/100000: episode: 1170, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.004350, mae: 0.038687, mean_q: 0.047449
  8309/100000: episode: 1171, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.003692, mae: 0.040574, mean_q: 0.035632
  8319/100000: episode: 1172, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.003593, mae: 0.040979, mean_q: 0.043387
  8329/100000: episode: 1173, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002989, mae: 0.033540, mean_q: 0.041794
  8339/100000: episode: 1174, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002293, mae: 0.033256, mean_q: 0.038783
  8349/100000: episode: 1175, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002836, mae: 0.031682, mean_q: 0.039939
  8359/100000: episode: 1176, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002319, mae: 0.029874, mean_q: 0.035422
  8369/100000: episode: 1177, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.003794, mae: 0.039186, mean_q: 0.052820
  8379/100000: episode: 1178, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002323, mae: 0.028403, mean_q: 0.034854
  8389/100000: episode: 1179, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001899, mae: 0.028690, mean_q: 0.026454
  8399/100000: episode: 1180, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.003799, mae: 0.037846, mean_q: 0.047232
  8409/100000: episode: 1181, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.003828, mae: 0.040757, mean_q: 0.045592
  8419/100000: episode: 1182, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.005254, mae: 0.048612, mean_q: 0.059471
  8429/100000: episode: 1183, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002621, mae: 0.031893, mean_q: 0.028232
  8439/100000: episode: 1184, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.004371, mae: 0.040011, mean_q: 0.048928
  8449/100000: episode: 1185, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002465, mae: 0.035004, mean_q: 0.042133
  8459/100000: episode: 1186, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.002499, mae: 0.036099, mean_q: 0.032711
  8469/100000: episode: 1187, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.003656, mae: 0.039407, mean_q: 0.045892
  8479/100000: episode: 1188, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.004708, mae: 0.043925, mean_q: 0.061274
  8489/100000: episode: 1189, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.004604, mae: 0.043886, mean_q: 0.050629
  8499/100000: episode: 1190, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.003940, mae: 0.048344, mean_q: 0.047977
  8509/100000: episode: 1191, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.003863, mae: 0.039599, mean_q: 0.032324
  8519/100000: episode: 1192, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002925, mae: 0.034920, mean_q: 0.045027
  8529/100000: episode: 1193, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002266, mae: 0.033761, mean_q: 0.038054
  8539/100000: episode: 1194, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.004862, mae: 0.038207, mean_q: 0.043915
  8549/100000: episode: 1195, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002917, mae: 0.044349, mean_q: 0.036096
  8559/100000: episode: 1196, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.004793, mae: 0.046117, mean_q: 0.051027
  8569/100000: episode: 1197, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001793, mae: 0.029348, mean_q: 0.037795
  8579/100000: episode: 1198, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001967, mae: 0.028770, mean_q: 0.026481
  8589/100000: episode: 1199, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.005645, mae: 0.042912, mean_q: 0.054514
  8599/100000: episode: 1200, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.005133, mae: 0.044233, mean_q: 0.048444
  8609/100000: episode: 1201, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002974, mae: 0.037168, mean_q: 0.039000
  8619/100000: episode: 1202, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.004989, mae: 0.047583, mean_q: 0.055149
  8629/100000: episode: 1203, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.002936, mae: 0.034883, mean_q: 0.040323
  8639/100000: episode: 1204, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.004156, mae: 0.044868, mean_q: 0.045526
  8649/100000: episode: 1205, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.003069, mae: 0.037877, mean_q: 0.041197
  8659/100000: episode: 1206, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002294, mae: 0.037640, mean_q: 0.022847
  8669/100000: episode: 1207, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.006206, mae: 0.051168, mean_q: 0.061425
  8679/100000: episode: 1208, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.004515, mae: 0.040362, mean_q: 0.040567
  8689/100000: episode: 1209, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003254, mae: 0.044388, mean_q: 0.043335
  8699/100000: episode: 1210, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.003899, mae: 0.046698, mean_q: 0.061358
  8709/100000: episode: 1211, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002525, mae: 0.032231, mean_q: 0.039025
  8719/100000: episode: 1212, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002388, mae: 0.036270, mean_q: 0.028644
  8729/100000: episode: 1213, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002867, mae: 0.034006, mean_q: 0.035756
  8739/100000: episode: 1214, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.003566, mae: 0.038080, mean_q: 0.045786
  8749/100000: episode: 1215, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.003301, mae: 0.035426, mean_q: 0.047869
  8759/100000: episode: 1216, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.004123, mae: 0.038518, mean_q: 0.045612
  8769/100000: episode: 1217, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002268, mae: 0.028227, mean_q: 0.031450
  8779/100000: episode: 1218, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002604, mae: 0.028800, mean_q: 0.038928
  8789/100000: episode: 1219, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002512, mae: 0.029179, mean_q: 0.034100
  8799/100000: episode: 1220, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002958, mae: 0.032275, mean_q: 0.046422
  8809/100000: episode: 1221, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.004670, mae: 0.041501, mean_q: 0.049180
  8819/100000: episode: 1222, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002026, mae: 0.030271, mean_q: 0.037361
  8829/100000: episode: 1223, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001704, mae: 0.029927, mean_q: 0.038187
  8839/100000: episode: 1224, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001396, mae: 0.027468, mean_q: 0.027136
  8849/100000: episode: 1225, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.004513, mae: 0.043577, mean_q: 0.046087
  8859/100000: episode: 1226, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.003276, mae: 0.042600, mean_q: 0.042352
  8869/100000: episode: 1227, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002964, mae: 0.044002, mean_q: 0.035297
  8879/100000: episode: 1228, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001862, mae: 0.030650, mean_q: 0.031961
  8889/100000: episode: 1229, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.006933, mae: 0.053344, mean_q: 0.065545
  8899/100000: episode: 1230, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.004236, mae: 0.047064, mean_q: 0.039518
  8909/100000: episode: 1231, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.004551, mae: 0.047365, mean_q: 0.033705
  8919/100000: episode: 1232, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002598, mae: 0.049837, mean_q: 0.032423
  8929/100000: episode: 1233, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.003113, mae: 0.042195, mean_q: 0.045345
  8939/100000: episode: 1234, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.003646, mae: 0.039435, mean_q: 0.044052
  8949/100000: episode: 1235, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002201, mae: 0.030121, mean_q: 0.031731
  8959/100000: episode: 1236, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002548, mae: 0.031896, mean_q: 0.041960
  8969/100000: episode: 1237, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003677, mae: 0.041044, mean_q: 0.044164
  8979/100000: episode: 1238, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.002444, mae: 0.029815, mean_q: 0.042133
[Info] 1-TH LEVEL FOUND: 0.0927918553352356, Considering 13/100 traces
  8989/100000: episode: 1239, duration: 0.693s, episode steps: 10, steps per second: 14, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.003996, mae: 0.041200, mean_q: 0.043340
  8993/100000: episode: 1240, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002481, mae: 0.039230, mean_q: 0.054087
  8997/100000: episode: 1241, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.003272, mae: 0.048792, mean_q: 0.021587
  9000/100000: episode: 1242, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001962, mae: 0.034945, mean_q: 0.050828
  9004/100000: episode: 1243, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002916, mae: 0.034246, mean_q: 0.036835
  9007/100000: episode: 1244, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.003290, mae: 0.039761, mean_q: 0.028149
  9011/100000: episode: 1245, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001590, mae: 0.033367, mean_q: 0.048396
  9014/100000: episode: 1246, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003957, mae: 0.029547, mean_q: 0.009503
  9017/100000: episode: 1247, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000841, mae: 0.020524, mean_q: 0.031683
  9021/100000: episode: 1248, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002399, mae: 0.028260, mean_q: 0.029849
  9025/100000: episode: 1249, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.007360, mae: 0.043255, mean_q: 0.045830
  9029/100000: episode: 1250, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002505, mae: 0.035509, mean_q: 0.049535
  9032/100000: episode: 1251, duration: 0.016s, episode steps: 3, steps per second: 186, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002509, mae: 0.030412, mean_q: 0.016166
  9036/100000: episode: 1252, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001876, mae: 0.030151, mean_q: 0.047099
  9040/100000: episode: 1253, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001987, mae: 0.033669, mean_q: 0.047060
  9043/100000: episode: 1254, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001104, mae: 0.027343, mean_q: 0.011323
  9046/100000: episode: 1255, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002755, mae: 0.030282, mean_q: 0.040080
  9049/100000: episode: 1256, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001556, mae: 0.029746, mean_q: 0.046434
  9053/100000: episode: 1257, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002664, mae: 0.031458, mean_q: 0.041604
  9056/100000: episode: 1258, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001212, mae: 0.028780, mean_q: 0.019596
  9060/100000: episode: 1259, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002747, mae: 0.035917, mean_q: 0.021698
  9063/100000: episode: 1260, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.003143, mae: 0.040633, mean_q: 0.049841
  9066/100000: episode: 1261, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001514, mae: 0.029697, mean_q: 0.029928
  9070/100000: episode: 1262, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002011, mae: 0.038968, mean_q: 0.043289
  9074/100000: episode: 1263, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001176, mae: 0.027630, mean_q: 0.041848
  9077/100000: episode: 1264, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001292, mae: 0.027581, mean_q: 0.029818
  9081/100000: episode: 1265, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000468, mae: 0.017624, mean_q: 0.012237
  9085/100000: episode: 1266, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001900, mae: 0.031566, mean_q: 0.046806
  9088/100000: episode: 1267, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001232, mae: 0.023426, mean_q: 0.032116
  9092/100000: episode: 1268, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.006121, mae: 0.043293, mean_q: 0.046558
  9095/100000: episode: 1269, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.005993, mae: 0.045674, mean_q: 0.052314
  9098/100000: episode: 1270, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.008089, mae: 0.063518, mean_q: 0.074222
  9101/100000: episode: 1271, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002273, mae: 0.029742, mean_q: 0.048647
  9104/100000: episode: 1272, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.006013, mae: 0.047887, mean_q: 0.048346
  9107/100000: episode: 1273, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.007814, mae: 0.055515, mean_q: 0.061141
  9111/100000: episode: 1274, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.004499, mae: 0.046104, mean_q: 0.064259
  9114/100000: episode: 1275, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002033, mae: 0.045478, mean_q: 0.020457
  9117/100000: episode: 1276, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001440, mae: 0.031177, mean_q: 0.025760
  9121/100000: episode: 1277, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.003362, mae: 0.040146, mean_q: 0.046649
  9125/100000: episode: 1278, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001893, mae: 0.023713, mean_q: 0.032113
  9128/100000: episode: 1279, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001011, mae: 0.021076, mean_q: 0.033460
  9132/100000: episode: 1280, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.005286, mae: 0.041325, mean_q: 0.042547
  9136/100000: episode: 1281, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001016, mae: 0.022191, mean_q: 0.040243
  9139/100000: episode: 1282, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003218, mae: 0.034746, mean_q: 0.027646
  9143/100000: episode: 1283, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001155, mae: 0.023525, mean_q: 0.030308
  9146/100000: episode: 1284, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000801, mae: 0.020292, mean_q: 0.018299
  9149/100000: episode: 1285, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003874, mae: 0.042501, mean_q: 0.051620
  9152/100000: episode: 1286, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002219, mae: 0.039673, mean_q: 0.058829
  9155/100000: episode: 1287, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.004891, mae: 0.043204, mean_q: 0.032088
  9158/100000: episode: 1288, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.004516, mae: 0.042871, mean_q: 0.069038
  9162/100000: episode: 1289, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.006947, mae: 0.047678, mean_q: 0.050967
  9165/100000: episode: 1290, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.006807, mae: 0.047843, mean_q: 0.060706
  9168/100000: episode: 1291, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001441, mae: 0.028494, mean_q: 0.050306
  9172/100000: episode: 1292, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.005091, mae: 0.054641, mean_q: 0.029278
  9175/100000: episode: 1293, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.003227, mae: 0.042252, mean_q: 0.057610
  9178/100000: episode: 1294, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001895, mae: 0.036083, mean_q: 0.031455
  9181/100000: episode: 1295, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.004350, mae: 0.041309, mean_q: 0.036224
  9184/100000: episode: 1296, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002020, mae: 0.033678, mean_q: 0.050020
  9188/100000: episode: 1297, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003787, mae: 0.038166, mean_q: 0.010772
  9191/100000: episode: 1298, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001619, mae: 0.035075, mean_q: 0.049124
  9195/100000: episode: 1299, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.004536, mae: 0.045551, mean_q: 0.054628
  9199/100000: episode: 1300, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.003798, mae: 0.042556, mean_q: 0.040812
  9203/100000: episode: 1301, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001568, mae: 0.025986, mean_q: 0.049764
  9206/100000: episode: 1302, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.003071, mae: 0.032677, mean_q: 0.038575
  9210/100000: episode: 1303, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.006789, mae: 0.044883, mean_q: 0.050595
  9213/100000: episode: 1304, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002212, mae: 0.038317, mean_q: 0.058814
  9216/100000: episode: 1305, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.003963, mae: 0.053913, mean_q: 0.016878
  9219/100000: episode: 1306, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001533, mae: 0.033586, mean_q: 0.049364
  9223/100000: episode: 1307, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.003678, mae: 0.036504, mean_q: 0.037191
  9226/100000: episode: 1308, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.004734, mae: 0.041084, mean_q: 0.032536
  9229/100000: episode: 1309, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.007417, mae: 0.059202, mean_q: 0.079953
  9232/100000: episode: 1310, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.005601, mae: 0.043072, mean_q: 0.038992
  9235/100000: episode: 1311, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001212, mae: 0.028501, mean_q: 0.032433
  9238/100000: episode: 1312, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003731, mae: 0.042436, mean_q: 0.057651
  9241/100000: episode: 1313, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003259, mae: 0.045365, mean_q: 0.006397
  9245/100000: episode: 1314, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001977, mae: 0.039897, mean_q: 0.054976
  9248/100000: episode: 1315, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.004731, mae: 0.040280, mean_q: 0.031376
  9251/100000: episode: 1316, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001183, mae: 0.030971, mean_q: 0.015480
  9254/100000: episode: 1317, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.004911, mae: 0.047574, mean_q: 0.063676
  9257/100000: episode: 1318, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001259, mae: 0.030486, mean_q: 0.031053
  9260/100000: episode: 1319, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.002918, mae: 0.042757, mean_q: 0.008298
  9263/100000: episode: 1320, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.004995, mae: 0.055177, mean_q: 0.081762
  9266/100000: episode: 1321, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.003352, mae: 0.052171, mean_q: 0.087846
  9269/100000: episode: 1322, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002864, mae: 0.038629, mean_q: 0.013642
  9272/100000: episode: 1323, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003644, mae: 0.042348, mean_q: 0.056693
  9275/100000: episode: 1324, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.005928, mae: 0.053369, mean_q: 0.069796
  9278/100000: episode: 1325, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001756, mae: 0.033286, mean_q: 0.032506
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.0927918553352356
  9281/100000: episode: 1326, duration: 0.480s, episode steps: 3, steps per second: 6, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.003699, mae: 0.047384, mean_q: 0.037188
  9291/100000: episode: 1327, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.004139, mae: 0.040375, mean_q: 0.053638
  9301/100000: episode: 1328, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001986, mae: 0.030700, mean_q: 0.037000
  9311/100000: episode: 1329, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002709, mae: 0.031292, mean_q: 0.030987
  9321/100000: episode: 1330, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001901, mae: 0.036200, mean_q: 0.029824
  9331/100000: episode: 1331, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002173, mae: 0.030183, mean_q: 0.033461
  9341/100000: episode: 1332, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.001641, mae: 0.027464, mean_q: 0.032447
  9351/100000: episode: 1333, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002963, mae: 0.035637, mean_q: 0.043107
  9361/100000: episode: 1334, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.003152, mae: 0.041374, mean_q: 0.040717
  9371/100000: episode: 1335, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001980, mae: 0.031218, mean_q: 0.031758
  9381/100000: episode: 1336, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002545, mae: 0.037403, mean_q: 0.043279
  9391/100000: episode: 1337, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.003108, mae: 0.038287, mean_q: 0.034853
  9401/100000: episode: 1338, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.003818, mae: 0.044241, mean_q: 0.049912
  9411/100000: episode: 1339, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002334, mae: 0.030312, mean_q: 0.034151
  9421/100000: episode: 1340, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002927, mae: 0.032873, mean_q: 0.044030
  9431/100000: episode: 1341, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003840, mae: 0.040545, mean_q: 0.045931
  9441/100000: episode: 1342, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002812, mae: 0.034754, mean_q: 0.044098
  9451/100000: episode: 1343, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.003276, mae: 0.035895, mean_q: 0.043384
  9461/100000: episode: 1344, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001596, mae: 0.026659, mean_q: 0.035498
  9471/100000: episode: 1345, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.004703, mae: 0.045347, mean_q: 0.044695
  9481/100000: episode: 1346, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003515, mae: 0.040416, mean_q: 0.041576
  9491/100000: episode: 1347, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002328, mae: 0.040522, mean_q: 0.036218
  9501/100000: episode: 1348, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.003619, mae: 0.043265, mean_q: 0.039792
  9511/100000: episode: 1349, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.004288, mae: 0.046086, mean_q: 0.046558
  9521/100000: episode: 1350, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.003103, mae: 0.043265, mean_q: 0.058057
  9531/100000: episode: 1351, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.004011, mae: 0.043653, mean_q: 0.047435
  9541/100000: episode: 1352, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.003709, mae: 0.043615, mean_q: 0.052567
  9551/100000: episode: 1353, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.003839, mae: 0.046362, mean_q: 0.047100
  9561/100000: episode: 1354, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.003225, mae: 0.033679, mean_q: 0.046070
  9571/100000: episode: 1355, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002605, mae: 0.032470, mean_q: 0.031938
  9581/100000: episode: 1356, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002205, mae: 0.033349, mean_q: 0.038054
  9591/100000: episode: 1357, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002096, mae: 0.030387, mean_q: 0.039761
  9601/100000: episode: 1358, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001307, mae: 0.029106, mean_q: 0.033985
  9611/100000: episode: 1359, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002223, mae: 0.033008, mean_q: 0.038533
  9621/100000: episode: 1360, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.003878, mae: 0.040534, mean_q: 0.052218
  9631/100000: episode: 1361, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.003025, mae: 0.036241, mean_q: 0.041100
  9641/100000: episode: 1362, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.003265, mae: 0.034512, mean_q: 0.036130
  9651/100000: episode: 1363, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002768, mae: 0.031788, mean_q: 0.044178
  9661/100000: episode: 1364, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.003336, mae: 0.036239, mean_q: 0.034623
  9671/100000: episode: 1365, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.003931, mae: 0.033123, mean_q: 0.042651
  9681/100000: episode: 1366, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.003660, mae: 0.038869, mean_q: 0.038075
  9691/100000: episode: 1367, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.002655, mae: 0.030942, mean_q: 0.037067
  9701/100000: episode: 1368, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001937, mae: 0.031772, mean_q: 0.042556
  9711/100000: episode: 1369, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002419, mae: 0.033917, mean_q: 0.037767
  9721/100000: episode: 1370, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.005057, mae: 0.043470, mean_q: 0.050075
  9731/100000: episode: 1371, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002073, mae: 0.037134, mean_q: 0.036399
  9741/100000: episode: 1372, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.003224, mae: 0.038094, mean_q: 0.042744
  9751/100000: episode: 1373, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.003174, mae: 0.039641, mean_q: 0.036047
  9761/100000: episode: 1374, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002771, mae: 0.029177, mean_q: 0.033027
  9771/100000: episode: 1375, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002753, mae: 0.031846, mean_q: 0.040461
  9781/100000: episode: 1376, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.004350, mae: 0.044498, mean_q: 0.057911
  9791/100000: episode: 1377, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.004041, mae: 0.043337, mean_q: 0.048368
  9801/100000: episode: 1378, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001658, mae: 0.032855, mean_q: 0.026653
  9811/100000: episode: 1379, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001618, mae: 0.027538, mean_q: 0.035867
  9821/100000: episode: 1380, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.004193, mae: 0.041606, mean_q: 0.050626
  9831/100000: episode: 1381, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001944, mae: 0.031633, mean_q: 0.037048
  9841/100000: episode: 1382, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001733, mae: 0.025951, mean_q: 0.038997
  9851/100000: episode: 1383, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001669, mae: 0.027537, mean_q: 0.033418
  9861/100000: episode: 1384, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.005562, mae: 0.046527, mean_q: 0.056729
  9871/100000: episode: 1385, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.003398, mae: 0.038600, mean_q: 0.034577
  9881/100000: episode: 1386, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001795, mae: 0.032580, mean_q: 0.019450
  9891/100000: episode: 1387, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003271, mae: 0.038150, mean_q: 0.046719
  9901/100000: episode: 1388, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.003958, mae: 0.043656, mean_q: 0.057475
  9911/100000: episode: 1389, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001976, mae: 0.028311, mean_q: 0.036982
  9921/100000: episode: 1390, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.005062, mae: 0.045273, mean_q: 0.051812
  9931/100000: episode: 1391, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.003353, mae: 0.037625, mean_q: 0.029620
  9941/100000: episode: 1392, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002863, mae: 0.042136, mean_q: 0.035863
  9951/100000: episode: 1393, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001466, mae: 0.032695, mean_q: 0.038752
  9961/100000: episode: 1394, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002356, mae: 0.029170, mean_q: 0.032543
  9971/100000: episode: 1395, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002834, mae: 0.038006, mean_q: 0.032583
  9981/100000: episode: 1396, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.003960, mae: 0.043733, mean_q: 0.056832
  9991/100000: episode: 1397, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002955, mae: 0.037248, mean_q: 0.042402
 10001/100000: episode: 1398, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002105, mae: 0.032273, mean_q: 0.031931
 10011/100000: episode: 1399, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002508, mae: 0.031046, mean_q: 0.041418
 10021/100000: episode: 1400, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002292, mae: 0.034626, mean_q: 0.032093
 10031/100000: episode: 1401, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002023, mae: 0.029035, mean_q: 0.028758
 10041/100000: episode: 1402, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003477, mae: 0.032448, mean_q: 0.047002
 10051/100000: episode: 1403, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002610, mae: 0.035430, mean_q: 0.033988
 10061/100000: episode: 1404, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002564, mae: 0.036108, mean_q: 0.029555
 10071/100000: episode: 1405, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.003341, mae: 0.040886, mean_q: 0.029538
 10081/100000: episode: 1406, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.003083, mae: 0.036025, mean_q: 0.031358
 10091/100000: episode: 1407, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.003527, mae: 0.034412, mean_q: 0.024501
 10101/100000: episode: 1408, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.003890, mae: 0.038475, mean_q: 0.052717
 10111/100000: episode: 1409, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001574, mae: 0.028404, mean_q: 0.029219
 10121/100000: episode: 1410, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.003738, mae: 0.040681, mean_q: 0.037699
 10131/100000: episode: 1411, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.003634, mae: 0.046334, mean_q: 0.040937
 10141/100000: episode: 1412, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001704, mae: 0.031138, mean_q: 0.026379
 10151/100000: episode: 1413, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002841, mae: 0.038094, mean_q: 0.040968
 10161/100000: episode: 1414, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002783, mae: 0.030586, mean_q: 0.038073
 10171/100000: episode: 1415, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002012, mae: 0.024336, mean_q: 0.034695
 10181/100000: episode: 1416, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002408, mae: 0.025835, mean_q: 0.029015
 10191/100000: episode: 1417, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.004059, mae: 0.043817, mean_q: 0.045882
 10201/100000: episode: 1418, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.003720, mae: 0.042497, mean_q: 0.035196
 10211/100000: episode: 1419, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002629, mae: 0.032426, mean_q: 0.043499
 10221/100000: episode: 1420, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001804, mae: 0.033783, mean_q: 0.027635
 10231/100000: episode: 1421, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002010, mae: 0.027769, mean_q: 0.022509
 10241/100000: episode: 1422, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.003579, mae: 0.031111, mean_q: 0.039226
 10251/100000: episode: 1423, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001994, mae: 0.031745, mean_q: 0.027141
 10261/100000: episode: 1424, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002769, mae: 0.040158, mean_q: 0.041066
 10271/100000: episode: 1425, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002226, mae: 0.030144, mean_q: 0.047553
[Info] 1-TH LEVEL FOUND: 0.06297530233860016, Considering 13/100 traces
 10281/100000: episode: 1426, duration: 0.701s, episode steps: 10, steps per second: 14, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001767, mae: 0.027006, mean_q: 0.026367
 10283/100000: episode: 1427, duration: 0.015s, episode steps: 2, steps per second: 138, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000831, mae: 0.023994, mean_q: 0.035718
 10285/100000: episode: 1428, duration: 0.014s, episode steps: 2, steps per second: 140, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003281, mae: 0.033164, mean_q: 0.033231
 10287/100000: episode: 1429, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002939, mae: 0.029812, mean_q: 0.032772
 10289/100000: episode: 1430, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000916, mae: 0.020547, mean_q: 0.029321
 10291/100000: episode: 1431, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002741, mae: 0.027131, mean_q: 0.033294
 10293/100000: episode: 1432, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000560, mae: 0.020381, mean_q: 0.022514
 10295/100000: episode: 1433, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000517, mae: 0.017608, mean_q: 0.016550
 10298/100000: episode: 1434, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003147, mae: 0.028637, mean_q: 0.032010
 10300/100000: episode: 1435, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001266, mae: 0.026886, mean_q: 0.036098
 10302/100000: episode: 1436, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001115, mae: 0.025521, mean_q: 0.029056
 10304/100000: episode: 1437, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001116, mae: 0.028349, mean_q: 0.019247
 10306/100000: episode: 1438, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000790, mae: 0.018951, mean_q: 0.018449
 10308/100000: episode: 1439, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001352, mae: 0.026623, mean_q: 0.036500
 10310/100000: episode: 1440, duration: 0.014s, episode steps: 2, steps per second: 140, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006346, mae: 0.032666, mean_q: 0.020662
 10313/100000: episode: 1441, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.004163, mae: 0.028072, mean_q: 0.024954
 10315/100000: episode: 1442, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002338, mae: 0.034546, mean_q: 0.051296
 10317/100000: episode: 1443, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001373, mae: 0.033303, mean_q: 0.006209
 10319/100000: episode: 1444, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000443, mae: 0.020091, mean_q: 0.014543
 10321/100000: episode: 1445, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004217, mae: 0.048730, mean_q: 0.070543
 10323/100000: episode: 1446, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003078, mae: 0.042918, mean_q: 0.071708
 10325/100000: episode: 1447, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001405, mae: 0.025934, mean_q: 0.014553
 10327/100000: episode: 1448, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000618, mae: 0.016734, mean_q: 0.025336
 10329/100000: episode: 1449, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000517, mae: 0.014287, mean_q: 0.016116
 10331/100000: episode: 1450, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001897, mae: 0.033399, mean_q: 0.015763
 10333/100000: episode: 1451, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001713, mae: 0.022170, mean_q: 0.017775
 10335/100000: episode: 1452, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001684, mae: 0.034590, mean_q: 0.050273
 10337/100000: episode: 1453, duration: 0.014s, episode steps: 2, steps per second: 142, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001800, mae: 0.035372, mean_q: 0.054456
 10339/100000: episode: 1454, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001142, mae: 0.030722, mean_q: 0.014624
 10341/100000: episode: 1455, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000626, mae: 0.025151, mean_q: -0.011583
 10343/100000: episode: 1456, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000484, mae: 0.020184, mean_q: 0.018935
 10346/100000: episode: 1457, duration: 0.017s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001391, mae: 0.034024, mean_q: 0.051731
 10348/100000: episode: 1458, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003851, mae: 0.040423, mean_q: 0.017230
 10350/100000: episode: 1459, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005773, mae: 0.032434, mean_q: 0.037990
 10353/100000: episode: 1460, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002052, mae: 0.036650, mean_q: 0.051649
 10355/100000: episode: 1461, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000807, mae: 0.024780, mean_q: 0.003427
 10357/100000: episode: 1462, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003757, mae: 0.043666, mean_q: 0.028384
 10359/100000: episode: 1463, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000822, mae: 0.024051, mean_q: 0.034235
 10361/100000: episode: 1464, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000544, mae: 0.022890, mean_q: 0.025476
 10363/100000: episode: 1465, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000814, mae: 0.024363, mean_q: 0.007930
 10366/100000: episode: 1466, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004990, mae: 0.035890, mean_q: 0.031047
 10368/100000: episode: 1467, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001915, mae: 0.041590, mean_q: 0.052177
 10371/100000: episode: 1468, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.004999, mae: 0.039003, mean_q: 0.029591
 10373/100000: episode: 1469, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001196, mae: 0.030394, mean_q: 0.004926
 10375/100000: episode: 1470, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002425, mae: 0.034322, mean_q: 0.045543
 10378/100000: episode: 1471, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001852, mae: 0.026597, mean_q: 0.011277
 10380/100000: episode: 1472, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003977, mae: 0.043215, mean_q: 0.047171
 10382/100000: episode: 1473, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001544, mae: 0.038575, mean_q: 0.054188
 10384/100000: episode: 1474, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001071, mae: 0.024161, mean_q: 0.030383
 10386/100000: episode: 1475, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001202, mae: 0.030227, mean_q: 0.004604
 10388/100000: episode: 1476, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000372, mae: 0.012877, mean_q: 0.019765
 10390/100000: episode: 1477, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006013, mae: 0.049196, mean_q: 0.068205
 10393/100000: episode: 1478, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001677, mae: 0.023556, mean_q: 0.020158
 10395/100000: episode: 1479, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001866, mae: 0.032675, mean_q: 0.049696
 10397/100000: episode: 1480, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001429, mae: 0.021103, mean_q: 0.028638
 10400/100000: episode: 1481, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004624, mae: 0.033192, mean_q: 0.034019
 10403/100000: episode: 1482, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001928, mae: 0.023583, mean_q: 0.032021
 10405/100000: episode: 1483, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003746, mae: 0.042610, mean_q: 0.056657
 10407/100000: episode: 1484, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004378, mae: 0.032782, mean_q: 0.037328
 10409/100000: episode: 1485, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001479, mae: 0.023196, mean_q: 0.029315
 10411/100000: episode: 1486, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005857, mae: 0.040288, mean_q: 0.045482
 10413/100000: episode: 1487, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001715, mae: 0.023466, mean_q: 0.032253
 10415/100000: episode: 1488, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001378, mae: 0.026038, mean_q: 0.030241
 10417/100000: episode: 1489, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000898, mae: 0.030322, mean_q: 0.001192
 10419/100000: episode: 1490, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001680, mae: 0.028408, mean_q: 0.031563
 10421/100000: episode: 1491, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001595, mae: 0.032942, mean_q: 0.051021
 10423/100000: episode: 1492, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006126, mae: 0.041664, mean_q: 0.027954
 10425/100000: episode: 1493, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000466, mae: 0.019687, mean_q: 0.017410
 10428/100000: episode: 1494, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000974, mae: 0.020830, mean_q: 0.027147
 10430/100000: episode: 1495, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000796, mae: 0.018150, mean_q: 0.017538
 10432/100000: episode: 1496, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003194, mae: 0.027762, mean_q: 0.025109
 10434/100000: episode: 1497, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001435, mae: 0.033224, mean_q: 0.052248
 10437/100000: episode: 1498, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002550, mae: 0.028784, mean_q: 0.025413
 10439/100000: episode: 1499, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000570, mae: 0.019584, mean_q: 0.016780
 10441/100000: episode: 1500, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000803, mae: 0.018315, mean_q: 0.025303
 10443/100000: episode: 1501, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001138, mae: 0.018885, mean_q: 0.019309
 10445/100000: episode: 1502, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002096, mae: 0.016710, mean_q: 0.023977
 10447/100000: episode: 1503, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002256, mae: 0.029349, mean_q: 0.033949
 10449/100000: episode: 1504, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000968, mae: 0.019050, mean_q: 0.022556
 10451/100000: episode: 1505, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002582, mae: 0.029477, mean_q: 0.010572
 10453/100000: episode: 1506, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002096, mae: 0.030699, mean_q: 0.026135
 10455/100000: episode: 1507, duration: 0.015s, episode steps: 2, steps per second: 138, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002688, mae: 0.032069, mean_q: 0.037232
 10457/100000: episode: 1508, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001749, mae: 0.032643, mean_q: 0.044089
 10459/100000: episode: 1509, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001030, mae: 0.022531, mean_q: 0.020198
 10461/100000: episode: 1510, duration: 0.014s, episode steps: 2, steps per second: 143, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000318, mae: 0.015144, mean_q: -0.002295
 10463/100000: episode: 1511, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001913, mae: 0.030958, mean_q: 0.050127
 10465/100000: episode: 1512, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006025, mae: 0.042137, mean_q: 0.043589
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.06297530233860016
 10467/100000: episode: 1513, duration: 0.490s, episode steps: 2, steps per second: 4, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001389, mae: 0.020611, mean_q: 0.031288
 10477/100000: episode: 1514, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000955, mae: 0.023301, mean_q: 0.020009
 10487/100000: episode: 1515, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001698, mae: 0.024378, mean_q: 0.027530
 10497/100000: episode: 1516, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002040, mae: 0.018785, mean_q: 0.016802
 10507/100000: episode: 1517, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001960, mae: 0.021156, mean_q: 0.024173
 10517/100000: episode: 1518, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001976, mae: 0.026878, mean_q: 0.026308
 10527/100000: episode: 1519, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001196, mae: 0.021887, mean_q: 0.021398
 10537/100000: episode: 1520, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002984, mae: 0.032204, mean_q: 0.036633
 10547/100000: episode: 1521, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001021, mae: 0.024652, mean_q: 0.015449
 10557/100000: episode: 1522, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000926, mae: 0.019469, mean_q: 0.015756
 10567/100000: episode: 1523, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001728, mae: 0.023491, mean_q: 0.031949
 10577/100000: episode: 1524, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000946, mae: 0.016441, mean_q: 0.018972
 10587/100000: episode: 1525, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000441, mae: 0.013780, mean_q: 0.012785
 10597/100000: episode: 1526, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001658, mae: 0.022829, mean_q: 0.031548
 10607/100000: episode: 1527, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001106, mae: 0.019497, mean_q: 0.018943
 10617/100000: episode: 1528, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000691, mae: 0.018948, mean_q: 0.017347
 10627/100000: episode: 1529, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000268, mae: 0.011121, mean_q: 0.009736
 10637/100000: episode: 1530, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000476, mae: 0.013673, mean_q: 0.012839
 10647/100000: episode: 1531, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000386, mae: 0.012774, mean_q: 0.012262
 10657/100000: episode: 1532, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000612, mae: 0.012342, mean_q: 0.014611
 10667/100000: episode: 1533, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000381, mae: 0.013273, mean_q: 0.011313
 10677/100000: episode: 1534, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001431, mae: 0.018887, mean_q: 0.013512
 10687/100000: episode: 1535, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000212, mae: 0.010652, mean_q: 0.012139
 10697/100000: episode: 1536, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000284, mae: 0.010574, mean_q: 0.009623
 10707/100000: episode: 1537, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000434, mae: 0.012763, mean_q: 0.011557
 10717/100000: episode: 1538, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000256, mae: 0.010827, mean_q: 0.009840
 10727/100000: episode: 1539, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000191, mae: 0.009462, mean_q: 0.008500
 10737/100000: episode: 1540, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000318, mae: 0.012774, mean_q: 0.012353
 10747/100000: episode: 1541, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000465, mae: 0.012425, mean_q: 0.012183
 10757/100000: episode: 1542, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000418, mae: 0.013476, mean_q: 0.011404
 10767/100000: episode: 1543, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000469, mae: 0.013759, mean_q: 0.014561
 10777/100000: episode: 1544, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000416, mae: 0.012810, mean_q: 0.014196
 10787/100000: episode: 1545, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000331, mae: 0.013011, mean_q: 0.010308
 10797/100000: episode: 1546, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000916, mae: 0.015732, mean_q: 0.014945
 10807/100000: episode: 1547, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000303, mae: 0.011751, mean_q: 0.011384
 10817/100000: episode: 1548, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000225, mae: 0.011308, mean_q: 0.008765
 10827/100000: episode: 1549, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000264, mae: 0.010252, mean_q: 0.011176
 10837/100000: episode: 1550, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001578, mae: 0.017775, mean_q: 0.016040
 10847/100000: episode: 1551, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000355, mae: 0.015387, mean_q: 0.008488
 10857/100000: episode: 1552, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000292, mae: 0.013084, mean_q: 0.010683
 10867/100000: episode: 1553, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000385, mae: 0.013219, mean_q: 0.013001
 10877/100000: episode: 1554, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001461, mae: 0.014217, mean_q: 0.011875
 10887/100000: episode: 1555, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000282, mae: 0.014630, mean_q: 0.004786
 10897/100000: episode: 1556, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000379, mae: 0.014350, mean_q: 0.013166
 10907/100000: episode: 1557, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000322, mae: 0.011998, mean_q: 0.008324
 10917/100000: episode: 1558, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001605, mae: 0.018572, mean_q: 0.017970
 10927/100000: episode: 1559, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000302, mae: 0.014716, mean_q: 0.006527
 10937/100000: episode: 1560, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000234, mae: 0.010047, mean_q: 0.009413
 10947/100000: episode: 1561, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000270, mae: 0.009187, mean_q: 0.011366
 10957/100000: episode: 1562, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000656, mae: 0.013093, mean_q: 0.012115
 10967/100000: episode: 1563, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000242, mae: 0.013651, mean_q: 0.006783
 10977/100000: episode: 1564, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000250, mae: 0.010461, mean_q: 0.009175
 10987/100000: episode: 1565, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000412, mae: 0.011935, mean_q: 0.013434
 10997/100000: episode: 1566, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000130, mae: 0.008038, mean_q: 0.008073
 11007/100000: episode: 1567, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000338, mae: 0.012441, mean_q: 0.012067
 11017/100000: episode: 1568, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000355, mae: 0.011196, mean_q: 0.012370
 11027/100000: episode: 1569, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000228, mae: 0.010408, mean_q: 0.009791
 11037/100000: episode: 1570, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000292, mae: 0.010420, mean_q: 0.013562
 11047/100000: episode: 1571, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002591, mae: 0.020070, mean_q: 0.012346
 11057/100000: episode: 1572, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000786, mae: 0.016364, mean_q: 0.014318
 11067/100000: episode: 1573, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000229, mae: 0.010015, mean_q: 0.007073
 11077/100000: episode: 1574, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000292, mae: 0.013134, mean_q: 0.010119
 11087/100000: episode: 1575, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001559, mae: 0.017726, mean_q: 0.012701
 11097/100000: episode: 1576, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001450, mae: 0.017052, mean_q: 0.016995
 11107/100000: episode: 1577, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000420, mae: 0.013471, mean_q: 0.010487
 11117/100000: episode: 1578, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000325, mae: 0.012480, mean_q: 0.012284
 11127/100000: episode: 1579, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000386, mae: 0.013002, mean_q: 0.013736
 11137/100000: episode: 1580, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000306, mae: 0.012636, mean_q: 0.010369
 11147/100000: episode: 1581, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000262, mae: 0.011942, mean_q: 0.010051
 11157/100000: episode: 1582, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000244, mae: 0.011835, mean_q: 0.009186
 11167/100000: episode: 1583, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000313, mae: 0.009645, mean_q: 0.009033
 11177/100000: episode: 1584, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000254, mae: 0.011000, mean_q: 0.012596
 11187/100000: episode: 1585, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000535, mae: 0.014721, mean_q: 0.014894
 11197/100000: episode: 1586, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000256, mae: 0.011226, mean_q: 0.009285
 11207/100000: episode: 1587, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000804, mae: 0.014660, mean_q: 0.014384
 11217/100000: episode: 1588, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000296, mae: 0.015853, mean_q: 0.011268
 11227/100000: episode: 1589, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000217, mae: 0.011656, mean_q: 0.005822
 11237/100000: episode: 1590, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000124, mae: 0.008422, mean_q: 0.009773
 11247/100000: episode: 1591, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001556, mae: 0.014952, mean_q: 0.011209
 11257/100000: episode: 1592, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000306, mae: 0.016546, mean_q: 0.009144
 11267/100000: episode: 1593, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000182, mae: 0.010733, mean_q: 0.006198
 11277/100000: episode: 1594, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001442, mae: 0.017072, mean_q: 0.011455
 11287/100000: episode: 1595, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000243, mae: 0.010657, mean_q: 0.008507
 11297/100000: episode: 1596, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000331, mae: 0.012590, mean_q: 0.010256
 11307/100000: episode: 1597, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000280, mae: 0.011660, mean_q: 0.013087
 11317/100000: episode: 1598, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000240, mae: 0.012422, mean_q: 0.009763
 11327/100000: episode: 1599, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000300, mae: 0.012480, mean_q: 0.009665
 11337/100000: episode: 1600, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000301, mae: 0.011952, mean_q: 0.010949
 11347/100000: episode: 1601, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000333, mae: 0.015459, mean_q: 0.009924
 11357/100000: episode: 1602, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001570, mae: 0.018649, mean_q: 0.014035
 11367/100000: episode: 1603, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000470, mae: 0.020448, mean_q: 0.013093
 11377/100000: episode: 1604, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000246, mae: 0.013704, mean_q: 0.005498
 11387/100000: episode: 1605, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000292, mae: 0.012186, mean_q: 0.011166
 11397/100000: episode: 1606, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000367, mae: 0.014759, mean_q: 0.011908
 11407/100000: episode: 1607, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000255, mae: 0.010994, mean_q: 0.010144
 11417/100000: episode: 1608, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000351, mae: 0.011818, mean_q: 0.011389
 11427/100000: episode: 1609, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000389, mae: 0.012161, mean_q: 0.013884
 11437/100000: episode: 1610, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000827, mae: 0.015150, mean_q: 0.014353
 11447/100000: episode: 1611, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000361, mae: 0.014648, mean_q: 0.009672
 11457/100000: episode: 1612, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000320, mae: 0.012451, mean_q: 0.008773
[Info] 1-TH LEVEL FOUND: 0.04308784008026123, Considering 10/100 traces
 11467/100000: episode: 1613, duration: 0.727s, episode steps: 10, steps per second: 14, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000293, mae: 0.011840, mean_q: 0.011804
 11473/100000: episode: 1614, duration: 0.033s, episode steps: 6, steps per second: 181, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001860, mae: 0.018314, mean_q: 0.021897
 11479/100000: episode: 1615, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000429, mae: 0.015821, mean_q: 0.011312
[Info] FALSIFICATION!
 11484/100000: episode: 1616, duration: 0.267s, episode steps: 5, steps per second: 19, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000482, mae: 0.014095, mean_q: 0.016215
 11490/100000: episode: 1617, duration: 0.034s, episode steps: 6, steps per second: 174, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000494, mae: 0.015570, mean_q: 0.020910
 11493/100000: episode: 1618, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000305, mae: 0.018395, mean_q: -0.002611
 11499/100000: episode: 1619, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000328, mae: 0.012488, mean_q: 0.012191
 11502/100000: episode: 1620, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000233, mae: 0.011895, mean_q: 0.009473
 11508/100000: episode: 1621, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001194, mae: 0.015639, mean_q: 0.019304
 11514/100000: episode: 1622, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000392, mae: 0.016983, mean_q: 0.005711
 11520/100000: episode: 1623, duration: 0.031s, episode steps: 6, steps per second: 193, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000284, mae: 0.014675, mean_q: 0.015192
 11526/100000: episode: 1624, duration: 0.031s, episode steps: 6, steps per second: 191, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000620, mae: 0.020018, mean_q: 0.015741
 11529/100000: episode: 1625, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000456, mae: 0.016719, mean_q: 0.014409
 11532/100000: episode: 1626, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000212, mae: 0.011417, mean_q: 0.009519
 11535/100000: episode: 1627, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000273, mae: 0.012208, mean_q: 0.013267
 11541/100000: episode: 1628, duration: 0.031s, episode steps: 6, steps per second: 193, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000222, mae: 0.010351, mean_q: 0.009471
 11547/100000: episode: 1629, duration: 0.035s, episode steps: 6, steps per second: 171, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001089, mae: 0.014324, mean_q: 0.015371
 11553/100000: episode: 1630, duration: 0.031s, episode steps: 6, steps per second: 191, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000452, mae: 0.015135, mean_q: 0.011615
 11556/100000: episode: 1631, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000221, mae: 0.011955, mean_q: 0.019950
 11559/100000: episode: 1632, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000622, mae: 0.016211, mean_q: 0.008835
 11565/100000: episode: 1633, duration: 0.033s, episode steps: 6, steps per second: 179, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000371, mae: 0.015180, mean_q: 0.015425
 11568/100000: episode: 1634, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000492, mae: 0.016578, mean_q: 0.010535
 11574/100000: episode: 1635, duration: 0.031s, episode steps: 6, steps per second: 192, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000485, mae: 0.018203, mean_q: 0.011309
 11577/100000: episode: 1636, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000830, mae: 0.019146, mean_q: 0.026556
 11583/100000: episode: 1637, duration: 0.032s, episode steps: 6, steps per second: 190, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000500, mae: 0.014713, mean_q: 0.006318
 11589/100000: episode: 1638, duration: 0.032s, episode steps: 6, steps per second: 190, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000612, mae: 0.020283, mean_q: 0.015365
 11595/100000: episode: 1639, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000284, mae: 0.014781, mean_q: 0.017016
 11598/100000: episode: 1640, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000572, mae: 0.017723, mean_q: 0.005454
 11604/100000: episode: 1641, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000266, mae: 0.014032, mean_q: 0.010537
 11610/100000: episode: 1642, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.001148, mae: 0.015252, mean_q: 0.014497
 11616/100000: episode: 1643, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000192, mae: 0.010079, mean_q: 0.010001
 11619/100000: episode: 1644, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000360, mae: 0.013735, mean_q: 0.013797
 11625/100000: episode: 1645, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000233, mae: 0.010847, mean_q: 0.004740
 11631/100000: episode: 1646, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000489, mae: 0.018725, mean_q: 0.020630
 11637/100000: episode: 1647, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002690, mae: 0.026764, mean_q: 0.029991
 11643/100000: episode: 1648, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000474, mae: 0.017269, mean_q: 0.013725
 11649/100000: episode: 1649, duration: 0.031s, episode steps: 6, steps per second: 197, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000286, mae: 0.013984, mean_q: 0.004892
 11652/100000: episode: 1650, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000165, mae: 0.011912, mean_q: 0.015517
 11655/100000: episode: 1651, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000253, mae: 0.012811, mean_q: 0.006524
 11661/100000: episode: 1652, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000308, mae: 0.011981, mean_q: 0.015727
 11667/100000: episode: 1653, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.002008, mae: 0.014229, mean_q: 0.007330
 11670/100000: episode: 1654, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000191, mae: 0.013481, mean_q: 0.017283
 11676/100000: episode: 1655, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000433, mae: 0.016523, mean_q: 0.010308
 11682/100000: episode: 1656, duration: 0.031s, episode steps: 6, steps per second: 192, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000713, mae: 0.017870, mean_q: 0.012150
 11688/100000: episode: 1657, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002211, mae: 0.026888, mean_q: 0.027399
 11694/100000: episode: 1658, duration: 0.032s, episode steps: 6, steps per second: 187, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002235, mae: 0.027988, mean_q: 0.018683
 11697/100000: episode: 1659, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000661, mae: 0.018834, mean_q: 0.015023
 11703/100000: episode: 1660, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000499, mae: 0.019178, mean_q: 0.012534
 11709/100000: episode: 1661, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000503, mae: 0.017734, mean_q: 0.007210
 11715/100000: episode: 1662, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000656, mae: 0.018271, mean_q: 0.015658
 11721/100000: episode: 1663, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000648, mae: 0.021333, mean_q: 0.016481
 11724/100000: episode: 1664, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000519, mae: 0.014521, mean_q: 0.017547
 11727/100000: episode: 1665, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000329, mae: 0.014968, mean_q: 0.017841
 11733/100000: episode: 1666, duration: 0.031s, episode steps: 6, steps per second: 191, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002022, mae: 0.020025, mean_q: 0.017324
 11736/100000: episode: 1667, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000595, mae: 0.021323, mean_q: 0.022307
 11739/100000: episode: 1668, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000443, mae: 0.015952, mean_q: 0.015690
 11745/100000: episode: 1669, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000679, mae: 0.019719, mean_q: 0.007704
 11748/100000: episode: 1670, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000386, mae: 0.015959, mean_q: 0.015003
 11754/100000: episode: 1671, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000449, mae: 0.015250, mean_q: 0.005431
 11757/100000: episode: 1672, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000355, mae: 0.018046, mean_q: 0.021915
 11763/100000: episode: 1673, duration: 0.033s, episode steps: 6, steps per second: 183, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000336, mae: 0.014808, mean_q: 0.006494
 11766/100000: episode: 1674, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000828, mae: 0.033597, mean_q: 0.045237
 11769/100000: episode: 1675, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000558, mae: 0.025861, mean_q: -0.012930
 11775/100000: episode: 1676, duration: 0.033s, episode steps: 6, steps per second: 180, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000383, mae: 0.019899, mean_q: 0.021815
 11781/100000: episode: 1677, duration: 0.031s, episode steps: 6, steps per second: 193, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000466, mae: 0.019032, mean_q: 0.014393
 11787/100000: episode: 1678, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000511, mae: 0.018363, mean_q: 0.002043
 11793/100000: episode: 1679, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000633, mae: 0.020191, mean_q: 0.021319
 11796/100000: episode: 1680, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000705, mae: 0.018572, mean_q: 0.014236
 11802/100000: episode: 1681, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000768, mae: 0.021490, mean_q: 0.021198
 11808/100000: episode: 1682, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002376, mae: 0.025831, mean_q: 0.031291
 11811/100000: episode: 1683, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000559, mae: 0.024689, mean_q: -0.010022
 11817/100000: episode: 1684, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000380, mae: 0.016474, mean_q: 0.022601
 11820/100000: episode: 1685, duration: 0.019s, episode steps: 3, steps per second: 162, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000510, mae: 0.014796, mean_q: 0.011362
 11823/100000: episode: 1686, duration: 0.019s, episode steps: 3, steps per second: 155, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000344, mae: 0.016705, mean_q: 0.019585
 11829/100000: episode: 1687, duration: 0.032s, episode steps: 6, steps per second: 185, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000753, mae: 0.018965, mean_q: 0.025438
 11832/100000: episode: 1688, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000356, mae: 0.018213, mean_q: 0.001541
 11838/100000: episode: 1689, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000276, mae: 0.014345, mean_q: 0.015721
 11844/100000: episode: 1690, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000645, mae: 0.018820, mean_q: 0.012286
 11850/100000: episode: 1691, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001174, mae: 0.018760, mean_q: 0.014080
 11853/100000: episode: 1692, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000360, mae: 0.017369, mean_q: 0.022266
 11859/100000: episode: 1693, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000305, mae: 0.015408, mean_q: 0.009200
 11865/100000: episode: 1694, duration: 0.032s, episode steps: 6, steps per second: 190, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000420, mae: 0.017223, mean_q: 0.011877
 11871/100000: episode: 1695, duration: 0.034s, episode steps: 6, steps per second: 175, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002278, mae: 0.022880, mean_q: 0.022905
 11874/100000: episode: 1696, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000291, mae: 0.015612, mean_q: 0.014339
 11880/100000: episode: 1697, duration: 0.034s, episode steps: 6, steps per second: 178, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000448, mae: 0.017011, mean_q: 0.017519
 11883/100000: episode: 1698, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003865, mae: 0.021364, mean_q: 0.011304
 11886/100000: episode: 1699, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000554, mae: 0.022660, mean_q: 0.029477
 11892/100000: episode: 1700, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000552, mae: 0.020130, mean_q: 0.005494
 11898/100000: episode: 1701, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000463, mae: 0.015165, mean_q: 0.014206
 11904/100000: episode: 1702, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.002010, mae: 0.018464, mean_q: 0.020274
[Info] Complete ISplit Iteration
[Info] Levels: [0.04308784, 0.6266349]
[Info] Cond. Prob: [0.1, 0.01]
[Info] Error Prob: 0.001

 11910/100000: episode: 1703, duration: 0.745s, episode steps: 6, steps per second: 8, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002292, mae: 0.026059, mean_q: 0.016606
 11920/100000: episode: 1704, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000571, mae: 0.017543, mean_q: 0.015489
 11930/100000: episode: 1705, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000571, mae: 0.018534, mean_q: 0.015639
 11940/100000: episode: 1706, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000496, mae: 0.017728, mean_q: 0.016381
 11950/100000: episode: 1707, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001708, mae: 0.021266, mean_q: 0.017408
 11960/100000: episode: 1708, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000536, mae: 0.015167, mean_q: 0.016807
 11970/100000: episode: 1709, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000397, mae: 0.012693, mean_q: 0.014179
 11980/100000: episode: 1710, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000411, mae: 0.011476, mean_q: 0.012226
 11990/100000: episode: 1711, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000587, mae: 0.015315, mean_q: 0.018431
 12000/100000: episode: 1712, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001574, mae: 0.018966, mean_q: 0.023344
 12010/100000: episode: 1713, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001509, mae: 0.018220, mean_q: 0.018605
 12020/100000: episode: 1714, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000508, mae: 0.016082, mean_q: 0.015544
 12030/100000: episode: 1715, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.002430, mae: 0.024404, mean_q: 0.026881
 12040/100000: episode: 1716, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000886, mae: 0.017204, mean_q: 0.017787
 12050/100000: episode: 1717, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000577, mae: 0.016395, mean_q: 0.016175
 12060/100000: episode: 1718, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000583, mae: 0.016499, mean_q: 0.021504
 12070/100000: episode: 1719, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001888, mae: 0.026975, mean_q: 0.021737
 12080/100000: episode: 1720, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000706, mae: 0.022428, mean_q: 0.017317
 12090/100000: episode: 1721, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.004652, mae: 0.040845, mean_q: 0.032778
 12100/100000: episode: 1722, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000878, mae: 0.023364, mean_q: 0.016337
 12110/100000: episode: 1723, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001560, mae: 0.021745, mean_q: 0.018822
 12120/100000: episode: 1724, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000537, mae: 0.021262, mean_q: 0.019759
 12130/100000: episode: 1725, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000557, mae: 0.014566, mean_q: 0.013866
 12140/100000: episode: 1726, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000599, mae: 0.019847, mean_q: 0.016380
 12150/100000: episode: 1727, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001700, mae: 0.024734, mean_q: 0.024513
 12160/100000: episode: 1728, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000691, mae: 0.024198, mean_q: 0.013941
 12170/100000: episode: 1729, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000633, mae: 0.019564, mean_q: 0.013240
 12180/100000: episode: 1730, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001577, mae: 0.023021, mean_q: 0.022528
 12190/100000: episode: 1731, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000379, mae: 0.014186, mean_q: 0.010322
 12200/100000: episode: 1732, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000644, mae: 0.014662, mean_q: 0.015451
 12210/100000: episode: 1733, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001715, mae: 0.020944, mean_q: 0.019349
 12220/100000: episode: 1734, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000405, mae: 0.015690, mean_q: 0.013733
 12230/100000: episode: 1735, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000371, mae: 0.014282, mean_q: 0.015390
 12240/100000: episode: 1736, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001482, mae: 0.020256, mean_q: 0.021344
 12250/100000: episode: 1737, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000364, mae: 0.012702, mean_q: 0.014434
 12260/100000: episode: 1738, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000442, mae: 0.015055, mean_q: 0.010502
 12270/100000: episode: 1739, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000656, mae: 0.018800, mean_q: 0.017062
 12280/100000: episode: 1740, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001277, mae: 0.017157, mean_q: 0.011079
 12290/100000: episode: 1741, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001430, mae: 0.020618, mean_q: 0.019457
 12300/100000: episode: 1742, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000526, mae: 0.016883, mean_q: 0.012855
 12310/100000: episode: 1743, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000325, mae: 0.013435, mean_q: 0.006554
 12320/100000: episode: 1744, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000364, mae: 0.012477, mean_q: 0.014632
 12330/100000: episode: 1745, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001460, mae: 0.021821, mean_q: 0.012574
 12340/100000: episode: 1746, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000324, mae: 0.015905, mean_q: 0.012386
 12350/100000: episode: 1747, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000271, mae: 0.010770, mean_q: 0.010675
 12360/100000: episode: 1748, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000226, mae: 0.011028, mean_q: 0.012692
 12370/100000: episode: 1749, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000437, mae: 0.012510, mean_q: 0.012009
 12380/100000: episode: 1750, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000323, mae: 0.012258, mean_q: 0.011925
 12390/100000: episode: 1751, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001200, mae: 0.013178, mean_q: 0.014132
 12400/100000: episode: 1752, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000354, mae: 0.014075, mean_q: 0.009452
 12410/100000: episode: 1753, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000353, mae: 0.013229, mean_q: 0.012970
 12420/100000: episode: 1754, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000211, mae: 0.009520, mean_q: 0.011655
 12430/100000: episode: 1755, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000368, mae: 0.013026, mean_q: 0.013304
 12440/100000: episode: 1756, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001306, mae: 0.017003, mean_q: 0.014485
 12450/100000: episode: 1757, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000262, mae: 0.010229, mean_q: 0.008243
 12460/100000: episode: 1758, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000204, mae: 0.010845, mean_q: 0.014576
 12470/100000: episode: 1759, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000347, mae: 0.013918, mean_q: 0.012601
 12480/100000: episode: 1760, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000220, mae: 0.012793, mean_q: 0.012668
 12490/100000: episode: 1761, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000305, mae: 0.012197, mean_q: 0.010944
 12500/100000: episode: 1762, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000151, mae: 0.010999, mean_q: 0.008469
 12510/100000: episode: 1763, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000185, mae: 0.010463, mean_q: 0.009026
 12520/100000: episode: 1764, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000244, mae: 0.010143, mean_q: 0.011016
 12530/100000: episode: 1765, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000129, mae: 0.007900, mean_q: 0.009290
 12540/100000: episode: 1766, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000255, mae: 0.011502, mean_q: 0.012211
 12550/100000: episode: 1767, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002410, mae: 0.020637, mean_q: 0.013739
 12560/100000: episode: 1768, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000431, mae: 0.018880, mean_q: 0.009549
 12570/100000: episode: 1769, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000762, mae: 0.015698, mean_q: 0.016864
 12580/100000: episode: 1770, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000390, mae: 0.016093, mean_q: 0.011120
 12590/100000: episode: 1771, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000374, mae: 0.014877, mean_q: 0.015041
 12600/100000: episode: 1772, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000204, mae: 0.009733, mean_q: 0.012980
 12610/100000: episode: 1773, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000413, mae: 0.014537, mean_q: 0.014721
 12620/100000: episode: 1774, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001371, mae: 0.019342, mean_q: 0.014982
 12630/100000: episode: 1775, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000368, mae: 0.013898, mean_q: 0.009939
 12640/100000: episode: 1776, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000220, mae: 0.011752, mean_q: 0.008460
 12650/100000: episode: 1777, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000158, mae: 0.011277, mean_q: 0.009142
 12660/100000: episode: 1778, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000408, mae: 0.013518, mean_q: 0.014440
 12670/100000: episode: 1779, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000279, mae: 0.011574, mean_q: 0.011824
 12680/100000: episode: 1780, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000283, mae: 0.011229, mean_q: 0.010562
 12690/100000: episode: 1781, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000234, mae: 0.011114, mean_q: 0.012587
 12700/100000: episode: 1782, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000377, mae: 0.011432, mean_q: 0.015152
 12710/100000: episode: 1783, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000273, mae: 0.013271, mean_q: 0.008707
 12720/100000: episode: 1784, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000199, mae: 0.010289, mean_q: 0.009650
 12730/100000: episode: 1785, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000240, mae: 0.011293, mean_q: 0.012313
 12740/100000: episode: 1786, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000465, mae: 0.012680, mean_q: 0.015135
 12750/100000: episode: 1787, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000282, mae: 0.011527, mean_q: 0.012722
 12760/100000: episode: 1788, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000249, mae: 0.011888, mean_q: 0.007122
 12770/100000: episode: 1789, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000264, mae: 0.010233, mean_q: 0.011075
 12780/100000: episode: 1790, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000220, mae: 0.011068, mean_q: 0.014337
 12790/100000: episode: 1791, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001262, mae: 0.011938, mean_q: 0.013318
 12800/100000: episode: 1792, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000277, mae: 0.013805, mean_q: 0.014909
 12810/100000: episode: 1793, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000275, mae: 0.012046, mean_q: 0.013300
 12820/100000: episode: 1794, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001324, mae: 0.016588, mean_q: 0.014631
 12830/100000: episode: 1795, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001352, mae: 0.015380, mean_q: 0.014776
 12840/100000: episode: 1796, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000349, mae: 0.013268, mean_q: 0.010729
 12850/100000: episode: 1797, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001345, mae: 0.015923, mean_q: 0.015870
 12860/100000: episode: 1798, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000391, mae: 0.013293, mean_q: 0.014782
 12870/100000: episode: 1799, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000224, mae: 0.012843, mean_q: 0.010108
 12880/100000: episode: 1800, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000620, mae: 0.019262, mean_q: 0.013966
 12890/100000: episode: 1801, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000414, mae: 0.016636, mean_q: 0.012073
 12900/100000: episode: 1802, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000209, mae: 0.011626, mean_q: 0.013702
[Info] 1-TH LEVEL FOUND: 0.01395733654499054, Considering 16/100 traces
 12910/100000: episode: 1803, duration: 0.740s, episode steps: 10, steps per second: 14, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000306, mae: 0.011603, mean_q: 0.014657
 12918/100000: episode: 1804, duration: 0.042s, episode steps: 8, steps per second: 190, episode reward: 0.128, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000139, mae: 0.012008, mean_q: 0.005622
 12926/100000: episode: 1805, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.055, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000329, mae: 0.010944, mean_q: 0.013397
 12934/100000: episode: 1806, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.033, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000399, mae: 0.014103, mean_q: 0.011720
 12942/100000: episode: 1807, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000348, mae: 0.012678, mean_q: 0.014795
 12950/100000: episode: 1808, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.015, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000561, mae: 0.013132, mean_q: 0.017880
 12958/100000: episode: 1809, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.001499, mae: 0.019020, mean_q: 0.014265
 12962/100000: episode: 1810, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000301, mae: 0.017175, mean_q: 0.004587
 12970/100000: episode: 1811, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.036, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.001577, mae: 0.017886, mean_q: 0.013969
 12978/100000: episode: 1812, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.812 [-1.000, 11.000], loss: 0.000460, mae: 0.018672, mean_q: 0.013614
 12986/100000: episode: 1813, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.128, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000705, mae: 0.023326, mean_q: 0.012851
 12990/100000: episode: 1814, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000383, mae: 0.019122, mean_q: 0.025589
 12998/100000: episode: 1815, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.114, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000822, mae: 0.016688, mean_q: 0.010230
 13006/100000: episode: 1816, duration: 0.041s, episode steps: 8, steps per second: 197, episode reward: 0.013, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000375, mae: 0.011607, mean_q: 0.015316
 13014/100000: episode: 1817, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.134, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000312, mae: 0.014425, mean_q: 0.016068
 13022/100000: episode: 1818, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.028, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001474, mae: 0.017531, mean_q: 0.021648
 13030/100000: episode: 1819, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.054, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000448, mae: 0.018585, mean_q: 0.008384
 13038/100000: episode: 1820, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.082, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000351, mae: 0.012555, mean_q: 0.008039
 13046/100000: episode: 1821, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.231, mean reward: 0.029 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.000331, mae: 0.013890, mean_q: 0.010890
 13054/100000: episode: 1822, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.348, mean reward: 0.044 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000421, mae: 0.015521, mean_q: 0.011113
 13062/100000: episode: 1823, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000327, mae: 0.011732, mean_q: 0.012180
 13070/100000: episode: 1824, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.032, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000574, mae: 0.011773, mean_q: 0.011372
 13078/100000: episode: 1825, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.022, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000377, mae: 0.016105, mean_q: 0.015211
 13086/100000: episode: 1826, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 1.950, mean reward: 0.244 [0.002, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 7.375 [4.000, 11.000], loss: 0.001693, mae: 0.018691, mean_q: 0.022692
 13094/100000: episode: 1827, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.035, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000246, mae: 0.015278, mean_q: 0.005026
 13098/100000: episode: 1828, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000453, mae: 0.014628, mean_q: 0.011229
 13106/100000: episode: 1829, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.875 [-1.000, 11.000], loss: 0.000390, mae: 0.011739, mean_q: 0.012424
 13114/100000: episode: 1830, duration: 0.043s, episode steps: 8, steps per second: 185, episode reward: 0.039, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000228, mae: 0.012953, mean_q: 0.008021
 13122/100000: episode: 1831, duration: 0.040s, episode steps: 8, steps per second: 198, episode reward: 0.013, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000267, mae: 0.013338, mean_q: 0.009670
 13130/100000: episode: 1832, duration: 0.037s, episode steps: 8, steps per second: 213, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.001559, mae: 0.021460, mean_q: 0.014107
 13138/100000: episode: 1833, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.097, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.001671, mae: 0.016686, mean_q: 0.017304
 13146/100000: episode: 1834, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.055, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001521, mae: 0.020797, mean_q: 0.013975
 13154/100000: episode: 1835, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.051, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000772, mae: 0.026408, mean_q: 0.009433
 13162/100000: episode: 1836, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.231, mean reward: 0.029 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.000600, mae: 0.018100, mean_q: 0.010928
 13170/100000: episode: 1837, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.097, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000456, mae: 0.018305, mean_q: 0.013569
 13178/100000: episode: 1838, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.059, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000479, mae: 0.017633, mean_q: 0.017392
 13186/100000: episode: 1839, duration: 0.040s, episode steps: 8, steps per second: 202, episode reward: 0.082, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000364, mae: 0.016625, mean_q: 0.015849
 13194/100000: episode: 1840, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.812 [-1.000, 11.000], loss: 0.000363, mae: 0.015929, mean_q: 0.016433
 13202/100000: episode: 1841, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.054, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000162, mae: 0.008992, mean_q: 0.010715
 13206/100000: episode: 1842, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000251, mae: 0.011620, mean_q: 0.013644
 13214/100000: episode: 1843, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.134, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000492, mae: 0.017121, mean_q: 0.018842
 13222/100000: episode: 1844, duration: 0.040s, episode steps: 8, steps per second: 202, episode reward: 0.128, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000271, mae: 0.014053, mean_q: 0.006881
 13230/100000: episode: 1845, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.128, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000485, mae: 0.014965, mean_q: 0.012961
 13234/100000: episode: 1846, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000289, mae: 0.015615, mean_q: 0.012615
 13242/100000: episode: 1847, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.001636, mae: 0.018478, mean_q: 0.021709
 13250/100000: episode: 1848, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.002628, mae: 0.021511, mean_q: 0.017531
 13258/100000: episode: 1849, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.231, mean reward: 0.029 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.000278, mae: 0.012927, mean_q: 0.009562
 13266/100000: episode: 1850, duration: 0.039s, episode steps: 8, steps per second: 208, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000400, mae: 0.013386, mean_q: 0.009321
 13274/100000: episode: 1851, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.134, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000597, mae: 0.012203, mean_q: 0.016101
 13282/100000: episode: 1852, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.098, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000407, mae: 0.014510, mean_q: 0.017913
 13286/100000: episode: 1853, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000315, mae: 0.014106, mean_q: 0.002774
 13294/100000: episode: 1854, duration: 0.039s, episode steps: 8, steps per second: 208, episode reward: 0.071, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.001457, mae: 0.015425, mean_q: 0.011391
 13302/100000: episode: 1855, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.032, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.001744, mae: 0.027130, mean_q: 0.019557
 13310/100000: episode: 1856, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.022, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000891, mae: 0.024466, mean_q: 0.016877
 13318/100000: episode: 1857, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.033, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000439, mae: 0.014815, mean_q: 0.011053
 13326/100000: episode: 1858, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.002753, mae: 0.020702, mean_q: 0.014283
 13334/100000: episode: 1859, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000810, mae: 0.024523, mean_q: 0.014660
 13342/100000: episode: 1860, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.146, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000457, mae: 0.016125, mean_q: 0.015486
 13350/100000: episode: 1861, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000336, mae: 0.014367, mean_q: 0.010800
 13358/100000: episode: 1862, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000583, mae: 0.016279, mean_q: 0.018098
 13366/100000: episode: 1863, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000249, mae: 0.012563, mean_q: 0.014734
 13374/100000: episode: 1864, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000425, mae: 0.014368, mean_q: 0.019487
 13382/100000: episode: 1865, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.032, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000268, mae: 0.011557, mean_q: 0.012296
 13390/100000: episode: 1866, duration: 0.037s, episode steps: 8, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.875 [-1.000, 11.000], loss: 0.000507, mae: 0.016463, mean_q: 0.016348
 13398/100000: episode: 1867, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000425, mae: 0.017123, mean_q: 0.018745
 13406/100000: episode: 1868, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.177, mean reward: 0.022 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.000452, mae: 0.017136, mean_q: 0.019377
 13414/100000: episode: 1869, duration: 0.037s, episode steps: 8, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.812 [-1.000, 11.000], loss: 0.000519, mae: 0.018023, mean_q: 0.016182
 13422/100000: episode: 1870, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.055, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000322, mae: 0.014369, mean_q: 0.011070
 13430/100000: episode: 1871, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000261, mae: 0.012167, mean_q: 0.009766
 13438/100000: episode: 1872, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.039, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000295, mae: 0.013825, mean_q: 0.016237
 13446/100000: episode: 1873, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000401, mae: 0.017588, mean_q: 0.015872
 13454/100000: episode: 1874, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.033, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000285, mae: 0.013188, mean_q: 0.017033
 13462/100000: episode: 1875, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.081, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000355, mae: 0.014690, mean_q: 0.011602
 13470/100000: episode: 1876, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.079, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000294, mae: 0.014215, mean_q: 0.013344
 13478/100000: episode: 1877, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000570, mae: 0.018458, mean_q: 0.017128
 13486/100000: episode: 1878, duration: 0.037s, episode steps: 8, steps per second: 216, episode reward: 0.098, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000364, mae: 0.012076, mean_q: 0.013669
 13490/100000: episode: 1879, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000195, mae: 0.010543, mean_q: 0.011421
 13498/100000: episode: 1880, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.044, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000306, mae: 0.011923, mean_q: 0.013064
 13506/100000: episode: 1881, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.097, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000732, mae: 0.015485, mean_q: 0.019054
 13510/100000: episode: 1882, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000231, mae: 0.013479, mean_q: 0.009704
 13518/100000: episode: 1883, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000294, mae: 0.013075, mean_q: 0.013281
 13526/100000: episode: 1884, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000255, mae: 0.012041, mean_q: 0.010261
 13530/100000: episode: 1885, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000341, mae: 0.015862, mean_q: 0.021388
 13538/100000: episode: 1886, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000384, mae: 0.016817, mean_q: 0.010647
[Info] 2-TH LEVEL FOUND: 0.10393638908863068, Considering 14/100 traces
 13546/100000: episode: 1887, duration: 0.713s, episode steps: 8, steps per second: 11, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000488, mae: 0.014267, mean_q: 0.013295
 13551/100000: episode: 1888, duration: 0.029s, episode steps: 5, steps per second: 174, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000401, mae: 0.013651, mean_q: 0.015409
 13556/100000: episode: 1889, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000254, mae: 0.012259, mean_q: 0.014040
 13558/100000: episode: 1890, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000218, mae: 0.011737, mean_q: 0.008093
 13560/100000: episode: 1891, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000252, mae: 0.012404, mean_q: 0.007140
 13565/100000: episode: 1892, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000221, mae: 0.010881, mean_q: 0.015031
 13567/100000: episode: 1893, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000120, mae: 0.008842, mean_q: 0.005801
 13572/100000: episode: 1894, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000216, mae: 0.010534, mean_q: 0.013991
 13574/100000: episode: 1895, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001002, mae: 0.017400, mean_q: 0.013617
 13579/100000: episode: 1896, duration: 0.028s, episode steps: 5, steps per second: 182, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002369, mae: 0.022228, mean_q: 0.027706
 13584/100000: episode: 1897, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000488, mae: 0.015073, mean_q: 0.015433
 13589/100000: episode: 1898, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000177, mae: 0.011439, mean_q: 0.010509
 13594/100000: episode: 1899, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000403, mae: 0.015241, mean_q: 0.009162
 13596/100000: episode: 1900, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000386, mae: 0.016023, mean_q: 0.016950
 13598/100000: episode: 1901, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000269, mae: 0.014601, mean_q: 0.026712
 13603/100000: episode: 1902, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000366, mae: 0.015238, mean_q: 0.018336
 13608/100000: episode: 1903, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000321, mae: 0.016577, mean_q: 0.001959
 13613/100000: episode: 1904, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000448, mae: 0.016778, mean_q: 0.018571
 13618/100000: episode: 1905, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000722, mae: 0.018553, mean_q: 0.019136
 13620/100000: episode: 1906, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000258, mae: 0.013499, mean_q: 0.019041
 13625/100000: episode: 1907, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000863, mae: 0.022965, mean_q: 0.016575
[Info] FALSIFICATION!
 13629/100000: episode: 1908, duration: 0.273s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000476, mae: 0.016362, mean_q: 0.014719
 13634/100000: episode: 1909, duration: 0.031s, episode steps: 5, steps per second: 160, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000381, mae: 0.016337, mean_q: 0.020634
 13639/100000: episode: 1910, duration: 0.032s, episode steps: 5, steps per second: 155, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002606, mae: 0.019732, mean_q: 0.014970
 13641/100000: episode: 1911, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000879, mae: 0.023515, mean_q: 0.036194
 13646/100000: episode: 1912, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002484, mae: 0.022814, mean_q: 0.016666
 13651/100000: episode: 1913, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000400, mae: 0.016176, mean_q: 0.018654
 13656/100000: episode: 1914, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000601, mae: 0.017974, mean_q: 0.022781
 13658/100000: episode: 1915, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000297, mae: 0.019329, mean_q: -0.007957
 13660/100000: episode: 1916, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000184, mae: 0.016343, mean_q: 0.023983
 13665/100000: episode: 1917, duration: 0.028s, episode steps: 5, steps per second: 179, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000678, mae: 0.021515, mean_q: 0.001893
 13670/100000: episode: 1918, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000530, mae: 0.017039, mean_q: 0.022977
 13672/100000: episode: 1919, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000431, mae: 0.015307, mean_q: 0.008205
 13677/100000: episode: 1920, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000382, mae: 0.013754, mean_q: 0.017183
 13679/100000: episode: 1921, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000419, mae: 0.016089, mean_q: 0.011865
 13684/100000: episode: 1922, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000405, mae: 0.011156, mean_q: 0.017874
 13686/100000: episode: 1923, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000573, mae: 0.012505, mean_q: 0.016440
 13688/100000: episode: 1924, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002164, mae: 0.020468, mean_q: 0.030564
 13693/100000: episode: 1925, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000563, mae: 0.020202, mean_q: 0.018395
 13698/100000: episode: 1926, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000644, mae: 0.015468, mean_q: 0.020628
 13703/100000: episode: 1927, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.003513, mae: 0.035722, mean_q: 0.035334
 13708/100000: episode: 1928, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000551, mae: 0.025577, mean_q: -0.001776
 13710/100000: episode: 1929, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000310, mae: 0.017289, mean_q: 0.017486
 13712/100000: episode: 1930, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004295, mae: 0.025130, mean_q: 0.025707
 13717/100000: episode: 1931, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000978, mae: 0.015140, mean_q: 0.018992
 13719/100000: episode: 1932, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000700, mae: 0.024239, mean_q: -0.002925
 13721/100000: episode: 1933, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002643, mae: 0.030939, mean_q: 0.040962
 13726/100000: episode: 1934, duration: 0.028s, episode steps: 5, steps per second: 182, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000550, mae: 0.020601, mean_q: 0.015345
 13731/100000: episode: 1935, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000602, mae: 0.019152, mean_q: 0.023414
 13736/100000: episode: 1936, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000742, mae: 0.017862, mean_q: 0.010460
 13738/100000: episode: 1937, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000526, mae: 0.024134, mean_q: 0.036083
 13743/100000: episode: 1938, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000571, mae: 0.021772, mean_q: 0.003565
 13748/100000: episode: 1939, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000842, mae: 0.022206, mean_q: 0.033645
 13750/100000: episode: 1940, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000884, mae: 0.031137, mean_q: -0.014370
 13752/100000: episode: 1941, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000875, mae: 0.028355, mean_q: 0.029166
[Info] FALSIFICATION!
 13756/100000: episode: 1942, duration: 0.276s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000341, mae: 0.016240, mean_q: 0.012020
 13761/100000: episode: 1943, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000419, mae: 0.017060, mean_q: 0.013991
 13763/100000: episode: 1944, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000430, mae: 0.015951, mean_q: 0.002479
 13765/100000: episode: 1945, duration: 0.015s, episode steps: 2, steps per second: 135, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006498, mae: 0.030060, mean_q: 0.022882
[Info] FALSIFICATION!
 13769/100000: episode: 1946, duration: 0.267s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000492, mae: 0.019980, mean_q: 0.025172
 13771/100000: episode: 1947, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000577, mae: 0.021961, mean_q: 0.006429
 13776/100000: episode: 1948, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000398, mae: 0.018992, mean_q: 0.024980
 13781/100000: episode: 1949, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.003639, mae: 0.033007, mean_q: 0.033552
 13783/100000: episode: 1950, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000561, mae: 0.018987, mean_q: 0.028464
 13788/100000: episode: 1951, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000887, mae: 0.024165, mean_q: 0.020249
 13793/100000: episode: 1952, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000603, mae: 0.020542, mean_q: 0.005520
 13798/100000: episode: 1953, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000564, mae: 0.017796, mean_q: 0.024114
 13803/100000: episode: 1954, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000363, mae: 0.015235, mean_q: 0.001215
 13805/100000: episode: 1955, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000462, mae: 0.020961, mean_q: 0.034233
 13810/100000: episode: 1956, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000448, mae: 0.017633, mean_q: 0.001901
 13815/100000: episode: 1957, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000402, mae: 0.016195, mean_q: 0.018824
 13820/100000: episode: 1958, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000266, mae: 0.009636, mean_q: 0.015962
 13825/100000: episode: 1959, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000440, mae: 0.013501, mean_q: 0.014087
 13830/100000: episode: 1960, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000596, mae: 0.014454, mean_q: 0.019563
[Info] FALSIFICATION!
 13834/100000: episode: 1961, duration: 0.263s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000382, mae: 0.013385, mean_q: 0.014265
 13839/100000: episode: 1962, duration: 0.030s, episode steps: 5, steps per second: 167, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002454, mae: 0.021214, mean_q: 0.023644
 13841/100000: episode: 1963, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000378, mae: 0.020128, mean_q: -0.003416
 13843/100000: episode: 1964, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000573, mae: 0.017496, mean_q: 0.005080
 13845/100000: episode: 1965, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002047, mae: 0.043667, mean_q: 0.061207
 13850/100000: episode: 1966, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000560, mae: 0.023809, mean_q: 0.011067
 13855/100000: episode: 1967, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000786, mae: 0.023950, mean_q: 0.034075
 13860/100000: episode: 1968, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000721, mae: 0.027060, mean_q: 0.014248
 13865/100000: episode: 1969, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001451, mae: 0.035687, mean_q: 0.011893
 13870/100000: episode: 1970, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000590, mae: 0.021550, mean_q: 0.030469
 13872/100000: episode: 1971, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001122, mae: 0.026946, mean_q: 0.001876
 13874/100000: episode: 1972, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000372, mae: 0.018646, mean_q: 0.020522
[Info] Complete ISplit Iteration
[Info] Levels: [0.013957337, 0.10393639, 0.6300182]
[Info] Cond. Prob: [0.16, 0.14, 0.04]
[Info] Error Prob: 0.0008960000000000001

 13879/100000: episode: 1973, duration: 0.889s, episode steps: 5, steps per second: 6, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000266, mae: 0.012575, mean_q: 0.012635
 13889/100000: episode: 1974, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000924, mae: 0.021858, mean_q: 0.022304
 13899/100000: episode: 1975, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001256, mae: 0.023802, mean_q: 0.024866
 13909/100000: episode: 1976, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000543, mae: 0.016140, mean_q: 0.020652
 13919/100000: episode: 1977, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000487, mae: 0.013902, mean_q: 0.018240
 13929/100000: episode: 1978, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002245, mae: 0.025042, mean_q: 0.034021
 13939/100000: episode: 1979, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000610, mae: 0.016513, mean_q: 0.017433
 13949/100000: episode: 1980, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001365, mae: 0.016317, mean_q: 0.019369
 13959/100000: episode: 1981, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001716, mae: 0.024251, mean_q: 0.022749
 13969/100000: episode: 1982, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001967, mae: 0.025021, mean_q: 0.027615
 13979/100000: episode: 1983, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001340, mae: 0.023151, mean_q: 0.023422
 13989/100000: episode: 1984, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000878, mae: 0.021854, mean_q: 0.020861
 13999/100000: episode: 1985, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001660, mae: 0.023754, mean_q: 0.026556
 14009/100000: episode: 1986, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000519, mae: 0.017186, mean_q: 0.014027
 14019/100000: episode: 1987, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000677, mae: 0.018687, mean_q: 0.015960
 14029/100000: episode: 1988, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002177, mae: 0.024752, mean_q: 0.030995
 14039/100000: episode: 1989, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001175, mae: 0.027159, mean_q: 0.021036
 14049/100000: episode: 1990, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002349, mae: 0.029318, mean_q: 0.021236
 14059/100000: episode: 1991, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000780, mae: 0.022782, mean_q: 0.017580
 14069/100000: episode: 1992, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000922, mae: 0.019523, mean_q: 0.022006
 14079/100000: episode: 1993, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000869, mae: 0.015317, mean_q: 0.018657
 14089/100000: episode: 1994, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001435, mae: 0.017222, mean_q: 0.017528
 14099/100000: episode: 1995, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001182, mae: 0.029810, mean_q: 0.024357
 14109/100000: episode: 1996, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000952, mae: 0.025022, mean_q: 0.015660
 14119/100000: episode: 1997, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002310, mae: 0.035004, mean_q: 0.033331
 14129/100000: episode: 1998, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001224, mae: 0.032710, mean_q: 0.022691
 14139/100000: episode: 1999, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001037, mae: 0.027903, mean_q: 0.022950
 14149/100000: episode: 2000, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001058, mae: 0.022652, mean_q: 0.023669
 14159/100000: episode: 2001, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001009, mae: 0.019327, mean_q: 0.024673
 14169/100000: episode: 2002, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001515, mae: 0.024799, mean_q: 0.025147
 14179/100000: episode: 2003, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000457, mae: 0.016009, mean_q: 0.026697
 14189/100000: episode: 2004, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001353, mae: 0.023961, mean_q: 0.023778
 14199/100000: episode: 2005, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000774, mae: 0.021407, mean_q: 0.019865
 14209/100000: episode: 2006, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001016, mae: 0.019266, mean_q: 0.024642
 14219/100000: episode: 2007, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001408, mae: 0.020572, mean_q: 0.022902
 14229/100000: episode: 2008, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000806, mae: 0.023245, mean_q: 0.020819
 14239/100000: episode: 2009, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000771, mae: 0.017913, mean_q: 0.023841
 14249/100000: episode: 2010, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000830, mae: 0.019575, mean_q: 0.025920
 14259/100000: episode: 2011, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000625, mae: 0.017542, mean_q: 0.016139
 14269/100000: episode: 2012, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000636, mae: 0.017261, mean_q: 0.017536
 14279/100000: episode: 2013, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000663, mae: 0.015934, mean_q: 0.019270
 14289/100000: episode: 2014, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000537, mae: 0.015248, mean_q: 0.019786
 14299/100000: episode: 2015, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000726, mae: 0.017698, mean_q: 0.019724
 14309/100000: episode: 2016, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000462, mae: 0.013635, mean_q: 0.015731
 14319/100000: episode: 2017, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000894, mae: 0.015224, mean_q: 0.013796
 14329/100000: episode: 2018, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000579, mae: 0.015710, mean_q: 0.015904
 14339/100000: episode: 2019, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001029, mae: 0.016708, mean_q: 0.021763
 14349/100000: episode: 2020, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000507, mae: 0.014664, mean_q: 0.016988
 14359/100000: episode: 2021, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001315, mae: 0.015935, mean_q: 0.016338
 14369/100000: episode: 2022, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001962, mae: 0.023687, mean_q: 0.032520
 14379/100000: episode: 2023, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001069, mae: 0.025091, mean_q: 0.024760
 14389/100000: episode: 2024, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002279, mae: 0.033292, mean_q: 0.032936
 14399/100000: episode: 2025, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.002059, mae: 0.033381, mean_q: 0.016645
 14409/100000: episode: 2026, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000927, mae: 0.032727, mean_q: 0.015329
 14419/100000: episode: 2027, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002140, mae: 0.030552, mean_q: 0.026536
 14429/100000: episode: 2028, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001009, mae: 0.022960, mean_q: 0.019921
 14439/100000: episode: 2029, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000637, mae: 0.017062, mean_q: 0.018179
 14449/100000: episode: 2030, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001953, mae: 0.018662, mean_q: 0.021695
 14459/100000: episode: 2031, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001228, mae: 0.026865, mean_q: 0.031733
 14469/100000: episode: 2032, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000759, mae: 0.018334, mean_q: 0.021404
 14479/100000: episode: 2033, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000654, mae: 0.020212, mean_q: 0.015500
 14489/100000: episode: 2034, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000936, mae: 0.021394, mean_q: 0.015880
 14499/100000: episode: 2035, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000732, mae: 0.021760, mean_q: 0.018491
 14509/100000: episode: 2036, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001871, mae: 0.024287, mean_q: 0.024615
 14519/100000: episode: 2037, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000761, mae: 0.024190, mean_q: 0.019850
 14529/100000: episode: 2038, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001016, mae: 0.026660, mean_q: 0.022518
 14539/100000: episode: 2039, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000931, mae: 0.022372, mean_q: 0.026810
 14549/100000: episode: 2040, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000606, mae: 0.018876, mean_q: 0.019191
 14559/100000: episode: 2041, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000513, mae: 0.018125, mean_q: 0.015831
 14569/100000: episode: 2042, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000890, mae: 0.021119, mean_q: 0.025811
 14579/100000: episode: 2043, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000665, mae: 0.018574, mean_q: 0.018930
 14589/100000: episode: 2044, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001980, mae: 0.024973, mean_q: 0.032663
 14599/100000: episode: 2045, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002486, mae: 0.025281, mean_q: 0.024646
 14609/100000: episode: 2046, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001619, mae: 0.025642, mean_q: 0.021843
 14619/100000: episode: 2047, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001474, mae: 0.025261, mean_q: 0.034551
 14629/100000: episode: 2048, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001280, mae: 0.023844, mean_q: 0.029810
 14639/100000: episode: 2049, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000528, mae: 0.016541, mean_q: 0.014537
 14649/100000: episode: 2050, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002035, mae: 0.025610, mean_q: 0.022511
 14659/100000: episode: 2051, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000809, mae: 0.020585, mean_q: 0.022804
 14669/100000: episode: 2052, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000926, mae: 0.024179, mean_q: 0.028516
 14679/100000: episode: 2053, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000701, mae: 0.017958, mean_q: 0.015852
 14689/100000: episode: 2054, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000619, mae: 0.016837, mean_q: 0.019608
 14699/100000: episode: 2055, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000761, mae: 0.018310, mean_q: 0.020062
 14709/100000: episode: 2056, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001928, mae: 0.026530, mean_q: 0.026750
 14719/100000: episode: 2057, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000562, mae: 0.020655, mean_q: 0.012237
 14729/100000: episode: 2058, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000634, mae: 0.018343, mean_q: 0.016195
 14739/100000: episode: 2059, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000667, mae: 0.016793, mean_q: 0.017499
 14749/100000: episode: 2060, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000599, mae: 0.014492, mean_q: 0.017388
 14759/100000: episode: 2061, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000506, mae: 0.017319, mean_q: 0.012432
 14769/100000: episode: 2062, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001619, mae: 0.022727, mean_q: 0.022936
 14779/100000: episode: 2063, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000568, mae: 0.019848, mean_q: 0.016456
 14789/100000: episode: 2064, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000366, mae: 0.013934, mean_q: 0.016918
 14799/100000: episode: 2065, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000688, mae: 0.016564, mean_q: 0.019569
 14809/100000: episode: 2066, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000650, mae: 0.016615, mean_q: 0.018619
 14819/100000: episode: 2067, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000732, mae: 0.015363, mean_q: 0.024477
 14829/100000: episode: 2068, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000656, mae: 0.017968, mean_q: 0.023641
 14839/100000: episode: 2069, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000596, mae: 0.019754, mean_q: 0.018004
 14849/100000: episode: 2070, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001753, mae: 0.020379, mean_q: 0.017613
 14859/100000: episode: 2071, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000470, mae: 0.017208, mean_q: 0.016774
 14869/100000: episode: 2072, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001016, mae: 0.018914, mean_q: 0.026168
[Info] 1-TH LEVEL FOUND: 0.04712739586830139, Considering 10/100 traces
 14879/100000: episode: 2073, duration: 0.716s, episode steps: 10, steps per second: 14, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000784, mae: 0.017928, mean_q: 0.023343
 14885/100000: episode: 2074, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002094, mae: 0.020125, mean_q: 0.023327
 14891/100000: episode: 2075, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000557, mae: 0.017550, mean_q: 0.013708
 14894/100000: episode: 2076, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003734, mae: 0.022490, mean_q: 0.024070
 14897/100000: episode: 2077, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001646, mae: 0.023360, mean_q: 0.035453
 14903/100000: episode: 2078, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000550, mae: 0.020507, mean_q: 0.009431
 14906/100000: episode: 2079, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000811, mae: 0.022902, mean_q: 0.032989
 14909/100000: episode: 2080, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000550, mae: 0.016554, mean_q: 0.010669
 14915/100000: episode: 2081, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000651, mae: 0.020444, mean_q: 0.035654
 14921/100000: episode: 2082, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.002911, mae: 0.030948, mean_q: 0.023594
 14924/100000: episode: 2083, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001533, mae: 0.030115, mean_q: 0.054224
 14927/100000: episode: 2084, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002274, mae: 0.035786, mean_q: 0.000060
 14933/100000: episode: 2085, duration: 0.031s, episode steps: 6, steps per second: 192, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001654, mae: 0.032692, mean_q: 0.048734
 14936/100000: episode: 2086, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003648, mae: 0.030960, mean_q: 0.025350
 14942/100000: episode: 2087, duration: 0.031s, episode steps: 6, steps per second: 197, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000673, mae: 0.018495, mean_q: 0.029125
 14948/100000: episode: 2088, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000533, mae: 0.016189, mean_q: 0.023184
 14951/100000: episode: 2089, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000854, mae: 0.023041, mean_q: 0.003701
 14954/100000: episode: 2090, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003657, mae: 0.030607, mean_q: 0.032975
 14960/100000: episode: 2091, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000846, mae: 0.022918, mean_q: 0.023580
 14966/100000: episode: 2092, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.003446, mae: 0.030715, mean_q: 0.041291
 14969/100000: episode: 2093, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000720, mae: 0.025467, mean_q: 0.009532
 14972/100000: episode: 2094, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000443, mae: 0.019945, mean_q: 0.009931
 14975/100000: episode: 2095, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000682, mae: 0.024763, mean_q: 0.031237
 14978/100000: episode: 2096, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000924, mae: 0.027098, mean_q: 0.002217
 14981/100000: episode: 2097, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000381, mae: 0.020347, mean_q: 0.034085
 14984/100000: episode: 2098, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003800, mae: 0.025774, mean_q: 0.033789
 14987/100000: episode: 2099, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.004395, mae: 0.026798, mean_q: 0.028607
 14990/100000: episode: 2100, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001132, mae: 0.022158, mean_q: 0.017719
 14996/100000: episode: 2101, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001052, mae: 0.022244, mean_q: 0.022121
 14999/100000: episode: 2102, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000491, mae: 0.016328, mean_q: 0.014526
 15005/100000: episode: 2103, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000638, mae: 0.016851, mean_q: 0.023377
 15008/100000: episode: 2104, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000584, mae: 0.024791, mean_q: 0.004930
 15011/100000: episode: 2105, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001078, mae: 0.021444, mean_q: 0.031211
 15017/100000: episode: 2106, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001044, mae: 0.023957, mean_q: 0.030619
 15023/100000: episode: 2107, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000660, mae: 0.017343, mean_q: 0.029446
 15029/100000: episode: 2108, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000849, mae: 0.017725, mean_q: 0.018809
 15032/100000: episode: 2109, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000538, mae: 0.018332, mean_q: 0.023011
 15035/100000: episode: 2110, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000170, mae: 0.009392, mean_q: 0.010623
 15038/100000: episode: 2111, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000246, mae: 0.012348, mean_q: 0.005150
 15044/100000: episode: 2112, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000814, mae: 0.027620, mean_q: 0.033827
 15050/100000: episode: 2113, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001025, mae: 0.025820, mean_q: 0.016415
 15053/100000: episode: 2114, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000841, mae: 0.025040, mean_q: 0.036007
 15059/100000: episode: 2115, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000904, mae: 0.022102, mean_q: 0.017278
 15062/100000: episode: 2116, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001709, mae: 0.019926, mean_q: 0.024622
 15065/100000: episode: 2117, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002325, mae: 0.032013, mean_q: 0.052370
 15068/100000: episode: 2118, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000492, mae: 0.016326, mean_q: 0.013496
 15071/100000: episode: 2119, duration: 0.016s, episode steps: 3, steps per second: 187, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000700, mae: 0.020863, mean_q: 0.011157
 15074/100000: episode: 2120, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001044, mae: 0.024712, mean_q: 0.035897
 15080/100000: episode: 2121, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000748, mae: 0.018845, mean_q: 0.021027
 15086/100000: episode: 2122, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000482, mae: 0.013583, mean_q: 0.022182
 15089/100000: episode: 2123, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000522, mae: 0.015135, mean_q: 0.016741
 15092/100000: episode: 2124, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000283, mae: 0.011834, mean_q: 0.008871
 15095/100000: episode: 2125, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000916, mae: 0.023234, mean_q: 0.031103
 15098/100000: episode: 2126, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000790, mae: 0.015721, mean_q: 0.014406
 15101/100000: episode: 2127, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000438, mae: 0.015860, mean_q: 0.022058
 15104/100000: episode: 2128, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001676, mae: 0.020208, mean_q: 0.028149
 15107/100000: episode: 2129, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000661, mae: 0.017849, mean_q: 0.014862
 15113/100000: episode: 2130, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.002662, mae: 0.027737, mean_q: 0.029351
 15116/100000: episode: 2131, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000547, mae: 0.016671, mean_q: 0.021267
 15122/100000: episode: 2132, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000538, mae: 0.019052, mean_q: 0.022068
 15128/100000: episode: 2133, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000660, mae: 0.016766, mean_q: 0.020061
 15131/100000: episode: 2134, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000201, mae: 0.010169, mean_q: 0.012598
 15137/100000: episode: 2135, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000849, mae: 0.017261, mean_q: 0.033515
 15140/100000: episode: 2136, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000464, mae: 0.013021, mean_q: 0.020713
 15146/100000: episode: 2137, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000772, mae: 0.016358, mean_q: 0.021041
 15152/100000: episode: 2138, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000822, mae: 0.019377, mean_q: 0.021781
 15158/100000: episode: 2139, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000436, mae: 0.014103, mean_q: 0.018290
 15161/100000: episode: 2140, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000453, mae: 0.015943, mean_q: 0.019573
 15164/100000: episode: 2141, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000582, mae: 0.019920, mean_q: 0.030090
 15170/100000: episode: 2142, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002296, mae: 0.026540, mean_q: 0.038023
 15173/100000: episode: 2143, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003495, mae: 0.022413, mean_q: 0.012135
 15176/100000: episode: 2144, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001719, mae: 0.034244, mean_q: 0.054305
 15179/100000: episode: 2145, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000527, mae: 0.019498, mean_q: 0.015748
 15182/100000: episode: 2146, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000876, mae: 0.022388, mean_q: 0.020453
 15185/100000: episode: 2147, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000636, mae: 0.015270, mean_q: 0.024307
 15191/100000: episode: 2148, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002637, mae: 0.027773, mean_q: 0.031699
 15197/100000: episode: 2149, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000958, mae: 0.029670, mean_q: 0.017536
 15203/100000: episode: 2150, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000969, mae: 0.027421, mean_q: 0.033891
 15209/100000: episode: 2151, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.002444, mae: 0.027881, mean_q: 0.005812
 15212/100000: episode: 2152, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001187, mae: 0.035567, mean_q: 0.051118
 15215/100000: episode: 2153, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000685, mae: 0.029575, mean_q: -0.008167
 15221/100000: episode: 2154, duration: 0.031s, episode steps: 6, steps per second: 191, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.002132, mae: 0.027567, mean_q: 0.039039
 15224/100000: episode: 2155, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001007, mae: 0.028453, mean_q: 0.002371
 15227/100000: episode: 2156, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000537, mae: 0.018559, mean_q: 0.019698
 15233/100000: episode: 2157, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002407, mae: 0.030392, mean_q: 0.025245
 15239/100000: episode: 2158, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000481, mae: 0.019771, mean_q: 0.028338
 15242/100000: episode: 2159, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000452, mae: 0.018298, mean_q: 0.005202
 15248/100000: episode: 2160, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000832, mae: 0.022487, mean_q: 0.031889
 15251/100000: episode: 2161, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000657, mae: 0.018959, mean_q: 0.022983
[Info] FALSIFICATION!
 15256/100000: episode: 2162, duration: 0.260s, episode steps: 5, steps per second: 19, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000794, mae: 0.019005, mean_q: 0.021348
[Info] Complete ISplit Iteration
[Info] Levels: [0.047127396, 0.69053084]
[Info] Cond. Prob: [0.1, 0.01]
[Info] Error Prob: 0.001

 15259/100000: episode: 2163, duration: 0.726s, episode steps: 3, steps per second: 4, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004214, mae: 0.029219, mean_q: 0.035811
 15269/100000: episode: 2164, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002226, mae: 0.025775, mean_q: 0.032746
 15279/100000: episode: 2165, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001698, mae: 0.033293, mean_q: 0.033087
 15289/100000: episode: 2166, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002353, mae: 0.038218, mean_q: 0.031705
 15299/100000: episode: 2167, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002032, mae: 0.033568, mean_q: 0.027458
 15309/100000: episode: 2168, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000988, mae: 0.028382, mean_q: 0.023522
 15319/100000: episode: 2169, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001610, mae: 0.020603, mean_q: 0.028086
 15329/100000: episode: 2170, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001399, mae: 0.025600, mean_q: 0.025710
 15339/100000: episode: 2171, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000788, mae: 0.020996, mean_q: 0.021390
 15349/100000: episode: 2172, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001955, mae: 0.024148, mean_q: 0.024633
 15359/100000: episode: 2173, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000783, mae: 0.020115, mean_q: 0.018226
 15369/100000: episode: 2174, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000909, mae: 0.023791, mean_q: 0.027882
 15379/100000: episode: 2175, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000825, mae: 0.021282, mean_q: 0.018175
 15389/100000: episode: 2176, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001461, mae: 0.027994, mean_q: 0.031763
 15399/100000: episode: 2177, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000681, mae: 0.019931, mean_q: 0.020617
 15409/100000: episode: 2178, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000903, mae: 0.021372, mean_q: 0.026477
 15419/100000: episode: 2179, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000593, mae: 0.016483, mean_q: 0.017561
 15429/100000: episode: 2180, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000906, mae: 0.018784, mean_q: 0.022778
 15439/100000: episode: 2181, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001115, mae: 0.021203, mean_q: 0.032896
 15449/100000: episode: 2182, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000600, mae: 0.016904, mean_q: 0.020049
 15459/100000: episode: 2183, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000830, mae: 0.018261, mean_q: 0.018877
 15469/100000: episode: 2184, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.003158, mae: 0.038413, mean_q: 0.038067
 15479/100000: episode: 2185, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001079, mae: 0.028637, mean_q: 0.023557
 15489/100000: episode: 2186, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000978, mae: 0.021935, mean_q: 0.020619
 15499/100000: episode: 2187, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001036, mae: 0.022434, mean_q: 0.026546
 15509/100000: episode: 2188, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000634, mae: 0.018851, mean_q: 0.023049
 15519/100000: episode: 2189, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001188, mae: 0.023974, mean_q: 0.025233
 15529/100000: episode: 2190, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000736, mae: 0.021006, mean_q: 0.022772
 15539/100000: episode: 2191, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001707, mae: 0.023395, mean_q: 0.025278
 15549/100000: episode: 2192, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001275, mae: 0.025907, mean_q: 0.026810
 15559/100000: episode: 2193, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000809, mae: 0.026593, mean_q: 0.020167
 15569/100000: episode: 2194, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001245, mae: 0.025742, mean_q: 0.017527
 15579/100000: episode: 2195, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003079, mae: 0.026342, mean_q: 0.024118
 15589/100000: episode: 2196, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000572, mae: 0.016275, mean_q: 0.018189
 15599/100000: episode: 2197, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001166, mae: 0.020637, mean_q: 0.024053
 15609/100000: episode: 2198, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000847, mae: 0.022146, mean_q: 0.024728
 15619/100000: episode: 2199, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000880, mae: 0.020554, mean_q: 0.029994
 15629/100000: episode: 2200, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000548, mae: 0.016705, mean_q: 0.015059
 15639/100000: episode: 2201, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001073, mae: 0.023691, mean_q: 0.028153
 15649/100000: episode: 2202, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000808, mae: 0.023471, mean_q: 0.029467
 15659/100000: episode: 2203, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001098, mae: 0.022651, mean_q: 0.028825
 15669/100000: episode: 2204, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.001241, mae: 0.023372, mean_q: 0.034371
 15679/100000: episode: 2205, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000850, mae: 0.023761, mean_q: 0.025633
 15689/100000: episode: 2206, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001186, mae: 0.023049, mean_q: 0.025500
 15699/100000: episode: 2207, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000626, mae: 0.019377, mean_q: 0.019848
 15709/100000: episode: 2208, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001285, mae: 0.025975, mean_q: 0.026906
 15719/100000: episode: 2209, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000694, mae: 0.024417, mean_q: 0.022476
 15729/100000: episode: 2210, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001651, mae: 0.024400, mean_q: 0.020662
 15739/100000: episode: 2211, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000405, mae: 0.014962, mean_q: 0.021109
 15749/100000: episode: 2212, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001418, mae: 0.024049, mean_q: 0.032312
 15759/100000: episode: 2213, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001659, mae: 0.023412, mean_q: 0.024400
 15769/100000: episode: 2214, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.003722, mae: 0.031393, mean_q: 0.038099
 15779/100000: episode: 2215, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001634, mae: 0.034657, mean_q: 0.022760
 15789/100000: episode: 2216, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001992, mae: 0.026188, mean_q: 0.029586
 15799/100000: episode: 2217, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001681, mae: 0.023950, mean_q: 0.030282
 15809/100000: episode: 2218, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000815, mae: 0.022930, mean_q: 0.022712
 15819/100000: episode: 2219, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001423, mae: 0.022536, mean_q: 0.018721
 15829/100000: episode: 2220, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002025, mae: 0.027029, mean_q: 0.036750
 15839/100000: episode: 2221, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001747, mae: 0.025270, mean_q: 0.024736
 15849/100000: episode: 2222, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000944, mae: 0.023371, mean_q: 0.021879
 15859/100000: episode: 2223, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001761, mae: 0.024371, mean_q: 0.023950
 15869/100000: episode: 2224, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000975, mae: 0.023248, mean_q: 0.024437
 15879/100000: episode: 2225, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000734, mae: 0.020607, mean_q: 0.022078
 15889/100000: episode: 2226, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000622, mae: 0.015422, mean_q: 0.015810
 15899/100000: episode: 2227, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000620, mae: 0.018277, mean_q: 0.022679
 15909/100000: episode: 2228, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000473, mae: 0.014633, mean_q: 0.020760
 15919/100000: episode: 2229, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001898, mae: 0.023524, mean_q: 0.029160
 15929/100000: episode: 2230, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002646, mae: 0.025973, mean_q: 0.032090
 15939/100000: episode: 2231, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001821, mae: 0.022420, mean_q: 0.032237
 15949/100000: episode: 2232, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000843, mae: 0.021961, mean_q: 0.020442
 15959/100000: episode: 2233, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002428, mae: 0.034819, mean_q: 0.021630
 15969/100000: episode: 2234, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001838, mae: 0.027504, mean_q: 0.032075
 15979/100000: episode: 2235, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002244, mae: 0.021612, mean_q: 0.019812
 15989/100000: episode: 2236, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000799, mae: 0.024087, mean_q: 0.024716
 15999/100000: episode: 2237, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001518, mae: 0.021014, mean_q: 0.021678
 16009/100000: episode: 2238, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001635, mae: 0.023111, mean_q: 0.024018
 16019/100000: episode: 2239, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001962, mae: 0.027412, mean_q: 0.024941
 16029/100000: episode: 2240, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002198, mae: 0.025198, mean_q: 0.032846
 16039/100000: episode: 2241, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000595, mae: 0.017222, mean_q: 0.013486
 16049/100000: episode: 2242, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002153, mae: 0.024920, mean_q: 0.023702
 16059/100000: episode: 2243, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000588, mae: 0.021568, mean_q: 0.023963
 16069/100000: episode: 2244, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001524, mae: 0.018769, mean_q: 0.018231
 16079/100000: episode: 2245, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001666, mae: 0.021467, mean_q: 0.031712
 16089/100000: episode: 2246, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000461, mae: 0.014388, mean_q: 0.015309
 16099/100000: episode: 2247, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002536, mae: 0.027489, mean_q: 0.032842
 16109/100000: episode: 2248, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000658, mae: 0.017992, mean_q: 0.020370
 16119/100000: episode: 2249, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000477, mae: 0.016302, mean_q: 0.019499
 16129/100000: episode: 2250, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000465, mae: 0.014839, mean_q: 0.017665
 16139/100000: episode: 2251, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002310, mae: 0.021200, mean_q: 0.025245
 16149/100000: episode: 2252, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000943, mae: 0.021450, mean_q: 0.022871
 16159/100000: episode: 2253, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000540, mae: 0.018476, mean_q: 0.015471
 16169/100000: episode: 2254, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001452, mae: 0.022776, mean_q: 0.017976
 16179/100000: episode: 2255, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000586, mae: 0.016804, mean_q: 0.018866
 16189/100000: episode: 2256, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000626, mae: 0.014769, mean_q: 0.019722
 16199/100000: episode: 2257, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000905, mae: 0.019445, mean_q: 0.021368
 16209/100000: episode: 2258, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000759, mae: 0.016953, mean_q: 0.019315
 16219/100000: episode: 2259, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000757, mae: 0.016468, mean_q: 0.024478
 16229/100000: episode: 2260, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000857, mae: 0.013425, mean_q: 0.016695
 16239/100000: episode: 2261, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000703, mae: 0.014556, mean_q: 0.019614
 16249/100000: episode: 2262, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001942, mae: 0.023219, mean_q: 0.026984
[Info] 1-TH LEVEL FOUND: 0.012824460864067078, Considering 11/100 traces
 16259/100000: episode: 2263, duration: 0.700s, episode steps: 10, steps per second: 14, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000861, mae: 0.021868, mean_q: 0.019782
 16266/100000: episode: 2264, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000320, mae: 0.013866, mean_q: 0.015761
 16273/100000: episode: 2265, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000679, mae: 0.022036, mean_q: 0.019476
 16280/100000: episode: 2266, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000578, mae: 0.016511, mean_q: 0.018857
[Info] FALSIFICATION!
 16286/100000: episode: 2267, duration: 0.261s, episode steps: 6, steps per second: 23, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000401, mae: 0.014468, mean_q: 0.011896
 16293/100000: episode: 2268, duration: 0.039s, episode steps: 7, steps per second: 180, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.002611, mae: 0.023014, mean_q: 0.026866
 16300/100000: episode: 2269, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000389, mae: 0.014729, mean_q: 0.014866
 16307/100000: episode: 2270, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000565, mae: 0.016731, mean_q: 0.022820
 16311/100000: episode: 2271, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000665, mae: 0.019225, mean_q: 0.008649
 16313/100000: episode: 2272, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002227, mae: 0.031716, mean_q: 0.045480
 16320/100000: episode: 2273, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001924, mae: 0.021631, mean_q: 0.014159
 16327/100000: episode: 2274, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000830, mae: 0.025969, mean_q: 0.017613
 16331/100000: episode: 2275, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001014, mae: 0.023898, mean_q: 0.035358
 16338/100000: episode: 2276, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000336, mae: 0.018759, mean_q: 0.006323
 16345/100000: episode: 2277, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000683, mae: 0.016932, mean_q: 0.026163
 16349/100000: episode: 2278, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000237, mae: 0.011905, mean_q: 0.017205
 16356/100000: episode: 2279, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001493, mae: 0.018098, mean_q: 0.022960
 16358/100000: episode: 2280, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000230, mae: 0.009720, mean_q: 0.007236
 16365/100000: episode: 2281, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.002990, mae: 0.023753, mean_q: 0.027891
 16372/100000: episode: 2282, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000743, mae: 0.020193, mean_q: 0.019756
 16376/100000: episode: 2283, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000710, mae: 0.017223, mean_q: 0.016653
 16383/100000: episode: 2284, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000827, mae: 0.019935, mean_q: 0.018323
 16390/100000: episode: 2285, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000205, mae: 0.010858, mean_q: 0.016829
 16397/100000: episode: 2286, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000784, mae: 0.016637, mean_q: 0.021022
 16404/100000: episode: 2287, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002389, mae: 0.021781, mean_q: 0.022075
 16406/100000: episode: 2288, duration: 0.014s, episode steps: 2, steps per second: 143, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000454, mae: 0.022439, mean_q: 0.035662
 16410/100000: episode: 2289, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.003166, mae: 0.025740, mean_q: 0.016395
 16412/100000: episode: 2290, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000189, mae: 0.010775, mean_q: 0.023024
 16419/100000: episode: 2291, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000805, mae: 0.014402, mean_q: 0.019436
 16426/100000: episode: 2292, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.002152, mae: 0.020592, mean_q: 0.025812
 16433/100000: episode: 2293, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000517, mae: 0.015677, mean_q: 0.014351
 16440/100000: episode: 2294, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000657, mae: 0.016206, mean_q: 0.016237
 16447/100000: episode: 2295, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.002038, mae: 0.025331, mean_q: 0.023467
 16454/100000: episode: 2296, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000583, mae: 0.018398, mean_q: 0.026429
 16461/100000: episode: 2297, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000544, mae: 0.014228, mean_q: 0.019606
 16468/100000: episode: 2298, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000864, mae: 0.018742, mean_q: 0.018454
 16475/100000: episode: 2299, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000456, mae: 0.016333, mean_q: 0.021984
 16482/100000: episode: 2300, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000896, mae: 0.015809, mean_q: 0.018714
 16484/100000: episode: 2301, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000181, mae: 0.009732, mean_q: 0.010632
 16488/100000: episode: 2302, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000476, mae: 0.013882, mean_q: 0.015927
 16495/100000: episode: 2303, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000411, mae: 0.013242, mean_q: 0.015756
 16502/100000: episode: 2304, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000377, mae: 0.013895, mean_q: 0.011515
 16509/100000: episode: 2305, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000426, mae: 0.013670, mean_q: 0.016651
 16516/100000: episode: 2306, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000693, mae: 0.014570, mean_q: 0.017878
 16523/100000: episode: 2307, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000535, mae: 0.014872, mean_q: 0.017506
 16530/100000: episode: 2308, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000336, mae: 0.014521, mean_q: 0.017745
 16537/100000: episode: 2309, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.002165, mae: 0.020657, mean_q: 0.021928
 16544/100000: episode: 2310, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000503, mae: 0.015214, mean_q: 0.013244
 16546/100000: episode: 2311, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000072, mae: 0.006389, mean_q: 0.005184
 16553/100000: episode: 2312, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000384, mae: 0.013568, mean_q: 0.015781
 16560/100000: episode: 2313, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000671, mae: 0.018052, mean_q: 0.031013
 16567/100000: episode: 2314, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000375, mae: 0.012515, mean_q: 0.014759
 16569/100000: episode: 2315, duration: 0.012s, episode steps: 2, steps per second: 168, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000254, mae: 0.012055, mean_q: 0.015304
 16571/100000: episode: 2316, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000200, mae: 0.012309, mean_q: 0.016622
 16575/100000: episode: 2317, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001241, mae: 0.018801, mean_q: 0.023812
 16582/100000: episode: 2318, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001783, mae: 0.019046, mean_q: 0.016025
 16586/100000: episode: 2319, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000463, mae: 0.015294, mean_q: 0.028711
 16593/100000: episode: 2320, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000447, mae: 0.015167, mean_q: 0.018087
 16595/100000: episode: 2321, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000490, mae: 0.021608, mean_q: 0.029127
 16602/100000: episode: 2322, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000666, mae: 0.019457, mean_q: 0.014734
 16609/100000: episode: 2323, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000779, mae: 0.017330, mean_q: 0.017967
 16611/100000: episode: 2324, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000379, mae: 0.018948, mean_q: 0.023563
 16615/100000: episode: 2325, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000835, mae: 0.017916, mean_q: 0.013669
 16617/100000: episode: 2326, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000508, mae: 0.015139, mean_q: 0.022298
 16624/100000: episode: 2327, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001429, mae: 0.018963, mean_q: 0.020003
 16626/100000: episode: 2328, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002278, mae: 0.036071, mean_q: 0.060742
 16633/100000: episode: 2329, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000566, mae: 0.019069, mean_q: 0.019998
 16637/100000: episode: 2330, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001215, mae: 0.026285, mean_q: 0.018896
 16644/100000: episode: 2331, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000634, mae: 0.017912, mean_q: 0.017621
 16646/100000: episode: 2332, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001087, mae: 0.022817, mean_q: 0.028410
 16653/100000: episode: 2333, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000636, mae: 0.017991, mean_q: 0.019235
 16657/100000: episode: 2334, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001513, mae: 0.019833, mean_q: 0.025540
 16661/100000: episode: 2335, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000346, mae: 0.013427, mean_q: 0.015969
 16668/100000: episode: 2336, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000637, mae: 0.019377, mean_q: 0.012521
 16675/100000: episode: 2337, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000966, mae: 0.017111, mean_q: 0.022294
 16682/100000: episode: 2338, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.001127, mae: 0.020215, mean_q: 0.020944
 16689/100000: episode: 2339, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000536, mae: 0.017275, mean_q: 0.024011
 16696/100000: episode: 2340, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000904, mae: 0.016191, mean_q: 0.019134
 16698/100000: episode: 2341, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000516, mae: 0.018618, mean_q: 0.009827
 16705/100000: episode: 2342, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000445, mae: 0.013205, mean_q: 0.015474
 16712/100000: episode: 2343, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.002468, mae: 0.022998, mean_q: 0.031460
 16719/100000: episode: 2344, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000723, mae: 0.024036, mean_q: 0.030265
 16721/100000: episode: 2345, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000695, mae: 0.018921, mean_q: 0.012218
 16728/100000: episode: 2346, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001568, mae: 0.020505, mean_q: 0.029786
 16735/100000: episode: 2347, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001002, mae: 0.018503, mean_q: 0.019812
 16742/100000: episode: 2348, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000939, mae: 0.017580, mean_q: 0.021102
 16746/100000: episode: 2349, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000435, mae: 0.012315, mean_q: 0.015258
 16753/100000: episode: 2350, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000623, mae: 0.016811, mean_q: 0.018392
 16760/100000: episode: 2351, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000661, mae: 0.018775, mean_q: 0.025099
[Info] Complete ISplit Iteration
[Info] Levels: [0.012824461, 0.66686517]
[Info] Cond. Prob: [0.11, 0.01]
[Info] Error Prob: 0.0011

 16767/100000: episode: 2352, duration: 0.838s, episode steps: 7, steps per second: 8, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000346, mae: 0.012531, mean_q: 0.014789
 16777/100000: episode: 2353, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000434, mae: 0.016081, mean_q: 0.014917
 16787/100000: episode: 2354, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000793, mae: 0.018295, mean_q: 0.022018
 16797/100000: episode: 2355, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001393, mae: 0.025738, mean_q: 0.029776
 16807/100000: episode: 2356, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000923, mae: 0.018011, mean_q: 0.020095
 16817/100000: episode: 2357, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000415, mae: 0.015196, mean_q: 0.019472
 16827/100000: episode: 2358, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000606, mae: 0.017619, mean_q: 0.012216
 16837/100000: episode: 2359, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000864, mae: 0.022751, mean_q: 0.020009
 16847/100000: episode: 2360, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000740, mae: 0.020553, mean_q: 0.023000
 16857/100000: episode: 2361, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000407, mae: 0.013544, mean_q: 0.015156
 16867/100000: episode: 2362, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000888, mae: 0.023186, mean_q: 0.029314
 16877/100000: episode: 2363, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001273, mae: 0.022082, mean_q: 0.031354
 16887/100000: episode: 2364, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000935, mae: 0.018687, mean_q: 0.019572
 16897/100000: episode: 2365, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000639, mae: 0.017614, mean_q: 0.013509
 16907/100000: episode: 2366, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000860, mae: 0.017705, mean_q: 0.022536
 16917/100000: episode: 2367, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000950, mae: 0.020828, mean_q: 0.020996
 16927/100000: episode: 2368, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001660, mae: 0.018701, mean_q: 0.026789
 16937/100000: episode: 2369, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000713, mae: 0.024004, mean_q: 0.022529
 16947/100000: episode: 2370, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000541, mae: 0.019203, mean_q: 0.020330
 16957/100000: episode: 2371, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000864, mae: 0.021380, mean_q: 0.021092
 16967/100000: episode: 2372, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000775, mae: 0.019572, mean_q: 0.021869
 16977/100000: episode: 2373, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001829, mae: 0.024775, mean_q: 0.022898
 16987/100000: episode: 2374, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001811, mae: 0.025084, mean_q: 0.024644
 16997/100000: episode: 2375, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001059, mae: 0.028936, mean_q: 0.020485
 17007/100000: episode: 2376, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000934, mae: 0.021016, mean_q: 0.021295
 17017/100000: episode: 2377, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000554, mae: 0.016481, mean_q: 0.023001
 17027/100000: episode: 2378, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001052, mae: 0.020575, mean_q: 0.027691
 17037/100000: episode: 2379, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000777, mae: 0.020024, mean_q: 0.024320
 17047/100000: episode: 2380, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000729, mae: 0.017725, mean_q: 0.024127
 17057/100000: episode: 2381, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001822, mae: 0.019367, mean_q: 0.025130
 17067/100000: episode: 2382, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000710, mae: 0.022856, mean_q: 0.022907
 17077/100000: episode: 2383, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000566, mae: 0.019187, mean_q: 0.017916
 17087/100000: episode: 2384, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001105, mae: 0.024783, mean_q: 0.023793
 17097/100000: episode: 2385, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000691, mae: 0.019557, mean_q: 0.020151
 17107/100000: episode: 2386, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001263, mae: 0.024879, mean_q: 0.024646
 17117/100000: episode: 2387, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001029, mae: 0.021498, mean_q: 0.024601
 17127/100000: episode: 2388, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000435, mae: 0.015164, mean_q: 0.018787
 17137/100000: episode: 2389, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001142, mae: 0.021024, mean_q: 0.028465
 17147/100000: episode: 2390, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000468, mae: 0.016238, mean_q: 0.016787
 17157/100000: episode: 2391, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000881, mae: 0.019427, mean_q: 0.025456
 17167/100000: episode: 2392, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000625, mae: 0.020893, mean_q: 0.023045
 17177/100000: episode: 2393, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001641, mae: 0.024536, mean_q: 0.030456
 17187/100000: episode: 2394, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001276, mae: 0.024758, mean_q: 0.024360
 17197/100000: episode: 2395, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001147, mae: 0.023459, mean_q: 0.018962
 17207/100000: episode: 2396, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000863, mae: 0.020810, mean_q: 0.020482
 17217/100000: episode: 2397, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001444, mae: 0.017266, mean_q: 0.021328
 17227/100000: episode: 2398, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000733, mae: 0.020588, mean_q: 0.017485
 17237/100000: episode: 2399, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000457, mae: 0.017088, mean_q: 0.018433
 17247/100000: episode: 2400, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000691, mae: 0.020369, mean_q: 0.018042
 17257/100000: episode: 2401, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001915, mae: 0.026488, mean_q: 0.022176
 17267/100000: episode: 2402, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000825, mae: 0.023638, mean_q: 0.019093
 17277/100000: episode: 2403, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000638, mae: 0.020309, mean_q: 0.015691
 17287/100000: episode: 2404, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000524, mae: 0.016201, mean_q: 0.018177
 17297/100000: episode: 2405, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000581, mae: 0.016902, mean_q: 0.017504
 17307/100000: episode: 2406, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000704, mae: 0.018523, mean_q: 0.022580
 17317/100000: episode: 2407, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000553, mae: 0.017874, mean_q: 0.018028
 17327/100000: episode: 2408, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000794, mae: 0.021269, mean_q: 0.028277
 17337/100000: episode: 2409, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001642, mae: 0.024612, mean_q: 0.029535
 17347/100000: episode: 2410, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000589, mae: 0.018978, mean_q: 0.012791
 17357/100000: episode: 2411, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000549, mae: 0.016062, mean_q: 0.014694
 17367/100000: episode: 2412, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001550, mae: 0.019143, mean_q: 0.023673
 17377/100000: episode: 2413, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000615, mae: 0.017073, mean_q: 0.023543
 17387/100000: episode: 2414, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000349, mae: 0.012197, mean_q: 0.011790
 17397/100000: episode: 2415, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000521, mae: 0.014267, mean_q: 0.016528
 17407/100000: episode: 2416, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000461, mae: 0.013973, mean_q: 0.018407
 17417/100000: episode: 2417, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001900, mae: 0.023639, mean_q: 0.027004
 17427/100000: episode: 2418, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000967, mae: 0.020702, mean_q: 0.021009
 17437/100000: episode: 2419, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000884, mae: 0.018243, mean_q: 0.019107
 17447/100000: episode: 2420, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000657, mae: 0.017951, mean_q: 0.021821
 17457/100000: episode: 2421, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000508, mae: 0.017885, mean_q: 0.020335
 17467/100000: episode: 2422, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000744, mae: 0.023494, mean_q: 0.018081
 17477/100000: episode: 2423, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000655, mae: 0.021957, mean_q: 0.017825
 17487/100000: episode: 2424, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001867, mae: 0.021320, mean_q: 0.023005
 17497/100000: episode: 2425, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000841, mae: 0.021898, mean_q: 0.022665
 17507/100000: episode: 2426, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000756, mae: 0.021052, mean_q: 0.018052
 17517/100000: episode: 2427, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000751, mae: 0.020413, mean_q: 0.023570
 17527/100000: episode: 2428, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000734, mae: 0.020752, mean_q: 0.022393
 17537/100000: episode: 2429, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000563, mae: 0.017944, mean_q: 0.013278
 17547/100000: episode: 2430, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001090, mae: 0.023357, mean_q: 0.021077
 17557/100000: episode: 2431, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000707, mae: 0.016215, mean_q: 0.023707
 17567/100000: episode: 2432, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001177, mae: 0.018226, mean_q: 0.022706
 17577/100000: episode: 2433, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000773, mae: 0.020606, mean_q: 0.021807
 17587/100000: episode: 2434, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000402, mae: 0.017329, mean_q: 0.014745
 17597/100000: episode: 2435, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000672, mae: 0.014127, mean_q: 0.015482
 17607/100000: episode: 2436, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000747, mae: 0.021231, mean_q: 0.022856
 17617/100000: episode: 2437, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000792, mae: 0.024158, mean_q: 0.018007
 17627/100000: episode: 2438, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002201, mae: 0.021976, mean_q: 0.021396
 17637/100000: episode: 2439, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000834, mae: 0.023587, mean_q: 0.020000
 17647/100000: episode: 2440, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000706, mae: 0.019923, mean_q: 0.022667
 17657/100000: episode: 2441, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001048, mae: 0.018938, mean_q: 0.021429
 17667/100000: episode: 2442, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001566, mae: 0.027623, mean_q: 0.030604
 17677/100000: episode: 2443, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001509, mae: 0.025301, mean_q: 0.018959
 17687/100000: episode: 2444, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000681, mae: 0.021023, mean_q: 0.022276
 17697/100000: episode: 2445, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000649, mae: 0.018527, mean_q: 0.021498
 17707/100000: episode: 2446, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000771, mae: 0.021223, mean_q: 0.023949
 17717/100000: episode: 2447, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000780, mae: 0.025228, mean_q: 0.020938
 17727/100000: episode: 2448, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001947, mae: 0.022416, mean_q: 0.022934
 17737/100000: episode: 2449, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000715, mae: 0.024473, mean_q: 0.014752
 17747/100000: episode: 2450, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000593, mae: 0.015870, mean_q: 0.021408
 17757/100000: episode: 2451, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000546, mae: 0.014178, mean_q: 0.019553
[Info] 1-TH LEVEL FOUND: 0.037977173924446106, Considering 13/100 traces
 17767/100000: episode: 2452, duration: 0.704s, episode steps: 10, steps per second: 14, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000743, mae: 0.017201, mean_q: 0.017365
 17771/100000: episode: 2453, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001255, mae: 0.022934, mean_q: 0.034094
 17778/100000: episode: 2454, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002052, mae: 0.021541, mean_q: 0.019993
 17782/100000: episode: 2455, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000837, mae: 0.017469, mean_q: 0.028667
 17789/100000: episode: 2456, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000595, mae: 0.016469, mean_q: 0.016465
 17796/100000: episode: 2457, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002099, mae: 0.020994, mean_q: 0.026427
 17803/100000: episode: 2458, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000494, mae: 0.015389, mean_q: 0.017438
 17810/100000: episode: 2459, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000485, mae: 0.015882, mean_q: 0.023028
 17817/100000: episode: 2460, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.002164, mae: 0.023983, mean_q: 0.029590
 17824/100000: episode: 2461, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001221, mae: 0.023874, mean_q: 0.021520
 17828/100000: episode: 2462, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001242, mae: 0.013693, mean_q: 0.013474
 17832/100000: episode: 2463, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000541, mae: 0.016615, mean_q: 0.024290
 17839/100000: episode: 2464, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000651, mae: 0.017620, mean_q: 0.016358
 17846/100000: episode: 2465, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000568, mae: 0.018622, mean_q: 0.014208
 17850/100000: episode: 2466, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000686, mae: 0.019908, mean_q: 0.008403
 17857/100000: episode: 2467, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.002048, mae: 0.023107, mean_q: 0.027572
 17864/100000: episode: 2468, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000472, mae: 0.017231, mean_q: 0.019457
 17871/100000: episode: 2469, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000986, mae: 0.022242, mean_q: 0.014968
 17878/100000: episode: 2470, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.001105, mae: 0.022848, mean_q: 0.017824
 17882/100000: episode: 2471, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001228, mae: 0.027415, mean_q: 0.042645
 17886/100000: episode: 2472, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000757, mae: 0.019063, mean_q: 0.010900
 17893/100000: episode: 2473, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000464, mae: 0.016428, mean_q: 0.017546
 17897/100000: episode: 2474, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000691, mae: 0.017176, mean_q: 0.026271
 17901/100000: episode: 2475, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003188, mae: 0.026410, mean_q: 0.015990
 17905/100000: episode: 2476, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001309, mae: 0.028803, mean_q: 0.040271
 17912/100000: episode: 2477, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000795, mae: 0.023211, mean_q: 0.015806
 17919/100000: episode: 2478, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001131, mae: 0.021219, mean_q: 0.017501
 17926/100000: episode: 2479, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000642, mae: 0.018454, mean_q: 0.021774
 17933/100000: episode: 2480, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000476, mae: 0.015773, mean_q: 0.022169
 17937/100000: episode: 2481, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000303, mae: 0.013773, mean_q: 0.005941
 17941/100000: episode: 2482, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000588, mae: 0.020039, mean_q: 0.023408
 17945/100000: episode: 2483, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000367, mae: 0.015124, mean_q: 0.021661
 17949/100000: episode: 2484, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001181, mae: 0.022967, mean_q: 0.022917
 17953/100000: episode: 2485, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.003425, mae: 0.026515, mean_q: 0.031459
[Info] FALSIFICATION!
 17959/100000: episode: 2486, duration: 0.261s, episode steps: 6, steps per second: 23, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.001005, mae: 0.021591, mean_q: 0.012189
 17963/100000: episode: 2487, duration: 0.024s, episode steps: 4, steps per second: 170, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001212, mae: 0.028119, mean_q: 0.042582
 17970/100000: episode: 2488, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 1.947, mean reward: 0.278 [0.007, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 7.857 [5.000, 11.000], loss: 0.000692, mae: 0.019018, mean_q: 0.021249
 17977/100000: episode: 2489, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000526, mae: 0.016264, mean_q: 0.021585
 17981/100000: episode: 2490, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001496, mae: 0.018767, mean_q: 0.027401
 17985/100000: episode: 2491, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000774, mae: 0.016193, mean_q: 0.020420
 17992/100000: episode: 2492, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000542, mae: 0.013858, mean_q: 0.021742
 17999/100000: episode: 2493, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000524, mae: 0.017176, mean_q: 0.010475
 18003/100000: episode: 2494, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000428, mae: 0.015159, mean_q: 0.011511
 18007/100000: episode: 2495, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000869, mae: 0.023529, mean_q: 0.027210
 18014/100000: episode: 2496, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000841, mae: 0.017123, mean_q: 0.023353
 18021/100000: episode: 2497, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000507, mae: 0.016925, mean_q: 0.011820
 18028/100000: episode: 2498, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000799, mae: 0.018948, mean_q: 0.022531
 18032/100000: episode: 2499, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.003733, mae: 0.028028, mean_q: 0.031811
 18039/100000: episode: 2500, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000885, mae: 0.027679, mean_q: 0.023182
 18046/100000: episode: 2501, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000789, mae: 0.021840, mean_q: 0.022608
 18053/100000: episode: 2502, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001937, mae: 0.025505, mean_q: 0.031421
 18057/100000: episode: 2503, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000877, mae: 0.027331, mean_q: 0.000683
 18064/100000: episode: 2504, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000850, mae: 0.019931, mean_q: 0.021015
 18071/100000: episode: 2505, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001459, mae: 0.025781, mean_q: 0.029702
 18078/100000: episode: 2506, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001315, mae: 0.025207, mean_q: 0.016685
 18085/100000: episode: 2507, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000420, mae: 0.013478, mean_q: 0.017441
 18092/100000: episode: 2508, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000433, mae: 0.012010, mean_q: 0.014798
 18099/100000: episode: 2509, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.001072, mae: 0.021658, mean_q: 0.023461
 18106/100000: episode: 2510, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.002287, mae: 0.021838, mean_q: 0.026558
 18113/100000: episode: 2511, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000820, mae: 0.023901, mean_q: 0.012537
 18120/100000: episode: 2512, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000886, mae: 0.022152, mean_q: 0.023513
 18127/100000: episode: 2513, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000614, mae: 0.017326, mean_q: 0.019395
 18134/100000: episode: 2514, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001193, mae: 0.022461, mean_q: 0.033669
 18138/100000: episode: 2515, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000299, mae: 0.014598, mean_q: 0.008092
 18145/100000: episode: 2516, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001026, mae: 0.025357, mean_q: 0.029954
 18149/100000: episode: 2517, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000566, mae: 0.022428, mean_q: 0.020340
 18153/100000: episode: 2518, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000943, mae: 0.026042, mean_q: 0.017638
 18157/100000: episode: 2519, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000481, mae: 0.019064, mean_q: 0.018658
 18164/100000: episode: 2520, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000869, mae: 0.025313, mean_q: 0.017139
 18171/100000: episode: 2521, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000681, mae: 0.018487, mean_q: 0.024231
 18175/100000: episode: 2522, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001288, mae: 0.017252, mean_q: 0.024466
 18182/100000: episode: 2523, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000527, mae: 0.013951, mean_q: 0.017603
 18189/100000: episode: 2524, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000712, mae: 0.016771, mean_q: 0.018583
 18196/100000: episode: 2525, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000363, mae: 0.014539, mean_q: 0.009082
 18203/100000: episode: 2526, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000628, mae: 0.014732, mean_q: 0.018475
 18207/100000: episode: 2527, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000943, mae: 0.018205, mean_q: 0.026987
 18214/100000: episode: 2528, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001029, mae: 0.022562, mean_q: 0.029861
 18218/100000: episode: 2529, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000357, mae: 0.014839, mean_q: 0.013393
 18225/100000: episode: 2530, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000300, mae: 0.013173, mean_q: 0.012719
 18232/100000: episode: 2531, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000954, mae: 0.017513, mean_q: 0.021839
 18236/100000: episode: 2532, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000856, mae: 0.014758, mean_q: 0.019430
 18243/100000: episode: 2533, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000335, mae: 0.015176, mean_q: 0.012731
 18247/100000: episode: 2534, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000171, mae: 0.009996, mean_q: 0.015999
 18254/100000: episode: 2535, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000419, mae: 0.013259, mean_q: 0.015370
 18258/100000: episode: 2536, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003040, mae: 0.019706, mean_q: 0.017322
 18262/100000: episode: 2537, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000524, mae: 0.018576, mean_q: 0.023300
 18269/100000: episode: 2538, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.000258, mae: 0.014623, mean_q: 0.009984
[Info] Complete ISplit Iteration
[Info] Levels: [0.037977174, 0.7403153]
[Info] Cond. Prob: [0.13, 0.01]
[Info] Error Prob: 0.0013000000000000002

 18276/100000: episode: 2539, duration: 0.743s, episode steps: 7, steps per second: 9, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000579, mae: 0.015587, mean_q: 0.011898
 18286/100000: episode: 2540, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000600, mae: 0.014787, mean_q: 0.014599
 18296/100000: episode: 2541, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000402, mae: 0.012869, mean_q: 0.011925
 18306/100000: episode: 2542, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000456, mae: 0.015626, mean_q: 0.017555
 18316/100000: episode: 2543, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000547, mae: 0.016320, mean_q: 0.022219
 18326/100000: episode: 2544, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000530, mae: 0.017170, mean_q: 0.021034
 18336/100000: episode: 2545, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000406, mae: 0.015105, mean_q: 0.016424
 18346/100000: episode: 2546, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000427, mae: 0.016935, mean_q: 0.018228
 18356/100000: episode: 2547, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000480, mae: 0.013973, mean_q: 0.015740
 18366/100000: episode: 2548, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000355, mae: 0.013250, mean_q: 0.015082
 18376/100000: episode: 2549, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000753, mae: 0.012846, mean_q: 0.018141
 18386/100000: episode: 2550, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000303, mae: 0.015042, mean_q: 0.009289
 18396/100000: episode: 2551, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000556, mae: 0.019050, mean_q: 0.014319
 18406/100000: episode: 2552, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001739, mae: 0.021208, mean_q: 0.019473
 18416/100000: episode: 2553, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000660, mae: 0.018219, mean_q: 0.015448
 18426/100000: episode: 2554, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000524, mae: 0.020688, mean_q: 0.014735
 18436/100000: episode: 2555, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000828, mae: 0.020516, mean_q: 0.016875
 18446/100000: episode: 2556, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000370, mae: 0.019226, mean_q: 0.009926
 18456/100000: episode: 2557, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000258, mae: 0.014353, mean_q: 0.012746
 18466/100000: episode: 2558, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000250, mae: 0.010679, mean_q: 0.014515
 18476/100000: episode: 2559, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000366, mae: 0.013348, mean_q: 0.015028
 18486/100000: episode: 2560, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000355, mae: 0.014959, mean_q: 0.013698
 18496/100000: episode: 2561, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000343, mae: 0.015776, mean_q: 0.011858
 18506/100000: episode: 2562, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000844, mae: 0.016030, mean_q: 0.017961
 18516/100000: episode: 2563, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000354, mae: 0.013235, mean_q: 0.013625
 18526/100000: episode: 2564, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000503, mae: 0.016550, mean_q: 0.020720
 18536/100000: episode: 2565, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000710, mae: 0.019292, mean_q: 0.017389
 18546/100000: episode: 2566, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000528, mae: 0.020684, mean_q: 0.011328
 18556/100000: episode: 2567, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000810, mae: 0.018187, mean_q: 0.018583
 18566/100000: episode: 2568, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000477, mae: 0.015681, mean_q: 0.019592
 18576/100000: episode: 2569, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000793, mae: 0.018038, mean_q: 0.018159
 18586/100000: episode: 2570, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000415, mae: 0.013501, mean_q: 0.014499
 18596/100000: episode: 2571, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000439, mae: 0.014295, mean_q: 0.017999
 18606/100000: episode: 2572, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001447, mae: 0.021127, mean_q: 0.018176
 18616/100000: episode: 2573, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000575, mae: 0.014668, mean_q: 0.017616
 18626/100000: episode: 2574, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000462, mae: 0.015556, mean_q: 0.018254
 18636/100000: episode: 2575, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000485, mae: 0.011556, mean_q: 0.017158
 18646/100000: episode: 2576, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000908, mae: 0.021036, mean_q: 0.019313
 18656/100000: episode: 2577, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000573, mae: 0.019028, mean_q: 0.016659
 18666/100000: episode: 2578, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000336, mae: 0.014355, mean_q: 0.017056
 18676/100000: episode: 2579, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000425, mae: 0.015707, mean_q: 0.016025
 18686/100000: episode: 2580, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000324, mae: 0.013012, mean_q: 0.014620
 18696/100000: episode: 2581, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000276, mae: 0.013403, mean_q: 0.015432
 18706/100000: episode: 2582, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000449, mae: 0.013327, mean_q: 0.013130
 18716/100000: episode: 2583, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000481, mae: 0.014650, mean_q: 0.017100
 18726/100000: episode: 2584, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001349, mae: 0.015769, mean_q: 0.017963
 18736/100000: episode: 2585, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000364, mae: 0.013185, mean_q: 0.016054
 18746/100000: episode: 2586, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000403, mae: 0.013181, mean_q: 0.014859
 18756/100000: episode: 2587, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000386, mae: 0.012567, mean_q: 0.017380
 18766/100000: episode: 2588, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000528, mae: 0.015506, mean_q: 0.017628
 18776/100000: episode: 2589, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000812, mae: 0.014906, mean_q: 0.015385
 18786/100000: episode: 2590, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000463, mae: 0.018487, mean_q: 0.011977
 18796/100000: episode: 2591, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001399, mae: 0.017849, mean_q: 0.020665
 18806/100000: episode: 2592, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000449, mae: 0.015301, mean_q: 0.017308
 18816/100000: episode: 2593, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000562, mae: 0.019605, mean_q: 0.014763
 18826/100000: episode: 2594, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000501, mae: 0.015263, mean_q: 0.013766
 18836/100000: episode: 2595, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000409, mae: 0.014615, mean_q: 0.016248
 18846/100000: episode: 2596, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001455, mae: 0.022784, mean_q: 0.027044
 18856/100000: episode: 2597, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000622, mae: 0.015734, mean_q: 0.015813
 18866/100000: episode: 2598, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000455, mae: 0.014837, mean_q: 0.016974
 18876/100000: episode: 2599, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000733, mae: 0.019823, mean_q: 0.022008
 18886/100000: episode: 2600, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000323, mae: 0.015806, mean_q: 0.013574
 18896/100000: episode: 2601, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000346, mae: 0.014675, mean_q: 0.010586
 18906/100000: episode: 2602, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000459, mae: 0.016728, mean_q: 0.016691
 18916/100000: episode: 2603, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001238, mae: 0.014290, mean_q: 0.017058
 18926/100000: episode: 2604, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000367, mae: 0.016427, mean_q: 0.015641
 18936/100000: episode: 2605, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000480, mae: 0.017956, mean_q: 0.015698
 18946/100000: episode: 2606, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000239, mae: 0.012631, mean_q: 0.012629
 18956/100000: episode: 2607, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000652, mae: 0.016266, mean_q: 0.017613
 18966/100000: episode: 2608, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001229, mae: 0.019075, mean_q: 0.020852
 18976/100000: episode: 2609, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000591, mae: 0.018098, mean_q: 0.017253
 18986/100000: episode: 2610, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000604, mae: 0.019401, mean_q: 0.014919
 18996/100000: episode: 2611, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000680, mae: 0.016055, mean_q: 0.016203
 19006/100000: episode: 2612, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000450, mae: 0.016447, mean_q: 0.013401
 19016/100000: episode: 2613, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000519, mae: 0.019802, mean_q: 0.016338
 19026/100000: episode: 2614, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000546, mae: 0.019543, mean_q: 0.015619
 19036/100000: episode: 2615, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000440, mae: 0.018937, mean_q: 0.016354
 19046/100000: episode: 2616, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000639, mae: 0.018528, mean_q: 0.014869
 19056/100000: episode: 2617, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000398, mae: 0.016124, mean_q: 0.017279
 19066/100000: episode: 2618, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000341, mae: 0.013060, mean_q: 0.014455
 19076/100000: episode: 2619, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000280, mae: 0.010618, mean_q: 0.013749
 19086/100000: episode: 2620, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000367, mae: 0.013085, mean_q: 0.017450
 19096/100000: episode: 2621, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001379, mae: 0.021451, mean_q: 0.020868
 19106/100000: episode: 2622, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001648, mae: 0.029325, mean_q: 0.018601
 19116/100000: episode: 2623, duration: 0.055s, episode steps: 10, steps per second: 180, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000563, mae: 0.022007, mean_q: 0.012376
 19126/100000: episode: 2624, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000512, mae: 0.015989, mean_q: 0.014308
 19136/100000: episode: 2625, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000264, mae: 0.012168, mean_q: 0.013537
 19146/100000: episode: 2626, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000919, mae: 0.015249, mean_q: 0.017317
 19156/100000: episode: 2627, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001580, mae: 0.021393, mean_q: 0.021973
 19166/100000: episode: 2628, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000469, mae: 0.018712, mean_q: 0.009225
 19176/100000: episode: 2629, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000467, mae: 0.015982, mean_q: 0.017431
 19186/100000: episode: 2630, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000440, mae: 0.013069, mean_q: 0.010951
 19196/100000: episode: 2631, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002045, mae: 0.026251, mean_q: 0.023751
 19206/100000: episode: 2632, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000374, mae: 0.015364, mean_q: 0.015701
 19216/100000: episode: 2633, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000285, mae: 0.012801, mean_q: 0.013339
 19226/100000: episode: 2634, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000506, mae: 0.015080, mean_q: 0.017355
 19236/100000: episode: 2635, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000350, mae: 0.013472, mean_q: 0.015247
 19246/100000: episode: 2636, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001250, mae: 0.012809, mean_q: 0.014026
 19256/100000: episode: 2637, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000431, mae: 0.019722, mean_q: 0.011773
 19266/100000: episode: 2638, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000516, mae: 0.019425, mean_q: 0.016218
[Info] 1-TH LEVEL FOUND: 0.030836299061775208, Considering 10/100 traces
 19276/100000: episode: 2639, duration: 0.673s, episode steps: 10, steps per second: 15, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000253, mae: 0.012177, mean_q: 0.012930
 19283/100000: episode: 2640, duration: 0.038s, episode steps: 7, steps per second: 184, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000184, mae: 0.010213, mean_q: 0.013418
 19290/100000: episode: 2641, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000308, mae: 0.011920, mean_q: 0.018722
 19297/100000: episode: 2642, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000530, mae: 0.012512, mean_q: 0.017068
 19304/100000: episode: 2643, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000246, mae: 0.011086, mean_q: 0.011465
 19311/100000: episode: 2644, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000730, mae: 0.016826, mean_q: 0.021338
 19318/100000: episode: 2645, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000561, mae: 0.012849, mean_q: 0.017533
 19325/100000: episode: 2646, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000214, mae: 0.011191, mean_q: 0.011117
 19329/100000: episode: 2647, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000416, mae: 0.013595, mean_q: 0.020200
 19336/100000: episode: 2648, duration: 0.038s, episode steps: 7, steps per second: 185, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.001918, mae: 0.020463, mean_q: 0.025817
 19343/100000: episode: 2649, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000305, mae: 0.012206, mean_q: 0.014205
 19350/100000: episode: 2650, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000400, mae: 0.017109, mean_q: 0.019868
 19354/100000: episode: 2651, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000243, mae: 0.014493, mean_q: -0.000524
 19361/100000: episode: 2652, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000700, mae: 0.018088, mean_q: 0.019043
 19368/100000: episode: 2653, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001848, mae: 0.022701, mean_q: 0.025076
 19372/100000: episode: 2654, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000410, mae: 0.014562, mean_q: 0.018804
 19379/100000: episode: 2655, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000355, mae: 0.014903, mean_q: 0.005369
 19383/100000: episode: 2656, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000291, mae: 0.014961, mean_q: 0.017044
 19390/100000: episode: 2657, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000619, mae: 0.013470, mean_q: 0.018477
 19394/100000: episode: 2658, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000663, mae: 0.020862, mean_q: 0.015996
 19401/100000: episode: 2659, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000364, mae: 0.013691, mean_q: 0.016445
 19408/100000: episode: 2660, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000309, mae: 0.014195, mean_q: 0.016153
 19415/100000: episode: 2661, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000290, mae: 0.014285, mean_q: 0.016690
 19419/100000: episode: 2662, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003140, mae: 0.030428, mean_q: 0.026985
 19426/100000: episode: 2663, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000994, mae: 0.023786, mean_q: 0.014079
 19433/100000: episode: 2664, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000546, mae: 0.020802, mean_q: 0.007249
 19440/100000: episode: 2665, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000466, mae: 0.016223, mean_q: 0.015505
 19447/100000: episode: 2666, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000947, mae: 0.023272, mean_q: 0.019402
 19454/100000: episode: 2667, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000728, mae: 0.014821, mean_q: 0.017512
 19461/100000: episode: 2668, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000489, mae: 0.015802, mean_q: 0.024543
 19468/100000: episode: 2669, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001081, mae: 0.021436, mean_q: 0.023979
 19475/100000: episode: 2670, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000461, mae: 0.014050, mean_q: 0.017853
 19482/100000: episode: 2671, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000295, mae: 0.011424, mean_q: 0.015190
 19489/100000: episode: 2672, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000283, mae: 0.011792, mean_q: 0.013929
 19493/100000: episode: 2673, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000346, mae: 0.011832, mean_q: 0.013332
 19500/100000: episode: 2674, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000839, mae: 0.015445, mean_q: 0.015405
 19504/100000: episode: 2675, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000339, mae: 0.017037, mean_q: 0.019690
[Info] FALSIFICATION!
 19510/100000: episode: 2676, duration: 0.176s, episode steps: 6, steps per second: 34, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000344, mae: 0.013464, mean_q: 0.012175
 19517/100000: episode: 2677, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000349, mae: 0.013316, mean_q: 0.012389
 19524/100000: episode: 2678, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000425, mae: 0.014642, mean_q: 0.017617
 19531/100000: episode: 2679, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000718, mae: 0.019351, mean_q: 0.017999
 19538/100000: episode: 2680, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000418, mae: 0.014771, mean_q: 0.014110
 19545/100000: episode: 2681, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000291, mae: 0.015450, mean_q: 0.012822
[Info] FALSIFICATION!
 19551/100000: episode: 2682, duration: 0.236s, episode steps: 6, steps per second: 25, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000475, mae: 0.017981, mean_q: 0.013519
 19558/100000: episode: 2683, duration: 0.046s, episode steps: 7, steps per second: 153, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000475, mae: 0.014468, mean_q: 0.012639
 19565/100000: episode: 2684, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000675, mae: 0.018444, mean_q: 0.020937
 19569/100000: episode: 2685, duration: 0.030s, episode steps: 4, steps per second: 135, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000362, mae: 0.016524, mean_q: 0.020231
 19576/100000: episode: 2686, duration: 0.059s, episode steps: 7, steps per second: 118, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000382, mae: 0.014489, mean_q: 0.007275
 19583/100000: episode: 2687, duration: 0.042s, episode steps: 7, steps per second: 167, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000656, mae: 0.017164, mean_q: 0.019927
 19590/100000: episode: 2688, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000254, mae: 0.011847, mean_q: 0.015647
 19597/100000: episode: 2689, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000409, mae: 0.014691, mean_q: 0.015071
 19604/100000: episode: 2690, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002168, mae: 0.018755, mean_q: 0.023042
 19611/100000: episode: 2691, duration: 0.045s, episode steps: 7, steps per second: 156, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000249, mae: 0.013758, mean_q: 0.009992
 19618/100000: episode: 2692, duration: 0.041s, episode steps: 7, steps per second: 169, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000314, mae: 0.011555, mean_q: 0.017579
 19625/100000: episode: 2693, duration: 0.066s, episode steps: 7, steps per second: 106, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000676, mae: 0.019491, mean_q: 0.023983
 19632/100000: episode: 2694, duration: 0.073s, episode steps: 7, steps per second: 96, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000615, mae: 0.015223, mean_q: 0.020457
 19639/100000: episode: 2695, duration: 0.061s, episode steps: 7, steps per second: 116, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000394, mae: 0.012885, mean_q: 0.015916
 19646/100000: episode: 2696, duration: 0.040s, episode steps: 7, steps per second: 175, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000518, mae: 0.014182, mean_q: 0.021186
 19653/100000: episode: 2697, duration: 0.037s, episode steps: 7, steps per second: 188, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000630, mae: 0.013120, mean_q: 0.021464
 19660/100000: episode: 2698, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000369, mae: 0.012426, mean_q: 0.008930
 19664/100000: episode: 2699, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000504, mae: 0.015568, mean_q: 0.013274
 19671/100000: episode: 2700, duration: 0.060s, episode steps: 7, steps per second: 116, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.000608, mae: 0.018175, mean_q: 0.023755
 19678/100000: episode: 2701, duration: 0.042s, episode steps: 7, steps per second: 167, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000674, mae: 0.019985, mean_q: 0.016364
 19685/100000: episode: 2702, duration: 0.050s, episode steps: 7, steps per second: 140, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000618, mae: 0.014605, mean_q: 0.018881
 19692/100000: episode: 2703, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001112, mae: 0.022265, mean_q: 0.029969
 19699/100000: episode: 2704, duration: 0.046s, episode steps: 7, steps per second: 154, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000462, mae: 0.019440, mean_q: 0.007564
 19706/100000: episode: 2705, duration: 0.040s, episode steps: 7, steps per second: 175, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000225, mae: 0.011698, mean_q: 0.010097
 19713/100000: episode: 2706, duration: 0.044s, episode steps: 7, steps per second: 160, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000664, mae: 0.014027, mean_q: 0.016575
 19720/100000: episode: 2707, duration: 0.041s, episode steps: 7, steps per second: 172, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000419, mae: 0.014540, mean_q: 0.009751
 19727/100000: episode: 2708, duration: 0.049s, episode steps: 7, steps per second: 143, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000507, mae: 0.018588, mean_q: 0.020852
 19734/100000: episode: 2709, duration: 0.041s, episode steps: 7, steps per second: 169, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000394, mae: 0.018348, mean_q: 0.022764
 19738/100000: episode: 2710, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000389, mae: 0.016227, mean_q: 0.017749
 19745/100000: episode: 2711, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000471, mae: 0.015851, mean_q: 0.015297
 19752/100000: episode: 2712, duration: 0.062s, episode steps: 7, steps per second: 112, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000397, mae: 0.019347, mean_q: 0.015865
 19759/100000: episode: 2713, duration: 0.082s, episode steps: 7, steps per second: 86, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000279, mae: 0.011801, mean_q: 0.011675
 19763/100000: episode: 2714, duration: 0.028s, episode steps: 4, steps per second: 142, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000261, mae: 0.011942, mean_q: 0.013645
 19770/100000: episode: 2715, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000117, mae: 0.007888, mean_q: 0.006832
 19774/100000: episode: 2716, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000374, mae: 0.013644, mean_q: 0.017435
 19781/100000: episode: 2717, duration: 0.038s, episode steps: 7, steps per second: 183, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001839, mae: 0.017569, mean_q: 0.018297
 19788/100000: episode: 2718, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000845, mae: 0.018178, mean_q: 0.016966
 19795/100000: episode: 2719, duration: 0.041s, episode steps: 7, steps per second: 171, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000273, mae: 0.013984, mean_q: 0.010112
 19799/100000: episode: 2720, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000358, mae: 0.013236, mean_q: 0.015387
 19806/100000: episode: 2721, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000379, mae: 0.011450, mean_q: 0.012669
 19810/100000: episode: 2722, duration: 0.047s, episode steps: 4, steps per second: 85, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000373, mae: 0.011769, mean_q: 0.016837
 19817/100000: episode: 2723, duration: 0.068s, episode steps: 7, steps per second: 103, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000756, mae: 0.018557, mean_q: 0.014389
 19824/100000: episode: 2724, duration: 0.038s, episode steps: 7, steps per second: 184, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000329, mae: 0.016537, mean_q: 0.008795
 19831/100000: episode: 2725, duration: 0.037s, episode steps: 7, steps per second: 191, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000295, mae: 0.013631, mean_q: 0.017808
 19838/100000: episode: 2726, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000294, mae: 0.013252, mean_q: 0.013942
 19842/100000: episode: 2727, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000496, mae: 0.017048, mean_q: 0.028779
 19849/100000: episode: 2728, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.002035, mae: 0.021522, mean_q: 0.027606
[Info] FALSIFICATION!
[Info] Complete ISplit Iteration
[Info] Levels: [0.030836299, 0.85735863]
[Info] Cond. Prob: [0.1, 0.03]
[Info] Error Prob: 0.003

 19855/100000: episode: 2729, duration: 1.270s, episode steps: 6, steps per second: 5, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000434, mae: 0.017968, mean_q: 0.009544
 19865/100000: episode: 2730, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000765, mae: 0.022820, mean_q: 0.017700
 19875/100000: episode: 2731, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000440, mae: 0.015545, mean_q: 0.017895
 19885/100000: episode: 2732, duration: 0.083s, episode steps: 10, steps per second: 120, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000419, mae: 0.013769, mean_q: 0.015700
 19895/100000: episode: 2733, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000245, mae: 0.012555, mean_q: 0.010598
 19905/100000: episode: 2734, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000608, mae: 0.016985, mean_q: 0.019116
 19915/100000: episode: 2735, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000395, mae: 0.016555, mean_q: 0.012551
 19925/100000: episode: 2736, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000415, mae: 0.015951, mean_q: 0.012650
 19935/100000: episode: 2737, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000329, mae: 0.015318, mean_q: 0.015299
 19945/100000: episode: 2738, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000266, mae: 0.012269, mean_q: 0.013666
 19955/100000: episode: 2739, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000455, mae: 0.012763, mean_q: 0.016129
 19965/100000: episode: 2740, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000393, mae: 0.015569, mean_q: 0.014079
 19975/100000: episode: 2741, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000542, mae: 0.017202, mean_q: 0.021080
 19985/100000: episode: 2742, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000563, mae: 0.018281, mean_q: 0.020495
 19995/100000: episode: 2743, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000399, mae: 0.016320, mean_q: 0.018325
 20005/100000: episode: 2744, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001242, mae: 0.017360, mean_q: 0.018724
 20015/100000: episode: 2745, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000441, mae: 0.018414, mean_q: 0.012792
 20025/100000: episode: 2746, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000380, mae: 0.013455, mean_q: 0.013481
 20035/100000: episode: 2747, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000487, mae: 0.014295, mean_q: 0.014430
 20045/100000: episode: 2748, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000296, mae: 0.011683, mean_q: 0.013476
 20055/100000: episode: 2749, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000368, mae: 0.013366, mean_q: 0.016202
 20065/100000: episode: 2750, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000539, mae: 0.014366, mean_q: 0.019566
 20075/100000: episode: 2751, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000719, mae: 0.019415, mean_q: 0.020192
 20085/100000: episode: 2752, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000293, mae: 0.012168, mean_q: 0.012075
 20095/100000: episode: 2753, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000434, mae: 0.016739, mean_q: 0.012785
 20105/100000: episode: 2754, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000848, mae: 0.020629, mean_q: 0.023436
 20115/100000: episode: 2755, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000332, mae: 0.014517, mean_q: 0.012604
 20125/100000: episode: 2756, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000869, mae: 0.017846, mean_q: 0.020138
 20135/100000: episode: 2757, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000391, mae: 0.014531, mean_q: 0.014234
 20145/100000: episode: 2758, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000998, mae: 0.020717, mean_q: 0.019949
 20155/100000: episode: 2759, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001447, mae: 0.019291, mean_q: 0.025552
 20165/100000: episode: 2760, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000613, mae: 0.018749, mean_q: 0.019162
 20175/100000: episode: 2761, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000515, mae: 0.015889, mean_q: 0.018354
 20185/100000: episode: 2762, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000265, mae: 0.013676, mean_q: 0.011204
 20195/100000: episode: 2763, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000524, mae: 0.017756, mean_q: 0.021307
 20205/100000: episode: 2764, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000625, mae: 0.016077, mean_q: 0.021426
 20215/100000: episode: 2765, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000594, mae: 0.015999, mean_q: 0.019726
 20225/100000: episode: 2766, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001188, mae: 0.014509, mean_q: 0.015404
 20235/100000: episode: 2767, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000373, mae: 0.012776, mean_q: 0.011700
 20245/100000: episode: 2768, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000438, mae: 0.015860, mean_q: 0.016521
 20255/100000: episode: 2769, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000509, mae: 0.015446, mean_q: 0.021001
 20265/100000: episode: 2770, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000605, mae: 0.017379, mean_q: 0.016643
 20275/100000: episode: 2771, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000455, mae: 0.017797, mean_q: 0.019146
 20285/100000: episode: 2772, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000201, mae: 0.011646, mean_q: 0.013729
 20295/100000: episode: 2773, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000736, mae: 0.014850, mean_q: 0.017921
 20305/100000: episode: 2774, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000502, mae: 0.016178, mean_q: 0.013295
 20315/100000: episode: 2775, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000762, mae: 0.019073, mean_q: 0.013420
 20325/100000: episode: 2776, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000507, mae: 0.015063, mean_q: 0.020067
 20335/100000: episode: 2777, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001114, mae: 0.019017, mean_q: 0.026795
 20345/100000: episode: 2778, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000548, mae: 0.015922, mean_q: 0.021640
 20355/100000: episode: 2779, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000502, mae: 0.012903, mean_q: 0.018093
 20365/100000: episode: 2780, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000583, mae: 0.018130, mean_q: 0.017192
 20375/100000: episode: 2781, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001441, mae: 0.019477, mean_q: 0.021716
 20385/100000: episode: 2782, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000346, mae: 0.013898, mean_q: 0.012038
 20395/100000: episode: 2783, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002239, mae: 0.024447, mean_q: 0.022395
 20405/100000: episode: 2784, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000466, mae: 0.021004, mean_q: 0.014410
 20415/100000: episode: 2785, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000429, mae: 0.017386, mean_q: 0.014986
 20425/100000: episode: 2786, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000520, mae: 0.018893, mean_q: 0.016191
 20435/100000: episode: 2787, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000412, mae: 0.015005, mean_q: 0.013654
 20445/100000: episode: 2788, duration: 0.106s, episode steps: 10, steps per second: 94, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000473, mae: 0.014951, mean_q: 0.015722
 20455/100000: episode: 2789, duration: 0.071s, episode steps: 10, steps per second: 140, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000638, mae: 0.015780, mean_q: 0.020075
 20465/100000: episode: 2790, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000694, mae: 0.018490, mean_q: 0.015401
 20475/100000: episode: 2791, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001315, mae: 0.023948, mean_q: 0.020664
 20485/100000: episode: 2792, duration: 0.085s, episode steps: 10, steps per second: 117, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000695, mae: 0.025127, mean_q: 0.017285
 20495/100000: episode: 2793, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000833, mae: 0.014786, mean_q: 0.015995
 20505/100000: episode: 2794, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001488, mae: 0.024220, mean_q: 0.019467
 20515/100000: episode: 2795, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000606, mae: 0.021695, mean_q: 0.017641
 20525/100000: episode: 2796, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000412, mae: 0.016451, mean_q: 0.014292
 20535/100000: episode: 2797, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000503, mae: 0.014630, mean_q: 0.017409
 20545/100000: episode: 2798, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000541, mae: 0.018143, mean_q: 0.015087
 20555/100000: episode: 2799, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000662, mae: 0.015796, mean_q: 0.017599
 20565/100000: episode: 2800, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000584, mae: 0.016426, mean_q: 0.015258
 20575/100000: episode: 2801, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000479, mae: 0.015185, mean_q: 0.020693
 20585/100000: episode: 2802, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000339, mae: 0.013726, mean_q: 0.016384
 20595/100000: episode: 2803, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000738, mae: 0.016927, mean_q: 0.022354
 20605/100000: episode: 2804, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000308, mae: 0.012295, mean_q: 0.012077
 20615/100000: episode: 2805, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000746, mae: 0.019121, mean_q: 0.023030
 20625/100000: episode: 2806, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000690, mae: 0.017463, mean_q: 0.019276
 20635/100000: episode: 2807, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000538, mae: 0.018331, mean_q: 0.015695
 20645/100000: episode: 2808, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000367, mae: 0.016913, mean_q: 0.012487
 20655/100000: episode: 2809, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000526, mae: 0.021297, mean_q: 0.014247
 20665/100000: episode: 2810, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000706, mae: 0.023103, mean_q: 0.016671
 20675/100000: episode: 2811, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000605, mae: 0.016297, mean_q: 0.020377
 20685/100000: episode: 2812, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000341, mae: 0.014180, mean_q: 0.013371
 20695/100000: episode: 2813, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000349, mae: 0.012916, mean_q: 0.017792
 20705/100000: episode: 2814, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000524, mae: 0.014996, mean_q: 0.016020
 20715/100000: episode: 2815, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000579, mae: 0.014224, mean_q: 0.014756
 20725/100000: episode: 2816, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000528, mae: 0.016078, mean_q: 0.014232
 20735/100000: episode: 2817, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001423, mae: 0.019159, mean_q: 0.024013
 20745/100000: episode: 2818, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000473, mae: 0.016875, mean_q: 0.016209
 20755/100000: episode: 2819, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001293, mae: 0.017815, mean_q: 0.014980
 20765/100000: episode: 2820, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000812, mae: 0.024761, mean_q: 0.018646
 20775/100000: episode: 2821, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000388, mae: 0.014692, mean_q: 0.016260
 20785/100000: episode: 2822, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000350, mae: 0.013467, mean_q: 0.014758
 20795/100000: episode: 2823, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000341, mae: 0.013124, mean_q: 0.013791
 20805/100000: episode: 2824, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000194, mae: 0.010343, mean_q: 0.012155
 20815/100000: episode: 2825, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001554, mae: 0.017195, mean_q: 0.017680
 20825/100000: episode: 2826, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000706, mae: 0.019479, mean_q: 0.025325
 20835/100000: episode: 2827, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000400, mae: 0.015299, mean_q: 0.017068
 20845/100000: episode: 2828, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000437, mae: 0.015740, mean_q: 0.016983
[Info] 1-TH LEVEL FOUND: 0.014494702219963074, Considering 10/100 traces
 20855/100000: episode: 2829, duration: 0.667s, episode steps: 10, steps per second: 15, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000169, mae: 0.008336, mean_q: 0.008669
 20862/100000: episode: 2830, duration: 0.052s, episode steps: 7, steps per second: 133, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001242, mae: 0.018505, mean_q: 0.028219
 20869/100000: episode: 2831, duration: 0.037s, episode steps: 7, steps per second: 188, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000384, mae: 0.014211, mean_q: 0.020197
 20873/100000: episode: 2832, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000405, mae: 0.013904, mean_q: 0.024369
 20880/100000: episode: 2833, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000271, mae: 0.011612, mean_q: 0.012029
 20887/100000: episode: 2834, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000474, mae: 0.013290, mean_q: 0.013464
 20891/100000: episode: 2835, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000393, mae: 0.013223, mean_q: 0.022723
 20895/100000: episode: 2836, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000506, mae: 0.012025, mean_q: 0.011699
 20902/100000: episode: 2837, duration: 0.037s, episode steps: 7, steps per second: 188, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000295, mae: 0.013019, mean_q: 0.016789
 20909/100000: episode: 2838, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001575, mae: 0.016893, mean_q: 0.020006
 20916/100000: episode: 2839, duration: 0.042s, episode steps: 7, steps per second: 167, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000248, mae: 0.014223, mean_q: 0.007876
 20923/100000: episode: 2840, duration: 0.038s, episode steps: 7, steps per second: 182, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000324, mae: 0.012174, mean_q: 0.009117
 20930/100000: episode: 2841, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.000203, mae: 0.010862, mean_q: 0.010710
 20937/100000: episode: 2842, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000261, mae: 0.012911, mean_q: 0.022235
 20944/100000: episode: 2843, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000489, mae: 0.012823, mean_q: 0.018042
 20951/100000: episode: 2844, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000318, mae: 0.011863, mean_q: 0.016477
 20958/100000: episode: 2845, duration: 0.044s, episode steps: 7, steps per second: 159, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000332, mae: 0.014271, mean_q: 0.018826
 20962/100000: episode: 2846, duration: 0.025s, episode steps: 4, steps per second: 161, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000436, mae: 0.014123, mean_q: 0.010231
 20966/100000: episode: 2847, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000763, mae: 0.015319, mean_q: 0.014530
 20973/100000: episode: 2848, duration: 0.040s, episode steps: 7, steps per second: 176, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000402, mae: 0.014556, mean_q: 0.020474
 20980/100000: episode: 2849, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000444, mae: 0.016509, mean_q: 0.022256
 20987/100000: episode: 2850, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001304, mae: 0.014480, mean_q: 0.008708
 20994/100000: episode: 2851, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000434, mae: 0.016540, mean_q: 0.008618
 21001/100000: episode: 2852, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001588, mae: 0.025021, mean_q: 0.029345
 21005/100000: episode: 2853, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000426, mae: 0.020055, mean_q: 0.005799
 21012/100000: episode: 2854, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000455, mae: 0.019241, mean_q: 0.008562
 21016/100000: episode: 2855, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000437, mae: 0.016355, mean_q: 0.026604
 21020/100000: episode: 2856, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000542, mae: 0.011741, mean_q: 0.010219
 21024/100000: episode: 2857, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002397, mae: 0.019291, mean_q: 0.020480
 21028/100000: episode: 2858, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000597, mae: 0.013859, mean_q: 0.016342
 21032/100000: episode: 2859, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000677, mae: 0.017278, mean_q: 0.032240
 21036/100000: episode: 2860, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000254, mae: 0.015265, mean_q: 0.011422
 21043/100000: episode: 2861, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000563, mae: 0.013946, mean_q: 0.012886
 21047/100000: episode: 2862, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000431, mae: 0.015838, mean_q: 0.019485
 21054/100000: episode: 2863, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000413, mae: 0.015760, mean_q: 0.012229
 21058/100000: episode: 2864, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000327, mae: 0.014102, mean_q: 0.024194
 21065/100000: episode: 2865, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000454, mae: 0.014539, mean_q: 0.017765
 21069/100000: episode: 2866, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000139, mae: 0.008447, mean_q: 0.005295
 21076/100000: episode: 2867, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000948, mae: 0.016932, mean_q: 0.018597
 21083/100000: episode: 2868, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000625, mae: 0.021009, mean_q: 0.014897
 21087/100000: episode: 2869, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000314, mae: 0.014856, mean_q: 0.026261
 21091/100000: episode: 2870, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000237, mae: 0.014601, mean_q: 0.003253
 21098/100000: episode: 2871, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000322, mae: 0.017521, mean_q: 0.014639
 21102/100000: episode: 2872, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002887, mae: 0.022314, mean_q: 0.015963
 21106/100000: episode: 2873, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000333, mae: 0.019442, mean_q: 0.027182
 21110/100000: episode: 2874, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000326, mae: 0.016564, mean_q: 0.003858
 21117/100000: episode: 2875, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000217, mae: 0.011743, mean_q: 0.010202
 21121/100000: episode: 2876, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000196, mae: 0.012461, mean_q: 0.017156
 21125/100000: episode: 2877, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000607, mae: 0.014894, mean_q: 0.011261
 21132/100000: episode: 2878, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000571, mae: 0.014927, mean_q: 0.018577
 21139/100000: episode: 2879, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000534, mae: 0.012630, mean_q: 0.018152
 21143/100000: episode: 2880, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000384, mae: 0.016280, mean_q: 0.022666
 21147/100000: episode: 2881, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000919, mae: 0.018689, mean_q: 0.015542
 21154/100000: episode: 2882, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000422, mae: 0.021096, mean_q: 0.017960
 21158/100000: episode: 2883, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000210, mae: 0.011732, mean_q: 0.018927
 21162/100000: episode: 2884, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000361, mae: 0.014537, mean_q: 0.008227
 21169/100000: episode: 2885, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000195, mae: 0.010586, mean_q: 0.011675
 21173/100000: episode: 2886, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000164, mae: 0.012889, mean_q: 0.015062
 21180/100000: episode: 2887, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000371, mae: 0.015020, mean_q: 0.019539
 21187/100000: episode: 2888, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000872, mae: 0.017511, mean_q: 0.019337
 21191/100000: episode: 2889, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000317, mae: 0.019286, mean_q: 0.024654
 21198/100000: episode: 2890, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000395, mae: 0.018242, mean_q: 0.011252
 21202/100000: episode: 2891, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000169, mae: 0.011017, mean_q: 0.014330
 21206/100000: episode: 2892, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000449, mae: 0.013029, mean_q: 0.012219
 21213/100000: episode: 2893, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000396, mae: 0.012580, mean_q: 0.016576
 21217/100000: episode: 2894, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000184, mae: 0.010792, mean_q: 0.002475
 21224/100000: episode: 2895, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000792, mae: 0.016048, mean_q: 0.022778
 21231/100000: episode: 2896, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001612, mae: 0.022826, mean_q: 0.030866
 21235/100000: episode: 2897, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001158, mae: 0.025829, mean_q: 0.006314
 21242/100000: episode: 2898, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000465, mae: 0.018582, mean_q: 0.010579
 21249/100000: episode: 2899, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000403, mae: 0.014212, mean_q: 0.015526
 21253/100000: episode: 2900, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000599, mae: 0.023703, mean_q: 0.014938
 21260/100000: episode: 2901, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000507, mae: 0.017733, mean_q: 0.020216
 21267/100000: episode: 2902, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000483, mae: 0.016302, mean_q: 0.019778
 21271/100000: episode: 2903, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000692, mae: 0.020518, mean_q: 0.006821
 21275/100000: episode: 2904, duration: 0.023s, episode steps: 4, steps per second: 170, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000395, mae: 0.013900, mean_q: 0.018616
 21282/100000: episode: 2905, duration: 0.039s, episode steps: 7, steps per second: 178, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000449, mae: 0.013802, mean_q: 0.017974
 21289/100000: episode: 2906, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000277, mae: 0.012812, mean_q: 0.017675
 21293/100000: episode: 2907, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000264, mae: 0.011793, mean_q: 0.004696
 21300/100000: episode: 2908, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000308, mae: 0.017089, mean_q: 0.015724
 21304/100000: episode: 2909, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000266, mae: 0.014125, mean_q: 0.020417
 21308/100000: episode: 2910, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000681, mae: 0.019752, mean_q: 0.017103
 21312/100000: episode: 2911, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000345, mae: 0.015318, mean_q: 0.017768
 21316/100000: episode: 2912, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000330, mae: 0.011114, mean_q: 0.009167
 21323/100000: episode: 2913, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000296, mae: 0.014193, mean_q: 0.010033
 21327/100000: episode: 2914, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000377, mae: 0.014843, mean_q: 0.022764
 21334/100000: episode: 2915, duration: 0.040s, episode steps: 7, steps per second: 173, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000413, mae: 0.015183, mean_q: 0.019078
 21341/100000: episode: 2916, duration: 0.038s, episode steps: 7, steps per second: 184, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000227, mae: 0.014800, mean_q: 0.009455
 21345/100000: episode: 2917, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000158, mae: 0.010920, mean_q: 0.016919
 21352/100000: episode: 2918, duration: 0.037s, episode steps: 7, steps per second: 188, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000293, mae: 0.012652, mean_q: 0.013938
[Info] 2-TH LEVEL FOUND: 0.1009821891784668, Considering 20/100 traces
 21359/100000: episode: 2919, duration: 0.757s, episode steps: 7, steps per second: 9, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000343, mae: 0.011211, mean_q: 0.011639
 21361/100000: episode: 2920, duration: 0.015s, episode steps: 2, steps per second: 136, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000310, mae: 0.015058, mean_q: 0.019080
 21363/100000: episode: 2921, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000367, mae: 0.013148, mean_q: 0.010179
 21367/100000: episode: 2922, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000449, mae: 0.014042, mean_q: 0.018816
 21369/100000: episode: 2923, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000245, mae: 0.011532, mean_q: 0.019465
 21371/100000: episode: 2924, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000182, mae: 0.012173, mean_q: 0.003537
 21373/100000: episode: 2925, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000457, mae: 0.014778, mean_q: 0.010852
 21375/100000: episode: 2926, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000385, mae: 0.018952, mean_q: 0.030957
 21377/100000: episode: 2927, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000306, mae: 0.012110, mean_q: 0.004543
 21379/100000: episode: 2928, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000914, mae: 0.021608, mean_q: 0.023649
 21381/100000: episode: 2929, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000143, mae: 0.011649, mean_q: 0.017526
 21383/100000: episode: 2930, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000218, mae: 0.012373, mean_q: 0.003758
 21385/100000: episode: 2931, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000340, mae: 0.014342, mean_q: 0.018340
 21387/100000: episode: 2932, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000425, mae: 0.017635, mean_q: 0.022241
 21389/100000: episode: 2933, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000481, mae: 0.017375, mean_q: 0.008156
 21391/100000: episode: 2934, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000437, mae: 0.014669, mean_q: 0.011294
 21393/100000: episode: 2935, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000655, mae: 0.023316, mean_q: 0.032516
 21395/100000: episode: 2936, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000423, mae: 0.019232, mean_q: -0.003792
 21397/100000: episode: 2937, duration: 0.014s, episode steps: 2, steps per second: 142, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000704, mae: 0.015087, mean_q: 0.022606
 21399/100000: episode: 2938, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000135, mae: 0.009760, mean_q: 0.014146
 21401/100000: episode: 2939, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000952, mae: 0.016126, mean_q: 0.013187
 21403/100000: episode: 2940, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000306, mae: 0.016245, mean_q: 0.025058
 21405/100000: episode: 2941, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000544, mae: 0.017685, mean_q: 0.029201
 21407/100000: episode: 2942, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001259, mae: 0.022281, mean_q: 0.021468
 21409/100000: episode: 2943, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000172, mae: 0.015505, mean_q: 0.024480
 21411/100000: episode: 2944, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000306, mae: 0.013858, mean_q: 0.004729
 21413/100000: episode: 2945, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001867, mae: 0.026690, mean_q: 0.027680
 21415/100000: episode: 2946, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000282, mae: 0.014225, mean_q: 0.019308
 21417/100000: episode: 2947, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000790, mae: 0.019176, mean_q: 0.006643
 21419/100000: episode: 2948, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000508, mae: 0.022325, mean_q: 0.032563
 21421/100000: episode: 2949, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000134, mae: 0.010172, mean_q: 0.004420
 21423/100000: episode: 2950, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000208, mae: 0.010211, mean_q: 0.006168
 21425/100000: episode: 2951, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000729, mae: 0.023040, mean_q: 0.038719
 21427/100000: episode: 2952, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000738, mae: 0.023082, mean_q: 0.031221
 21429/100000: episode: 2953, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000190, mae: 0.010677, mean_q: 0.006231
 21431/100000: episode: 2954, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000255, mae: 0.016189, mean_q: 0.022772
 21433/100000: episode: 2955, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000686, mae: 0.019080, mean_q: 0.025596
 21435/100000: episode: 2956, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000382, mae: 0.012812, mean_q: 0.008989
 21439/100000: episode: 2957, duration: 0.036s, episode steps: 4, steps per second: 110, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000451, mae: 0.015224, mean_q: 0.020906
 21441/100000: episode: 2958, duration: 0.029s, episode steps: 2, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000615, mae: 0.023572, mean_q: -0.006099
 21443/100000: episode: 2959, duration: 0.026s, episode steps: 2, steps per second: 78, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000816, mae: 0.027571, mean_q: 0.037325
 21445/100000: episode: 2960, duration: 0.018s, episode steps: 2, steps per second: 110, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000167, mae: 0.010699, mean_q: 0.014683
 21447/100000: episode: 2961, duration: 0.019s, episode steps: 2, steps per second: 106, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000465, mae: 0.020490, mean_q: -0.002591
 21449/100000: episode: 2962, duration: 0.015s, episode steps: 2, steps per second: 132, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000207, mae: 0.014204, mean_q: 0.020596
 21451/100000: episode: 2963, duration: 0.017s, episode steps: 2, steps per second: 117, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000237, mae: 0.012553, mean_q: 0.020880
 21453/100000: episode: 2964, duration: 0.016s, episode steps: 2, steps per second: 129, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000644, mae: 0.018382, mean_q: 0.003404
[Info] FALSIFICATION!
 21456/100000: episode: 2965, duration: 0.217s, episode steps: 3, steps per second: 14, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000289, mae: 0.012677, mean_q: 0.012356
 21458/100000: episode: 2966, duration: 0.017s, episode steps: 2, steps per second: 119, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001807, mae: 0.025487, mean_q: 0.031228
 21460/100000: episode: 2967, duration: 0.016s, episode steps: 2, steps per second: 124, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000802, mae: 0.020773, mean_q: 0.029085
 21462/100000: episode: 2968, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000496, mae: 0.017440, mean_q: 0.014144
 21464/100000: episode: 2969, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000747, mae: 0.019706, mean_q: 0.014622
[Info] FALSIFICATION!
 21467/100000: episode: 2970, duration: 0.255s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000487, mae: 0.017913, mean_q: 0.030204
 21469/100000: episode: 2971, duration: 0.023s, episode steps: 2, steps per second: 86, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000700, mae: 0.018061, mean_q: 0.017203
 21471/100000: episode: 2972, duration: 0.019s, episode steps: 2, steps per second: 103, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000742, mae: 0.018290, mean_q: 0.003954
 21473/100000: episode: 2973, duration: 0.020s, episode steps: 2, steps per second: 102, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000303, mae: 0.015635, mean_q: 0.021072
 21477/100000: episode: 2974, duration: 0.029s, episode steps: 4, steps per second: 139, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000297, mae: 0.014567, mean_q: 0.013979
 21479/100000: episode: 2975, duration: 0.014s, episode steps: 2, steps per second: 140, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005427, mae: 0.038236, mean_q: 0.043458
 21481/100000: episode: 2976, duration: 0.016s, episode steps: 2, steps per second: 124, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000957, mae: 0.022431, mean_q: 0.036077
 21483/100000: episode: 2977, duration: 0.018s, episode steps: 2, steps per second: 110, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000874, mae: 0.033668, mean_q: -0.017240
 21485/100000: episode: 2978, duration: 0.018s, episode steps: 2, steps per second: 114, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000405, mae: 0.015664, mean_q: 0.021488
 21489/100000: episode: 2979, duration: 0.035s, episode steps: 4, steps per second: 113, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000998, mae: 0.025832, mean_q: 0.028329
 21491/100000: episode: 2980, duration: 0.021s, episode steps: 2, steps per second: 96, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000902, mae: 0.017906, mean_q: 0.018752
 21493/100000: episode: 2981, duration: 0.020s, episode steps: 2, steps per second: 99, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000445, mae: 0.016158, mean_q: 0.020541
 21497/100000: episode: 2982, duration: 0.031s, episode steps: 4, steps per second: 128, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000779, mae: 0.019815, mean_q: 0.017521
 21499/100000: episode: 2983, duration: 0.021s, episode steps: 2, steps per second: 93, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000226, mae: 0.013398, mean_q: 0.021405
 21501/100000: episode: 2984, duration: 0.015s, episode steps: 2, steps per second: 130, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000447, mae: 0.014261, mean_q: 0.018188
 21505/100000: episode: 2985, duration: 0.025s, episode steps: 4, steps per second: 158, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000488, mae: 0.013835, mean_q: 0.012283
 21509/100000: episode: 2986, duration: 0.031s, episode steps: 4, steps per second: 131, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000437, mae: 0.014596, mean_q: 0.015074
 21513/100000: episode: 2987, duration: 0.030s, episode steps: 4, steps per second: 134, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000213, mae: 0.010040, mean_q: 0.007678
 21515/100000: episode: 2988, duration: 0.018s, episode steps: 2, steps per second: 109, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000356, mae: 0.014813, mean_q: 0.018556
 21517/100000: episode: 2989, duration: 0.015s, episode steps: 2, steps per second: 135, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000336, mae: 0.013250, mean_q: 0.013266
 21521/100000: episode: 2990, duration: 0.034s, episode steps: 4, steps per second: 118, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000510, mae: 0.017646, mean_q: 0.024488
 21523/100000: episode: 2991, duration: 0.016s, episode steps: 2, steps per second: 125, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000302, mae: 0.013973, mean_q: 0.014238
 21525/100000: episode: 2992, duration: 0.016s, episode steps: 2, steps per second: 127, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000450, mae: 0.017153, mean_q: 0.007615
 21527/100000: episode: 2993, duration: 0.023s, episode steps: 2, steps per second: 86, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000888, mae: 0.019911, mean_q: 0.025810
 21529/100000: episode: 2994, duration: 0.023s, episode steps: 2, steps per second: 89, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000419, mae: 0.019183, mean_q: 0.027029
 21531/100000: episode: 2995, duration: 0.014s, episode steps: 2, steps per second: 142, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000302, mae: 0.014648, mean_q: 0.020457
 21533/100000: episode: 2996, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000175, mae: 0.012304, mean_q: 0.000535
 21535/100000: episode: 2997, duration: 0.014s, episode steps: 2, steps per second: 142, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000287, mae: 0.012713, mean_q: 0.021559
 21537/100000: episode: 2998, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001505, mae: 0.018739, mean_q: 0.019251
[Info] Complete ISplit Iteration
[Info] Levels: [0.014494702, 0.10098219, 0.7551411]
[Info] Cond. Prob: [0.1, 0.2, 0.02]
[Info] Error Prob: 0.0004000000000000001

 21539/100000: episode: 2999, duration: 0.982s, episode steps: 2, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000252, mae: 0.012574, mean_q: 0.011249
 21549/100000: episode: 3000, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000531, mae: 0.014014, mean_q: 0.016399
 21559/100000: episode: 3001, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000571, mae: 0.017255, mean_q: 0.022081
 21569/100000: episode: 3002, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000805, mae: 0.021448, mean_q: 0.021117
 21579/100000: episode: 3003, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000587, mae: 0.013792, mean_q: 0.015438
 21589/100000: episode: 3004, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000405, mae: 0.013470, mean_q: 0.013523
 21599/100000: episode: 3005, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000760, mae: 0.016868, mean_q: 0.018858
 21609/100000: episode: 3006, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000580, mae: 0.016763, mean_q: 0.017688
 21619/100000: episode: 3007, duration: 0.092s, episode steps: 10, steps per second: 108, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000546, mae: 0.015852, mean_q: 0.015660
 21629/100000: episode: 3008, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000617, mae: 0.021558, mean_q: 0.016802
 21639/100000: episode: 3009, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000614, mae: 0.020847, mean_q: 0.017870
 21649/100000: episode: 3010, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000785, mae: 0.018408, mean_q: 0.023351
 21659/100000: episode: 3011, duration: 0.080s, episode steps: 10, steps per second: 124, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000672, mae: 0.019242, mean_q: 0.017126
 21669/100000: episode: 3012, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001440, mae: 0.026191, mean_q: 0.015791
 21679/100000: episode: 3013, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000928, mae: 0.022401, mean_q: 0.024929
 21689/100000: episode: 3014, duration: 0.119s, episode steps: 10, steps per second: 84, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001470, mae: 0.019504, mean_q: 0.016905
 21699/100000: episode: 3015, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000608, mae: 0.014963, mean_q: 0.017861
 21709/100000: episode: 3016, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000497, mae: 0.016007, mean_q: 0.018901
 21719/100000: episode: 3017, duration: 0.096s, episode steps: 10, steps per second: 105, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000756, mae: 0.018003, mean_q: 0.015656
 21729/100000: episode: 3018, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000460, mae: 0.013749, mean_q: 0.015273
 21739/100000: episode: 3019, duration: 0.129s, episode steps: 10, steps per second: 78, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000445, mae: 0.015903, mean_q: 0.022213
 21749/100000: episode: 3020, duration: 0.086s, episode steps: 10, steps per second: 117, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000424, mae: 0.013423, mean_q: 0.018266
 21759/100000: episode: 3021, duration: 0.111s, episode steps: 10, steps per second: 90, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000693, mae: 0.016446, mean_q: 0.018274
 21769/100000: episode: 3022, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000473, mae: 0.017185, mean_q: 0.017817
 21779/100000: episode: 3023, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000379, mae: 0.014139, mean_q: 0.016066
 21789/100000: episode: 3024, duration: 0.074s, episode steps: 10, steps per second: 136, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000604, mae: 0.016867, mean_q: 0.020457
 21799/100000: episode: 3025, duration: 0.126s, episode steps: 10, steps per second: 80, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000422, mae: 0.016419, mean_q: 0.016335
 21809/100000: episode: 3026, duration: 0.103s, episode steps: 10, steps per second: 97, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001182, mae: 0.022290, mean_q: 0.029656
 21819/100000: episode: 3027, duration: 0.125s, episode steps: 10, steps per second: 80, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001025, mae: 0.027053, mean_q: 0.020583
 21829/100000: episode: 3028, duration: 0.082s, episode steps: 10, steps per second: 121, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001029, mae: 0.023629, mean_q: 0.015196
 21839/100000: episode: 3029, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000829, mae: 0.018966, mean_q: 0.022121
 21849/100000: episode: 3030, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000426, mae: 0.015518, mean_q: 0.017305
 21859/100000: episode: 3031, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000547, mae: 0.016413, mean_q: 0.015327
 21869/100000: episode: 3032, duration: 0.071s, episode steps: 10, steps per second: 142, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000813, mae: 0.021929, mean_q: 0.017106
 21879/100000: episode: 3033, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000420, mae: 0.015163, mean_q: 0.015782
 21889/100000: episode: 3034, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000603, mae: 0.015066, mean_q: 0.020566
 21899/100000: episode: 3035, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000773, mae: 0.017292, mean_q: 0.023511
 21909/100000: episode: 3036, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000670, mae: 0.018477, mean_q: 0.020497
 21919/100000: episode: 3037, duration: 0.137s, episode steps: 10, steps per second: 73, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000573, mae: 0.017447, mean_q: 0.015891
 21929/100000: episode: 3038, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000591, mae: 0.020435, mean_q: 0.025198
 21939/100000: episode: 3039, duration: 0.080s, episode steps: 10, steps per second: 124, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000497, mae: 0.015666, mean_q: 0.019469
 21949/100000: episode: 3040, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000529, mae: 0.016212, mean_q: 0.016010
 21959/100000: episode: 3041, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000356, mae: 0.013542, mean_q: 0.016957
 21969/100000: episode: 3042, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000305, mae: 0.014884, mean_q: 0.014011
 21979/100000: episode: 3043, duration: 0.081s, episode steps: 10, steps per second: 124, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000484, mae: 0.014718, mean_q: 0.015444
 21989/100000: episode: 3044, duration: 0.114s, episode steps: 10, steps per second: 88, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000458, mae: 0.015884, mean_q: 0.019605
 21999/100000: episode: 3045, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000752, mae: 0.017355, mean_q: 0.019009
 22009/100000: episode: 3046, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000686, mae: 0.018211, mean_q: 0.022567
 22019/100000: episode: 3047, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000629, mae: 0.016670, mean_q: 0.018025
 22029/100000: episode: 3048, duration: 0.079s, episode steps: 10, steps per second: 126, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001002, mae: 0.024156, mean_q: 0.019894
 22039/100000: episode: 3049, duration: 0.104s, episode steps: 10, steps per second: 97, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001301, mae: 0.021999, mean_q: 0.022307
 22049/100000: episode: 3050, duration: 0.071s, episode steps: 10, steps per second: 142, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000617, mae: 0.015904, mean_q: 0.014073
 22059/100000: episode: 3051, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.002606, mae: 0.028728, mean_q: 0.031431
 22069/100000: episode: 3052, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001768, mae: 0.034116, mean_q: 0.019144
 22079/100000: episode: 3053, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001786, mae: 0.024635, mean_q: 0.015145
 22089/100000: episode: 3054, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000466, mae: 0.018588, mean_q: 0.016240
 22099/100000: episode: 3055, duration: 0.094s, episode steps: 10, steps per second: 107, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001711, mae: 0.025342, mean_q: 0.023478
 22109/100000: episode: 3056, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001707, mae: 0.029643, mean_q: 0.022874
 22119/100000: episode: 3057, duration: 0.093s, episode steps: 10, steps per second: 108, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000588, mae: 0.020983, mean_q: 0.015862
 22129/100000: episode: 3058, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000375, mae: 0.014822, mean_q: 0.013833
 22139/100000: episode: 3059, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000372, mae: 0.012645, mean_q: 0.015979
 22149/100000: episode: 3060, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000508, mae: 0.015553, mean_q: 0.018668
 22159/100000: episode: 3061, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000312, mae: 0.014491, mean_q: 0.013196
 22169/100000: episode: 3062, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001740, mae: 0.023962, mean_q: 0.025951
 22179/100000: episode: 3063, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000668, mae: 0.016739, mean_q: 0.019603
 22189/100000: episode: 3064, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000620, mae: 0.016936, mean_q: 0.019034
 22199/100000: episode: 3065, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000742, mae: 0.017756, mean_q: 0.021755
 22209/100000: episode: 3066, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000558, mae: 0.018842, mean_q: 0.018718
 22219/100000: episode: 3067, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000850, mae: 0.019149, mean_q: 0.020914
 22229/100000: episode: 3068, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000648, mae: 0.013707, mean_q: 0.018069
 22239/100000: episode: 3069, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000293, mae: 0.011135, mean_q: 0.013254
 22249/100000: episode: 3070, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000383, mae: 0.013540, mean_q: 0.014862
 22259/100000: episode: 3071, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000474, mae: 0.014198, mean_q: 0.020284
 22269/100000: episode: 3072, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000718, mae: 0.017513, mean_q: 0.021213
 22279/100000: episode: 3073, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000594, mae: 0.016866, mean_q: 0.018494
 22289/100000: episode: 3074, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000884, mae: 0.019757, mean_q: 0.018209
 22299/100000: episode: 3075, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000526, mae: 0.015499, mean_q: 0.014733
 22309/100000: episode: 3076, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000238, mae: 0.012156, mean_q: 0.013042
 22319/100000: episode: 3077, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000417, mae: 0.014292, mean_q: 0.013724
 22329/100000: episode: 3078, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000652, mae: 0.020155, mean_q: 0.018223
 22339/100000: episode: 3079, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000905, mae: 0.017408, mean_q: 0.023464
 22349/100000: episode: 3080, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000659, mae: 0.016088, mean_q: 0.015674
 22359/100000: episode: 3081, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000213, mae: 0.010905, mean_q: 0.012074
 22369/100000: episode: 3082, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000168, mae: 0.008790, mean_q: 0.006779
 22379/100000: episode: 3083, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000701, mae: 0.014781, mean_q: 0.019893
 22389/100000: episode: 3084, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000628, mae: 0.023003, mean_q: 0.014950
 22399/100000: episode: 3085, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000696, mae: 0.017001, mean_q: 0.020132
 22409/100000: episode: 3086, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000583, mae: 0.016646, mean_q: 0.013663
 22419/100000: episode: 3087, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000488, mae: 0.017688, mean_q: 0.015221
 22429/100000: episode: 3088, duration: 0.072s, episode steps: 10, steps per second: 138, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000481, mae: 0.019114, mean_q: 0.015295
 22439/100000: episode: 3089, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000352, mae: 0.012676, mean_q: 0.011123
 22449/100000: episode: 3090, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000475, mae: 0.012822, mean_q: 0.015446
 22459/100000: episode: 3091, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000558, mae: 0.017971, mean_q: 0.019038
 22469/100000: episode: 3092, duration: 0.055s, episode steps: 10, steps per second: 180, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001107, mae: 0.020533, mean_q: 0.024750
 22479/100000: episode: 3093, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000766, mae: 0.017528, mean_q: 0.015238
 22489/100000: episode: 3094, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000517, mae: 0.015291, mean_q: 0.014447
 22499/100000: episode: 3095, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000706, mae: 0.018334, mean_q: 0.020362
 22509/100000: episode: 3096, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000408, mae: 0.015141, mean_q: 0.014809
 22519/100000: episode: 3097, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000520, mae: 0.014525, mean_q: 0.012338
 22529/100000: episode: 3098, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000174, mae: 0.008939, mean_q: 0.010101
[Info] 1-TH LEVEL FOUND: 0.04859064519405365, Considering 10/100 traces
 22539/100000: episode: 3099, duration: 0.932s, episode steps: 10, steps per second: 11, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000468, mae: 0.013546, mean_q: 0.015430
 22541/100000: episode: 3100, duration: 0.041s, episode steps: 2, steps per second: 49, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001252, mae: 0.018184, mean_q: 0.030553
 22547/100000: episode: 3101, duration: 0.036s, episode steps: 6, steps per second: 169, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000992, mae: 0.021908, mean_q: 0.008550
 22549/100000: episode: 3102, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000416, mae: 0.020703, mean_q: 0.026403
 22555/100000: episode: 3103, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000315, mae: 0.011969, mean_q: 0.009448
 22557/100000: episode: 3104, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001006, mae: 0.018912, mean_q: 0.021717
 22561/100000: episode: 3105, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000354, mae: 0.014489, mean_q: 0.000860
 22563/100000: episode: 3106, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000210, mae: 0.013485, mean_q: 0.019551
 22565/100000: episode: 3107, duration: 0.017s, episode steps: 2, steps per second: 115, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000284, mae: 0.011467, mean_q: 0.014607
 22567/100000: episode: 3108, duration: 0.017s, episode steps: 2, steps per second: 119, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000225, mae: 0.009721, mean_q: 0.005189
 22569/100000: episode: 3109, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005542, mae: 0.033422, mean_q: 0.035194
 22571/100000: episode: 3110, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000448, mae: 0.019767, mean_q: 0.026841
 22575/100000: episode: 3111, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000783, mae: 0.027455, mean_q: 0.003780
 22581/100000: episode: 3112, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000220, mae: 0.013528, mean_q: 0.019997
 22583/100000: episode: 3113, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000292, mae: 0.016314, mean_q: -0.000837
 22585/100000: episode: 3114, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000337, mae: 0.016370, mean_q: 0.019122
 22587/100000: episode: 3115, duration: 0.012s, episode steps: 2, steps per second: 166, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000269, mae: 0.013025, mean_q: 0.019172
 22589/100000: episode: 3116, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001214, mae: 0.021380, mean_q: 0.017644
 22591/100000: episode: 3117, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000953, mae: 0.019567, mean_q: 0.015620
 22597/100000: episode: 3118, duration: 0.031s, episode steps: 6, steps per second: 193, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000253, mae: 0.011697, mean_q: 0.015867
 22599/100000: episode: 3119, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000428, mae: 0.014369, mean_q: 0.012223
 22603/100000: episode: 3120, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002856, mae: 0.015709, mean_q: 0.011863
 22605/100000: episode: 3121, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000646, mae: 0.024613, mean_q: 0.034442
 22607/100000: episode: 3122, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000685, mae: 0.021084, mean_q: 0.007577
 22611/100000: episode: 3123, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000459, mae: 0.017424, mean_q: 0.015802
 22613/100000: episode: 3124, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000116, mae: 0.007905, mean_q: 0.006935
 22619/100000: episode: 3125, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000316, mae: 0.015499, mean_q: 0.012426
 22621/100000: episode: 3126, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000373, mae: 0.013394, mean_q: 0.010928
 22623/100000: episode: 3127, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000102, mae: 0.006942, mean_q: 0.008046
 22629/100000: episode: 3128, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000498, mae: 0.012240, mean_q: 0.010435
 22633/100000: episode: 3129, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000572, mae: 0.015299, mean_q: 0.024593
 22635/100000: episode: 3130, duration: 0.016s, episode steps: 2, steps per second: 124, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000550, mae: 0.014221, mean_q: 0.001496
 22639/100000: episode: 3131, duration: 0.030s, episode steps: 4, steps per second: 132, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000404, mae: 0.019733, mean_q: 0.021205
 22643/100000: episode: 3132, duration: 0.023s, episode steps: 4, steps per second: 170, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000390, mae: 0.016811, mean_q: 0.001977
 22645/100000: episode: 3133, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000308, mae: 0.015114, mean_q: 0.018206
 22647/100000: episode: 3134, duration: 0.016s, episode steps: 2, steps per second: 124, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000972, mae: 0.018378, mean_q: 0.023810
 22649/100000: episode: 3135, duration: 0.014s, episode steps: 2, steps per second: 143, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000508, mae: 0.011483, mean_q: 0.010198
 22651/100000: episode: 3136, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000062, mae: 0.006033, mean_q: 0.006470
 22657/100000: episode: 3137, duration: 0.031s, episode steps: 6, steps per second: 191, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000822, mae: 0.018876, mean_q: 0.020501
 22661/100000: episode: 3138, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000248, mae: 0.011737, mean_q: 0.011606
 22663/100000: episode: 3139, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000140, mae: 0.009650, mean_q: 0.013129
 22665/100000: episode: 3140, duration: 0.014s, episode steps: 2, steps per second: 140, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000361, mae: 0.010082, mean_q: 0.010429
 22669/100000: episode: 3141, duration: 0.030s, episode steps: 4, steps per second: 132, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000306, mae: 0.013327, mean_q: 0.014428
 22673/100000: episode: 3142, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000525, mae: 0.015621, mean_q: 0.012154
 22675/100000: episode: 3143, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000848, mae: 0.018331, mean_q: 0.024777
 22677/100000: episode: 3144, duration: 0.014s, episode steps: 2, steps per second: 144, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000132, mae: 0.008579, mean_q: 0.012295
 22679/100000: episode: 3145, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000270, mae: 0.012484, mean_q: 0.002896
 22681/100000: episode: 3146, duration: 0.045s, episode steps: 2, steps per second: 45, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000649, mae: 0.020116, mean_q: 0.030478
 22683/100000: episode: 3147, duration: 0.036s, episode steps: 2, steps per second: 56, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000252, mae: 0.016045, mean_q: 0.018634
 22689/100000: episode: 3148, duration: 0.061s, episode steps: 6, steps per second: 98, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000348, mae: 0.016801, mean_q: 0.014584
 22691/100000: episode: 3149, duration: 0.015s, episode steps: 2, steps per second: 135, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000194, mae: 0.007934, mean_q: 0.005337
 22693/100000: episode: 3150, duration: 0.016s, episode steps: 2, steps per second: 128, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000097, mae: 0.007938, mean_q: 0.002684
 22699/100000: episode: 3151, duration: 0.033s, episode steps: 6, steps per second: 182, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000430, mae: 0.014652, mean_q: 0.015137
 22701/100000: episode: 3152, duration: 0.014s, episode steps: 2, steps per second: 139, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000258, mae: 0.011680, mean_q: 0.009524
 22703/100000: episode: 3153, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000666, mae: 0.014814, mean_q: 0.025908
 22705/100000: episode: 3154, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000380, mae: 0.013411, mean_q: 0.015029
 22707/100000: episode: 3155, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000189, mae: 0.012128, mean_q: 0.003904
 22709/100000: episode: 3156, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000446, mae: 0.012825, mean_q: 0.024881
 22713/100000: episode: 3157, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000305, mae: 0.011334, mean_q: 0.012183
 22715/100000: episode: 3158, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001183, mae: 0.015476, mean_q: 0.020164
 22717/100000: episode: 3159, duration: 0.018s, episode steps: 2, steps per second: 109, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000462, mae: 0.020389, mean_q: 0.029138
 22719/100000: episode: 3160, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001043, mae: 0.018977, mean_q: 0.013268
 22721/100000: episode: 3161, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000308, mae: 0.015623, mean_q: 0.000206
 22725/100000: episode: 3162, duration: 0.028s, episode steps: 4, steps per second: 143, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001261, mae: 0.028585, mean_q: 0.039237
 22727/100000: episode: 3163, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001676, mae: 0.027326, mean_q: -0.003087
 22729/100000: episode: 3164, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000440, mae: 0.020014, mean_q: 0.033767
 22733/100000: episode: 3165, duration: 0.024s, episode steps: 4, steps per second: 167, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000508, mae: 0.020709, mean_q: 0.010297
 22737/100000: episode: 3166, duration: 0.042s, episode steps: 4, steps per second: 94, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001323, mae: 0.030540, mean_q: 0.027752
 22741/100000: episode: 3167, duration: 0.030s, episode steps: 4, steps per second: 132, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000524, mae: 0.022044, mean_q: 0.001718
 22743/100000: episode: 3168, duration: 0.017s, episode steps: 2, steps per second: 115, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000245, mae: 0.014067, mean_q: 0.007678
 22749/100000: episode: 3169, duration: 0.051s, episode steps: 6, steps per second: 117, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000436, mae: 0.020932, mean_q: 0.008231
 22751/100000: episode: 3170, duration: 0.020s, episode steps: 2, steps per second: 101, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000814, mae: 0.027919, mean_q: 0.037176
 22755/100000: episode: 3171, duration: 0.040s, episode steps: 4, steps per second: 99, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001215, mae: 0.025819, mean_q: 0.020695
 22759/100000: episode: 3172, duration: 0.040s, episode steps: 4, steps per second: 100, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001550, mae: 0.029365, mean_q: 0.038362
 22761/100000: episode: 3173, duration: 0.019s, episode steps: 2, steps per second: 108, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000272, mae: 0.014466, mean_q: 0.002282
 22765/100000: episode: 3174, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000475, mae: 0.017040, mean_q: 0.014712
 22767/100000: episode: 3175, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000315, mae: 0.015092, mean_q: 0.023502
 22769/100000: episode: 3176, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001816, mae: 0.020139, mean_q: 0.025644
 22771/100000: episode: 3177, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000617, mae: 0.014471, mean_q: 0.023891
 22773/100000: episode: 3178, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000428, mae: 0.017944, mean_q: 0.013646
 22779/100000: episode: 3179, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001358, mae: 0.019078, mean_q: 0.027864
 22781/100000: episode: 3180, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000504, mae: 0.021072, mean_q: -0.008662
 22785/100000: episode: 3181, duration: 0.026s, episode steps: 4, steps per second: 152, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000309, mae: 0.019805, mean_q: 0.023218
 22789/100000: episode: 3182, duration: 0.036s, episode steps: 4, steps per second: 112, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000307, mae: 0.016303, mean_q: -0.003770
 22793/100000: episode: 3183, duration: 0.024s, episode steps: 4, steps per second: 170, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000403, mae: 0.015738, mean_q: 0.021589
 22795/100000: episode: 3184, duration: 0.016s, episode steps: 2, steps per second: 127, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000623, mae: 0.019364, mean_q: 0.001261
 22797/100000: episode: 3185, duration: 0.016s, episode steps: 2, steps per second: 128, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000967, mae: 0.018595, mean_q: 0.023338
 22801/100000: episode: 3186, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000270, mae: 0.015052, mean_q: 0.016297
 22803/100000: episode: 3187, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001656, mae: 0.019916, mean_q: 0.006602
 22805/100000: episode: 3188, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000527, mae: 0.022136, mean_q: 0.030937
[Info] 2-TH LEVEL FOUND: 0.058924779295921326, Considering 18/100 traces
 22809/100000: episode: 3189, duration: 0.901s, episode steps: 4, steps per second: 4, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000354, mae: 0.018604, mean_q: 0.013280
 22811/100000: episode: 3190, duration: 0.032s, episode steps: 2, steps per second: 62, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000595, mae: 0.017422, mean_q: 0.015039
 22813/100000: episode: 3191, duration: 0.029s, episode steps: 2, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000566, mae: 0.018419, mean_q: 0.029388
 22818/100000: episode: 3192, duration: 0.044s, episode steps: 5, steps per second: 114, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000935, mae: 0.016681, mean_q: 0.020459
 22820/100000: episode: 3193, duration: 0.032s, episode steps: 2, steps per second: 63, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001296, mae: 0.020268, mean_q: 0.024564
 22825/100000: episode: 3194, duration: 0.041s, episode steps: 5, steps per second: 121, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001184, mae: 0.024524, mean_q: 0.023663
 22830/100000: episode: 3195, duration: 0.033s, episode steps: 5, steps per second: 152, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000725, mae: 0.015643, mean_q: 0.009815
 22832/100000: episode: 3196, duration: 0.015s, episode steps: 2, steps per second: 130, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000194, mae: 0.013116, mean_q: 0.017491
 22834/100000: episode: 3197, duration: 0.017s, episode steps: 2, steps per second: 116, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000101, mae: 0.008114, mean_q: 0.005873
 22836/100000: episode: 3198, duration: 0.017s, episode steps: 2, steps per second: 120, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000330, mae: 0.011479, mean_q: 0.007336
 22841/100000: episode: 3199, duration: 0.032s, episode steps: 5, steps per second: 156, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000788, mae: 0.018058, mean_q: 0.025515
 22843/100000: episode: 3200, duration: 0.021s, episode steps: 2, steps per second: 95, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000228, mae: 0.012063, mean_q: 0.011008
 22848/100000: episode: 3201, duration: 0.033s, episode steps: 5, steps per second: 153, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001007, mae: 0.018207, mean_q: 0.025836
 22850/100000: episode: 3202, duration: 0.023s, episode steps: 2, steps per second: 85, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000966, mae: 0.018533, mean_q: 0.016992
 22852/100000: episode: 3203, duration: 0.023s, episode steps: 2, steps per second: 87, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000955, mae: 0.021666, mean_q: 0.006200
 22857/100000: episode: 3204, duration: 0.056s, episode steps: 5, steps per second: 89, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000547, mae: 0.020458, mean_q: 0.021330
 22862/100000: episode: 3205, duration: 0.051s, episode steps: 5, steps per second: 98, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000692, mae: 0.016998, mean_q: 0.021360
 22864/100000: episode: 3206, duration: 0.017s, episode steps: 2, steps per second: 120, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000707, mae: 0.012228, mean_q: 0.019638
 22869/100000: episode: 3207, duration: 0.041s, episode steps: 5, steps per second: 121, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000259, mae: 0.011620, mean_q: 0.013789
 22874/100000: episode: 3208, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000400, mae: 0.015124, mean_q: 0.018444
 22879/100000: episode: 3209, duration: 0.035s, episode steps: 5, steps per second: 142, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000788, mae: 0.017657, mean_q: 0.013448
 22881/100000: episode: 3210, duration: 0.015s, episode steps: 2, steps per second: 133, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000437, mae: 0.019762, mean_q: 0.020130
 22886/100000: episode: 3211, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000601, mae: 0.016820, mean_q: 0.017138
 22891/100000: episode: 3212, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001355, mae: 0.026675, mean_q: 0.038942
 22893/100000: episode: 3213, duration: 0.014s, episode steps: 2, steps per second: 144, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001816, mae: 0.032481, mean_q: 0.030824
 22895/100000: episode: 3214, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000707, mae: 0.020022, mean_q: 0.001707
 22897/100000: episode: 3215, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001299, mae: 0.030501, mean_q: 0.052778
 22902/100000: episode: 3216, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000803, mae: 0.020694, mean_q: 0.003625
 22907/100000: episode: 3217, duration: 0.062s, episode steps: 5, steps per second: 81, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000716, mae: 0.022281, mean_q: 0.024912
 22912/100000: episode: 3218, duration: 0.065s, episode steps: 5, steps per second: 77, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000777, mae: 0.024349, mean_q: 0.025257
 22914/100000: episode: 3219, duration: 0.021s, episode steps: 2, steps per second: 95, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001177, mae: 0.021958, mean_q: 0.015720
 22916/100000: episode: 3220, duration: 0.019s, episode steps: 2, steps per second: 104, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000218, mae: 0.012669, mean_q: 0.016654
 22918/100000: episode: 3221, duration: 0.016s, episode steps: 2, steps per second: 122, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000543, mae: 0.022941, mean_q: 0.028780
 22920/100000: episode: 3222, duration: 0.016s, episode steps: 2, steps per second: 127, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000349, mae: 0.019059, mean_q: -0.003654
 22925/100000: episode: 3223, duration: 0.045s, episode steps: 5, steps per second: 110, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000251, mae: 0.012481, mean_q: 0.016865
 22927/100000: episode: 3224, duration: 0.027s, episode steps: 2, steps per second: 74, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000146, mae: 0.009245, mean_q: 0.001243
 22929/100000: episode: 3225, duration: 0.021s, episode steps: 2, steps per second: 97, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000331, mae: 0.012627, mean_q: 0.012394
 22931/100000: episode: 3226, duration: 0.024s, episode steps: 2, steps per second: 85, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000534, mae: 0.013965, mean_q: 0.023240
 22933/100000: episode: 3227, duration: 0.015s, episode steps: 2, steps per second: 130, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000273, mae: 0.012635, mean_q: 0.013756
 22938/100000: episode: 3228, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000447, mae: 0.016306, mean_q: 0.022405
 22943/100000: episode: 3229, duration: 0.032s, episode steps: 5, steps per second: 155, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000490, mae: 0.016277, mean_q: 0.018124
 22945/100000: episode: 3230, duration: 0.019s, episode steps: 2, steps per second: 103, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000346, mae: 0.013974, mean_q: 0.004027
 22947/100000: episode: 3231, duration: 0.016s, episode steps: 2, steps per second: 126, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000736, mae: 0.021544, mean_q: 0.024121
 22949/100000: episode: 3232, duration: 0.019s, episode steps: 2, steps per second: 104, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000452, mae: 0.019879, mean_q: 0.028376
 22954/100000: episode: 3233, duration: 0.030s, episode steps: 5, steps per second: 164, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.004616, mae: 0.028132, mean_q: 0.028113
 22956/100000: episode: 3234, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001381, mae: 0.029160, mean_q: 0.015094
 22961/100000: episode: 3235, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000577, mae: 0.021180, mean_q: 0.010250
 22966/100000: episode: 3236, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000668, mae: 0.018493, mean_q: 0.011902
 22968/100000: episode: 3237, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000311, mae: 0.012092, mean_q: 0.009987
 22973/100000: episode: 3238, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000897, mae: 0.024718, mean_q: 0.026022
 22975/100000: episode: 3239, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000656, mae: 0.026955, mean_q: 0.002929
 22977/100000: episode: 3240, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000907, mae: 0.024782, mean_q: 0.036037
 22982/100000: episode: 3241, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000373, mae: 0.015863, mean_q: 0.005641
 22984/100000: episode: 3242, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000886, mae: 0.025471, mean_q: 0.029698
 22986/100000: episode: 3243, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001087, mae: 0.016117, mean_q: 0.007197
 22991/100000: episode: 3244, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000377, mae: 0.012002, mean_q: 0.012230
 22993/100000: episode: 3245, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000178, mae: 0.014701, mean_q: 0.019527
 22995/100000: episode: 3246, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000080, mae: 0.008564, mean_q: 0.009787
 22997/100000: episode: 3247, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000251, mae: 0.012142, mean_q: 0.008130
 23002/100000: episode: 3248, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.004887, mae: 0.033590, mean_q: 0.030283
 23007/100000: episode: 3249, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001036, mae: 0.032615, mean_q: 0.004634
 23009/100000: episode: 3250, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000791, mae: 0.028089, mean_q: 0.036255
 23014/100000: episode: 3251, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000970, mae: 0.028628, mean_q: 0.001532
 23016/100000: episode: 3252, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000845, mae: 0.026338, mean_q: 0.032086
 23018/100000: episode: 3253, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001128, mae: 0.030379, mean_q: 0.040468
 23020/100000: episode: 3254, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000577, mae: 0.029089, mean_q: -0.020352
 23022/100000: episode: 3255, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001482, mae: 0.025186, mean_q: 0.022549
 23027/100000: episode: 3256, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002160, mae: 0.025361, mean_q: 0.027116
 23029/100000: episode: 3257, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000791, mae: 0.030837, mean_q: 0.046946
 23031/100000: episode: 3258, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000592, mae: 0.021381, mean_q: 0.012693
 23036/100000: episode: 3259, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000612, mae: 0.020724, mean_q: 0.009156
 23038/100000: episode: 3260, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000371, mae: 0.020091, mean_q: 0.029010
 23043/100000: episode: 3261, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000697, mae: 0.019893, mean_q: 0.001757
 23048/100000: episode: 3262, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000482, mae: 0.018587, mean_q: 0.023368
 23050/100000: episode: 3263, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000519, mae: 0.015986, mean_q: -0.002267
 23052/100000: episode: 3264, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000665, mae: 0.022145, mean_q: 0.025565
 23054/100000: episode: 3265, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000231, mae: 0.012966, mean_q: 0.014943
 23056/100000: episode: 3266, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001380, mae: 0.023548, mean_q: 0.015494
 23058/100000: episode: 3267, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002026, mae: 0.032011, mean_q: 0.044106
[Info] FALSIFICATION!
 23062/100000: episode: 3268, duration: 0.346s, episode steps: 4, steps per second: 12, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000936, mae: 0.025662, mean_q: 0.016745
 23064/100000: episode: 3269, duration: 0.014s, episode steps: 2, steps per second: 138, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001976, mae: 0.028274, mean_q: 0.025172
 23066/100000: episode: 3270, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000563, mae: 0.027687, mean_q: 0.036869
[Info] Complete ISplit Iteration
[Info] Levels: [0.048590645, 0.05892478, 0.78090477]
[Info] Cond. Prob: [0.1, 0.18, 0.01]
[Info] Error Prob: 0.00017999999999999998

 23068/100000: episode: 3271, duration: 0.744s, episode steps: 2, steps per second: 3, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001237, mae: 0.024327, mean_q: 0.016777
 23078/100000: episode: 3272, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001708, mae: 0.027359, mean_q: 0.016697
 23088/100000: episode: 3273, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001311, mae: 0.025659, mean_q: 0.026119
 23098/100000: episode: 3274, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000590, mae: 0.020362, mean_q: 0.014801
 23108/100000: episode: 3275, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001049, mae: 0.020307, mean_q: 0.023461
 23118/100000: episode: 3276, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001708, mae: 0.020310, mean_q: 0.021408
 23128/100000: episode: 3277, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000556, mae: 0.015703, mean_q: 0.018363
 23138/100000: episode: 3278, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000830, mae: 0.020142, mean_q: 0.016317
 23148/100000: episode: 3279, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000941, mae: 0.023399, mean_q: 0.020222
 23158/100000: episode: 3280, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000641, mae: 0.017550, mean_q: 0.019222
 23168/100000: episode: 3281, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001043, mae: 0.021197, mean_q: 0.022192
 23178/100000: episode: 3282, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000641, mae: 0.018160, mean_q: 0.019609
 23188/100000: episode: 3283, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000853, mae: 0.021037, mean_q: 0.019617
 23198/100000: episode: 3284, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000612, mae: 0.018782, mean_q: 0.016083
 23208/100000: episode: 3285, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000955, mae: 0.023444, mean_q: 0.018460
 23218/100000: episode: 3286, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001035, mae: 0.025222, mean_q: 0.022985
 23228/100000: episode: 3287, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000696, mae: 0.018182, mean_q: 0.019003
 23238/100000: episode: 3288, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002707, mae: 0.033960, mean_q: 0.035414
 23248/100000: episode: 3289, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001225, mae: 0.028709, mean_q: 0.015374
 23258/100000: episode: 3290, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000787, mae: 0.021311, mean_q: 0.020952
 23268/100000: episode: 3291, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000836, mae: 0.017938, mean_q: 0.014324
 23278/100000: episode: 3292, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001101, mae: 0.024584, mean_q: 0.024247
 23288/100000: episode: 3293, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000888, mae: 0.018342, mean_q: 0.018803
 23298/100000: episode: 3294, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000577, mae: 0.017258, mean_q: 0.015609
 23308/100000: episode: 3295, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001801, mae: 0.023630, mean_q: 0.027612
 23318/100000: episode: 3296, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000955, mae: 0.023611, mean_q: 0.018372
 23328/100000: episode: 3297, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000431, mae: 0.015220, mean_q: 0.015906
 23338/100000: episode: 3298, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001779, mae: 0.023853, mean_q: 0.021505
 23348/100000: episode: 3299, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000949, mae: 0.021804, mean_q: 0.016704
 23358/100000: episode: 3300, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000827, mae: 0.024241, mean_q: 0.021009
 23368/100000: episode: 3301, duration: 0.074s, episode steps: 10, steps per second: 134, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000758, mae: 0.020186, mean_q: 0.022313
 23378/100000: episode: 3302, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000777, mae: 0.018633, mean_q: 0.023150
 23388/100000: episode: 3303, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000561, mae: 0.016571, mean_q: 0.018452
 23398/100000: episode: 3304, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001105, mae: 0.021735, mean_q: 0.019367
 23408/100000: episode: 3305, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000543, mae: 0.019987, mean_q: 0.020293
 23418/100000: episode: 3306, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000454, mae: 0.015616, mean_q: 0.012475
 23428/100000: episode: 3307, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000951, mae: 0.019711, mean_q: 0.026575
 23438/100000: episode: 3308, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001408, mae: 0.022182, mean_q: 0.019859
 23448/100000: episode: 3309, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000870, mae: 0.021598, mean_q: 0.020016
 23458/100000: episode: 3310, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001045, mae: 0.022776, mean_q: 0.025091
 23468/100000: episode: 3311, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001286, mae: 0.028867, mean_q: 0.019299
 23478/100000: episode: 3312, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000853, mae: 0.026896, mean_q: 0.016522
 23488/100000: episode: 3313, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001143, mae: 0.026170, mean_q: 0.021202
 23498/100000: episode: 3314, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000741, mae: 0.019951, mean_q: 0.019677
 23508/100000: episode: 3315, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000649, mae: 0.016939, mean_q: 0.022209
 23518/100000: episode: 3316, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000779, mae: 0.020201, mean_q: 0.016078
 23528/100000: episode: 3317, duration: 0.072s, episode steps: 10, steps per second: 140, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000436, mae: 0.014492, mean_q: 0.012121
 23538/100000: episode: 3318, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000571, mae: 0.019531, mean_q: 0.016500
 23548/100000: episode: 3319, duration: 0.116s, episode steps: 10, steps per second: 86, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000900, mae: 0.022282, mean_q: 0.018849
 23558/100000: episode: 3320, duration: 0.093s, episode steps: 10, steps per second: 108, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001625, mae: 0.019840, mean_q: 0.023431
 23568/100000: episode: 3321, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001010, mae: 0.020451, mean_q: 0.021122
 23578/100000: episode: 3322, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000515, mae: 0.016128, mean_q: 0.015226
 23588/100000: episode: 3323, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001476, mae: 0.023721, mean_q: 0.020366
 23598/100000: episode: 3324, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000668, mae: 0.018158, mean_q: 0.020955
 23608/100000: episode: 3325, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000945, mae: 0.019257, mean_q: 0.021213
 23618/100000: episode: 3326, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000735, mae: 0.025038, mean_q: 0.018526
 23628/100000: episode: 3327, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001745, mae: 0.026211, mean_q: 0.021871
 23638/100000: episode: 3328, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000948, mae: 0.023995, mean_q: 0.027187
 23648/100000: episode: 3329, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000727, mae: 0.018224, mean_q: 0.015330
 23658/100000: episode: 3330, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000493, mae: 0.015186, mean_q: 0.015819
 23668/100000: episode: 3331, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000489, mae: 0.016318, mean_q: 0.017164
 23678/100000: episode: 3332, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001168, mae: 0.025030, mean_q: 0.020790
 23688/100000: episode: 3333, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000636, mae: 0.015926, mean_q: 0.018973
 23698/100000: episode: 3334, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000681, mae: 0.017662, mean_q: 0.017382
 23708/100000: episode: 3335, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000738, mae: 0.018045, mean_q: 0.013018
 23718/100000: episode: 3336, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000861, mae: 0.018065, mean_q: 0.022328
 23728/100000: episode: 3337, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000693, mae: 0.016496, mean_q: 0.013329
 23738/100000: episode: 3338, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000501, mae: 0.016216, mean_q: 0.011592
 23748/100000: episode: 3339, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000945, mae: 0.021567, mean_q: 0.016998
 23758/100000: episode: 3340, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001018, mae: 0.023450, mean_q: 0.022922
 23768/100000: episode: 3341, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000909, mae: 0.019168, mean_q: 0.022672
 23778/100000: episode: 3342, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000900, mae: 0.020813, mean_q: 0.019795
 23788/100000: episode: 3343, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000656, mae: 0.019013, mean_q: 0.009882
 23798/100000: episode: 3344, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000264, mae: 0.012208, mean_q: 0.010277
 23808/100000: episode: 3345, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000605, mae: 0.016248, mean_q: 0.016550
 23818/100000: episode: 3346, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000500, mae: 0.013290, mean_q: 0.014342
 23828/100000: episode: 3347, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000911, mae: 0.017592, mean_q: 0.015007
 23838/100000: episode: 3348, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001751, mae: 0.021587, mean_q: 0.021660
 23848/100000: episode: 3349, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000699, mae: 0.018347, mean_q: 0.020124
 23858/100000: episode: 3350, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000670, mae: 0.017873, mean_q: 0.020264
 23868/100000: episode: 3351, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000617, mae: 0.015156, mean_q: 0.016883
 23878/100000: episode: 3352, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000265, mae: 0.010285, mean_q: 0.013244
 23888/100000: episode: 3353, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000567, mae: 0.017978, mean_q: 0.015264
 23898/100000: episode: 3354, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000412, mae: 0.012965, mean_q: 0.013605
 23908/100000: episode: 3355, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000551, mae: 0.014927, mean_q: 0.014232
 23918/100000: episode: 3356, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000597, mae: 0.018495, mean_q: 0.013606
 23928/100000: episode: 3357, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000550, mae: 0.018196, mean_q: 0.014254
 23938/100000: episode: 3358, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000894, mae: 0.021856, mean_q: 0.016746
 23948/100000: episode: 3359, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000813, mae: 0.022561, mean_q: 0.019627
 23958/100000: episode: 3360, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001696, mae: 0.023566, mean_q: 0.014774
 23968/100000: episode: 3361, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000768, mae: 0.019929, mean_q: 0.012830
 23978/100000: episode: 3362, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000491, mae: 0.016229, mean_q: 0.014020
 23988/100000: episode: 3363, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000617, mae: 0.016081, mean_q: 0.019523
 23998/100000: episode: 3364, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000517, mae: 0.018276, mean_q: 0.021787
 24008/100000: episode: 3365, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000390, mae: 0.015080, mean_q: 0.011371
 24018/100000: episode: 3366, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000377, mae: 0.012221, mean_q: 0.009537
 24028/100000: episode: 3367, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000679, mae: 0.015358, mean_q: 0.020322
 24038/100000: episode: 3368, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001404, mae: 0.018555, mean_q: 0.013871
 24048/100000: episode: 3369, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001522, mae: 0.018932, mean_q: 0.020507
 24058/100000: episode: 3370, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000947, mae: 0.017635, mean_q: 0.020568
[Info] 1-TH LEVEL FOUND: 0.03360472619533539, Considering 11/100 traces
 24068/100000: episode: 3371, duration: 0.696s, episode steps: 10, steps per second: 14, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001351, mae: 0.017276, mean_q: 0.013766
 24075/100000: episode: 3372, duration: 0.042s, episode steps: 7, steps per second: 166, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000499, mae: 0.014146, mean_q: 0.014136
 24077/100000: episode: 3373, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000245, mae: 0.012164, mean_q: 0.012163
 24084/100000: episode: 3374, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000924, mae: 0.021675, mean_q: 0.021462
 24091/100000: episode: 3375, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000657, mae: 0.016374, mean_q: 0.015222
 24096/100000: episode: 3376, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000330, mae: 0.016416, mean_q: 0.005201
 24101/100000: episode: 3377, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000632, mae: 0.018389, mean_q: 0.015216
 24103/100000: episode: 3378, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000389, mae: 0.016663, mean_q: 0.001007
[Info] FALSIFICATION!
 24109/100000: episode: 3379, duration: 0.263s, episode steps: 6, steps per second: 23, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000808, mae: 0.018436, mean_q: 0.016615
 24116/100000: episode: 3380, duration: 0.037s, episode steps: 7, steps per second: 187, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000371, mae: 0.014899, mean_q: 0.017149
 24123/100000: episode: 3381, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000439, mae: 0.014865, mean_q: 0.014179
 24130/100000: episode: 3382, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000294, mae: 0.011380, mean_q: 0.006868
 24137/100000: episode: 3383, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000422, mae: 0.016389, mean_q: 0.017690
 24142/100000: episode: 3384, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000676, mae: 0.019902, mean_q: 0.020626
 24147/100000: episode: 3385, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000679, mae: 0.019223, mean_q: 0.011417
 24154/100000: episode: 3386, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000501, mae: 0.014745, mean_q: 0.011716
[Info] FALSIFICATION!
 24160/100000: episode: 3387, duration: 0.266s, episode steps: 6, steps per second: 23, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000592, mae: 0.017139, mean_q: 0.017866
 24167/100000: episode: 3388, duration: 0.037s, episode steps: 7, steps per second: 189, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000714, mae: 0.021683, mean_q: 0.019459
 24174/100000: episode: 3389, duration: 0.039s, episode steps: 7, steps per second: 181, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000436, mae: 0.014459, mean_q: 0.017919
 24179/100000: episode: 3390, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000523, mae: 0.014129, mean_q: 0.015328
 24184/100000: episode: 3391, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000685, mae: 0.014770, mean_q: 0.016630
 24189/100000: episode: 3392, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000356, mae: 0.011561, mean_q: 0.013976
 24194/100000: episode: 3393, duration: 0.028s, episode steps: 5, steps per second: 176, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000498, mae: 0.017123, mean_q: 0.019585
 24199/100000: episode: 3394, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000537, mae: 0.014436, mean_q: 0.010049
 24206/100000: episode: 3395, duration: 0.049s, episode steps: 7, steps per second: 142, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000222, mae: 0.011203, mean_q: 0.006650
 24213/100000: episode: 3396, duration: 0.081s, episode steps: 7, steps per second: 86, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001047, mae: 0.022399, mean_q: 0.022807
 24218/100000: episode: 3397, duration: 0.045s, episode steps: 5, steps per second: 111, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000264, mae: 0.014576, mean_q: 0.014277
 24225/100000: episode: 3398, duration: 0.053s, episode steps: 7, steps per second: 133, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000366, mae: 0.012699, mean_q: 0.014970
 24230/100000: episode: 3399, duration: 0.050s, episode steps: 5, steps per second: 99, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000361, mae: 0.011996, mean_q: 0.007797
 24237/100000: episode: 3400, duration: 0.085s, episode steps: 7, steps per second: 82, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000378, mae: 0.012912, mean_q: 0.012729
 24242/100000: episode: 3401, duration: 0.035s, episode steps: 5, steps per second: 142, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000615, mae: 0.018165, mean_q: 0.026273
 24247/100000: episode: 3402, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000583, mae: 0.016753, mean_q: 0.008596
 24252/100000: episode: 3403, duration: 0.030s, episode steps: 5, steps per second: 167, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000239, mae: 0.013114, mean_q: 0.008059
 24254/100000: episode: 3404, duration: 0.019s, episode steps: 2, steps per second: 103, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000209, mae: 0.010546, mean_q: 0.011960
 24259/100000: episode: 3405, duration: 0.040s, episode steps: 5, steps per second: 124, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000498, mae: 0.013894, mean_q: 0.008727
 24266/100000: episode: 3406, duration: 0.046s, episode steps: 7, steps per second: 152, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000513, mae: 0.017847, mean_q: 0.020445
 24273/100000: episode: 3407, duration: 0.050s, episode steps: 7, steps per second: 139, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000665, mae: 0.016782, mean_q: 0.019062
 24280/100000: episode: 3408, duration: 0.065s, episode steps: 7, steps per second: 108, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000515, mae: 0.013536, mean_q: 0.014284
 24287/100000: episode: 3409, duration: 0.048s, episode steps: 7, steps per second: 146, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000295, mae: 0.009817, mean_q: 0.008541
 24292/100000: episode: 3410, duration: 0.038s, episode steps: 5, steps per second: 133, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000769, mae: 0.013829, mean_q: 0.017534
 24294/100000: episode: 3411, duration: 0.018s, episode steps: 2, steps per second: 109, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000230, mae: 0.011088, mean_q: 0.013452
 24301/100000: episode: 3412, duration: 0.053s, episode steps: 7, steps per second: 133, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000314, mae: 0.014428, mean_q: 0.014425
 24306/100000: episode: 3413, duration: 0.036s, episode steps: 5, steps per second: 140, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000737, mae: 0.014097, mean_q: 0.015237
 24311/100000: episode: 3414, duration: 0.030s, episode steps: 5, steps per second: 164, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000341, mae: 0.014986, mean_q: 0.020743
 24316/100000: episode: 3415, duration: 0.034s, episode steps: 5, steps per second: 147, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002914, mae: 0.022762, mean_q: 0.022168
 24323/100000: episode: 3416, duration: 0.055s, episode steps: 7, steps per second: 128, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000797, mae: 0.016461, mean_q: 0.012455
 24328/100000: episode: 3417, duration: 0.031s, episode steps: 5, steps per second: 162, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000281, mae: 0.012881, mean_q: 0.015057
 24333/100000: episode: 3418, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000873, mae: 0.017505, mean_q: 0.014411
 24338/100000: episode: 3419, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000286, mae: 0.013227, mean_q: 0.008276
 24343/100000: episode: 3420, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.001281, mae: 0.025009, mean_q: 0.031079
 24348/100000: episode: 3421, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002586, mae: 0.022507, mean_q: 0.013969
 24353/100000: episode: 3422, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001263, mae: 0.018883, mean_q: 0.019788
 24358/100000: episode: 3423, duration: 0.036s, episode steps: 5, steps per second: 138, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.001992, mae: 0.025935, mean_q: 0.019553
 24363/100000: episode: 3424, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000966, mae: 0.026298, mean_q: 0.013394
 24365/100000: episode: 3425, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002199, mae: 0.026389, mean_q: 0.030061
 24372/100000: episode: 3426, duration: 0.042s, episode steps: 7, steps per second: 165, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.002460, mae: 0.025425, mean_q: 0.015242
 24377/100000: episode: 3427, duration: 0.058s, episode steps: 5, steps per second: 86, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000667, mae: 0.027264, mean_q: 0.033034
 24384/100000: episode: 3428, duration: 0.077s, episode steps: 7, steps per second: 91, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000629, mae: 0.023896, mean_q: 0.016752
 24391/100000: episode: 3429, duration: 0.051s, episode steps: 7, steps per second: 136, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000910, mae: 0.027370, mean_q: 0.013191
 24398/100000: episode: 3430, duration: 0.054s, episode steps: 7, steps per second: 129, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000648, mae: 0.020259, mean_q: 0.014497
 24405/100000: episode: 3431, duration: 0.037s, episode steps: 7, steps per second: 189, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000658, mae: 0.018264, mean_q: 0.014814
 24412/100000: episode: 3432, duration: 0.037s, episode steps: 7, steps per second: 188, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000500, mae: 0.019603, mean_q: 0.015237
 24414/100000: episode: 3433, duration: 0.018s, episode steps: 2, steps per second: 111, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000713, mae: 0.019082, mean_q: 0.002993
 24421/100000: episode: 3434, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000717, mae: 0.020761, mean_q: 0.022208
 24423/100000: episode: 3435, duration: 0.015s, episode steps: 2, steps per second: 134, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000736, mae: 0.023727, mean_q: -0.005637
 24430/100000: episode: 3436, duration: 0.038s, episode steps: 7, steps per second: 185, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000316, mae: 0.014223, mean_q: 0.013285
 24437/100000: episode: 3437, duration: 0.043s, episode steps: 7, steps per second: 161, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.002402, mae: 0.023484, mean_q: 0.026392
 24442/100000: episode: 3438, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000281, mae: 0.014744, mean_q: 0.003040
 24444/100000: episode: 3439, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000525, mae: 0.019938, mean_q: 0.023612
 24451/100000: episode: 3440, duration: 0.049s, episode steps: 7, steps per second: 142, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001142, mae: 0.018257, mean_q: 0.022002
 24458/100000: episode: 3441, duration: 0.053s, episode steps: 7, steps per second: 131, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000313, mae: 0.011902, mean_q: 0.013519
 24465/100000: episode: 3442, duration: 0.070s, episode steps: 7, steps per second: 100, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000422, mae: 0.015955, mean_q: 0.017702
 24470/100000: episode: 3443, duration: 0.044s, episode steps: 5, steps per second: 114, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000415, mae: 0.013984, mean_q: 0.013325
 24477/100000: episode: 3444, duration: 0.048s, episode steps: 7, steps per second: 146, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000828, mae: 0.025486, mean_q: 0.018145
 24484/100000: episode: 3445, duration: 0.039s, episode steps: 7, steps per second: 177, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000898, mae: 0.022429, mean_q: 0.026651
 24489/100000: episode: 3446, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.001296, mae: 0.024719, mean_q: 0.023174
 24491/100000: episode: 3447, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000590, mae: 0.019140, mean_q: 0.026823
 24498/100000: episode: 3448, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000408, mae: 0.015610, mean_q: 0.006456
 24505/100000: episode: 3449, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000982, mae: 0.019034, mean_q: 0.018985
 24512/100000: episode: 3450, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000563, mae: 0.015674, mean_q: 0.020174
 24514/100000: episode: 3451, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002446, mae: 0.022279, mean_q: 0.028836
 24519/100000: episode: 3452, duration: 0.024s, episode steps: 5, steps per second: 205, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.002492, mae: 0.015604, mean_q: 0.013767
 24524/100000: episode: 3453, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000498, mae: 0.019697, mean_q: 0.028045
 24531/100000: episode: 3454, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000986, mae: 0.019690, mean_q: 0.024508
 24538/100000: episode: 3455, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000412, mae: 0.014882, mean_q: 0.013302
 24545/100000: episode: 3456, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000465, mae: 0.015718, mean_q: 0.012984
 24552/100000: episode: 3457, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000770, mae: 0.015752, mean_q: 0.017880
 24559/100000: episode: 3458, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000782, mae: 0.016621, mean_q: 0.010662
 24566/100000: episode: 3459, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000428, mae: 0.018121, mean_q: 0.018854
[Info] Complete ISplit Iteration
[Info] Levels: [0.033604726, 0.7831198]
[Info] Cond. Prob: [0.11, 0.02]
[Info] Error Prob: 0.0022

 24568/100000: episode: 3460, duration: 1.076s, episode steps: 2, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001021, mae: 0.021516, mean_q: 0.035987
 24578/100000: episode: 3461, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001706, mae: 0.025522, mean_q: 0.022461
 24588/100000: episode: 3462, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000715, mae: 0.020505, mean_q: 0.017029
 24598/100000: episode: 3463, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000643, mae: 0.022076, mean_q: 0.015647
 24608/100000: episode: 3464, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000432, mae: 0.015397, mean_q: 0.013438
 24618/100000: episode: 3465, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000291, mae: 0.012153, mean_q: 0.012202
 24628/100000: episode: 3466, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000660, mae: 0.018192, mean_q: 0.019875
 24638/100000: episode: 3467, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001714, mae: 0.021870, mean_q: 0.019830
 24648/100000: episode: 3468, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000883, mae: 0.021731, mean_q: 0.018483
 24658/100000: episode: 3469, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001094, mae: 0.028628, mean_q: 0.020868
 24668/100000: episode: 3470, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000874, mae: 0.025426, mean_q: 0.014818
 24678/100000: episode: 3471, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000662, mae: 0.018878, mean_q: 0.021682
 24688/100000: episode: 3472, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000537, mae: 0.015296, mean_q: 0.016937
 24698/100000: episode: 3473, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001852, mae: 0.024901, mean_q: 0.017707
 24708/100000: episode: 3474, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000611, mae: 0.020522, mean_q: 0.009446
 24718/100000: episode: 3475, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000477, mae: 0.017190, mean_q: 0.015106
 24728/100000: episode: 3476, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000780, mae: 0.015415, mean_q: 0.016949
 24738/100000: episode: 3477, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000378, mae: 0.013141, mean_q: 0.012673
 24748/100000: episode: 3478, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000812, mae: 0.021325, mean_q: 0.017131
 24758/100000: episode: 3479, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001587, mae: 0.022131, mean_q: 0.021189
 24768/100000: episode: 3480, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001443, mae: 0.019510, mean_q: 0.023295
 24778/100000: episode: 3481, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001719, mae: 0.021214, mean_q: 0.015690
 24788/100000: episode: 3482, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001202, mae: 0.025081, mean_q: 0.026025
 24798/100000: episode: 3483, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000304, mae: 0.013091, mean_q: 0.011521
 24808/100000: episode: 3484, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000455, mae: 0.016083, mean_q: 0.016148
 24818/100000: episode: 3485, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000454, mae: 0.016067, mean_q: 0.012891
 24828/100000: episode: 3486, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000591, mae: 0.016137, mean_q: 0.016691
 24838/100000: episode: 3487, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001583, mae: 0.019145, mean_q: 0.021901
 24848/100000: episode: 3488, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001000, mae: 0.021561, mean_q: 0.021617
 24858/100000: episode: 3489, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000532, mae: 0.014256, mean_q: 0.018378
 24868/100000: episode: 3490, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000455, mae: 0.014215, mean_q: 0.013471
 24878/100000: episode: 3491, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000765, mae: 0.022426, mean_q: 0.017237
 24888/100000: episode: 3492, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000694, mae: 0.018281, mean_q: 0.012622
 24898/100000: episode: 3493, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000859, mae: 0.018197, mean_q: 0.020526
 24908/100000: episode: 3494, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000435, mae: 0.014693, mean_q: 0.016002
 24918/100000: episode: 3495, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000612, mae: 0.013841, mean_q: 0.013271
 24928/100000: episode: 3496, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001869, mae: 0.023982, mean_q: 0.019415
 24938/100000: episode: 3497, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001718, mae: 0.022377, mean_q: 0.018771
 24948/100000: episode: 3498, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000663, mae: 0.013806, mean_q: 0.016372
 24958/100000: episode: 3499, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000538, mae: 0.014138, mean_q: 0.015104
 24968/100000: episode: 3500, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.004259, mae: 0.038761, mean_q: 0.034977
 24978/100000: episode: 3501, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001392, mae: 0.031953, mean_q: 0.018072
 24988/100000: episode: 3502, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000574, mae: 0.021942, mean_q: 0.011503
 24998/100000: episode: 3503, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000618, mae: 0.019115, mean_q: 0.018981
 25008/100000: episode: 3504, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000942, mae: 0.024919, mean_q: 0.019978
 25018/100000: episode: 3505, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000880, mae: 0.020175, mean_q: 0.021665
 25028/100000: episode: 3506, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000789, mae: 0.019621, mean_q: 0.018255
 25038/100000: episode: 3507, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000539, mae: 0.017288, mean_q: 0.012521
 25048/100000: episode: 3508, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000488, mae: 0.016258, mean_q: 0.013618
 25058/100000: episode: 3509, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000473, mae: 0.015529, mean_q: 0.011380
 25068/100000: episode: 3510, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001891, mae: 0.017350, mean_q: 0.019339
 25078/100000: episode: 3511, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001022, mae: 0.021278, mean_q: 0.017528
 25088/100000: episode: 3512, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000812, mae: 0.017851, mean_q: 0.016988
 25098/100000: episode: 3513, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.001169, mae: 0.020521, mean_q: 0.024426
 25108/100000: episode: 3514, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000290, mae: 0.013130, mean_q: 0.012382
 25118/100000: episode: 3515, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000553, mae: 0.015005, mean_q: 0.017762
 25128/100000: episode: 3516, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000357, mae: 0.015425, mean_q: 0.016568
 25138/100000: episode: 3517, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001010, mae: 0.019498, mean_q: 0.023221
 25148/100000: episode: 3518, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000591, mae: 0.017348, mean_q: 0.013983
 25158/100000: episode: 3519, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000711, mae: 0.016953, mean_q: 0.015372
 25168/100000: episode: 3520, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000410, mae: 0.014472, mean_q: 0.015998
 25178/100000: episode: 3521, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000603, mae: 0.016368, mean_q: 0.020485
 25188/100000: episode: 3522, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001826, mae: 0.021264, mean_q: 0.019214
 25198/100000: episode: 3523, duration: 0.074s, episode steps: 10, steps per second: 136, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000570, mae: 0.019563, mean_q: 0.014921
 25208/100000: episode: 3524, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000828, mae: 0.021765, mean_q: 0.017992
 25218/100000: episode: 3525, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000596, mae: 0.017956, mean_q: 0.022201
 25228/100000: episode: 3526, duration: 0.055s, episode steps: 10, steps per second: 180, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000515, mae: 0.016790, mean_q: 0.016339
 25238/100000: episode: 3527, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000521, mae: 0.014514, mean_q: 0.014243
 25248/100000: episode: 3528, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000417, mae: 0.012885, mean_q: 0.012714
 25258/100000: episode: 3529, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000510, mae: 0.014935, mean_q: 0.014493
 25268/100000: episode: 3530, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001136, mae: 0.020590, mean_q: 0.020656
 25278/100000: episode: 3531, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000511, mae: 0.017128, mean_q: 0.014359
 25288/100000: episode: 3532, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000558, mae: 0.015183, mean_q: 0.013307
 25298/100000: episode: 3533, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001094, mae: 0.019520, mean_q: 0.027526
 25308/100000: episode: 3534, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000606, mae: 0.018809, mean_q: 0.013624
 25318/100000: episode: 3535, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000527, mae: 0.015895, mean_q: 0.016571
 25328/100000: episode: 3536, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000789, mae: 0.018787, mean_q: 0.019223
 25338/100000: episode: 3537, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000986, mae: 0.021861, mean_q: 0.022060
 25348/100000: episode: 3538, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000515, mae: 0.018914, mean_q: 0.012341
 25358/100000: episode: 3539, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000774, mae: 0.021579, mean_q: 0.016004
 25368/100000: episode: 3540, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000666, mae: 0.017441, mean_q: 0.016352
 25378/100000: episode: 3541, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000510, mae: 0.015902, mean_q: 0.017506
 25388/100000: episode: 3542, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000450, mae: 0.013621, mean_q: 0.013227
 25398/100000: episode: 3543, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000387, mae: 0.013601, mean_q: 0.013235
 25408/100000: episode: 3544, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000532, mae: 0.014665, mean_q: 0.016309
 25418/100000: episode: 3545, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000778, mae: 0.016147, mean_q: 0.015067
 25428/100000: episode: 3546, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000697, mae: 0.020451, mean_q: 0.013793
 25438/100000: episode: 3547, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000341, mae: 0.016489, mean_q: 0.013503
 25448/100000: episode: 3548, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000575, mae: 0.016460, mean_q: 0.014128
 25458/100000: episode: 3549, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001074, mae: 0.022044, mean_q: 0.021266
 25468/100000: episode: 3550, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000790, mae: 0.019042, mean_q: 0.023349
 25478/100000: episode: 3551, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001823, mae: 0.025958, mean_q: 0.013876
 25488/100000: episode: 3552, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000400, mae: 0.017759, mean_q: 0.011664
 25498/100000: episode: 3553, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001797, mae: 0.021926, mean_q: 0.025644
 25508/100000: episode: 3554, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000633, mae: 0.020836, mean_q: 0.013993
 25518/100000: episode: 3555, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000272, mae: 0.013586, mean_q: 0.010137
 25528/100000: episode: 3556, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001332, mae: 0.018316, mean_q: 0.012437
 25538/100000: episode: 3557, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001434, mae: 0.022869, mean_q: 0.013548
 25548/100000: episode: 3558, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000593, mae: 0.016569, mean_q: 0.017810
 25558/100000: episode: 3559, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000593, mae: 0.015441, mean_q: 0.014328
[Info] 1-TH LEVEL FOUND: 0.019318610429763794, Considering 10/100 traces
 25568/100000: episode: 3560, duration: 0.716s, episode steps: 10, steps per second: 14, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000682, mae: 0.015155, mean_q: 0.014796
 25573/100000: episode: 3561, duration: 0.029s, episode steps: 5, steps per second: 173, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000168, mae: 0.009133, mean_q: 0.009551
 25581/100000: episode: 3562, duration: 0.041s, episode steps: 8, steps per second: 196, episode reward: 0.065, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000447, mae: 0.014948, mean_q: 0.013832
 25589/100000: episode: 3563, duration: 0.041s, episode steps: 8, steps per second: 197, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000999, mae: 0.018033, mean_q: 0.012512
 25594/100000: episode: 3564, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000617, mae: 0.022238, mean_q: -0.000479
 25602/100000: episode: 3565, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000575, mae: 0.018343, mean_q: 0.018301
 25610/100000: episode: 3566, duration: 0.040s, episode steps: 8, steps per second: 198, episode reward: 0.114, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000328, mae: 0.013200, mean_q: 0.014961
 25618/100000: episode: 3567, duration: 0.041s, episode steps: 8, steps per second: 197, episode reward: 0.032, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000410, mae: 0.013503, mean_q: 0.016815
 25623/100000: episode: 3568, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000247, mae: 0.009691, mean_q: 0.010485
 25628/100000: episode: 3569, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000499, mae: 0.014290, mean_q: 0.014212
 25633/100000: episode: 3570, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000508, mae: 0.017503, mean_q: 0.003868
 25641/100000: episode: 3571, duration: 0.040s, episode steps: 8, steps per second: 199, episode reward: 0.023, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000418, mae: 0.015145, mean_q: 0.016862
 25649/100000: episode: 3572, duration: 0.045s, episode steps: 8, steps per second: 177, episode reward: 0.079, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001902, mae: 0.021738, mean_q: 0.020047
 25657/100000: episode: 3573, duration: 0.040s, episode steps: 8, steps per second: 202, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.812 [-1.000, 11.000], loss: 0.001956, mae: 0.021707, mean_q: 0.024431
 25662/100000: episode: 3574, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002226, mae: 0.016557, mean_q: 0.019135
 25670/100000: episode: 3575, duration: 0.041s, episode steps: 8, steps per second: 194, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000516, mae: 0.017490, mean_q: 0.011055
 25678/100000: episode: 3576, duration: 0.040s, episode steps: 8, steps per second: 201, episode reward: 0.085, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001704, mae: 0.018657, mean_q: 0.014895
 25686/100000: episode: 3577, duration: 0.040s, episode steps: 8, steps per second: 202, episode reward: 0.054, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000361, mae: 0.015530, mean_q: 0.007416
 25691/100000: episode: 3578, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000286, mae: 0.012728, mean_q: 0.006222
 25699/100000: episode: 3579, duration: 0.040s, episode steps: 8, steps per second: 199, episode reward: 0.015, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000272, mae: 0.010012, mean_q: 0.008925
 25707/100000: episode: 3580, duration: 0.043s, episode steps: 8, steps per second: 186, episode reward: 0.065, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000828, mae: 0.016650, mean_q: 0.013893
 25715/100000: episode: 3581, duration: 0.040s, episode steps: 8, steps per second: 201, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000854, mae: 0.019285, mean_q: 0.014907
[Info] FALSIFICATION!
 25722/100000: episode: 3582, duration: 0.192s, episode steps: 7, steps per second: 36, episode reward: 1.581, mean reward: 0.226 [0.002, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.000 [4.000, 10.000], loss: 0.002176, mae: 0.021535, mean_q: 0.015727
 25730/100000: episode: 3583, duration: 0.043s, episode steps: 8, steps per second: 187, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.001922, mae: 0.018426, mean_q: 0.021830
 25738/100000: episode: 3584, duration: 0.041s, episode steps: 8, steps per second: 194, episode reward: 0.055, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001301, mae: 0.021480, mean_q: 0.021583
 25746/100000: episode: 3585, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000395, mae: 0.013578, mean_q: 0.014567
 25751/100000: episode: 3586, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000153, mae: 0.010593, mean_q: 0.007828
 25756/100000: episode: 3587, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.002148, mae: 0.016812, mean_q: 0.015134
 25764/100000: episode: 3588, duration: 0.040s, episode steps: 8, steps per second: 202, episode reward: 0.035, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000419, mae: 0.016447, mean_q: 0.005702
 25772/100000: episode: 3589, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.067, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000378, mae: 0.014599, mean_q: 0.006157
 25780/100000: episode: 3590, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000558, mae: 0.018042, mean_q: 0.020405
 25788/100000: episode: 3591, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.039, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000541, mae: 0.012663, mean_q: 0.013001
 25796/100000: episode: 3592, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.022, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000526, mae: 0.016787, mean_q: 0.015286
 25801/100000: episode: 3593, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001108, mae: 0.024903, mean_q: 0.007373
 25809/100000: episode: 3594, duration: 0.037s, episode steps: 8, steps per second: 213, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.001181, mae: 0.026036, mean_q: 0.031556
 25817/100000: episode: 3595, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.097, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000933, mae: 0.022528, mean_q: 0.021459
 25825/100000: episode: 3596, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.085, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000829, mae: 0.021090, mean_q: 0.018471
 25833/100000: episode: 3597, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.097, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.001112, mae: 0.023938, mean_q: 0.019963
 25838/100000: episode: 3598, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000552, mae: 0.019803, mean_q: 0.019413
 25843/100000: episode: 3599, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000563, mae: 0.017905, mean_q: 0.014894
 25851/100000: episode: 3600, duration: 0.040s, episode steps: 8, steps per second: 201, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000387, mae: 0.016455, mean_q: 0.008151
 25859/100000: episode: 3601, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000434, mae: 0.013643, mean_q: 0.010876
 25867/100000: episode: 3602, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.036, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000759, mae: 0.015525, mean_q: 0.016903
 25875/100000: episode: 3603, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.023, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000807, mae: 0.017261, mean_q: 0.017008
 25880/100000: episode: 3604, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000376, mae: 0.017651, mean_q: 0.004163
 25885/100000: episode: 3605, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003068, mae: 0.034652, mean_q: 0.038253
 25893/100000: episode: 3606, duration: 0.040s, episode steps: 8, steps per second: 202, episode reward: 0.022, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.001861, mae: 0.025791, mean_q: 0.011806
 25901/100000: episode: 3607, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.128, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.002133, mae: 0.028681, mean_q: 0.014873
 25909/100000: episode: 3608, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001225, mae: 0.027772, mean_q: 0.006808
 25917/100000: episode: 3609, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.875 [-1.000, 11.000], loss: 0.000551, mae: 0.020773, mean_q: 0.011631
 25925/100000: episode: 3610, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.875 [-1.000, 11.000], loss: 0.000878, mae: 0.020883, mean_q: 0.017133
 25933/100000: episode: 3611, duration: 0.060s, episode steps: 8, steps per second: 133, episode reward: 0.032, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000888, mae: 0.017801, mean_q: 0.021180
 25941/100000: episode: 3612, duration: 0.067s, episode steps: 8, steps per second: 120, episode reward: 0.348, mean reward: 0.044 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000523, mae: 0.013976, mean_q: 0.013912
 25949/100000: episode: 3613, duration: 0.050s, episode steps: 8, steps per second: 161, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000549, mae: 0.017709, mean_q: 0.013503
 25957/100000: episode: 3614, duration: 0.044s, episode steps: 8, steps per second: 180, episode reward: 0.215, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000648, mae: 0.019342, mean_q: 0.009333
 25962/100000: episode: 3615, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000674, mae: 0.017887, mean_q: 0.020885
 25967/100000: episode: 3616, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000821, mae: 0.015447, mean_q: 0.015717
 25975/100000: episode: 3617, duration: 0.040s, episode steps: 8, steps per second: 200, episode reward: 0.130, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000395, mae: 0.012204, mean_q: 0.016410
 25983/100000: episode: 3618, duration: 0.076s, episode steps: 8, steps per second: 106, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000743, mae: 0.015916, mean_q: 0.017186
 25991/100000: episode: 3619, duration: 0.061s, episode steps: 8, steps per second: 130, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000307, mae: 0.011732, mean_q: 0.011104
 25999/100000: episode: 3620, duration: 0.058s, episode steps: 8, steps per second: 138, episode reward: 0.130, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000335, mae: 0.011303, mean_q: 0.011513
 26007/100000: episode: 3621, duration: 0.058s, episode steps: 8, steps per second: 137, episode reward: 0.032, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000797, mae: 0.016678, mean_q: 0.018303
 26012/100000: episode: 3622, duration: 0.035s, episode steps: 5, steps per second: 145, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000446, mae: 0.015074, mean_q: 0.017886
 26020/100000: episode: 3623, duration: 0.043s, episode steps: 8, steps per second: 185, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000656, mae: 0.014687, mean_q: 0.013344
 26028/100000: episode: 3624, duration: 0.044s, episode steps: 8, steps per second: 181, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000751, mae: 0.012773, mean_q: 0.014536
 26033/100000: episode: 3625, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000509, mae: 0.013534, mean_q: 0.017600
 26038/100000: episode: 3626, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000306, mae: 0.011664, mean_q: 0.011615
 26043/100000: episode: 3627, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000870, mae: 0.017696, mean_q: 0.030438
 26051/100000: episode: 3628, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.036, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000705, mae: 0.014289, mean_q: 0.012443
 26059/100000: episode: 3629, duration: 0.083s, episode steps: 8, steps per second: 96, episode reward: 0.085, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001781, mae: 0.026136, mean_q: 0.016537
 26067/100000: episode: 3630, duration: 0.067s, episode steps: 8, steps per second: 120, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000406, mae: 0.014148, mean_q: 0.009194
 26075/100000: episode: 3631, duration: 0.057s, episode steps: 8, steps per second: 140, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000326, mae: 0.015513, mean_q: 0.013765
 26083/100000: episode: 3632, duration: 0.045s, episode steps: 8, steps per second: 177, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000405, mae: 0.014248, mean_q: 0.014266
 26091/100000: episode: 3633, duration: 0.064s, episode steps: 8, steps per second: 124, episode reward: 0.082, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000484, mae: 0.016118, mean_q: 0.015230
 26099/100000: episode: 3634, duration: 0.068s, episode steps: 8, steps per second: 117, episode reward: 0.022, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000371, mae: 0.015182, mean_q: 0.014060
 26107/100000: episode: 3635, duration: 0.067s, episode steps: 8, steps per second: 119, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000293, mae: 0.012729, mean_q: 0.012861
 26115/100000: episode: 3636, duration: 0.102s, episode steps: 8, steps per second: 79, episode reward: 0.102, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000281, mae: 0.011920, mean_q: 0.010016
 26123/100000: episode: 3637, duration: 0.081s, episode steps: 8, steps per second: 98, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000283, mae: 0.011484, mean_q: 0.011514
 26131/100000: episode: 3638, duration: 0.063s, episode steps: 8, steps per second: 127, episode reward: 0.038, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000302, mae: 0.013286, mean_q: 0.014127
 26139/100000: episode: 3639, duration: 0.076s, episode steps: 8, steps per second: 106, episode reward: 0.023, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000432, mae: 0.013680, mean_q: 0.011435
 26147/100000: episode: 3640, duration: 0.077s, episode steps: 8, steps per second: 104, episode reward: 0.049, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000354, mae: 0.011898, mean_q: 0.012865
 26155/100000: episode: 3641, duration: 0.074s, episode steps: 8, steps per second: 107, episode reward: 0.065, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000426, mae: 0.014437, mean_q: 0.011615
 26160/100000: episode: 3642, duration: 0.039s, episode steps: 5, steps per second: 129, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000847, mae: 0.017067, mean_q: 0.018693
 26168/100000: episode: 3643, duration: 0.049s, episode steps: 8, steps per second: 165, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.812 [-1.000, 11.000], loss: 0.000555, mae: 0.013897, mean_q: 0.013601
 26176/100000: episode: 3644, duration: 0.043s, episode steps: 8, steps per second: 186, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000585, mae: 0.016732, mean_q: 0.023462
 26181/100000: episode: 3645, duration: 0.039s, episode steps: 5, steps per second: 128, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000445, mae: 0.014387, mean_q: 0.015528
 26189/100000: episode: 3646, duration: 0.058s, episode steps: 8, steps per second: 137, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001033, mae: 0.022116, mean_q: 0.019486
 26194/100000: episode: 3647, duration: 0.041s, episode steps: 5, steps per second: 121, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000514, mae: 0.018085, mean_q: 0.004004
 26202/100000: episode: 3648, duration: 0.068s, episode steps: 8, steps per second: 118, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000543, mae: 0.016411, mean_q: 0.014930
 26210/100000: episode: 3649, duration: 0.052s, episode steps: 8, steps per second: 153, episode reward: 0.036, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000503, mae: 0.017259, mean_q: 0.015250
[Info] Complete ISplit Iteration
[Info] Levels: [0.01931861, 0.7093835]
[Info] Cond. Prob: [0.1, 0.01]
[Info] Error Prob: 0.001

 26218/100000: episode: 3650, duration: 1.178s, episode steps: 8, steps per second: 7, episode reward: 0.033, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000476, mae: 0.019211, mean_q: 0.020602
 26228/100000: episode: 3651, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000316, mae: 0.014695, mean_q: 0.010057
 26238/100000: episode: 3652, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000520, mae: 0.013872, mean_q: 0.014365
 26248/100000: episode: 3653, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000681, mae: 0.018179, mean_q: 0.013513
 26258/100000: episode: 3654, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001236, mae: 0.015631, mean_q: 0.014360
 26268/100000: episode: 3655, duration: 0.070s, episode steps: 10, steps per second: 144, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000619, mae: 0.014337, mean_q: 0.015854
 26278/100000: episode: 3656, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000410, mae: 0.012807, mean_q: 0.015242
 26288/100000: episode: 3657, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001628, mae: 0.018870, mean_q: 0.016371
 26298/100000: episode: 3658, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001324, mae: 0.016660, mean_q: 0.017005
 26308/100000: episode: 3659, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000774, mae: 0.017990, mean_q: 0.019736
 26318/100000: episode: 3660, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000469, mae: 0.011422, mean_q: 0.011615
 26328/100000: episode: 3661, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000976, mae: 0.020658, mean_q: 0.025126
 26338/100000: episode: 3662, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000612, mae: 0.016369, mean_q: 0.017724
 26348/100000: episode: 3663, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000768, mae: 0.019258, mean_q: 0.015620
 26358/100000: episode: 3664, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000346, mae: 0.013132, mean_q: 0.012249
 26368/100000: episode: 3665, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000587, mae: 0.015161, mean_q: 0.013967
 26378/100000: episode: 3666, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000523, mae: 0.016890, mean_q: 0.017946
 26388/100000: episode: 3667, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000702, mae: 0.018366, mean_q: 0.015674
 26398/100000: episode: 3668, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000295, mae: 0.014801, mean_q: 0.007145
 26408/100000: episode: 3669, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000258, mae: 0.012680, mean_q: 0.011102
 26418/100000: episode: 3670, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000438, mae: 0.014648, mean_q: 0.013432
 26428/100000: episode: 3671, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000431, mae: 0.017388, mean_q: 0.012290
 26438/100000: episode: 3672, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000438, mae: 0.016738, mean_q: 0.014108
 26448/100000: episode: 3673, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000570, mae: 0.017889, mean_q: 0.017178
 26458/100000: episode: 3674, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000334, mae: 0.015151, mean_q: 0.014699
 26468/100000: episode: 3675, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000996, mae: 0.021928, mean_q: 0.020792
 26478/100000: episode: 3676, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000419, mae: 0.015413, mean_q: 0.014916
 26488/100000: episode: 3677, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000665, mae: 0.013590, mean_q: 0.014966
 26498/100000: episode: 3678, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000382, mae: 0.015719, mean_q: 0.012313
 26508/100000: episode: 3679, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000386, mae: 0.014943, mean_q: 0.012048
 26518/100000: episode: 3680, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000437, mae: 0.012227, mean_q: 0.012377
 26528/100000: episode: 3681, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000680, mae: 0.020002, mean_q: 0.020007
 26538/100000: episode: 3682, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000569, mae: 0.014303, mean_q: 0.016089
 26548/100000: episode: 3683, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000523, mae: 0.014189, mean_q: 0.015945
 26558/100000: episode: 3684, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000554, mae: 0.013869, mean_q: 0.015131
 26568/100000: episode: 3685, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001073, mae: 0.020223, mean_q: 0.018538
 26578/100000: episode: 3686, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000283, mae: 0.017368, mean_q: 0.014384
 26588/100000: episode: 3687, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000247, mae: 0.012653, mean_q: 0.010228
 26598/100000: episode: 3688, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000560, mae: 0.015754, mean_q: 0.017840
 26608/100000: episode: 3689, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000331, mae: 0.011498, mean_q: 0.012401
 26618/100000: episode: 3690, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000418, mae: 0.012589, mean_q: 0.016638
 26628/100000: episode: 3691, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000369, mae: 0.013668, mean_q: 0.017824
 26638/100000: episode: 3692, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000505, mae: 0.016495, mean_q: 0.011468
 26648/100000: episode: 3693, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000367, mae: 0.011413, mean_q: 0.013767
 26658/100000: episode: 3694, duration: 0.069s, episode steps: 10, steps per second: 146, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000771, mae: 0.015320, mean_q: 0.014127
 26668/100000: episode: 3695, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000686, mae: 0.017921, mean_q: 0.015316
 26678/100000: episode: 3696, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000563, mae: 0.018362, mean_q: 0.016021
 26688/100000: episode: 3697, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000325, mae: 0.014779, mean_q: 0.010898
 26698/100000: episode: 3698, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000309, mae: 0.011339, mean_q: 0.011368
 26708/100000: episode: 3699, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000408, mae: 0.011430, mean_q: 0.016475
 26718/100000: episode: 3700, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000811, mae: 0.015225, mean_q: 0.019450
 26728/100000: episode: 3701, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000483, mae: 0.015898, mean_q: 0.012741
 26738/100000: episode: 3702, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000376, mae: 0.010653, mean_q: 0.009812
 26748/100000: episode: 3703, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000436, mae: 0.012036, mean_q: 0.015671
 26758/100000: episode: 3704, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000982, mae: 0.014883, mean_q: 0.020093
 26768/100000: episode: 3705, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000545, mae: 0.013643, mean_q: 0.015057
 26778/100000: episode: 3706, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000456, mae: 0.011932, mean_q: 0.012127
 26788/100000: episode: 3707, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000580, mae: 0.013947, mean_q: 0.016176
 26798/100000: episode: 3708, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000598, mae: 0.015988, mean_q: 0.016382
 26808/100000: episode: 3709, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000576, mae: 0.017087, mean_q: 0.017172
 26818/100000: episode: 3710, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000511, mae: 0.014301, mean_q: 0.010305
 26828/100000: episode: 3711, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000621, mae: 0.016625, mean_q: 0.014977
 26838/100000: episode: 3712, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000626, mae: 0.014335, mean_q: 0.013365
 26848/100000: episode: 3713, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000431, mae: 0.013154, mean_q: 0.015597
 26858/100000: episode: 3714, duration: 0.110s, episode steps: 10, steps per second: 91, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000799, mae: 0.018226, mean_q: 0.021562
 26868/100000: episode: 3715, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000433, mae: 0.014718, mean_q: 0.011780
 26878/100000: episode: 3716, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000313, mae: 0.012185, mean_q: 0.010523
 26888/100000: episode: 3717, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000553, mae: 0.015947, mean_q: 0.015524
 26898/100000: episode: 3718, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000552, mae: 0.016829, mean_q: 0.013894
 26908/100000: episode: 3719, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000743, mae: 0.013984, mean_q: 0.013656
 26918/100000: episode: 3720, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000386, mae: 0.012488, mean_q: 0.013024
 26928/100000: episode: 3721, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000753, mae: 0.016051, mean_q: 0.018386
 26938/100000: episode: 3722, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000607, mae: 0.016283, mean_q: 0.009312
 26948/100000: episode: 3723, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000926, mae: 0.017606, mean_q: 0.020146
 26958/100000: episode: 3724, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000848, mae: 0.021727, mean_q: 0.019264
 26968/100000: episode: 3725, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000877, mae: 0.020563, mean_q: 0.009941
 26978/100000: episode: 3726, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000562, mae: 0.019322, mean_q: 0.016895
 26988/100000: episode: 3727, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000971, mae: 0.022443, mean_q: 0.013577
 26998/100000: episode: 3728, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000452, mae: 0.012152, mean_q: 0.012949
 27008/100000: episode: 3729, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000835, mae: 0.018290, mean_q: 0.017091
 27018/100000: episode: 3730, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000563, mae: 0.017288, mean_q: 0.015384
 27028/100000: episode: 3731, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000501, mae: 0.018651, mean_q: 0.017192
 27038/100000: episode: 3732, duration: 0.092s, episode steps: 10, steps per second: 108, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000362, mae: 0.015452, mean_q: 0.009396
 27048/100000: episode: 3733, duration: 0.067s, episode steps: 10, steps per second: 148, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000618, mae: 0.017865, mean_q: 0.012921
 27058/100000: episode: 3734, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001045, mae: 0.023733, mean_q: 0.015868
 27068/100000: episode: 3735, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000640, mae: 0.022119, mean_q: 0.017205
 27078/100000: episode: 3736, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000667, mae: 0.015745, mean_q: 0.014193
 27088/100000: episode: 3737, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000629, mae: 0.014102, mean_q: 0.017706
 27098/100000: episode: 3738, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000382, mae: 0.011557, mean_q: 0.012200
 27108/100000: episode: 3739, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000887, mae: 0.016469, mean_q: 0.022310
 27118/100000: episode: 3740, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001527, mae: 0.018335, mean_q: 0.016191
 27128/100000: episode: 3741, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000438, mae: 0.014773, mean_q: 0.011099
 27138/100000: episode: 3742, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000562, mae: 0.016511, mean_q: 0.012641
 27148/100000: episode: 3743, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000382, mae: 0.013657, mean_q: 0.013776
 27158/100000: episode: 3744, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000369, mae: 0.012258, mean_q: 0.011192
 27168/100000: episode: 3745, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000237, mae: 0.013761, mean_q: 0.012764
 27178/100000: episode: 3746, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000491, mae: 0.014903, mean_q: 0.017586
 27188/100000: episode: 3747, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001445, mae: 0.017563, mean_q: 0.017055
 27198/100000: episode: 3748, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000651, mae: 0.019300, mean_q: 0.016930
 27208/100000: episode: 3749, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000590, mae: 0.017424, mean_q: 0.010779
[Info] 1-TH LEVEL FOUND: 0.020619958639144897, Considering 14/100 traces
 27218/100000: episode: 3750, duration: 0.698s, episode steps: 10, steps per second: 14, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000418, mae: 0.011919, mean_q: 0.010695
 27225/100000: episode: 3751, duration: 0.037s, episode steps: 7, steps per second: 188, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000704, mae: 0.013910, mean_q: 0.019790
 27227/100000: episode: 3752, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000659, mae: 0.011644, mean_q: 0.015368
 27234/100000: episode: 3753, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000267, mae: 0.013178, mean_q: 0.011845
 27236/100000: episode: 3754, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000134, mae: 0.008238, mean_q: 0.013902
[Info] FALSIFICATION!
 27242/100000: episode: 3755, duration: 0.269s, episode steps: 6, steps per second: 22, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000968, mae: 0.019110, mean_q: 0.016364
 27244/100000: episode: 3756, duration: 0.022s, episode steps: 2, steps per second: 93, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001200, mae: 0.018635, mean_q: 0.030208
 27246/100000: episode: 3757, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000252, mae: 0.013363, mean_q: 0.019496
 27249/100000: episode: 3758, duration: 0.021s, episode steps: 3, steps per second: 143, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000591, mae: 0.018483, mean_q: 0.015110
 27251/100000: episode: 3759, duration: 0.017s, episode steps: 2, steps per second: 116, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000771, mae: 0.020438, mean_q: 0.014660
 27258/100000: episode: 3760, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000462, mae: 0.011532, mean_q: 0.012297
 27260/100000: episode: 3761, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000394, mae: 0.013697, mean_q: 0.010821
 27262/100000: episode: 3762, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000321, mae: 0.015760, mean_q: 0.021927
 27269/100000: episode: 3763, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000480, mae: 0.016910, mean_q: 0.012132
 27276/100000: episode: 3764, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000527, mae: 0.019728, mean_q: 0.009548
 27278/100000: episode: 3765, duration: 0.018s, episode steps: 2, steps per second: 109, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001067, mae: 0.025622, mean_q: 0.037128
 27285/100000: episode: 3766, duration: 0.039s, episode steps: 7, steps per second: 179, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000292, mae: 0.012041, mean_q: 0.004845
 27287/100000: episode: 3767, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000087, mae: 0.008049, mean_q: 0.009705
 27294/100000: episode: 3768, duration: 0.044s, episode steps: 7, steps per second: 160, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000151, mae: 0.009762, mean_q: 0.011043
 27301/100000: episode: 3769, duration: 0.038s, episode steps: 7, steps per second: 184, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000376, mae: 0.012374, mean_q: 0.013289
 27303/100000: episode: 3770, duration: 0.014s, episode steps: 2, steps per second: 139, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000358, mae: 0.011489, mean_q: 0.010680
 27310/100000: episode: 3771, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000508, mae: 0.013157, mean_q: 0.016137
 27317/100000: episode: 3772, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000607, mae: 0.014966, mean_q: 0.015875
 27319/100000: episode: 3773, duration: 0.017s, episode steps: 2, steps per second: 120, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000974, mae: 0.014686, mean_q: 0.016935
 27326/100000: episode: 3774, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000643, mae: 0.012964, mean_q: 0.014666
 27333/100000: episode: 3775, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000124, mae: 0.008457, mean_q: 0.010141
 27340/100000: episode: 3776, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000313, mae: 0.011614, mean_q: 0.011612
 27342/100000: episode: 3777, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000195, mae: 0.010345, mean_q: 0.016544
 27344/100000: episode: 3778, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000081, mae: 0.008336, mean_q: 0.012648
 27351/100000: episode: 3779, duration: 0.057s, episode steps: 7, steps per second: 124, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000608, mae: 0.013430, mean_q: 0.015943
 27358/100000: episode: 3780, duration: 0.056s, episode steps: 7, steps per second: 125, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000351, mae: 0.010694, mean_q: 0.009293
 27360/100000: episode: 3781, duration: 0.024s, episode steps: 2, steps per second: 82, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000130, mae: 0.012774, mean_q: 0.016721
 27362/100000: episode: 3782, duration: 0.020s, episode steps: 2, steps per second: 102, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000273, mae: 0.014133, mean_q: 0.017372
 27369/100000: episode: 3783, duration: 0.053s, episode steps: 7, steps per second: 131, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000664, mae: 0.014509, mean_q: 0.009657
 27376/100000: episode: 3784, duration: 0.051s, episode steps: 7, steps per second: 138, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000356, mae: 0.013796, mean_q: 0.007734
 27378/100000: episode: 3785, duration: 0.024s, episode steps: 2, steps per second: 83, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000427, mae: 0.019569, mean_q: 0.021941
 27385/100000: episode: 3786, duration: 0.059s, episode steps: 7, steps per second: 118, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000378, mae: 0.013226, mean_q: 0.009308
 27392/100000: episode: 3787, duration: 0.048s, episode steps: 7, steps per second: 145, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000409, mae: 0.010902, mean_q: 0.013699
 27399/100000: episode: 3788, duration: 0.038s, episode steps: 7, steps per second: 185, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000632, mae: 0.012322, mean_q: 0.011228
 27401/100000: episode: 3789, duration: 0.019s, episode steps: 2, steps per second: 103, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000688, mae: 0.019196, mean_q: 0.030901
 27408/100000: episode: 3790, duration: 0.043s, episode steps: 7, steps per second: 163, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000736, mae: 0.016533, mean_q: 0.015467
 27415/100000: episode: 3791, duration: 0.047s, episode steps: 7, steps per second: 149, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000416, mae: 0.011910, mean_q: 0.012755
 27422/100000: episode: 3792, duration: 0.039s, episode steps: 7, steps per second: 181, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000250, mae: 0.010503, mean_q: 0.010892
 27424/100000: episode: 3793, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000348, mae: 0.015986, mean_q: -0.000461
 27426/100000: episode: 3794, duration: 0.014s, episode steps: 2, steps per second: 143, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000341, mae: 0.019197, mean_q: 0.026427
 27428/100000: episode: 3795, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000227, mae: 0.010202, mean_q: 0.009632
 27430/100000: episode: 3796, duration: 0.014s, episode steps: 2, steps per second: 138, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000207, mae: 0.013350, mean_q: 0.007171
 27433/100000: episode: 3797, duration: 0.023s, episode steps: 3, steps per second: 128, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000391, mae: 0.019045, mean_q: 0.027537
 27440/100000: episode: 3798, duration: 0.038s, episode steps: 7, steps per second: 182, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000236, mae: 0.013951, mean_q: 0.004356
 27442/100000: episode: 3799, duration: 0.019s, episode steps: 2, steps per second: 108, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000244, mae: 0.013641, mean_q: 0.015470
 27444/100000: episode: 3800, duration: 0.019s, episode steps: 2, steps per second: 103, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000580, mae: 0.016182, mean_q: 0.004571
 27447/100000: episode: 3801, duration: 0.031s, episode steps: 3, steps per second: 97, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000427, mae: 0.012584, mean_q: 0.018050
 27449/100000: episode: 3802, duration: 0.024s, episode steps: 2, steps per second: 83, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000172, mae: 0.011432, mean_q: 0.004417
 27456/100000: episode: 3803, duration: 0.044s, episode steps: 7, steps per second: 158, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000433, mae: 0.012611, mean_q: 0.016567
 27458/100000: episode: 3804, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000172, mae: 0.013318, mean_q: -0.001384
 27460/100000: episode: 3805, duration: 0.014s, episode steps: 2, steps per second: 142, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000146, mae: 0.012623, mean_q: 0.016457
 27467/100000: episode: 3806, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000503, mae: 0.012422, mean_q: 0.015193
 27469/100000: episode: 3807, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000164, mae: 0.013610, mean_q: 0.018763
 27476/100000: episode: 3808, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000402, mae: 0.016207, mean_q: 0.002821
 27483/100000: episode: 3809, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000207, mae: 0.012139, mean_q: 0.003431
 27486/100000: episode: 3810, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000198, mae: 0.012877, mean_q: 0.017762
 27488/100000: episode: 3811, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000071, mae: 0.008261, mean_q: 0.000641
 27490/100000: episode: 3812, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000240, mae: 0.012037, mean_q: 0.017780
 27492/100000: episode: 3813, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001186, mae: 0.016478, mean_q: 0.026538
 27494/100000: episode: 3814, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000221, mae: 0.012533, mean_q: 0.002308
 27496/100000: episode: 3815, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000331, mae: 0.011757, mean_q: 0.008791
 27499/100000: episode: 3816, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000106, mae: 0.009543, mean_q: 0.016195
 27506/100000: episode: 3817, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000473, mae: 0.012193, mean_q: 0.006693
 27508/100000: episode: 3818, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000387, mae: 0.018591, mean_q: 0.021334
 27511/100000: episode: 3819, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000456, mae: 0.012063, mean_q: 0.013103
 27513/100000: episode: 3820, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000916, mae: 0.018973, mean_q: 0.011919
 27520/100000: episode: 3821, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000290, mae: 0.013422, mean_q: 0.012150
 27522/100000: episode: 3822, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000379, mae: 0.014976, mean_q: 0.010765
 27524/100000: episode: 3823, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000163, mae: 0.015470, mean_q: 0.021708
 27526/100000: episode: 3824, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000083, mae: 0.008527, mean_q: 0.008064
 27528/100000: episode: 3825, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000312, mae: 0.013531, mean_q: 0.009628
 27530/100000: episode: 3826, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000212, mae: 0.012269, mean_q: 0.020175
[Info] FALSIFICATION!
 27536/100000: episode: 3827, duration: 0.175s, episode steps: 6, steps per second: 34, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000240, mae: 0.011611, mean_q: 0.008448
 27543/100000: episode: 3828, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000610, mae: 0.014212, mean_q: 0.017946
 27550/100000: episode: 3829, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000240, mae: 0.011611, mean_q: 0.009285
 27557/100000: episode: 3830, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000381, mae: 0.009384, mean_q: 0.013927
 27564/100000: episode: 3831, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000283, mae: 0.009858, mean_q: 0.010421
 27571/100000: episode: 3832, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000492, mae: 0.009342, mean_q: 0.011497
 27578/100000: episode: 3833, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000124, mae: 0.009430, mean_q: 0.009288
 27580/100000: episode: 3834, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000118, mae: 0.008968, mean_q: 0.014785
 27582/100000: episode: 3835, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000240, mae: 0.010625, mean_q: 0.013507
[Info] Complete ISplit Iteration
[Info] Levels: [0.020619959, 0.85748315]
[Info] Cond. Prob: [0.14, 0.02]
[Info] Error Prob: 0.0028000000000000004

 27589/100000: episode: 3836, duration: 0.750s, episode steps: 7, steps per second: 9, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000202, mae: 0.008063, mean_q: 0.010244
 27599/100000: episode: 3837, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000162, mae: 0.009080, mean_q: 0.009341
 27609/100000: episode: 3838, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000568, mae: 0.017471, mean_q: 0.012845
 27619/100000: episode: 3839, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000711, mae: 0.019833, mean_q: 0.017459
 27629/100000: episode: 3840, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000333, mae: 0.014234, mean_q: 0.008729
 27639/100000: episode: 3841, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000634, mae: 0.014665, mean_q: 0.019364
 27649/100000: episode: 3842, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000196, mae: 0.013060, mean_q: 0.012061
 27659/100000: episode: 3843, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000220, mae: 0.011653, mean_q: 0.011364
 27669/100000: episode: 3844, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000313, mae: 0.010348, mean_q: 0.012035
 27679/100000: episode: 3845, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000150, mae: 0.008758, mean_q: 0.009031
 27689/100000: episode: 3846, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000185, mae: 0.009851, mean_q: 0.009173
 27699/100000: episode: 3847, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000473, mae: 0.013239, mean_q: 0.014024
 27709/100000: episode: 3848, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000243, mae: 0.013130, mean_q: 0.010218
 27719/100000: episode: 3849, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000249, mae: 0.013969, mean_q: 0.012563
 27729/100000: episode: 3850, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000321, mae: 0.016345, mean_q: 0.011523
 27739/100000: episode: 3851, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000333, mae: 0.012825, mean_q: 0.009119
 27749/100000: episode: 3852, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000362, mae: 0.014210, mean_q: 0.011746
 27759/100000: episode: 3853, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000344, mae: 0.013139, mean_q: 0.013277
 27769/100000: episode: 3854, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000460, mae: 0.012220, mean_q: 0.010758
 27779/100000: episode: 3855, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000412, mae: 0.013681, mean_q: 0.012259
 27789/100000: episode: 3856, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000350, mae: 0.011359, mean_q: 0.014838
 27799/100000: episode: 3857, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000159, mae: 0.009062, mean_q: 0.009199
 27809/100000: episode: 3858, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000225, mae: 0.011121, mean_q: 0.011599
 27819/100000: episode: 3859, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000266, mae: 0.010982, mean_q: 0.013141
 27829/100000: episode: 3860, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000203, mae: 0.010003, mean_q: 0.010831
 27839/100000: episode: 3861, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000358, mae: 0.012975, mean_q: 0.012787
 27849/100000: episode: 3862, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000394, mae: 0.012629, mean_q: 0.012444
 27859/100000: episode: 3863, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000642, mae: 0.014094, mean_q: 0.017664
 27869/100000: episode: 3864, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000579, mae: 0.019968, mean_q: 0.016028
 27879/100000: episode: 3865, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000237, mae: 0.013522, mean_q: 0.009436
 27889/100000: episode: 3866, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000211, mae: 0.010955, mean_q: 0.012250
 27899/100000: episode: 3867, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000676, mae: 0.011526, mean_q: 0.017157
 27909/100000: episode: 3868, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000288, mae: 0.011831, mean_q: 0.012869
 27919/100000: episode: 3869, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000273, mae: 0.009926, mean_q: 0.012961
 27929/100000: episode: 3870, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000517, mae: 0.011457, mean_q: 0.016445
 27939/100000: episode: 3871, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000224, mae: 0.008734, mean_q: 0.011723
 27949/100000: episode: 3872, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000193, mae: 0.010363, mean_q: 0.010237
 27959/100000: episode: 3873, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000552, mae: 0.011796, mean_q: 0.017980
 27969/100000: episode: 3874, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000427, mae: 0.014207, mean_q: 0.012115
 27979/100000: episode: 3875, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000457, mae: 0.012924, mean_q: 0.015121
 27989/100000: episode: 3876, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000409, mae: 0.012346, mean_q: 0.010922
 27999/100000: episode: 3877, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000263, mae: 0.009758, mean_q: 0.013574
 28009/100000: episode: 3878, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000273, mae: 0.012852, mean_q: 0.011990
 28019/100000: episode: 3879, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000394, mae: 0.009406, mean_q: 0.013062
 28029/100000: episode: 3880, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000481, mae: 0.012621, mean_q: 0.017653
 28039/100000: episode: 3881, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000211, mae: 0.009666, mean_q: 0.011514
 28049/100000: episode: 3882, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000408, mae: 0.012615, mean_q: 0.014325
 28059/100000: episode: 3883, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000176, mae: 0.007573, mean_q: 0.010399
 28069/100000: episode: 3884, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000455, mae: 0.013616, mean_q: 0.015178
 28079/100000: episode: 3885, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000303, mae: 0.012172, mean_q: 0.013299
 28089/100000: episode: 3886, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000109, mae: 0.008991, mean_q: 0.010312
 28099/100000: episode: 3887, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000445, mae: 0.013257, mean_q: 0.014064
 28109/100000: episode: 3888, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000273, mae: 0.013894, mean_q: 0.007681
 28119/100000: episode: 3889, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000258, mae: 0.012476, mean_q: 0.011149
 28129/100000: episode: 3890, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000311, mae: 0.014753, mean_q: 0.009696
 28139/100000: episode: 3891, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000267, mae: 0.010403, mean_q: 0.008583
 28149/100000: episode: 3892, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000290, mae: 0.011736, mean_q: 0.013831
 28159/100000: episode: 3893, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000632, mae: 0.013108, mean_q: 0.017548
 28169/100000: episode: 3894, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000422, mae: 0.013456, mean_q: 0.010431
 28179/100000: episode: 3895, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000201, mae: 0.011619, mean_q: 0.009359
 28189/100000: episode: 3896, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000287, mae: 0.011468, mean_q: 0.011640
 28199/100000: episode: 3897, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000284, mae: 0.010320, mean_q: 0.012625
 28209/100000: episode: 3898, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000795, mae: 0.018249, mean_q: 0.017714
 28219/100000: episode: 3899, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000132, mae: 0.009745, mean_q: 0.010585
 28229/100000: episode: 3900, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000286, mae: 0.012367, mean_q: 0.016456
 28239/100000: episode: 3901, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000346, mae: 0.009348, mean_q: 0.009528
 28249/100000: episode: 3902, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000309, mae: 0.011753, mean_q: 0.011061
 28259/100000: episode: 3903, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000512, mae: 0.014766, mean_q: 0.012150
 28269/100000: episode: 3904, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000271, mae: 0.014521, mean_q: 0.011694
 28279/100000: episode: 3905, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000212, mae: 0.012379, mean_q: 0.009300
 28289/100000: episode: 3906, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000512, mae: 0.014163, mean_q: 0.018835
 28299/100000: episode: 3907, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000280, mae: 0.014944, mean_q: 0.009543
 28309/100000: episode: 3908, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000300, mae: 0.010955, mean_q: 0.011341
 28319/100000: episode: 3909, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000171, mae: 0.009326, mean_q: 0.012513
 28329/100000: episode: 3910, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000279, mae: 0.010711, mean_q: 0.014958
 28339/100000: episode: 3911, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000736, mae: 0.013304, mean_q: 0.019534
 28349/100000: episode: 3912, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000584, mae: 0.016838, mean_q: 0.016673
 28359/100000: episode: 3913, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000263, mae: 0.013665, mean_q: 0.011546
 28369/100000: episode: 3914, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000570, mae: 0.013306, mean_q: 0.012222
 28379/100000: episode: 3915, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000216, mae: 0.012382, mean_q: 0.012906
 28389/100000: episode: 3916, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000572, mae: 0.011924, mean_q: 0.010053
 28399/100000: episode: 3917, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000590, mae: 0.016129, mean_q: 0.013636
 28409/100000: episode: 3918, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000434, mae: 0.014132, mean_q: 0.019048
 28419/100000: episode: 3919, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000470, mae: 0.015050, mean_q: 0.014106
 28429/100000: episode: 3920, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000459, mae: 0.014824, mean_q: 0.012655
 28439/100000: episode: 3921, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000210, mae: 0.011877, mean_q: 0.013140
 28449/100000: episode: 3922, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000168, mae: 0.010650, mean_q: 0.009969
 28459/100000: episode: 3923, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000317, mae: 0.013934, mean_q: 0.011287
 28469/100000: episode: 3924, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000499, mae: 0.012912, mean_q: 0.011489
 28479/100000: episode: 3925, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000267, mae: 0.010719, mean_q: 0.012165
 28489/100000: episode: 3926, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000410, mae: 0.012366, mean_q: 0.012034
 28499/100000: episode: 3927, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000184, mae: 0.010632, mean_q: 0.009894
 28509/100000: episode: 3928, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000392, mae: 0.011688, mean_q: 0.010377
 28519/100000: episode: 3929, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000094, mae: 0.007001, mean_q: 0.007397
 28529/100000: episode: 3930, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000333, mae: 0.011525, mean_q: 0.012491
 28539/100000: episode: 3931, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000952, mae: 0.024469, mean_q: 0.012453
 28549/100000: episode: 3932, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000330, mae: 0.016827, mean_q: 0.011805
 28559/100000: episode: 3933, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000359, mae: 0.016001, mean_q: 0.013823
 28569/100000: episode: 3934, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000695, mae: 0.015562, mean_q: 0.015237
 28579/100000: episode: 3935, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000501, mae: 0.015484, mean_q: 0.010481
[Info] 1-TH LEVEL FOUND: 0.022575199604034424, Considering 12/100 traces
 28589/100000: episode: 3936, duration: 0.824s, episode steps: 10, steps per second: 12, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000365, mae: 0.012175, mean_q: 0.014934
 28593/100000: episode: 3937, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000516, mae: 0.012190, mean_q: 0.010465
 28597/100000: episode: 3938, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000312, mae: 0.012534, mean_q: 0.012004
 28601/100000: episode: 3939, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000265, mae: 0.010243, mean_q: 0.005341
 28608/100000: episode: 3940, duration: 0.032s, episode steps: 7, steps per second: 216, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000091, mae: 0.008324, mean_q: 0.007887
 28615/100000: episode: 3941, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000338, mae: 0.011973, mean_q: 0.011817
 28619/100000: episode: 3942, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000338, mae: 0.012861, mean_q: 0.009448
 28626/100000: episode: 3943, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000288, mae: 0.010846, mean_q: 0.009385
 28633/100000: episode: 3944, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000335, mae: 0.012337, mean_q: 0.011076
 28637/100000: episode: 3945, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000340, mae: 0.013217, mean_q: 0.015427
 28641/100000: episode: 3946, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000263, mae: 0.014303, mean_q: 0.016775
 28645/100000: episode: 3947, duration: 0.020s, episode steps: 4, steps per second: 200, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000266, mae: 0.014739, mean_q: 0.002638
 28652/100000: episode: 3948, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000286, mae: 0.016347, mean_q: 0.009755
 28656/100000: episode: 3949, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000243, mae: 0.012625, mean_q: 0.014637
 28660/100000: episode: 3950, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000263, mae: 0.009332, mean_q: 0.003871
 28664/100000: episode: 3951, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000198, mae: 0.009285, mean_q: 0.011365
 28668/100000: episode: 3952, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000488, mae: 0.012546, mean_q: 0.017568
 28675/100000: episode: 3953, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000258, mae: 0.013352, mean_q: 0.010636
 28679/100000: episode: 3954, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000195, mae: 0.009489, mean_q: 0.006451
 28686/100000: episode: 3955, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000212, mae: 0.009259, mean_q: 0.007468
 28693/100000: episode: 3956, duration: 0.032s, episode steps: 7, steps per second: 216, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000310, mae: 0.010914, mean_q: 0.010535
 28700/100000: episode: 3957, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000225, mae: 0.009572, mean_q: 0.009636
 28707/100000: episode: 3958, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000117, mae: 0.007112, mean_q: 0.009653
 28714/100000: episode: 3959, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000603, mae: 0.013732, mean_q: 0.017286
 28718/100000: episode: 3960, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000215, mae: 0.013429, mean_q: 0.008488
 28722/100000: episode: 3961, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000191, mae: 0.008038, mean_q: 0.006992
 28729/100000: episode: 3962, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000149, mae: 0.010164, mean_q: 0.009269
 28733/100000: episode: 3963, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000171, mae: 0.012144, mean_q: 0.018722
 28740/100000: episode: 3964, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000254, mae: 0.011423, mean_q: 0.011110
 28744/100000: episode: 3965, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000117, mae: 0.006941, mean_q: 0.011285
 28748/100000: episode: 3966, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000774, mae: 0.012217, mean_q: 0.020115
 28752/100000: episode: 3967, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000722, mae: 0.013212, mean_q: 0.012830
 28756/100000: episode: 3968, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000530, mae: 0.013596, mean_q: 0.020526
 28763/100000: episode: 3969, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000494, mae: 0.012135, mean_q: 0.008196
 28770/100000: episode: 3970, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000178, mae: 0.011342, mean_q: 0.008322
 28774/100000: episode: 3971, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000437, mae: 0.013148, mean_q: 0.022935
 28778/100000: episode: 3972, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000714, mae: 0.015848, mean_q: 0.007315
[Info] FALSIFICATION!
 28784/100000: episode: 3973, duration: 0.264s, episode steps: 6, steps per second: 23, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000561, mae: 0.017964, mean_q: 0.017829
 28788/100000: episode: 3974, duration: 0.024s, episode steps: 4, steps per second: 167, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000190, mae: 0.009461, mean_q: 0.004546
 28792/100000: episode: 3975, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000131, mae: 0.008886, mean_q: 0.016141
 28799/100000: episode: 3976, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000139, mae: 0.009450, mean_q: 0.008643
 28803/100000: episode: 3977, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000573, mae: 0.013164, mean_q: 0.008185
 28807/100000: episode: 3978, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000234, mae: 0.011062, mean_q: 0.015403
 28814/100000: episode: 3979, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000227, mae: 0.009990, mean_q: 0.012012
 28821/100000: episode: 3980, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000289, mae: 0.013692, mean_q: 0.015110
 28828/100000: episode: 3981, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000300, mae: 0.011077, mean_q: 0.011971
 28835/100000: episode: 3982, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000499, mae: 0.015527, mean_q: 0.013828
 28839/100000: episode: 3983, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000154, mae: 0.010740, mean_q: 0.000346
 28846/100000: episode: 3984, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000236, mae: 0.011266, mean_q: 0.012644
 28853/100000: episode: 3985, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000304, mae: 0.015167, mean_q: 0.014875
 28860/100000: episode: 3986, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000189, mae: 0.011534, mean_q: 0.008626
 28864/100000: episode: 3987, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000117, mae: 0.010922, mean_q: 0.003293
 28871/100000: episode: 3988, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000540, mae: 0.019724, mean_q: 0.024236
 28875/100000: episode: 3989, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000781, mae: 0.021554, mean_q: 0.018658
 28879/100000: episode: 3990, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000509, mae: 0.017867, mean_q: 0.002005
 28883/100000: episode: 3991, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000598, mae: 0.014106, mean_q: 0.017506
 28887/100000: episode: 3992, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000545, mae: 0.011760, mean_q: 0.007223
 28894/100000: episode: 3993, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000290, mae: 0.014425, mean_q: 0.013771
 28901/100000: episode: 3994, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000318, mae: 0.011951, mean_q: 0.012037
 28905/100000: episode: 3995, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000135, mae: 0.010568, mean_q: 0.011548
 28909/100000: episode: 3996, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000113, mae: 0.009795, mean_q: 0.001586
 28913/100000: episode: 3997, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000181, mae: 0.011054, mean_q: 0.016759
 28920/100000: episode: 3998, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000195, mae: 0.010528, mean_q: 0.008449
 28927/100000: episode: 3999, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000235, mae: 0.009967, mean_q: 0.011473
 28934/100000: episode: 4000, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000580, mae: 0.009789, mean_q: 0.013247
 28938/100000: episode: 4001, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000251, mae: 0.011986, mean_q: 0.017764
 28945/100000: episode: 4002, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000494, mae: 0.015574, mean_q: 0.018852
 28949/100000: episode: 4003, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000204, mae: 0.008906, mean_q: 0.011007
 28953/100000: episode: 4004, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000248, mae: 0.012980, mean_q: 0.009829
 28957/100000: episode: 4005, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000107, mae: 0.008054, mean_q: 0.010195
 28964/100000: episode: 4006, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000672, mae: 0.016332, mean_q: 0.021485
 28968/100000: episode: 4007, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000590, mae: 0.023109, mean_q: 0.000819
 28975/100000: episode: 4008, duration: 0.037s, episode steps: 7, steps per second: 192, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000241, mae: 0.013683, mean_q: 0.011399
 28979/100000: episode: 4009, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000480, mae: 0.014210, mean_q: 0.021183
 28986/100000: episode: 4010, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000521, mae: 0.012871, mean_q: 0.013611
 28990/100000: episode: 4011, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000137, mae: 0.007701, mean_q: 0.009255
 28994/100000: episode: 4012, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000356, mae: 0.010232, mean_q: 0.006441
 29001/100000: episode: 4013, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000521, mae: 0.015486, mean_q: 0.017393
 29005/100000: episode: 4014, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000856, mae: 0.017474, mean_q: 0.009707
 29012/100000: episode: 4015, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000334, mae: 0.015674, mean_q: 0.012798
 29019/100000: episode: 4016, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000352, mae: 0.014490, mean_q: 0.014391
 29026/100000: episode: 4017, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000162, mae: 0.010975, mean_q: 0.008905
 29033/100000: episode: 4018, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000264, mae: 0.009909, mean_q: 0.009104
 29037/100000: episode: 4019, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000475, mae: 0.015934, mean_q: 0.020394
 29044/100000: episode: 4020, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000299, mae: 0.016887, mean_q: 0.011086
 29051/100000: episode: 4021, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000492, mae: 0.012709, mean_q: 0.008023
 29058/100000: episode: 4022, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000183, mae: 0.008649, mean_q: 0.010270
 29062/100000: episode: 4023, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000170, mae: 0.010277, mean_q: 0.015665
[Info] Complete ISplit Iteration
[Info] Levels: [0.0225752, 0.95772886]
[Info] Cond. Prob: [0.12, 0.01]
[Info] Error Prob: 0.0012

 29069/100000: episode: 4024, duration: 1.179s, episode steps: 7, steps per second: 6, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000462, mae: 0.015329, mean_q: 0.021654
 29079/100000: episode: 4025, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000395, mae: 0.013788, mean_q: 0.008479
 29089/100000: episode: 4026, duration: 0.109s, episode steps: 10, steps per second: 92, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000609, mae: 0.016672, mean_q: 0.022644
 29099/100000: episode: 4027, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000583, mae: 0.018987, mean_q: 0.013784
 29109/100000: episode: 4028, duration: 0.101s, episode steps: 10, steps per second: 99, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000233, mae: 0.011949, mean_q: 0.008336
 29119/100000: episode: 4029, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000302, mae: 0.010908, mean_q: 0.012813
 29129/100000: episode: 4030, duration: 0.077s, episode steps: 10, steps per second: 129, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000311, mae: 0.012453, mean_q: 0.013173
 29139/100000: episode: 4031, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000280, mae: 0.009312, mean_q: 0.012252
 29149/100000: episode: 4032, duration: 0.110s, episode steps: 10, steps per second: 91, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000789, mae: 0.016330, mean_q: 0.013836
 29159/100000: episode: 4033, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000548, mae: 0.015386, mean_q: 0.019424
 29169/100000: episode: 4034, duration: 0.074s, episode steps: 10, steps per second: 134, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000232, mae: 0.010225, mean_q: 0.013198
 29179/100000: episode: 4035, duration: 0.084s, episode steps: 10, steps per second: 120, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000374, mae: 0.012477, mean_q: 0.012279
 29189/100000: episode: 4036, duration: 0.144s, episode steps: 10, steps per second: 69, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000410, mae: 0.012457, mean_q: 0.008148
 29199/100000: episode: 4037, duration: 0.104s, episode steps: 10, steps per second: 96, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000766, mae: 0.017246, mean_q: 0.017223
 29209/100000: episode: 4038, duration: 0.104s, episode steps: 10, steps per second: 96, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000468, mae: 0.013747, mean_q: 0.011414
 29219/100000: episode: 4039, duration: 0.108s, episode steps: 10, steps per second: 93, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000289, mae: 0.013662, mean_q: 0.013933
 29229/100000: episode: 4040, duration: 0.117s, episode steps: 10, steps per second: 86, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000305, mae: 0.014656, mean_q: 0.007550
 29239/100000: episode: 4041, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000471, mae: 0.017054, mean_q: 0.010509
 29249/100000: episode: 4042, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000274, mae: 0.012158, mean_q: 0.012856
 29259/100000: episode: 4043, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000255, mae: 0.012828, mean_q: 0.011613
 29269/100000: episode: 4044, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000590, mae: 0.016326, mean_q: 0.011089
 29279/100000: episode: 4045, duration: 0.086s, episode steps: 10, steps per second: 117, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000185, mae: 0.011240, mean_q: 0.010189
 29289/100000: episode: 4046, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000339, mae: 0.010645, mean_q: 0.008158
 29299/100000: episode: 4047, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000251, mae: 0.010166, mean_q: 0.009732
 29309/100000: episode: 4048, duration: 0.095s, episode steps: 10, steps per second: 106, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000557, mae: 0.013874, mean_q: 0.011353
 29319/100000: episode: 4049, duration: 0.086s, episode steps: 10, steps per second: 117, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000696, mae: 0.022991, mean_q: 0.016010
 29329/100000: episode: 4050, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000370, mae: 0.018341, mean_q: 0.010074
 29339/100000: episode: 4051, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000307, mae: 0.016371, mean_q: 0.007064
 29349/100000: episode: 4052, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000357, mae: 0.013883, mean_q: 0.012505
 29359/100000: episode: 4053, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000249, mae: 0.009622, mean_q: 0.011553
 29369/100000: episode: 4054, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000584, mae: 0.013879, mean_q: 0.015187
 29379/100000: episode: 4055, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000286, mae: 0.013851, mean_q: 0.010368
 29389/100000: episode: 4056, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000357, mae: 0.014202, mean_q: 0.011152
 29399/100000: episode: 4057, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000442, mae: 0.012422, mean_q: 0.016984
 29409/100000: episode: 4058, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000361, mae: 0.012003, mean_q: 0.006778
 29419/100000: episode: 4059, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000186, mae: 0.009220, mean_q: 0.010281
 29429/100000: episode: 4060, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000275, mae: 0.011732, mean_q: 0.012010
 29439/100000: episode: 4061, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000197, mae: 0.009448, mean_q: 0.008171
 29449/100000: episode: 4062, duration: 0.077s, episode steps: 10, steps per second: 131, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001016, mae: 0.020184, mean_q: 0.014688
 29459/100000: episode: 4063, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000678, mae: 0.017113, mean_q: 0.016816
 29469/100000: episode: 4064, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000514, mae: 0.012728, mean_q: 0.010565
 29479/100000: episode: 4065, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000277, mae: 0.009021, mean_q: 0.014783
 29489/100000: episode: 4066, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000511, mae: 0.011695, mean_q: 0.011640
 29499/100000: episode: 4067, duration: 0.064s, episode steps: 10, steps per second: 155, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000422, mae: 0.014057, mean_q: 0.012405
 29509/100000: episode: 4068, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000377, mae: 0.012794, mean_q: 0.011744
 29519/100000: episode: 4069, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000238, mae: 0.010025, mean_q: 0.009837
 29529/100000: episode: 4070, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000372, mae: 0.014478, mean_q: 0.013011
 29539/100000: episode: 4071, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000595, mae: 0.012961, mean_q: 0.015034
 29549/100000: episode: 4072, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000308, mae: 0.010406, mean_q: 0.013928
 29559/100000: episode: 4073, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000184, mae: 0.008309, mean_q: 0.012366
 29569/100000: episode: 4074, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000269, mae: 0.015778, mean_q: 0.005647
 29579/100000: episode: 4075, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000894, mae: 0.018451, mean_q: 0.012989
 29589/100000: episode: 4076, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000314, mae: 0.014264, mean_q: 0.011740
 29599/100000: episode: 4077, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000606, mae: 0.014850, mean_q: 0.015052
 29609/100000: episode: 4078, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000843, mae: 0.017938, mean_q: 0.013400
 29619/100000: episode: 4079, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000264, mae: 0.014300, mean_q: 0.009860
 29629/100000: episode: 4080, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001054, mae: 0.020049, mean_q: 0.022066
 29639/100000: episode: 4081, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000309, mae: 0.012783, mean_q: 0.010440
 29649/100000: episode: 4082, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000297, mae: 0.013188, mean_q: 0.006110
 29659/100000: episode: 4083, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000316, mae: 0.011704, mean_q: 0.011927
 29669/100000: episode: 4084, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000330, mae: 0.011735, mean_q: 0.010642
 29679/100000: episode: 4085, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000293, mae: 0.009986, mean_q: 0.011443
 29689/100000: episode: 4086, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000198, mae: 0.011599, mean_q: 0.009751
 29699/100000: episode: 4087, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000154, mae: 0.010675, mean_q: 0.008220
 29709/100000: episode: 4088, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000586, mae: 0.013565, mean_q: 0.018800
 29719/100000: episode: 4089, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000375, mae: 0.015654, mean_q: 0.010127
 29729/100000: episode: 4090, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000435, mae: 0.011693, mean_q: 0.012053
 29739/100000: episode: 4091, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000478, mae: 0.016696, mean_q: 0.020301
 29749/100000: episode: 4092, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000354, mae: 0.012010, mean_q: 0.018933
 29759/100000: episode: 4093, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000479, mae: 0.012118, mean_q: 0.010738
 29769/100000: episode: 4094, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000389, mae: 0.010280, mean_q: 0.014004
 29779/100000: episode: 4095, duration: 0.089s, episode steps: 10, steps per second: 113, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000557, mae: 0.017379, mean_q: 0.011746
 29789/100000: episode: 4096, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000414, mae: 0.011906, mean_q: 0.010411
 29799/100000: episode: 4097, duration: 0.064s, episode steps: 10, steps per second: 155, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000393, mae: 0.011923, mean_q: 0.012667
 29809/100000: episode: 4098, duration: 0.088s, episode steps: 10, steps per second: 113, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000234, mae: 0.009314, mean_q: 0.010535
 29819/100000: episode: 4099, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000602, mae: 0.013657, mean_q: 0.015802
 29829/100000: episode: 4100, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000255, mae: 0.015862, mean_q: 0.011107
 29839/100000: episode: 4101, duration: 0.101s, episode steps: 10, steps per second: 99, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000265, mae: 0.011869, mean_q: 0.009376
 29849/100000: episode: 4102, duration: 0.087s, episode steps: 10, steps per second: 114, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000285, mae: 0.012116, mean_q: 0.011819
 29859/100000: episode: 4103, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000376, mae: 0.011240, mean_q: 0.012516
 29869/100000: episode: 4104, duration: 0.083s, episode steps: 10, steps per second: 121, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000503, mae: 0.016315, mean_q: 0.012535
 29879/100000: episode: 4105, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000433, mae: 0.015173, mean_q: 0.015317
 29889/100000: episode: 4106, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000269, mae: 0.014966, mean_q: 0.009899
 29899/100000: episode: 4107, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000385, mae: 0.013135, mean_q: 0.012049
 29909/100000: episode: 4108, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000260, mae: 0.012296, mean_q: 0.010738
 29919/100000: episode: 4109, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000544, mae: 0.013025, mean_q: 0.017977
 29929/100000: episode: 4110, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000233, mae: 0.011878, mean_q: 0.010541
 29939/100000: episode: 4111, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000395, mae: 0.011003, mean_q: 0.014337
 29949/100000: episode: 4112, duration: 0.084s, episode steps: 10, steps per second: 120, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000192, mae: 0.011383, mean_q: 0.009639
 29959/100000: episode: 4113, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000527, mae: 0.015355, mean_q: 0.012440
 29969/100000: episode: 4114, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000304, mae: 0.014146, mean_q: 0.009053
 29979/100000: episode: 4115, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000160, mae: 0.010045, mean_q: 0.009674
 29989/100000: episode: 4116, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000551, mae: 0.019375, mean_q: 0.013141
 29999/100000: episode: 4117, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000441, mae: 0.015123, mean_q: 0.016397
 30009/100000: episode: 4118, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000401, mae: 0.010925, mean_q: 0.014355
 30019/100000: episode: 4119, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000276, mae: 0.009433, mean_q: 0.008069
 30029/100000: episode: 4120, duration: 0.068s, episode steps: 10, steps per second: 146, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000262, mae: 0.010682, mean_q: 0.011140
 30039/100000: episode: 4121, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000445, mae: 0.013559, mean_q: 0.020404
 30049/100000: episode: 4122, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000238, mae: 0.009940, mean_q: 0.010188
 30059/100000: episode: 4123, duration: 0.069s, episode steps: 10, steps per second: 146, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000276, mae: 0.009745, mean_q: 0.008448
[Info] 1-TH LEVEL FOUND: 0.006755858659744263, Considering 13/100 traces
 30069/100000: episode: 4124, duration: 0.745s, episode steps: 10, steps per second: 13, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000441, mae: 0.011630, mean_q: 0.010929
 30075/100000: episode: 4125, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000216, mae: 0.010975, mean_q: 0.010988
 30078/100000: episode: 4126, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000490, mae: 0.010514, mean_q: 0.012802
 30081/100000: episode: 4127, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000303, mae: 0.015381, mean_q: 0.019145
 30087/100000: episode: 4128, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000507, mae: 0.013983, mean_q: 0.010744
 30090/100000: episode: 4129, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000373, mae: 0.010923, mean_q: 0.010368
 30096/100000: episode: 4130, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000163, mae: 0.008614, mean_q: 0.006474
 30102/100000: episode: 4131, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000326, mae: 0.013036, mean_q: 0.017603
 30108/100000: episode: 4132, duration: 0.031s, episode steps: 6, steps per second: 192, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000556, mae: 0.012907, mean_q: 0.009117
 30114/100000: episode: 4133, duration: 0.032s, episode steps: 6, steps per second: 187, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000467, mae: 0.013184, mean_q: 0.013202
 30120/100000: episode: 4134, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000505, mae: 0.009753, mean_q: 0.011991
 30123/100000: episode: 4135, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000133, mae: 0.007155, mean_q: 0.008817
 30126/100000: episode: 4136, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000267, mae: 0.012718, mean_q: -0.000967
 30130/100000: episode: 4137, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000617, mae: 0.018434, mean_q: 0.014997
 30134/100000: episode: 4138, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000512, mae: 0.010981, mean_q: 0.014348
 30140/100000: episode: 4139, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000314, mae: 0.012417, mean_q: 0.013033
 30146/100000: episode: 4140, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000457, mae: 0.016881, mean_q: 0.010896
 30149/100000: episode: 4141, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000212, mae: 0.012566, mean_q: 0.007823
 30152/100000: episode: 4142, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001250, mae: 0.020082, mean_q: 0.018129
 30158/100000: episode: 4143, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000640, mae: 0.010950, mean_q: 0.010031
 30161/100000: episode: 4144, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000240, mae: 0.017690, mean_q: 0.024596
 30164/100000: episode: 4145, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000530, mae: 0.024170, mean_q: -0.009595
 30167/100000: episode: 4146, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000946, mae: 0.024864, mean_q: 0.035012
 30173/100000: episode: 4147, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000325, mae: 0.015832, mean_q: 0.003683
 30179/100000: episode: 4148, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000487, mae: 0.014895, mean_q: 0.010287
 30183/100000: episode: 4149, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000187, mae: 0.010785, mean_q: 0.012128
 30186/100000: episode: 4150, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000596, mae: 0.013103, mean_q: 0.009289
 30190/100000: episode: 4151, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001144, mae: 0.015218, mean_q: 0.017985
 30193/100000: episode: 4152, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000084, mae: 0.009956, mean_q: 0.014488
 30196/100000: episode: 4153, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000088, mae: 0.008696, mean_q: 0.001914
 30202/100000: episode: 4154, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000326, mae: 0.012954, mean_q: 0.012662
 30205/100000: episode: 4155, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001084, mae: 0.016659, mean_q: 0.018232
 30208/100000: episode: 4156, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000200, mae: 0.014054, mean_q: 0.019572
 30211/100000: episode: 4157, duration: 0.033s, episode steps: 3, steps per second: 90, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000172, mae: 0.012002, mean_q: 0.000747
 30215/100000: episode: 4158, duration: 0.026s, episode steps: 4, steps per second: 155, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000455, mae: 0.016908, mean_q: 0.018105
 30218/100000: episode: 4159, duration: 0.023s, episode steps: 3, steps per second: 131, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000737, mae: 0.016723, mean_q: 0.008416
 30224/100000: episode: 4160, duration: 0.038s, episode steps: 6, steps per second: 159, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000185, mae: 0.011207, mean_q: 0.008159
 30227/100000: episode: 4161, duration: 0.024s, episode steps: 3, steps per second: 124, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000347, mae: 0.010304, mean_q: 0.014644
 30230/100000: episode: 4162, duration: 0.022s, episode steps: 3, steps per second: 135, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000075, mae: 0.008893, mean_q: 0.002257
 30233/100000: episode: 4163, duration: 0.019s, episode steps: 3, steps per second: 157, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000162, mae: 0.008572, mean_q: 0.011709
 30239/100000: episode: 4164, duration: 0.036s, episode steps: 6, steps per second: 166, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000332, mae: 0.010823, mean_q: 0.011947
 30245/100000: episode: 4165, duration: 0.035s, episode steps: 6, steps per second: 170, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000357, mae: 0.009648, mean_q: 0.010022
 30248/100000: episode: 4166, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000087, mae: 0.006780, mean_q: 0.003872
 30254/100000: episode: 4167, duration: 0.039s, episode steps: 6, steps per second: 155, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000398, mae: 0.012596, mean_q: 0.006516
 30258/100000: episode: 4168, duration: 0.026s, episode steps: 4, steps per second: 152, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000499, mae: 0.013669, mean_q: 0.018084
 30261/100000: episode: 4169, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000442, mae: 0.015092, mean_q: 0.012844
 30267/100000: episode: 4170, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000460, mae: 0.017394, mean_q: 0.007719
 30271/100000: episode: 4171, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.004459, mae: 0.024133, mean_q: 0.014848
 30274/100000: episode: 4172, duration: 0.019s, episode steps: 3, steps per second: 155, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000565, mae: 0.022475, mean_q: 0.029369
 30278/100000: episode: 4173, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000431, mae: 0.022386, mean_q: -0.005118
 30281/100000: episode: 4174, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000287, mae: 0.016873, mean_q: 0.023320
 30284/100000: episode: 4175, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000614, mae: 0.018756, mean_q: 0.003701
 30288/100000: episode: 4176, duration: 0.026s, episode steps: 4, steps per second: 152, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000510, mae: 0.012691, mean_q: 0.017938
 30291/100000: episode: 4177, duration: 0.023s, episode steps: 3, steps per second: 130, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000200, mae: 0.011099, mean_q: 0.000600
 30294/100000: episode: 4178, duration: 0.027s, episode steps: 3, steps per second: 109, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000420, mae: 0.012988, mean_q: 0.016415
 30300/100000: episode: 4179, duration: 0.049s, episode steps: 6, steps per second: 123, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000413, mae: 0.009650, mean_q: 0.008698
 30303/100000: episode: 4180, duration: 0.020s, episode steps: 3, steps per second: 147, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000337, mae: 0.013891, mean_q: 0.019258
 30306/100000: episode: 4181, duration: 0.024s, episode steps: 3, steps per second: 127, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000185, mae: 0.009692, mean_q: 0.005116
 30309/100000: episode: 4182, duration: 0.020s, episode steps: 3, steps per second: 148, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000345, mae: 0.012061, mean_q: 0.015135
 30312/100000: episode: 4183, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001086, mae: 0.016114, mean_q: 0.023261
 30316/100000: episode: 4184, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000180, mae: 0.010939, mean_q: 0.011075
 30322/100000: episode: 4185, duration: 0.040s, episode steps: 6, steps per second: 149, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000793, mae: 0.016841, mean_q: 0.019766
 30328/100000: episode: 4186, duration: 0.034s, episode steps: 6, steps per second: 177, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000125, mae: 0.011923, mean_q: 0.012995
 30332/100000: episode: 4187, duration: 0.026s, episode steps: 4, steps per second: 156, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000339, mae: 0.010186, mean_q: 0.006362
 30335/100000: episode: 4188, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000148, mae: 0.008774, mean_q: 0.009923
 30338/100000: episode: 4189, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000637, mae: 0.013722, mean_q: 0.019062
 30341/100000: episode: 4190, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000212, mae: 0.009729, mean_q: 0.002010
 30344/100000: episode: 4191, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000158, mae: 0.010716, mean_q: 0.012459
 30347/100000: episode: 4192, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000055, mae: 0.006478, mean_q: 0.002908
 30351/100000: episode: 4193, duration: 0.027s, episode steps: 4, steps per second: 147, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000399, mae: 0.014404, mean_q: 0.021489
 30357/100000: episode: 4194, duration: 0.037s, episode steps: 6, steps per second: 162, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000174, mae: 0.009641, mean_q: 0.004548
 30363/100000: episode: 4195, duration: 0.035s, episode steps: 6, steps per second: 173, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000145, mae: 0.009349, mean_q: 0.012094
 30366/100000: episode: 4196, duration: 0.022s, episode steps: 3, steps per second: 135, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000127, mae: 0.007431, mean_q: 0.005984
 30369/100000: episode: 4197, duration: 0.020s, episode steps: 3, steps per second: 150, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000282, mae: 0.008296, mean_q: 0.011475
 30372/100000: episode: 4198, duration: 0.026s, episode steps: 3, steps per second: 116, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000327, mae: 0.011587, mean_q: 0.006745
 30375/100000: episode: 4199, duration: 0.022s, episode steps: 3, steps per second: 139, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000322, mae: 0.015351, mean_q: 0.023636
 30381/100000: episode: 4200, duration: 0.063s, episode steps: 6, steps per second: 95, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000276, mae: 0.013466, mean_q: 0.011815
 30384/100000: episode: 4201, duration: 0.047s, episode steps: 3, steps per second: 63, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000806, mae: 0.014131, mean_q: 0.022584
 30387/100000: episode: 4202, duration: 0.065s, episode steps: 3, steps per second: 46, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000256, mae: 0.011461, mean_q: 0.008890
 30393/100000: episode: 4203, duration: 0.087s, episode steps: 6, steps per second: 69, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000241, mae: 0.008855, mean_q: 0.010321
 30397/100000: episode: 4204, duration: 0.033s, episode steps: 4, steps per second: 119, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000134, mae: 0.006844, mean_q: 0.008272
 30400/100000: episode: 4205, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000620, mae: 0.012314, mean_q: 0.012794
 30406/100000: episode: 4206, duration: 0.032s, episode steps: 6, steps per second: 186, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000489, mae: 0.016339, mean_q: 0.014707
 30410/100000: episode: 4207, duration: 0.043s, episode steps: 4, steps per second: 93, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000143, mae: 0.012137, mean_q: 0.015298
 30414/100000: episode: 4208, duration: 0.049s, episode steps: 4, steps per second: 81, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000190, mae: 0.008488, mean_q: 0.004774
 30420/100000: episode: 4209, duration: 0.066s, episode steps: 6, steps per second: 92, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000404, mae: 0.011351, mean_q: 0.017494
 30424/100000: episode: 4210, duration: 0.030s, episode steps: 4, steps per second: 135, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000283, mae: 0.015618, mean_q: 0.011562
[Info] 2-TH LEVEL FOUND: 0.06848810613155365, Considering 14/100 traces
 30427/100000: episode: 4211, duration: 1.012s, episode steps: 3, steps per second: 3, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000268, mae: 0.011607, mean_q: 0.006818
 30429/100000: episode: 4212, duration: 0.020s, episode steps: 2, steps per second: 99, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000051, mae: 0.006596, mean_q: 0.008879
 30431/100000: episode: 4213, duration: 0.020s, episode steps: 2, steps per second: 101, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000357, mae: 0.014924, mean_q: 0.021610
 30433/100000: episode: 4214, duration: 0.020s, episode steps: 2, steps per second: 100, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000393, mae: 0.016740, mean_q: -0.001588
 30435/100000: episode: 4215, duration: 0.015s, episode steps: 2, steps per second: 131, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000238, mae: 0.013151, mean_q: 0.015459
[Info] FALSIFICATION!
 30438/100000: episode: 4216, duration: 0.267s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000216, mae: 0.009498, mean_q: 0.003721
 30440/100000: episode: 4217, duration: 0.018s, episode steps: 2, steps per second: 110, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000280, mae: 0.011783, mean_q: 0.014096
 30442/100000: episode: 4218, duration: 0.024s, episode steps: 2, steps per second: 82, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000098, mae: 0.010000, mean_q: 0.015287
 30444/100000: episode: 4219, duration: 0.026s, episode steps: 2, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000323, mae: 0.012611, mean_q: 0.004561
 30448/100000: episode: 4220, duration: 0.037s, episode steps: 4, steps per second: 109, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000090, mae: 0.008274, mean_q: 0.011737
 30450/100000: episode: 4221, duration: 0.028s, episode steps: 2, steps per second: 71, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000122, mae: 0.009029, mean_q: 0.004094
 30454/100000: episode: 4222, duration: 0.038s, episode steps: 4, steps per second: 104, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000944, mae: 0.016881, mean_q: 0.018534
 30456/100000: episode: 4223, duration: 0.026s, episode steps: 2, steps per second: 78, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000149, mae: 0.007992, mean_q: 0.012180
 30460/100000: episode: 4224, duration: 0.036s, episode steps: 4, steps per second: 110, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000361, mae: 0.014337, mean_q: 0.010119
 30464/100000: episode: 4225, duration: 0.027s, episode steps: 4, steps per second: 147, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000265, mae: 0.012179, mean_q: 0.008182
[Info] FALSIFICATION!
 30467/100000: episode: 4226, duration: 0.195s, episode steps: 3, steps per second: 15, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000193, mae: 0.008018, mean_q: 0.010400
 30471/100000: episode: 4227, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000208, mae: 0.010153, mean_q: 0.014358
 30473/100000: episode: 4228, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000249, mae: 0.011750, mean_q: 0.012986
 30475/100000: episode: 4229, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000194, mae: 0.010434, mean_q: 0.011753
 30477/100000: episode: 4230, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000256, mae: 0.009487, mean_q: 0.005431
 30481/100000: episode: 4231, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000951, mae: 0.015928, mean_q: 0.017832
 30483/100000: episode: 4232, duration: 0.012s, episode steps: 2, steps per second: 167, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000261, mae: 0.012845, mean_q: 0.015805
 30485/100000: episode: 4233, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000382, mae: 0.012337, mean_q: 0.019842
 30487/100000: episode: 4234, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000184, mae: 0.009833, mean_q: 0.013238
 30491/100000: episode: 4235, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000127, mae: 0.010347, mean_q: 0.008685
 30493/100000: episode: 4236, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001025, mae: 0.013329, mean_q: 0.019955
[Info] FALSIFICATION!
 30496/100000: episode: 4237, duration: 0.259s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001017, mae: 0.020327, mean_q: 0.022316
[Info] FALSIFICATION!
 30499/100000: episode: 4238, duration: 0.271s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000524, mae: 0.016635, mean_q: 0.016278
 30503/100000: episode: 4239, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000471, mae: 0.015731, mean_q: 0.018125
 30505/100000: episode: 4240, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000740, mae: 0.025983, mean_q: 0.003162
 30507/100000: episode: 4241, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000543, mae: 0.027400, mean_q: 0.035508
 30511/100000: episode: 4242, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000456, mae: 0.017135, mean_q: 0.001232
 30513/100000: episode: 4243, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004470, mae: 0.028733, mean_q: 0.030936
 30515/100000: episode: 4244, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000967, mae: 0.020689, mean_q: 0.033809
 30519/100000: episode: 4245, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000372, mae: 0.017617, mean_q: 0.002041
 30521/100000: episode: 4246, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001473, mae: 0.025429, mean_q: 0.037621
[Info] FALSIFICATION!
 30524/100000: episode: 4247, duration: 0.244s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001327, mae: 0.027044, mean_q: 0.010748
 30526/100000: episode: 4248, duration: 0.016s, episode steps: 2, steps per second: 124, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001217, mae: 0.027887, mean_q: 0.046278
 30528/100000: episode: 4249, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000347, mae: 0.016070, mean_q: 0.020767
 30532/100000: episode: 4250, duration: 0.027s, episode steps: 4, steps per second: 150, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000730, mae: 0.024768, mean_q: 0.003360
 30534/100000: episode: 4251, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000206, mae: 0.012725, mean_q: 0.017547
 30538/100000: episode: 4252, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000623, mae: 0.016865, mean_q: 0.001900
 30542/100000: episode: 4253, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001064, mae: 0.027614, mean_q: 0.031701
 30546/100000: episode: 4254, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000467, mae: 0.017741, mean_q: 0.007942
 30548/100000: episode: 4255, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000249, mae: 0.014745, mean_q: 0.021002
 30550/100000: episode: 4256, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001708, mae: 0.020382, mean_q: 0.031533
[Info] FALSIFICATION!
 30553/100000: episode: 4257, duration: 0.268s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000960, mae: 0.016686, mean_q: 0.025977
 30557/100000: episode: 4258, duration: 0.025s, episode steps: 4, steps per second: 163, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000253, mae: 0.015225, mean_q: 0.004058
[Info] FALSIFICATION!
 30560/100000: episode: 4259, duration: 0.263s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001352, mae: 0.021292, mean_q: 0.027339
 30564/100000: episode: 4260, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000322, mae: 0.012970, mean_q: -0.000597
 30568/100000: episode: 4261, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000381, mae: 0.018468, mean_q: 0.023867
 30572/100000: episode: 4262, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000636, mae: 0.016084, mean_q: 0.008678
 30574/100000: episode: 4263, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000120, mae: 0.006905, mean_q: 0.012658
 30578/100000: episode: 4264, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001066, mae: 0.015538, mean_q: 0.015336
 30582/100000: episode: 4265, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000561, mae: 0.016245, mean_q: 0.019931
 30586/100000: episode: 4266, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002827, mae: 0.024270, mean_q: 0.024927
 30588/100000: episode: 4267, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000690, mae: 0.020314, mean_q: 0.006130
 30592/100000: episode: 4268, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000367, mae: 0.016787, mean_q: 0.011366
[Info] FALSIFICATION!
 30595/100000: episode: 4269, duration: 0.225s, episode steps: 3, steps per second: 13, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000885, mae: 0.019291, mean_q: 0.023728
 30597/100000: episode: 4270, duration: 0.015s, episode steps: 2, steps per second: 134, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001847, mae: 0.033039, mean_q: 0.009614
 30601/100000: episode: 4271, duration: 0.024s, episode steps: 4, steps per second: 167, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.001061, mae: 0.023328, mean_q: 0.031362
 30605/100000: episode: 4272, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001063, mae: 0.020622, mean_q: 0.016512
 30609/100000: episode: 4273, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000933, mae: 0.020517, mean_q: 0.012959
[Info] FALSIFICATION!
 30612/100000: episode: 4274, duration: 0.271s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002111, mae: 0.028225, mean_q: 0.038688
 30616/100000: episode: 4275, duration: 0.026s, episode steps: 4, steps per second: 156, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000659, mae: 0.018543, mean_q: 0.014770
 30620/100000: episode: 4276, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000912, mae: 0.023667, mean_q: 0.027732
 30624/100000: episode: 4277, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000421, mae: 0.013561, mean_q: 0.012996
 30626/100000: episode: 4278, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001066, mae: 0.022311, mean_q: 0.015188
 30630/100000: episode: 4279, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000861, mae: 0.017939, mean_q: 0.027456
 30634/100000: episode: 4280, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000466, mae: 0.014676, mean_q: 0.005263
 30638/100000: episode: 4281, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001001, mae: 0.019708, mean_q: 0.027362
 30640/100000: episode: 4282, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002215, mae: 0.033458, mean_q: 0.016890
 30644/100000: episode: 4283, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000828, mae: 0.020899, mean_q: 0.029708
 30648/100000: episode: 4284, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000502, mae: 0.016604, mean_q: 0.002024
 30652/100000: episode: 4285, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001013, mae: 0.017007, mean_q: 0.022734
 30654/100000: episode: 4286, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001038, mae: 0.018385, mean_q: 0.022898
 30656/100000: episode: 4287, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000533, mae: 0.016296, mean_q: 0.020832
 30660/100000: episode: 4288, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001765, mae: 0.021763, mean_q: 0.028177
 30664/100000: episode: 4289, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000242, mae: 0.012930, mean_q: 0.002364
 30668/100000: episode: 4290, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001211, mae: 0.021555, mean_q: 0.031021
 30672/100000: episode: 4291, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000428, mae: 0.012993, mean_q: 0.017173
 30674/100000: episode: 4292, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000109, mae: 0.010994, mean_q: -0.000524
 30678/100000: episode: 4293, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001110, mae: 0.020444, mean_q: 0.027991
 30682/100000: episode: 4294, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001050, mae: 0.023594, mean_q: 0.030408
 30684/100000: episode: 4295, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000641, mae: 0.025663, mean_q: 0.000242
 30686/100000: episode: 4296, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002260, mae: 0.025719, mean_q: 0.047464
[Info] Complete ISplit Iteration
[Info] Levels: [0.0067558587, 0.068488106, 0.8738232]
[Info] Cond. Prob: [0.13, 0.14, 0.09]
[Info] Error Prob: 0.001638

 30690/100000: episode: 4297, duration: 0.930s, episode steps: 4, steps per second: 4, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000874, mae: 0.016764, mean_q: 0.020832
 30700/100000: episode: 4298, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001674, mae: 0.021411, mean_q: 0.030089
 30710/100000: episode: 4299, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001087, mae: 0.022795, mean_q: 0.020004
 30720/100000: episode: 4300, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001905, mae: 0.023974, mean_q: 0.022886
 30730/100000: episode: 4301, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001533, mae: 0.030892, mean_q: 0.025463
 30740/100000: episode: 4302, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001442, mae: 0.029061, mean_q: 0.014285
 30750/100000: episode: 4303, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002597, mae: 0.029623, mean_q: 0.030218
 30760/100000: episode: 4304, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001982, mae: 0.028987, mean_q: 0.029755
 30770/100000: episode: 4305, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001821, mae: 0.021741, mean_q: 0.022496
 30780/100000: episode: 4306, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001745, mae: 0.025397, mean_q: 0.019097
 30790/100000: episode: 4307, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000793, mae: 0.018515, mean_q: 0.022151
 30800/100000: episode: 4308, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000520, mae: 0.016381, mean_q: 0.018669
 30810/100000: episode: 4309, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001303, mae: 0.024158, mean_q: 0.031398
 30820/100000: episode: 4310, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002300, mae: 0.026525, mean_q: 0.029327
 30830/100000: episode: 4311, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001089, mae: 0.021124, mean_q: 0.027166
 30840/100000: episode: 4312, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001796, mae: 0.023627, mean_q: 0.029038
 30850/100000: episode: 4313, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002678, mae: 0.025691, mean_q: 0.033260
 30860/100000: episode: 4314, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000786, mae: 0.024182, mean_q: 0.016992
 30870/100000: episode: 4315, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000734, mae: 0.018992, mean_q: 0.013835
 30880/100000: episode: 4316, duration: 0.079s, episode steps: 10, steps per second: 126, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000848, mae: 0.016198, mean_q: 0.024139
 30890/100000: episode: 4317, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001016, mae: 0.021048, mean_q: 0.026897
 30900/100000: episode: 4318, duration: 0.115s, episode steps: 10, steps per second: 87, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000568, mae: 0.018645, mean_q: 0.016782
 30910/100000: episode: 4319, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001678, mae: 0.029843, mean_q: 0.020582
 30920/100000: episode: 4320, duration: 0.073s, episode steps: 10, steps per second: 136, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001011, mae: 0.021886, mean_q: 0.020251
 30930/100000: episode: 4321, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000883, mae: 0.021432, mean_q: 0.024198
 30940/100000: episode: 4322, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002844, mae: 0.028646, mean_q: 0.035943
 30950/100000: episode: 4323, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001879, mae: 0.026792, mean_q: 0.029080
 30960/100000: episode: 4324, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001462, mae: 0.026549, mean_q: 0.020512
 30970/100000: episode: 4325, duration: 0.076s, episode steps: 10, steps per second: 131, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001218, mae: 0.020539, mean_q: 0.023597
 30980/100000: episode: 4326, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001089, mae: 0.020539, mean_q: 0.019076
 30990/100000: episode: 4327, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001097, mae: 0.026336, mean_q: 0.022230
 31000/100000: episode: 4328, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.002238, mae: 0.026133, mean_q: 0.031813
 31010/100000: episode: 4329, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000920, mae: 0.021146, mean_q: 0.017351
 31020/100000: episode: 4330, duration: 0.071s, episode steps: 10, steps per second: 140, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001864, mae: 0.020110, mean_q: 0.018309
 31030/100000: episode: 4331, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001021, mae: 0.021493, mean_q: 0.028667
 31040/100000: episode: 4332, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002122, mae: 0.027054, mean_q: 0.019159
 31050/100000: episode: 4333, duration: 0.079s, episode steps: 10, steps per second: 126, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001114, mae: 0.024143, mean_q: 0.020665
 31060/100000: episode: 4334, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000846, mae: 0.019190, mean_q: 0.018115
 31070/100000: episode: 4335, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.003698, mae: 0.032848, mean_q: 0.037214
 31080/100000: episode: 4336, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002110, mae: 0.030360, mean_q: 0.024165
 31090/100000: episode: 4337, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001492, mae: 0.023156, mean_q: 0.022771
 31100/100000: episode: 4338, duration: 0.076s, episode steps: 10, steps per second: 131, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.002069, mae: 0.023588, mean_q: 0.035064
 31110/100000: episode: 4339, duration: 0.086s, episode steps: 10, steps per second: 117, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000963, mae: 0.019714, mean_q: 0.023463
 31120/100000: episode: 4340, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000847, mae: 0.018150, mean_q: 0.014342
 31130/100000: episode: 4341, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001237, mae: 0.022021, mean_q: 0.035448
 31140/100000: episode: 4342, duration: 0.072s, episode steps: 10, steps per second: 138, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001072, mae: 0.025644, mean_q: 0.018956
 31150/100000: episode: 4343, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000811, mae: 0.019157, mean_q: 0.019369
 31160/100000: episode: 4344, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000731, mae: 0.016504, mean_q: 0.019862
 31170/100000: episode: 4345, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001901, mae: 0.029234, mean_q: 0.032212
 31180/100000: episode: 4346, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000960, mae: 0.017936, mean_q: 0.023223
 31190/100000: episode: 4347, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000758, mae: 0.015385, mean_q: 0.015440
 31200/100000: episode: 4348, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000989, mae: 0.017616, mean_q: 0.023675
 31210/100000: episode: 4349, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001214, mae: 0.019713, mean_q: 0.029969
 31220/100000: episode: 4350, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001198, mae: 0.023339, mean_q: 0.023610
 31230/100000: episode: 4351, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002035, mae: 0.023067, mean_q: 0.023990
 31240/100000: episode: 4352, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001692, mae: 0.031227, mean_q: 0.029626
 31250/100000: episode: 4353, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001114, mae: 0.023767, mean_q: 0.025680
 31260/100000: episode: 4354, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001013, mae: 0.017817, mean_q: 0.025150
 31270/100000: episode: 4355, duration: 0.083s, episode steps: 10, steps per second: 121, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001872, mae: 0.021427, mean_q: 0.024933
 31280/100000: episode: 4356, duration: 0.074s, episode steps: 10, steps per second: 134, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001172, mae: 0.021081, mean_q: 0.021806
 31290/100000: episode: 4357, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000888, mae: 0.020283, mean_q: 0.023045
 31300/100000: episode: 4358, duration: 0.092s, episode steps: 10, steps per second: 108, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001640, mae: 0.022037, mean_q: 0.029014
 31310/100000: episode: 4359, duration: 0.083s, episode steps: 10, steps per second: 120, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002077, mae: 0.029625, mean_q: 0.031653
 31320/100000: episode: 4360, duration: 0.108s, episode steps: 10, steps per second: 93, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002166, mae: 0.025181, mean_q: 0.024782
 31330/100000: episode: 4361, duration: 0.076s, episode steps: 10, steps per second: 131, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001605, mae: 0.026882, mean_q: 0.024225
 31340/100000: episode: 4362, duration: 0.093s, episode steps: 10, steps per second: 108, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001841, mae: 0.024184, mean_q: 0.022627
 31350/100000: episode: 4363, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001474, mae: 0.019490, mean_q: 0.025634
 31360/100000: episode: 4364, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002883, mae: 0.029953, mean_q: 0.027650
 31370/100000: episode: 4365, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001331, mae: 0.031868, mean_q: 0.019789
 31380/100000: episode: 4366, duration: 0.079s, episode steps: 10, steps per second: 126, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002414, mae: 0.030789, mean_q: 0.027527
 31390/100000: episode: 4367, duration: 0.103s, episode steps: 10, steps per second: 97, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001454, mae: 0.025439, mean_q: 0.030770
 31400/100000: episode: 4368, duration: 0.107s, episode steps: 10, steps per second: 93, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000765, mae: 0.016799, mean_q: 0.018518
 31410/100000: episode: 4369, duration: 0.108s, episode steps: 10, steps per second: 93, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001240, mae: 0.022832, mean_q: 0.027872
 31420/100000: episode: 4370, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001324, mae: 0.030265, mean_q: 0.026615
 31430/100000: episode: 4371, duration: 0.088s, episode steps: 10, steps per second: 113, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002066, mae: 0.031303, mean_q: 0.025057
 31440/100000: episode: 4372, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000742, mae: 0.021272, mean_q: 0.019219
 31450/100000: episode: 4373, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000955, mae: 0.023919, mean_q: 0.019129
 31460/100000: episode: 4374, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001826, mae: 0.024488, mean_q: 0.031064
 31470/100000: episode: 4375, duration: 0.083s, episode steps: 10, steps per second: 120, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001397, mae: 0.021478, mean_q: 0.023636
 31480/100000: episode: 4376, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000925, mae: 0.016524, mean_q: 0.019329
 31490/100000: episode: 4377, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.003468, mae: 0.027038, mean_q: 0.032403
 31500/100000: episode: 4378, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000790, mae: 0.020978, mean_q: 0.011309
 31510/100000: episode: 4379, duration: 0.116s, episode steps: 10, steps per second: 86, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001736, mae: 0.021631, mean_q: 0.016289
 31520/100000: episode: 4380, duration: 0.077s, episode steps: 10, steps per second: 129, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001343, mae: 0.021217, mean_q: 0.022875
 31530/100000: episode: 4381, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000797, mae: 0.018591, mean_q: 0.016179
 31540/100000: episode: 4382, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001824, mae: 0.023317, mean_q: 0.018487
 31550/100000: episode: 4383, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001960, mae: 0.023439, mean_q: 0.020132
 31560/100000: episode: 4384, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000962, mae: 0.021052, mean_q: 0.019361
 31570/100000: episode: 4385, duration: 0.084s, episode steps: 10, steps per second: 120, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001253, mae: 0.025076, mean_q: 0.031822
 31580/100000: episode: 4386, duration: 0.069s, episode steps: 10, steps per second: 146, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000633, mae: 0.019021, mean_q: 0.014008
 31590/100000: episode: 4387, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001055, mae: 0.020679, mean_q: 0.017458
 31600/100000: episode: 4388, duration: 0.109s, episode steps: 10, steps per second: 92, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001136, mae: 0.025889, mean_q: 0.020985
 31610/100000: episode: 4389, duration: 0.126s, episode steps: 10, steps per second: 79, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002536, mae: 0.027603, mean_q: 0.021176
 31620/100000: episode: 4390, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001674, mae: 0.035848, mean_q: 0.027304
 31630/100000: episode: 4391, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000758, mae: 0.020883, mean_q: 0.014156
 31640/100000: episode: 4392, duration: 0.104s, episode steps: 10, steps per second: 96, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000455, mae: 0.012718, mean_q: 0.018098
 31650/100000: episode: 4393, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001571, mae: 0.021926, mean_q: 0.025814
 31660/100000: episode: 4394, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002375, mae: 0.025796, mean_q: 0.024886
 31670/100000: episode: 4395, duration: 0.067s, episode steps: 10, steps per second: 148, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001027, mae: 0.022718, mean_q: 0.014311
 31680/100000: episode: 4396, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001854, mae: 0.023096, mean_q: 0.020782
[Info] 1-TH LEVEL FOUND: 0.03394623100757599, Considering 20/100 traces
 31690/100000: episode: 4397, duration: 0.781s, episode steps: 10, steps per second: 13, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001156, mae: 0.026721, mean_q: 0.021178
[Info] FALSIFICATION!
 31695/100000: episode: 4398, duration: 0.314s, episode steps: 5, steps per second: 16, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.001075, mae: 0.021083, mean_q: 0.015800
 31697/100000: episode: 4399, duration: 0.028s, episode steps: 2, steps per second: 71, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004071, mae: 0.027675, mean_q: 0.025030
 31699/100000: episode: 4400, duration: 0.023s, episode steps: 2, steps per second: 89, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001926, mae: 0.034620, mean_q: 0.050129
 31701/100000: episode: 4401, duration: 0.026s, episode steps: 2, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001596, mae: 0.022782, mean_q: 0.023306
 31703/100000: episode: 4402, duration: 0.023s, episode steps: 2, steps per second: 88, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001677, mae: 0.042044, mean_q: 0.006704
 31705/100000: episode: 4403, duration: 0.018s, episode steps: 2, steps per second: 109, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001155, mae: 0.014999, mean_q: 0.019729
 31707/100000: episode: 4404, duration: 0.021s, episode steps: 2, steps per second: 94, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000881, mae: 0.020703, mean_q: 0.021981
 31709/100000: episode: 4405, duration: 0.025s, episode steps: 2, steps per second: 81, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000899, mae: 0.019388, mean_q: 0.006677
 31715/100000: episode: 4406, duration: 0.047s, episode steps: 6, steps per second: 128, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001570, mae: 0.027731, mean_q: 0.030321
 31721/100000: episode: 4407, duration: 0.054s, episode steps: 6, steps per second: 111, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000576, mae: 0.018003, mean_q: 0.017196
 31723/100000: episode: 4408, duration: 0.020s, episode steps: 2, steps per second: 98, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000360, mae: 0.014043, mean_q: 0.018154
 31725/100000: episode: 4409, duration: 0.022s, episode steps: 2, steps per second: 90, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000447, mae: 0.014606, mean_q: 0.015821
 31727/100000: episode: 4410, duration: 0.026s, episode steps: 2, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000878, mae: 0.016458, mean_q: 0.025108
 31729/100000: episode: 4411, duration: 0.028s, episode steps: 2, steps per second: 73, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002327, mae: 0.025810, mean_q: 0.035256
 31731/100000: episode: 4412, duration: 0.033s, episode steps: 2, steps per second: 60, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000368, mae: 0.012073, mean_q: 0.007070
 31733/100000: episode: 4413, duration: 0.025s, episode steps: 2, steps per second: 80, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001297, mae: 0.021520, mean_q: 0.033309
 31735/100000: episode: 4414, duration: 0.019s, episode steps: 2, steps per second: 108, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001792, mae: 0.025409, mean_q: 0.039172
 31741/100000: episode: 4415, duration: 0.039s, episode steps: 6, steps per second: 155, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002372, mae: 0.023664, mean_q: 0.016215
 31743/100000: episode: 4416, duration: 0.017s, episode steps: 2, steps per second: 119, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001049, mae: 0.026495, mean_q: 0.045767
 31745/100000: episode: 4417, duration: 0.032s, episode steps: 2, steps per second: 62, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000715, mae: 0.019699, mean_q: 0.016921
 31747/100000: episode: 4418, duration: 0.031s, episode steps: 2, steps per second: 65, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000963, mae: 0.020066, mean_q: 0.027952
 31749/100000: episode: 4419, duration: 0.027s, episode steps: 2, steps per second: 73, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000793, mae: 0.020410, mean_q: 0.028115
 31751/100000: episode: 4420, duration: 0.036s, episode steps: 2, steps per second: 56, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001637, mae: 0.023223, mean_q: 0.032649
 31753/100000: episode: 4421, duration: 0.023s, episode steps: 2, steps per second: 85, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000741, mae: 0.024703, mean_q: 0.009774
 31755/100000: episode: 4422, duration: 0.027s, episode steps: 2, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001918, mae: 0.024723, mean_q: 0.035834
 31757/100000: episode: 4423, duration: 0.018s, episode steps: 2, steps per second: 111, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001523, mae: 0.026992, mean_q: 0.042711
 31763/100000: episode: 4424, duration: 0.039s, episode steps: 6, steps per second: 152, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001421, mae: 0.024131, mean_q: 0.018244
 31765/100000: episode: 4425, duration: 0.018s, episode steps: 2, steps per second: 114, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003402, mae: 0.037607, mean_q: 0.055333
 31767/100000: episode: 4426, duration: 0.016s, episode steps: 2, steps per second: 129, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005179, mae: 0.038852, mean_q: 0.042041
 31773/100000: episode: 4427, duration: 0.033s, episode steps: 6, steps per second: 183, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004343, mae: 0.032584, mean_q: 0.032459
 31775/100000: episode: 4428, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000740, mae: 0.025590, mean_q: 0.006117
 31777/100000: episode: 4429, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001192, mae: 0.022391, mean_q: 0.023159
 31779/100000: episode: 4430, duration: 0.017s, episode steps: 2, steps per second: 117, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001801, mae: 0.027024, mean_q: 0.042131
 31781/100000: episode: 4431, duration: 0.015s, episode steps: 2, steps per second: 134, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003116, mae: 0.036532, mean_q: 0.050004
 31783/100000: episode: 4432, duration: 0.017s, episode steps: 2, steps per second: 115, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001000, mae: 0.016717, mean_q: 0.019327
 31785/100000: episode: 4433, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004798, mae: 0.029402, mean_q: 0.034889
 31787/100000: episode: 4434, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001716, mae: 0.024287, mean_q: 0.035084
 31793/100000: episode: 4435, duration: 0.034s, episode steps: 6, steps per second: 175, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002626, mae: 0.031095, mean_q: 0.013455
 31795/100000: episode: 4436, duration: 0.017s, episode steps: 2, steps per second: 119, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000607, mae: 0.025516, mean_q: 0.033598
 31797/100000: episode: 4437, duration: 0.016s, episode steps: 2, steps per second: 125, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000355, mae: 0.018359, mean_q: -0.009389
 31799/100000: episode: 4438, duration: 0.019s, episode steps: 2, steps per second: 104, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000742, mae: 0.021725, mean_q: 0.018107
 31801/100000: episode: 4439, duration: 0.019s, episode steps: 2, steps per second: 108, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001259, mae: 0.027670, mean_q: 0.048533
 31803/100000: episode: 4440, duration: 0.017s, episode steps: 2, steps per second: 118, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000580, mae: 0.013909, mean_q: 0.013609
 31805/100000: episode: 4441, duration: 0.024s, episode steps: 2, steps per second: 83, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001252, mae: 0.022104, mean_q: 0.013029
 31811/100000: episode: 4442, duration: 0.062s, episode steps: 6, steps per second: 97, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.002518, mae: 0.027599, mean_q: 0.036420
 31813/100000: episode: 4443, duration: 0.023s, episode steps: 2, steps per second: 85, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001031, mae: 0.030085, mean_q: -0.011023
 31815/100000: episode: 4444, duration: 0.030s, episode steps: 2, steps per second: 67, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000159, mae: 0.010721, mean_q: 0.006498
 31821/100000: episode: 4445, duration: 0.068s, episode steps: 6, steps per second: 88, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000920, mae: 0.022318, mean_q: 0.024827
 31823/100000: episode: 4446, duration: 0.033s, episode steps: 2, steps per second: 61, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000535, mae: 0.016806, mean_q: 0.007336
 31825/100000: episode: 4447, duration: 0.027s, episode steps: 2, steps per second: 74, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000272, mae: 0.016009, mean_q: 0.023076
 31829/100000: episode: 4448, duration: 0.040s, episode steps: 4, steps per second: 99, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001156, mae: 0.020788, mean_q: 0.028526
 31831/100000: episode: 4449, duration: 0.015s, episode steps: 2, steps per second: 135, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000929, mae: 0.018962, mean_q: 0.011720
 31833/100000: episode: 4450, duration: 0.015s, episode steps: 2, steps per second: 129, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000284, mae: 0.011647, mean_q: 0.012305
 31835/100000: episode: 4451, duration: 0.029s, episode steps: 2, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000372, mae: 0.011736, mean_q: 0.012853
 31837/100000: episode: 4452, duration: 0.035s, episode steps: 2, steps per second: 58, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001473, mae: 0.015285, mean_q: 0.025009
 31839/100000: episode: 4453, duration: 0.030s, episode steps: 2, steps per second: 67, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001677, mae: 0.021279, mean_q: 0.029485
 31845/100000: episode: 4454, duration: 0.076s, episode steps: 6, steps per second: 79, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000535, mae: 0.013191, mean_q: 0.018841
 31847/100000: episode: 4455, duration: 0.024s, episode steps: 2, steps per second: 84, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000617, mae: 0.014715, mean_q: 0.010014
 31849/100000: episode: 4456, duration: 0.017s, episode steps: 2, steps per second: 118, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005392, mae: 0.028668, mean_q: 0.022209
 31851/100000: episode: 4457, duration: 0.023s, episode steps: 2, steps per second: 86, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001601, mae: 0.033747, mean_q: 0.042142
 31853/100000: episode: 4458, duration: 0.026s, episode steps: 2, steps per second: 78, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001691, mae: 0.034190, mean_q: 0.006874
 31859/100000: episode: 4459, duration: 0.043s, episode steps: 6, steps per second: 139, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001058, mae: 0.026138, mean_q: 0.032190
 31861/100000: episode: 4460, duration: 0.026s, episode steps: 2, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000814, mae: 0.023181, mean_q: 0.006296
 31863/100000: episode: 4461, duration: 0.019s, episode steps: 2, steps per second: 105, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000776, mae: 0.022554, mean_q: 0.003837
 31865/100000: episode: 4462, duration: 0.016s, episode steps: 2, steps per second: 124, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000445, mae: 0.021292, mean_q: 0.028167
 31869/100000: episode: 4463, duration: 0.038s, episode steps: 4, steps per second: 106, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000940, mae: 0.017687, mean_q: 0.010080
 31871/100000: episode: 4464, duration: 0.025s, episode steps: 2, steps per second: 79, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000936, mae: 0.022029, mean_q: 0.003656
 31873/100000: episode: 4465, duration: 0.023s, episode steps: 2, steps per second: 85, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000286, mae: 0.018677, mean_q: 0.022374
 31875/100000: episode: 4466, duration: 0.023s, episode steps: 2, steps per second: 86, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001795, mae: 0.025449, mean_q: 0.028280
 31877/100000: episode: 4467, duration: 0.020s, episode steps: 2, steps per second: 102, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000787, mae: 0.013725, mean_q: 0.016694
 31879/100000: episode: 4468, duration: 0.023s, episode steps: 2, steps per second: 85, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000782, mae: 0.018146, mean_q: 0.019355
 31885/100000: episode: 4469, duration: 0.054s, episode steps: 6, steps per second: 111, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000545, mae: 0.017065, mean_q: 0.019480
 31887/100000: episode: 4470, duration: 0.032s, episode steps: 2, steps per second: 62, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000361, mae: 0.010688, mean_q: 0.011784
 31893/100000: episode: 4471, duration: 0.053s, episode steps: 6, steps per second: 113, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000697, mae: 0.016772, mean_q: 0.027422
 31895/100000: episode: 4472, duration: 0.017s, episode steps: 2, steps per second: 117, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000673, mae: 0.022408, mean_q: -0.000826
 31897/100000: episode: 4473, duration: 0.025s, episode steps: 2, steps per second: 81, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005075, mae: 0.027553, mean_q: 0.019819
 31899/100000: episode: 4474, duration: 0.023s, episode steps: 2, steps per second: 86, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001752, mae: 0.034348, mean_q: 0.056781
 31901/100000: episode: 4475, duration: 0.020s, episode steps: 2, steps per second: 98, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000546, mae: 0.014101, mean_q: 0.006051
 31903/100000: episode: 4476, duration: 0.020s, episode steps: 2, steps per second: 101, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001504, mae: 0.026532, mean_q: 0.007844
[Info] Complete ISplit Iteration
[Info] Levels: [0.03394623, 0.8146312]
[Info] Cond. Prob: [0.2, 0.01]
[Info] Error Prob: 0.002

 31909/100000: episode: 4477, duration: 1.203s, episode steps: 6, steps per second: 5, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001563, mae: 0.022041, mean_q: 0.028213
 31919/100000: episode: 4478, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002468, mae: 0.019535, mean_q: 0.021938
 31929/100000: episode: 4479, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000944, mae: 0.021133, mean_q: 0.013282
 31939/100000: episode: 4480, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000871, mae: 0.023048, mean_q: 0.021823
 31949/100000: episode: 4481, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000650, mae: 0.020516, mean_q: 0.020725
 31959/100000: episode: 4482, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000636, mae: 0.013572, mean_q: 0.016702
 31969/100000: episode: 4483, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001711, mae: 0.020161, mean_q: 0.024044
 31979/100000: episode: 4484, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000891, mae: 0.018647, mean_q: 0.020043
 31989/100000: episode: 4485, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001788, mae: 0.023026, mean_q: 0.026096
 31999/100000: episode: 4486, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000963, mae: 0.020251, mean_q: 0.017473
[Info] FALSIFICATION!
 32009/100000: episode: 4487, duration: 0.313s, episode steps: 10, steps per second: 32, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.001152, mae: 0.021105, mean_q: 0.026374
 32019/100000: episode: 4488, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001092, mae: 0.018810, mean_q: 0.021706
 32029/100000: episode: 4489, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000772, mae: 0.016388, mean_q: 0.018400
 32039/100000: episode: 4490, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001250, mae: 0.013335, mean_q: 0.016772
 32049/100000: episode: 4491, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001042, mae: 0.017504, mean_q: 0.030447
 32059/100000: episode: 4492, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002153, mae: 0.023457, mean_q: 0.024288
 32069/100000: episode: 4493, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000715, mae: 0.018949, mean_q: 0.018094
 32079/100000: episode: 4494, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000763, mae: 0.014883, mean_q: 0.019322
 32089/100000: episode: 4495, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001418, mae: 0.022560, mean_q: 0.023909
 32099/100000: episode: 4496, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002235, mae: 0.023733, mean_q: 0.030133
 32109/100000: episode: 4497, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000911, mae: 0.021507, mean_q: 0.018971
 32119/100000: episode: 4498, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000963, mae: 0.017567, mean_q: 0.017385
 32129/100000: episode: 4499, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000992, mae: 0.021021, mean_q: 0.025027
 32139/100000: episode: 4500, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001751, mae: 0.024428, mean_q: 0.023151
 32149/100000: episode: 4501, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000915, mae: 0.022174, mean_q: 0.016983
 32159/100000: episode: 4502, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001066, mae: 0.019445, mean_q: 0.022877
 32169/100000: episode: 4503, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001066, mae: 0.019871, mean_q: 0.016734
 32179/100000: episode: 4504, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000764, mae: 0.015706, mean_q: 0.017738
 32189/100000: episode: 4505, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001420, mae: 0.023003, mean_q: 0.028253
 32199/100000: episode: 4506, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000905, mae: 0.019535, mean_q: 0.019786
 32209/100000: episode: 4507, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000929, mae: 0.017198, mean_q: 0.019760
 32219/100000: episode: 4508, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000990, mae: 0.017156, mean_q: 0.021763
 32229/100000: episode: 4509, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001380, mae: 0.017538, mean_q: 0.021680
 32239/100000: episode: 4510, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001045, mae: 0.020692, mean_q: 0.019952
 32249/100000: episode: 4511, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001798, mae: 0.027035, mean_q: 0.023526
 32259/100000: episode: 4512, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001073, mae: 0.023821, mean_q: 0.024300
 32269/100000: episode: 4513, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001514, mae: 0.022607, mean_q: 0.015468
 32279/100000: episode: 4514, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000895, mae: 0.022202, mean_q: 0.022367
 32289/100000: episode: 4515, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000912, mae: 0.013917, mean_q: 0.021131
 32299/100000: episode: 4516, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001685, mae: 0.023243, mean_q: 0.030193
 32309/100000: episode: 4517, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001285, mae: 0.026557, mean_q: 0.018848
 32319/100000: episode: 4518, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001013, mae: 0.022455, mean_q: 0.030032
 32329/100000: episode: 4519, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001653, mae: 0.024422, mean_q: 0.026106
 32339/100000: episode: 4520, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001279, mae: 0.023427, mean_q: 0.026081
 32349/100000: episode: 4521, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001256, mae: 0.019260, mean_q: 0.032078
 32359/100000: episode: 4522, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001252, mae: 0.022159, mean_q: 0.027936
 32369/100000: episode: 4523, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001289, mae: 0.024308, mean_q: 0.018176
 32379/100000: episode: 4524, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000834, mae: 0.016271, mean_q: 0.019655
 32389/100000: episode: 4525, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000897, mae: 0.019657, mean_q: 0.022475
 32399/100000: episode: 4526, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000713, mae: 0.014814, mean_q: 0.016025
 32409/100000: episode: 4527, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001141, mae: 0.016977, mean_q: 0.025216
 32419/100000: episode: 4528, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000995, mae: 0.017011, mean_q: 0.017195
 32429/100000: episode: 4529, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001430, mae: 0.015638, mean_q: 0.018148
 32439/100000: episode: 4530, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.001039, mae: 0.021899, mean_q: 0.016751
 32449/100000: episode: 4531, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002052, mae: 0.022630, mean_q: 0.026425
 32459/100000: episode: 4532, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001039, mae: 0.020006, mean_q: 0.025880
 32469/100000: episode: 4533, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000911, mae: 0.021395, mean_q: 0.016228
 32479/100000: episode: 4534, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001999, mae: 0.023141, mean_q: 0.028984
 32489/100000: episode: 4535, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001134, mae: 0.023432, mean_q: 0.015362
 32499/100000: episode: 4536, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001504, mae: 0.026612, mean_q: 0.031490
 32509/100000: episode: 4537, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000861, mae: 0.018371, mean_q: 0.021243
 32519/100000: episode: 4538, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001352, mae: 0.018229, mean_q: 0.030348
 32529/100000: episode: 4539, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002094, mae: 0.029435, mean_q: 0.028173
 32539/100000: episode: 4540, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002281, mae: 0.023829, mean_q: 0.020168
 32549/100000: episode: 4541, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001054, mae: 0.017291, mean_q: 0.025305
 32559/100000: episode: 4542, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001013, mae: 0.018769, mean_q: 0.025305
 32569/100000: episode: 4543, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002118, mae: 0.027638, mean_q: 0.024732
 32579/100000: episode: 4544, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001594, mae: 0.017961, mean_q: 0.018626
 32589/100000: episode: 4545, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001466, mae: 0.022612, mean_q: 0.019403
 32599/100000: episode: 4546, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000973, mae: 0.018545, mean_q: 0.023067
 32609/100000: episode: 4547, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001172, mae: 0.020060, mean_q: 0.022430
 32619/100000: episode: 4548, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000612, mae: 0.016653, mean_q: 0.013568
 32629/100000: episode: 4549, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000772, mae: 0.016563, mean_q: 0.017030
 32639/100000: episode: 4550, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001140, mae: 0.019200, mean_q: 0.021580
 32649/100000: episode: 4551, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001038, mae: 0.017445, mean_q: 0.023335
 32659/100000: episode: 4552, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001268, mae: 0.021653, mean_q: 0.031789
 32669/100000: episode: 4553, duration: 0.086s, episode steps: 10, steps per second: 117, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000834, mae: 0.017933, mean_q: 0.019530
 32679/100000: episode: 4554, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000693, mae: 0.013864, mean_q: 0.018161
 32689/100000: episode: 4555, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001644, mae: 0.024259, mean_q: 0.024355
 32699/100000: episode: 4556, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002181, mae: 0.029796, mean_q: 0.023538
 32709/100000: episode: 4557, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001049, mae: 0.021321, mean_q: 0.020101
 32719/100000: episode: 4558, duration: 0.104s, episode steps: 10, steps per second: 96, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001831, mae: 0.020301, mean_q: 0.022498
 32729/100000: episode: 4559, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.002015, mae: 0.021986, mean_q: 0.032238
 32739/100000: episode: 4560, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.001525, mae: 0.026396, mean_q: 0.031842
 32749/100000: episode: 4561, duration: 0.119s, episode steps: 10, steps per second: 84, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001063, mae: 0.021506, mean_q: 0.021156
 32759/100000: episode: 4562, duration: 0.089s, episode steps: 10, steps per second: 113, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000463, mae: 0.015576, mean_q: 0.014692
 32769/100000: episode: 4563, duration: 0.088s, episode steps: 10, steps per second: 113, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000876, mae: 0.019541, mean_q: 0.024851
 32779/100000: episode: 4564, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000825, mae: 0.013570, mean_q: 0.015838
 32789/100000: episode: 4565, duration: 0.067s, episode steps: 10, steps per second: 148, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002199, mae: 0.025267, mean_q: 0.037586
 32799/100000: episode: 4566, duration: 0.077s, episode steps: 10, steps per second: 129, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001001, mae: 0.023031, mean_q: 0.024057
 32809/100000: episode: 4567, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001092, mae: 0.022968, mean_q: 0.024546
 32819/100000: episode: 4568, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001100, mae: 0.027476, mean_q: 0.023332
 32829/100000: episode: 4569, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000826, mae: 0.021281, mean_q: 0.017334
 32839/100000: episode: 4570, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000910, mae: 0.019211, mean_q: 0.024422
 32849/100000: episode: 4571, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002009, mae: 0.027853, mean_q: 0.025142
 32859/100000: episode: 4572, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000859, mae: 0.023218, mean_q: 0.022925
 32869/100000: episode: 4573, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000878, mae: 0.020217, mean_q: 0.015587
 32879/100000: episode: 4574, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000966, mae: 0.019633, mean_q: 0.020263
 32889/100000: episode: 4575, duration: 0.080s, episode steps: 10, steps per second: 124, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001480, mae: 0.024597, mean_q: 0.024979
 32899/100000: episode: 4576, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001459, mae: 0.021151, mean_q: 0.023660
[Info] Complete ISplit Iteration
[Info] Levels: [0.8291737]
[Info] Cond. Prob: [0.01]
[Info] Error Prob: 0.01

 32909/100000: episode: 4577, duration: 1.071s, episode steps: 10, steps per second: 9, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001389, mae: 0.025186, mean_q: 0.027647
 32919/100000: episode: 4578, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001306, mae: 0.024056, mean_q: 0.020776
 32929/100000: episode: 4579, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.003316, mae: 0.032693, mean_q: 0.033559
 32939/100000: episode: 4580, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001428, mae: 0.027363, mean_q: 0.028552
 32949/100000: episode: 4581, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001550, mae: 0.021297, mean_q: 0.029578
 32959/100000: episode: 4582, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001193, mae: 0.024131, mean_q: 0.025667
 32969/100000: episode: 4583, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000634, mae: 0.016349, mean_q: 0.018653
 32979/100000: episode: 4584, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000575, mae: 0.016427, mean_q: 0.018157
 32989/100000: episode: 4585, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000721, mae: 0.011986, mean_q: 0.017451
 32999/100000: episode: 4586, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002043, mae: 0.026508, mean_q: 0.029555
 33009/100000: episode: 4587, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002245, mae: 0.027300, mean_q: 0.022820
 33019/100000: episode: 4588, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001936, mae: 0.033735, mean_q: 0.029085
 33029/100000: episode: 4589, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002105, mae: 0.032082, mean_q: 0.029898
 33039/100000: episode: 4590, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002594, mae: 0.034949, mean_q: 0.051772
 33049/100000: episode: 4591, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001052, mae: 0.026862, mean_q: 0.016117
 33059/100000: episode: 4592, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000868, mae: 0.020278, mean_q: 0.015395
 33069/100000: episode: 4593, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001090, mae: 0.023273, mean_q: 0.028133
 33079/100000: episode: 4594, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000844, mae: 0.016627, mean_q: 0.020099
 33089/100000: episode: 4595, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001410, mae: 0.020022, mean_q: 0.022996
 33099/100000: episode: 4596, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002123, mae: 0.027207, mean_q: 0.027781
 33109/100000: episode: 4597, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001782, mae: 0.025546, mean_q: 0.023999
 33119/100000: episode: 4598, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001646, mae: 0.023900, mean_q: 0.026540
 33129/100000: episode: 4599, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001333, mae: 0.026927, mean_q: 0.025430
 33139/100000: episode: 4600, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.000706, mae: 0.021507, mean_q: 0.021246
 33149/100000: episode: 4601, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000702, mae: 0.017778, mean_q: 0.016641
 33159/100000: episode: 4602, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002239, mae: 0.024036, mean_q: 0.027536
 33169/100000: episode: 4603, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001120, mae: 0.020979, mean_q: 0.032777
 33179/100000: episode: 4604, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000553, mae: 0.012391, mean_q: 0.012762
 33189/100000: episode: 4605, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001134, mae: 0.018559, mean_q: 0.020690
 33199/100000: episode: 4606, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000532, mae: 0.015256, mean_q: 0.016188
 33209/100000: episode: 4607, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001141, mae: 0.023003, mean_q: 0.021008
 33219/100000: episode: 4608, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002820, mae: 0.028150, mean_q: 0.031904
 33229/100000: episode: 4609, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001025, mae: 0.021475, mean_q: 0.020406
 33239/100000: episode: 4610, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000712, mae: 0.017045, mean_q: 0.019855
 33249/100000: episode: 4611, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000701, mae: 0.014919, mean_q: 0.019674
 33259/100000: episode: 4612, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000461, mae: 0.017101, mean_q: 0.012399
 33269/100000: episode: 4613, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001919, mae: 0.026274, mean_q: 0.022411
 33279/100000: episode: 4614, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001103, mae: 0.027299, mean_q: 0.020956
 33289/100000: episode: 4615, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000528, mae: 0.013207, mean_q: 0.014665
 33299/100000: episode: 4616, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000762, mae: 0.014688, mean_q: 0.018171
 33309/100000: episode: 4617, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000757, mae: 0.016645, mean_q: 0.021072
 33319/100000: episode: 4618, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001031, mae: 0.019392, mean_q: 0.015153
 33329/100000: episode: 4619, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000496, mae: 0.014604, mean_q: 0.012350
 33339/100000: episode: 4620, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002700, mae: 0.031395, mean_q: 0.031561
 33349/100000: episode: 4621, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001212, mae: 0.020660, mean_q: 0.019324
 33359/100000: episode: 4622, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001238, mae: 0.020000, mean_q: 0.023001
 33369/100000: episode: 4623, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001005, mae: 0.022169, mean_q: 0.018310
 33379/100000: episode: 4624, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000854, mae: 0.013930, mean_q: 0.014618
 33389/100000: episode: 4625, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000983, mae: 0.017607, mean_q: 0.018696
 33399/100000: episode: 4626, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001988, mae: 0.022286, mean_q: 0.026481
 33409/100000: episode: 4627, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001182, mae: 0.021032, mean_q: 0.020063
 33419/100000: episode: 4628, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001220, mae: 0.022503, mean_q: 0.021008
 33429/100000: episode: 4629, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000640, mae: 0.016236, mean_q: 0.013112
 33439/100000: episode: 4630, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000985, mae: 0.018046, mean_q: 0.022081
 33449/100000: episode: 4631, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001073, mae: 0.017209, mean_q: 0.029277
 33459/100000: episode: 4632, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000965, mae: 0.019995, mean_q: 0.024581
 33469/100000: episode: 4633, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000800, mae: 0.014353, mean_q: 0.021962
 33479/100000: episode: 4634, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000657, mae: 0.012615, mean_q: 0.020514
 33489/100000: episode: 4635, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000471, mae: 0.010471, mean_q: 0.019270
 33499/100000: episode: 4636, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000774, mae: 0.016929, mean_q: 0.013511
 33509/100000: episode: 4637, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.001112, mae: 0.017141, mean_q: 0.020816
 33519/100000: episode: 4638, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002842, mae: 0.020364, mean_q: 0.022763
 33529/100000: episode: 4639, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000904, mae: 0.018756, mean_q: 0.017604
 33539/100000: episode: 4640, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000520, mae: 0.013532, mean_q: 0.015200
 33549/100000: episode: 4641, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001417, mae: 0.020953, mean_q: 0.025519
 33559/100000: episode: 4642, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000810, mae: 0.017939, mean_q: 0.014959
 33569/100000: episode: 4643, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000924, mae: 0.015648, mean_q: 0.016121
 33579/100000: episode: 4644, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001253, mae: 0.020707, mean_q: 0.021451
[Info] FALSIFICATION!
 33589/100000: episode: 4645, duration: 0.327s, episode steps: 10, steps per second: 31, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.002043, mae: 0.027801, mean_q: 0.030966
 33599/100000: episode: 4646, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001615, mae: 0.027488, mean_q: 0.034041
 33609/100000: episode: 4647, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000831, mae: 0.021212, mean_q: 0.016328
 33619/100000: episode: 4648, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001008, mae: 0.019665, mean_q: 0.029890
 33629/100000: episode: 4649, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001214, mae: 0.016612, mean_q: 0.026367
 33639/100000: episode: 4650, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001264, mae: 0.017608, mean_q: 0.023433
 33649/100000: episode: 4651, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002282, mae: 0.031959, mean_q: 0.028252
 33659/100000: episode: 4652, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000882, mae: 0.027253, mean_q: 0.013075
 33669/100000: episode: 4653, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000838, mae: 0.028360, mean_q: 0.007322
 33679/100000: episode: 4654, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000677, mae: 0.019174, mean_q: 0.010935
 33689/100000: episode: 4655, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001172, mae: 0.020000, mean_q: 0.020944
 33699/100000: episode: 4656, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000621, mae: 0.012810, mean_q: 0.010466
 33709/100000: episode: 4657, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001399, mae: 0.021416, mean_q: 0.026116
 33719/100000: episode: 4658, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000727, mae: 0.018106, mean_q: 0.020240
 33729/100000: episode: 4659, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001142, mae: 0.020110, mean_q: 0.015976
 33739/100000: episode: 4660, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000501, mae: 0.014610, mean_q: 0.013980
 33749/100000: episode: 4661, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001237, mae: 0.016549, mean_q: 0.023137
 33759/100000: episode: 4662, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001838, mae: 0.019471, mean_q: 0.022272
 33769/100000: episode: 4663, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002261, mae: 0.027269, mean_q: 0.026464
 33779/100000: episode: 4664, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000840, mae: 0.022495, mean_q: 0.013036
 33789/100000: episode: 4665, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000676, mae: 0.017035, mean_q: 0.012129
 33799/100000: episode: 4666, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000661, mae: 0.013579, mean_q: 0.018145
 33809/100000: episode: 4667, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001173, mae: 0.022075, mean_q: 0.018259
 33819/100000: episode: 4668, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000994, mae: 0.025154, mean_q: 0.015509
 33829/100000: episode: 4669, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001059, mae: 0.018004, mean_q: 0.024603
 33839/100000: episode: 4670, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001797, mae: 0.023927, mean_q: 0.023184
 33849/100000: episode: 4671, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000973, mae: 0.018474, mean_q: 0.019470
 33859/100000: episode: 4672, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000921, mae: 0.016624, mean_q: 0.019028
 33869/100000: episode: 4673, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001082, mae: 0.021576, mean_q: 0.019683
 33879/100000: episode: 4674, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002687, mae: 0.027869, mean_q: 0.029293
 33889/100000: episode: 4675, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001882, mae: 0.026243, mean_q: 0.022771
 33899/100000: episode: 4676, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001418, mae: 0.015224, mean_q: 0.021150
[Info] Complete ISplit Iteration
[Info] Levels: [0.8428061]
[Info] Cond. Prob: [0.01]
[Info] Error Prob: 0.01

 33909/100000: episode: 4677, duration: 0.842s, episode steps: 10, steps per second: 12, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001221, mae: 0.019489, mean_q: 0.015376
 33919/100000: episode: 4678, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001386, mae: 0.022342, mean_q: 0.028502
 33929/100000: episode: 4679, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000919, mae: 0.021008, mean_q: 0.018069
 33939/100000: episode: 4680, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000775, mae: 0.016364, mean_q: 0.012404
 33949/100000: episode: 4681, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001084, mae: 0.016095, mean_q: 0.016343
 33959/100000: episode: 4682, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000706, mae: 0.015006, mean_q: 0.015271
 33969/100000: episode: 4683, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000742, mae: 0.013419, mean_q: 0.015019
 33979/100000: episode: 4684, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001276, mae: 0.017219, mean_q: 0.022574
 33989/100000: episode: 4685, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000816, mae: 0.015761, mean_q: 0.019884
 33999/100000: episode: 4686, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000575, mae: 0.012665, mean_q: 0.027102
 34009/100000: episode: 4687, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001068, mae: 0.015082, mean_q: 0.017994
 34019/100000: episode: 4688, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001245, mae: 0.027542, mean_q: 0.017053
 34029/100000: episode: 4689, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002538, mae: 0.029411, mean_q: 0.021069
 34039/100000: episode: 4690, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001885, mae: 0.018704, mean_q: 0.025770
 34049/100000: episode: 4691, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001040, mae: 0.018622, mean_q: 0.023741
 34059/100000: episode: 4692, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000815, mae: 0.017075, mean_q: 0.016617
 34069/100000: episode: 4693, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001334, mae: 0.020547, mean_q: 0.024795
 34079/100000: episode: 4694, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000635, mae: 0.015452, mean_q: 0.021132
 34089/100000: episode: 4695, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000736, mae: 0.012960, mean_q: 0.016209
 34099/100000: episode: 4696, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002758, mae: 0.029132, mean_q: 0.031919
 34109/100000: episode: 4697, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002444, mae: 0.035726, mean_q: 0.019543
 34119/100000: episode: 4698, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000684, mae: 0.024003, mean_q: 0.007378
 34129/100000: episode: 4699, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000783, mae: 0.018557, mean_q: 0.017865
 34139/100000: episode: 4700, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001393, mae: 0.022171, mean_q: 0.019219
 34149/100000: episode: 4701, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001695, mae: 0.018701, mean_q: 0.017588
 34159/100000: episode: 4702, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000816, mae: 0.013969, mean_q: 0.016634
 34169/100000: episode: 4703, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001531, mae: 0.021123, mean_q: 0.031221
 34179/100000: episode: 4704, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000623, mae: 0.015199, mean_q: 0.017665
 34189/100000: episode: 4705, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001620, mae: 0.016869, mean_q: 0.018846
 34199/100000: episode: 4706, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001806, mae: 0.026011, mean_q: 0.015673
 34209/100000: episode: 4707, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001983, mae: 0.021750, mean_q: 0.023419
 34219/100000: episode: 4708, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000568, mae: 0.016425, mean_q: 0.013509
 34229/100000: episode: 4709, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001220, mae: 0.019526, mean_q: 0.027140
 34239/100000: episode: 4710, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000814, mae: 0.015086, mean_q: 0.021917
 34249/100000: episode: 4711, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001045, mae: 0.015346, mean_q: 0.020481
 34259/100000: episode: 4712, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002450, mae: 0.025241, mean_q: 0.035027
 34269/100000: episode: 4713, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000968, mae: 0.020703, mean_q: 0.017389
 34279/100000: episode: 4714, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001091, mae: 0.017639, mean_q: 0.022730
 34289/100000: episode: 4715, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000844, mae: 0.015656, mean_q: 0.019481
 34299/100000: episode: 4716, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000664, mae: 0.012918, mean_q: 0.020817
 34309/100000: episode: 4717, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000840, mae: 0.019480, mean_q: 0.028136
 34319/100000: episode: 4718, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000448, mae: 0.013537, mean_q: 0.016664
 34329/100000: episode: 4719, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000820, mae: 0.021068, mean_q: 0.020012
 34339/100000: episode: 4720, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000742, mae: 0.019771, mean_q: 0.014215
 34349/100000: episode: 4721, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000856, mae: 0.021491, mean_q: 0.018940
 34359/100000: episode: 4722, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000658, mae: 0.016048, mean_q: 0.011692
 34369/100000: episode: 4723, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.002042, mae: 0.023827, mean_q: 0.031121
 34379/100000: episode: 4724, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001649, mae: 0.025793, mean_q: 0.018677
 34389/100000: episode: 4725, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001156, mae: 0.017741, mean_q: 0.014005
 34399/100000: episode: 4726, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001178, mae: 0.023295, mean_q: 0.019495
 34409/100000: episode: 4727, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002147, mae: 0.029406, mean_q: 0.027346
 34419/100000: episode: 4728, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000933, mae: 0.018600, mean_q: 0.019651
 34429/100000: episode: 4729, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001005, mae: 0.020076, mean_q: 0.021242
 34439/100000: episode: 4730, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000584, mae: 0.014878, mean_q: 0.014313
 34449/100000: episode: 4731, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.003514, mae: 0.034053, mean_q: 0.033517
 34459/100000: episode: 4732, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001349, mae: 0.034047, mean_q: 0.021566
 34469/100000: episode: 4733, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001562, mae: 0.026085, mean_q: 0.021112
 34479/100000: episode: 4734, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000937, mae: 0.015043, mean_q: 0.017276
 34489/100000: episode: 4735, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001303, mae: 0.015753, mean_q: 0.018915
 34499/100000: episode: 4736, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001328, mae: 0.023143, mean_q: 0.018699
 34509/100000: episode: 4737, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002387, mae: 0.022678, mean_q: 0.029468
 34519/100000: episode: 4738, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000549, mae: 0.014489, mean_q: 0.014750
 34529/100000: episode: 4739, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000713, mae: 0.015088, mean_q: 0.016353
 34539/100000: episode: 4740, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000736, mae: 0.015183, mean_q: 0.021923
 34549/100000: episode: 4741, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001004, mae: 0.017060, mean_q: 0.015317
 34559/100000: episode: 4742, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000623, mae: 0.014831, mean_q: 0.012012
 34569/100000: episode: 4743, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001079, mae: 0.017363, mean_q: 0.019500
 34579/100000: episode: 4744, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001591, mae: 0.018264, mean_q: 0.011208
 34589/100000: episode: 4745, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000806, mae: 0.018248, mean_q: 0.013970
 34599/100000: episode: 4746, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000826, mae: 0.014706, mean_q: 0.021933
 34609/100000: episode: 4747, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000964, mae: 0.017885, mean_q: 0.020271
 34619/100000: episode: 4748, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000893, mae: 0.015603, mean_q: 0.018812
 34629/100000: episode: 4749, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001404, mae: 0.015861, mean_q: 0.019988
 34639/100000: episode: 4750, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001398, mae: 0.026196, mean_q: 0.020742
 34649/100000: episode: 4751, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001201, mae: 0.023064, mean_q: 0.015967
 34659/100000: episode: 4752, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001642, mae: 0.017060, mean_q: 0.011799
 34669/100000: episode: 4753, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000532, mae: 0.015439, mean_q: 0.011395
 34679/100000: episode: 4754, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001815, mae: 0.017169, mean_q: 0.016417
 34689/100000: episode: 4755, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000693, mae: 0.013023, mean_q: 0.019567
 34699/100000: episode: 4756, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000934, mae: 0.014123, mean_q: 0.014748
 34709/100000: episode: 4757, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000593, mae: 0.014731, mean_q: 0.015522
 34719/100000: episode: 4758, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000431, mae: 0.013509, mean_q: 0.007600
 34729/100000: episode: 4759, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000845, mae: 0.015908, mean_q: 0.010922
 34739/100000: episode: 4760, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000877, mae: 0.017236, mean_q: 0.017695
 34749/100000: episode: 4761, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001272, mae: 0.022909, mean_q: 0.024261
 34759/100000: episode: 4762, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001331, mae: 0.017079, mean_q: 0.012328
 34769/100000: episode: 4763, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000587, mae: 0.021350, mean_q: 0.009351
 34779/100000: episode: 4764, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002621, mae: 0.024692, mean_q: 0.032982
 34789/100000: episode: 4765, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000342, mae: 0.008947, mean_q: 0.012155
 34799/100000: episode: 4766, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001318, mae: 0.016865, mean_q: 0.021002
 34809/100000: episode: 4767, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000852, mae: 0.018149, mean_q: 0.013779
 34819/100000: episode: 4768, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001018, mae: 0.017548, mean_q: 0.018153
 34829/100000: episode: 4769, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000632, mae: 0.017654, mean_q: 0.011350
 34839/100000: episode: 4770, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001756, mae: 0.021084, mean_q: 0.024031
 34849/100000: episode: 4771, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000685, mae: 0.016962, mean_q: 0.012902
 34859/100000: episode: 4772, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000874, mae: 0.014938, mean_q: 0.026987
 34869/100000: episode: 4773, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001037, mae: 0.017795, mean_q: 0.019519
 34879/100000: episode: 4774, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001172, mae: 0.021224, mean_q: 0.017560
 34889/100000: episode: 4775, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001169, mae: 0.017578, mean_q: 0.023917
 34899/100000: episode: 4776, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001139, mae: 0.019838, mean_q: 0.015912
[Info] 1-TH LEVEL FOUND: 0.03547951579093933, Considering 10/100 traces
 34909/100000: episode: 4777, duration: 0.667s, episode steps: 10, steps per second: 15, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000350, mae: 0.011288, mean_q: 0.011465
 34913/100000: episode: 4778, duration: 0.024s, episode steps: 4, steps per second: 170, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000141, mae: 0.012149, mean_q: 0.015555
 34917/100000: episode: 4779, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001085, mae: 0.019030, mean_q: 0.016972
 34921/100000: episode: 4780, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000397, mae: 0.012523, mean_q: 0.021935
 34923/100000: episode: 4781, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000168, mae: 0.008436, mean_q: 0.004795
 34927/100000: episode: 4782, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000954, mae: 0.015894, mean_q: 0.018754
 34931/100000: episode: 4783, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000232, mae: 0.007583, mean_q: 0.015534
 34935/100000: episode: 4784, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.005082, mae: 0.030967, mean_q: 0.039924
 34937/100000: episode: 4785, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000455, mae: 0.015275, mean_q: 0.029930
 34939/100000: episode: 4786, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000507, mae: 0.022405, mean_q: -0.009756
 34945/100000: episode: 4787, duration: 0.031s, episode steps: 6, steps per second: 197, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001010, mae: 0.016691, mean_q: 0.021208
 34947/100000: episode: 4788, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000716, mae: 0.012188, mean_q: 0.015695
 34951/100000: episode: 4789, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000215, mae: 0.013913, mean_q: -0.005368
 34955/100000: episode: 4790, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000925, mae: 0.014983, mean_q: 0.015283
 34961/100000: episode: 4791, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000611, mae: 0.011972, mean_q: 0.014928
 34967/100000: episode: 4792, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000722, mae: 0.012565, mean_q: 0.017761
 34971/100000: episode: 4793, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002271, mae: 0.015467, mean_q: 0.016038
 34977/100000: episode: 4794, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000808, mae: 0.013826, mean_q: 0.014566
 34979/100000: episode: 4795, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001098, mae: 0.013698, mean_q: 0.022201
 34985/100000: episode: 4796, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000338, mae: 0.009490, mean_q: 0.005869
 34989/100000: episode: 4797, duration: 0.024s, episode steps: 4, steps per second: 167, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000073, mae: 0.008845, mean_q: 0.009617
 34991/100000: episode: 4798, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000369, mae: 0.011743, mean_q: 0.011551
 34993/100000: episode: 4799, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001120, mae: 0.016124, mean_q: 0.018737
 34995/100000: episode: 4800, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000982, mae: 0.018104, mean_q: 0.034951
 35001/100000: episode: 4801, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000434, mae: 0.012285, mean_q: 0.012618
 35003/100000: episode: 4802, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000249, mae: 0.009689, mean_q: 0.007332
[Info] FALSIFICATION!
 35008/100000: episode: 4803, duration: 0.175s, episode steps: 5, steps per second: 29, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000204, mae: 0.009433, mean_q: 0.011668
 35014/100000: episode: 4804, duration: 0.032s, episode steps: 6, steps per second: 187, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000127, mae: 0.005878, mean_q: 0.003224
 35016/100000: episode: 4805, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000297, mae: 0.009366, mean_q: 0.008224
 35018/100000: episode: 4806, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000910, mae: 0.014447, mean_q: 0.023129
 35022/100000: episode: 4807, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000310, mae: 0.010835, mean_q: 0.014545
 35024/100000: episode: 4808, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000326, mae: 0.014672, mean_q: 0.002745
 35030/100000: episode: 4809, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000863, mae: 0.016767, mean_q: 0.028017
 35032/100000: episode: 4810, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000105, mae: 0.007475, mean_q: 0.002144
 35038/100000: episode: 4811, duration: 0.033s, episode steps: 6, steps per second: 181, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000263, mae: 0.010910, mean_q: 0.011538
 35040/100000: episode: 4812, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001129, mae: 0.014339, mean_q: 0.018490
 35046/100000: episode: 4813, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000521, mae: 0.013088, mean_q: 0.009284
 35052/100000: episode: 4814, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000693, mae: 0.012686, mean_q: 0.009474
 35058/100000: episode: 4815, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000509, mae: 0.013068, mean_q: 0.015314
 35064/100000: episode: 4816, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000464, mae: 0.010426, mean_q: 0.007517
 35068/100000: episode: 4817, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000057, mae: 0.007744, mean_q: 0.010139
 35072/100000: episode: 4818, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000617, mae: 0.010205, mean_q: 0.011041
 35074/100000: episode: 4819, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000194, mae: 0.008339, mean_q: 0.009824
 35080/100000: episode: 4820, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000152, mae: 0.008148, mean_q: 0.002509
 35086/100000: episode: 4821, duration: 0.032s, episode steps: 6, steps per second: 189, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000289, mae: 0.013206, mean_q: 0.013505
 35090/100000: episode: 4822, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000743, mae: 0.013510, mean_q: 0.011376
[Info] FALSIFICATION!
 35095/100000: episode: 4823, duration: 0.263s, episode steps: 5, steps per second: 19, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000230, mae: 0.011726, mean_q: 0.011837
 35099/100000: episode: 4824, duration: 0.025s, episode steps: 4, steps per second: 163, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000255, mae: 0.011340, mean_q: -0.001465
 35101/100000: episode: 4825, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000893, mae: 0.015012, mean_q: 0.022650
 35105/100000: episode: 4826, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000128, mae: 0.006763, mean_q: 0.007125
 35109/100000: episode: 4827, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000279, mae: 0.008358, mean_q: 0.003091
 35113/100000: episode: 4828, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000629, mae: 0.011636, mean_q: 0.018448
 35119/100000: episode: 4829, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000247, mae: 0.009884, mean_q: 0.007080
 35125/100000: episode: 4830, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000137, mae: 0.009762, mean_q: 0.007566
 35129/100000: episode: 4831, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000265, mae: 0.008041, mean_q: 0.012841
 35135/100000: episode: 4832, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000822, mae: 0.014190, mean_q: 0.009905
 35139/100000: episode: 4833, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000148, mae: 0.010000, mean_q: 0.014022
 35143/100000: episode: 4834, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000158, mae: 0.009645, mean_q: 0.002213
 35147/100000: episode: 4835, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000398, mae: 0.009017, mean_q: 0.015594
 35149/100000: episode: 4836, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000349, mae: 0.007327, mean_q: 0.012844
 35151/100000: episode: 4837, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000069, mae: 0.004584, mean_q: 0.005194
 35157/100000: episode: 4838, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000079, mae: 0.005578, mean_q: 0.009877
 35163/100000: episode: 4839, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000635, mae: 0.008456, mean_q: 0.011664
 35165/100000: episode: 4840, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000061, mae: 0.005118, mean_q: 0.003862
 35171/100000: episode: 4841, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000735, mae: 0.010807, mean_q: 0.012681
 35175/100000: episode: 4842, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000254, mae: 0.009466, mean_q: -0.001185
 35181/100000: episode: 4843, duration: 0.031s, episode steps: 6, steps per second: 193, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000420, mae: 0.012836, mean_q: 0.015560
 35183/100000: episode: 4844, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000792, mae: 0.015242, mean_q: 0.004156
 35189/100000: episode: 4845, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000494, mae: 0.011525, mean_q: 0.013722
 35191/100000: episode: 4846, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000770, mae: 0.012053, mean_q: 0.002722
 35193/100000: episode: 4847, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000326, mae: 0.011827, mean_q: 0.010775
 35195/100000: episode: 4848, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000205, mae: 0.014972, mean_q: 0.019400
 35199/100000: episode: 4849, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000503, mae: 0.010382, mean_q: 0.009798
 35205/100000: episode: 4850, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000530, mae: 0.010544, mean_q: 0.012945
 35211/100000: episode: 4851, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000847, mae: 0.014758, mean_q: 0.025904
 35215/100000: episode: 4852, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000394, mae: 0.017430, mean_q: 0.003463
 35221/100000: episode: 4853, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000309, mae: 0.011514, mean_q: 0.017651
 35225/100000: episode: 4854, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000448, mae: 0.012371, mean_q: 0.005392
 35227/100000: episode: 4855, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000466, mae: 0.014076, mean_q: 0.021310
 35229/100000: episode: 4856, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000014, mae: 0.002567, mean_q: 0.004715
 35231/100000: episode: 4857, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000113, mae: 0.007704, mean_q: 0.007813
 35237/100000: episode: 4858, duration: 0.028s, episode steps: 6, steps per second: 211, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000111, mae: 0.006871, mean_q: 0.012186
 35243/100000: episode: 4859, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000120, mae: 0.006541, mean_q: 0.008118
 35247/100000: episode: 4860, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000472, mae: 0.014958, mean_q: 0.005120
 35253/100000: episode: 4861, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000368, mae: 0.010195, mean_q: 0.009998
 35259/100000: episode: 4862, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001965, mae: 0.018964, mean_q: 0.012880
 35263/100000: episode: 4863, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000273, mae: 0.017441, mean_q: 0.002710
 35269/100000: episode: 4864, duration: 0.029s, episode steps: 6, steps per second: 210, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000287, mae: 0.013614, mean_q: 0.016396
 35271/100000: episode: 4865, duration: 0.016s, episode steps: 2, steps per second: 124, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000212, mae: 0.010358, mean_q: 0.010755
 35277/100000: episode: 4866, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000107, mae: 0.008996, mean_q: 0.003763
[Info] Complete ISplit Iteration
[Info] Levels: [0.035479516, 0.9276096]
[Info] Cond. Prob: [0.1, 0.02]
[Info] Error Prob: 0.002

 35283/100000: episode: 4867, duration: 0.866s, episode steps: 6, steps per second: 7, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000387, mae: 0.012376, mean_q: 0.008140
 35293/100000: episode: 4868, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000395, mae: 0.011417, mean_q: 0.020236
 35303/100000: episode: 4869, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000759, mae: 0.014452, mean_q: 0.010020
 35313/100000: episode: 4870, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000436, mae: 0.012458, mean_q: 0.010434
 35323/100000: episode: 4871, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000312, mae: 0.009148, mean_q: 0.013386
 35333/100000: episode: 4872, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001087, mae: 0.013645, mean_q: 0.016963
 35343/100000: episode: 4873, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001223, mae: 0.014605, mean_q: 0.011281
 35353/100000: episode: 4874, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000588, mae: 0.017841, mean_q: 0.012686
 35363/100000: episode: 4875, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000622, mae: 0.013413, mean_q: 0.015086
 35373/100000: episode: 4876, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001287, mae: 0.015348, mean_q: 0.021008
 35383/100000: episode: 4877, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000327, mae: 0.009229, mean_q: 0.006472
 35393/100000: episode: 4878, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001020, mae: 0.012489, mean_q: 0.012080
 35403/100000: episode: 4879, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000204, mae: 0.008603, mean_q: 0.011257
 35413/100000: episode: 4880, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000445, mae: 0.015519, mean_q: 0.014542
 35423/100000: episode: 4881, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000736, mae: 0.015847, mean_q: 0.016560
 35433/100000: episode: 4882, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000731, mae: 0.019184, mean_q: 0.015487
 35443/100000: episode: 4883, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001381, mae: 0.017138, mean_q: 0.015000
 35453/100000: episode: 4884, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000618, mae: 0.017107, mean_q: 0.007722
 35463/100000: episode: 4885, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000215, mae: 0.010294, mean_q: 0.006625
 35473/100000: episode: 4886, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000432, mae: 0.011525, mean_q: 0.011019
 35483/100000: episode: 4887, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000429, mae: 0.010787, mean_q: 0.008968
 35493/100000: episode: 4888, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000270, mae: 0.010281, mean_q: 0.009817
 35503/100000: episode: 4889, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000517, mae: 0.012211, mean_q: 0.016506
 35513/100000: episode: 4890, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000201, mae: 0.007518, mean_q: 0.007617
 35523/100000: episode: 4891, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000313, mae: 0.009140, mean_q: 0.009980
 35533/100000: episode: 4892, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001194, mae: 0.015100, mean_q: 0.019053
 35543/100000: episode: 4893, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000268, mae: 0.014911, mean_q: 0.009839
 35553/100000: episode: 4894, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000863, mae: 0.016856, mean_q: 0.021078
 35563/100000: episode: 4895, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000274, mae: 0.011386, mean_q: 0.013769
 35573/100000: episode: 4896, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000316, mae: 0.008823, mean_q: 0.012932
 35583/100000: episode: 4897, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000477, mae: 0.012329, mean_q: 0.016014
 35593/100000: episode: 4898, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000517, mae: 0.010754, mean_q: 0.013636
 35603/100000: episode: 4899, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000174, mae: 0.007178, mean_q: 0.007585
 35613/100000: episode: 4900, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000161, mae: 0.007273, mean_q: 0.006189
 35623/100000: episode: 4901, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000484, mae: 0.009483, mean_q: 0.011981
 35633/100000: episode: 4902, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000979, mae: 0.014630, mean_q: 0.023788
 35643/100000: episode: 4903, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000402, mae: 0.009340, mean_q: 0.012344
 35653/100000: episode: 4904, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000230, mae: 0.009084, mean_q: 0.013407
 35663/100000: episode: 4905, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000543, mae: 0.011121, mean_q: 0.014766
 35673/100000: episode: 4906, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000578, mae: 0.014731, mean_q: 0.016132
 35683/100000: episode: 4907, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000189, mae: 0.011511, mean_q: 0.009716
 35693/100000: episode: 4908, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000360, mae: 0.012029, mean_q: 0.014643
 35703/100000: episode: 4909, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000221, mae: 0.009278, mean_q: 0.011907
 35713/100000: episode: 4910, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000228, mae: 0.012127, mean_q: 0.012786
 35723/100000: episode: 4911, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000424, mae: 0.011606, mean_q: 0.010687
 35733/100000: episode: 4912, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000186, mae: 0.008027, mean_q: 0.005988
 35743/100000: episode: 4913, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000379, mae: 0.011876, mean_q: 0.013200
 35753/100000: episode: 4914, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000373, mae: 0.010956, mean_q: 0.011694
 35763/100000: episode: 4915, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000378, mae: 0.014378, mean_q: 0.013704
 35773/100000: episode: 4916, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000291, mae: 0.013387, mean_q: 0.006368
 35783/100000: episode: 4917, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000451, mae: 0.011288, mean_q: 0.010176
 35793/100000: episode: 4918, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000731, mae: 0.012884, mean_q: 0.014686
 35803/100000: episode: 4919, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000169, mae: 0.008076, mean_q: 0.008040
 35813/100000: episode: 4920, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001213, mae: 0.015969, mean_q: 0.012781
 35823/100000: episode: 4921, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000390, mae: 0.010925, mean_q: 0.009375
 35833/100000: episode: 4922, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000431, mae: 0.010391, mean_q: 0.010065
 35843/100000: episode: 4923, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001477, mae: 0.025028, mean_q: 0.013168
 35853/100000: episode: 4924, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000292, mae: 0.013257, mean_q: 0.013677
 35863/100000: episode: 4925, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000224, mae: 0.010476, mean_q: 0.010984
 35873/100000: episode: 4926, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000303, mae: 0.010792, mean_q: 0.011581
 35883/100000: episode: 4927, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000364, mae: 0.011217, mean_q: 0.014638
 35893/100000: episode: 4928, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000468, mae: 0.008751, mean_q: 0.007621
 35903/100000: episode: 4929, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000136, mae: 0.007853, mean_q: 0.007246
 35913/100000: episode: 4930, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000203, mae: 0.007624, mean_q: 0.008758
 35923/100000: episode: 4931, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000769, mae: 0.014704, mean_q: 0.014314
 35933/100000: episode: 4932, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000338, mae: 0.011460, mean_q: 0.011722
 35943/100000: episode: 4933, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000319, mae: 0.009062, mean_q: 0.009577
 35953/100000: episode: 4934, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000276, mae: 0.010786, mean_q: 0.011796
 35963/100000: episode: 4935, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000620, mae: 0.010668, mean_q: 0.012752
 35973/100000: episode: 4936, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000417, mae: 0.011677, mean_q: 0.010559
 35983/100000: episode: 4937, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000207, mae: 0.009634, mean_q: 0.009479
 35993/100000: episode: 4938, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000883, mae: 0.015217, mean_q: 0.016902
 36003/100000: episode: 4939, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000212, mae: 0.009150, mean_q: 0.006511
 36013/100000: episode: 4940, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000281, mae: 0.009087, mean_q: 0.010240
 36023/100000: episode: 4941, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000443, mae: 0.014939, mean_q: 0.013812
 36033/100000: episode: 4942, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.001208, mae: 0.014366, mean_q: 0.015207
 36043/100000: episode: 4943, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000453, mae: 0.010928, mean_q: 0.012920
 36053/100000: episode: 4944, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000173, mae: 0.009418, mean_q: 0.007244
 36063/100000: episode: 4945, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000333, mae: 0.009792, mean_q: 0.007787
 36073/100000: episode: 4946, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000408, mae: 0.009804, mean_q: 0.012704
 36083/100000: episode: 4947, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000553, mae: 0.012044, mean_q: 0.010254
 36093/100000: episode: 4948, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000397, mae: 0.012509, mean_q: 0.011508
 36103/100000: episode: 4949, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000251, mae: 0.010229, mean_q: 0.009513
 36113/100000: episode: 4950, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000715, mae: 0.013412, mean_q: 0.012797
 36123/100000: episode: 4951, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000511, mae: 0.013952, mean_q: 0.013975
 36133/100000: episode: 4952, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000335, mae: 0.011388, mean_q: 0.012552
 36143/100000: episode: 4953, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000327, mae: 0.009714, mean_q: 0.010838
 36153/100000: episode: 4954, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000294, mae: 0.011716, mean_q: 0.014989
 36163/100000: episode: 4955, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000143, mae: 0.008500, mean_q: 0.005005
 36173/100000: episode: 4956, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000294, mae: 0.010339, mean_q: 0.006551
 36183/100000: episode: 4957, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000583, mae: 0.015793, mean_q: 0.015604
 36193/100000: episode: 4958, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000403, mae: 0.012803, mean_q: 0.017115
 36203/100000: episode: 4959, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000495, mae: 0.013697, mean_q: 0.015619
 36213/100000: episode: 4960, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000174, mae: 0.009727, mean_q: 0.007320
 36223/100000: episode: 4961, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000508, mae: 0.010726, mean_q: 0.013779
 36233/100000: episode: 4962, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000246, mae: 0.009531, mean_q: 0.006412
 36243/100000: episode: 4963, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000090, mae: 0.005879, mean_q: 0.007332
 36253/100000: episode: 4964, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000393, mae: 0.010891, mean_q: 0.006212
 36263/100000: episode: 4965, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000221, mae: 0.010819, mean_q: 0.011787
 36273/100000: episode: 4966, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001377, mae: 0.016537, mean_q: 0.017308
[Info] 1-TH LEVEL FOUND: 0.003276526927947998, Considering 100/100 traces
 36283/100000: episode: 4967, duration: 0.692s, episode steps: 10, steps per second: 14, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000228, mae: 0.015658, mean_q: 0.005697
[Info] 2-TH LEVEL FOUND: 0.010310634970664978, Considering 100/100 traces
 36284/100000: episode: 4968, duration: 0.613s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.001266, mae: 0.026026, mean_q: 0.011712
[Info] 3-TH LEVEL FOUND: 0.023806899785995483, Considering 100/100 traces
 36285/100000: episode: 4969, duration: 0.670s, episode steps: 1, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000810, mae: 0.014352, mean_q: 0.010636
[Info] 4-TH LEVEL FOUND: 0.04472966492176056, Considering 11/100 traces
 36286/100000: episode: 4970, duration: 0.674s, episode steps: 1, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.001345, mae: 0.017741, mean_q: 0.033104
 36290/100000: episode: 4971, duration: 0.038s, episode steps: 4, steps per second: 104, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000187, mae: 0.010657, mean_q: 0.011335
 36294/100000: episode: 4972, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000380, mae: 0.013391, mean_q: 0.007742
 36296/100000: episode: 4973, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001230, mae: 0.017146, mean_q: 0.028285
 36302/100000: episode: 4974, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000391, mae: 0.010897, mean_q: 0.002230
 36304/100000: episode: 4975, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000093, mae: 0.009433, mean_q: 0.009556
 36308/100000: episode: 4976, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000159, mae: 0.007366, mean_q: 0.007070
 36310/100000: episode: 4977, duration: 0.015s, episode steps: 2, steps per second: 138, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000078, mae: 0.005638, mean_q: 0.004210
 36312/100000: episode: 4978, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000068, mae: 0.006787, mean_q: 0.003206
 36318/100000: episode: 4979, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000363, mae: 0.009419, mean_q: 0.011713
 36324/100000: episode: 4980, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000081, mae: 0.007587, mean_q: 0.004291
 36326/100000: episode: 4981, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000218, mae: 0.009720, mean_q: 0.014623
 36330/100000: episode: 4982, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000081, mae: 0.007381, mean_q: 0.006586
 36332/100000: episode: 4983, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000226, mae: 0.008169, mean_q: 0.003357
 36336/100000: episode: 4984, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000262, mae: 0.012511, mean_q: 0.013396
 36338/100000: episode: 4985, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000017, mae: 0.003898, mean_q: 0.004135
 36342/100000: episode: 4986, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000135, mae: 0.007630, mean_q: 0.003680
 36346/100000: episode: 4987, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003039, mae: 0.028956, mean_q: 0.034675
 36352/100000: episode: 4988, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000861, mae: 0.022203, mean_q: 0.011210
 36354/100000: episode: 4989, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000153, mae: 0.008844, mean_q: 0.008107
 36360/100000: episode: 4990, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000349, mae: 0.017537, mean_q: 0.004234
 36366/100000: episode: 4991, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000145, mae: 0.009743, mean_q: 0.006903
 36368/100000: episode: 4992, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000079, mae: 0.007799, mean_q: 0.010525
 36372/100000: episode: 4993, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000167, mae: 0.010776, mean_q: 0.003732
 36376/100000: episode: 4994, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000190, mae: 0.010543, mean_q: 0.012135
 36380/100000: episode: 4995, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000106, mae: 0.008004, mean_q: 0.004350
 36384/100000: episode: 4996, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000447, mae: 0.010452, mean_q: 0.015601
 36386/100000: episode: 4997, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000852, mae: 0.018537, mean_q: 0.028438
 36390/100000: episode: 4998, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000397, mae: 0.010859, mean_q: 0.006617
 36392/100000: episode: 4999, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000183, mae: 0.009245, mean_q: 0.005196
 36394/100000: episode: 5000, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001891, mae: 0.020522, mean_q: 0.021127
 36400/100000: episode: 5001, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000291, mae: 0.013878, mean_q: 0.014125
 36404/100000: episode: 5002, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000543, mae: 0.011823, mean_q: 0.009648
 36406/100000: episode: 5003, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000126, mae: 0.007278, mean_q: 0.014052
 36412/100000: episode: 5004, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000127, mae: 0.008889, mean_q: 0.004250
 36418/100000: episode: 5005, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000430, mae: 0.008721, mean_q: 0.012676
 36422/100000: episode: 5006, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000097, mae: 0.006718, mean_q: 0.008499
 36424/100000: episode: 5007, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000448, mae: 0.008411, mean_q: 0.008043
 36426/100000: episode: 5008, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000071, mae: 0.004619, mean_q: 0.003667
 36428/100000: episode: 5009, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000230, mae: 0.010191, mean_q: 0.009966
 36432/100000: episode: 5010, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000111, mae: 0.006986, mean_q: 0.008864
 36436/100000: episode: 5011, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000748, mae: 0.011709, mean_q: 0.014385
 36440/100000: episode: 5012, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000144, mae: 0.007779, mean_q: 0.011241
 36446/100000: episode: 5013, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000296, mae: 0.009757, mean_q: 0.005651
 36450/100000: episode: 5014, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000167, mae: 0.008072, mean_q: 0.006644
 36456/100000: episode: 5015, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000356, mae: 0.009833, mean_q: 0.012036
 36460/100000: episode: 5016, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000241, mae: 0.010692, mean_q: 0.007680
 36464/100000: episode: 5017, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000148, mae: 0.009948, mean_q: 0.014250
 36468/100000: episode: 5018, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000209, mae: 0.008357, mean_q: 0.009386
 36472/100000: episode: 5019, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000328, mae: 0.009725, mean_q: 0.010177
 36478/100000: episode: 5020, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000411, mae: 0.011791, mean_q: 0.014432
 36482/100000: episode: 5021, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.003073, mae: 0.020589, mean_q: 0.025179
 36486/100000: episode: 5022, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000497, mae: 0.020952, mean_q: 0.005091
 36492/100000: episode: 5023, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000304, mae: 0.015016, mean_q: 0.011962
 36498/100000: episode: 5024, duration: 0.033s, episode steps: 6, steps per second: 183, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000231, mae: 0.011121, mean_q: 0.008224
 36502/100000: episode: 5025, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000815, mae: 0.018294, mean_q: 0.031379
 36504/100000: episode: 5026, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000272, mae: 0.014928, mean_q: -0.001728
 36506/100000: episode: 5027, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001993, mae: 0.024507, mean_q: 0.039012
 36512/100000: episode: 5028, duration: 0.032s, episode steps: 6, steps per second: 187, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000659, mae: 0.015349, mean_q: 0.004058
 36516/100000: episode: 5029, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000375, mae: 0.015765, mean_q: 0.012626
 36522/100000: episode: 5030, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000367, mae: 0.018339, mean_q: 0.013179
 36526/100000: episode: 5031, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000180, mae: 0.014002, mean_q: -0.006904
 36528/100000: episode: 5032, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000335, mae: 0.016339, mean_q: 0.024934
 36534/100000: episode: 5033, duration: 0.031s, episode steps: 6, steps per second: 192, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000345, mae: 0.017474, mean_q: 0.005421
 36540/100000: episode: 5034, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000263, mae: 0.011850, mean_q: 0.015351
 36542/100000: episode: 5035, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000217, mae: 0.011284, mean_q: -0.000443
 36546/100000: episode: 5036, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000739, mae: 0.021388, mean_q: 0.027047
 36552/100000: episode: 5037, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000202, mae: 0.010558, mean_q: 0.006213
 36554/100000: episode: 5038, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000139, mae: 0.008574, mean_q: 0.010957
 36558/100000: episode: 5039, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000257, mae: 0.010345, mean_q: 0.000258
 36560/100000: episode: 5040, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000481, mae: 0.016833, mean_q: 0.022542
 36564/100000: episode: 5041, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000328, mae: 0.010608, mean_q: 0.007135
 36568/100000: episode: 5042, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000224, mae: 0.009922, mean_q: 0.007270
 36570/100000: episode: 5043, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000179, mae: 0.009394, mean_q: 0.013120
 36574/100000: episode: 5044, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000544, mae: 0.014098, mean_q: 0.010365
 36578/100000: episode: 5045, duration: 0.023s, episode steps: 4, steps per second: 178, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003010, mae: 0.016209, mean_q: 0.008007
 36580/100000: episode: 5046, duration: 0.016s, episode steps: 2, steps per second: 126, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000262, mae: 0.018706, mean_q: 0.024846
 36586/100000: episode: 5047, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000346, mae: 0.015476, mean_q: 0.009450
 36588/100000: episode: 5048, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000540, mae: 0.017842, mean_q: 0.005816
 36590/100000: episode: 5049, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000502, mae: 0.009717, mean_q: 0.006960
 36592/100000: episode: 5050, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001196, mae: 0.018803, mean_q: 0.024271
 36598/100000: episode: 5051, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000760, mae: 0.015110, mean_q: 0.013210
 36602/100000: episode: 5052, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000178, mae: 0.007572, mean_q: 0.005964
 36608/100000: episode: 5053, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000431, mae: 0.011769, mean_q: 0.009980
 36610/100000: episode: 5054, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001545, mae: 0.020672, mean_q: 0.024807
 36614/100000: episode: 5055, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003110, mae: 0.019147, mean_q: 0.016977
 36618/100000: episode: 5056, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000089, mae: 0.009290, mean_q: 0.004545
 36624/100000: episode: 5057, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000469, mae: 0.012797, mean_q: 0.012722
 36628/100000: episode: 5058, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000160, mae: 0.009094, mean_q: 0.002247
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.04472966492176056
 36630/100000: episode: 5059, duration: 0.504s, episode steps: 2, steps per second: 4, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000118, mae: 0.011802, mean_q: 0.016441
 36640/100000: episode: 5060, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000238, mae: 0.008131, mean_q: 0.008520
 36650/100000: episode: 5061, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000214, mae: 0.009930, mean_q: 0.010343
 36660/100000: episode: 5062, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000285, mae: 0.009344, mean_q: 0.009818
 36670/100000: episode: 5063, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000597, mae: 0.013386, mean_q: 0.013186
 36680/100000: episode: 5064, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000199, mae: 0.009836, mean_q: 0.010538
 36690/100000: episode: 5065, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000289, mae: 0.010804, mean_q: 0.010009
 36700/100000: episode: 5066, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000441, mae: 0.010493, mean_q: 0.012652
 36710/100000: episode: 5067, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001552, mae: 0.023566, mean_q: 0.010482
 36720/100000: episode: 5068, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000369, mae: 0.015719, mean_q: 0.014542
 36730/100000: episode: 5069, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000545, mae: 0.015805, mean_q: 0.011918
 36740/100000: episode: 5070, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000348, mae: 0.009758, mean_q: 0.013134
 36750/100000: episode: 5071, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000126, mae: 0.007657, mean_q: 0.009062
 36760/100000: episode: 5072, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001339, mae: 0.014153, mean_q: 0.015995
 36770/100000: episode: 5073, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000509, mae: 0.015885, mean_q: 0.013583
 36780/100000: episode: 5074, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000419, mae: 0.012830, mean_q: 0.015074
 36790/100000: episode: 5075, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000521, mae: 0.016230, mean_q: 0.019741
 36800/100000: episode: 5076, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000429, mae: 0.011104, mean_q: 0.013637
 36810/100000: episode: 5077, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000578, mae: 0.012499, mean_q: 0.014757
 36820/100000: episode: 5078, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000848, mae: 0.016919, mean_q: 0.013205
 36830/100000: episode: 5079, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000364, mae: 0.013508, mean_q: 0.010449
 36840/100000: episode: 5080, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000521, mae: 0.015882, mean_q: 0.011334
 36850/100000: episode: 5081, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000232, mae: 0.012401, mean_q: 0.009400
 36860/100000: episode: 5082, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000556, mae: 0.013310, mean_q: 0.012612
 36870/100000: episode: 5083, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000440, mae: 0.013212, mean_q: 0.014537
 36880/100000: episode: 5084, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000348, mae: 0.014965, mean_q: 0.011369
 36890/100000: episode: 5085, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001462, mae: 0.016326, mean_q: 0.016163
 36900/100000: episode: 5086, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000430, mae: 0.015534, mean_q: 0.008337
 36910/100000: episode: 5087, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000276, mae: 0.012415, mean_q: 0.006804
 36920/100000: episode: 5088, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000297, mae: 0.009467, mean_q: 0.010619
 36930/100000: episode: 5089, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000241, mae: 0.009736, mean_q: 0.010176
 36940/100000: episode: 5090, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001031, mae: 0.011097, mean_q: 0.008022
 36950/100000: episode: 5091, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001200, mae: 0.019589, mean_q: 0.015472
 36960/100000: episode: 5092, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000632, mae: 0.019774, mean_q: 0.009770
 36970/100000: episode: 5093, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000506, mae: 0.015724, mean_q: 0.011523
 36980/100000: episode: 5094, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000347, mae: 0.011544, mean_q: 0.010971
 36990/100000: episode: 5095, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000201, mae: 0.008377, mean_q: 0.007976
[Info] FALSIFICATION!
 37000/100000: episode: 5096, duration: 0.310s, episode steps: 10, steps per second: 32, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.000331, mae: 0.007937, mean_q: 0.009338
 37010/100000: episode: 5097, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000312, mae: 0.011152, mean_q: 0.010582
 37020/100000: episode: 5098, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000281, mae: 0.008625, mean_q: 0.009797
 37030/100000: episode: 5099, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000412, mae: 0.010585, mean_q: 0.011907
 37040/100000: episode: 5100, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000306, mae: 0.008644, mean_q: 0.013518
 37050/100000: episode: 5101, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000114, mae: 0.006863, mean_q: 0.008669
 37060/100000: episode: 5102, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001256, mae: 0.016115, mean_q: 0.012322
 37070/100000: episode: 5103, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000548, mae: 0.010478, mean_q: 0.016160
 37080/100000: episode: 5104, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000498, mae: 0.013422, mean_q: 0.018003
 37090/100000: episode: 5105, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000592, mae: 0.016114, mean_q: 0.012513
 37100/100000: episode: 5106, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001210, mae: 0.021392, mean_q: 0.015168
 37110/100000: episode: 5107, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000869, mae: 0.019701, mean_q: 0.013054
 37120/100000: episode: 5108, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001122, mae: 0.013932, mean_q: 0.014816
 37130/100000: episode: 5109, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000608, mae: 0.014746, mean_q: 0.009118
 37140/100000: episode: 5110, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000737, mae: 0.018040, mean_q: 0.019914
 37150/100000: episode: 5111, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000341, mae: 0.016101, mean_q: 0.005710
 37160/100000: episode: 5112, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000426, mae: 0.014858, mean_q: 0.014507
 37170/100000: episode: 5113, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000479, mae: 0.014137, mean_q: 0.013413
 37180/100000: episode: 5114, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000319, mae: 0.013125, mean_q: 0.016138
 37190/100000: episode: 5115, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000556, mae: 0.013381, mean_q: 0.014111
 37200/100000: episode: 5116, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000372, mae: 0.009727, mean_q: 0.012130
 37210/100000: episode: 5117, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000290, mae: 0.012779, mean_q: 0.013652
 37220/100000: episode: 5118, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000520, mae: 0.012543, mean_q: 0.016312
 37230/100000: episode: 5119, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.001517, mae: 0.019786, mean_q: 0.019220
 37240/100000: episode: 5120, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000398, mae: 0.011827, mean_q: 0.010992
 37250/100000: episode: 5121, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000550, mae: 0.014202, mean_q: 0.012295
 37260/100000: episode: 5122, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000269, mae: 0.010999, mean_q: 0.011791
 37270/100000: episode: 5123, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000699, mae: 0.014298, mean_q: 0.015558
 37280/100000: episode: 5124, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000362, mae: 0.011235, mean_q: 0.014135
 37290/100000: episode: 5125, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000651, mae: 0.012441, mean_q: 0.014295
 37300/100000: episode: 5126, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000361, mae: 0.011476, mean_q: 0.008905
 37310/100000: episode: 5127, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000226, mae: 0.010998, mean_q: 0.012234
 37320/100000: episode: 5128, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000378, mae: 0.012901, mean_q: 0.016080
 37330/100000: episode: 5129, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000304, mae: 0.010442, mean_q: 0.010991
 37340/100000: episode: 5130, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000155, mae: 0.010503, mean_q: 0.008366
 37350/100000: episode: 5131, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000574, mae: 0.015681, mean_q: 0.010267
 37360/100000: episode: 5132, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000612, mae: 0.016547, mean_q: 0.012949
 37370/100000: episode: 5133, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000584, mae: 0.010299, mean_q: 0.012299
 37380/100000: episode: 5134, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000208, mae: 0.009564, mean_q: 0.011200
 37390/100000: episode: 5135, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000352, mae: 0.012027, mean_q: 0.010862
 37400/100000: episode: 5136, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000325, mae: 0.011003, mean_q: 0.012195
 37410/100000: episode: 5137, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000755, mae: 0.015145, mean_q: 0.020421
 37420/100000: episode: 5138, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000356, mae: 0.012078, mean_q: 0.015742
 37430/100000: episode: 5139, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000435, mae: 0.012513, mean_q: 0.014949
 37440/100000: episode: 5140, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000583, mae: 0.012319, mean_q: 0.011749
 37450/100000: episode: 5141, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000383, mae: 0.013464, mean_q: 0.013647
 37460/100000: episode: 5142, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000406, mae: 0.009458, mean_q: 0.012495
 37470/100000: episode: 5143, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000134, mae: 0.008444, mean_q: 0.008385
 37480/100000: episode: 5144, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000531, mae: 0.013957, mean_q: 0.012462
 37490/100000: episode: 5145, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000324, mae: 0.013755, mean_q: 0.009653
 37500/100000: episode: 5146, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000509, mae: 0.018336, mean_q: 0.010894
 37510/100000: episode: 5147, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000446, mae: 0.016427, mean_q: 0.013539
 37520/100000: episode: 5148, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000217, mae: 0.011164, mean_q: 0.008425
 37530/100000: episode: 5149, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000560, mae: 0.014106, mean_q: 0.013376
 37540/100000: episode: 5150, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000307, mae: 0.011496, mean_q: 0.012391
 37550/100000: episode: 5151, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000489, mae: 0.012135, mean_q: 0.015508
 37560/100000: episode: 5152, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000711, mae: 0.013155, mean_q: 0.011330
 37570/100000: episode: 5153, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000249, mae: 0.012471, mean_q: 0.011578
 37580/100000: episode: 5154, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000192, mae: 0.008701, mean_q: 0.012482
 37590/100000: episode: 5155, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000476, mae: 0.011057, mean_q: 0.011448
 37600/100000: episode: 5156, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000465, mae: 0.012720, mean_q: 0.012607
 37610/100000: episode: 5157, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000765, mae: 0.017361, mean_q: 0.015297
 37620/100000: episode: 5158, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001294, mae: 0.020290, mean_q: 0.014681
[Info] Complete ISplit Iteration
[Info] Levels: [0.9303965]
[Info] Cond. Prob: [0.01]
[Info] Error Prob: 0.01

 37630/100000: episode: 5159, duration: 0.738s, episode steps: 10, steps per second: 14, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000428, mae: 0.014935, mean_q: 0.011602
 37640/100000: episode: 5160, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000269, mae: 0.011891, mean_q: 0.009491
 37650/100000: episode: 5161, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000316, mae: 0.011316, mean_q: 0.012783
 37660/100000: episode: 5162, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000573, mae: 0.018406, mean_q: 0.009323
 37670/100000: episode: 5163, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000291, mae: 0.013375, mean_q: 0.010235
 37680/100000: episode: 5164, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000503, mae: 0.013584, mean_q: 0.012050
 37690/100000: episode: 5165, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000490, mae: 0.016361, mean_q: 0.011921
 37700/100000: episode: 5166, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000405, mae: 0.012129, mean_q: 0.013623
 37710/100000: episode: 5167, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000683, mae: 0.019068, mean_q: 0.015255
 37720/100000: episode: 5168, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000207, mae: 0.011907, mean_q: 0.008184
 37730/100000: episode: 5169, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000569, mae: 0.014675, mean_q: 0.016948
 37740/100000: episode: 5170, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000316, mae: 0.012641, mean_q: 0.010319
 37750/100000: episode: 5171, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001491, mae: 0.018866, mean_q: 0.012322
 37760/100000: episode: 5172, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000502, mae: 0.014216, mean_q: 0.014115
 37770/100000: episode: 5173, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000226, mae: 0.012162, mean_q: 0.009825
 37780/100000: episode: 5174, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001275, mae: 0.016269, mean_q: 0.020922
 37790/100000: episode: 5175, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000333, mae: 0.012451, mean_q: 0.008753
 37800/100000: episode: 5176, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000445, mae: 0.014377, mean_q: 0.015985
 37810/100000: episode: 5177, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000252, mae: 0.009509, mean_q: 0.011666
 37820/100000: episode: 5178, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000451, mae: 0.010527, mean_q: 0.014357
 37830/100000: episode: 5179, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000267, mae: 0.011293, mean_q: 0.009713
 37840/100000: episode: 5180, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000597, mae: 0.014971, mean_q: 0.020741
 37850/100000: episode: 5181, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000632, mae: 0.014568, mean_q: 0.011467
 37860/100000: episode: 5182, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000514, mae: 0.013273, mean_q: 0.010590
 37870/100000: episode: 5183, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000475, mae: 0.014863, mean_q: 0.015884
 37880/100000: episode: 5184, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000456, mae: 0.014242, mean_q: 0.012756
 37890/100000: episode: 5185, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001249, mae: 0.017475, mean_q: 0.014471
 37900/100000: episode: 5186, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000522, mae: 0.013335, mean_q: 0.016456
 37910/100000: episode: 5187, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000172, mae: 0.010443, mean_q: 0.006666
 37920/100000: episode: 5188, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000199, mae: 0.011164, mean_q: 0.008688
 37930/100000: episode: 5189, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000146, mae: 0.008951, mean_q: 0.010119
 37940/100000: episode: 5190, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000246, mae: 0.010174, mean_q: 0.012146
 37950/100000: episode: 5191, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000210, mae: 0.011821, mean_q: 0.009865
 37960/100000: episode: 5192, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000406, mae: 0.012065, mean_q: 0.008512
 37970/100000: episode: 5193, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000454, mae: 0.009053, mean_q: 0.007685
 37980/100000: episode: 5194, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000701, mae: 0.014818, mean_q: 0.014338
 37990/100000: episode: 5195, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000331, mae: 0.011513, mean_q: 0.010879
 38000/100000: episode: 5196, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000452, mae: 0.010847, mean_q: 0.012911
 38010/100000: episode: 5197, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000407, mae: 0.008983, mean_q: 0.010654
 38020/100000: episode: 5198, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000384, mae: 0.014662, mean_q: 0.011890
 38030/100000: episode: 5199, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000396, mae: 0.014511, mean_q: 0.014519
 38040/100000: episode: 5200, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000413, mae: 0.013132, mean_q: 0.011451
 38050/100000: episode: 5201, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000407, mae: 0.013445, mean_q: 0.014478
 38060/100000: episode: 5202, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000478, mae: 0.014163, mean_q: 0.017299
 38070/100000: episode: 5203, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000371, mae: 0.012499, mean_q: 0.019681
 38080/100000: episode: 5204, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000647, mae: 0.017692, mean_q: 0.014416
 38090/100000: episode: 5205, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001016, mae: 0.015854, mean_q: 0.013955
 38100/100000: episode: 5206, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000324, mae: 0.017323, mean_q: 0.009153
 38110/100000: episode: 5207, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000502, mae: 0.016271, mean_q: 0.015395
 38120/100000: episode: 5208, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000410, mae: 0.009519, mean_q: 0.010220
 38130/100000: episode: 5209, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000500, mae: 0.013026, mean_q: 0.011599
 38140/100000: episode: 5210, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000323, mae: 0.014051, mean_q: 0.010770
 38150/100000: episode: 5211, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000241, mae: 0.010477, mean_q: 0.011191
 38160/100000: episode: 5212, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000366, mae: 0.012221, mean_q: 0.008048
 38170/100000: episode: 5213, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000486, mae: 0.014961, mean_q: 0.014152
 38180/100000: episode: 5214, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000306, mae: 0.013889, mean_q: 0.009598
 38190/100000: episode: 5215, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000446, mae: 0.016230, mean_q: 0.008365
 38200/100000: episode: 5216, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000534, mae: 0.015206, mean_q: 0.015120
 38210/100000: episode: 5217, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000426, mae: 0.012323, mean_q: 0.014597
 38220/100000: episode: 5218, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000392, mae: 0.014352, mean_q: 0.011804
 38230/100000: episode: 5219, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000221, mae: 0.009132, mean_q: 0.008176
 38240/100000: episode: 5220, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000602, mae: 0.016390, mean_q: 0.010089
 38250/100000: episode: 5221, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000534, mae: 0.015488, mean_q: 0.013916
 38260/100000: episode: 5222, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000556, mae: 0.014316, mean_q: 0.015607
 38270/100000: episode: 5223, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000280, mae: 0.011058, mean_q: 0.009097
 38280/100000: episode: 5224, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000360, mae: 0.012417, mean_q: 0.010088
 38290/100000: episode: 5225, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000275, mae: 0.010429, mean_q: 0.011316
 38300/100000: episode: 5226, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001354, mae: 0.015719, mean_q: 0.013141
 38310/100000: episode: 5227, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000133, mae: 0.008659, mean_q: 0.006595
 38320/100000: episode: 5228, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000374, mae: 0.009888, mean_q: 0.014462
 38330/100000: episode: 5229, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000158, mae: 0.008032, mean_q: 0.010360
 38340/100000: episode: 5230, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000209, mae: 0.009624, mean_q: 0.011035
 38350/100000: episode: 5231, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000592, mae: 0.014866, mean_q: 0.013908
 38360/100000: episode: 5232, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000379, mae: 0.012774, mean_q: 0.008478
 38370/100000: episode: 5233, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000125, mae: 0.008163, mean_q: 0.007992
 38380/100000: episode: 5234, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000442, mae: 0.011491, mean_q: 0.012138
 38390/100000: episode: 5235, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000309, mae: 0.012789, mean_q: 0.008069
 38400/100000: episode: 5236, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000489, mae: 0.012926, mean_q: 0.016161
 38410/100000: episode: 5237, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000392, mae: 0.012875, mean_q: 0.012166
 38420/100000: episode: 5238, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000476, mae: 0.013780, mean_q: 0.018672
 38430/100000: episode: 5239, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000459, mae: 0.012590, mean_q: 0.013096
 38440/100000: episode: 5240, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000211, mae: 0.010508, mean_q: 0.011089
 38450/100000: episode: 5241, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001132, mae: 0.020345, mean_q: 0.015504
 38460/100000: episode: 5242, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000444, mae: 0.012875, mean_q: 0.011319
 38470/100000: episode: 5243, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000583, mae: 0.017298, mean_q: 0.011044
 38480/100000: episode: 5244, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001454, mae: 0.016461, mean_q: 0.016140
 38490/100000: episode: 5245, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000297, mae: 0.014244, mean_q: 0.009278
 38500/100000: episode: 5246, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000492, mae: 0.015792, mean_q: 0.012219
 38510/100000: episode: 5247, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000256, mae: 0.011838, mean_q: 0.012413
 38520/100000: episode: 5248, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000349, mae: 0.011806, mean_q: 0.015934
 38530/100000: episode: 5249, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000446, mae: 0.016190, mean_q: 0.009715
 38540/100000: episode: 5250, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000367, mae: 0.012621, mean_q: 0.015526
 38550/100000: episode: 5251, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000379, mae: 0.011795, mean_q: 0.010208
 38560/100000: episode: 5252, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000314, mae: 0.009195, mean_q: 0.011453
 38570/100000: episode: 5253, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000161, mae: 0.008798, mean_q: 0.009913
 38580/100000: episode: 5254, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000443, mae: 0.015629, mean_q: 0.012253
 38590/100000: episode: 5255, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000483, mae: 0.015690, mean_q: 0.015029
 38600/100000: episode: 5256, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000276, mae: 0.013256, mean_q: 0.008311
 38610/100000: episode: 5257, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001109, mae: 0.015569, mean_q: 0.017204
 38620/100000: episode: 5258, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000927, mae: 0.015636, mean_q: 0.012278
[Info] 1-TH LEVEL FOUND: -0.0006451159715652466, Considering 100/100 traces
 38630/100000: episode: 5259, duration: 0.832s, episode steps: 10, steps per second: 12, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000568, mae: 0.014703, mean_q: 0.007884
[Info] 2-TH LEVEL FOUND: 0.017938345670700073, Considering 14/100 traces
 38640/100000: episode: 5260, duration: 0.657s, episode steps: 10, steps per second: 15, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000248, mae: 0.011781, mean_q: 0.005899
 38642/100000: episode: 5261, duration: 0.014s, episode steps: 2, steps per second: 142, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000085, mae: 0.009012, mean_q: 0.010856
 38647/100000: episode: 5262, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000196, mae: 0.010419, mean_q: 0.012139
 38649/100000: episode: 5263, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000094, mae: 0.008832, mean_q: 0.002142
 38654/100000: episode: 5264, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000171, mae: 0.010729, mean_q: 0.012756
 38656/100000: episode: 5265, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000299, mae: 0.014314, mean_q: -0.000608
 38658/100000: episode: 5266, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001167, mae: 0.016753, mean_q: 0.027057
 38660/100000: episode: 5267, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000312, mae: 0.014649, mean_q: 0.020069
 38662/100000: episode: 5268, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000033, mae: 0.004534, mean_q: 0.000662
 38664/100000: episode: 5269, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000078, mae: 0.005840, mean_q: 0.004501
 38666/100000: episode: 5270, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000852, mae: 0.018569, mean_q: 0.023197
 38668/100000: episode: 5271, duration: 0.015s, episode steps: 2, steps per second: 132, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000396, mae: 0.011602, mean_q: 0.008885
 38670/100000: episode: 5272, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000344, mae: 0.012355, mean_q: 0.017008
 38672/100000: episode: 5273, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000302, mae: 0.010955, mean_q: 0.007518
 38674/100000: episode: 5274, duration: 0.016s, episode steps: 2, steps per second: 128, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000231, mae: 0.010897, mean_q: 0.016487
 38676/100000: episode: 5275, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000671, mae: 0.012246, mean_q: 0.018471
 38678/100000: episode: 5276, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000063, mae: 0.006074, mean_q: 0.005705
 38680/100000: episode: 5277, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000115, mae: 0.005951, mean_q: 0.010885
 38682/100000: episode: 5278, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000253, mae: 0.008975, mean_q: 0.007579
 38684/100000: episode: 5279, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000156, mae: 0.006446, mean_q: 0.009295
 38686/100000: episode: 5280, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000111, mae: 0.007875, mean_q: 0.011645
 38688/100000: episode: 5281, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000447, mae: 0.010001, mean_q: 0.019577
 38690/100000: episode: 5282, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001448, mae: 0.013924, mean_q: 0.017497
 38692/100000: episode: 5283, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000552, mae: 0.011911, mean_q: 0.014151
 38697/100000: episode: 5284, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000152, mae: 0.009017, mean_q: 0.010568
 38699/100000: episode: 5285, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001220, mae: 0.015900, mean_q: 0.010324
 38701/100000: episode: 5286, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001108, mae: 0.018599, mean_q: 0.019492
 38703/100000: episode: 5287, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000336, mae: 0.016476, mean_q: 0.020388
 38708/100000: episode: 5288, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000682, mae: 0.012615, mean_q: 0.008543
 38710/100000: episode: 5289, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000130, mae: 0.010605, mean_q: 0.014298
 38712/100000: episode: 5290, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001060, mae: 0.014472, mean_q: 0.013501
 38714/100000: episode: 5291, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000869, mae: 0.019204, mean_q: 0.004035
 38716/100000: episode: 5292, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000256, mae: 0.015239, mean_q: 0.011128
 38718/100000: episode: 5293, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000224, mae: 0.016750, mean_q: 0.018841
 38720/100000: episode: 5294, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001076, mae: 0.014017, mean_q: 0.008176
 38722/100000: episode: 5295, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000195, mae: 0.009415, mean_q: 0.015278
 38724/100000: episode: 5296, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000445, mae: 0.016259, mean_q: 0.022862
 38726/100000: episode: 5297, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000218, mae: 0.011239, mean_q: -0.001991
 38728/100000: episode: 5298, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000461, mae: 0.012484, mean_q: 0.016849
 38730/100000: episode: 5299, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000293, mae: 0.010056, mean_q: 0.007055
 38732/100000: episode: 5300, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000563, mae: 0.015564, mean_q: 0.014447
 38734/100000: episode: 5301, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000123, mae: 0.008413, mean_q: 0.009135
 38736/100000: episode: 5302, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000080, mae: 0.006841, mean_q: 0.005067
 38738/100000: episode: 5303, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001232, mae: 0.019592, mean_q: 0.027083
 38740/100000: episode: 5304, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000242, mae: 0.014379, mean_q: 0.019211
 38742/100000: episode: 5305, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000512, mae: 0.020978, mean_q: -0.000805
 38744/100000: episode: 5306, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000227, mae: 0.013691, mean_q: 0.009793
 38746/100000: episode: 5307, duration: 0.014s, episode steps: 2, steps per second: 140, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000638, mae: 0.018153, mean_q: 0.026034
 38748/100000: episode: 5308, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000397, mae: 0.016682, mean_q: 0.001850
 38750/100000: episode: 5309, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000063, mae: 0.006957, mean_q: 0.007851
 38752/100000: episode: 5310, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000187, mae: 0.012927, mean_q: 0.016346
 38754/100000: episode: 5311, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000265, mae: 0.014269, mean_q: -0.002851
 38756/100000: episode: 5312, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000312, mae: 0.012254, mean_q: 0.007533
 38758/100000: episode: 5313, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000293, mae: 0.014014, mean_q: 0.018080
 38763/100000: episode: 5314, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000314, mae: 0.010748, mean_q: 0.004788
 38765/100000: episode: 5315, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000359, mae: 0.009285, mean_q: 0.008869
 38767/100000: episode: 5316, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000369, mae: 0.012498, mean_q: 0.007120
 38769/100000: episode: 5317, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000489, mae: 0.014427, mean_q: 0.011408
 38771/100000: episode: 5318, duration: 0.015s, episode steps: 2, steps per second: 134, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001230, mae: 0.016884, mean_q: 0.029293
 38773/100000: episode: 5319, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000676, mae: 0.018922, mean_q: 0.008179
 38775/100000: episode: 5320, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000536, mae: 0.021544, mean_q: 0.025790
 38780/100000: episode: 5321, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000283, mae: 0.013371, mean_q: 0.003922
 38782/100000: episode: 5322, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001185, mae: 0.021372, mean_q: 0.038336
 38784/100000: episode: 5323, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000222, mae: 0.012882, mean_q: 0.020822
 38786/100000: episode: 5324, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000197, mae: 0.015111, mean_q: 0.004498
 38788/100000: episode: 5325, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000459, mae: 0.014974, mean_q: 0.017298
 38793/100000: episode: 5326, duration: 0.025s, episode steps: 5, steps per second: 204, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000498, mae: 0.017319, mean_q: 0.012791
 38795/100000: episode: 5327, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000273, mae: 0.013123, mean_q: 0.018635
 38797/100000: episode: 5328, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000191, mae: 0.011977, mean_q: -0.001193
 38799/100000: episode: 5329, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000109, mae: 0.007062, mean_q: 0.011407
 38801/100000: episode: 5330, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000145, mae: 0.010978, mean_q: 0.016119
 38803/100000: episode: 5331, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000138, mae: 0.007828, mean_q: 0.006100
 38805/100000: episode: 5332, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000297, mae: 0.011375, mean_q: 0.007195
 38807/100000: episode: 5333, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000779, mae: 0.016837, mean_q: 0.020323
 38809/100000: episode: 5334, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000074, mae: 0.007657, mean_q: 0.001904
 38811/100000: episode: 5335, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000420, mae: 0.012517, mean_q: 0.006420
 38813/100000: episode: 5336, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000691, mae: 0.027611, mean_q: 0.033059
 38815/100000: episode: 5337, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000085, mae: 0.009285, mean_q: 0.004353
 38817/100000: episode: 5338, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000894, mae: 0.030333, mean_q: -0.006922
 38819/100000: episode: 5339, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000691, mae: 0.026590, mean_q: 0.038451
 38821/100000: episode: 5340, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000268, mae: 0.014783, mean_q: 0.021127
 38823/100000: episode: 5341, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000438, mae: 0.025413, mean_q: -0.015501
 38825/100000: episode: 5342, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000595, mae: 0.020549, mean_q: 0.025799
 38827/100000: episode: 5343, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000169, mae: 0.014618, mean_q: 0.017809
 38829/100000: episode: 5344, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000729, mae: 0.029866, mean_q: -0.003420
 38831/100000: episode: 5345, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000625, mae: 0.014095, mean_q: 0.013057
[Info] 3-TH LEVEL FOUND: 0.06720209121704102, Considering 20/100 traces
 38833/100000: episode: 5346, duration: 0.664s, episode steps: 2, steps per second: 3, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000314, mae: 0.016612, mean_q: 0.018481
 38835/100000: episode: 5347, duration: 0.016s, episode steps: 2, steps per second: 124, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000489, mae: 0.010680, mean_q: 0.011408
 38840/100000: episode: 5348, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000955, mae: 0.017946, mean_q: 0.013583
 38845/100000: episode: 5349, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000328, mae: 0.011682, mean_q: 0.002809
 38847/100000: episode: 5350, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000384, mae: 0.015860, mean_q: 0.017539
 38849/100000: episode: 5351, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000271, mae: 0.012499, mean_q: 0.016724
 38851/100000: episode: 5352, duration: 0.014s, episode steps: 2, steps per second: 142, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000390, mae: 0.016135, mean_q: 0.005090
 38856/100000: episode: 5353, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000331, mae: 0.010540, mean_q: 0.014747
 38858/100000: episode: 5354, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000270, mae: 0.013938, mean_q: 0.000431
 38860/100000: episode: 5355, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000254, mae: 0.012052, mean_q: 0.011961
 38862/100000: episode: 5356, duration: 0.016s, episode steps: 2, steps per second: 128, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000895, mae: 0.018923, mean_q: 0.027898
 38864/100000: episode: 5357, duration: 0.014s, episode steps: 2, steps per second: 143, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000129, mae: 0.007929, mean_q: 0.014011
 38866/100000: episode: 5358, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000474, mae: 0.016369, mean_q: 0.010567
 38868/100000: episode: 5359, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000378, mae: 0.015250, mean_q: 0.008658
 38870/100000: episode: 5360, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000152, mae: 0.006865, mean_q: 0.011352
 38872/100000: episode: 5361, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000317, mae: 0.010424, mean_q: 0.009330
 38874/100000: episode: 5362, duration: 0.016s, episode steps: 2, steps per second: 126, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000136, mae: 0.009614, mean_q: 0.007513
 38876/100000: episode: 5363, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001326, mae: 0.025202, mean_q: 0.039729
 38881/100000: episode: 5364, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000301, mae: 0.015528, mean_q: 0.004822
 38883/100000: episode: 5365, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000436, mae: 0.014245, mean_q: 0.011829
 38888/100000: episode: 5366, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001507, mae: 0.022282, mean_q: 0.021886
 38890/100000: episode: 5367, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001311, mae: 0.018693, mean_q: 0.012995
 38895/100000: episode: 5368, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000423, mae: 0.014342, mean_q: 0.018845
 38897/100000: episode: 5369, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000372, mae: 0.016157, mean_q: 0.001996
 38902/100000: episode: 5370, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000729, mae: 0.013634, mean_q: 0.021245
 38904/100000: episode: 5371, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000941, mae: 0.017003, mean_q: 0.022234
 38906/100000: episode: 5372, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000300, mae: 0.014544, mean_q: 0.017994
 38908/100000: episode: 5373, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000245, mae: 0.010016, mean_q: -0.000274
 38910/100000: episode: 5374, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000464, mae: 0.016078, mean_q: 0.003022
 38915/100000: episode: 5375, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000606, mae: 0.017400, mean_q: 0.025627
 38917/100000: episode: 5376, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000637, mae: 0.017800, mean_q: 0.012016
 38922/100000: episode: 5377, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000781, mae: 0.015815, mean_q: 0.021285
 38924/100000: episode: 5378, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004950, mae: 0.023642, mean_q: 0.015009
 38926/100000: episode: 5379, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000462, mae: 0.018579, mean_q: 0.029456
 38928/100000: episode: 5380, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000655, mae: 0.027540, mean_q: -0.003339
 38930/100000: episode: 5381, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000236, mae: 0.010666, mean_q: 0.009859
 38932/100000: episode: 5382, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000265, mae: 0.016309, mean_q: 0.020527
 38937/100000: episode: 5383, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001191, mae: 0.022223, mean_q: 0.009613
 38939/100000: episode: 5384, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000110, mae: 0.011012, mean_q: 0.013440
 38944/100000: episode: 5385, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000306, mae: 0.012470, mean_q: 0.007232
 38946/100000: episode: 5386, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000268, mae: 0.010051, mean_q: 0.016923
 38948/100000: episode: 5387, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000330, mae: 0.012658, mean_q: 0.014652
 38950/100000: episode: 5388, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000164, mae: 0.007734, mean_q: 0.008503
 38955/100000: episode: 5389, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000226, mae: 0.008956, mean_q: 0.007932
 38957/100000: episode: 5390, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005203, mae: 0.031911, mean_q: 0.037801
 38959/100000: episode: 5391, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000433, mae: 0.017770, mean_q: 0.024732
 38961/100000: episode: 5392, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000917, mae: 0.027228, mean_q: -0.009746
 38966/100000: episode: 5393, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000549, mae: 0.017685, mean_q: 0.021603
 38968/100000: episode: 5394, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004499, mae: 0.022856, mean_q: 0.009171
 38973/100000: episode: 5395, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000321, mae: 0.016870, mean_q: 0.017466
 38975/100000: episode: 5396, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000245, mae: 0.015646, mean_q: 0.003275
 38980/100000: episode: 5397, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000441, mae: 0.017562, mean_q: 0.021342
 38982/100000: episode: 5398, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000329, mae: 0.017218, mean_q: -0.003230
 38987/100000: episode: 5399, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000658, mae: 0.014981, mean_q: 0.019983
 38992/100000: episode: 5400, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000265, mae: 0.011819, mean_q: 0.009165
 38994/100000: episode: 5401, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000445, mae: 0.011030, mean_q: 0.017641
 38996/100000: episode: 5402, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000157, mae: 0.005936, mean_q: 0.005033
 38998/100000: episode: 5403, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000121, mae: 0.006522, mean_q: 0.005059
 39000/100000: episode: 5404, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000345, mae: 0.011046, mean_q: 0.010408
 39002/100000: episode: 5405, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000239, mae: 0.011044, mean_q: 0.012122
 39007/100000: episode: 5406, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000745, mae: 0.019730, mean_q: 0.016732
 39012/100000: episode: 5407, duration: 0.029s, episode steps: 5, steps per second: 171, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000595, mae: 0.018286, mean_q: 0.012494
 39014/100000: episode: 5408, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000439, mae: 0.017205, mean_q: 0.019800
 39016/100000: episode: 5409, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000309, mae: 0.014775, mean_q: 0.023918
 39018/100000: episode: 5410, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000694, mae: 0.017416, mean_q: 0.017470
 39020/100000: episode: 5411, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000754, mae: 0.014187, mean_q: 0.025618
 39022/100000: episode: 5412, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000314, mae: 0.011752, mean_q: 0.001410
 39027/100000: episode: 5413, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000874, mae: 0.018889, mean_q: 0.025766
 39029/100000: episode: 5414, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001336, mae: 0.017575, mean_q: 0.028691
 39031/100000: episode: 5415, duration: 0.019s, episode steps: 2, steps per second: 108, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000670, mae: 0.018973, mean_q: 0.034161
 39033/100000: episode: 5416, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000096, mae: 0.007707, mean_q: 0.004163
[Info] FALSIFICATION!
 39037/100000: episode: 5417, duration: 0.281s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000391, mae: 0.014730, mean_q: 0.008973
 39042/100000: episode: 5418, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000533, mae: 0.015967, mean_q: 0.008044
 39044/100000: episode: 5419, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000079, mae: 0.007697, mean_q: 0.007254
 39046/100000: episode: 5420, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002528, mae: 0.034783, mean_q: 0.049305
 39048/100000: episode: 5421, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000288, mae: 0.013227, mean_q: 0.011193
 39053/100000: episode: 5422, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001002, mae: 0.024827, mean_q: 0.015559
 39058/100000: episode: 5423, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001133, mae: 0.024628, mean_q: 0.007314
 39060/100000: episode: 5424, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000412, mae: 0.016531, mean_q: 0.019784
 39062/100000: episode: 5425, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000507, mae: 0.016059, mean_q: 0.010685
[Info] Complete ISplit Iteration
[Info] Levels: [-0.000645116, 0.017938346, 0.06720209, 0.8199474]
[Info] Cond. Prob: [1.0, 0.14, 0.2, 0.01]
[Info] Error Prob: 0.00028000000000000003

 39064/100000: episode: 5426, duration: 0.815s, episode steps: 2, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001642, mae: 0.022113, mean_q: 0.028897
 39074/100000: episode: 5427, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000357, mae: 0.011689, mean_q: 0.012899
 39084/100000: episode: 5428, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000407, mae: 0.011446, mean_q: 0.011615
 39094/100000: episode: 5429, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001715, mae: 0.017643, mean_q: 0.020035
 39104/100000: episode: 5430, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000752, mae: 0.017234, mean_q: 0.012956
 39114/100000: episode: 5431, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000852, mae: 0.020200, mean_q: 0.012913
 39124/100000: episode: 5432, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000552, mae: 0.017718, mean_q: 0.015966
 39134/100000: episode: 5433, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002126, mae: 0.025005, mean_q: 0.018235
 39144/100000: episode: 5434, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000487, mae: 0.013090, mean_q: 0.012806
 39154/100000: episode: 5435, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000773, mae: 0.019166, mean_q: 0.018742
 39164/100000: episode: 5436, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000716, mae: 0.019145, mean_q: 0.015905
 39174/100000: episode: 5437, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000897, mae: 0.022225, mean_q: 0.014575
 39184/100000: episode: 5438, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001778, mae: 0.023745, mean_q: 0.019577
 39194/100000: episode: 5439, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000687, mae: 0.021298, mean_q: 0.010188
 39204/100000: episode: 5440, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000535, mae: 0.014835, mean_q: 0.010457
 39214/100000: episode: 5441, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001884, mae: 0.018900, mean_q: 0.014178
 39224/100000: episode: 5442, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000486, mae: 0.016091, mean_q: 0.013192
 39234/100000: episode: 5443, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001747, mae: 0.021259, mean_q: 0.022138
 39244/100000: episode: 5444, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000707, mae: 0.018958, mean_q: 0.016453
 39254/100000: episode: 5445, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000963, mae: 0.021354, mean_q: 0.016359
 39264/100000: episode: 5446, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000852, mae: 0.023407, mean_q: 0.017943
 39274/100000: episode: 5447, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001360, mae: 0.022906, mean_q: 0.017502
 39284/100000: episode: 5448, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001564, mae: 0.021375, mean_q: 0.013533
 39294/100000: episode: 5449, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000376, mae: 0.018186, mean_q: 0.009917
 39304/100000: episode: 5450, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001768, mae: 0.020460, mean_q: 0.021008
 39314/100000: episode: 5451, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000551, mae: 0.013611, mean_q: 0.013566
 39324/100000: episode: 5452, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000484, mae: 0.012218, mean_q: 0.014349
 39334/100000: episode: 5453, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000280, mae: 0.010641, mean_q: 0.010730
 39344/100000: episode: 5454, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000653, mae: 0.015266, mean_q: 0.015201
 39354/100000: episode: 5455, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001423, mae: 0.023458, mean_q: 0.013841
 39364/100000: episode: 5456, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000582, mae: 0.020261, mean_q: 0.015745
 39374/100000: episode: 5457, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000184, mae: 0.008037, mean_q: 0.007326
 39384/100000: episode: 5458, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000686, mae: 0.017532, mean_q: 0.012286
 39394/100000: episode: 5459, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000855, mae: 0.018412, mean_q: 0.015445
 39404/100000: episode: 5460, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000376, mae: 0.016534, mean_q: 0.010919
 39414/100000: episode: 5461, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000525, mae: 0.013037, mean_q: 0.013366
 39424/100000: episode: 5462, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000323, mae: 0.011746, mean_q: 0.012559
 39434/100000: episode: 5463, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000689, mae: 0.014337, mean_q: 0.019999
 39444/100000: episode: 5464, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000731, mae: 0.021909, mean_q: 0.015140
 39454/100000: episode: 5465, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000661, mae: 0.014362, mean_q: 0.013563
 39464/100000: episode: 5466, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000311, mae: 0.011788, mean_q: 0.009199
 39474/100000: episode: 5467, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001613, mae: 0.018428, mean_q: 0.012779
 39484/100000: episode: 5468, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000659, mae: 0.014247, mean_q: 0.012415
 39494/100000: episode: 5469, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000479, mae: 0.016583, mean_q: 0.018378
 39504/100000: episode: 5470, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000504, mae: 0.014468, mean_q: 0.011610
 39514/100000: episode: 5471, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001423, mae: 0.017351, mean_q: 0.019910
 39524/100000: episode: 5472, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000850, mae: 0.018890, mean_q: 0.010349
 39534/100000: episode: 5473, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001689, mae: 0.021246, mean_q: 0.018389
 39544/100000: episode: 5474, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000270, mae: 0.013106, mean_q: 0.009385
 39554/100000: episode: 5475, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002295, mae: 0.024740, mean_q: 0.023951
 39564/100000: episode: 5476, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000564, mae: 0.015985, mean_q: 0.014662
 39574/100000: episode: 5477, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000524, mae: 0.017628, mean_q: 0.016838
 39584/100000: episode: 5478, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000535, mae: 0.014020, mean_q: 0.012012
 39594/100000: episode: 5479, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000394, mae: 0.016386, mean_q: 0.014123
 39604/100000: episode: 5480, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000322, mae: 0.013224, mean_q: 0.013568
 39614/100000: episode: 5481, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000407, mae: 0.011822, mean_q: 0.013925
 39624/100000: episode: 5482, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000349, mae: 0.009212, mean_q: 0.010439
 39634/100000: episode: 5483, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000433, mae: 0.010862, mean_q: 0.013469
 39644/100000: episode: 5484, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000498, mae: 0.016995, mean_q: 0.015312
 39654/100000: episode: 5485, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000450, mae: 0.011718, mean_q: 0.010208
 39664/100000: episode: 5486, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001408, mae: 0.011493, mean_q: 0.011952
 39674/100000: episode: 5487, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000369, mae: 0.014480, mean_q: 0.007408
 39684/100000: episode: 5488, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000196, mae: 0.010081, mean_q: 0.007924
 39694/100000: episode: 5489, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000475, mae: 0.016178, mean_q: 0.009265
 39704/100000: episode: 5490, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001343, mae: 0.020567, mean_q: 0.014699
 39714/100000: episode: 5491, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000835, mae: 0.022316, mean_q: 0.013486
 39724/100000: episode: 5492, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000266, mae: 0.014455, mean_q: 0.007284
 39734/100000: episode: 5493, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000658, mae: 0.015179, mean_q: 0.010456
 39744/100000: episode: 5494, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000256, mae: 0.010259, mean_q: 0.008863
 39754/100000: episode: 5495, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000512, mae: 0.012647, mean_q: 0.009602
 39764/100000: episode: 5496, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000594, mae: 0.013403, mean_q: 0.014530
 39774/100000: episode: 5497, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000476, mae: 0.010985, mean_q: 0.010698
 39784/100000: episode: 5498, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000308, mae: 0.010167, mean_q: 0.013077
 39794/100000: episode: 5499, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001481, mae: 0.022651, mean_q: 0.012594
 39804/100000: episode: 5500, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000488, mae: 0.021404, mean_q: 0.010845
 39814/100000: episode: 5501, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001540, mae: 0.016383, mean_q: 0.018101
 39824/100000: episode: 5502, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000691, mae: 0.011958, mean_q: 0.013116
 39834/100000: episode: 5503, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002901, mae: 0.020116, mean_q: 0.021322
 39844/100000: episode: 5504, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000712, mae: 0.019049, mean_q: 0.014516
 39854/100000: episode: 5505, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000439, mae: 0.012849, mean_q: 0.008772
 39864/100000: episode: 5506, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000375, mae: 0.010860, mean_q: 0.014074
 39874/100000: episode: 5507, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000419, mae: 0.010036, mean_q: 0.013210
 39884/100000: episode: 5508, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000570, mae: 0.015043, mean_q: 0.015864
 39894/100000: episode: 5509, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000412, mae: 0.014466, mean_q: 0.008639
 39904/100000: episode: 5510, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000299, mae: 0.013411, mean_q: 0.008225
 39914/100000: episode: 5511, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000503, mae: 0.017234, mean_q: 0.011619
 39924/100000: episode: 5512, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000799, mae: 0.018688, mean_q: 0.014234
 39934/100000: episode: 5513, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000592, mae: 0.014056, mean_q: 0.018381
 39944/100000: episode: 5514, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000268, mae: 0.009649, mean_q: 0.008254
 39954/100000: episode: 5515, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000253, mae: 0.010291, mean_q: 0.013400
 39964/100000: episode: 5516, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001158, mae: 0.012608, mean_q: 0.011909
 39974/100000: episode: 5517, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000520, mae: 0.015292, mean_q: 0.015906
 39984/100000: episode: 5518, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000498, mae: 0.012445, mean_q: 0.010682
 39994/100000: episode: 5519, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000582, mae: 0.014086, mean_q: 0.014634
 40004/100000: episode: 5520, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000340, mae: 0.011774, mean_q: 0.010470
 40014/100000: episode: 5521, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000350, mae: 0.011494, mean_q: 0.013233
 40024/100000: episode: 5522, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000583, mae: 0.015156, mean_q: 0.015186
 40034/100000: episode: 5523, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001390, mae: 0.016448, mean_q: 0.015667
 40044/100000: episode: 5524, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000632, mae: 0.019195, mean_q: 0.011179
 40054/100000: episode: 5525, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000426, mae: 0.011325, mean_q: 0.010155
[Info] 1-TH LEVEL FOUND: 0.023548349738121033, Considering 15/100 traces
 40064/100000: episode: 5526, duration: 0.671s, episode steps: 10, steps per second: 15, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000310, mae: 0.010191, mean_q: 0.010039
 40071/100000: episode: 5527, duration: 0.038s, episode steps: 7, steps per second: 183, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000231, mae: 0.009739, mean_q: 0.006125
 40078/100000: episode: 5528, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000416, mae: 0.010867, mean_q: 0.010704
 40085/100000: episode: 5529, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000700, mae: 0.013963, mean_q: 0.019814
 40087/100000: episode: 5530, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000217, mae: 0.014905, mean_q: -0.003837
 40089/100000: episode: 5531, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000034, mae: 0.005449, mean_q: 0.007401
 40091/100000: episode: 5532, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001073, mae: 0.016698, mean_q: 0.022911
 40093/100000: episode: 5533, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000308, mae: 0.009343, mean_q: 0.009966
 40100/100000: episode: 5534, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000738, mae: 0.015086, mean_q: 0.020597
 40102/100000: episode: 5535, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000754, mae: 0.013512, mean_q: 0.005108
 40105/100000: episode: 5536, duration: 0.020s, episode steps: 3, steps per second: 152, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000484, mae: 0.011990, mean_q: 0.010506
 40112/100000: episode: 5537, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000214, mae: 0.011489, mean_q: 0.005965
 40114/100000: episode: 5538, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000289, mae: 0.016250, mean_q: 0.017538
 40116/100000: episode: 5539, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000079, mae: 0.008942, mean_q: 0.011995
 40123/100000: episode: 5540, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000444, mae: 0.013235, mean_q: 0.011368
 40125/100000: episode: 5541, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000135, mae: 0.008047, mean_q: 0.010686
 40127/100000: episode: 5542, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000299, mae: 0.014156, mean_q: 0.000554
 40134/100000: episode: 5543, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000250, mae: 0.013696, mean_q: 0.012933
 40141/100000: episode: 5544, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000263, mae: 0.015078, mean_q: 0.017779
 40143/100000: episode: 5545, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000198, mae: 0.015600, mean_q: -0.004871
 40150/100000: episode: 5546, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000797, mae: 0.016233, mean_q: 0.022810
 40157/100000: episode: 5547, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001609, mae: 0.017005, mean_q: 0.014587
 40159/100000: episode: 5548, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001052, mae: 0.016806, mean_q: 0.014222
 40161/100000: episode: 5549, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000314, mae: 0.021267, mean_q: -0.008804
 40168/100000: episode: 5550, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000492, mae: 0.015625, mean_q: 0.016185
 40175/100000: episode: 5551, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000492, mae: 0.014137, mean_q: 0.020232
 40177/100000: episode: 5552, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000313, mae: 0.014692, mean_q: 0.003255
 40179/100000: episode: 5553, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000523, mae: 0.014186, mean_q: 0.009366
 40182/100000: episode: 5554, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000662, mae: 0.012046, mean_q: 0.017994
 40189/100000: episode: 5555, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000573, mae: 0.014771, mean_q: 0.014822
 40196/100000: episode: 5556, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000696, mae: 0.015089, mean_q: 0.017129
 40203/100000: episode: 5557, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000807, mae: 0.015890, mean_q: 0.013063
 40205/100000: episode: 5558, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001243, mae: 0.023811, mean_q: 0.033493
 40212/100000: episode: 5559, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000357, mae: 0.014437, mean_q: 0.005250
 40219/100000: episode: 5560, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000381, mae: 0.018180, mean_q: 0.010286
 40221/100000: episode: 5561, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000219, mae: 0.015242, mean_q: 0.019429
 40223/100000: episode: 5562, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001125, mae: 0.018642, mean_q: 0.025570
 40225/100000: episode: 5563, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000293, mae: 0.018491, mean_q: -0.011402
 40232/100000: episode: 5564, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001842, mae: 0.026106, mean_q: 0.021854
 40234/100000: episode: 5565, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000573, mae: 0.030269, mean_q: -0.019268
 40241/100000: episode: 5566, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000654, mae: 0.016455, mean_q: 0.017132
 40243/100000: episode: 5567, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001023, mae: 0.020558, mean_q: 0.025143
 40245/100000: episode: 5568, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000275, mae: 0.015407, mean_q: 0.015813
 40252/100000: episode: 5569, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000233, mae: 0.011699, mean_q: 0.007311
 40259/100000: episode: 5570, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000168, mae: 0.007552, mean_q: 0.006473
 40266/100000: episode: 5571, duration: 0.038s, episode steps: 7, steps per second: 183, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000206, mae: 0.008982, mean_q: 0.011337
 40273/100000: episode: 5572, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000468, mae: 0.012744, mean_q: 0.014100
 40275/100000: episode: 5573, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001292, mae: 0.020714, mean_q: 0.016323
 40277/100000: episode: 5574, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000286, mae: 0.015919, mean_q: -0.006334
 40279/100000: episode: 5575, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004891, mae: 0.021163, mean_q: 0.014717
 40281/100000: episode: 5576, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000884, mae: 0.037354, mean_q: 0.044053
 40288/100000: episode: 5577, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000530, mae: 0.023191, mean_q: -0.005407
 40295/100000: episode: 5578, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001134, mae: 0.025074, mean_q: 0.012899
 40297/100000: episode: 5579, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001274, mae: 0.027446, mean_q: 0.027220
 40304/100000: episode: 5580, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000205, mae: 0.010901, mean_q: 0.007170
 40306/100000: episode: 5581, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000444, mae: 0.016772, mean_q: 0.007152
 40309/100000: episode: 5582, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000409, mae: 0.018452, mean_q: 0.024237
 40316/100000: episode: 5583, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000286, mae: 0.012607, mean_q: 0.006018
 40323/100000: episode: 5584, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000517, mae: 0.015571, mean_q: 0.010443
 40325/100000: episode: 5585, duration: 0.015s, episode steps: 2, steps per second: 134, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000295, mae: 0.015413, mean_q: 0.017615
 40332/100000: episode: 5586, duration: 0.039s, episode steps: 7, steps per second: 179, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000218, mae: 0.010657, mean_q: 0.004071
 40335/100000: episode: 5587, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000635, mae: 0.017697, mean_q: 0.023049
 40337/100000: episode: 5588, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000713, mae: 0.020262, mean_q: 0.018532
 40340/100000: episode: 5589, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000591, mae: 0.013502, mean_q: 0.009647
 40342/100000: episode: 5590, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000199, mae: 0.007730, mean_q: 0.004827
 40349/100000: episode: 5591, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000144, mae: 0.009805, mean_q: 0.009226
 40351/100000: episode: 5592, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000468, mae: 0.014155, mean_q: 0.017408
 40353/100000: episode: 5593, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000416, mae: 0.011751, mean_q: 0.005928
 40355/100000: episode: 5594, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000113, mae: 0.010754, mean_q: -0.000272
 40362/100000: episode: 5595, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001797, mae: 0.016086, mean_q: 0.015101
 40369/100000: episode: 5596, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 1.947, mean reward: 0.278 [0.007, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 7.857 [5.000, 11.000], loss: 0.000781, mae: 0.017487, mean_q: 0.019342
 40376/100000: episode: 5597, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000378, mae: 0.015561, mean_q: 0.015092
 40383/100000: episode: 5598, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000613, mae: 0.014532, mean_q: 0.012865
 40390/100000: episode: 5599, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000561, mae: 0.012172, mean_q: 0.012404
 40392/100000: episode: 5600, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000172, mae: 0.007916, mean_q: 0.008481
 40395/100000: episode: 5601, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000815, mae: 0.015901, mean_q: 0.011143
 40397/100000: episode: 5602, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000410, mae: 0.013404, mean_q: 0.012993
 40404/100000: episode: 5603, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001860, mae: 0.019916, mean_q: 0.015746
 40411/100000: episode: 5604, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000293, mae: 0.013041, mean_q: 0.015199
 40413/100000: episode: 5605, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000129, mae: 0.011523, mean_q: 0.000236
 40415/100000: episode: 5606, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000533, mae: 0.014076, mean_q: 0.011251
 40422/100000: episode: 5607, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.002108, mae: 0.021860, mean_q: 0.019194
 40425/100000: episode: 5608, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000384, mae: 0.015143, mean_q: 0.017600
 40432/100000: episode: 5609, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000873, mae: 0.018389, mean_q: 0.013050
 40439/100000: episode: 5610, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.002011, mae: 0.019820, mean_q: 0.016784
[Info] 2-TH LEVEL FOUND: 0.06420035660266876, Considering 17/100 traces
 40441/100000: episode: 5611, duration: 0.699s, episode steps: 2, steps per second: 3, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000684, mae: 0.015522, mean_q: 0.028074
 40443/100000: episode: 5612, duration: 0.015s, episode steps: 2, steps per second: 134, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000261, mae: 0.011905, mean_q: 0.014535
 40445/100000: episode: 5613, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002060, mae: 0.025497, mean_q: 0.027168
 40447/100000: episode: 5614, duration: 0.017s, episode steps: 2, steps per second: 117, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000120, mae: 0.007932, mean_q: 0.008873
 40452/100000: episode: 5615, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000451, mae: 0.016213, mean_q: 0.017937
 40454/100000: episode: 5616, duration: 0.015s, episode steps: 2, steps per second: 133, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000347, mae: 0.011048, mean_q: 0.003370
 40456/100000: episode: 5617, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005454, mae: 0.025344, mean_q: 0.007549
 40461/100000: episode: 5618, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000310, mae: 0.017246, mean_q: 0.017501
 40466/100000: episode: 5619, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000762, mae: 0.016922, mean_q: 0.008645
 40471/100000: episode: 5620, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000253, mae: 0.012987, mean_q: 0.012111
 40476/100000: episode: 5621, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000953, mae: 0.016970, mean_q: 0.022208
 40481/100000: episode: 5622, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000352, mae: 0.014654, mean_q: 0.010528
 40486/100000: episode: 5623, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000309, mae: 0.013293, mean_q: 0.014824
 40491/100000: episode: 5624, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000728, mae: 0.013581, mean_q: 0.013774
 40496/100000: episode: 5625, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000285, mae: 0.014980, mean_q: 0.018205
 40498/100000: episode: 5626, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001131, mae: 0.026493, mean_q: 0.011248
 40503/100000: episode: 5627, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.002245, mae: 0.029717, mean_q: 0.035305
 40505/100000: episode: 5628, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000614, mae: 0.025304, mean_q: -0.001079
 40510/100000: episode: 5629, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000693, mae: 0.018793, mean_q: 0.024170
 40515/100000: episode: 5630, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002165, mae: 0.021094, mean_q: 0.006657
 40517/100000: episode: 5631, duration: 0.017s, episode steps: 2, steps per second: 115, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000894, mae: 0.025111, mean_q: 0.039329
 40522/100000: episode: 5632, duration: 0.029s, episode steps: 5, steps per second: 174, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000787, mae: 0.021608, mean_q: 0.006298
 40527/100000: episode: 5633, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000684, mae: 0.021667, mean_q: 0.024888
 40529/100000: episode: 5634, duration: 0.017s, episode steps: 2, steps per second: 115, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000578, mae: 0.016337, mean_q: 0.025213
 40534/100000: episode: 5635, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000227, mae: 0.011953, mean_q: 0.011675
 40539/100000: episode: 5636, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000769, mae: 0.018574, mean_q: 0.012305
 40541/100000: episode: 5637, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000282, mae: 0.018293, mean_q: 0.023942
 40546/100000: episode: 5638, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000599, mae: 0.022224, mean_q: 0.014460
 40551/100000: episode: 5639, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000859, mae: 0.021759, mean_q: 0.017806
 40556/100000: episode: 5640, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000687, mae: 0.019291, mean_q: 0.011647
 40558/100000: episode: 5641, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000327, mae: 0.007617, mean_q: 0.011053
 40563/100000: episode: 5642, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000378, mae: 0.014189, mean_q: 0.018169
 40568/100000: episode: 5643, duration: 0.032s, episode steps: 5, steps per second: 155, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002646, mae: 0.023187, mean_q: 0.015575
 40573/100000: episode: 5644, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000574, mae: 0.022811, mean_q: 0.020087
 40575/100000: episode: 5645, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000520, mae: 0.018226, mean_q: 0.011007
 40580/100000: episode: 5646, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000675, mae: 0.019562, mean_q: 0.016784
 40582/100000: episode: 5647, duration: 0.017s, episode steps: 2, steps per second: 119, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000603, mae: 0.018739, mean_q: 0.001861
 40584/100000: episode: 5648, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000494, mae: 0.023685, mean_q: 0.030012
 40586/100000: episode: 5649, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004841, mae: 0.021059, mean_q: 0.013640
 40588/100000: episode: 5650, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000646, mae: 0.016741, mean_q: 0.016636
 40593/100000: episode: 5651, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000401, mae: 0.015664, mean_q: 0.015658
 40598/100000: episode: 5652, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000518, mae: 0.016022, mean_q: 0.022548
 40603/100000: episode: 5653, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000399, mae: 0.012436, mean_q: 0.013932
 40608/100000: episode: 5654, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002250, mae: 0.018076, mean_q: 0.017560
 40610/100000: episode: 5655, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000615, mae: 0.019493, mean_q: 0.030803
 40612/100000: episode: 5656, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000196, mae: 0.010922, mean_q: 0.011458
 40617/100000: episode: 5657, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000403, mae: 0.013138, mean_q: 0.007063
[Info] FALSIFICATION!
 40621/100000: episode: 5658, duration: 0.278s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000973, mae: 0.015653, mean_q: 0.018719
 40626/100000: episode: 5659, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000826, mae: 0.018088, mean_q: 0.016216
 40631/100000: episode: 5660, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000856, mae: 0.021508, mean_q: 0.028655
 40636/100000: episode: 5661, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000556, mae: 0.019281, mean_q: 0.011470
[Info] FALSIFICATION!
 40640/100000: episode: 5662, duration: 0.270s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000367, mae: 0.014473, mean_q: 0.018653
 40642/100000: episode: 5663, duration: 0.015s, episode steps: 2, steps per second: 130, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000115, mae: 0.010602, mean_q: 0.012145
[Info] FALSIFICATION!
 40646/100000: episode: 5664, duration: 0.185s, episode steps: 4, steps per second: 22, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000814, mae: 0.014998, mean_q: 0.010969
 40648/100000: episode: 5665, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001085, mae: 0.013993, mean_q: 0.028941
 40650/100000: episode: 5666, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000583, mae: 0.012536, mean_q: 0.011757
 40655/100000: episode: 5667, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000749, mae: 0.019435, mean_q: 0.022060
 40660/100000: episode: 5668, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001200, mae: 0.028602, mean_q: 0.028779
 40665/100000: episode: 5669, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001150, mae: 0.026907, mean_q: 0.026107
 40670/100000: episode: 5670, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000848, mae: 0.024256, mean_q: 0.011178
 40675/100000: episode: 5671, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001058, mae: 0.025628, mean_q: 0.037211
 40677/100000: episode: 5672, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000520, mae: 0.022702, mean_q: -0.004306
 40682/100000: episode: 5673, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000434, mae: 0.018804, mean_q: 0.016579
 40684/100000: episode: 5674, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001142, mae: 0.020710, mean_q: 0.020478
 40689/100000: episode: 5675, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000693, mae: 0.016561, mean_q: 0.013864
 40691/100000: episode: 5676, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001729, mae: 0.024883, mean_q: 0.035171
 40693/100000: episode: 5677, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000829, mae: 0.012780, mean_q: 0.014921
 40698/100000: episode: 5678, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002207, mae: 0.021174, mean_q: 0.013068
 40703/100000: episode: 5679, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002434, mae: 0.027669, mean_q: 0.034237
 40705/100000: episode: 5680, duration: 0.015s, episode steps: 2, steps per second: 132, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001517, mae: 0.025237, mean_q: 0.033785
 40710/100000: episode: 5681, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000742, mae: 0.018481, mean_q: 0.019663
 40715/100000: episode: 5682, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001011, mae: 0.022299, mean_q: 0.013192
 40720/100000: episode: 5683, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000805, mae: 0.023599, mean_q: 0.022384
 40722/100000: episode: 5684, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000321, mae: 0.012675, mean_q: 0.001654
 40724/100000: episode: 5685, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000623, mae: 0.015331, mean_q: 0.005780
 40729/100000: episode: 5686, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000688, mae: 0.018412, mean_q: 0.018861
 40731/100000: episode: 5687, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000730, mae: 0.015287, mean_q: 0.002763
[Info] FALSIFICATION!
 40735/100000: episode: 5688, duration: 0.268s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000358, mae: 0.018161, mean_q: 0.020686
 40740/100000: episode: 5689, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000686, mae: 0.018186, mean_q: 0.018921
 40742/100000: episode: 5690, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000412, mae: 0.016364, mean_q: 0.002351
 40744/100000: episode: 5691, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000452, mae: 0.016201, mean_q: 0.008770
 40749/100000: episode: 5692, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000401, mae: 0.014851, mean_q: 0.014743
 40754/100000: episode: 5693, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000698, mae: 0.014044, mean_q: 0.019610
[Info] Complete ISplit Iteration
[Info] Levels: [0.02354835, 0.06420036, 0.8900959]
[Info] Cond. Prob: [0.15, 0.17, 0.04]
[Info] Error Prob: 0.00102

 40756/100000: episode: 5694, duration: 0.862s, episode steps: 2, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001499, mae: 0.022195, mean_q: 0.036913
 40766/100000: episode: 5695, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000746, mae: 0.018950, mean_q: 0.016908
 40776/100000: episode: 5696, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000771, mae: 0.015367, mean_q: 0.019604
 40786/100000: episode: 5697, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000527, mae: 0.016934, mean_q: 0.017307
 40796/100000: episode: 5698, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000663, mae: 0.015438, mean_q: 0.019554
 40806/100000: episode: 5699, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000793, mae: 0.018071, mean_q: 0.012862
 40816/100000: episode: 5700, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002856, mae: 0.031248, mean_q: 0.024995
 40826/100000: episode: 5701, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000791, mae: 0.023683, mean_q: 0.017039
 40836/100000: episode: 5702, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001317, mae: 0.017229, mean_q: 0.015708
 40846/100000: episode: 5703, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001569, mae: 0.021630, mean_q: 0.018707
 40856/100000: episode: 5704, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000850, mae: 0.020870, mean_q: 0.015021
 40866/100000: episode: 5705, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001579, mae: 0.020487, mean_q: 0.018415
 40876/100000: episode: 5706, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000843, mae: 0.024718, mean_q: 0.017048
 40886/100000: episode: 5707, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000732, mae: 0.017172, mean_q: 0.012504
 40896/100000: episode: 5708, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002309, mae: 0.029008, mean_q: 0.021587
 40906/100000: episode: 5709, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001056, mae: 0.022679, mean_q: 0.019279
 40916/100000: episode: 5710, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001861, mae: 0.025908, mean_q: 0.029023
 40926/100000: episode: 5711, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001576, mae: 0.021852, mean_q: 0.020109
 40936/100000: episode: 5712, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000868, mae: 0.021740, mean_q: 0.020850
 40946/100000: episode: 5713, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001721, mae: 0.020201, mean_q: 0.023394
 40956/100000: episode: 5714, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000459, mae: 0.014305, mean_q: 0.010742
 40966/100000: episode: 5715, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000472, mae: 0.013521, mean_q: 0.013746
 40976/100000: episode: 5716, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000705, mae: 0.017199, mean_q: 0.019098
 40986/100000: episode: 5717, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001816, mae: 0.024433, mean_q: 0.022674
 40996/100000: episode: 5718, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000814, mae: 0.020059, mean_q: 0.018442
 41006/100000: episode: 5719, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000690, mae: 0.018471, mean_q: 0.014201
 41016/100000: episode: 5720, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000528, mae: 0.018607, mean_q: 0.013115
 41026/100000: episode: 5721, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001564, mae: 0.020835, mean_q: 0.022481
 41036/100000: episode: 5722, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001493, mae: 0.021593, mean_q: 0.017636
 41046/100000: episode: 5723, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001892, mae: 0.027687, mean_q: 0.018565
 41056/100000: episode: 5724, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000962, mae: 0.018378, mean_q: 0.019843
 41066/100000: episode: 5725, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000336, mae: 0.011366, mean_q: 0.015494
 41076/100000: episode: 5726, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001148, mae: 0.019704, mean_q: 0.025959
 41086/100000: episode: 5727, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002666, mae: 0.029238, mean_q: 0.023914
 41096/100000: episode: 5728, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002252, mae: 0.028689, mean_q: 0.034255
 41106/100000: episode: 5729, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000908, mae: 0.017811, mean_q: 0.016772
 41116/100000: episode: 5730, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000806, mae: 0.014349, mean_q: 0.016743
 41126/100000: episode: 5731, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.003012, mae: 0.024798, mean_q: 0.025477
 41136/100000: episode: 5732, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001374, mae: 0.017623, mean_q: 0.012408
 41146/100000: episode: 5733, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001090, mae: 0.020971, mean_q: 0.024041
 41156/100000: episode: 5734, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001708, mae: 0.020782, mean_q: 0.021142
 41166/100000: episode: 5735, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001023, mae: 0.021346, mean_q: 0.018996
 41176/100000: episode: 5736, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000623, mae: 0.017705, mean_q: 0.014781
 41186/100000: episode: 5737, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001000, mae: 0.022791, mean_q: 0.021353
 41196/100000: episode: 5738, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000752, mae: 0.016943, mean_q: 0.023869
 41206/100000: episode: 5739, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000980, mae: 0.020939, mean_q: 0.016860
 41216/100000: episode: 5740, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001908, mae: 0.020122, mean_q: 0.020573
 41226/100000: episode: 5741, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001911, mae: 0.026982, mean_q: 0.030446
 41236/100000: episode: 5742, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001228, mae: 0.024393, mean_q: 0.013981
 41246/100000: episode: 5743, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001592, mae: 0.019486, mean_q: 0.018213
 41256/100000: episode: 5744, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000971, mae: 0.023897, mean_q: 0.018702
 41266/100000: episode: 5745, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001964, mae: 0.024454, mean_q: 0.014133
 41276/100000: episode: 5746, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001059, mae: 0.018845, mean_q: 0.018885
 41286/100000: episode: 5747, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001580, mae: 0.017870, mean_q: 0.019582
 41296/100000: episode: 5748, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001302, mae: 0.024980, mean_q: 0.021318
 41306/100000: episode: 5749, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001097, mae: 0.019887, mean_q: 0.024287
 41316/100000: episode: 5750, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000488, mae: 0.015603, mean_q: 0.015276
 41326/100000: episode: 5751, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000504, mae: 0.014648, mean_q: 0.008836
 41336/100000: episode: 5752, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000487, mae: 0.012239, mean_q: 0.013027
 41346/100000: episode: 5753, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000719, mae: 0.016301, mean_q: 0.015265
 41356/100000: episode: 5754, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001461, mae: 0.015289, mean_q: 0.014281
 41366/100000: episode: 5755, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.002453, mae: 0.023416, mean_q: 0.018583
 41376/100000: episode: 5756, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001077, mae: 0.020154, mean_q: 0.022393
 41386/100000: episode: 5757, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000928, mae: 0.019737, mean_q: 0.017667
 41396/100000: episode: 5758, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000731, mae: 0.017614, mean_q: 0.017329
 41406/100000: episode: 5759, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000999, mae: 0.020302, mean_q: 0.020652
 41416/100000: episode: 5760, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001761, mae: 0.024543, mean_q: 0.017241
 41426/100000: episode: 5761, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001192, mae: 0.022752, mean_q: 0.023298
 41436/100000: episode: 5762, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000645, mae: 0.018001, mean_q: 0.011866
 41446/100000: episode: 5763, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000708, mae: 0.012323, mean_q: 0.018546
 41456/100000: episode: 5764, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000438, mae: 0.013132, mean_q: 0.011648
 41466/100000: episode: 5765, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001890, mae: 0.020622, mean_q: 0.022779
 41476/100000: episode: 5766, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.002104, mae: 0.021388, mean_q: 0.026183
 41486/100000: episode: 5767, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000683, mae: 0.016040, mean_q: 0.012947
 41496/100000: episode: 5768, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000913, mae: 0.017624, mean_q: 0.019924
 41506/100000: episode: 5769, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000557, mae: 0.014241, mean_q: 0.009904
 41516/100000: episode: 5770, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001307, mae: 0.013216, mean_q: 0.012515
 41526/100000: episode: 5771, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000788, mae: 0.019308, mean_q: 0.015477
 41536/100000: episode: 5772, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001734, mae: 0.017390, mean_q: 0.018507
 41546/100000: episode: 5773, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000635, mae: 0.019839, mean_q: 0.012697
 41556/100000: episode: 5774, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001181, mae: 0.018047, mean_q: 0.021861
 41566/100000: episode: 5775, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000901, mae: 0.017001, mean_q: 0.018417
 41576/100000: episode: 5776, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000938, mae: 0.016454, mean_q: 0.017119
 41586/100000: episode: 5777, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001534, mae: 0.016176, mean_q: 0.017314
 41596/100000: episode: 5778, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000598, mae: 0.017343, mean_q: 0.018577
 41606/100000: episode: 5779, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000539, mae: 0.014132, mean_q: 0.020722
 41616/100000: episode: 5780, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000641, mae: 0.015398, mean_q: 0.017720
 41626/100000: episode: 5781, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000714, mae: 0.013991, mean_q: 0.017468
 41636/100000: episode: 5782, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.003020, mae: 0.024858, mean_q: 0.029571
 41646/100000: episode: 5783, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000717, mae: 0.016856, mean_q: 0.014490
 41656/100000: episode: 5784, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000328, mae: 0.011353, mean_q: 0.012390
 41666/100000: episode: 5785, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001514, mae: 0.021581, mean_q: 0.023539
 41676/100000: episode: 5786, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000767, mae: 0.016887, mean_q: 0.016377
 41686/100000: episode: 5787, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001412, mae: 0.018800, mean_q: 0.019474
 41696/100000: episode: 5788, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000593, mae: 0.016257, mean_q: 0.012728
 41706/100000: episode: 5789, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001858, mae: 0.026566, mean_q: 0.025578
 41716/100000: episode: 5790, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000886, mae: 0.017694, mean_q: 0.021650
 41726/100000: episode: 5791, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001741, mae: 0.018089, mean_q: 0.022819
 41736/100000: episode: 5792, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001904, mae: 0.023480, mean_q: 0.026111
 41746/100000: episode: 5793, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000429, mae: 0.015724, mean_q: 0.014201
[Info] 1-TH LEVEL FOUND: 0.012143045663833618, Considering 11/100 traces
 41756/100000: episode: 5794, duration: 0.699s, episode steps: 10, steps per second: 14, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000438, mae: 0.013988, mean_q: 0.013044
 41764/100000: episode: 5795, duration: 0.044s, episode steps: 8, steps per second: 181, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000877, mae: 0.016385, mean_q: 0.016333
 41772/100000: episode: 5796, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000939, mae: 0.021913, mean_q: 0.018382
 41780/100000: episode: 5797, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.085, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000748, mae: 0.016208, mean_q: 0.021694
 41788/100000: episode: 5798, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000494, mae: 0.013590, mean_q: 0.013066
 41791/100000: episode: 5799, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001121, mae: 0.016904, mean_q: 0.022713
 41799/100000: episode: 5800, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.102, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.002022, mae: 0.017550, mean_q: 0.020081
 41807/100000: episode: 5801, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.067, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000670, mae: 0.015418, mean_q: 0.012156
 41815/100000: episode: 5802, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.028, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001022, mae: 0.017985, mean_q: 0.022803
 41823/100000: episode: 5803, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.051, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000223, mae: 0.011245, mean_q: 0.007198
 41831/100000: episode: 5804, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000472, mae: 0.013583, mean_q: 0.012903
 41839/100000: episode: 5805, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.214, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.001883, mae: 0.020581, mean_q: 0.018074
 41847/100000: episode: 5806, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.098, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.001065, mae: 0.020794, mean_q: 0.028029
 41855/100000: episode: 5807, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000443, mae: 0.014903, mean_q: 0.014656
 41863/100000: episode: 5808, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.033, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000445, mae: 0.014781, mean_q: 0.018376
 41871/100000: episode: 5809, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.013, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000606, mae: 0.014092, mean_q: 0.020081
 41879/100000: episode: 5810, duration: 0.041s, episode steps: 8, steps per second: 197, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000634, mae: 0.012550, mean_q: 0.013996
 41882/100000: episode: 5811, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001090, mae: 0.015955, mean_q: 0.020860
 41890/100000: episode: 5812, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.231, mean reward: 0.029 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.000882, mae: 0.014444, mean_q: 0.017824
 41893/100000: episode: 5813, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000424, mae: 0.011544, mean_q: 0.018047
 41901/100000: episode: 5814, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.085, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000479, mae: 0.010913, mean_q: 0.015822
 41909/100000: episode: 5815, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.023, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000497, mae: 0.013565, mean_q: 0.015850
 41917/100000: episode: 5816, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.049, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001865, mae: 0.017448, mean_q: 0.019910
 41925/100000: episode: 5817, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.087, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.002003, mae: 0.025485, mean_q: 0.025950
 41933/100000: episode: 5818, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.134, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000749, mae: 0.017713, mean_q: 0.025699
 41936/100000: episode: 5819, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000801, mae: 0.019738, mean_q: 0.011673
 41944/100000: episode: 5820, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.001270, mae: 0.023468, mean_q: 0.020370
 41952/100000: episode: 5821, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.001214, mae: 0.020718, mean_q: 0.022817
 41960/100000: episode: 5822, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.039, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001986, mae: 0.026205, mean_q: 0.025506
 41968/100000: episode: 5823, duration: 0.041s, episode steps: 8, steps per second: 196, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.001120, mae: 0.023729, mean_q: 0.019928
 41976/100000: episode: 5824, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.177, mean reward: 0.022 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.002458, mae: 0.024606, mean_q: 0.022334
 41979/100000: episode: 5825, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000896, mae: 0.026731, mean_q: 0.012466
 41987/100000: episode: 5826, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.036, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000590, mae: 0.017399, mean_q: 0.015137
 41995/100000: episode: 5827, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.146, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000339, mae: 0.016241, mean_q: 0.010411
 41998/100000: episode: 5828, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000460, mae: 0.014904, mean_q: 0.005123
 42006/100000: episode: 5829, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.102, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.001143, mae: 0.022479, mean_q: 0.031403
 42014/100000: episode: 5830, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.134, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.002798, mae: 0.021760, mean_q: 0.021516
 42022/100000: episode: 5831, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000976, mae: 0.026387, mean_q: 0.009351
 42030/100000: episode: 5832, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.038, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000688, mae: 0.019329, mean_q: 0.015057
 42038/100000: episode: 5833, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.079, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000456, mae: 0.013165, mean_q: 0.012291
 42046/100000: episode: 5834, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001075, mae: 0.018134, mean_q: 0.022021
 42054/100000: episode: 5835, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000745, mae: 0.018665, mean_q: 0.013967
 42062/100000: episode: 5836, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.214, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000351, mae: 0.013204, mean_q: 0.015005
 42070/100000: episode: 5837, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.035, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.002115, mae: 0.023975, mean_q: 0.021297
 42078/100000: episode: 5838, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.022, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000544, mae: 0.015796, mean_q: 0.018451
 42086/100000: episode: 5839, duration: 0.040s, episode steps: 8, steps per second: 200, episode reward: 0.030, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.001003, mae: 0.017201, mean_q: 0.020673
 42089/100000: episode: 5840, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000156, mae: 0.008710, mean_q: 0.009378
 42092/100000: episode: 5841, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000613, mae: 0.018729, mean_q: 0.029562
 42100/100000: episode: 5842, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.051, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.001788, mae: 0.020439, mean_q: 0.029830
 42108/100000: episode: 5843, duration: 0.040s, episode steps: 8, steps per second: 200, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.001373, mae: 0.022931, mean_q: 0.019035
 42116/100000: episode: 5844, duration: 0.040s, episode steps: 8, steps per second: 202, episode reward: 0.146, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000621, mae: 0.017541, mean_q: 0.011679
 42124/100000: episode: 5845, duration: 0.042s, episode steps: 8, steps per second: 192, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.001873, mae: 0.023880, mean_q: 0.028943
 42132/100000: episode: 5846, duration: 0.043s, episode steps: 8, steps per second: 186, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000486, mae: 0.019171, mean_q: 0.005426
 42140/100000: episode: 5847, duration: 0.041s, episode steps: 8, steps per second: 196, episode reward: 0.054, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.002213, mae: 0.021286, mean_q: 0.018492
 42148/100000: episode: 5848, duration: 0.041s, episode steps: 8, steps per second: 197, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000545, mae: 0.016674, mean_q: 0.009577
 42151/100000: episode: 5849, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001002, mae: 0.015236, mean_q: 0.020048
 42154/100000: episode: 5850, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000608, mae: 0.015536, mean_q: 0.013505
 42162/100000: episode: 5851, duration: 0.042s, episode steps: 8, steps per second: 190, episode reward: 0.114, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.002603, mae: 0.026524, mean_q: 0.027048
 42165/100000: episode: 5852, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001033, mae: 0.022048, mean_q: 0.010723
 42173/100000: episode: 5853, duration: 0.040s, episode steps: 8, steps per second: 202, episode reward: 0.263, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.938 [-1.000, 11.000], loss: 0.000529, mae: 0.018469, mean_q: 0.017831
 42176/100000: episode: 5854, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000247, mae: 0.012906, mean_q: 0.011733
 42179/100000: episode: 5855, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000314, mae: 0.015382, mean_q: 0.015495
 42187/100000: episode: 5856, duration: 0.040s, episode steps: 8, steps per second: 200, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000644, mae: 0.018891, mean_q: 0.015883
 42195/100000: episode: 5857, duration: 0.042s, episode steps: 8, steps per second: 190, episode reward: 0.022, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000604, mae: 0.020115, mean_q: 0.011708
 42203/100000: episode: 5858, duration: 0.040s, episode steps: 8, steps per second: 200, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000658, mae: 0.016807, mean_q: 0.014551
 42206/100000: episode: 5859, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000704, mae: 0.012671, mean_q: 0.009476
 42209/100000: episode: 5860, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001163, mae: 0.016132, mean_q: 0.019836
 42217/100000: episode: 5861, duration: 0.040s, episode steps: 8, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000702, mae: 0.016968, mean_q: 0.017444
 42225/100000: episode: 5862, duration: 0.044s, episode steps: 8, steps per second: 182, episode reward: 0.036, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.001943, mae: 0.020518, mean_q: 0.022756
 42233/100000: episode: 5863, duration: 0.042s, episode steps: 8, steps per second: 192, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.812 [-1.000, 11.000], loss: 0.001128, mae: 0.019842, mean_q: 0.023736
 42241/100000: episode: 5864, duration: 0.043s, episode steps: 8, steps per second: 187, episode reward: 0.036, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.003066, mae: 0.032840, mean_q: 0.040490
 42249/100000: episode: 5865, duration: 0.041s, episode steps: 8, steps per second: 194, episode reward: 0.023, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.001528, mae: 0.026985, mean_q: 0.026085
 42252/100000: episode: 5866, duration: 0.019s, episode steps: 3, steps per second: 155, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003903, mae: 0.022758, mean_q: 0.009139
 42260/100000: episode: 5867, duration: 0.045s, episode steps: 8, steps per second: 178, episode reward: 0.071, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000674, mae: 0.018582, mean_q: 0.018924
 42268/100000: episode: 5868, duration: 0.042s, episode steps: 8, steps per second: 188, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000802, mae: 0.021956, mean_q: 0.022789
 42276/100000: episode: 5869, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000700, mae: 0.017526, mean_q: 0.018722
 42284/100000: episode: 5870, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000855, mae: 0.019769, mean_q: 0.025521
 42292/100000: episode: 5871, duration: 0.040s, episode steps: 8, steps per second: 199, episode reward: 0.114, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001484, mae: 0.019673, mean_q: 0.019101
 42295/100000: episode: 5872, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001403, mae: 0.027366, mean_q: 0.015566
 42303/100000: episode: 5873, duration: 0.042s, episode steps: 8, steps per second: 189, episode reward: 0.134, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000559, mae: 0.018627, mean_q: 0.015019
 42306/100000: episode: 5874, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000679, mae: 0.019757, mean_q: 0.000516
 42314/100000: episode: 5875, duration: 0.042s, episode steps: 8, steps per second: 190, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000843, mae: 0.015060, mean_q: 0.019669
 42322/100000: episode: 5876, duration: 0.044s, episode steps: 8, steps per second: 183, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000642, mae: 0.017351, mean_q: 0.018939
 42330/100000: episode: 5877, duration: 0.043s, episode steps: 8, steps per second: 184, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001845, mae: 0.020791, mean_q: 0.016056
 42338/100000: episode: 5878, duration: 0.044s, episode steps: 8, steps per second: 183, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.002969, mae: 0.028482, mean_q: 0.029834
 42341/100000: episode: 5879, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001407, mae: 0.027716, mean_q: 0.016996
 42349/100000: episode: 5880, duration: 0.043s, episode steps: 8, steps per second: 186, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.001292, mae: 0.026719, mean_q: 0.025672
 42357/100000: episode: 5881, duration: 0.042s, episode steps: 8, steps per second: 189, episode reward: 0.231, mean reward: 0.029 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.000763, mae: 0.019687, mean_q: 0.014249
 42365/100000: episode: 5882, duration: 0.041s, episode steps: 8, steps per second: 195, episode reward: 0.348, mean reward: 0.044 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000708, mae: 0.014899, mean_q: 0.015955
[Info] 2-TH LEVEL FOUND: 0.06612442433834076, Considering 11/100 traces
 42368/100000: episode: 5883, duration: 0.978s, episode steps: 3, steps per second: 3, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000652, mae: 0.019120, mean_q: 0.024314
 42373/100000: episode: 5884, duration: 0.075s, episode steps: 5, steps per second: 67, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000748, mae: 0.017403, mean_q: 0.013147
 42378/100000: episode: 5885, duration: 0.060s, episode steps: 5, steps per second: 83, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000504, mae: 0.015411, mean_q: 0.012963
 42383/100000: episode: 5886, duration: 0.046s, episode steps: 5, steps per second: 109, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000751, mae: 0.018501, mean_q: 0.027962
 42388/100000: episode: 5887, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002240, mae: 0.018742, mean_q: 0.014379
 42393/100000: episode: 5888, duration: 0.049s, episode steps: 5, steps per second: 103, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000911, mae: 0.021457, mean_q: 0.026412
 42398/100000: episode: 5889, duration: 0.058s, episode steps: 5, steps per second: 87, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001385, mae: 0.026546, mean_q: 0.013599
 42403/100000: episode: 5890, duration: 0.050s, episode steps: 5, steps per second: 101, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002657, mae: 0.029214, mean_q: 0.030718
 42408/100000: episode: 5891, duration: 0.047s, episode steps: 5, steps per second: 106, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002689, mae: 0.026571, mean_q: 0.010734
 42413/100000: episode: 5892, duration: 0.054s, episode steps: 5, steps per second: 92, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000564, mae: 0.021774, mean_q: 0.027907
 42418/100000: episode: 5893, duration: 0.049s, episode steps: 5, steps per second: 102, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000374, mae: 0.017442, mean_q: -0.001422
 42423/100000: episode: 5894, duration: 0.047s, episode steps: 5, steps per second: 106, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000616, mae: 0.024263, mean_q: 0.033280
 42428/100000: episode: 5895, duration: 0.070s, episode steps: 5, steps per second: 72, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000696, mae: 0.021706, mean_q: 0.011909
 42433/100000: episode: 5896, duration: 0.047s, episode steps: 5, steps per second: 107, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002649, mae: 0.029603, mean_q: 0.040897
 42438/100000: episode: 5897, duration: 0.044s, episode steps: 5, steps per second: 113, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000968, mae: 0.025397, mean_q: 0.007275
 42443/100000: episode: 5898, duration: 0.046s, episode steps: 5, steps per second: 108, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001691, mae: 0.027384, mean_q: 0.038976
 42448/100000: episode: 5899, duration: 0.034s, episode steps: 5, steps per second: 149, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000805, mae: 0.021249, mean_q: 0.008487
 42453/100000: episode: 5900, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000822, mae: 0.020145, mean_q: 0.023655
 42458/100000: episode: 5901, duration: 0.030s, episode steps: 5, steps per second: 164, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.004603, mae: 0.033332, mean_q: 0.030834
 42463/100000: episode: 5902, duration: 0.034s, episode steps: 5, steps per second: 148, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001353, mae: 0.034670, mean_q: 0.010263
 42468/100000: episode: 5903, duration: 0.038s, episode steps: 5, steps per second: 131, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001553, mae: 0.029308, mean_q: 0.042382
 42473/100000: episode: 5904, duration: 0.052s, episode steps: 5, steps per second: 97, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.003068, mae: 0.028049, mean_q: 0.009339
 42478/100000: episode: 5905, duration: 0.045s, episode steps: 5, steps per second: 111, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000514, mae: 0.017087, mean_q: 0.019219
 42483/100000: episode: 5906, duration: 0.047s, episode steps: 5, steps per second: 107, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000612, mae: 0.019563, mean_q: 0.016637
 42488/100000: episode: 5907, duration: 0.047s, episode steps: 5, steps per second: 107, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000987, mae: 0.020554, mean_q: 0.020890
 42493/100000: episode: 5908, duration: 0.034s, episode steps: 5, steps per second: 149, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000333, mae: 0.015139, mean_q: 0.017886
 42498/100000: episode: 5909, duration: 0.036s, episode steps: 5, steps per second: 141, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001199, mae: 0.019872, mean_q: 0.026594
 42503/100000: episode: 5910, duration: 0.029s, episode steps: 5, steps per second: 171, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000412, mae: 0.014118, mean_q: 0.011574
 42508/100000: episode: 5911, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001075, mae: 0.016885, mean_q: 0.023424
 42513/100000: episode: 5912, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000985, mae: 0.018191, mean_q: 0.019710
 42518/100000: episode: 5913, duration: 0.032s, episode steps: 5, steps per second: 155, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001246, mae: 0.024118, mean_q: 0.021830
 42523/100000: episode: 5914, duration: 0.033s, episode steps: 5, steps per second: 151, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000511, mae: 0.015544, mean_q: 0.020581
 42528/100000: episode: 5915, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000904, mae: 0.019927, mean_q: 0.022979
 42533/100000: episode: 5916, duration: 0.029s, episode steps: 5, steps per second: 173, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002496, mae: 0.019916, mean_q: 0.012084
 42538/100000: episode: 5917, duration: 0.032s, episode steps: 5, steps per second: 154, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002740, mae: 0.021615, mean_q: 0.026024
 42543/100000: episode: 5918, duration: 0.030s, episode steps: 5, steps per second: 167, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000789, mae: 0.018599, mean_q: 0.025372
 42548/100000: episode: 5919, duration: 0.038s, episode steps: 5, steps per second: 131, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000580, mae: 0.014979, mean_q: 0.015939
 42553/100000: episode: 5920, duration: 0.037s, episode steps: 5, steps per second: 134, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001553, mae: 0.023579, mean_q: 0.035721
 42558/100000: episode: 5921, duration: 0.030s, episode steps: 5, steps per second: 168, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001290, mae: 0.020537, mean_q: 0.022455
 42563/100000: episode: 5922, duration: 0.036s, episode steps: 5, steps per second: 137, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000717, mae: 0.019746, mean_q: 0.021822
 42568/100000: episode: 5923, duration: 0.035s, episode steps: 5, steps per second: 144, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001109, mae: 0.023670, mean_q: 0.027208
 42573/100000: episode: 5924, duration: 0.050s, episode steps: 5, steps per second: 99, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000438, mae: 0.016373, mean_q: 0.003160
 42578/100000: episode: 5925, duration: 0.065s, episode steps: 5, steps per second: 76, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000921, mae: 0.019995, mean_q: 0.026115
 42583/100000: episode: 5926, duration: 0.057s, episode steps: 5, steps per second: 88, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000833, mae: 0.019059, mean_q: 0.017853
 42588/100000: episode: 5927, duration: 0.036s, episode steps: 5, steps per second: 138, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000670, mae: 0.017284, mean_q: 0.018018
[Info] FALSIFICATION!
 42592/100000: episode: 5928, duration: 0.328s, episode steps: 4, steps per second: 12, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000519, mae: 0.018081, mean_q: 0.019296
 42597/100000: episode: 5929, duration: 0.039s, episode steps: 5, steps per second: 127, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002820, mae: 0.023786, mean_q: 0.025218
 42602/100000: episode: 5930, duration: 0.041s, episode steps: 5, steps per second: 121, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.002356, mae: 0.034849, mean_q: 0.044226
 42607/100000: episode: 5931, duration: 0.047s, episode steps: 5, steps per second: 106, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001131, mae: 0.024158, mean_q: 0.034861
 42612/100000: episode: 5932, duration: 0.044s, episode steps: 5, steps per second: 114, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000629, mae: 0.020258, mean_q: 0.011941
 42617/100000: episode: 5933, duration: 0.042s, episode steps: 5, steps per second: 120, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001721, mae: 0.027588, mean_q: 0.029071
 42622/100000: episode: 5934, duration: 0.033s, episode steps: 5, steps per second: 150, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000598, mae: 0.019929, mean_q: 0.015521
 42627/100000: episode: 5935, duration: 0.030s, episode steps: 5, steps per second: 165, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002077, mae: 0.025379, mean_q: 0.027852
 42632/100000: episode: 5936, duration: 0.033s, episode steps: 5, steps per second: 150, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001213, mae: 0.023157, mean_q: 0.030218
 42637/100000: episode: 5937, duration: 0.032s, episode steps: 5, steps per second: 155, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.003658, mae: 0.030586, mean_q: 0.025927
 42642/100000: episode: 5938, duration: 0.030s, episode steps: 5, steps per second: 165, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001171, mae: 0.025163, mean_q: 0.021550
 42647/100000: episode: 5939, duration: 0.035s, episode steps: 5, steps per second: 145, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000987, mae: 0.023274, mean_q: 0.024780
 42652/100000: episode: 5940, duration: 0.031s, episode steps: 5, steps per second: 159, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001636, mae: 0.025504, mean_q: 0.018605
 42657/100000: episode: 5941, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001793, mae: 0.032328, mean_q: 0.044101
 42662/100000: episode: 5942, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002712, mae: 0.025550, mean_q: 0.020838
 42667/100000: episode: 5943, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001338, mae: 0.020748, mean_q: 0.022301
 42672/100000: episode: 5944, duration: 0.035s, episode steps: 5, steps per second: 143, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001301, mae: 0.024303, mean_q: 0.019931
 42677/100000: episode: 5945, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001027, mae: 0.023560, mean_q: 0.015721
 42682/100000: episode: 5946, duration: 0.031s, episode steps: 5, steps per second: 161, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001245, mae: 0.029766, mean_q: 0.040108
 42687/100000: episode: 5947, duration: 0.037s, episode steps: 5, steps per second: 137, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003332, mae: 0.031809, mean_q: 0.009561
 42692/100000: episode: 5948, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001390, mae: 0.030282, mean_q: 0.044794
 42697/100000: episode: 5949, duration: 0.033s, episode steps: 5, steps per second: 154, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.002485, mae: 0.028135, mean_q: 0.026345
 42702/100000: episode: 5950, duration: 0.030s, episode steps: 5, steps per second: 168, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003982, mae: 0.034948, mean_q: 0.042340
 42707/100000: episode: 5951, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001645, mae: 0.029949, mean_q: 0.037382
 42712/100000: episode: 5952, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001497, mae: 0.026978, mean_q: 0.024814
 42717/100000: episode: 5953, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001788, mae: 0.031760, mean_q: 0.039352
 42722/100000: episode: 5954, duration: 0.024s, episode steps: 5, steps per second: 204, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000471, mae: 0.021778, mean_q: -0.001108
 42727/100000: episode: 5955, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001263, mae: 0.034342, mean_q: 0.038140
 42732/100000: episode: 5956, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000949, mae: 0.025907, mean_q: 0.027671
 42737/100000: episode: 5957, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001661, mae: 0.029267, mean_q: 0.048038
 42742/100000: episode: 5958, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002294, mae: 0.036751, mean_q: 0.033262
 42747/100000: episode: 5959, duration: 0.024s, episode steps: 5, steps per second: 204, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000876, mae: 0.022350, mean_q: 0.019576
 42752/100000: episode: 5960, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001133, mae: 0.026204, mean_q: 0.033772
 42757/100000: episode: 5961, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001509, mae: 0.027984, mean_q: 0.030421
 42762/100000: episode: 5962, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002911, mae: 0.026826, mean_q: 0.028990
 42767/100000: episode: 5963, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002661, mae: 0.023873, mean_q: 0.025773
 42772/100000: episode: 5964, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000851, mae: 0.021781, mean_q: 0.011356
 42777/100000: episode: 5965, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001095, mae: 0.030213, mean_q: 0.044006
 42782/100000: episode: 5966, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001007, mae: 0.027160, mean_q: 0.014216
 42787/100000: episode: 5967, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.003444, mae: 0.032444, mean_q: 0.031484
 42792/100000: episode: 5968, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000985, mae: 0.023133, mean_q: 0.028020
 42797/100000: episode: 5969, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000705, mae: 0.022148, mean_q: 0.018753
 42802/100000: episode: 5970, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000591, mae: 0.017220, mean_q: 0.024466
 42807/100000: episode: 5971, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001499, mae: 0.024617, mean_q: 0.030515
[Info] Complete ISplit Iteration
[Info] Levels: [0.012143046, 0.066124424, 0.85401237]
[Info] Cond. Prob: [0.11, 0.11, 0.01]
[Info] Error Prob: 0.000121

 42812/100000: episode: 5972, duration: 0.989s, episode steps: 5, steps per second: 5, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000622, mae: 0.017158, mean_q: 0.023022
 42822/100000: episode: 5973, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001053, mae: 0.020622, mean_q: 0.030670
 42832/100000: episode: 5974, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001174, mae: 0.022928, mean_q: 0.025650
 42842/100000: episode: 5975, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001289, mae: 0.028986, mean_q: 0.022539
 42852/100000: episode: 5976, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.002870, mae: 0.034364, mean_q: 0.030050
 42862/100000: episode: 5977, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003631, mae: 0.039800, mean_q: 0.041343
 42872/100000: episode: 5978, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001481, mae: 0.031811, mean_q: 0.021093
 42882/100000: episode: 5979, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001099, mae: 0.027367, mean_q: 0.020048
 42892/100000: episode: 5980, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003473, mae: 0.033956, mean_q: 0.026381
 42902/100000: episode: 5981, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001939, mae: 0.031456, mean_q: 0.024310
 42912/100000: episode: 5982, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001455, mae: 0.027028, mean_q: 0.025532
 42922/100000: episode: 5983, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001201, mae: 0.020791, mean_q: 0.027836
 42932/100000: episode: 5984, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001440, mae: 0.023470, mean_q: 0.028931
 42942/100000: episode: 5985, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002346, mae: 0.034469, mean_q: 0.029573
 42952/100000: episode: 5986, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002267, mae: 0.038768, mean_q: 0.034212
 42962/100000: episode: 5987, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000999, mae: 0.028393, mean_q: 0.028691
 42972/100000: episode: 5988, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.002430, mae: 0.026003, mean_q: 0.025703
 42982/100000: episode: 5989, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002192, mae: 0.029853, mean_q: 0.028977
 42992/100000: episode: 5990, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001465, mae: 0.030189, mean_q: 0.027899
 43002/100000: episode: 5991, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000899, mae: 0.019446, mean_q: 0.016888
 43012/100000: episode: 5992, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001240, mae: 0.026608, mean_q: 0.029571
 43022/100000: episode: 5993, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000889, mae: 0.022849, mean_q: 0.024154
 43032/100000: episode: 5994, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000805, mae: 0.019181, mean_q: 0.020618
 43042/100000: episode: 5995, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002120, mae: 0.026854, mean_q: 0.030662
 43052/100000: episode: 5996, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002146, mae: 0.031541, mean_q: 0.033911
 43062/100000: episode: 5997, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002019, mae: 0.027646, mean_q: 0.031288
 43072/100000: episode: 5998, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001297, mae: 0.025697, mean_q: 0.029063
 43082/100000: episode: 5999, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000826, mae: 0.023722, mean_q: 0.018656
 43092/100000: episode: 6000, duration: 0.055s, episode steps: 10, steps per second: 180, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002106, mae: 0.026899, mean_q: 0.030498
 43102/100000: episode: 6001, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001216, mae: 0.021875, mean_q: 0.023695
 43112/100000: episode: 6002, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001932, mae: 0.023308, mean_q: 0.023286
 43122/100000: episode: 6003, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001168, mae: 0.026759, mean_q: 0.024320
 43132/100000: episode: 6004, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001072, mae: 0.021561, mean_q: 0.030451
 43142/100000: episode: 6005, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000852, mae: 0.020493, mean_q: 0.024386
 43152/100000: episode: 6006, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001010, mae: 0.023948, mean_q: 0.026922
 43162/100000: episode: 6007, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001056, mae: 0.026030, mean_q: 0.021515
 43172/100000: episode: 6008, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.003573, mae: 0.030746, mean_q: 0.032984
 43182/100000: episode: 6009, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001323, mae: 0.025310, mean_q: 0.024422
 43192/100000: episode: 6010, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001248, mae: 0.024529, mean_q: 0.027252
 43202/100000: episode: 6011, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001315, mae: 0.024675, mean_q: 0.027814
 43212/100000: episode: 6012, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000956, mae: 0.019433, mean_q: 0.023448
 43222/100000: episode: 6013, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.002039, mae: 0.024754, mean_q: 0.030241
 43232/100000: episode: 6014, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001254, mae: 0.025966, mean_q: 0.028719
 43242/100000: episode: 6015, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000837, mae: 0.020304, mean_q: 0.024759
 43252/100000: episode: 6016, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001475, mae: 0.023605, mean_q: 0.028589
 43262/100000: episode: 6017, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000669, mae: 0.020519, mean_q: 0.023967
 43272/100000: episode: 6018, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002431, mae: 0.028457, mean_q: 0.036232
 43282/100000: episode: 6019, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000810, mae: 0.020705, mean_q: 0.022597
 43292/100000: episode: 6020, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000711, mae: 0.019490, mean_q: 0.019929
 43302/100000: episode: 6021, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002087, mae: 0.027999, mean_q: 0.037942
 43312/100000: episode: 6022, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002864, mae: 0.032248, mean_q: 0.041370
 43322/100000: episode: 6023, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000757, mae: 0.021891, mean_q: 0.016769
 43332/100000: episode: 6024, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000770, mae: 0.016549, mean_q: 0.019748
 43342/100000: episode: 6025, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000665, mae: 0.017885, mean_q: 0.025673
 43352/100000: episode: 6026, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001885, mae: 0.022287, mean_q: 0.027442
 43362/100000: episode: 6027, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000715, mae: 0.015549, mean_q: 0.021029
 43372/100000: episode: 6028, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000790, mae: 0.016823, mean_q: 0.023680
 43382/100000: episode: 6029, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000898, mae: 0.018866, mean_q: 0.022895
 43392/100000: episode: 6030, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002437, mae: 0.026465, mean_q: 0.033570
 43402/100000: episode: 6031, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000934, mae: 0.018228, mean_q: 0.024988
 43412/100000: episode: 6032, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000613, mae: 0.016877, mean_q: 0.022859
 43422/100000: episode: 6033, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002267, mae: 0.022479, mean_q: 0.026133
 43432/100000: episode: 6034, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001120, mae: 0.022532, mean_q: 0.019992
 43442/100000: episode: 6035, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000993, mae: 0.019583, mean_q: 0.023237
 43452/100000: episode: 6036, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002072, mae: 0.024519, mean_q: 0.023540
 43462/100000: episode: 6037, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001949, mae: 0.026823, mean_q: 0.031955
 43472/100000: episode: 6038, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000707, mae: 0.024190, mean_q: 0.017431
 43482/100000: episode: 6039, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000804, mae: 0.017889, mean_q: 0.020468
 43492/100000: episode: 6040, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001840, mae: 0.026702, mean_q: 0.035470
 43502/100000: episode: 6041, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002794, mae: 0.034601, mean_q: 0.039270
 43512/100000: episode: 6042, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001178, mae: 0.030691, mean_q: 0.026176
 43522/100000: episode: 6043, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000684, mae: 0.018456, mean_q: 0.017241
 43532/100000: episode: 6044, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002825, mae: 0.027421, mean_q: 0.033755
 43542/100000: episode: 6045, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001631, mae: 0.029461, mean_q: 0.025619
 43552/100000: episode: 6046, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001987, mae: 0.025953, mean_q: 0.025662
 43562/100000: episode: 6047, duration: 0.055s, episode steps: 10, steps per second: 180, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001200, mae: 0.027865, mean_q: 0.016110
 43572/100000: episode: 6048, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000899, mae: 0.022775, mean_q: 0.023312
 43582/100000: episode: 6049, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000902, mae: 0.022945, mean_q: 0.031448
 43592/100000: episode: 6050, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001115, mae: 0.023476, mean_q: 0.033541
 43602/100000: episode: 6051, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001837, mae: 0.022370, mean_q: 0.028438
 43612/100000: episode: 6052, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000796, mae: 0.018694, mean_q: 0.019816
 43622/100000: episode: 6053, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000712, mae: 0.019292, mean_q: 0.017148
 43632/100000: episode: 6054, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000929, mae: 0.022729, mean_q: 0.023336
 43642/100000: episode: 6055, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000704, mae: 0.016903, mean_q: 0.024209
 43652/100000: episode: 6056, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002743, mae: 0.026414, mean_q: 0.031718
 43662/100000: episode: 6057, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001111, mae: 0.022918, mean_q: 0.024839
 43672/100000: episode: 6058, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001668, mae: 0.023662, mean_q: 0.030337
 43682/100000: episode: 6059, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002161, mae: 0.031594, mean_q: 0.025207
 43692/100000: episode: 6060, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000734, mae: 0.019244, mean_q: 0.015276
 43702/100000: episode: 6061, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000813, mae: 0.017318, mean_q: 0.019851
 43712/100000: episode: 6062, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001000, mae: 0.019216, mean_q: 0.028131
 43722/100000: episode: 6063, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000809, mae: 0.014722, mean_q: 0.019501
 43732/100000: episode: 6064, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000610, mae: 0.015605, mean_q: 0.021459
 43742/100000: episode: 6065, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000751, mae: 0.017159, mean_q: 0.020161
 43752/100000: episode: 6066, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.002074, mae: 0.025064, mean_q: 0.029768
 43762/100000: episode: 6067, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000671, mae: 0.017639, mean_q: 0.019624
 43772/100000: episode: 6068, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001145, mae: 0.022034, mean_q: 0.026376
 43782/100000: episode: 6069, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001816, mae: 0.023356, mean_q: 0.025381
 43792/100000: episode: 6070, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000969, mae: 0.019924, mean_q: 0.023948
 43802/100000: episode: 6071, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000631, mae: 0.015870, mean_q: 0.020762
[Info] 1-TH LEVEL FOUND: 0.0072470903396606445, Considering 13/100 traces
 43812/100000: episode: 6072, duration: 0.909s, episode steps: 10, steps per second: 11, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000515, mae: 0.015364, mean_q: 0.020249
 43820/100000: episode: 6073, duration: 0.079s, episode steps: 8, steps per second: 101, episode reward: 0.030, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000558, mae: 0.015227, mean_q: 0.018790
 43828/100000: episode: 6074, duration: 0.073s, episode steps: 8, steps per second: 110, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.001793, mae: 0.023544, mean_q: 0.027948
 43836/100000: episode: 6075, duration: 0.075s, episode steps: 8, steps per second: 106, episode reward: 0.015, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000917, mae: 0.024846, mean_q: 0.022510
 43844/100000: episode: 6076, duration: 0.068s, episode steps: 8, steps per second: 118, episode reward: 0.015, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.001171, mae: 0.026447, mean_q: 0.026118
[Info] FALSIFICATION!
 43851/100000: episode: 6077, duration: 0.341s, episode steps: 7, steps per second: 21, episode reward: 1.581, mean reward: 0.226 [0.002, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.000 [4.000, 10.000], loss: 0.002501, mae: 0.025178, mean_q: 0.023007
 43859/100000: episode: 6078, duration: 0.063s, episode steps: 8, steps per second: 127, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.002514, mae: 0.031631, mean_q: 0.029449
 43867/100000: episode: 6079, duration: 0.062s, episode steps: 8, steps per second: 130, episode reward: 0.082, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000800, mae: 0.023121, mean_q: 0.029869
 43875/100000: episode: 6080, duration: 0.053s, episode steps: 8, steps per second: 152, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.000577, mae: 0.015874, mean_q: 0.017888
 43883/100000: episode: 6081, duration: 0.053s, episode steps: 8, steps per second: 151, episode reward: 0.146, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.001445, mae: 0.023443, mean_q: 0.034698
 43891/100000: episode: 6082, duration: 0.067s, episode steps: 8, steps per second: 120, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.812 [-1.000, 11.000], loss: 0.002204, mae: 0.024431, mean_q: 0.028087
 43899/100000: episode: 6083, duration: 0.077s, episode steps: 8, steps per second: 104, episode reward: 0.036, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.001844, mae: 0.026985, mean_q: 0.020821
 43907/100000: episode: 6084, duration: 0.048s, episode steps: 8, steps per second: 167, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001082, mae: 0.024178, mean_q: 0.021685
 43915/100000: episode: 6085, duration: 0.047s, episode steps: 8, steps per second: 170, episode reward: 0.022, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.001012, mae: 0.023747, mean_q: 0.030663
 43923/100000: episode: 6086, duration: 0.070s, episode steps: 8, steps per second: 114, episode reward: 0.036, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.001519, mae: 0.026904, mean_q: 0.035562
 43931/100000: episode: 6087, duration: 0.120s, episode steps: 8, steps per second: 66, episode reward: 0.146, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000947, mae: 0.021178, mean_q: 0.022708
 43939/100000: episode: 6088, duration: 0.090s, episode steps: 8, steps per second: 89, episode reward: 0.146, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000800, mae: 0.019063, mean_q: 0.022165
 43947/100000: episode: 6089, duration: 0.079s, episode steps: 8, steps per second: 101, episode reward: 0.032, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000827, mae: 0.018464, mean_q: 0.023399
 43955/100000: episode: 6090, duration: 0.071s, episode steps: 8, steps per second: 112, episode reward: 0.098, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000517, mae: 0.016640, mean_q: 0.020205
 43963/100000: episode: 6091, duration: 0.076s, episode steps: 8, steps per second: 105, episode reward: 0.039, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001610, mae: 0.027508, mean_q: 0.029122
 43971/100000: episode: 6092, duration: 0.078s, episode steps: 8, steps per second: 102, episode reward: 0.015, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000745, mae: 0.018176, mean_q: 0.021887
 43979/100000: episode: 6093, duration: 0.084s, episode steps: 8, steps per second: 96, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.002379, mae: 0.027776, mean_q: 0.032410
 43987/100000: episode: 6094, duration: 0.082s, episode steps: 8, steps per second: 97, episode reward: 0.102, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.001579, mae: 0.026476, mean_q: 0.040968
 43995/100000: episode: 6095, duration: 0.080s, episode steps: 8, steps per second: 100, episode reward: 0.022, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.002581, mae: 0.023973, mean_q: 0.031574
 44003/100000: episode: 6096, duration: 0.071s, episode steps: 8, steps per second: 113, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.001482, mae: 0.025812, mean_q: 0.029461
 44011/100000: episode: 6097, duration: 0.059s, episode steps: 8, steps per second: 135, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000976, mae: 0.020648, mean_q: 0.026346
 44019/100000: episode: 6098, duration: 0.052s, episode steps: 8, steps per second: 155, episode reward: 0.030, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.002425, mae: 0.029259, mean_q: 0.034410
 44027/100000: episode: 6099, duration: 0.050s, episode steps: 8, steps per second: 159, episode reward: 0.036, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.001480, mae: 0.031839, mean_q: 0.021840
 44035/100000: episode: 6100, duration: 0.050s, episode steps: 8, steps per second: 162, episode reward: 0.038, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.002223, mae: 0.028958, mean_q: 0.033219
 44043/100000: episode: 6101, duration: 0.042s, episode steps: 8, steps per second: 193, episode reward: 0.022, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.001224, mae: 0.025566, mean_q: 0.026739
 44051/100000: episode: 6102, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.130, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000763, mae: 0.018557, mean_q: 0.017426
 44059/100000: episode: 6103, duration: 0.041s, episode steps: 8, steps per second: 195, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.002542, mae: 0.030513, mean_q: 0.036833
 44067/100000: episode: 6104, duration: 0.048s, episode steps: 8, steps per second: 167, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001514, mae: 0.028929, mean_q: 0.030640
 44075/100000: episode: 6105, duration: 0.054s, episode steps: 8, steps per second: 149, episode reward: 0.038, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001212, mae: 0.023514, mean_q: 0.027982
 44083/100000: episode: 6106, duration: 0.052s, episode steps: 8, steps per second: 153, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.002193, mae: 0.021279, mean_q: 0.025087
 44091/100000: episode: 6107, duration: 0.064s, episode steps: 8, steps per second: 126, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000957, mae: 0.017620, mean_q: 0.021740
 44099/100000: episode: 6108, duration: 0.041s, episode steps: 8, steps per second: 197, episode reward: 0.059, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.001022, mae: 0.020064, mean_q: 0.025740
 44107/100000: episode: 6109, duration: 0.048s, episode steps: 8, steps per second: 167, episode reward: 0.020, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.001517, mae: 0.017357, mean_q: 0.022070
 44115/100000: episode: 6110, duration: 0.040s, episode steps: 8, steps per second: 202, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000952, mae: 0.018762, mean_q: 0.027672
 44123/100000: episode: 6111, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.001684, mae: 0.020694, mean_q: 0.019710
 44131/100000: episode: 6112, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.231, mean reward: 0.029 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.001334, mae: 0.026654, mean_q: 0.028608
 44139/100000: episode: 6113, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.067, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000513, mae: 0.016623, mean_q: 0.020320
 44147/100000: episode: 6114, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.020, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.003332, mae: 0.031419, mean_q: 0.035699
 44155/100000: episode: 6115, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.002266, mae: 0.033731, mean_q: 0.021884
 44163/100000: episode: 6116, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.065, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001272, mae: 0.030487, mean_q: 0.029220
 44171/100000: episode: 6117, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.033, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000867, mae: 0.025775, mean_q: 0.029868
 44179/100000: episode: 6118, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.002366, mae: 0.030692, mean_q: 0.031052
 44187/100000: episode: 6119, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.055, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000625, mae: 0.018897, mean_q: 0.013001
 44195/100000: episode: 6120, duration: 0.040s, episode steps: 8, steps per second: 201, episode reward: 0.214, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000517, mae: 0.013959, mean_q: 0.014422
 44203/100000: episode: 6121, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.177, mean reward: 0.022 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.001025, mae: 0.022649, mean_q: 0.031270
 44211/100000: episode: 6122, duration: 0.046s, episode steps: 8, steps per second: 173, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.001801, mae: 0.021206, mean_q: 0.024670
 44219/100000: episode: 6123, duration: 0.040s, episode steps: 8, steps per second: 200, episode reward: 0.036, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000796, mae: 0.018913, mean_q: 0.016642
 44227/100000: episode: 6124, duration: 0.040s, episode steps: 8, steps per second: 202, episode reward: 0.087, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.002938, mae: 0.033411, mean_q: 0.049060
 44235/100000: episode: 6125, duration: 0.039s, episode steps: 8, steps per second: 208, episode reward: 0.049, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001213, mae: 0.024230, mean_q: 0.024773
 44243/100000: episode: 6126, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.001006, mae: 0.021146, mean_q: 0.013374
 44251/100000: episode: 6127, duration: 0.051s, episode steps: 8, steps per second: 157, episode reward: 0.067, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.002337, mae: 0.029586, mean_q: 0.038179
 44259/100000: episode: 6128, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000946, mae: 0.022817, mean_q: 0.019226
 44267/100000: episode: 6129, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.098, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.002332, mae: 0.028060, mean_q: 0.029389
 44275/100000: episode: 6130, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.081, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.001059, mae: 0.024337, mean_q: 0.029887
 44283/100000: episode: 6131, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001093, mae: 0.023191, mean_q: 0.032856
 44291/100000: episode: 6132, duration: 0.040s, episode steps: 8, steps per second: 202, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001259, mae: 0.028412, mean_q: 0.030494
 44299/100000: episode: 6133, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.002148, mae: 0.029174, mean_q: 0.018116
 44307/100000: episode: 6134, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.001069, mae: 0.030513, mean_q: 0.016512
 44315/100000: episode: 6135, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000677, mae: 0.023011, mean_q: 0.028295
 44323/100000: episode: 6136, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.146, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.001496, mae: 0.021176, mean_q: 0.025012
 44331/100000: episode: 6137, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.036, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.001933, mae: 0.031705, mean_q: 0.022154
 44339/100000: episode: 6138, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.098, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000751, mae: 0.023430, mean_q: 0.019825
 44347/100000: episode: 6139, duration: 0.040s, episode steps: 8, steps per second: 202, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.001357, mae: 0.026367, mean_q: 0.027636
 44355/100000: episode: 6140, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.079, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001520, mae: 0.030101, mean_q: 0.037425
 44363/100000: episode: 6141, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.114, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000852, mae: 0.024774, mean_q: 0.029450
 44371/100000: episode: 6142, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.098, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.001108, mae: 0.027108, mean_q: 0.023913
 44379/100000: episode: 6143, duration: 0.040s, episode steps: 8, steps per second: 199, episode reward: 0.081, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.000906, mae: 0.021242, mean_q: 0.018404
 44387/100000: episode: 6144, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.102, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.001179, mae: 0.024975, mean_q: 0.033323
 44395/100000: episode: 6145, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.001229, mae: 0.022376, mean_q: 0.031778
 44403/100000: episode: 6146, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.030, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000833, mae: 0.017541, mean_q: 0.021542
 44411/100000: episode: 6147, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.082, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001458, mae: 0.022755, mean_q: 0.032803
 44419/100000: episode: 6148, duration: 0.043s, episode steps: 8, steps per second: 185, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.001072, mae: 0.020868, mean_q: 0.025678
 44427/100000: episode: 6149, duration: 0.040s, episode steps: 8, steps per second: 199, episode reward: 0.020, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000831, mae: 0.018802, mean_q: 0.022793
 44435/100000: episode: 6150, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.003427, mae: 0.025107, mean_q: 0.026440
 44443/100000: episode: 6151, duration: 0.040s, episode steps: 8, steps per second: 199, episode reward: 0.013, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.001643, mae: 0.022657, mean_q: 0.022859
 44451/100000: episode: 6152, duration: 0.050s, episode steps: 8, steps per second: 160, episode reward: 0.134, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001073, mae: 0.020162, mean_q: 0.028499
 44459/100000: episode: 6153, duration: 0.049s, episode steps: 8, steps per second: 162, episode reward: 0.035, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000843, mae: 0.015978, mean_q: 0.020236
 44467/100000: episode: 6154, duration: 0.043s, episode steps: 8, steps per second: 185, episode reward: 0.028, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000846, mae: 0.016890, mean_q: 0.019269
 44475/100000: episode: 6155, duration: 0.040s, episode steps: 8, steps per second: 200, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.001570, mae: 0.025484, mean_q: 0.036656
 44483/100000: episode: 6156, duration: 0.041s, episode steps: 8, steps per second: 193, episode reward: 0.035, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001148, mae: 0.025871, mean_q: 0.023895
 44491/100000: episode: 6157, duration: 0.042s, episode steps: 8, steps per second: 190, episode reward: 0.055, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001619, mae: 0.025912, mean_q: 0.021293
 44499/100000: episode: 6158, duration: 0.041s, episode steps: 8, steps per second: 196, episode reward: 0.032, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001027, mae: 0.023624, mean_q: 0.017452
[Info] Complete ISplit Iteration
[Info] Levels: [0.0072470903, 0.7884941]
[Info] Cond. Prob: [0.13, 0.01]
[Info] Error Prob: 0.0013000000000000002

 44507/100000: episode: 6159, duration: 0.952s, episode steps: 8, steps per second: 8, episode reward: 0.348, mean reward: 0.044 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001192, mae: 0.025942, mean_q: 0.033479
 44517/100000: episode: 6160, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002026, mae: 0.028342, mean_q: 0.028150
 44527/100000: episode: 6161, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000899, mae: 0.023042, mean_q: 0.024653
 44537/100000: episode: 6162, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000655, mae: 0.014132, mean_q: 0.016883
 44547/100000: episode: 6163, duration: 0.101s, episode steps: 10, steps per second: 99, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001688, mae: 0.020385, mean_q: 0.022240
 44557/100000: episode: 6164, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001019, mae: 0.025479, mean_q: 0.027713
 44567/100000: episode: 6165, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000620, mae: 0.020565, mean_q: 0.020096
 44577/100000: episode: 6166, duration: 0.101s, episode steps: 10, steps per second: 99, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000540, mae: 0.018306, mean_q: 0.016601
 44587/100000: episode: 6167, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000498, mae: 0.014006, mean_q: 0.016901
 44597/100000: episode: 6168, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001545, mae: 0.021629, mean_q: 0.022837
 44607/100000: episode: 6169, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000719, mae: 0.023031, mean_q: 0.021981
 44617/100000: episode: 6170, duration: 0.088s, episode steps: 10, steps per second: 113, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000885, mae: 0.022757, mean_q: 0.030004
 44627/100000: episode: 6171, duration: 0.066s, episode steps: 10, steps per second: 150, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000985, mae: 0.021553, mean_q: 0.028179
 44637/100000: episode: 6172, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001867, mae: 0.022621, mean_q: 0.025915
 44647/100000: episode: 6173, duration: 0.084s, episode steps: 10, steps per second: 120, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001792, mae: 0.024748, mean_q: 0.026861
 44657/100000: episode: 6174, duration: 0.104s, episode steps: 10, steps per second: 96, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001164, mae: 0.020621, mean_q: 0.027237
 44667/100000: episode: 6175, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.001222, mae: 0.020864, mean_q: 0.029756
 44677/100000: episode: 6176, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001611, mae: 0.021615, mean_q: 0.021908
 44687/100000: episode: 6177, duration: 0.114s, episode steps: 10, steps per second: 88, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001225, mae: 0.024650, mean_q: 0.033630
 44697/100000: episode: 6178, duration: 0.101s, episode steps: 10, steps per second: 99, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001738, mae: 0.026258, mean_q: 0.031189
 44707/100000: episode: 6179, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000818, mae: 0.020506, mean_q: 0.023575
 44717/100000: episode: 6180, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000877, mae: 0.023029, mean_q: 0.026741
 44727/100000: episode: 6181, duration: 0.112s, episode steps: 10, steps per second: 89, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001132, mae: 0.022962, mean_q: 0.028482
 44737/100000: episode: 6182, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000727, mae: 0.020119, mean_q: 0.023040
 44747/100000: episode: 6183, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000603, mae: 0.017232, mean_q: 0.021214
 44757/100000: episode: 6184, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000923, mae: 0.020196, mean_q: 0.022262
 44767/100000: episode: 6185, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000781, mae: 0.020465, mean_q: 0.023752
 44777/100000: episode: 6186, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000875, mae: 0.021750, mean_q: 0.025269
 44787/100000: episode: 6187, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000906, mae: 0.021995, mean_q: 0.023207
 44797/100000: episode: 6188, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001758, mae: 0.022251, mean_q: 0.024025
 44807/100000: episode: 6189, duration: 0.072s, episode steps: 10, steps per second: 138, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001441, mae: 0.020848, mean_q: 0.023229
 44817/100000: episode: 6190, duration: 0.127s, episode steps: 10, steps per second: 79, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002227, mae: 0.032897, mean_q: 0.028398
 44827/100000: episode: 6191, duration: 0.108s, episode steps: 10, steps per second: 92, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.002088, mae: 0.032805, mean_q: 0.023287
 44837/100000: episode: 6192, duration: 0.083s, episode steps: 10, steps per second: 120, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002425, mae: 0.032649, mean_q: 0.036209
 44847/100000: episode: 6193, duration: 0.071s, episode steps: 10, steps per second: 140, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001038, mae: 0.022716, mean_q: 0.022361
 44857/100000: episode: 6194, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001194, mae: 0.021789, mean_q: 0.024342
 44867/100000: episode: 6195, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002813, mae: 0.029317, mean_q: 0.028441
 44877/100000: episode: 6196, duration: 0.071s, episode steps: 10, steps per second: 140, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000616, mae: 0.019677, mean_q: 0.016312
 44887/100000: episode: 6197, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002060, mae: 0.026821, mean_q: 0.027628
 44897/100000: episode: 6198, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000711, mae: 0.019083, mean_q: 0.020271
 44907/100000: episode: 6199, duration: 0.072s, episode steps: 10, steps per second: 140, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000997, mae: 0.016462, mean_q: 0.024255
 44917/100000: episode: 6200, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001076, mae: 0.021780, mean_q: 0.030039
 44927/100000: episode: 6201, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000886, mae: 0.019257, mean_q: 0.024512
 44937/100000: episode: 6202, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000777, mae: 0.017303, mean_q: 0.023699
 44947/100000: episode: 6203, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000947, mae: 0.019635, mean_q: 0.028705
 44957/100000: episode: 6204, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000438, mae: 0.013166, mean_q: 0.015537
 44967/100000: episode: 6205, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.002025, mae: 0.024741, mean_q: 0.028111
 44977/100000: episode: 6206, duration: 0.081s, episode steps: 10, steps per second: 124, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000789, mae: 0.017760, mean_q: 0.026479
 44987/100000: episode: 6207, duration: 0.068s, episode steps: 10, steps per second: 146, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000773, mae: 0.016223, mean_q: 0.017445
 44997/100000: episode: 6208, duration: 0.068s, episode steps: 10, steps per second: 146, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000470, mae: 0.016942, mean_q: 0.020347
 45007/100000: episode: 6209, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000570, mae: 0.018477, mean_q: 0.019644
 45017/100000: episode: 6210, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001032, mae: 0.019283, mean_q: 0.024613
 45027/100000: episode: 6211, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002048, mae: 0.027094, mean_q: 0.027708
 45037/100000: episode: 6212, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001054, mae: 0.023766, mean_q: 0.023797
 45047/100000: episode: 6213, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000552, mae: 0.014442, mean_q: 0.011320
 45057/100000: episode: 6214, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000758, mae: 0.018793, mean_q: 0.026326
 45067/100000: episode: 6215, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001511, mae: 0.022555, mean_q: 0.023180
 45077/100000: episode: 6216, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000996, mae: 0.018745, mean_q: 0.024582
 45087/100000: episode: 6217, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000490, mae: 0.012975, mean_q: 0.013769
 45097/100000: episode: 6218, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000788, mae: 0.019379, mean_q: 0.021217
 45107/100000: episode: 6219, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001193, mae: 0.021568, mean_q: 0.023337
 45117/100000: episode: 6220, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001457, mae: 0.019283, mean_q: 0.025735
 45127/100000: episode: 6221, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000998, mae: 0.020788, mean_q: 0.017996
 45137/100000: episode: 6222, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000975, mae: 0.021086, mean_q: 0.024456
 45147/100000: episode: 6223, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000499, mae: 0.015986, mean_q: 0.015645
 45157/100000: episode: 6224, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000692, mae: 0.015237, mean_q: 0.021428
 45167/100000: episode: 6225, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000486, mae: 0.014794, mean_q: 0.019315
 45177/100000: episode: 6226, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001932, mae: 0.024266, mean_q: 0.032143
 45187/100000: episode: 6227, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000431, mae: 0.011971, mean_q: 0.013137
 45197/100000: episode: 6228, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000496, mae: 0.014128, mean_q: 0.019670
 45207/100000: episode: 6229, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000500, mae: 0.013759, mean_q: 0.019756
 45217/100000: episode: 6230, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000651, mae: 0.015898, mean_q: 0.020233
 45227/100000: episode: 6231, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000627, mae: 0.014476, mean_q: 0.018648
 45237/100000: episode: 6232, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000781, mae: 0.014082, mean_q: 0.020355
 45247/100000: episode: 6233, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000553, mae: 0.013924, mean_q: 0.013134
 45257/100000: episode: 6234, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000333, mae: 0.011251, mean_q: 0.015706
 45267/100000: episode: 6235, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000556, mae: 0.013098, mean_q: 0.014134
 45277/100000: episode: 6236, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000482, mae: 0.012826, mean_q: 0.014387
 45287/100000: episode: 6237, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000631, mae: 0.021644, mean_q: 0.014742
 45297/100000: episode: 6238, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000303, mae: 0.018258, mean_q: 0.012014
 45307/100000: episode: 6239, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000440, mae: 0.013779, mean_q: 0.014968
 45317/100000: episode: 6240, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000477, mae: 0.014001, mean_q: 0.016953
 45327/100000: episode: 6241, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000398, mae: 0.012339, mean_q: 0.014780
 45337/100000: episode: 6242, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000331, mae: 0.010138, mean_q: 0.016379
 45347/100000: episode: 6243, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000368, mae: 0.012222, mean_q: 0.019673
 45357/100000: episode: 6244, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000429, mae: 0.011828, mean_q: 0.015089
 45367/100000: episode: 6245, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000466, mae: 0.011001, mean_q: 0.012661
 45377/100000: episode: 6246, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000353, mae: 0.012503, mean_q: 0.015167
 45387/100000: episode: 6247, duration: 0.055s, episode steps: 10, steps per second: 180, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000584, mae: 0.017732, mean_q: 0.019938
 45397/100000: episode: 6248, duration: 0.081s, episode steps: 10, steps per second: 124, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000435, mae: 0.017363, mean_q: 0.019776
 45407/100000: episode: 6249, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000218, mae: 0.010145, mean_q: 0.013600
 45417/100000: episode: 6250, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000510, mae: 0.011543, mean_q: 0.014081
 45427/100000: episode: 6251, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000309, mae: 0.012301, mean_q: 0.012194
 45437/100000: episode: 6252, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000376, mae: 0.012230, mean_q: 0.016054
 45447/100000: episode: 6253, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000298, mae: 0.010612, mean_q: 0.014425
 45457/100000: episode: 6254, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000474, mae: 0.012047, mean_q: 0.016097
 45467/100000: episode: 6255, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000699, mae: 0.014198, mean_q: 0.020296
 45477/100000: episode: 6256, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000366, mae: 0.013230, mean_q: 0.013322
 45487/100000: episode: 6257, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000863, mae: 0.017342, mean_q: 0.018021
 45497/100000: episode: 6258, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000310, mae: 0.013148, mean_q: 0.013234
[Info] 1-TH LEVEL FOUND: 0.019981414079666138, Considering 13/100 traces
 45507/100000: episode: 6259, duration: 0.868s, episode steps: 10, steps per second: 12, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000255, mae: 0.010424, mean_q: 0.014551
 45514/100000: episode: 6260, duration: 0.043s, episode steps: 7, steps per second: 165, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000249, mae: 0.009373, mean_q: 0.010872
 45516/100000: episode: 6261, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000044, mae: 0.005923, mean_q: 0.010868
 45523/100000: episode: 6262, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000653, mae: 0.009247, mean_q: 0.010853
 45527/100000: episode: 6263, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000721, mae: 0.014326, mean_q: 0.020652
 45531/100000: episode: 6264, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000686, mae: 0.015544, mean_q: 0.020020
 45538/100000: episode: 6265, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000254, mae: 0.011041, mean_q: 0.011570
 45542/100000: episode: 6266, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000495, mae: 0.011561, mean_q: 0.017773
 45546/100000: episode: 6267, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000451, mae: 0.012843, mean_q: 0.015784
 45548/100000: episode: 6268, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000671, mae: 0.015029, mean_q: 0.018094
 45550/100000: episode: 6269, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000124, mae: 0.007983, mean_q: 0.008107
 45552/100000: episode: 6270, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000360, mae: 0.012736, mean_q: 0.016944
 45554/100000: episode: 6271, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000575, mae: 0.015020, mean_q: 0.022770
 45556/100000: episode: 6272, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000877, mae: 0.018219, mean_q: 0.011227
 45558/100000: episode: 6273, duration: 0.014s, episode steps: 2, steps per second: 144, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002088, mae: 0.021299, mean_q: 0.027902
 45565/100000: episode: 6274, duration: 0.038s, episode steps: 7, steps per second: 182, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000439, mae: 0.014867, mean_q: 0.014499
 45572/100000: episode: 6275, duration: 0.041s, episode steps: 7, steps per second: 169, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001043, mae: 0.023467, mean_q: 0.032327
 45574/100000: episode: 6276, duration: 0.015s, episode steps: 2, steps per second: 131, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000541, mae: 0.025579, mean_q: -0.009607
 45578/100000: episode: 6277, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000383, mae: 0.016767, mean_q: 0.028933
 45580/100000: episode: 6278, duration: 0.016s, episode steps: 2, steps per second: 124, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000412, mae: 0.014213, mean_q: 0.012634
 45587/100000: episode: 6279, duration: 0.040s, episode steps: 7, steps per second: 174, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002110, mae: 0.020254, mean_q: 0.017429
 45589/100000: episode: 6280, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000718, mae: 0.021763, mean_q: 0.032756
 45596/100000: episode: 6281, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000323, mae: 0.016167, mean_q: 0.003704
 45603/100000: episode: 6282, duration: 0.039s, episode steps: 7, steps per second: 182, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001882, mae: 0.019771, mean_q: 0.024016
 45607/100000: episode: 6283, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002406, mae: 0.021522, mean_q: 0.019337
 45609/100000: episode: 6284, duration: 0.015s, episode steps: 2, steps per second: 131, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001065, mae: 0.028583, mean_q: 0.039072
 45611/100000: episode: 6285, duration: 0.016s, episode steps: 2, steps per second: 124, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000257, mae: 0.016090, mean_q: 0.011659
[Info] FALSIFICATION!
 45617/100000: episode: 6286, duration: 0.212s, episode steps: 6, steps per second: 28, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000507, mae: 0.016812, mean_q: 0.011467
 45624/100000: episode: 6287, duration: 0.057s, episode steps: 7, steps per second: 124, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000572, mae: 0.016808, mean_q: 0.012114
 45626/100000: episode: 6288, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001056, mae: 0.020602, mean_q: 0.028265
 45630/100000: episode: 6289, duration: 0.027s, episode steps: 4, steps per second: 147, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001002, mae: 0.020256, mean_q: 0.014611
 45632/100000: episode: 6290, duration: 0.015s, episode steps: 2, steps per second: 130, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001328, mae: 0.024789, mean_q: 0.039592
 45636/100000: episode: 6291, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000585, mae: 0.016794, mean_q: 0.014765
 45640/100000: episode: 6292, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000614, mae: 0.015915, mean_q: 0.020389
 45647/100000: episode: 6293, duration: 0.039s, episode steps: 7, steps per second: 179, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000505, mae: 0.015196, mean_q: 0.012247
 45649/100000: episode: 6294, duration: 0.015s, episode steps: 2, steps per second: 132, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000453, mae: 0.020040, mean_q: 0.026911
 45651/100000: episode: 6295, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000310, mae: 0.012305, mean_q: 0.016973
 45655/100000: episode: 6296, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000453, mae: 0.016693, mean_q: 0.011930
 45659/100000: episode: 6297, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000227, mae: 0.010229, mean_q: 0.012315
 45661/100000: episode: 6298, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000587, mae: 0.016699, mean_q: 0.021633
 45663/100000: episode: 6299, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000436, mae: 0.014255, mean_q: 0.005732
 45665/100000: episode: 6300, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000353, mae: 0.014301, mean_q: 0.019154
 45672/100000: episode: 6301, duration: 0.038s, episode steps: 7, steps per second: 182, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000482, mae: 0.013526, mean_q: 0.015003
 45679/100000: episode: 6302, duration: 0.037s, episode steps: 7, steps per second: 189, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000175, mae: 0.008372, mean_q: 0.010446
 45683/100000: episode: 6303, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000546, mae: 0.013651, mean_q: 0.024935
 45687/100000: episode: 6304, duration: 0.023s, episode steps: 4, steps per second: 170, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000648, mae: 0.016646, mean_q: 0.013119
 45689/100000: episode: 6305, duration: 0.015s, episode steps: 2, steps per second: 135, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000264, mae: 0.011450, mean_q: 0.017017
 45696/100000: episode: 6306, duration: 0.041s, episode steps: 7, steps per second: 171, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000546, mae: 0.013324, mean_q: 0.015483
 45700/100000: episode: 6307, duration: 0.025s, episode steps: 4, steps per second: 157, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000841, mae: 0.018420, mean_q: 0.013251
 45707/100000: episode: 6308, duration: 0.042s, episode steps: 7, steps per second: 168, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000503, mae: 0.014601, mean_q: 0.020525
 45711/100000: episode: 6309, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000234, mae: 0.011877, mean_q: 0.014370
 45713/100000: episode: 6310, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000322, mae: 0.012331, mean_q: 0.014712
 45717/100000: episode: 6311, duration: 0.027s, episode steps: 4, steps per second: 150, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000361, mae: 0.012742, mean_q: 0.014419
 45719/100000: episode: 6312, duration: 0.014s, episode steps: 2, steps per second: 139, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000642, mae: 0.013503, mean_q: 0.025120
 45721/100000: episode: 6313, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000411, mae: 0.011789, mean_q: 0.013373
 45725/100000: episode: 6314, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000441, mae: 0.012555, mean_q: 0.018212
 45727/100000: episode: 6315, duration: 0.014s, episode steps: 2, steps per second: 139, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000316, mae: 0.012052, mean_q: 0.015990
 45734/100000: episode: 6316, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001035, mae: 0.021376, mean_q: 0.022750
 45741/100000: episode: 6317, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000892, mae: 0.020151, mean_q: 0.021025
 45743/100000: episode: 6318, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000517, mae: 0.014531, mean_q: 0.020752
 45745/100000: episode: 6319, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000459, mae: 0.018009, mean_q: 0.009667
 45747/100000: episode: 6320, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000272, mae: 0.013284, mean_q: 0.018260
 45749/100000: episode: 6321, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000287, mae: 0.011205, mean_q: 0.016089
 45753/100000: episode: 6322, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000532, mae: 0.016630, mean_q: 0.018516
 45757/100000: episode: 6323, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000397, mae: 0.015485, mean_q: 0.024411
 45759/100000: episode: 6324, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000523, mae: 0.016020, mean_q: 0.005856
[Info] FALSIFICATION!
 45765/100000: episode: 6325, duration: 0.274s, episode steps: 6, steps per second: 22, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.002169, mae: 0.021961, mean_q: 0.027149
 45772/100000: episode: 6326, duration: 0.040s, episode steps: 7, steps per second: 176, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000987, mae: 0.021672, mean_q: 0.025659
 45776/100000: episode: 6327, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000509, mae: 0.018073, mean_q: 0.006458
 45783/100000: episode: 6328, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000678, mae: 0.017364, mean_q: 0.023703
 45787/100000: episode: 6329, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001069, mae: 0.018679, mean_q: 0.027992
 45791/100000: episode: 6330, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000594, mae: 0.015940, mean_q: 0.024189
 45793/100000: episode: 6331, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000777, mae: 0.016925, mean_q: 0.023777
 45795/100000: episode: 6332, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000308, mae: 0.011621, mean_q: 0.011835
 45797/100000: episode: 6333, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000529, mae: 0.013135, mean_q: 0.017225
 45801/100000: episode: 6334, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000750, mae: 0.013637, mean_q: 0.019333
 45803/100000: episode: 6335, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001248, mae: 0.022213, mean_q: 0.023745
 45807/100000: episode: 6336, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001268, mae: 0.020204, mean_q: 0.032931
 45811/100000: episode: 6337, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000285, mae: 0.013662, mean_q: 0.015015
 45818/100000: episode: 6338, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000664, mae: 0.018474, mean_q: 0.015767
 45820/100000: episode: 6339, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000491, mae: 0.018346, mean_q: 0.021217
 45827/100000: episode: 6340, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000317, mae: 0.014081, mean_q: 0.012181
 45834/100000: episode: 6341, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000709, mae: 0.017526, mean_q: 0.019019
 45836/100000: episode: 6342, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000319, mae: 0.012390, mean_q: 0.012764
 45840/100000: episode: 6343, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000620, mae: 0.018556, mean_q: 0.026173
 45842/100000: episode: 6344, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000338, mae: 0.015180, mean_q: 0.006234
 45846/100000: episode: 6345, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000729, mae: 0.020676, mean_q: 0.026678
[Info] Complete ISplit Iteration
[Info] Levels: [0.019981414, 0.77805066]
[Info] Cond. Prob: [0.13, 0.02]
[Info] Error Prob: 0.0026000000000000003

 45850/100000: episode: 6346, duration: 0.994s, episode steps: 4, steps per second: 4, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000311, mae: 0.013603, mean_q: 0.013766
 45860/100000: episode: 6347, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000267, mae: 0.014178, mean_q: 0.016699
 45870/100000: episode: 6348, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000732, mae: 0.018015, mean_q: 0.021135
 45880/100000: episode: 6349, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000550, mae: 0.017402, mean_q: 0.019361
 45890/100000: episode: 6350, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001253, mae: 0.016197, mean_q: 0.020528
 45900/100000: episode: 6351, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000749, mae: 0.019283, mean_q: 0.024203
 45910/100000: episode: 6352, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001142, mae: 0.023914, mean_q: 0.024561
 45920/100000: episode: 6353, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000640, mae: 0.013354, mean_q: 0.018977
 45930/100000: episode: 6354, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001280, mae: 0.019354, mean_q: 0.017410
 45940/100000: episode: 6355, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000762, mae: 0.018998, mean_q: 0.021416
 45950/100000: episode: 6356, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001553, mae: 0.019447, mean_q: 0.021116
 45960/100000: episode: 6357, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000419, mae: 0.016981, mean_q: 0.015986
 45970/100000: episode: 6358, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000489, mae: 0.012524, mean_q: 0.013974
 45980/100000: episode: 6359, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000465, mae: 0.016147, mean_q: 0.016452
 45990/100000: episode: 6360, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000668, mae: 0.015704, mean_q: 0.022444
 46000/100000: episode: 6361, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000620, mae: 0.014641, mean_q: 0.022225
 46010/100000: episode: 6362, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000576, mae: 0.014836, mean_q: 0.021913
 46020/100000: episode: 6363, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001173, mae: 0.016752, mean_q: 0.019942
 46030/100000: episode: 6364, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000641, mae: 0.020158, mean_q: 0.017338
 46040/100000: episode: 6365, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000487, mae: 0.014067, mean_q: 0.015398
 46050/100000: episode: 6366, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000500, mae: 0.016411, mean_q: 0.018757
 46060/100000: episode: 6367, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000667, mae: 0.018545, mean_q: 0.020465
 46070/100000: episode: 6368, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000461, mae: 0.016024, mean_q: 0.022834
 46080/100000: episode: 6369, duration: 0.060s, episode steps: 10, steps per second: 165, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000738, mae: 0.019919, mean_q: 0.019660
 46090/100000: episode: 6370, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000485, mae: 0.016786, mean_q: 0.017954
 46100/100000: episode: 6371, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000584, mae: 0.018638, mean_q: 0.017502
 46110/100000: episode: 6372, duration: 0.063s, episode steps: 10, steps per second: 157, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000347, mae: 0.013888, mean_q: 0.012703
 46120/100000: episode: 6373, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000707, mae: 0.014862, mean_q: 0.019685
 46130/100000: episode: 6374, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000462, mae: 0.014953, mean_q: 0.017315
 46140/100000: episode: 6375, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000530, mae: 0.017004, mean_q: 0.017003
 46150/100000: episode: 6376, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000595, mae: 0.014203, mean_q: 0.016640
 46160/100000: episode: 6377, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000442, mae: 0.013339, mean_q: 0.016403
 46170/100000: episode: 6378, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001730, mae: 0.020804, mean_q: 0.021055
 46180/100000: episode: 6379, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000661, mae: 0.014690, mean_q: 0.020709
 46190/100000: episode: 6380, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001536, mae: 0.018692, mean_q: 0.023243
 46200/100000: episode: 6381, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000652, mae: 0.016788, mean_q: 0.022777
 46210/100000: episode: 6382, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000729, mae: 0.022394, mean_q: 0.021087
 46220/100000: episode: 6383, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000855, mae: 0.022656, mean_q: 0.019010
 46230/100000: episode: 6384, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001677, mae: 0.020525, mean_q: 0.023628
 46240/100000: episode: 6385, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000719, mae: 0.018879, mean_q: 0.017932
 46250/100000: episode: 6386, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000572, mae: 0.016337, mean_q: 0.021310
 46260/100000: episode: 6387, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000869, mae: 0.020440, mean_q: 0.023309
 46270/100000: episode: 6388, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000436, mae: 0.016687, mean_q: 0.012667
 46280/100000: episode: 6389, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000369, mae: 0.013786, mean_q: 0.012882
 46290/100000: episode: 6390, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000326, mae: 0.012624, mean_q: 0.015322
 46300/100000: episode: 6391, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000562, mae: 0.014319, mean_q: 0.016249
 46310/100000: episode: 6392, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000566, mae: 0.018342, mean_q: 0.018545
 46320/100000: episode: 6393, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000597, mae: 0.017408, mean_q: 0.018905
 46330/100000: episode: 6394, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000588, mae: 0.016295, mean_q: 0.016513
 46340/100000: episode: 6395, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000614, mae: 0.018004, mean_q: 0.019073
 46350/100000: episode: 6396, duration: 0.064s, episode steps: 10, steps per second: 155, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000558, mae: 0.013938, mean_q: 0.015317
 46360/100000: episode: 6397, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001938, mae: 0.025760, mean_q: 0.021064
 46370/100000: episode: 6398, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000726, mae: 0.019475, mean_q: 0.019736
 46380/100000: episode: 6399, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000753, mae: 0.016553, mean_q: 0.019268
 46390/100000: episode: 6400, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001417, mae: 0.017026, mean_q: 0.021851
 46400/100000: episode: 6401, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000594, mae: 0.014727, mean_q: 0.018527
 46410/100000: episode: 6402, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000596, mae: 0.015638, mean_q: 0.020712
 46420/100000: episode: 6403, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000361, mae: 0.011991, mean_q: 0.013280
 46430/100000: episode: 6404, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000512, mae: 0.016638, mean_q: 0.017821
 46440/100000: episode: 6405, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000693, mae: 0.016280, mean_q: 0.016258
 46450/100000: episode: 6406, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000479, mae: 0.019287, mean_q: 0.017108
 46460/100000: episode: 6407, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001357, mae: 0.027416, mean_q: 0.017088
 46470/100000: episode: 6408, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001175, mae: 0.030410, mean_q: 0.019705
 46480/100000: episode: 6409, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000935, mae: 0.023093, mean_q: 0.016565
 46490/100000: episode: 6410, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001065, mae: 0.025981, mean_q: 0.020230
 46500/100000: episode: 6411, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000491, mae: 0.016646, mean_q: 0.018014
 46510/100000: episode: 6412, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000625, mae: 0.014114, mean_q: 0.014776
 46520/100000: episode: 6413, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000539, mae: 0.013688, mean_q: 0.019256
 46530/100000: episode: 6414, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000743, mae: 0.019023, mean_q: 0.018514
 46540/100000: episode: 6415, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000560, mae: 0.017209, mean_q: 0.015060
 46550/100000: episode: 6416, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000507, mae: 0.014529, mean_q: 0.017508
 46560/100000: episode: 6417, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001390, mae: 0.018480, mean_q: 0.022082
 46570/100000: episode: 6418, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000659, mae: 0.017355, mean_q: 0.014347
 46580/100000: episode: 6419, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000990, mae: 0.019925, mean_q: 0.022751
 46590/100000: episode: 6420, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000602, mae: 0.017900, mean_q: 0.017352
 46600/100000: episode: 6421, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000580, mae: 0.015430, mean_q: 0.020078
 46610/100000: episode: 6422, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000924, mae: 0.016823, mean_q: 0.024296
 46620/100000: episode: 6423, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000549, mae: 0.014135, mean_q: 0.018613
 46630/100000: episode: 6424, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000789, mae: 0.019099, mean_q: 0.018458
 46640/100000: episode: 6425, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000906, mae: 0.018873, mean_q: 0.021882
 46650/100000: episode: 6426, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000675, mae: 0.014143, mean_q: 0.018315
 46660/100000: episode: 6427, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000427, mae: 0.012225, mean_q: 0.014810
 46670/100000: episode: 6428, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000814, mae: 0.018528, mean_q: 0.027129
 46680/100000: episode: 6429, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.001235, mae: 0.017568, mean_q: 0.016145
 46690/100000: episode: 6430, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002088, mae: 0.022197, mean_q: 0.021699
 46700/100000: episode: 6431, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000465, mae: 0.013517, mean_q: 0.014401
 46710/100000: episode: 6432, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000670, mae: 0.017287, mean_q: 0.016751
 46720/100000: episode: 6433, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000342, mae: 0.015302, mean_q: 0.014825
 46730/100000: episode: 6434, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000530, mae: 0.016762, mean_q: 0.014194
 46740/100000: episode: 6435, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000840, mae: 0.019112, mean_q: 0.020184
 46750/100000: episode: 6436, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000966, mae: 0.020443, mean_q: 0.028531
 46760/100000: episode: 6437, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000543, mae: 0.015646, mean_q: 0.020314
 46770/100000: episode: 6438, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000523, mae: 0.015772, mean_q: 0.014286
 46780/100000: episode: 6439, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000872, mae: 0.020372, mean_q: 0.019029
 46790/100000: episode: 6440, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000534, mae: 0.015111, mean_q: 0.015942
 46800/100000: episode: 6441, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000394, mae: 0.012700, mean_q: 0.011164
 46810/100000: episode: 6442, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000368, mae: 0.013034, mean_q: 0.015483
 46820/100000: episode: 6443, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000197, mae: 0.010768, mean_q: 0.010242
 46830/100000: episode: 6444, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000470, mae: 0.011544, mean_q: 0.014159
 46840/100000: episode: 6445, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001079, mae: 0.018224, mean_q: 0.021777
[Info] 1-TH LEVEL FOUND: 0.023455843329429626, Considering 100/100 traces
 46850/100000: episode: 6446, duration: 0.767s, episode steps: 10, steps per second: 13, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000477, mae: 0.012243, mean_q: 0.012422
[Info] 2-TH LEVEL FOUND: 0.032056763768196106, Considering 100/100 traces
 46851/100000: episode: 6447, duration: 0.730s, episode steps: 1, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000827, mae: 0.024822, mean_q: 0.016467
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.032056763768196106
 46852/100000: episode: 6448, duration: 0.435s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000207, mae: 0.014787, mean_q: 0.017348
 46862/100000: episode: 6449, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000308, mae: 0.011295, mean_q: 0.012879
 46872/100000: episode: 6450, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000854, mae: 0.015787, mean_q: 0.020747
 46882/100000: episode: 6451, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000423, mae: 0.014365, mean_q: 0.014743
 46892/100000: episode: 6452, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000528, mae: 0.014088, mean_q: 0.015773
 46902/100000: episode: 6453, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000876, mae: 0.016168, mean_q: 0.018479
 46912/100000: episode: 6454, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000495, mae: 0.016190, mean_q: 0.017241
 46922/100000: episode: 6455, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000385, mae: 0.013971, mean_q: 0.011090
 46932/100000: episode: 6456, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000275, mae: 0.011261, mean_q: 0.013932
 46942/100000: episode: 6457, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000334, mae: 0.011124, mean_q: 0.011103
 46952/100000: episode: 6458, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000416, mae: 0.012695, mean_q: 0.014677
 46962/100000: episode: 6459, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000471, mae: 0.012816, mean_q: 0.017863
 46972/100000: episode: 6460, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001197, mae: 0.016136, mean_q: 0.013712
 46982/100000: episode: 6461, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000250, mae: 0.012148, mean_q: 0.010919
 46992/100000: episode: 6462, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000182, mae: 0.009919, mean_q: 0.012038
 47002/100000: episode: 6463, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000554, mae: 0.012997, mean_q: 0.010845
 47012/100000: episode: 6464, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000229, mae: 0.011737, mean_q: 0.010925
 47022/100000: episode: 6465, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000275, mae: 0.011474, mean_q: 0.012259
 47032/100000: episode: 6466, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000272, mae: 0.008392, mean_q: 0.010237
 47042/100000: episode: 6467, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000208, mae: 0.010151, mean_q: 0.011315
 47052/100000: episode: 6468, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001214, mae: 0.012911, mean_q: 0.014554
 47062/100000: episode: 6469, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001423, mae: 0.016816, mean_q: 0.020091
 47072/100000: episode: 6470, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000426, mae: 0.013404, mean_q: 0.012785
 47082/100000: episode: 6471, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000460, mae: 0.012468, mean_q: 0.013448
 47092/100000: episode: 6472, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001037, mae: 0.015300, mean_q: 0.012046
 47102/100000: episode: 6473, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000374, mae: 0.014292, mean_q: 0.008936
 47112/100000: episode: 6474, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000525, mae: 0.011364, mean_q: 0.012425
 47122/100000: episode: 6475, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000577, mae: 0.014166, mean_q: 0.016856
 47132/100000: episode: 6476, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001158, mae: 0.015827, mean_q: 0.017806
 47142/100000: episode: 6477, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000404, mae: 0.011947, mean_q: 0.014938
 47152/100000: episode: 6478, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000267, mae: 0.009760, mean_q: 0.008936
 47162/100000: episode: 6479, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000208, mae: 0.009256, mean_q: 0.009588
 47172/100000: episode: 6480, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000324, mae: 0.009537, mean_q: 0.011724
 47182/100000: episode: 6481, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000323, mae: 0.009903, mean_q: 0.012083
 47192/100000: episode: 6482, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000304, mae: 0.009909, mean_q: 0.011861
 47202/100000: episode: 6483, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000226, mae: 0.011141, mean_q: 0.011582
 47212/100000: episode: 6484, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000137, mae: 0.009444, mean_q: 0.008479
 47222/100000: episode: 6485, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000252, mae: 0.010290, mean_q: 0.010653
 47232/100000: episode: 6486, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000095, mae: 0.008193, mean_q: 0.007522
 47242/100000: episode: 6487, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000109, mae: 0.008198, mean_q: 0.009325
 47252/100000: episode: 6488, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000119, mae: 0.006471, mean_q: 0.007139
 47262/100000: episode: 6489, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000224, mae: 0.007461, mean_q: 0.007742
 47272/100000: episode: 6490, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000484, mae: 0.011308, mean_q: 0.012200
 47282/100000: episode: 6491, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000169, mae: 0.011247, mean_q: 0.008769
 47292/100000: episode: 6492, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000115, mae: 0.008239, mean_q: 0.006245
 47302/100000: episode: 6493, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000472, mae: 0.012446, mean_q: 0.012602
 47312/100000: episode: 6494, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000139, mae: 0.008436, mean_q: 0.007834
 47322/100000: episode: 6495, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000125, mae: 0.008298, mean_q: 0.009042
 47332/100000: episode: 6496, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000119, mae: 0.007243, mean_q: 0.009958
 47342/100000: episode: 6497, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000246, mae: 0.008579, mean_q: 0.009688
 47352/100000: episode: 6498, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000124, mae: 0.007459, mean_q: 0.007567
 47362/100000: episode: 6499, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000146, mae: 0.006552, mean_q: 0.006710
 47372/100000: episode: 6500, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000419, mae: 0.010600, mean_q: 0.008910
 47382/100000: episode: 6501, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000291, mae: 0.012348, mean_q: 0.013850
 47392/100000: episode: 6502, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000055, mae: 0.005685, mean_q: 0.007490
 47402/100000: episode: 6503, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000274, mae: 0.008431, mean_q: 0.010906
 47412/100000: episode: 6504, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000098, mae: 0.007181, mean_q: 0.006863
 47422/100000: episode: 6505, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000055, mae: 0.005102, mean_q: 0.006107
 47432/100000: episode: 6506, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000132, mae: 0.006793, mean_q: 0.009478
 47442/100000: episode: 6507, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000073, mae: 0.005946, mean_q: 0.006498
 47452/100000: episode: 6508, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000209, mae: 0.007509, mean_q: 0.008328
 47462/100000: episode: 6509, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000201, mae: 0.007794, mean_q: 0.008502
 47472/100000: episode: 6510, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000082, mae: 0.006132, mean_q: 0.008344
 47482/100000: episode: 6511, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000132, mae: 0.006551, mean_q: 0.008119
 47492/100000: episode: 6512, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000099, mae: 0.006868, mean_q: 0.009264
 47502/100000: episode: 6513, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000571, mae: 0.010768, mean_q: 0.014133
 47512/100000: episode: 6514, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000133, mae: 0.008063, mean_q: 0.008403
 47522/100000: episode: 6515, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000177, mae: 0.008395, mean_q: 0.009394
 47532/100000: episode: 6516, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000651, mae: 0.011431, mean_q: 0.012482
 47542/100000: episode: 6517, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000354, mae: 0.009112, mean_q: 0.010842
 47552/100000: episode: 6518, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000274, mae: 0.008912, mean_q: 0.010858
 47562/100000: episode: 6519, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000072, mae: 0.006743, mean_q: 0.006577
 47572/100000: episode: 6520, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000347, mae: 0.009777, mean_q: 0.011435
 47582/100000: episode: 6521, duration: 0.091s, episode steps: 10, steps per second: 109, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000242, mae: 0.008991, mean_q: 0.010030
 47592/100000: episode: 6522, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000122, mae: 0.007277, mean_q: 0.007920
 47602/100000: episode: 6523, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000057, mae: 0.005290, mean_q: 0.007711
 47612/100000: episode: 6524, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000110, mae: 0.006253, mean_q: 0.007435
 47622/100000: episode: 6525, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000182, mae: 0.008216, mean_q: 0.009740
 47632/100000: episode: 6526, duration: 0.103s, episode steps: 10, steps per second: 97, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000108, mae: 0.006876, mean_q: 0.007376
 47642/100000: episode: 6527, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000105, mae: 0.006838, mean_q: 0.008957
 47652/100000: episode: 6528, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000249, mae: 0.008596, mean_q: 0.006828
 47662/100000: episode: 6529, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000225, mae: 0.009483, mean_q: 0.011447
 47672/100000: episode: 6530, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000143, mae: 0.008297, mean_q: 0.010216
 47682/100000: episode: 6531, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000447, mae: 0.011619, mean_q: 0.016632
 47692/100000: episode: 6532, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000234, mae: 0.008949, mean_q: 0.012255
 47702/100000: episode: 6533, duration: 0.088s, episode steps: 10, steps per second: 114, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000149, mae: 0.008442, mean_q: 0.009606
 47712/100000: episode: 6534, duration: 0.131s, episode steps: 10, steps per second: 77, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000188, mae: 0.008876, mean_q: 0.010657
 47722/100000: episode: 6535, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000390, mae: 0.010847, mean_q: 0.007767
 47732/100000: episode: 6536, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000347, mae: 0.009833, mean_q: 0.008048
 47742/100000: episode: 6537, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000301, mae: 0.011132, mean_q: 0.011570
 47752/100000: episode: 6538, duration: 0.089s, episode steps: 10, steps per second: 113, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000297, mae: 0.009706, mean_q: 0.008951
 47762/100000: episode: 6539, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000235, mae: 0.008172, mean_q: 0.008966
 47772/100000: episode: 6540, duration: 0.072s, episode steps: 10, steps per second: 138, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000185, mae: 0.009325, mean_q: 0.008168
 47782/100000: episode: 6541, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000184, mae: 0.007805, mean_q: 0.008504
 47792/100000: episode: 6542, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000112, mae: 0.007522, mean_q: 0.009181
 47802/100000: episode: 6543, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000380, mae: 0.010582, mean_q: 0.011804
 47812/100000: episode: 6544, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000555, mae: 0.011596, mean_q: 0.014044
 47822/100000: episode: 6545, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000283, mae: 0.016406, mean_q: 0.006550
 47832/100000: episode: 6546, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000508, mae: 0.016891, mean_q: 0.014002
 47842/100000: episode: 6547, duration: 0.074s, episode steps: 10, steps per second: 134, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000329, mae: 0.012489, mean_q: 0.011482
[Info] 1-TH LEVEL FOUND: 0.024653449654579163, Considering 10/100 traces
 47852/100000: episode: 6548, duration: 1.140s, episode steps: 10, steps per second: 9, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000324, mae: 0.015288, mean_q: 0.008837
 47858/100000: episode: 6549, duration: 0.034s, episode steps: 6, steps per second: 175, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000124, mae: 0.008647, mean_q: 0.007202
 47864/100000: episode: 6550, duration: 0.051s, episode steps: 6, steps per second: 118, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000225, mae: 0.012847, mean_q: 0.007302
 47868/100000: episode: 6551, duration: 0.031s, episode steps: 4, steps per second: 129, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000036, mae: 0.005335, mean_q: 0.007544
 47872/100000: episode: 6552, duration: 0.036s, episode steps: 4, steps per second: 112, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000070, mae: 0.006619, mean_q: 0.006116
 47878/100000: episode: 6553, duration: 0.052s, episode steps: 6, steps per second: 115, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000153, mae: 0.007684, mean_q: 0.009359
 47882/100000: episode: 6554, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000377, mae: 0.009592, mean_q: 0.017345
 47884/100000: episode: 6555, duration: 0.015s, episode steps: 2, steps per second: 131, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000147, mae: 0.008460, mean_q: 0.011366
 47886/100000: episode: 6556, duration: 0.020s, episode steps: 2, steps per second: 98, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000092, mae: 0.010111, mean_q: 0.001573
 47888/100000: episode: 6557, duration: 0.018s, episode steps: 2, steps per second: 111, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000058, mae: 0.006572, mean_q: 0.010104
 47890/100000: episode: 6558, duration: 0.018s, episode steps: 2, steps per second: 108, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000032, mae: 0.005556, mean_q: 0.009387
 47896/100000: episode: 6559, duration: 0.036s, episode steps: 6, steps per second: 166, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000172, mae: 0.010642, mean_q: 0.007576
 47902/100000: episode: 6560, duration: 0.033s, episode steps: 6, steps per second: 181, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000136, mae: 0.006571, mean_q: 0.006423
 47908/100000: episode: 6561, duration: 0.063s, episode steps: 6, steps per second: 96, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000170, mae: 0.009563, mean_q: 0.007587
 47912/100000: episode: 6562, duration: 0.053s, episode steps: 4, steps per second: 76, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000119, mae: 0.008068, mean_q: 0.011231
 47916/100000: episode: 6563, duration: 0.061s, episode steps: 4, steps per second: 66, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000072, mae: 0.005727, mean_q: 0.005204
 47922/100000: episode: 6564, duration: 0.055s, episode steps: 6, steps per second: 108, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000098, mae: 0.006448, mean_q: 0.008017
 47928/100000: episode: 6565, duration: 0.046s, episode steps: 6, steps per second: 132, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000480, mae: 0.009770, mean_q: 0.010737
 47932/100000: episode: 6566, duration: 0.038s, episode steps: 4, steps per second: 106, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000545, mae: 0.013720, mean_q: 0.014782
 47934/100000: episode: 6567, duration: 0.025s, episode steps: 2, steps per second: 81, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000140, mae: 0.012268, mean_q: 0.016783
 47938/100000: episode: 6568, duration: 0.039s, episode steps: 4, steps per second: 101, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000102, mae: 0.009453, mean_q: -0.001782
 47942/100000: episode: 6569, duration: 0.039s, episode steps: 4, steps per second: 101, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000238, mae: 0.010418, mean_q: 0.013219
 47948/100000: episode: 6570, duration: 0.041s, episode steps: 6, steps per second: 147, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000052, mae: 0.005408, mean_q: 0.005334
 47952/100000: episode: 6571, duration: 0.029s, episode steps: 4, steps per second: 137, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000109, mae: 0.006059, mean_q: 0.009506
 47958/100000: episode: 6572, duration: 0.046s, episode steps: 6, steps per second: 131, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000254, mae: 0.011358, mean_q: 0.004303
 47960/100000: episode: 6573, duration: 0.021s, episode steps: 2, steps per second: 97, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000132, mae: 0.013531, mean_q: 0.019095
 47966/100000: episode: 6574, duration: 0.033s, episode steps: 6, steps per second: 182, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000257, mae: 0.009159, mean_q: 0.006567
 47970/100000: episode: 6575, duration: 0.032s, episode steps: 4, steps per second: 124, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000196, mae: 0.007966, mean_q: 0.006257
 47972/100000: episode: 6576, duration: 0.019s, episode steps: 2, steps per second: 105, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000136, mae: 0.008442, mean_q: 0.010638
 47978/100000: episode: 6577, duration: 0.044s, episode steps: 6, steps per second: 137, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000143, mae: 0.010613, mean_q: 0.005909
 47984/100000: episode: 6578, duration: 0.047s, episode steps: 6, steps per second: 126, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000289, mae: 0.013052, mean_q: 0.014906
 47990/100000: episode: 6579, duration: 0.039s, episode steps: 6, steps per second: 152, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000286, mae: 0.009836, mean_q: 0.007938
 47994/100000: episode: 6580, duration: 0.052s, episode steps: 4, steps per second: 77, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000254, mae: 0.007913, mean_q: 0.002621
 48000/100000: episode: 6581, duration: 0.114s, episode steps: 6, steps per second: 53, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000339, mae: 0.014031, mean_q: 0.016768
 48004/100000: episode: 6582, duration: 0.056s, episode steps: 4, steps per second: 72, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000182, mae: 0.010559, mean_q: 0.008283
 48010/100000: episode: 6583, duration: 0.080s, episode steps: 6, steps per second: 75, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000170, mae: 0.010892, mean_q: 0.007276
 48014/100000: episode: 6584, duration: 0.048s, episode steps: 4, steps per second: 84, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000066, mae: 0.006918, mean_q: 0.011199
[Info] FALSIFICATION!
 48019/100000: episode: 6585, duration: 0.449s, episode steps: 5, steps per second: 11, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000077, mae: 0.006591, mean_q: 0.007331
 48021/100000: episode: 6586, duration: 0.032s, episode steps: 2, steps per second: 63, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000314, mae: 0.015780, mean_q: 0.023022
 48025/100000: episode: 6587, duration: 0.048s, episode steps: 4, steps per second: 83, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000201, mae: 0.011083, mean_q: 0.008460
 48029/100000: episode: 6588, duration: 0.051s, episode steps: 4, steps per second: 79, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000193, mae: 0.009770, mean_q: 0.013807
 48031/100000: episode: 6589, duration: 0.027s, episode steps: 2, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000121, mae: 0.006958, mean_q: 0.005868
 48037/100000: episode: 6590, duration: 0.052s, episode steps: 6, steps per second: 116, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000211, mae: 0.010761, mean_q: 0.011203
 48041/100000: episode: 6591, duration: 0.038s, episode steps: 4, steps per second: 107, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000203, mae: 0.009359, mean_q: 0.006428
 48047/100000: episode: 6592, duration: 0.060s, episode steps: 6, steps per second: 100, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000153, mae: 0.008837, mean_q: 0.012778
 48051/100000: episode: 6593, duration: 0.058s, episode steps: 4, steps per second: 69, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000457, mae: 0.011141, mean_q: 0.012989
[Info] FALSIFICATION!
 48056/100000: episode: 6594, duration: 0.424s, episode steps: 5, steps per second: 12, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000303, mae: 0.008783, mean_q: 0.014472
 48062/100000: episode: 6595, duration: 0.062s, episode steps: 6, steps per second: 96, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000328, mae: 0.009894, mean_q: 0.011100
 48066/100000: episode: 6596, duration: 0.047s, episode steps: 4, steps per second: 86, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000846, mae: 0.017326, mean_q: 0.017672
 48068/100000: episode: 6597, duration: 0.047s, episode steps: 2, steps per second: 43, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000782, mae: 0.012440, mean_q: 0.019191
 48074/100000: episode: 6598, duration: 0.078s, episode steps: 6, steps per second: 77, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000166, mae: 0.009290, mean_q: 0.006345
 48080/100000: episode: 6599, duration: 0.067s, episode steps: 6, steps per second: 90, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000327, mae: 0.010580, mean_q: 0.011523
 48086/100000: episode: 6600, duration: 0.065s, episode steps: 6, steps per second: 93, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000217, mae: 0.008894, mean_q: 0.010209
 48092/100000: episode: 6601, duration: 0.055s, episode steps: 6, steps per second: 109, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000235, mae: 0.010361, mean_q: 0.014024
 48096/100000: episode: 6602, duration: 0.034s, episode steps: 4, steps per second: 118, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000633, mae: 0.011616, mean_q: 0.008060
 48102/100000: episode: 6603, duration: 0.042s, episode steps: 6, steps per second: 142, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000258, mae: 0.012127, mean_q: 0.015659
 48108/100000: episode: 6604, duration: 0.052s, episode steps: 6, steps per second: 115, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000247, mae: 0.009791, mean_q: 0.016290
 48112/100000: episode: 6605, duration: 0.035s, episode steps: 4, steps per second: 115, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000500, mae: 0.014999, mean_q: 0.008840
 48118/100000: episode: 6606, duration: 0.063s, episode steps: 6, steps per second: 96, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000480, mae: 0.012050, mean_q: 0.018177
 48120/100000: episode: 6607, duration: 0.024s, episode steps: 2, steps per second: 83, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000176, mae: 0.008862, mean_q: 0.010813
 48124/100000: episode: 6608, duration: 0.045s, episode steps: 4, steps per second: 89, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000267, mae: 0.009431, mean_q: 0.009377
 48130/100000: episode: 6609, duration: 0.070s, episode steps: 6, steps per second: 86, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000305, mae: 0.010746, mean_q: 0.013553
 48136/100000: episode: 6610, duration: 0.060s, episode steps: 6, steps per second: 100, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000169, mae: 0.008252, mean_q: 0.013555
 48138/100000: episode: 6611, duration: 0.023s, episode steps: 2, steps per second: 86, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000028, mae: 0.004775, mean_q: 0.003571
 48142/100000: episode: 6612, duration: 0.042s, episode steps: 4, steps per second: 94, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000539, mae: 0.011693, mean_q: 0.010966
 48146/100000: episode: 6613, duration: 0.040s, episode steps: 4, steps per second: 101, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001089, mae: 0.014180, mean_q: 0.017218
 48150/100000: episode: 6614, duration: 0.046s, episode steps: 4, steps per second: 87, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000254, mae: 0.016115, mean_q: 0.022129
 48152/100000: episode: 6615, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000882, mae: 0.018935, mean_q: 0.010397
 48158/100000: episode: 6616, duration: 0.082s, episode steps: 6, steps per second: 73, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000476, mae: 0.016004, mean_q: 0.017550
 48162/100000: episode: 6617, duration: 0.070s, episode steps: 4, steps per second: 57, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000201, mae: 0.010270, mean_q: 0.007725
 48166/100000: episode: 6618, duration: 0.042s, episode steps: 4, steps per second: 94, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000227, mae: 0.011784, mean_q: 0.015514
 48170/100000: episode: 6619, duration: 0.041s, episode steps: 4, steps per second: 99, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000149, mae: 0.008928, mean_q: 0.005410
 48176/100000: episode: 6620, duration: 0.063s, episode steps: 6, steps per second: 95, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001403, mae: 0.012329, mean_q: 0.012495
 48180/100000: episode: 6621, duration: 0.044s, episode steps: 4, steps per second: 91, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001202, mae: 0.022719, mean_q: 0.013916
 48186/100000: episode: 6622, duration: 0.057s, episode steps: 6, steps per second: 106, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000237, mae: 0.012897, mean_q: 0.014109
 48192/100000: episode: 6623, duration: 0.060s, episode steps: 6, steps per second: 99, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000572, mae: 0.015127, mean_q: 0.011415
 48196/100000: episode: 6624, duration: 0.048s, episode steps: 4, steps per second: 84, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000337, mae: 0.011276, mean_q: 0.011203
 48200/100000: episode: 6625, duration: 0.050s, episode steps: 4, steps per second: 80, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000241, mae: 0.011478, mean_q: 0.013655
 48202/100000: episode: 6626, duration: 0.024s, episode steps: 2, steps per second: 84, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000072, mae: 0.007031, mean_q: 0.007411
 48208/100000: episode: 6627, duration: 0.075s, episode steps: 6, steps per second: 80, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000645, mae: 0.012607, mean_q: 0.015330
 48212/100000: episode: 6628, duration: 0.037s, episode steps: 4, steps per second: 108, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000593, mae: 0.015052, mean_q: 0.013873
 48216/100000: episode: 6629, duration: 0.041s, episode steps: 4, steps per second: 97, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000145, mae: 0.008173, mean_q: 0.010508
 48222/100000: episode: 6630, duration: 0.058s, episode steps: 6, steps per second: 103, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000740, mae: 0.014990, mean_q: 0.022351
 48226/100000: episode: 6631, duration: 0.034s, episode steps: 4, steps per second: 118, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000519, mae: 0.016542, mean_q: 0.011673
 48232/100000: episode: 6632, duration: 0.048s, episode steps: 6, steps per second: 124, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000476, mae: 0.014271, mean_q: 0.008571
 48238/100000: episode: 6633, duration: 0.055s, episode steps: 6, steps per second: 109, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000531, mae: 0.011867, mean_q: 0.020216
 48242/100000: episode: 6634, duration: 0.035s, episode steps: 4, steps per second: 113, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000242, mae: 0.011305, mean_q: 0.011784
 48248/100000: episode: 6635, duration: 0.058s, episode steps: 6, steps per second: 104, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000468, mae: 0.011038, mean_q: 0.014812
 48254/100000: episode: 6636, duration: 0.060s, episode steps: 6, steps per second: 100, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000578, mae: 0.018153, mean_q: 0.022574
 48260/100000: episode: 6637, duration: 0.049s, episode steps: 6, steps per second: 122, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000564, mae: 0.017655, mean_q: 0.008899
[Info] Complete ISplit Iteration
[Info] Levels: [0.02465345, 0.90264255]
[Info] Cond. Prob: [0.1, 0.02]
[Info] Error Prob: 0.002

 48264/100000: episode: 6638, duration: 1.211s, episode steps: 4, steps per second: 3, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000526, mae: 0.011509, mean_q: 0.013428
 48274/100000: episode: 6639, duration: 0.074s, episode steps: 10, steps per second: 134, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000286, mae: 0.011013, mean_q: 0.009908
 48284/100000: episode: 6640, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000259, mae: 0.011440, mean_q: 0.009476
 48294/100000: episode: 6641, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000208, mae: 0.009659, mean_q: 0.008784
 48304/100000: episode: 6642, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000345, mae: 0.013570, mean_q: 0.010456
 48314/100000: episode: 6643, duration: 0.079s, episode steps: 10, steps per second: 126, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000218, mae: 0.014198, mean_q: 0.010629
 48324/100000: episode: 6644, duration: 0.123s, episode steps: 10, steps per second: 82, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000549, mae: 0.016996, mean_q: 0.017920
 48334/100000: episode: 6645, duration: 0.127s, episode steps: 10, steps per second: 79, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000494, mae: 0.017961, mean_q: 0.011932
 48344/100000: episode: 6646, duration: 0.103s, episode steps: 10, steps per second: 97, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001092, mae: 0.016093, mean_q: 0.019163
 48354/100000: episode: 6647, duration: 0.141s, episode steps: 10, steps per second: 71, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000928, mae: 0.012730, mean_q: 0.014554
 48364/100000: episode: 6648, duration: 0.105s, episode steps: 10, steps per second: 95, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000476, mae: 0.015510, mean_q: 0.014668
 48374/100000: episode: 6649, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000357, mae: 0.011931, mean_q: 0.014295
 48384/100000: episode: 6650, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000287, mae: 0.011359, mean_q: 0.010805
 48394/100000: episode: 6651, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000314, mae: 0.012362, mean_q: 0.011374
 48404/100000: episode: 6652, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000339, mae: 0.011346, mean_q: 0.011839
 48414/100000: episode: 6653, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000472, mae: 0.010987, mean_q: 0.013407
 48424/100000: episode: 6654, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000339, mae: 0.012745, mean_q: 0.016414
 48434/100000: episode: 6655, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000420, mae: 0.013195, mean_q: 0.014036
 48444/100000: episode: 6656, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000625, mae: 0.016938, mean_q: 0.020957
 48454/100000: episode: 6657, duration: 0.080s, episode steps: 10, steps per second: 126, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000507, mae: 0.014894, mean_q: 0.018830
 48464/100000: episode: 6658, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000500, mae: 0.014091, mean_q: 0.012908
 48474/100000: episode: 6659, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000495, mae: 0.015485, mean_q: 0.011208
 48484/100000: episode: 6660, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000324, mae: 0.012538, mean_q: 0.012878
 48494/100000: episode: 6661, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000366, mae: 0.010132, mean_q: 0.010085
 48504/100000: episode: 6662, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000304, mae: 0.009814, mean_q: 0.010659
 48514/100000: episode: 6663, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000614, mae: 0.013172, mean_q: 0.015986
 48524/100000: episode: 6664, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000856, mae: 0.018207, mean_q: 0.020875
 48534/100000: episode: 6665, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000710, mae: 0.013956, mean_q: 0.020143
 48544/100000: episode: 6666, duration: 0.068s, episode steps: 10, steps per second: 146, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000364, mae: 0.014437, mean_q: 0.012398
 48554/100000: episode: 6667, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000237, mae: 0.012028, mean_q: 0.015802
 48564/100000: episode: 6668, duration: 0.113s, episode steps: 10, steps per second: 88, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000349, mae: 0.013011, mean_q: 0.014957
 48574/100000: episode: 6669, duration: 0.089s, episode steps: 10, steps per second: 113, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000250, mae: 0.011235, mean_q: 0.009307
 48584/100000: episode: 6670, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000396, mae: 0.014025, mean_q: 0.018494
 48594/100000: episode: 6671, duration: 0.083s, episode steps: 10, steps per second: 121, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000705, mae: 0.017360, mean_q: 0.016695
 48604/100000: episode: 6672, duration: 0.077s, episode steps: 10, steps per second: 129, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000405, mae: 0.010954, mean_q: 0.014431
 48614/100000: episode: 6673, duration: 0.088s, episode steps: 10, steps per second: 113, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000200, mae: 0.010298, mean_q: 0.009947
 48624/100000: episode: 6674, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000390, mae: 0.010608, mean_q: 0.011804
 48634/100000: episode: 6675, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000390, mae: 0.015577, mean_q: 0.016813
 48644/100000: episode: 6676, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000426, mae: 0.012590, mean_q: 0.012239
 48654/100000: episode: 6677, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000228, mae: 0.011057, mean_q: 0.012029
 48664/100000: episode: 6678, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001256, mae: 0.020299, mean_q: 0.014837
 48674/100000: episode: 6679, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000390, mae: 0.015234, mean_q: 0.011855
 48684/100000: episode: 6680, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000221, mae: 0.010004, mean_q: 0.009500
 48694/100000: episode: 6681, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000243, mae: 0.010861, mean_q: 0.009498
 48704/100000: episode: 6682, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000397, mae: 0.012440, mean_q: 0.011901
 48714/100000: episode: 6683, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000457, mae: 0.013126, mean_q: 0.012085
 48724/100000: episode: 6684, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000196, mae: 0.009782, mean_q: 0.010276
 48734/100000: episode: 6685, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000620, mae: 0.012363, mean_q: 0.014246
 48744/100000: episode: 6686, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001036, mae: 0.012611, mean_q: 0.013094
 48754/100000: episode: 6687, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000489, mae: 0.014527, mean_q: 0.011416
 48764/100000: episode: 6688, duration: 0.076s, episode steps: 10, steps per second: 131, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000677, mae: 0.017629, mean_q: 0.022090
 48774/100000: episode: 6689, duration: 0.067s, episode steps: 10, steps per second: 148, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000284, mae: 0.011409, mean_q: 0.011724
 48784/100000: episode: 6690, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000464, mae: 0.010818, mean_q: 0.012586
 48794/100000: episode: 6691, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000703, mae: 0.016770, mean_q: 0.014613
 48804/100000: episode: 6692, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000144, mae: 0.011861, mean_q: 0.009338
 48814/100000: episode: 6693, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000377, mae: 0.015934, mean_q: 0.013548
 48824/100000: episode: 6694, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000204, mae: 0.009615, mean_q: 0.009655
 48834/100000: episode: 6695, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001425, mae: 0.018471, mean_q: 0.013827
 48844/100000: episode: 6696, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000524, mae: 0.015996, mean_q: 0.018872
 48854/100000: episode: 6697, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001172, mae: 0.018637, mean_q: 0.016643
 48864/100000: episode: 6698, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000321, mae: 0.014817, mean_q: 0.013117
 48874/100000: episode: 6699, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000440, mae: 0.016026, mean_q: 0.015434
 48884/100000: episode: 6700, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000606, mae: 0.013925, mean_q: 0.013540
 48894/100000: episode: 6701, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000228, mae: 0.009702, mean_q: 0.012338
 48904/100000: episode: 6702, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000273, mae: 0.009416, mean_q: 0.010252
 48914/100000: episode: 6703, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000239, mae: 0.008156, mean_q: 0.010148
 48924/100000: episode: 6704, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000277, mae: 0.010240, mean_q: 0.013812
 48934/100000: episode: 6705, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000363, mae: 0.011936, mean_q: 0.012207
 48944/100000: episode: 6706, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000414, mae: 0.015949, mean_q: 0.011696
 48954/100000: episode: 6707, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000282, mae: 0.012933, mean_q: 0.012025
 48964/100000: episode: 6708, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000590, mae: 0.014593, mean_q: 0.015441
 48974/100000: episode: 6709, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000119, mae: 0.009142, mean_q: 0.006902
 48984/100000: episode: 6710, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000346, mae: 0.011853, mean_q: 0.013295
 48994/100000: episode: 6711, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000313, mae: 0.010696, mean_q: 0.010270
 49004/100000: episode: 6712, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000280, mae: 0.009606, mean_q: 0.012787
 49014/100000: episode: 6713, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000347, mae: 0.011438, mean_q: 0.011945
 49024/100000: episode: 6714, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000238, mae: 0.010127, mean_q: 0.010405
 49034/100000: episode: 6715, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000306, mae: 0.013191, mean_q: 0.013368
 49044/100000: episode: 6716, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000196, mae: 0.010128, mean_q: 0.011706
 49054/100000: episode: 6717, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000340, mae: 0.010642, mean_q: 0.010755
 49064/100000: episode: 6718, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000206, mae: 0.007288, mean_q: 0.010870
 49074/100000: episode: 6719, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000445, mae: 0.008899, mean_q: 0.011009
 49084/100000: episode: 6720, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000205, mae: 0.011748, mean_q: 0.011594
 49094/100000: episode: 6721, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000328, mae: 0.011244, mean_q: 0.010674
 49104/100000: episode: 6722, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000548, mae: 0.012283, mean_q: 0.015353
 49114/100000: episode: 6723, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000344, mae: 0.013643, mean_q: 0.016214
 49124/100000: episode: 6724, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000330, mae: 0.010826, mean_q: 0.007709
 49134/100000: episode: 6725, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000321, mae: 0.010151, mean_q: 0.012384
 49144/100000: episode: 6726, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000340, mae: 0.011490, mean_q: 0.011172
 49154/100000: episode: 6727, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000606, mae: 0.014343, mean_q: 0.017334
 49164/100000: episode: 6728, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000433, mae: 0.013846, mean_q: 0.011857
 49174/100000: episode: 6729, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001515, mae: 0.018319, mean_q: 0.020520
 49184/100000: episode: 6730, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000644, mae: 0.013643, mean_q: 0.008664
 49194/100000: episode: 6731, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000784, mae: 0.020169, mean_q: 0.014359
 49204/100000: episode: 6732, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001004, mae: 0.017926, mean_q: 0.012408
 49214/100000: episode: 6733, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000333, mae: 0.013145, mean_q: 0.011062
 49224/100000: episode: 6734, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000394, mae: 0.010898, mean_q: 0.011707
 49234/100000: episode: 6735, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000945, mae: 0.012706, mean_q: 0.013303
 49244/100000: episode: 6736, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000296, mae: 0.014279, mean_q: 0.012430
 49254/100000: episode: 6737, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000529, mae: 0.016351, mean_q: 0.011264
[Info] 1-TH LEVEL FOUND: 0.015494167804718018, Considering 10/100 traces
 49264/100000: episode: 6738, duration: 0.704s, episode steps: 10, steps per second: 14, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000538, mae: 0.016529, mean_q: 0.013079
 49271/100000: episode: 6739, duration: 0.038s, episode steps: 7, steps per second: 185, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000311, mae: 0.016429, mean_q: 0.016706
 49274/100000: episode: 6740, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000236, mae: 0.012674, mean_q: -0.002352
 49281/100000: episode: 6741, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000423, mae: 0.011281, mean_q: 0.018126
 49288/100000: episode: 6742, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000189, mae: 0.010221, mean_q: 0.008658
 49295/100000: episode: 6743, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000424, mae: 0.011354, mean_q: 0.014393
 49302/100000: episode: 6744, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000451, mae: 0.013109, mean_q: 0.008800
 49309/100000: episode: 6745, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001483, mae: 0.015829, mean_q: 0.020454
 49316/100000: episode: 6746, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000846, mae: 0.019004, mean_q: 0.018362
 49323/100000: episode: 6747, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000264, mae: 0.013334, mean_q: 0.012993
 49326/100000: episode: 6748, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000322, mae: 0.010938, mean_q: 0.008665
 49333/100000: episode: 6749, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000306, mae: 0.013657, mean_q: 0.004308
 49336/100000: episode: 6750, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000274, mae: 0.017947, mean_q: 0.024552
 49339/100000: episode: 6751, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000328, mae: 0.015916, mean_q: -0.001809
 49346/100000: episode: 6752, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000645, mae: 0.016419, mean_q: 0.013877
 49353/100000: episode: 6753, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.002175, mae: 0.024477, mean_q: 0.025324
 49360/100000: episode: 6754, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000459, mae: 0.021390, mean_q: 0.010046
 49367/100000: episode: 6755, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000232, mae: 0.011722, mean_q: 0.004324
 49370/100000: episode: 6756, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000223, mae: 0.012308, mean_q: 0.015771
 49377/100000: episode: 6757, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000454, mae: 0.012928, mean_q: 0.008823
 49384/100000: episode: 6758, duration: 0.037s, episode steps: 7, steps per second: 189, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000463, mae: 0.012325, mean_q: 0.014794
 49391/100000: episode: 6759, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000257, mae: 0.012153, mean_q: 0.009481
 49398/100000: episode: 6760, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000261, mae: 0.010114, mean_q: 0.010204
 49401/100000: episode: 6761, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000320, mae: 0.012116, mean_q: 0.013756
 49404/100000: episode: 6762, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000094, mae: 0.006321, mean_q: 0.007198
 49407/100000: episode: 6763, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000122, mae: 0.006392, mean_q: 0.007508
 49414/100000: episode: 6764, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000502, mae: 0.011865, mean_q: 0.010415
 49417/100000: episode: 6765, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000286, mae: 0.014519, mean_q: 0.019799
 49424/100000: episode: 6766, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000353, mae: 0.014154, mean_q: 0.005713
 49427/100000: episode: 6767, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000760, mae: 0.019491, mean_q: 0.022962
 49434/100000: episode: 6768, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000324, mae: 0.016400, mean_q: 0.010473
 49437/100000: episode: 6769, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000066, mae: 0.006436, mean_q: 0.006726
 49444/100000: episode: 6770, duration: 0.036s, episode steps: 7, steps per second: 192, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000214, mae: 0.009393, mean_q: 0.012550
 49451/100000: episode: 6771, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000346, mae: 0.014040, mean_q: 0.014003
 49458/100000: episode: 6772, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000558, mae: 0.015471, mean_q: 0.013225
 49461/100000: episode: 6773, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000933, mae: 0.015320, mean_q: 0.014883
 49464/100000: episode: 6774, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000153, mae: 0.008645, mean_q: 0.005730
 49467/100000: episode: 6775, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000393, mae: 0.018588, mean_q: 0.024883
 49470/100000: episode: 6776, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000218, mae: 0.011654, mean_q: 0.012888
 49477/100000: episode: 6777, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000418, mae: 0.014878, mean_q: 0.017001
 49484/100000: episode: 6778, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000496, mae: 0.016035, mean_q: 0.010067
 49491/100000: episode: 6779, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000704, mae: 0.015194, mean_q: 0.019390
 49494/100000: episode: 6780, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000096, mae: 0.007454, mean_q: 0.011264
 49501/100000: episode: 6781, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000479, mae: 0.009388, mean_q: 0.012742
 49508/100000: episode: 6782, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000621, mae: 0.011989, mean_q: 0.012947
 49511/100000: episode: 6783, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000158, mae: 0.009075, mean_q: 0.015312
 49514/100000: episode: 6784, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000471, mae: 0.011972, mean_q: 0.015515
 49521/100000: episode: 6785, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000670, mae: 0.017473, mean_q: 0.011292
 49524/100000: episode: 6786, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000993, mae: 0.022489, mean_q: 0.039730
 49527/100000: episode: 6787, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000633, mae: 0.017797, mean_q: 0.004165
 49534/100000: episode: 6788, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000527, mae: 0.021310, mean_q: 0.021726
 49537/100000: episode: 6789, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001247, mae: 0.020257, mean_q: 0.020137
 49544/100000: episode: 6790, duration: 0.037s, episode steps: 7, steps per second: 189, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000345, mae: 0.014662, mean_q: 0.010816
 49551/100000: episode: 6791, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000525, mae: 0.019197, mean_q: 0.020722
 49554/100000: episode: 6792, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000316, mae: 0.019661, mean_q: -0.008154
 49561/100000: episode: 6793, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000608, mae: 0.017336, mean_q: 0.020842
 49564/100000: episode: 6794, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000951, mae: 0.018810, mean_q: 0.031852
 49571/100000: episode: 6795, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000653, mae: 0.017025, mean_q: 0.008232
 49578/100000: episode: 6796, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000598, mae: 0.015597, mean_q: 0.016840
 49581/100000: episode: 6797, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000688, mae: 0.016311, mean_q: 0.030047
 49584/100000: episode: 6798, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000066, mae: 0.006356, mean_q: 0.003626
[Info] FALSIFICATION!
 49590/100000: episode: 6799, duration: 0.271s, episode steps: 6, steps per second: 22, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000613, mae: 0.013583, mean_q: 0.018651
 49593/100000: episode: 6800, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000890, mae: 0.016283, mean_q: 0.016414
 49600/100000: episode: 6801, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000416, mae: 0.012434, mean_q: 0.013082
 49607/100000: episode: 6802, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000474, mae: 0.011719, mean_q: 0.015802
 49610/100000: episode: 6803, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000703, mae: 0.014932, mean_q: 0.016106
 49617/100000: episode: 6804, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000487, mae: 0.013902, mean_q: 0.019373
 49624/100000: episode: 6805, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000234, mae: 0.012713, mean_q: 0.012337
[Info] FALSIFICATION!
 49630/100000: episode: 6806, duration: 0.269s, episode steps: 6, steps per second: 22, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000897, mae: 0.017423, mean_q: 0.016048
 49633/100000: episode: 6807, duration: 0.019s, episode steps: 3, steps per second: 157, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001170, mae: 0.027078, mean_q: 0.041669
 49640/100000: episode: 6808, duration: 0.037s, episode steps: 7, steps per second: 188, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000794, mae: 0.017995, mean_q: 0.012552
 49647/100000: episode: 6809, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000977, mae: 0.019709, mean_q: 0.027569
 49654/100000: episode: 6810, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 1.947, mean reward: 0.278 [0.007, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 7.857 [5.000, 11.000], loss: 0.000786, mae: 0.019929, mean_q: 0.015142
 49657/100000: episode: 6811, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000583, mae: 0.014802, mean_q: 0.023025
 49664/100000: episode: 6812, duration: 0.037s, episode steps: 7, steps per second: 188, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000284, mae: 0.012535, mean_q: 0.009803
 49671/100000: episode: 6813, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000480, mae: 0.013229, mean_q: 0.017261
 49678/100000: episode: 6814, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.000640, mae: 0.016740, mean_q: 0.019927
 49685/100000: episode: 6815, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000497, mae: 0.013282, mean_q: 0.010852
 49688/100000: episode: 6816, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001940, mae: 0.023544, mean_q: 0.021877
 49691/100000: episode: 6817, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001057, mae: 0.024524, mean_q: 0.036243
 49698/100000: episode: 6818, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000442, mae: 0.016199, mean_q: 0.014710
 49705/100000: episode: 6819, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000853, mae: 0.019648, mean_q: 0.019464
 49712/100000: episode: 6820, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001476, mae: 0.016057, mean_q: 0.017887
 49719/100000: episode: 6821, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000764, mae: 0.018273, mean_q: 0.011910
 49726/100000: episode: 6822, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000280, mae: 0.012959, mean_q: 0.006766
 49729/100000: episode: 6823, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000275, mae: 0.012656, mean_q: 0.011599
 49736/100000: episode: 6824, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000889, mae: 0.020015, mean_q: 0.021546
 49743/100000: episode: 6825, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001748, mae: 0.023900, mean_q: 0.024858
 49750/100000: episode: 6826, duration: 0.037s, episode steps: 7, steps per second: 189, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001065, mae: 0.022672, mean_q: 0.025326
 49757/100000: episode: 6827, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000972, mae: 0.028484, mean_q: 0.009059
[Info] Complete ISplit Iteration
[Info] Levels: [0.015494168, 0.8475791]
[Info] Cond. Prob: [0.1, 0.02]
[Info] Error Prob: 0.002

 49760/100000: episode: 6828, duration: 0.847s, episode steps: 3, steps per second: 4, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000612, mae: 0.018679, mean_q: 0.010609
 49770/100000: episode: 6829, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001542, mae: 0.024710, mean_q: 0.021068
 49780/100000: episode: 6830, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000839, mae: 0.020147, mean_q: 0.015933
 49790/100000: episode: 6831, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001430, mae: 0.021014, mean_q: 0.018599
 49800/100000: episode: 6832, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000500, mae: 0.016990, mean_q: 0.013921
 49810/100000: episode: 6833, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000243, mae: 0.010680, mean_q: 0.012291
 49820/100000: episode: 6834, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000620, mae: 0.013451, mean_q: 0.015759
 49830/100000: episode: 6835, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000725, mae: 0.017857, mean_q: 0.019020
 49840/100000: episode: 6836, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000710, mae: 0.015953, mean_q: 0.020315
 49850/100000: episode: 6837, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000784, mae: 0.016281, mean_q: 0.022505
 49860/100000: episode: 6838, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000781, mae: 0.016007, mean_q: 0.023692
 49870/100000: episode: 6839, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000533, mae: 0.014223, mean_q: 0.013384
 49880/100000: episode: 6840, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000639, mae: 0.018681, mean_q: 0.017781
 49890/100000: episode: 6841, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000975, mae: 0.018361, mean_q: 0.028172
 49900/100000: episode: 6842, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000363, mae: 0.011389, mean_q: 0.014617
 49910/100000: episode: 6843, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000483, mae: 0.013151, mean_q: 0.013442
 49920/100000: episode: 6844, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000752, mae: 0.019845, mean_q: 0.025056
 49930/100000: episode: 6845, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000938, mae: 0.020863, mean_q: 0.019264
 49940/100000: episode: 6846, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001649, mae: 0.029159, mean_q: 0.019723
 49950/100000: episode: 6847, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000970, mae: 0.019558, mean_q: 0.013307
[Info] FALSIFICATION!
 49960/100000: episode: 6848, duration: 0.229s, episode steps: 10, steps per second: 44, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.000943, mae: 0.020631, mean_q: 0.023953
 49970/100000: episode: 6849, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000498, mae: 0.014634, mean_q: 0.015575
 49980/100000: episode: 6850, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000467, mae: 0.012659, mean_q: 0.011756
 49990/100000: episode: 6851, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000445, mae: 0.013178, mean_q: 0.015465
 50000/100000: episode: 6852, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000424, mae: 0.016085, mean_q: 0.015930
 50010/100000: episode: 6853, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000598, mae: 0.015812, mean_q: 0.018143
 50020/100000: episode: 6854, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000416, mae: 0.013022, mean_q: 0.014723
 50030/100000: episode: 6855, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000490, mae: 0.014516, mean_q: 0.017126
 50040/100000: episode: 6856, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000581, mae: 0.014143, mean_q: 0.020308
 50050/100000: episode: 6857, duration: 0.066s, episode steps: 10, steps per second: 153, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000842, mae: 0.019578, mean_q: 0.016818
 50060/100000: episode: 6858, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000481, mae: 0.013449, mean_q: 0.016964
 50070/100000: episode: 6859, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000317, mae: 0.012943, mean_q: 0.010379
 50080/100000: episode: 6860, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000410, mae: 0.015866, mean_q: 0.012169
 50090/100000: episode: 6861, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000644, mae: 0.015758, mean_q: 0.022208
 50100/100000: episode: 6862, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000192, mae: 0.010885, mean_q: 0.009399
 50110/100000: episode: 6863, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000709, mae: 0.016299, mean_q: 0.024540
 50120/100000: episode: 6864, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001550, mae: 0.023799, mean_q: 0.020797
 50130/100000: episode: 6865, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000819, mae: 0.017592, mean_q: 0.016624
 50140/100000: episode: 6866, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001011, mae: 0.016975, mean_q: 0.021438
 50150/100000: episode: 6867, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000454, mae: 0.016166, mean_q: 0.010289
 50160/100000: episode: 6868, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000942, mae: 0.020297, mean_q: 0.024899
 50170/100000: episode: 6869, duration: 0.069s, episode steps: 10, steps per second: 146, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001633, mae: 0.024437, mean_q: 0.028927
 50180/100000: episode: 6870, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000829, mae: 0.022732, mean_q: 0.018433
 50190/100000: episode: 6871, duration: 0.071s, episode steps: 10, steps per second: 140, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000543, mae: 0.019094, mean_q: 0.017387
 50200/100000: episode: 6872, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000338, mae: 0.011380, mean_q: 0.014415
 50210/100000: episode: 6873, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001587, mae: 0.017515, mean_q: 0.021898
 50220/100000: episode: 6874, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000411, mae: 0.013390, mean_q: 0.010823
 50230/100000: episode: 6875, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000370, mae: 0.013340, mean_q: 0.013803
 50240/100000: episode: 6876, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000390, mae: 0.016026, mean_q: 0.014443
 50250/100000: episode: 6877, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000526, mae: 0.020845, mean_q: 0.018301
 50260/100000: episode: 6878, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000361, mae: 0.014563, mean_q: 0.008385
 50270/100000: episode: 6879, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000637, mae: 0.014892, mean_q: 0.014818
 50280/100000: episode: 6880, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000590, mae: 0.015012, mean_q: 0.023639
 50290/100000: episode: 6881, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000604, mae: 0.013287, mean_q: 0.013828
 50300/100000: episode: 6882, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000493, mae: 0.014282, mean_q: 0.018310
 50310/100000: episode: 6883, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000632, mae: 0.011894, mean_q: 0.018885
 50320/100000: episode: 6884, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000800, mae: 0.015254, mean_q: 0.022583
 50330/100000: episode: 6885, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000275, mae: 0.010878, mean_q: 0.010324
 50340/100000: episode: 6886, duration: 0.098s, episode steps: 10, steps per second: 102, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000631, mae: 0.014199, mean_q: 0.018440
 50350/100000: episode: 6887, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000457, mae: 0.012090, mean_q: 0.013708
 50360/100000: episode: 6888, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000491, mae: 0.015283, mean_q: 0.020322
 50370/100000: episode: 6889, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001149, mae: 0.019632, mean_q: 0.018865
 50380/100000: episode: 6890, duration: 0.111s, episode steps: 10, steps per second: 90, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001408, mae: 0.018084, mean_q: 0.020105
 50390/100000: episode: 6891, duration: 0.112s, episode steps: 10, steps per second: 89, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000519, mae: 0.018335, mean_q: 0.010300
 50400/100000: episode: 6892, duration: 0.116s, episode steps: 10, steps per second: 86, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000287, mae: 0.011905, mean_q: 0.013672
 50410/100000: episode: 6893, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000546, mae: 0.015363, mean_q: 0.017776
 50420/100000: episode: 6894, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000202, mae: 0.009644, mean_q: 0.010467
 50430/100000: episode: 6895, duration: 0.103s, episode steps: 10, steps per second: 97, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000714, mae: 0.016602, mean_q: 0.017267
 50440/100000: episode: 6896, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000517, mae: 0.014462, mean_q: 0.014476
 50450/100000: episode: 6897, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000448, mae: 0.012546, mean_q: 0.015648
 50460/100000: episode: 6898, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001375, mae: 0.019393, mean_q: 0.022037
 50470/100000: episode: 6899, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000545, mae: 0.016033, mean_q: 0.011247
 50480/100000: episode: 6900, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000381, mae: 0.012907, mean_q: 0.011248
 50490/100000: episode: 6901, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000835, mae: 0.022033, mean_q: 0.018840
 50500/100000: episode: 6902, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000424, mae: 0.015660, mean_q: 0.013310
 50510/100000: episode: 6903, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000369, mae: 0.010700, mean_q: 0.009735
 50520/100000: episode: 6904, duration: 0.085s, episode steps: 10, steps per second: 117, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000299, mae: 0.011282, mean_q: 0.012193
 50530/100000: episode: 6905, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001232, mae: 0.016168, mean_q: 0.016490
 50540/100000: episode: 6906, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000569, mae: 0.015278, mean_q: 0.019265
 50550/100000: episode: 6907, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000427, mae: 0.011170, mean_q: 0.014124
[Info] FALSIFICATION!
 50560/100000: episode: 6908, duration: 0.365s, episode steps: 10, steps per second: 27, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.000619, mae: 0.015244, mean_q: 0.014560
 50570/100000: episode: 6909, duration: 0.080s, episode steps: 10, steps per second: 126, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000288, mae: 0.011258, mean_q: 0.010974
 50580/100000: episode: 6910, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000425, mae: 0.014834, mean_q: 0.014287
 50590/100000: episode: 6911, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000667, mae: 0.013276, mean_q: 0.022785
 50600/100000: episode: 6912, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000594, mae: 0.014763, mean_q: 0.017227
 50610/100000: episode: 6913, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000605, mae: 0.014165, mean_q: 0.017086
 50620/100000: episode: 6914, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000275, mae: 0.011232, mean_q: 0.013646
 50630/100000: episode: 6915, duration: 0.107s, episode steps: 10, steps per second: 93, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001286, mae: 0.019540, mean_q: 0.021285
 50640/100000: episode: 6916, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000766, mae: 0.019608, mean_q: 0.021271
 50650/100000: episode: 6917, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000707, mae: 0.018914, mean_q: 0.019234
 50660/100000: episode: 6918, duration: 0.115s, episode steps: 10, steps per second: 87, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001050, mae: 0.021164, mean_q: 0.021414
 50670/100000: episode: 6919, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001389, mae: 0.022518, mean_q: 0.014861
 50680/100000: episode: 6920, duration: 0.083s, episode steps: 10, steps per second: 120, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000863, mae: 0.021791, mean_q: 0.021342
 50690/100000: episode: 6921, duration: 0.115s, episode steps: 10, steps per second: 87, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000452, mae: 0.016477, mean_q: 0.013840
 50700/100000: episode: 6922, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000315, mae: 0.012236, mean_q: 0.015070
 50710/100000: episode: 6923, duration: 0.119s, episode steps: 10, steps per second: 84, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000828, mae: 0.016279, mean_q: 0.027298
 50720/100000: episode: 6924, duration: 0.082s, episode steps: 10, steps per second: 123, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000811, mae: 0.018370, mean_q: 0.017025
 50730/100000: episode: 6925, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000416, mae: 0.012859, mean_q: 0.013552
 50740/100000: episode: 6926, duration: 0.072s, episode steps: 10, steps per second: 140, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000388, mae: 0.014593, mean_q: 0.015397
 50750/100000: episode: 6927, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000425, mae: 0.016695, mean_q: 0.016094
[Info] Complete ISplit Iteration
[Info] Levels: [0.8733237]
[Info] Cond. Prob: [0.02]
[Info] Error Prob: 0.02

 50760/100000: episode: 6928, duration: 1.104s, episode steps: 10, steps per second: 9, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000500, mae: 0.014589, mean_q: 0.013637
 50770/100000: episode: 6929, duration: 0.077s, episode steps: 10, steps per second: 129, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000781, mae: 0.016259, mean_q: 0.019297
 50780/100000: episode: 6930, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000506, mae: 0.010671, mean_q: 0.011524
 50790/100000: episode: 6931, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000576, mae: 0.014353, mean_q: 0.015425
 50800/100000: episode: 6932, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000360, mae: 0.010531, mean_q: 0.013521
 50810/100000: episode: 6933, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000621, mae: 0.018092, mean_q: 0.017216
 50820/100000: episode: 6934, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000558, mae: 0.017583, mean_q: 0.018529
 50830/100000: episode: 6935, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001701, mae: 0.020966, mean_q: 0.022521
 50840/100000: episode: 6936, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000361, mae: 0.015724, mean_q: 0.012386
 50850/100000: episode: 6937, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000576, mae: 0.016502, mean_q: 0.019537
 50860/100000: episode: 6938, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000455, mae: 0.018327, mean_q: 0.011135
 50870/100000: episode: 6939, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000626, mae: 0.015023, mean_q: 0.018438
 50880/100000: episode: 6940, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000636, mae: 0.016087, mean_q: 0.017631
 50890/100000: episode: 6941, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000365, mae: 0.015938, mean_q: 0.011491
 50900/100000: episode: 6942, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001726, mae: 0.016817, mean_q: 0.022417
 50910/100000: episode: 6943, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000901, mae: 0.014819, mean_q: 0.015033
 50920/100000: episode: 6944, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000824, mae: 0.016625, mean_q: 0.017753
 50930/100000: episode: 6945, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000412, mae: 0.013544, mean_q: 0.012094
 50940/100000: episode: 6946, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000633, mae: 0.016254, mean_q: 0.015656
 50950/100000: episode: 6947, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000714, mae: 0.013960, mean_q: 0.016320
 50960/100000: episode: 6948, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001022, mae: 0.016053, mean_q: 0.015597
 50970/100000: episode: 6949, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000336, mae: 0.012974, mean_q: 0.017427
 50980/100000: episode: 6950, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000566, mae: 0.013753, mean_q: 0.015104
 50990/100000: episode: 6951, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000450, mae: 0.013092, mean_q: 0.019353
 51000/100000: episode: 6952, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000418, mae: 0.012295, mean_q: 0.015493
 51010/100000: episode: 6953, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000442, mae: 0.010935, mean_q: 0.013022
 51020/100000: episode: 6954, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000403, mae: 0.010272, mean_q: 0.015197
 51030/100000: episode: 6955, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000260, mae: 0.009919, mean_q: 0.015394
 51040/100000: episode: 6956, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000261, mae: 0.011030, mean_q: 0.011889
 51050/100000: episode: 6957, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000352, mae: 0.011667, mean_q: 0.013933
 51060/100000: episode: 6958, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000276, mae: 0.010979, mean_q: 0.013409
 51070/100000: episode: 6959, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000406, mae: 0.011921, mean_q: 0.008271
 51080/100000: episode: 6960, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000584, mae: 0.016084, mean_q: 0.018113
 51090/100000: episode: 6961, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000220, mae: 0.009306, mean_q: 0.010155
 51100/100000: episode: 6962, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000267, mae: 0.010062, mean_q: 0.010711
 51110/100000: episode: 6963, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001871, mae: 0.019521, mean_q: 0.020570
 51120/100000: episode: 6964, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000914, mae: 0.026345, mean_q: 0.015193
 51130/100000: episode: 6965, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000916, mae: 0.021176, mean_q: 0.020264
 51140/100000: episode: 6966, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000766, mae: 0.020453, mean_q: 0.019544
 51150/100000: episode: 6967, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001404, mae: 0.021936, mean_q: 0.027158
 51160/100000: episode: 6968, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000504, mae: 0.016579, mean_q: 0.017341
 51170/100000: episode: 6969, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000817, mae: 0.015775, mean_q: 0.020424
 51180/100000: episode: 6970, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000660, mae: 0.018859, mean_q: 0.019702
 51190/100000: episode: 6971, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000413, mae: 0.013152, mean_q: 0.010725
 51200/100000: episode: 6972, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000486, mae: 0.012264, mean_q: 0.012723
 51210/100000: episode: 6973, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000407, mae: 0.011660, mean_q: 0.014481
 51220/100000: episode: 6974, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001233, mae: 0.018299, mean_q: 0.019324
 51230/100000: episode: 6975, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000829, mae: 0.020076, mean_q: 0.012163
 51240/100000: episode: 6976, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000662, mae: 0.012142, mean_q: 0.015681
 51250/100000: episode: 6977, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000551, mae: 0.013856, mean_q: 0.017705
 51260/100000: episode: 6978, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000676, mae: 0.018750, mean_q: 0.022532
 51270/100000: episode: 6979, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000961, mae: 0.018530, mean_q: 0.017249
 51280/100000: episode: 6980, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000523, mae: 0.013173, mean_q: 0.010216
 51290/100000: episode: 6981, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000262, mae: 0.010084, mean_q: 0.010614
 51300/100000: episode: 6982, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000612, mae: 0.014582, mean_q: 0.011516
 51310/100000: episode: 6983, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000291, mae: 0.012749, mean_q: 0.010285
 51320/100000: episode: 6984, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000420, mae: 0.011488, mean_q: 0.016926
 51330/100000: episode: 6985, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000381, mae: 0.010410, mean_q: 0.016721
 51340/100000: episode: 6986, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000415, mae: 0.012385, mean_q: 0.017775
 51350/100000: episode: 6987, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000345, mae: 0.011137, mean_q: 0.014368
 51360/100000: episode: 6988, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000675, mae: 0.014082, mean_q: 0.020087
 51370/100000: episode: 6989, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000629, mae: 0.013634, mean_q: 0.020989
 51380/100000: episode: 6990, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000448, mae: 0.015052, mean_q: 0.015848
 51390/100000: episode: 6991, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001081, mae: 0.016205, mean_q: 0.017218
 51400/100000: episode: 6992, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000612, mae: 0.013509, mean_q: 0.018978
 51410/100000: episode: 6993, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000340, mae: 0.011238, mean_q: 0.014593
 51420/100000: episode: 6994, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000680, mae: 0.016907, mean_q: 0.013952
 51430/100000: episode: 6995, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000265, mae: 0.011984, mean_q: 0.014191
 51440/100000: episode: 6996, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000226, mae: 0.011177, mean_q: 0.011371
 51450/100000: episode: 6997, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000511, mae: 0.013576, mean_q: 0.013416
 51460/100000: episode: 6998, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000351, mae: 0.012037, mean_q: 0.009426
 51470/100000: episode: 6999, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000751, mae: 0.017144, mean_q: 0.018882
 51480/100000: episode: 7000, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000589, mae: 0.015306, mean_q: 0.013003
 51490/100000: episode: 7001, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000408, mae: 0.011651, mean_q: 0.014086
 51500/100000: episode: 7002, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000495, mae: 0.013761, mean_q: 0.018618
 51510/100000: episode: 7003, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000926, mae: 0.019320, mean_q: 0.018996
 51520/100000: episode: 7004, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000328, mae: 0.014430, mean_q: 0.010813
 51530/100000: episode: 7005, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001750, mae: 0.024592, mean_q: 0.023729
 51540/100000: episode: 7006, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000326, mae: 0.012516, mean_q: 0.010789
 51550/100000: episode: 7007, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000526, mae: 0.013486, mean_q: 0.011209
 51560/100000: episode: 7008, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000472, mae: 0.017148, mean_q: 0.013498
 51570/100000: episode: 7009, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000691, mae: 0.014974, mean_q: 0.015500
 51580/100000: episode: 7010, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000496, mae: 0.014302, mean_q: 0.013191
 51590/100000: episode: 7011, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000600, mae: 0.015968, mean_q: 0.016774
 51600/100000: episode: 7012, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000419, mae: 0.012981, mean_q: 0.014265
 51610/100000: episode: 7013, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001024, mae: 0.018446, mean_q: 0.015775
 51620/100000: episode: 7014, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000757, mae: 0.021540, mean_q: 0.019525
 51630/100000: episode: 7015, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000550, mae: 0.017705, mean_q: 0.014850
 51640/100000: episode: 7016, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001313, mae: 0.016068, mean_q: 0.016189
 51650/100000: episode: 7017, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000624, mae: 0.018520, mean_q: 0.015178
 51660/100000: episode: 7018, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.001179, mae: 0.015742, mean_q: 0.019230
 51670/100000: episode: 7019, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000454, mae: 0.014380, mean_q: 0.021416
 51680/100000: episode: 7020, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000853, mae: 0.015260, mean_q: 0.019385
 51690/100000: episode: 7021, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000373, mae: 0.011271, mean_q: 0.016852
 51700/100000: episode: 7022, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000373, mae: 0.012137, mean_q: 0.013230
 51710/100000: episode: 7023, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000596, mae: 0.013948, mean_q: 0.022950
 51720/100000: episode: 7024, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000783, mae: 0.019723, mean_q: 0.012926
 51730/100000: episode: 7025, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000506, mae: 0.014896, mean_q: 0.013713
 51740/100000: episode: 7026, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000495, mae: 0.014667, mean_q: 0.017384
 51750/100000: episode: 7027, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001237, mae: 0.018006, mean_q: 0.025997
[Info] 1-TH LEVEL FOUND: 0.0002628117799758911, Considering 100/100 traces
 51760/100000: episode: 7028, duration: 0.750s, episode steps: 10, steps per second: 13, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001166, mae: 0.018785, mean_q: 0.022880
[Info] 2-TH LEVEL FOUND: 0.02595175802707672, Considering 100/100 traces
 51761/100000: episode: 7029, duration: 0.752s, episode steps: 1, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000542, mae: 0.016058, mean_q: 0.007243
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.02595175802707672
 51762/100000: episode: 7030, duration: 0.585s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.002048, mae: 0.030687, mean_q: 0.049409
 51772/100000: episode: 7031, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000291, mae: 0.011000, mean_q: 0.009292
 51782/100000: episode: 7032, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000505, mae: 0.011079, mean_q: 0.017161
 51792/100000: episode: 7033, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000431, mae: 0.012265, mean_q: 0.012758
 51802/100000: episode: 7034, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000722, mae: 0.015910, mean_q: 0.026828
 51812/100000: episode: 7035, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000401, mae: 0.013502, mean_q: 0.016086
 51822/100000: episode: 7036, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000354, mae: 0.012414, mean_q: 0.012716
 51832/100000: episode: 7037, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001184, mae: 0.014696, mean_q: 0.017266
 51842/100000: episode: 7038, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000888, mae: 0.020291, mean_q: 0.014272
 51852/100000: episode: 7039, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000713, mae: 0.015812, mean_q: 0.020660
 51862/100000: episode: 7040, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000588, mae: 0.013429, mean_q: 0.019347
 51872/100000: episode: 7041, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000459, mae: 0.013077, mean_q: 0.017718
 51882/100000: episode: 7042, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001315, mae: 0.015150, mean_q: 0.019451
 51892/100000: episode: 7043, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000240, mae: 0.009256, mean_q: 0.010496
 51902/100000: episode: 7044, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000558, mae: 0.016153, mean_q: 0.012246
 51912/100000: episode: 7045, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000488, mae: 0.015871, mean_q: 0.015645
 51922/100000: episode: 7046, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000604, mae: 0.012730, mean_q: 0.019928
 51932/100000: episode: 7047, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000357, mae: 0.011999, mean_q: 0.008350
 51942/100000: episode: 7048, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000734, mae: 0.019161, mean_q: 0.025061
 51952/100000: episode: 7049, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000683, mae: 0.016005, mean_q: 0.013406
 51962/100000: episode: 7050, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000363, mae: 0.017056, mean_q: 0.011893
 51972/100000: episode: 7051, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000768, mae: 0.019313, mean_q: 0.014435
 51982/100000: episode: 7052, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000667, mae: 0.018911, mean_q: 0.015910
 51992/100000: episode: 7053, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000860, mae: 0.018981, mean_q: 0.022649
 52002/100000: episode: 7054, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001339, mae: 0.021528, mean_q: 0.024901
 52012/100000: episode: 7055, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000746, mae: 0.020819, mean_q: 0.011933
 52022/100000: episode: 7056, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000488, mae: 0.012136, mean_q: 0.011918
 52032/100000: episode: 7057, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000564, mae: 0.013582, mean_q: 0.015890
 52042/100000: episode: 7058, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000791, mae: 0.019301, mean_q: 0.019932
 52052/100000: episode: 7059, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000642, mae: 0.020144, mean_q: 0.009618
 52062/100000: episode: 7060, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000229, mae: 0.012257, mean_q: 0.007145
 52072/100000: episode: 7061, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001963, mae: 0.029921, mean_q: 0.017994
 52082/100000: episode: 7062, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000731, mae: 0.019342, mean_q: 0.018882
 52092/100000: episode: 7063, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000383, mae: 0.018788, mean_q: 0.016565
 52102/100000: episode: 7064, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000503, mae: 0.016512, mean_q: 0.017521
 52112/100000: episode: 7065, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001673, mae: 0.019572, mean_q: 0.022766
 52122/100000: episode: 7066, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000354, mae: 0.013465, mean_q: 0.019346
 52132/100000: episode: 7067, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000355, mae: 0.011353, mean_q: 0.010597
 52142/100000: episode: 7068, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000731, mae: 0.017652, mean_q: 0.022874
 52152/100000: episode: 7069, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000609, mae: 0.017180, mean_q: 0.019382
 52162/100000: episode: 7070, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000442, mae: 0.013728, mean_q: 0.021774
 52172/100000: episode: 7071, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000378, mae: 0.015377, mean_q: 0.015102
 52182/100000: episode: 7072, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001121, mae: 0.016733, mean_q: 0.019836
 52192/100000: episode: 7073, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000367, mae: 0.014472, mean_q: 0.011506
 52202/100000: episode: 7074, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000387, mae: 0.013730, mean_q: 0.010787
 52212/100000: episode: 7075, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000482, mae: 0.012872, mean_q: 0.015930
 52222/100000: episode: 7076, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001640, mae: 0.016679, mean_q: 0.029290
 52232/100000: episode: 7077, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000742, mae: 0.016152, mean_q: 0.018007
 52242/100000: episode: 7078, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000584, mae: 0.014074, mean_q: 0.019286
 52252/100000: episode: 7079, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000237, mae: 0.010375, mean_q: 0.009201
 52262/100000: episode: 7080, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000596, mae: 0.014877, mean_q: 0.020012
 52272/100000: episode: 7081, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000696, mae: 0.017287, mean_q: 0.013306
 52282/100000: episode: 7082, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000627, mae: 0.013766, mean_q: 0.021838
 52292/100000: episode: 7083, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000597, mae: 0.013013, mean_q: 0.014163
 52302/100000: episode: 7084, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000427, mae: 0.013671, mean_q: 0.015229
 52312/100000: episode: 7085, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000643, mae: 0.016439, mean_q: 0.012510
 52322/100000: episode: 7086, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001030, mae: 0.015899, mean_q: 0.021320
 52332/100000: episode: 7087, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000518, mae: 0.012474, mean_q: 0.015332
 52342/100000: episode: 7088, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000647, mae: 0.015362, mean_q: 0.016415
 52352/100000: episode: 7089, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001176, mae: 0.013341, mean_q: 0.015176
 52362/100000: episode: 7090, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000591, mae: 0.017260, mean_q: 0.019572
 52372/100000: episode: 7091, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000595, mae: 0.015868, mean_q: 0.015075
 52382/100000: episode: 7092, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000305, mae: 0.009153, mean_q: 0.008273
 52392/100000: episode: 7093, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000694, mae: 0.015521, mean_q: 0.017077
 52402/100000: episode: 7094, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000597, mae: 0.014047, mean_q: 0.013007
 52412/100000: episode: 7095, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000891, mae: 0.016486, mean_q: 0.018309
 52422/100000: episode: 7096, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000677, mae: 0.019359, mean_q: 0.018890
 52432/100000: episode: 7097, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000615, mae: 0.014514, mean_q: 0.015982
 52442/100000: episode: 7098, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000481, mae: 0.013885, mean_q: 0.012611
 52452/100000: episode: 7099, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000564, mae: 0.015352, mean_q: 0.016805
 52462/100000: episode: 7100, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000548, mae: 0.011485, mean_q: 0.017227
 52472/100000: episode: 7101, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000761, mae: 0.015683, mean_q: 0.014900
 52482/100000: episode: 7102, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000539, mae: 0.014450, mean_q: 0.017595
 52492/100000: episode: 7103, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000638, mae: 0.013326, mean_q: 0.015019
 52502/100000: episode: 7104, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000591, mae: 0.017184, mean_q: 0.015536
 52512/100000: episode: 7105, duration: 0.071s, episode steps: 10, steps per second: 140, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000750, mae: 0.018027, mean_q: 0.012792
 52522/100000: episode: 7106, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000844, mae: 0.021898, mean_q: 0.020458
 52532/100000: episode: 7107, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000539, mae: 0.012890, mean_q: 0.014944
 52542/100000: episode: 7108, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000676, mae: 0.013107, mean_q: 0.014407
 52552/100000: episode: 7109, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000433, mae: 0.016316, mean_q: 0.014327
 52562/100000: episode: 7110, duration: 0.077s, episode steps: 10, steps per second: 131, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000436, mae: 0.014150, mean_q: 0.014586
 52572/100000: episode: 7111, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000306, mae: 0.011664, mean_q: 0.013377
 52582/100000: episode: 7112, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000540, mae: 0.014087, mean_q: 0.015477
 52592/100000: episode: 7113, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000368, mae: 0.013049, mean_q: 0.016714
 52602/100000: episode: 7114, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000578, mae: 0.017747, mean_q: 0.015285
 52612/100000: episode: 7115, duration: 0.104s, episode steps: 10, steps per second: 96, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000695, mae: 0.014897, mean_q: 0.020883
 52622/100000: episode: 7116, duration: 0.134s, episode steps: 10, steps per second: 74, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000269, mae: 0.009797, mean_q: 0.009208
 52632/100000: episode: 7117, duration: 0.112s, episode steps: 10, steps per second: 89, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000738, mae: 0.013939, mean_q: 0.017149
 52642/100000: episode: 7118, duration: 0.136s, episode steps: 10, steps per second: 74, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000554, mae: 0.012940, mean_q: 0.011881
 52652/100000: episode: 7119, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000313, mae: 0.011240, mean_q: 0.013200
 52662/100000: episode: 7120, duration: 0.089s, episode steps: 10, steps per second: 113, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000299, mae: 0.010173, mean_q: 0.014867
 52672/100000: episode: 7121, duration: 0.104s, episode steps: 10, steps per second: 96, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000954, mae: 0.013687, mean_q: 0.012971
 52682/100000: episode: 7122, duration: 0.110s, episode steps: 10, steps per second: 91, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000518, mae: 0.011134, mean_q: 0.009920
 52692/100000: episode: 7123, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000310, mae: 0.008389, mean_q: 0.009161
 52702/100000: episode: 7124, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000283, mae: 0.011070, mean_q: 0.011053
 52712/100000: episode: 7125, duration: 0.110s, episode steps: 10, steps per second: 91, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000501, mae: 0.011253, mean_q: 0.014102
 52722/100000: episode: 7126, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000635, mae: 0.016179, mean_q: 0.023898
 52732/100000: episode: 7127, duration: 0.111s, episode steps: 10, steps per second: 90, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000421, mae: 0.016449, mean_q: 0.011242
 52742/100000: episode: 7128, duration: 0.103s, episode steps: 10, steps per second: 97, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000471, mae: 0.013579, mean_q: 0.010159
 52752/100000: episode: 7129, duration: 0.084s, episode steps: 10, steps per second: 120, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000239, mae: 0.010471, mean_q: 0.012100
[Info] 1-TH LEVEL FOUND: 0.014013394713401794, Considering 100/100 traces
 52762/100000: episode: 7130, duration: 1.092s, episode steps: 10, steps per second: 9, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000492, mae: 0.009480, mean_q: 0.006920
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.014013394713401794
 52763/100000: episode: 7131, duration: 0.800s, episode steps: 1, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000134, mae: 0.007522, mean_q: 0.005065
 52773/100000: episode: 7132, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000586, mae: 0.014486, mean_q: 0.017969
 52783/100000: episode: 7133, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000525, mae: 0.014936, mean_q: 0.007581
 52793/100000: episode: 7134, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000438, mae: 0.012192, mean_q: 0.010358
 52803/100000: episode: 7135, duration: 0.083s, episode steps: 10, steps per second: 121, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000315, mae: 0.015169, mean_q: 0.012784
 52813/100000: episode: 7136, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000304, mae: 0.017488, mean_q: 0.010205
 52823/100000: episode: 7137, duration: 0.085s, episode steps: 10, steps per second: 117, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000268, mae: 0.011295, mean_q: 0.008770
 52833/100000: episode: 7138, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000517, mae: 0.016914, mean_q: 0.011716
 52843/100000: episode: 7139, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000260, mae: 0.011532, mean_q: 0.013566
 52853/100000: episode: 7140, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000614, mae: 0.011543, mean_q: 0.009385
 52863/100000: episode: 7141, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000339, mae: 0.011054, mean_q: 0.011861
 52873/100000: episode: 7142, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000591, mae: 0.014544, mean_q: 0.008863
 52883/100000: episode: 7143, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000395, mae: 0.011091, mean_q: 0.010950
 52893/100000: episode: 7144, duration: 0.066s, episode steps: 10, steps per second: 150, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000397, mae: 0.011384, mean_q: 0.013305
 52903/100000: episode: 7145, duration: 0.092s, episode steps: 10, steps per second: 108, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000898, mae: 0.018829, mean_q: 0.014035
 52913/100000: episode: 7146, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000342, mae: 0.011124, mean_q: 0.011009
 52923/100000: episode: 7147, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001141, mae: 0.013931, mean_q: 0.009622
 52933/100000: episode: 7148, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000461, mae: 0.014509, mean_q: 0.013266
 52943/100000: episode: 7149, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000285, mae: 0.011278, mean_q: 0.011638
 52953/100000: episode: 7150, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000513, mae: 0.012882, mean_q: 0.014681
 52963/100000: episode: 7151, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000288, mae: 0.009836, mean_q: 0.011144
 52973/100000: episode: 7152, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000321, mae: 0.009510, mean_q: 0.012391
 52983/100000: episode: 7153, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000569, mae: 0.012117, mean_q: 0.019315
 52993/100000: episode: 7154, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000994, mae: 0.010876, mean_q: 0.011789
 53003/100000: episode: 7155, duration: 0.128s, episode steps: 10, steps per second: 78, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000187, mae: 0.011933, mean_q: 0.008622
 53013/100000: episode: 7156, duration: 0.101s, episode steps: 10, steps per second: 99, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000302, mae: 0.011860, mean_q: 0.011025
 53023/100000: episode: 7157, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000108, mae: 0.006797, mean_q: 0.006211
 53033/100000: episode: 7158, duration: 0.062s, episode steps: 10, steps per second: 163, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000390, mae: 0.009133, mean_q: 0.009852
 53043/100000: episode: 7159, duration: 0.079s, episode steps: 10, steps per second: 126, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000362, mae: 0.011682, mean_q: 0.013010
 53053/100000: episode: 7160, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000477, mae: 0.014367, mean_q: 0.019395
 53063/100000: episode: 7161, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000583, mae: 0.014606, mean_q: 0.024740
 53073/100000: episode: 7162, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000173, mae: 0.011110, mean_q: 0.010260
 53083/100000: episode: 7163, duration: 0.078s, episode steps: 10, steps per second: 129, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000285, mae: 0.011964, mean_q: 0.007340
 53093/100000: episode: 7164, duration: 0.126s, episode steps: 10, steps per second: 80, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000765, mae: 0.013488, mean_q: 0.009837
 53103/100000: episode: 7165, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000156, mae: 0.009437, mean_q: 0.008390
 53113/100000: episode: 7166, duration: 0.120s, episode steps: 10, steps per second: 83, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000431, mae: 0.012071, mean_q: 0.012236
 53123/100000: episode: 7167, duration: 0.115s, episode steps: 10, steps per second: 87, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000392, mae: 0.012002, mean_q: 0.012342
 53133/100000: episode: 7168, duration: 0.103s, episode steps: 10, steps per second: 97, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000585, mae: 0.011054, mean_q: 0.011364
 53143/100000: episode: 7169, duration: 0.083s, episode steps: 10, steps per second: 121, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000782, mae: 0.019448, mean_q: 0.015194
 53153/100000: episode: 7170, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000434, mae: 0.016791, mean_q: 0.010409
 53163/100000: episode: 7171, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000351, mae: 0.012040, mean_q: 0.011626
 53173/100000: episode: 7172, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000259, mae: 0.009593, mean_q: 0.010574
 53183/100000: episode: 7173, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000187, mae: 0.010143, mean_q: 0.006040
 53193/100000: episode: 7174, duration: 0.094s, episode steps: 10, steps per second: 106, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000514, mae: 0.011064, mean_q: 0.020769
 53203/100000: episode: 7175, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000449, mae: 0.009139, mean_q: 0.012828
 53213/100000: episode: 7176, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000126, mae: 0.007164, mean_q: 0.006768
 53223/100000: episode: 7177, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000276, mae: 0.006341, mean_q: 0.006419
 53233/100000: episode: 7178, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000140, mae: 0.007624, mean_q: 0.010350
 53243/100000: episode: 7179, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000302, mae: 0.010791, mean_q: 0.013130
 53253/100000: episode: 7180, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000812, mae: 0.012047, mean_q: 0.016237
 53263/100000: episode: 7181, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000262, mae: 0.007868, mean_q: 0.007782
 53273/100000: episode: 7182, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001264, mae: 0.014583, mean_q: 0.013792
 53283/100000: episode: 7183, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000354, mae: 0.015648, mean_q: 0.010110
 53293/100000: episode: 7184, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000448, mae: 0.015507, mean_q: 0.010514
 53303/100000: episode: 7185, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000335, mae: 0.010866, mean_q: 0.011483
 53313/100000: episode: 7186, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000448, mae: 0.012858, mean_q: 0.010773
 53323/100000: episode: 7187, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000599, mae: 0.013391, mean_q: 0.013963
 53333/100000: episode: 7188, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000253, mae: 0.008425, mean_q: 0.007779
 53343/100000: episode: 7189, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000138, mae: 0.007430, mean_q: 0.005973
 53353/100000: episode: 7190, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000285, mae: 0.008795, mean_q: 0.009673
 53363/100000: episode: 7191, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000423, mae: 0.009391, mean_q: 0.011400
 53373/100000: episode: 7192, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000401, mae: 0.012202, mean_q: 0.013626
 53383/100000: episode: 7193, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000250, mae: 0.013123, mean_q: 0.008155
 53393/100000: episode: 7194, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000474, mae: 0.012659, mean_q: 0.008813
 53403/100000: episode: 7195, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000286, mae: 0.010909, mean_q: 0.010715
 53413/100000: episode: 7196, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000193, mae: 0.010413, mean_q: 0.009924
 53423/100000: episode: 7197, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000533, mae: 0.010096, mean_q: 0.010779
 53433/100000: episode: 7198, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000165, mae: 0.007850, mean_q: 0.007634
 53443/100000: episode: 7199, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000445, mae: 0.011551, mean_q: 0.009682
 53453/100000: episode: 7200, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001220, mae: 0.014264, mean_q: 0.014768
 53463/100000: episode: 7201, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001016, mae: 0.015441, mean_q: 0.009354
 53473/100000: episode: 7202, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001012, mae: 0.019744, mean_q: 0.012714
 53483/100000: episode: 7203, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000337, mae: 0.013679, mean_q: 0.006327
 53493/100000: episode: 7204, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000535, mae: 0.014447, mean_q: 0.010687
 53503/100000: episode: 7205, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000311, mae: 0.009919, mean_q: 0.009404
 53513/100000: episode: 7206, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000089, mae: 0.006507, mean_q: 0.006351
 53523/100000: episode: 7207, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000762, mae: 0.013203, mean_q: 0.018259
 53533/100000: episode: 7208, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000413, mae: 0.016199, mean_q: 0.013238
 53543/100000: episode: 7209, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000275, mae: 0.011028, mean_q: 0.012306
 53553/100000: episode: 7210, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000279, mae: 0.009712, mean_q: 0.011642
 53563/100000: episode: 7211, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000297, mae: 0.009755, mean_q: 0.010797
 53573/100000: episode: 7212, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000303, mae: 0.008127, mean_q: 0.010277
 53583/100000: episode: 7213, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000637, mae: 0.013110, mean_q: 0.011693
 53593/100000: episode: 7214, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000275, mae: 0.010844, mean_q: 0.013342
 53603/100000: episode: 7215, duration: 0.115s, episode steps: 10, steps per second: 87, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000236, mae: 0.010631, mean_q: 0.008508
 53613/100000: episode: 7216, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000157, mae: 0.008862, mean_q: 0.009336
 53623/100000: episode: 7217, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000290, mae: 0.008261, mean_q: 0.011273
 53633/100000: episode: 7218, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000442, mae: 0.010973, mean_q: 0.013564
 53643/100000: episode: 7219, duration: 0.105s, episode steps: 10, steps per second: 96, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001231, mae: 0.015566, mean_q: 0.016692
 53653/100000: episode: 7220, duration: 0.134s, episode steps: 10, steps per second: 75, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000304, mae: 0.012003, mean_q: 0.010859
 53663/100000: episode: 7221, duration: 0.087s, episode steps: 10, steps per second: 114, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000434, mae: 0.008943, mean_q: 0.009455
 53673/100000: episode: 7222, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000238, mae: 0.007901, mean_q: 0.009578
 53683/100000: episode: 7223, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000414, mae: 0.009327, mean_q: 0.012456
 53693/100000: episode: 7224, duration: 0.095s, episode steps: 10, steps per second: 106, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000207, mae: 0.009112, mean_q: 0.008026
 53703/100000: episode: 7225, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000287, mae: 0.010359, mean_q: 0.010624
 53713/100000: episode: 7226, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000383, mae: 0.012717, mean_q: 0.005973
 53723/100000: episode: 7227, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000207, mae: 0.008707, mean_q: 0.009625
 53733/100000: episode: 7228, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000384, mae: 0.009985, mean_q: 0.008281
 53743/100000: episode: 7229, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000324, mae: 0.011510, mean_q: 0.010517
 53753/100000: episode: 7230, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000415, mae: 0.011762, mean_q: 0.012369
[Info] 1-TH LEVEL FOUND: 0.031621530652046204, Considering 10/100 traces
 53763/100000: episode: 7231, duration: 0.732s, episode steps: 10, steps per second: 14, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000196, mae: 0.009757, mean_q: 0.011113
 53770/100000: episode: 7232, duration: 0.039s, episode steps: 7, steps per second: 181, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000224, mae: 0.008945, mean_q: 0.010529
 53774/100000: episode: 7233, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000142, mae: 0.008129, mean_q: 0.007205
 53781/100000: episode: 7234, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000703, mae: 0.012732, mean_q: 0.013481
 53785/100000: episode: 7235, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000264, mae: 0.012813, mean_q: 0.012264
 53792/100000: episode: 7236, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000785, mae: 0.013202, mean_q: 0.010096
 53799/100000: episode: 7237, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000299, mae: 0.014435, mean_q: 0.005008
 53803/100000: episode: 7238, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000330, mae: 0.018429, mean_q: 0.024935
 53810/100000: episode: 7239, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000704, mae: 0.020160, mean_q: 0.008298
 53814/100000: episode: 7240, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000174, mae: 0.012703, mean_q: 0.003579
 53821/100000: episode: 7241, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000364, mae: 0.013343, mean_q: 0.020140
 53825/100000: episode: 7242, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000151, mae: 0.012325, mean_q: 0.002124
 53832/100000: episode: 7243, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000181, mae: 0.008862, mean_q: 0.011171
 53836/100000: episode: 7244, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000450, mae: 0.013882, mean_q: 0.012854
 53843/100000: episode: 7245, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000169, mae: 0.009165, mean_q: 0.007182
 53850/100000: episode: 7246, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000111, mae: 0.006542, mean_q: 0.007627
 53857/100000: episode: 7247, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000193, mae: 0.008089, mean_q: 0.009374
 53864/100000: episode: 7248, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000134, mae: 0.010389, mean_q: 0.010191
 53868/100000: episode: 7249, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000262, mae: 0.010193, mean_q: 0.015962
 53875/100000: episode: 7250, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000174, mae: 0.011132, mean_q: 0.000206
[Info] FALSIFICATION!
 53881/100000: episode: 7251, duration: 0.264s, episode steps: 6, steps per second: 23, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000241, mae: 0.012646, mean_q: 0.012468
 53888/100000: episode: 7252, duration: 0.036s, episode steps: 7, steps per second: 192, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000625, mae: 0.008932, mean_q: 0.012010
 53895/100000: episode: 7253, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000145, mae: 0.007739, mean_q: 0.009848
 53902/100000: episode: 7254, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000265, mae: 0.007807, mean_q: 0.008466
 53909/100000: episode: 7255, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000172, mae: 0.006781, mean_q: 0.008547
 53916/100000: episode: 7256, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000385, mae: 0.007965, mean_q: 0.011151
 53920/100000: episode: 7257, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000298, mae: 0.013009, mean_q: 0.019101
 53924/100000: episode: 7258, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000559, mae: 0.015644, mean_q: 0.001289
 53931/100000: episode: 7259, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000229, mae: 0.011077, mean_q: 0.011930
 53938/100000: episode: 7260, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000130, mae: 0.006066, mean_q: 0.007982
 53945/100000: episode: 7261, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000102, mae: 0.006716, mean_q: 0.006398
 53949/100000: episode: 7262, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000214, mae: 0.007069, mean_q: 0.008159
 53956/100000: episode: 7263, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000127, mae: 0.007763, mean_q: 0.008688
 53963/100000: episode: 7264, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000176, mae: 0.009362, mean_q: 0.012109
 53970/100000: episode: 7265, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000371, mae: 0.009344, mean_q: 0.008669
 53977/100000: episode: 7266, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000416, mae: 0.013320, mean_q: 0.016499
 53984/100000: episode: 7267, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000225, mae: 0.010463, mean_q: 0.003383
 53988/100000: episode: 7268, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000022, mae: 0.003965, mean_q: 0.007133
 53992/100000: episode: 7269, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000134, mae: 0.006530, mean_q: 0.011208
 53996/100000: episode: 7270, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000630, mae: 0.008659, mean_q: 0.010872
 54000/100000: episode: 7271, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000341, mae: 0.009853, mean_q: 0.009816
 54007/100000: episode: 7272, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000122, mae: 0.007402, mean_q: 0.006291
 54014/100000: episode: 7273, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000053, mae: 0.005466, mean_q: 0.008726
 54018/100000: episode: 7274, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000285, mae: 0.006508, mean_q: 0.011669
 54025/100000: episode: 7275, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000085, mae: 0.005202, mean_q: 0.007170
 54032/100000: episode: 7276, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000117, mae: 0.005975, mean_q: 0.006688
 54039/100000: episode: 7277, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000445, mae: 0.008303, mean_q: 0.012983
 54043/100000: episode: 7278, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000131, mae: 0.006919, mean_q: 0.007736
 54050/100000: episode: 7279, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000169, mae: 0.006180, mean_q: 0.006123
 54057/100000: episode: 7280, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000206, mae: 0.008614, mean_q: 0.013301
 54064/100000: episode: 7281, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000298, mae: 0.009049, mean_q: 0.014111
 54071/100000: episode: 7282, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000553, mae: 0.012591, mean_q: 0.015096
 54075/100000: episode: 7283, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000673, mae: 0.014189, mean_q: 0.017223
 54079/100000: episode: 7284, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000706, mae: 0.017040, mean_q: 0.027743
 54086/100000: episode: 7285, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000156, mae: 0.010814, mean_q: 0.004948
 54090/100000: episode: 7286, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000512, mae: 0.008862, mean_q: 0.016081
 54094/100000: episode: 7287, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000133, mae: 0.007414, mean_q: 0.009068
 54101/100000: episode: 7288, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000276, mae: 0.009615, mean_q: 0.010863
 54105/100000: episode: 7289, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000057, mae: 0.005820, mean_q: 0.007315
 54112/100000: episode: 7290, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000106, mae: 0.008203, mean_q: 0.007128
 54119/100000: episode: 7291, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000136, mae: 0.009004, mean_q: 0.008505
 54126/100000: episode: 7292, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000119, mae: 0.007655, mean_q: 0.010936
 54130/100000: episode: 7293, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000195, mae: 0.011301, mean_q: 0.004883
 54137/100000: episode: 7294, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000205, mae: 0.009807, mean_q: 0.007976
 54144/100000: episode: 7295, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000424, mae: 0.013009, mean_q: 0.009792
 54151/100000: episode: 7296, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001407, mae: 0.018092, mean_q: 0.019502
 54155/100000: episode: 7297, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000143, mae: 0.012783, mean_q: -0.005756
 54159/100000: episode: 7298, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000100, mae: 0.009627, mean_q: 0.014932
 54163/100000: episode: 7299, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000463, mae: 0.014074, mean_q: 0.005965
 54170/100000: episode: 7300, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000415, mae: 0.013442, mean_q: 0.027129
 54174/100000: episode: 7301, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000233, mae: 0.011566, mean_q: 0.000372
 54181/100000: episode: 7302, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000229, mae: 0.008791, mean_q: 0.008101
 54188/100000: episode: 7303, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000327, mae: 0.009805, mean_q: 0.015613
 54192/100000: episode: 7304, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000168, mae: 0.009742, mean_q: 0.012651
[Info] FALSIFICATION!
 54198/100000: episode: 7305, duration: 0.267s, episode steps: 6, steps per second: 22, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000236, mae: 0.009356, mean_q: 0.010767
 54202/100000: episode: 7306, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000270, mae: 0.008583, mean_q: 0.013979
 54206/100000: episode: 7307, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000102, mae: 0.008159, mean_q: 0.016798
 54213/100000: episode: 7308, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000181, mae: 0.007162, mean_q: 0.007611
 54217/100000: episode: 7309, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000080, mae: 0.005954, mean_q: 0.005131
 54221/100000: episode: 7310, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000859, mae: 0.013492, mean_q: 0.011022
 54228/100000: episode: 7311, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000219, mae: 0.010101, mean_q: 0.016010
 54235/100000: episode: 7312, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000249, mae: 0.009741, mean_q: 0.013631
 54242/100000: episode: 7313, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000213, mae: 0.008273, mean_q: 0.010868
 54246/100000: episode: 7314, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000041, mae: 0.004814, mean_q: 0.006337
 54250/100000: episode: 7315, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000554, mae: 0.013753, mean_q: 0.005631
 54254/100000: episode: 7316, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000092, mae: 0.009842, mean_q: 0.012549
 54261/100000: episode: 7317, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000379, mae: 0.009708, mean_q: 0.004803
 54268/100000: episode: 7318, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000238, mae: 0.010209, mean_q: 0.008846
 54272/100000: episode: 7319, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000412, mae: 0.012618, mean_q: 0.013327
 54279/100000: episode: 7320, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000435, mae: 0.014654, mean_q: 0.011227
[Info] Complete ISplit Iteration
[Info] Levels: [0.03162153, 0.9280768]
[Info] Cond. Prob: [0.1, 0.02]
[Info] Error Prob: 0.002

 54286/100000: episode: 7321, duration: 0.855s, episode steps: 7, steps per second: 8, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000265, mae: 0.009640, mean_q: 0.009241
 54296/100000: episode: 7322, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000460, mae: 0.015539, mean_q: 0.013681
 54306/100000: episode: 7323, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000165, mae: 0.009868, mean_q: 0.009961
 54316/100000: episode: 7324, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000692, mae: 0.012615, mean_q: 0.014694
 54326/100000: episode: 7325, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000543, mae: 0.013103, mean_q: 0.014729
 54336/100000: episode: 7326, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000284, mae: 0.011147, mean_q: 0.012628
 54346/100000: episode: 7327, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000301, mae: 0.011349, mean_q: 0.013510
 54356/100000: episode: 7328, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000166, mae: 0.010995, mean_q: 0.009707
 54366/100000: episode: 7329, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000278, mae: 0.009209, mean_q: 0.010160
 54376/100000: episode: 7330, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000080, mae: 0.005572, mean_q: 0.006916
 54386/100000: episode: 7331, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000103, mae: 0.006500, mean_q: 0.008203
 54396/100000: episode: 7332, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000417, mae: 0.008481, mean_q: 0.011037
 54406/100000: episode: 7333, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000184, mae: 0.009588, mean_q: 0.007825
 54416/100000: episode: 7334, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000383, mae: 0.010657, mean_q: 0.012963
 54426/100000: episode: 7335, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000198, mae: 0.009469, mean_q: 0.010525
 54436/100000: episode: 7336, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000266, mae: 0.009254, mean_q: 0.010223
 54446/100000: episode: 7337, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000328, mae: 0.009650, mean_q: 0.012600
 54456/100000: episode: 7338, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000146, mae: 0.008270, mean_q: 0.006632
 54466/100000: episode: 7339, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000368, mae: 0.010281, mean_q: 0.014145
 54476/100000: episode: 7340, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000292, mae: 0.007008, mean_q: 0.005914
 54486/100000: episode: 7341, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000246, mae: 0.013930, mean_q: 0.010614
 54496/100000: episode: 7342, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000152, mae: 0.007187, mean_q: 0.006769
 54506/100000: episode: 7343, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000335, mae: 0.012891, mean_q: 0.014980
 54516/100000: episode: 7344, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000616, mae: 0.015601, mean_q: 0.012765
 54526/100000: episode: 7345, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000745, mae: 0.016652, mean_q: 0.015159
 54536/100000: episode: 7346, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000156, mae: 0.010506, mean_q: 0.008515
 54546/100000: episode: 7347, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000271, mae: 0.012612, mean_q: 0.012956
 54556/100000: episode: 7348, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000320, mae: 0.012487, mean_q: 0.010386
 54566/100000: episode: 7349, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000219, mae: 0.010466, mean_q: 0.007150
 54576/100000: episode: 7350, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000297, mae: 0.013080, mean_q: 0.011316
 54586/100000: episode: 7351, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000203, mae: 0.011192, mean_q: 0.010500
 54596/100000: episode: 7352, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000465, mae: 0.015303, mean_q: 0.007783
 54606/100000: episode: 7353, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000203, mae: 0.009055, mean_q: 0.010269
 54616/100000: episode: 7354, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000386, mae: 0.009602, mean_q: 0.010896
 54626/100000: episode: 7355, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000324, mae: 0.009003, mean_q: 0.009741
 54636/100000: episode: 7356, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000174, mae: 0.007894, mean_q: 0.009549
 54646/100000: episode: 7357, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000154, mae: 0.008828, mean_q: 0.010640
 54656/100000: episode: 7358, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000092, mae: 0.006609, mean_q: 0.007929
 54666/100000: episode: 7359, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000161, mae: 0.008330, mean_q: 0.008458
 54676/100000: episode: 7360, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000186, mae: 0.010687, mean_q: 0.007278
 54686/100000: episode: 7361, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000288, mae: 0.009455, mean_q: 0.012502
 54696/100000: episode: 7362, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000160, mae: 0.008157, mean_q: 0.009670
 54706/100000: episode: 7363, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000306, mae: 0.008297, mean_q: 0.008509
 54716/100000: episode: 7364, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000150, mae: 0.008898, mean_q: 0.006315
 54726/100000: episode: 7365, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000052, mae: 0.006794, mean_q: 0.006394
 54736/100000: episode: 7366, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000433, mae: 0.013594, mean_q: 0.012965
 54746/100000: episode: 7367, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000121, mae: 0.007355, mean_q: 0.006582
 54756/100000: episode: 7368, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000370, mae: 0.009319, mean_q: 0.010999
 54766/100000: episode: 7369, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000174, mae: 0.008761, mean_q: 0.009118
 54776/100000: episode: 7370, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000298, mae: 0.009247, mean_q: 0.012635
 54786/100000: episode: 7371, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000290, mae: 0.008027, mean_q: 0.009713
 54796/100000: episode: 7372, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000173, mae: 0.008432, mean_q: 0.008741
 54806/100000: episode: 7373, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000103, mae: 0.008581, mean_q: 0.005516
 54816/100000: episode: 7374, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000279, mae: 0.009377, mean_q: 0.011077
 54826/100000: episode: 7375, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000504, mae: 0.015138, mean_q: 0.011764
 54836/100000: episode: 7376, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000085, mae: 0.008331, mean_q: 0.007851
 54846/100000: episode: 7377, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000116, mae: 0.006086, mean_q: 0.006147
 54856/100000: episode: 7378, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000158, mae: 0.008350, mean_q: 0.008327
 54866/100000: episode: 7379, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000378, mae: 0.011824, mean_q: 0.014088
 54876/100000: episode: 7380, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000446, mae: 0.011723, mean_q: 0.011642
 54886/100000: episode: 7381, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000097, mae: 0.007891, mean_q: 0.006662
 54896/100000: episode: 7382, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000339, mae: 0.009357, mean_q: 0.012877
 54906/100000: episode: 7383, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000284, mae: 0.010302, mean_q: 0.008711
 54916/100000: episode: 7384, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000167, mae: 0.008747, mean_q: 0.007079
 54926/100000: episode: 7385, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000206, mae: 0.008528, mean_q: 0.008453
 54936/100000: episode: 7386, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000203, mae: 0.008345, mean_q: 0.009416
 54946/100000: episode: 7387, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000159, mae: 0.009799, mean_q: 0.009482
 54956/100000: episode: 7388, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000263, mae: 0.008887, mean_q: 0.013959
 54966/100000: episode: 7389, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000134, mae: 0.008195, mean_q: 0.008992
 54976/100000: episode: 7390, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000146, mae: 0.008561, mean_q: 0.007434
 54986/100000: episode: 7391, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000117, mae: 0.007905, mean_q: 0.012630
 54996/100000: episode: 7392, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000231, mae: 0.009921, mean_q: 0.010568
 55006/100000: episode: 7393, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000206, mae: 0.008652, mean_q: 0.010601
 55016/100000: episode: 7394, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000325, mae: 0.010921, mean_q: 0.008755
 55026/100000: episode: 7395, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000696, mae: 0.014503, mean_q: 0.011403
 55036/100000: episode: 7396, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000448, mae: 0.011560, mean_q: 0.011097
 55046/100000: episode: 7397, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000514, mae: 0.012574, mean_q: 0.012556
 55056/100000: episode: 7398, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000054, mae: 0.005871, mean_q: 0.006606
 55066/100000: episode: 7399, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000121, mae: 0.007606, mean_q: 0.007256
 55076/100000: episode: 7400, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000092, mae: 0.006986, mean_q: 0.008177
 55086/100000: episode: 7401, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000245, mae: 0.010029, mean_q: 0.007062
 55096/100000: episode: 7402, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000568, mae: 0.014298, mean_q: 0.012697
 55106/100000: episode: 7403, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000115, mae: 0.008523, mean_q: 0.009037
 55116/100000: episode: 7404, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000100, mae: 0.007291, mean_q: 0.007153
 55126/100000: episode: 7405, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000165, mae: 0.008384, mean_q: 0.008346
 55136/100000: episode: 7406, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000271, mae: 0.010154, mean_q: 0.008282
 55146/100000: episode: 7407, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000464, mae: 0.013908, mean_q: 0.010606
 55156/100000: episode: 7408, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000422, mae: 0.011696, mean_q: 0.010004
 55166/100000: episode: 7409, duration: 0.064s, episode steps: 10, steps per second: 155, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000218, mae: 0.007273, mean_q: 0.005931
 55176/100000: episode: 7410, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000091, mae: 0.006055, mean_q: 0.008231
 55186/100000: episode: 7411, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000071, mae: 0.005882, mean_q: 0.005874
 55196/100000: episode: 7412, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000120, mae: 0.008230, mean_q: 0.007593
 55206/100000: episode: 7413, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000437, mae: 0.008912, mean_q: 0.009464
 55216/100000: episode: 7414, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000327, mae: 0.007935, mean_q: 0.009389
 55226/100000: episode: 7415, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000241, mae: 0.007813, mean_q: 0.007658
 55236/100000: episode: 7416, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000242, mae: 0.008048, mean_q: 0.007903
 55246/100000: episode: 7417, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000064, mae: 0.005471, mean_q: 0.006630
 55256/100000: episode: 7418, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000152, mae: 0.008270, mean_q: 0.009437
 55266/100000: episode: 7419, duration: 0.132s, episode steps: 10, steps per second: 76, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000090, mae: 0.006552, mean_q: 0.006845
 55276/100000: episode: 7420, duration: 0.087s, episode steps: 10, steps per second: 114, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000140, mae: 0.006122, mean_q: 0.008096
[Info] 1-TH LEVEL FOUND: 0.028443709015846252, Considering 10/100 traces
 55286/100000: episode: 7421, duration: 1.088s, episode steps: 10, steps per second: 9, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000161, mae: 0.008809, mean_q: 0.005865
 55289/100000: episode: 7422, duration: 0.025s, episode steps: 3, steps per second: 121, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000061, mae: 0.007742, mean_q: 0.010727
 55293/100000: episode: 7423, duration: 0.026s, episode steps: 4, steps per second: 154, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000049, mae: 0.005564, mean_q: 0.003979
 55296/100000: episode: 7424, duration: 0.027s, episode steps: 3, steps per second: 111, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000020, mae: 0.004084, mean_q: 0.006100
 55302/100000: episode: 7425, duration: 0.047s, episode steps: 6, steps per second: 127, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000186, mae: 0.008845, mean_q: 0.011331
 55305/100000: episode: 7426, duration: 0.022s, episode steps: 3, steps per second: 134, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000068, mae: 0.007201, mean_q: 0.001757
 55309/100000: episode: 7427, duration: 0.032s, episode steps: 4, steps per second: 123, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000546, mae: 0.010082, mean_q: 0.014850
 55313/100000: episode: 7428, duration: 0.033s, episode steps: 4, steps per second: 120, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000096, mae: 0.007078, mean_q: 0.009155
 55316/100000: episode: 7429, duration: 0.020s, episode steps: 3, steps per second: 148, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000057, mae: 0.006635, mean_q: 0.007168
 55320/100000: episode: 7430, duration: 0.029s, episode steps: 4, steps per second: 139, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000027, mae: 0.004449, mean_q: 0.004600
 55326/100000: episode: 7431, duration: 0.034s, episode steps: 6, steps per second: 177, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000046, mae: 0.005689, mean_q: 0.008628
 55329/100000: episode: 7432, duration: 0.025s, episode steps: 3, steps per second: 122, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000092, mae: 0.006426, mean_q: 0.007077
 55332/100000: episode: 7433, duration: 0.025s, episode steps: 3, steps per second: 122, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000080, mae: 0.007689, mean_q: 0.012949
 55336/100000: episode: 7434, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000062, mae: 0.006821, mean_q: 0.005111
 55339/100000: episode: 7435, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000104, mae: 0.008943, mean_q: 0.013723
 55342/100000: episode: 7436, duration: 0.026s, episode steps: 3, steps per second: 116, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000131, mae: 0.009439, mean_q: 0.004076
 55345/100000: episode: 7437, duration: 0.024s, episode steps: 3, steps per second: 127, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000122, mae: 0.007048, mean_q: 0.006506
 55348/100000: episode: 7438, duration: 0.021s, episode steps: 3, steps per second: 142, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000136, mae: 0.009253, mean_q: 0.016295
 55354/100000: episode: 7439, duration: 0.038s, episode steps: 6, steps per second: 158, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000560, mae: 0.011555, mean_q: 0.007098
 55358/100000: episode: 7440, duration: 0.030s, episode steps: 4, steps per second: 133, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000199, mae: 0.008828, mean_q: 0.010087
 55361/100000: episode: 7441, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000037, mae: 0.005123, mean_q: 0.002274
 55365/100000: episode: 7442, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000045, mae: 0.006645, mean_q: 0.009897
 55369/100000: episode: 7443, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001081, mae: 0.012022, mean_q: 0.012267
 55375/100000: episode: 7444, duration: 0.040s, episode steps: 6, steps per second: 150, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000175, mae: 0.009865, mean_q: 0.011323
 55378/100000: episode: 7445, duration: 0.022s, episode steps: 3, steps per second: 135, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000238, mae: 0.009962, mean_q: 0.002452
 55381/100000: episode: 7446, duration: 0.020s, episode steps: 3, steps per second: 149, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000179, mae: 0.012072, mean_q: 0.016558
 55384/100000: episode: 7447, duration: 0.026s, episode steps: 3, steps per second: 114, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000636, mae: 0.018235, mean_q: -0.000414
 55387/100000: episode: 7448, duration: 0.024s, episode steps: 3, steps per second: 127, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000158, mae: 0.012889, mean_q: 0.014859
 55390/100000: episode: 7449, duration: 0.020s, episode steps: 3, steps per second: 148, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000132, mae: 0.006967, mean_q: 0.004815
 55394/100000: episode: 7450, duration: 0.027s, episode steps: 4, steps per second: 148, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000096, mae: 0.007251, mean_q: 0.007690
 55397/100000: episode: 7451, duration: 0.022s, episode steps: 3, steps per second: 137, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000225, mae: 0.008685, mean_q: 0.009224
 55401/100000: episode: 7452, duration: 0.025s, episode steps: 4, steps per second: 160, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000230, mae: 0.008073, mean_q: 0.009051
 55405/100000: episode: 7453, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000443, mae: 0.010639, mean_q: 0.011007
 55408/100000: episode: 7454, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000354, mae: 0.010285, mean_q: 0.012039
 55414/100000: episode: 7455, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000789, mae: 0.009892, mean_q: 0.009285
 55418/100000: episode: 7456, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000352, mae: 0.015556, mean_q: 0.019173
 55421/100000: episode: 7457, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000110, mae: 0.010018, mean_q: 0.004672
 55427/100000: episode: 7458, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000106, mae: 0.008399, mean_q: 0.008663
 55431/100000: episode: 7459, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000502, mae: 0.009385, mean_q: 0.013471
 55435/100000: episode: 7460, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000332, mae: 0.011544, mean_q: 0.008349
 55438/100000: episode: 7461, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000142, mae: 0.009576, mean_q: 0.013029
 55441/100000: episode: 7462, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000097, mae: 0.009191, mean_q: 0.006120
 55444/100000: episode: 7463, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000167, mae: 0.010107, mean_q: 0.010190
 55447/100000: episode: 7464, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000286, mae: 0.009445, mean_q: 0.012761
 55451/100000: episode: 7465, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000108, mae: 0.005685, mean_q: 0.007180
 55454/100000: episode: 7466, duration: 0.021s, episode steps: 3, steps per second: 146, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000067, mae: 0.006370, mean_q: 0.007876
 55457/100000: episode: 7467, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000229, mae: 0.007682, mean_q: 0.006357
 55461/100000: episode: 7468, duration: 0.024s, episode steps: 4, steps per second: 166, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000072, mae: 0.006804, mean_q: 0.009221
 55465/100000: episode: 7469, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000591, mae: 0.010720, mean_q: 0.010952
 55469/100000: episode: 7470, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000132, mae: 0.008680, mean_q: 0.010137
 55472/100000: episode: 7471, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000206, mae: 0.007445, mean_q: 0.006201
 55475/100000: episode: 7472, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000277, mae: 0.011882, mean_q: 0.016259
 55481/100000: episode: 7473, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000191, mae: 0.009472, mean_q: 0.006342
 55484/100000: episode: 7474, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000204, mae: 0.013581, mean_q: 0.018040
 55488/100000: episode: 7475, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000871, mae: 0.015964, mean_q: 0.015867
 55492/100000: episode: 7476, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000151, mae: 0.011263, mean_q: 0.005043
 55498/100000: episode: 7477, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000092, mae: 0.007503, mean_q: 0.007598
 55502/100000: episode: 7478, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000196, mae: 0.010625, mean_q: 0.013105
 55505/100000: episode: 7479, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000097, mae: 0.008616, mean_q: 0.000989
 55509/100000: episode: 7480, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000077, mae: 0.006725, mean_q: 0.010289
 55513/100000: episode: 7481, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000138, mae: 0.008831, mean_q: 0.005178
 55517/100000: episode: 7482, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000183, mae: 0.009180, mean_q: 0.011082
 55520/100000: episode: 7483, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000087, mae: 0.007337, mean_q: 0.006185
 55526/100000: episode: 7484, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000400, mae: 0.008150, mean_q: 0.011719
 55529/100000: episode: 7485, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000068, mae: 0.007308, mean_q: 0.004073
 55535/100000: episode: 7486, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000265, mae: 0.007143, mean_q: 0.007698
 55538/100000: episode: 7487, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000191, mae: 0.010039, mean_q: 0.012044
 55544/100000: episode: 7488, duration: 0.031s, episode steps: 6, steps per second: 191, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000616, mae: 0.010719, mean_q: 0.009367
 55547/100000: episode: 7489, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000248, mae: 0.012238, mean_q: 0.012328
 55553/100000: episode: 7490, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000085, mae: 0.008106, mean_q: 0.007889
 55557/100000: episode: 7491, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000231, mae: 0.010187, mean_q: 0.013488
 55560/100000: episode: 7492, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000459, mae: 0.014853, mean_q: 0.012334
 55566/100000: episode: 7493, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000354, mae: 0.012601, mean_q: 0.009417
 55569/100000: episode: 7494, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001006, mae: 0.019991, mean_q: 0.027352
 55572/100000: episode: 7495, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000188, mae: 0.016033, mean_q: -0.009846
 55578/100000: episode: 7496, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000513, mae: 0.018249, mean_q: 0.018280
 55582/100000: episode: 7497, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000820, mae: 0.014161, mean_q: 0.019483
 55585/100000: episode: 7498, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000146, mae: 0.010376, mean_q: 0.007086
 55591/100000: episode: 7499, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000326, mae: 0.013119, mean_q: 0.014476
 55594/100000: episode: 7500, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000224, mae: 0.012199, mean_q: 0.019664
 55598/100000: episode: 7501, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000205, mae: 0.009327, mean_q: 0.004629
 55601/100000: episode: 7502, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000146, mae: 0.011287, mean_q: 0.018748
 55605/100000: episode: 7503, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000107, mae: 0.010570, mean_q: -0.001076
 55608/100000: episode: 7504, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000233, mae: 0.014276, mean_q: 0.016964
 55612/100000: episode: 7505, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000793, mae: 0.014055, mean_q: 0.007599
 55615/100000: episode: 7506, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000085, mae: 0.008988, mean_q: 0.011347
 55618/100000: episode: 7507, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000089, mae: 0.006611, mean_q: 0.006132
 55624/100000: episode: 7508, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000327, mae: 0.009745, mean_q: 0.011257
 55630/100000: episode: 7509, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000180, mae: 0.007020, mean_q: 0.008454
 55633/100000: episode: 7510, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000350, mae: 0.012717, mean_q: 0.013593
[Info] 2-TH LEVEL FOUND: 0.04332375526428223, Considering 12/100 traces
 55636/100000: episode: 7511, duration: 0.674s, episode steps: 3, steps per second: 4, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000189, mae: 0.010248, mean_q: 0.007942
 55641/100000: episode: 7512, duration: 0.029s, episode steps: 5, steps per second: 171, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.001435, mae: 0.018506, mean_q: 0.019839
 55646/100000: episode: 7513, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000242, mae: 0.011639, mean_q: 0.012461
 55651/100000: episode: 7514, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000427, mae: 0.010554, mean_q: 0.010706
 55656/100000: episode: 7515, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000116, mae: 0.007505, mean_q: 0.006282
 55661/100000: episode: 7516, duration: 0.028s, episode steps: 5, steps per second: 179, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000373, mae: 0.013248, mean_q: 0.017504
 55666/100000: episode: 7517, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000566, mae: 0.013333, mean_q: 0.003962
[Info] FALSIFICATION!
 55670/100000: episode: 7518, duration: 0.182s, episode steps: 4, steps per second: 22, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000810, mae: 0.015759, mean_q: 0.012511
 55675/100000: episode: 7519, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000072, mae: 0.007838, mean_q: 0.009803
 55680/100000: episode: 7520, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002887, mae: 0.020406, mean_q: 0.021836
 55685/100000: episode: 7521, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000610, mae: 0.017016, mean_q: 0.005013
 55690/100000: episode: 7522, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000734, mae: 0.015670, mean_q: 0.013319
 55695/100000: episode: 7523, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000345, mae: 0.014350, mean_q: 0.016634
 55700/100000: episode: 7524, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000385, mae: 0.015587, mean_q: 0.012507
 55705/100000: episode: 7525, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001196, mae: 0.018358, mean_q: 0.016713
 55710/100000: episode: 7526, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000176, mae: 0.013989, mean_q: 0.016261
 55715/100000: episode: 7527, duration: 0.029s, episode steps: 5, steps per second: 173, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.003086, mae: 0.029753, mean_q: 0.032097
 55720/100000: episode: 7528, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000477, mae: 0.023138, mean_q: -0.000175
 55725/100000: episode: 7529, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000331, mae: 0.015128, mean_q: 0.002769
 55730/100000: episode: 7530, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000586, mae: 0.017751, mean_q: 0.029578
 55735/100000: episode: 7531, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000455, mae: 0.016063, mean_q: 0.006382
 55740/100000: episode: 7532, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000185, mae: 0.010020, mean_q: 0.006577
 55745/100000: episode: 7533, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000273, mae: 0.014186, mean_q: 0.018176
 55750/100000: episode: 7534, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000141, mae: 0.009662, mean_q: 0.009442
 55755/100000: episode: 7535, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000745, mae: 0.012933, mean_q: 0.013526
 55760/100000: episode: 7536, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000288, mae: 0.011968, mean_q: 0.018207
 55765/100000: episode: 7537, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000280, mae: 0.013162, mean_q: 0.012433
 55770/100000: episode: 7538, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000087, mae: 0.008356, mean_q: 0.005073
 55775/100000: episode: 7539, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002397, mae: 0.021070, mean_q: 0.019461
 55780/100000: episode: 7540, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000476, mae: 0.014546, mean_q: 0.001962
 55785/100000: episode: 7541, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000326, mae: 0.012121, mean_q: 0.009896
 55790/100000: episode: 7542, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000250, mae: 0.012863, mean_q: 0.019477
 55795/100000: episode: 7543, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000648, mae: 0.016330, mean_q: 0.018643
 55800/100000: episode: 7544, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001187, mae: 0.026622, mean_q: 0.009936
 55805/100000: episode: 7545, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000588, mae: 0.021282, mean_q: 0.017988
 55810/100000: episode: 7546, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000341, mae: 0.015712, mean_q: 0.020506
 55815/100000: episode: 7547, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000354, mae: 0.012479, mean_q: 0.005655
 55820/100000: episode: 7548, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000602, mae: 0.013921, mean_q: 0.019498
 55825/100000: episode: 7549, duration: 0.030s, episode steps: 5, steps per second: 166, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000474, mae: 0.014462, mean_q: 0.013549
 55830/100000: episode: 7550, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000139, mae: 0.009450, mean_q: 0.004656
 55835/100000: episode: 7551, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000486, mae: 0.011568, mean_q: 0.018765
 55840/100000: episode: 7552, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000727, mae: 0.015475, mean_q: 0.024551
 55845/100000: episode: 7553, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000337, mae: 0.013586, mean_q: 0.010677
 55850/100000: episode: 7554, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000726, mae: 0.014197, mean_q: 0.020377
[Info] FALSIFICATION!
 55854/100000: episode: 7555, duration: 0.271s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000601, mae: 0.012053, mean_q: 0.012092
 55859/100000: episode: 7556, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000483, mae: 0.017597, mean_q: 0.026121
 55864/100000: episode: 7557, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000714, mae: 0.016304, mean_q: 0.018461
[Info] FALSIFICATION!
 55868/100000: episode: 7558, duration: 0.274s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000439, mae: 0.010802, mean_q: 0.016014
 55873/100000: episode: 7559, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000382, mae: 0.015335, mean_q: 0.020438
 55878/100000: episode: 7560, duration: 0.025s, episode steps: 5, steps per second: 204, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000440, mae: 0.014830, mean_q: 0.014206
 55883/100000: episode: 7561, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000816, mae: 0.015350, mean_q: 0.010248
 55888/100000: episode: 7562, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000355, mae: 0.014839, mean_q: 0.021253
 55893/100000: episode: 7563, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001131, mae: 0.019771, mean_q: 0.015085
 55898/100000: episode: 7564, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001072, mae: 0.023585, mean_q: 0.031803
 55903/100000: episode: 7565, duration: 0.029s, episode steps: 5, steps per second: 171, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000723, mae: 0.020156, mean_q: 0.018601
 55908/100000: episode: 7566, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000315, mae: 0.014011, mean_q: 0.016925
 55913/100000: episode: 7567, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.003069, mae: 0.025962, mean_q: 0.023070
 55918/100000: episode: 7568, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000479, mae: 0.015986, mean_q: 0.018346
 55923/100000: episode: 7569, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001049, mae: 0.014737, mean_q: 0.021045
 55928/100000: episode: 7570, duration: 0.029s, episode steps: 5, steps per second: 174, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001054, mae: 0.018030, mean_q: 0.027654
 55933/100000: episode: 7571, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001400, mae: 0.019581, mean_q: 0.025103
 55938/100000: episode: 7572, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000649, mae: 0.014479, mean_q: 0.020287
 55943/100000: episode: 7573, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002133, mae: 0.020850, mean_q: 0.027896
 55948/100000: episode: 7574, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.001008, mae: 0.021506, mean_q: 0.009327
 55953/100000: episode: 7575, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001953, mae: 0.025195, mean_q: 0.030243
 55958/100000: episode: 7576, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000887, mae: 0.021969, mean_q: 0.016028
 55963/100000: episode: 7577, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000956, mae: 0.017831, mean_q: 0.027666
 55968/100000: episode: 7578, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000483, mae: 0.013586, mean_q: 0.016155
 55973/100000: episode: 7579, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000365, mae: 0.011875, mean_q: 0.013144
 55978/100000: episode: 7580, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000584, mae: 0.013364, mean_q: 0.008784
 55983/100000: episode: 7581, duration: 0.025s, episode steps: 5, steps per second: 204, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001037, mae: 0.020181, mean_q: 0.022296
 55988/100000: episode: 7582, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000419, mae: 0.012752, mean_q: 0.012065
 55993/100000: episode: 7583, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002776, mae: 0.028868, mean_q: 0.031181
 55998/100000: episode: 7584, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000758, mae: 0.024074, mean_q: 0.001539
 56003/100000: episode: 7585, duration: 0.032s, episode steps: 5, steps per second: 158, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001526, mae: 0.023518, mean_q: 0.035544
 56008/100000: episode: 7586, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000443, mae: 0.018057, mean_q: 0.008500
 56013/100000: episode: 7587, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000758, mae: 0.019411, mean_q: 0.020886
 56018/100000: episode: 7588, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001264, mae: 0.024365, mean_q: 0.026217
 56023/100000: episode: 7589, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001179, mae: 0.020866, mean_q: 0.014860
 56028/100000: episode: 7590, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000570, mae: 0.016513, mean_q: 0.024943
 56033/100000: episode: 7591, duration: 0.027s, episode steps: 5, steps per second: 189, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000544, mae: 0.013765, mean_q: 0.013191
 56038/100000: episode: 7592, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000536, mae: 0.020143, mean_q: 0.030139
 56043/100000: episode: 7593, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000805, mae: 0.020238, mean_q: 0.020097
 56048/100000: episode: 7594, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000400, mae: 0.014145, mean_q: 0.013587
 56053/100000: episode: 7595, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000996, mae: 0.017253, mean_q: 0.027428
 56058/100000: episode: 7596, duration: 0.030s, episode steps: 5, steps per second: 165, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000902, mae: 0.013027, mean_q: 0.014107
 56063/100000: episode: 7597, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001010, mae: 0.020051, mean_q: 0.027707
 56068/100000: episode: 7598, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000517, mae: 0.015484, mean_q: 0.018810
[Info] Complete ISplit Iteration
[Info] Levels: [0.028443709, 0.043323755, 0.86736983]
[Info] Cond. Prob: [0.1, 0.12, 0.03]
[Info] Error Prob: 0.00035999999999999997

 56073/100000: episode: 7599, duration: 0.787s, episode steps: 5, steps per second: 6, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000579, mae: 0.018006, mean_q: 0.012615
 56083/100000: episode: 7600, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000926, mae: 0.020894, mean_q: 0.018867
 56093/100000: episode: 7601, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001028, mae: 0.024840, mean_q: 0.024199
 56103/100000: episode: 7602, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000709, mae: 0.021954, mean_q: 0.016280
 56113/100000: episode: 7603, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000654, mae: 0.018595, mean_q: 0.016752
 56123/100000: episode: 7604, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000500, mae: 0.014938, mean_q: 0.013452
 56133/100000: episode: 7605, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000648, mae: 0.015408, mean_q: 0.022091
 56143/100000: episode: 7606, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001344, mae: 0.029643, mean_q: 0.021994
 56153/100000: episode: 7607, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000919, mae: 0.021719, mean_q: 0.019461
 56163/100000: episode: 7608, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000930, mae: 0.023930, mean_q: 0.022978
 56173/100000: episode: 7609, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001839, mae: 0.020031, mean_q: 0.024704
 56183/100000: episode: 7610, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001382, mae: 0.020830, mean_q: 0.023989
 56193/100000: episode: 7611, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001794, mae: 0.022183, mean_q: 0.023842
 56203/100000: episode: 7612, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000697, mae: 0.021484, mean_q: 0.020842
 56213/100000: episode: 7613, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001747, mae: 0.023456, mean_q: 0.018457
 56223/100000: episode: 7614, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000687, mae: 0.015595, mean_q: 0.017532
 56233/100000: episode: 7615, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001367, mae: 0.023300, mean_q: 0.025371
 56243/100000: episode: 7616, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000506, mae: 0.013548, mean_q: 0.017501
 56253/100000: episode: 7617, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000587, mae: 0.016967, mean_q: 0.012694
 56263/100000: episode: 7618, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000655, mae: 0.018580, mean_q: 0.022363
 56273/100000: episode: 7619, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001722, mae: 0.020935, mean_q: 0.027571
 56283/100000: episode: 7620, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000680, mae: 0.016454, mean_q: 0.023024
 56293/100000: episode: 7621, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001090, mae: 0.019460, mean_q: 0.025023
 56303/100000: episode: 7622, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000666, mae: 0.018377, mean_q: 0.020409
 56313/100000: episode: 7623, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001168, mae: 0.024387, mean_q: 0.025056
 56323/100000: episode: 7624, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001035, mae: 0.020320, mean_q: 0.027243
 56333/100000: episode: 7625, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000731, mae: 0.020500, mean_q: 0.019670
 56343/100000: episode: 7626, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000798, mae: 0.015878, mean_q: 0.021405
 56353/100000: episode: 7627, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001427, mae: 0.015299, mean_q: 0.021120
 56363/100000: episode: 7628, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000605, mae: 0.014716, mean_q: 0.022566
 56373/100000: episode: 7629, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001540, mae: 0.026906, mean_q: 0.023164
 56383/100000: episode: 7630, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000722, mae: 0.019067, mean_q: 0.015612
 56393/100000: episode: 7631, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000574, mae: 0.019028, mean_q: 0.021990
 56403/100000: episode: 7632, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000436, mae: 0.016476, mean_q: 0.017399
 56413/100000: episode: 7633, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001030, mae: 0.019450, mean_q: 0.025134
 56423/100000: episode: 7634, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000399, mae: 0.013974, mean_q: 0.015137
 56433/100000: episode: 7635, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001488, mae: 0.022683, mean_q: 0.020402
 56443/100000: episode: 7636, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000763, mae: 0.020367, mean_q: 0.023097
 56453/100000: episode: 7637, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000953, mae: 0.023204, mean_q: 0.033622
 56463/100000: episode: 7638, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000584, mae: 0.017222, mean_q: 0.020164
 56473/100000: episode: 7639, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.003121, mae: 0.035291, mean_q: 0.030817
 56483/100000: episode: 7640, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002204, mae: 0.030296, mean_q: 0.031893
 56493/100000: episode: 7641, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001199, mae: 0.021964, mean_q: 0.022635
 56503/100000: episode: 7642, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000899, mae: 0.016391, mean_q: 0.020411
 56513/100000: episode: 7643, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000850, mae: 0.018793, mean_q: 0.019259
 56523/100000: episode: 7644, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000514, mae: 0.015669, mean_q: 0.014679
 56533/100000: episode: 7645, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001269, mae: 0.025320, mean_q: 0.024224
 56543/100000: episode: 7646, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001868, mae: 0.020307, mean_q: 0.022956
 56553/100000: episode: 7647, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000607, mae: 0.019168, mean_q: 0.020956
 56563/100000: episode: 7648, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000662, mae: 0.016315, mean_q: 0.018474
 56573/100000: episode: 7649, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002027, mae: 0.032786, mean_q: 0.024097
 56583/100000: episode: 7650, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001332, mae: 0.026931, mean_q: 0.030944
 56593/100000: episode: 7651, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000782, mae: 0.016947, mean_q: 0.022040
 56603/100000: episode: 7652, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000787, mae: 0.019765, mean_q: 0.022146
 56613/100000: episode: 7653, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000634, mae: 0.018547, mean_q: 0.020397
 56623/100000: episode: 7654, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000521, mae: 0.016598, mean_q: 0.018261
 56633/100000: episode: 7655, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000363, mae: 0.014641, mean_q: 0.020157
 56643/100000: episode: 7656, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001434, mae: 0.021273, mean_q: 0.022343
 56653/100000: episode: 7657, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000892, mae: 0.017323, mean_q: 0.016929
 56663/100000: episode: 7658, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000825, mae: 0.021183, mean_q: 0.029391
 56673/100000: episode: 7659, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000999, mae: 0.022671, mean_q: 0.028767
 56683/100000: episode: 7660, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000663, mae: 0.015805, mean_q: 0.024908
 56693/100000: episode: 7661, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000432, mae: 0.016195, mean_q: 0.019779
 56703/100000: episode: 7662, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000486, mae: 0.017270, mean_q: 0.020686
 56713/100000: episode: 7663, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000702, mae: 0.017782, mean_q: 0.022749
 56723/100000: episode: 7664, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001870, mae: 0.023176, mean_q: 0.027014
 56733/100000: episode: 7665, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001184, mae: 0.022756, mean_q: 0.022781
 56743/100000: episode: 7666, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001941, mae: 0.022750, mean_q: 0.033034
 56753/100000: episode: 7667, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000791, mae: 0.018083, mean_q: 0.023286
 56763/100000: episode: 7668, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000746, mae: 0.019061, mean_q: 0.023630
 56773/100000: episode: 7669, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000794, mae: 0.015154, mean_q: 0.022721
 56783/100000: episode: 7670, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000827, mae: 0.016244, mean_q: 0.020527
 56793/100000: episode: 7671, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001133, mae: 0.022452, mean_q: 0.020360
 56803/100000: episode: 7672, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001844, mae: 0.026391, mean_q: 0.032071
 56813/100000: episode: 7673, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000748, mae: 0.014778, mean_q: 0.018645
 56823/100000: episode: 7674, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000821, mae: 0.020427, mean_q: 0.021072
 56833/100000: episode: 7675, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000721, mae: 0.020445, mean_q: 0.021924
 56843/100000: episode: 7676, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000897, mae: 0.018114, mean_q: 0.022178
 56853/100000: episode: 7677, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001241, mae: 0.022699, mean_q: 0.031254
 56863/100000: episode: 7678, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000813, mae: 0.018161, mean_q: 0.026867
 56873/100000: episode: 7679, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000675, mae: 0.017125, mean_q: 0.021246
 56883/100000: episode: 7680, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001741, mae: 0.019136, mean_q: 0.025903
 56893/100000: episode: 7681, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000691, mae: 0.019867, mean_q: 0.021821
 56903/100000: episode: 7682, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000544, mae: 0.013794, mean_q: 0.014095
 56913/100000: episode: 7683, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000654, mae: 0.013484, mean_q: 0.016147
 56923/100000: episode: 7684, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000628, mae: 0.015104, mean_q: 0.018512
 56933/100000: episode: 7685, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001033, mae: 0.019814, mean_q: 0.024696
 56943/100000: episode: 7686, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000661, mae: 0.019009, mean_q: 0.018727
 56953/100000: episode: 7687, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000667, mae: 0.016506, mean_q: 0.018771
 56963/100000: episode: 7688, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000927, mae: 0.017050, mean_q: 0.019496
 56973/100000: episode: 7689, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000947, mae: 0.022218, mean_q: 0.022195
 56983/100000: episode: 7690, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000767, mae: 0.017124, mean_q: 0.021507
 56993/100000: episode: 7691, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000562, mae: 0.015221, mean_q: 0.019453
 57003/100000: episode: 7692, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000632, mae: 0.016402, mean_q: 0.019343
 57013/100000: episode: 7693, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001326, mae: 0.018433, mean_q: 0.023307
 57023/100000: episode: 7694, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000804, mae: 0.021674, mean_q: 0.024590
 57033/100000: episode: 7695, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000850, mae: 0.017449, mean_q: 0.020467
 57043/100000: episode: 7696, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000656, mae: 0.017924, mean_q: 0.020686
 57053/100000: episode: 7697, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001542, mae: 0.020071, mean_q: 0.024248
 57063/100000: episode: 7698, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000637, mae: 0.018602, mean_q: 0.017313
[Info] 1-TH LEVEL FOUND: 0.01957133412361145, Considering 24/100 traces
 57073/100000: episode: 7699, duration: 0.858s, episode steps: 10, steps per second: 12, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000564, mae: 0.015692, mean_q: 0.018437
 57075/100000: episode: 7700, duration: 0.015s, episode steps: 2, steps per second: 134, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000543, mae: 0.014658, mean_q: 0.017759
 57077/100000: episode: 7701, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000230, mae: 0.008994, mean_q: 0.004886
 57079/100000: episode: 7702, duration: 0.014s, episode steps: 2, steps per second: 143, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001054, mae: 0.018658, mean_q: 0.020196
 57081/100000: episode: 7703, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001442, mae: 0.028089, mean_q: 0.032647
 57083/100000: episode: 7704, duration: 0.014s, episode steps: 2, steps per second: 139, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000460, mae: 0.013915, mean_q: 0.019126
 57085/100000: episode: 7705, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000398, mae: 0.012199, mean_q: 0.018987
 57087/100000: episode: 7706, duration: 0.018s, episode steps: 2, steps per second: 112, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000446, mae: 0.013364, mean_q: 0.013355
 57091/100000: episode: 7707, duration: 0.029s, episode steps: 4, steps per second: 139, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000545, mae: 0.013305, mean_q: 0.005861
 57093/100000: episode: 7708, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000856, mae: 0.022197, mean_q: 0.026369
 57095/100000: episode: 7709, duration: 0.020s, episode steps: 2, steps per second: 100, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001868, mae: 0.029584, mean_q: 0.042530
 57099/100000: episode: 7710, duration: 0.035s, episode steps: 4, steps per second: 115, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000739, mae: 0.020015, mean_q: 0.008650
 57101/100000: episode: 7711, duration: 0.024s, episode steps: 2, steps per second: 84, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002148, mae: 0.036151, mean_q: 0.058054
 57103/100000: episode: 7712, duration: 0.015s, episode steps: 2, steps per second: 131, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001752, mae: 0.029299, mean_q: 0.047208
 57110/100000: episode: 7713, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000736, mae: 0.022997, mean_q: 0.009759
 57114/100000: episode: 7714, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000660, mae: 0.018264, mean_q: 0.025894
 57116/100000: episode: 7715, duration: 0.017s, episode steps: 2, steps per second: 119, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001038, mae: 0.014142, mean_q: 0.015396
 57123/100000: episode: 7716, duration: 0.043s, episode steps: 7, steps per second: 164, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000564, mae: 0.019321, mean_q: 0.021237
 57125/100000: episode: 7717, duration: 0.029s, episode steps: 2, steps per second: 69, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000906, mae: 0.015827, mean_q: 0.019538
 57129/100000: episode: 7718, duration: 0.030s, episode steps: 4, steps per second: 135, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000940, mae: 0.024803, mean_q: 0.027752
 57133/100000: episode: 7719, duration: 0.026s, episode steps: 4, steps per second: 152, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000794, mae: 0.016139, mean_q: 0.017444
 57137/100000: episode: 7720, duration: 0.055s, episode steps: 4, steps per second: 72, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000972, mae: 0.019903, mean_q: 0.029238
 57139/100000: episode: 7721, duration: 0.032s, episode steps: 2, steps per second: 63, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001627, mae: 0.027594, mean_q: 0.040816
 57141/100000: episode: 7722, duration: 0.027s, episode steps: 2, steps per second: 74, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000701, mae: 0.025530, mean_q: 0.000200
 57143/100000: episode: 7723, duration: 0.034s, episode steps: 2, steps per second: 59, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000768, mae: 0.019980, mean_q: 0.031841
 57145/100000: episode: 7724, duration: 0.041s, episode steps: 2, steps per second: 49, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000388, mae: 0.020798, mean_q: 0.027907
 57147/100000: episode: 7725, duration: 0.031s, episode steps: 2, steps per second: 65, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001123, mae: 0.019050, mean_q: 0.020941
 57154/100000: episode: 7726, duration: 0.074s, episode steps: 7, steps per second: 94, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001097, mae: 0.019222, mean_q: 0.027075
 57158/100000: episode: 7727, duration: 0.067s, episode steps: 4, steps per second: 60, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000514, mae: 0.012737, mean_q: 0.010692
 57160/100000: episode: 7728, duration: 0.049s, episode steps: 2, steps per second: 41, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000325, mae: 0.014751, mean_q: 0.019493
 57162/100000: episode: 7729, duration: 0.064s, episode steps: 2, steps per second: 31, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000277, mae: 0.011819, mean_q: 0.014536
 57164/100000: episode: 7730, duration: 0.047s, episode steps: 2, steps per second: 43, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001186, mae: 0.024170, mean_q: 0.024833
 57166/100000: episode: 7731, duration: 0.038s, episode steps: 2, steps per second: 52, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000861, mae: 0.019709, mean_q: 0.033451
 57170/100000: episode: 7732, duration: 0.053s, episode steps: 4, steps per second: 75, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000594, mae: 0.016108, mean_q: 0.021046
 57172/100000: episode: 7733, duration: 0.025s, episode steps: 2, steps per second: 79, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000934, mae: 0.016976, mean_q: 0.011605
 57174/100000: episode: 7734, duration: 0.026s, episode steps: 2, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000763, mae: 0.017703, mean_q: 0.025817
 57176/100000: episode: 7735, duration: 0.029s, episode steps: 2, steps per second: 69, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004991, mae: 0.023061, mean_q: 0.018893
 57178/100000: episode: 7736, duration: 0.019s, episode steps: 2, steps per second: 103, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001536, mae: 0.028124, mean_q: 0.040280
 57180/100000: episode: 7737, duration: 0.020s, episode steps: 2, steps per second: 100, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000886, mae: 0.021117, mean_q: 0.014558
 57182/100000: episode: 7738, duration: 0.020s, episode steps: 2, steps per second: 98, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001006, mae: 0.023623, mean_q: 0.008106
 57184/100000: episode: 7739, duration: 0.020s, episode steps: 2, steps per second: 99, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000495, mae: 0.017455, mean_q: 0.027501
 57186/100000: episode: 7740, duration: 0.022s, episode steps: 2, steps per second: 89, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000624, mae: 0.020421, mean_q: 0.027100
 57188/100000: episode: 7741, duration: 0.019s, episode steps: 2, steps per second: 105, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000391, mae: 0.011790, mean_q: 0.017985
 57190/100000: episode: 7742, duration: 0.022s, episode steps: 2, steps per second: 90, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000234, mae: 0.008648, mean_q: 0.008771
 57192/100000: episode: 7743, duration: 0.027s, episode steps: 2, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000266, mae: 0.011105, mean_q: 0.015409
 57194/100000: episode: 7744, duration: 0.030s, episode steps: 2, steps per second: 67, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000144, mae: 0.007813, mean_q: 0.010080
 57196/100000: episode: 7745, duration: 0.028s, episode steps: 2, steps per second: 71, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000656, mae: 0.015689, mean_q: 0.012118
 57198/100000: episode: 7746, duration: 0.029s, episode steps: 2, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000453, mae: 0.012434, mean_q: 0.020752
 57200/100000: episode: 7747, duration: 0.033s, episode steps: 2, steps per second: 60, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001266, mae: 0.021401, mean_q: 0.040466
 57207/100000: episode: 7748, duration: 0.088s, episode steps: 7, steps per second: 80, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000619, mae: 0.018093, mean_q: 0.021856
 57209/100000: episode: 7749, duration: 0.036s, episode steps: 2, steps per second: 56, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000328, mae: 0.011948, mean_q: 0.015246
 57216/100000: episode: 7750, duration: 0.101s, episode steps: 7, steps per second: 69, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.001192, mae: 0.021722, mean_q: 0.026520
 57220/100000: episode: 7751, duration: 0.049s, episode steps: 4, steps per second: 82, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000807, mae: 0.017913, mean_q: 0.021779
 57222/100000: episode: 7752, duration: 0.042s, episode steps: 2, steps per second: 48, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001712, mae: 0.026296, mean_q: 0.028134
 57224/100000: episode: 7753, duration: 0.023s, episode steps: 2, steps per second: 85, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002495, mae: 0.026877, mean_q: 0.035955
 57226/100000: episode: 7754, duration: 0.029s, episode steps: 2, steps per second: 69, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001518, mae: 0.023260, mean_q: 0.033650
 57230/100000: episode: 7755, duration: 0.048s, episode steps: 4, steps per second: 84, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000306, mae: 0.016999, mean_q: 0.025641
 57237/100000: episode: 7756, duration: 0.063s, episode steps: 7, steps per second: 110, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000707, mae: 0.016280, mean_q: 0.017173
 57239/100000: episode: 7757, duration: 0.019s, episode steps: 2, steps per second: 104, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000906, mae: 0.014754, mean_q: 0.025294
 57241/100000: episode: 7758, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001282, mae: 0.022921, mean_q: 0.020270
 57243/100000: episode: 7759, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000458, mae: 0.014063, mean_q: 0.015297
 57245/100000: episode: 7760, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000636, mae: 0.023646, mean_q: 0.034660
 57247/100000: episode: 7761, duration: 0.017s, episode steps: 2, steps per second: 115, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001034, mae: 0.020997, mean_q: 0.030120
 57249/100000: episode: 7762, duration: 0.017s, episode steps: 2, steps per second: 121, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000420, mae: 0.018667, mean_q: -0.000031
 57251/100000: episode: 7763, duration: 0.019s, episode steps: 2, steps per second: 107, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001106, mae: 0.017976, mean_q: 0.032055
 57253/100000: episode: 7764, duration: 0.027s, episode steps: 2, steps per second: 74, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005618, mae: 0.035952, mean_q: 0.035056
 57255/100000: episode: 7765, duration: 0.021s, episode steps: 2, steps per second: 94, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000994, mae: 0.023913, mean_q: 0.034180
 57257/100000: episode: 7766, duration: 0.023s, episode steps: 2, steps per second: 89, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000307, mae: 0.015057, mean_q: 0.007839
 57259/100000: episode: 7767, duration: 0.020s, episode steps: 2, steps per second: 100, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001495, mae: 0.024421, mean_q: 0.039243
 57263/100000: episode: 7768, duration: 0.041s, episode steps: 4, steps per second: 98, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000670, mae: 0.019533, mean_q: 0.032727
 57265/100000: episode: 7769, duration: 0.018s, episode steps: 2, steps per second: 112, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000807, mae: 0.026825, mean_q: 0.007407
 57267/100000: episode: 7770, duration: 0.018s, episode steps: 2, steps per second: 113, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005571, mae: 0.034354, mean_q: 0.016039
 57274/100000: episode: 7771, duration: 0.060s, episode steps: 7, steps per second: 117, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002008, mae: 0.028432, mean_q: 0.033635
 57276/100000: episode: 7772, duration: 0.020s, episode steps: 2, steps per second: 101, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001167, mae: 0.032894, mean_q: 0.000645
 57280/100000: episode: 7773, duration: 0.033s, episode steps: 4, steps per second: 120, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000583, mae: 0.022070, mean_q: 0.034748
 57284/100000: episode: 7774, duration: 0.026s, episode steps: 4, steps per second: 153, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001877, mae: 0.029127, mean_q: 0.032117
[Info] 2-TH LEVEL FOUND: 0.09252330660820007, Considering 14/100 traces
 57286/100000: episode: 7775, duration: 0.874s, episode steps: 2, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000427, mae: 0.014868, mean_q: 0.017246
 57289/100000: episode: 7776, duration: 0.054s, episode steps: 3, steps per second: 55, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000421, mae: 0.014984, mean_q: 0.017152
 57294/100000: episode: 7777, duration: 0.056s, episode steps: 5, steps per second: 89, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000727, mae: 0.015629, mean_q: 0.018669
 57297/100000: episode: 7778, duration: 0.026s, episode steps: 3, steps per second: 117, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000463, mae: 0.015843, mean_q: 0.017932
 57302/100000: episode: 7779, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001277, mae: 0.019846, mean_q: 0.030856
 57305/100000: episode: 7780, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000930, mae: 0.016030, mean_q: 0.020699
 57308/100000: episode: 7781, duration: 0.023s, episode steps: 3, steps per second: 130, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.004614, mae: 0.036670, mean_q: 0.029739
 57311/100000: episode: 7782, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003545, mae: 0.027772, mean_q: 0.032258
 57314/100000: episode: 7783, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000138, mae: 0.010485, mean_q: 0.006418
 57317/100000: episode: 7784, duration: 0.022s, episode steps: 3, steps per second: 135, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000715, mae: 0.015691, mean_q: 0.018962
 57320/100000: episode: 7785, duration: 0.019s, episode steps: 3, steps per second: 156, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000117, mae: 0.008219, mean_q: 0.008710
 57323/100000: episode: 7786, duration: 0.024s, episode steps: 3, steps per second: 123, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001492, mae: 0.023509, mean_q: 0.027186
 57326/100000: episode: 7787, duration: 0.024s, episode steps: 3, steps per second: 124, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000620, mae: 0.011505, mean_q: 0.018079
 57329/100000: episode: 7788, duration: 0.022s, episode steps: 3, steps per second: 139, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001323, mae: 0.021237, mean_q: 0.029512
 57332/100000: episode: 7789, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000967, mae: 0.025665, mean_q: 0.036838
 57335/100000: episode: 7790, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001156, mae: 0.029976, mean_q: 0.003702
 57340/100000: episode: 7791, duration: 0.036s, episode steps: 5, steps per second: 137, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000757, mae: 0.022805, mean_q: 0.035562
 57343/100000: episode: 7792, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001630, mae: 0.032663, mean_q: 0.007629
 57346/100000: episode: 7793, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001141, mae: 0.029596, mean_q: 0.040839
 57351/100000: episode: 7794, duration: 0.031s, episode steps: 5, steps per second: 162, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000757, mae: 0.020504, mean_q: 0.016600
 57354/100000: episode: 7795, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000473, mae: 0.016723, mean_q: 0.016050
 57359/100000: episode: 7796, duration: 0.042s, episode steps: 5, steps per second: 118, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000396, mae: 0.014126, mean_q: 0.014165
 57362/100000: episode: 7797, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000441, mae: 0.015790, mean_q: 0.016541
 57365/100000: episode: 7798, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001547, mae: 0.025320, mean_q: 0.035013
 57368/100000: episode: 7799, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001260, mae: 0.022968, mean_q: 0.020682
 57373/100000: episode: 7800, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000725, mae: 0.018285, mean_q: 0.024532
 57376/100000: episode: 7801, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001059, mae: 0.020410, mean_q: 0.013883
 57379/100000: episode: 7802, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004653, mae: 0.037796, mean_q: 0.043401
 57382/100000: episode: 7803, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001324, mae: 0.025368, mean_q: 0.038188
 57385/100000: episode: 7804, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000363, mae: 0.017396, mean_q: 0.003510
 57388/100000: episode: 7805, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000731, mae: 0.019730, mean_q: 0.031611
 57391/100000: episode: 7806, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000457, mae: 0.015832, mean_q: 0.016140
 57396/100000: episode: 7807, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000615, mae: 0.018227, mean_q: 0.031259
 57399/100000: episode: 7808, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000873, mae: 0.017335, mean_q: 0.013147
 57402/100000: episode: 7809, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000290, mae: 0.011815, mean_q: 0.013560
 57405/100000: episode: 7810, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000912, mae: 0.016123, mean_q: 0.024137
 57408/100000: episode: 7811, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001034, mae: 0.017982, mean_q: 0.023448
 57411/100000: episode: 7812, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003567, mae: 0.027056, mean_q: 0.018044
 57416/100000: episode: 7813, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000530, mae: 0.018821, mean_q: 0.022869
 57419/100000: episode: 7814, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000540, mae: 0.019889, mean_q: 0.004086
 57422/100000: episode: 7815, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003428, mae: 0.033525, mean_q: 0.037074
 57425/100000: episode: 7816, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001083, mae: 0.024174, mean_q: 0.011381
 57428/100000: episode: 7817, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001613, mae: 0.028006, mean_q: 0.043729
 57431/100000: episode: 7818, duration: 0.023s, episode steps: 3, steps per second: 130, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000913, mae: 0.030585, mean_q: 0.048823
 57436/100000: episode: 7819, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001333, mae: 0.028531, mean_q: 0.013741
 57439/100000: episode: 7820, duration: 0.020s, episode steps: 3, steps per second: 153, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000393, mae: 0.020651, mean_q: 0.027434
 57444/100000: episode: 7821, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.002502, mae: 0.021365, mean_q: 0.025953
 57449/100000: episode: 7822, duration: 0.029s, episode steps: 5, steps per second: 173, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000753, mae: 0.018972, mean_q: 0.023674
 57452/100000: episode: 7823, duration: 0.021s, episode steps: 3, steps per second: 146, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001176, mae: 0.025585, mean_q: 0.016676
 57455/100000: episode: 7824, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001026, mae: 0.024367, mean_q: 0.033086
 57458/100000: episode: 7825, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000383, mae: 0.018568, mean_q: 0.004155
 57461/100000: episode: 7826, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000847, mae: 0.019652, mean_q: 0.030162
 57464/100000: episode: 7827, duration: 0.021s, episode steps: 3, steps per second: 145, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000456, mae: 0.020157, mean_q: 0.029409
 57467/100000: episode: 7828, duration: 0.022s, episode steps: 3, steps per second: 137, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000922, mae: 0.024944, mean_q: 0.012961
 57470/100000: episode: 7829, duration: 0.029s, episode steps: 3, steps per second: 105, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000847, mae: 0.019096, mean_q: 0.022430
 57473/100000: episode: 7830, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000863, mae: 0.018961, mean_q: 0.029925
 57476/100000: episode: 7831, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000540, mae: 0.016463, mean_q: 0.005625
 57479/100000: episode: 7832, duration: 0.024s, episode steps: 3, steps per second: 123, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000417, mae: 0.018910, mean_q: 0.027004
 57484/100000: episode: 7833, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000394, mae: 0.015887, mean_q: 0.014203
 57487/100000: episode: 7834, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003849, mae: 0.028024, mean_q: 0.024428
 57490/100000: episode: 7835, duration: 0.021s, episode steps: 3, steps per second: 146, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000484, mae: 0.018930, mean_q: 0.026439
 57495/100000: episode: 7836, duration: 0.033s, episode steps: 5, steps per second: 153, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000926, mae: 0.017297, mean_q: 0.017497
 57500/100000: episode: 7837, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000964, mae: 0.017319, mean_q: 0.018869
 57503/100000: episode: 7838, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001399, mae: 0.026717, mean_q: 0.038635
 57508/100000: episode: 7839, duration: 0.030s, episode steps: 5, steps per second: 165, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000927, mae: 0.022275, mean_q: 0.021201
 57511/100000: episode: 7840, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000604, mae: 0.017510, mean_q: 0.023807
 57514/100000: episode: 7841, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000997, mae: 0.021057, mean_q: 0.022695
 57517/100000: episode: 7842, duration: 0.019s, episode steps: 3, steps per second: 157, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001030, mae: 0.021687, mean_q: 0.033720
 57520/100000: episode: 7843, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001009, mae: 0.015821, mean_q: 0.026413
 57523/100000: episode: 7844, duration: 0.021s, episode steps: 3, steps per second: 141, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001362, mae: 0.026191, mean_q: 0.044295
 57526/100000: episode: 7845, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000970, mae: 0.027780, mean_q: 0.013784
 57529/100000: episode: 7846, duration: 0.019s, episode steps: 3, steps per second: 155, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001061, mae: 0.026819, mean_q: 0.032889
 57532/100000: episode: 7847, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001343, mae: 0.028470, mean_q: 0.037562
 57535/100000: episode: 7848, duration: 0.020s, episode steps: 3, steps per second: 150, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.004039, mae: 0.038067, mean_q: 0.010349
 57538/100000: episode: 7849, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001030, mae: 0.026333, mean_q: 0.039225
 57541/100000: episode: 7850, duration: 0.021s, episode steps: 3, steps per second: 141, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000615, mae: 0.022566, mean_q: 0.014561
 57544/100000: episode: 7851, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001097, mae: 0.023515, mean_q: 0.029696
 57547/100000: episode: 7852, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000401, mae: 0.016807, mean_q: 0.023864
 57550/100000: episode: 7853, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000273, mae: 0.012777, mean_q: 0.014423
 57553/100000: episode: 7854, duration: 0.022s, episode steps: 3, steps per second: 136, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001101, mae: 0.020880, mean_q: 0.023703
 57556/100000: episode: 7855, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000677, mae: 0.022373, mean_q: 0.039069
 57559/100000: episode: 7856, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000687, mae: 0.021995, mean_q: 0.006889
 57562/100000: episode: 7857, duration: 0.023s, episode steps: 3, steps per second: 132, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001407, mae: 0.027049, mean_q: 0.034603
 57565/100000: episode: 7858, duration: 0.026s, episode steps: 3, steps per second: 116, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000651, mae: 0.024004, mean_q: 0.031305
 57568/100000: episode: 7859, duration: 0.020s, episode steps: 3, steps per second: 148, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000924, mae: 0.019964, mean_q: 0.017218
 57571/100000: episode: 7860, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001516, mae: 0.027834, mean_q: 0.029711
[Info] 3-TH LEVEL FOUND: 0.11818006634712219, Considering 46/100 traces
 57574/100000: episode: 7861, duration: 0.828s, episode steps: 3, steps per second: 4, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000760, mae: 0.028860, mean_q: 0.045106
 57578/100000: episode: 7862, duration: 0.042s, episode steps: 4, steps per second: 94, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001330, mae: 0.029768, mean_q: 0.022466
 57580/100000: episode: 7863, duration: 0.028s, episode steps: 2, steps per second: 72, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002184, mae: 0.032618, mean_q: 0.011146
 57582/100000: episode: 7864, duration: 0.020s, episode steps: 2, steps per second: 98, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001104, mae: 0.031247, mean_q: 0.040115
 57584/100000: episode: 7865, duration: 0.021s, episode steps: 2, steps per second: 93, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000903, mae: 0.023638, mean_q: 0.028638
 57586/100000: episode: 7866, duration: 0.020s, episode steps: 2, steps per second: 98, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002422, mae: 0.043603, mean_q: 0.011904
 57588/100000: episode: 7867, duration: 0.016s, episode steps: 2, steps per second: 122, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000399, mae: 0.016721, mean_q: 0.022558
 57592/100000: episode: 7868, duration: 0.026s, episode steps: 4, steps per second: 152, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000567, mae: 0.022449, mean_q: 0.027897
 57594/100000: episode: 7869, duration: 0.031s, episode steps: 2, steps per second: 65, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.010187, mae: 0.047322, mean_q: 0.019918
 57596/100000: episode: 7870, duration: 0.032s, episode steps: 2, steps per second: 63, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000600, mae: 0.023682, mean_q: 0.037358
 57598/100000: episode: 7871, duration: 0.030s, episode steps: 2, steps per second: 67, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000474, mae: 0.018411, mean_q: 0.026240
 57600/100000: episode: 7872, duration: 0.033s, episode steps: 2, steps per second: 60, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000726, mae: 0.021696, mean_q: 0.012566
 57602/100000: episode: 7873, duration: 0.033s, episode steps: 2, steps per second: 62, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000833, mae: 0.017367, mean_q: 0.015375
[Info] FALSIFICATION!
 57605/100000: episode: 7874, duration: 0.283s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001319, mae: 0.027882, mean_q: 0.026601
 57609/100000: episode: 7875, duration: 0.025s, episode steps: 4, steps per second: 160, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000648, mae: 0.018057, mean_q: 0.023538
 57611/100000: episode: 7876, duration: 0.015s, episode steps: 2, steps per second: 135, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001112, mae: 0.025516, mean_q: 0.029905
 57615/100000: episode: 7877, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000659, mae: 0.018170, mean_q: 0.019330
 57617/100000: episode: 7878, duration: 0.014s, episode steps: 2, steps per second: 142, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001674, mae: 0.024240, mean_q: 0.029298
 57619/100000: episode: 7879, duration: 0.016s, episode steps: 2, steps per second: 122, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000565, mae: 0.016756, mean_q: 0.020157
 57623/100000: episode: 7880, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000769, mae: 0.021012, mean_q: 0.024607
 57627/100000: episode: 7881, duration: 0.029s, episode steps: 4, steps per second: 139, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000746, mae: 0.019732, mean_q: 0.022203
 57629/100000: episode: 7882, duration: 0.017s, episode steps: 2, steps per second: 117, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000456, mae: 0.015571, mean_q: 0.024820
 57631/100000: episode: 7883, duration: 0.027s, episode steps: 2, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005383, mae: 0.039957, mean_q: 0.038192
 57633/100000: episode: 7884, duration: 0.028s, episode steps: 2, steps per second: 72, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000377, mae: 0.018816, mean_q: 0.003714
 57635/100000: episode: 7885, duration: 0.021s, episode steps: 2, steps per second: 97, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001215, mae: 0.022067, mean_q: 0.023472
 57637/100000: episode: 7886, duration: 0.024s, episode steps: 2, steps per second: 85, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001107, mae: 0.024737, mean_q: 0.038500
 57639/100000: episode: 7887, duration: 0.027s, episode steps: 2, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001498, mae: 0.020713, mean_q: 0.025579
 57643/100000: episode: 7888, duration: 0.070s, episode steps: 4, steps per second: 57, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001065, mae: 0.021947, mean_q: 0.028125
 57645/100000: episode: 7889, duration: 0.037s, episode steps: 2, steps per second: 55, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000323, mae: 0.012604, mean_q: 0.021595
 57647/100000: episode: 7890, duration: 0.027s, episode steps: 2, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002595, mae: 0.035280, mean_q: 0.050519
 57649/100000: episode: 7891, duration: 0.019s, episode steps: 2, steps per second: 106, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000812, mae: 0.022539, mean_q: 0.022427
 57653/100000: episode: 7892, duration: 0.037s, episode steps: 4, steps per second: 109, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001131, mae: 0.025129, mean_q: 0.021904
 57657/100000: episode: 7893, duration: 0.029s, episode steps: 4, steps per second: 136, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001182, mae: 0.034652, mean_q: 0.047248
 57659/100000: episode: 7894, duration: 0.027s, episode steps: 2, steps per second: 73, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000927, mae: 0.025039, mean_q: 0.040160
 57661/100000: episode: 7895, duration: 0.042s, episode steps: 2, steps per second: 47, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000467, mae: 0.021232, mean_q: 0.000093
 57663/100000: episode: 7896, duration: 0.032s, episode steps: 2, steps per second: 62, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000348, mae: 0.016403, mean_q: 0.016568
 57665/100000: episode: 7897, duration: 0.026s, episode steps: 2, steps per second: 77, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001298, mae: 0.031959, mean_q: 0.047850
 57667/100000: episode: 7898, duration: 0.024s, episode steps: 2, steps per second: 82, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000671, mae: 0.016730, mean_q: 0.023835
 57671/100000: episode: 7899, duration: 0.042s, episode steps: 4, steps per second: 95, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001651, mae: 0.028836, mean_q: 0.048057
 57673/100000: episode: 7900, duration: 0.029s, episode steps: 2, steps per second: 69, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000918, mae: 0.022564, mean_q: 0.037243
 57675/100000: episode: 7901, duration: 0.026s, episode steps: 2, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000569, mae: 0.019935, mean_q: 0.012561
 57677/100000: episode: 7902, duration: 0.029s, episode steps: 2, steps per second: 68, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001187, mae: 0.019281, mean_q: 0.023885
 57679/100000: episode: 7903, duration: 0.031s, episode steps: 2, steps per second: 64, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000937, mae: 0.025215, mean_q: 0.040600
 57683/100000: episode: 7904, duration: 0.053s, episode steps: 4, steps per second: 75, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000732, mae: 0.020531, mean_q: 0.027513
 57685/100000: episode: 7905, duration: 0.033s, episode steps: 2, steps per second: 60, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000208, mae: 0.013784, mean_q: 0.004174
 57687/100000: episode: 7906, duration: 0.029s, episode steps: 2, steps per second: 70, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000484, mae: 0.015334, mean_q: 0.019425
 57689/100000: episode: 7907, duration: 0.025s, episode steps: 2, steps per second: 80, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.007302, mae: 0.054495, mean_q: 0.075312
 57691/100000: episode: 7908, duration: 0.028s, episode steps: 2, steps per second: 73, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000792, mae: 0.020379, mean_q: 0.025677
 57693/100000: episode: 7909, duration: 0.024s, episode steps: 2, steps per second: 84, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000525, mae: 0.019410, mean_q: 0.014195
 57695/100000: episode: 7910, duration: 0.027s, episode steps: 2, steps per second: 75, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001372, mae: 0.023559, mean_q: 0.034570
 57697/100000: episode: 7911, duration: 0.028s, episode steps: 2, steps per second: 72, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000686, mae: 0.015986, mean_q: 0.018164
 57699/100000: episode: 7912, duration: 0.017s, episode steps: 2, steps per second: 115, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000915, mae: 0.019887, mean_q: 0.024710
 57701/100000: episode: 7913, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001560, mae: 0.023635, mean_q: 0.035447
 57703/100000: episode: 7914, duration: 0.015s, episode steps: 2, steps per second: 131, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001137, mae: 0.021808, mean_q: 0.028120
[Info] Complete ISplit Iteration
[Info] Levels: [0.019571334, 0.09252331, 0.11818007, 0.84855783]
[Info] Cond. Prob: [0.24, 0.14, 0.46, 0.01]
[Info] Error Prob: 0.00015456000000000004

 57705/100000: episode: 7915, duration: 0.989s, episode steps: 2, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001938, mae: 0.030301, mean_q: 0.037283
 57715/100000: episode: 7916, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001891, mae: 0.025903, mean_q: 0.027956
 57725/100000: episode: 7917, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002333, mae: 0.034439, mean_q: 0.037130
 57735/100000: episode: 7918, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000754, mae: 0.019939, mean_q: 0.021966
 57745/100000: episode: 7919, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001841, mae: 0.025595, mean_q: 0.029989
 57755/100000: episode: 7920, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000979, mae: 0.021461, mean_q: 0.025291
 57765/100000: episode: 7921, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000967, mae: 0.024968, mean_q: 0.029650
 57775/100000: episode: 7922, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.002077, mae: 0.026091, mean_q: 0.035276
 57785/100000: episode: 7923, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000782, mae: 0.018904, mean_q: 0.028511
 57795/100000: episode: 7924, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000948, mae: 0.020844, mean_q: 0.029227
 57805/100000: episode: 7925, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000837, mae: 0.018210, mean_q: 0.022448
 57815/100000: episode: 7926, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001038, mae: 0.019546, mean_q: 0.025825
 57825/100000: episode: 7927, duration: 0.055s, episode steps: 10, steps per second: 180, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001089, mae: 0.025817, mean_q: 0.022404
 57835/100000: episode: 7928, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002258, mae: 0.029324, mean_q: 0.032216
 57845/100000: episode: 7929, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001081, mae: 0.024629, mean_q: 0.028170
 57855/100000: episode: 7930, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001585, mae: 0.025073, mean_q: 0.031344
 57865/100000: episode: 7931, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001794, mae: 0.028412, mean_q: 0.026687
 57875/100000: episode: 7932, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001856, mae: 0.027469, mean_q: 0.023501
 57885/100000: episode: 7933, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001103, mae: 0.025841, mean_q: 0.025318
 57895/100000: episode: 7934, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001286, mae: 0.027640, mean_q: 0.035405
 57905/100000: episode: 7935, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002518, mae: 0.035173, mean_q: 0.037845
 57915/100000: episode: 7936, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002168, mae: 0.026619, mean_q: 0.032179
 57925/100000: episode: 7937, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001277, mae: 0.029186, mean_q: 0.035927
 57935/100000: episode: 7938, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001369, mae: 0.026534, mean_q: 0.041547
 57945/100000: episode: 7939, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001644, mae: 0.022242, mean_q: 0.023881
 57955/100000: episode: 7940, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000693, mae: 0.019533, mean_q: 0.023736
 57965/100000: episode: 7941, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001873, mae: 0.023471, mean_q: 0.030104
 57975/100000: episode: 7942, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002022, mae: 0.023657, mean_q: 0.026527
 57985/100000: episode: 7943, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000901, mae: 0.021873, mean_q: 0.026909
 57995/100000: episode: 7944, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001743, mae: 0.024543, mean_q: 0.030809
 58005/100000: episode: 7945, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001420, mae: 0.023459, mean_q: 0.030703
 58015/100000: episode: 7946, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000840, mae: 0.017513, mean_q: 0.018775
 58025/100000: episode: 7947, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000907, mae: 0.017803, mean_q: 0.022224
 58035/100000: episode: 7948, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000798, mae: 0.021483, mean_q: 0.026409
 58045/100000: episode: 7949, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000738, mae: 0.017072, mean_q: 0.024016
 58055/100000: episode: 7950, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000574, mae: 0.015820, mean_q: 0.017407
 58065/100000: episode: 7951, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000732, mae: 0.016395, mean_q: 0.021213
 58075/100000: episode: 7952, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001668, mae: 0.021891, mean_q: 0.029267
 58085/100000: episode: 7953, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000936, mae: 0.026614, mean_q: 0.026509
 58095/100000: episode: 7954, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002072, mae: 0.028077, mean_q: 0.035059
 58105/100000: episode: 7955, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001208, mae: 0.022807, mean_q: 0.027590
 58115/100000: episode: 7956, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001428, mae: 0.023083, mean_q: 0.028781
 58125/100000: episode: 7957, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000889, mae: 0.022647, mean_q: 0.021903
 58135/100000: episode: 7958, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001968, mae: 0.026024, mean_q: 0.029475
 58145/100000: episode: 7959, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000958, mae: 0.021693, mean_q: 0.021450
 58155/100000: episode: 7960, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000738, mae: 0.020145, mean_q: 0.019890
 58165/100000: episode: 7961, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002016, mae: 0.023487, mean_q: 0.025375
 58175/100000: episode: 7962, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001408, mae: 0.028039, mean_q: 0.026469
 58185/100000: episode: 7963, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001974, mae: 0.030441, mean_q: 0.025048
 58195/100000: episode: 7964, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001536, mae: 0.025062, mean_q: 0.035812
 58205/100000: episode: 7965, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001777, mae: 0.027101, mean_q: 0.027951
 58215/100000: episode: 7966, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001283, mae: 0.024074, mean_q: 0.030485
 58225/100000: episode: 7967, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000932, mae: 0.021264, mean_q: 0.029556
 58235/100000: episode: 7968, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001461, mae: 0.020288, mean_q: 0.023682
 58245/100000: episode: 7969, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000496, mae: 0.015594, mean_q: 0.016367
 58255/100000: episode: 7970, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000866, mae: 0.019376, mean_q: 0.026613
 58265/100000: episode: 7971, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000764, mae: 0.018588, mean_q: 0.020645
 58275/100000: episode: 7972, duration: 0.078s, episode steps: 10, steps per second: 129, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000812, mae: 0.020305, mean_q: 0.020656
 58285/100000: episode: 7973, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002066, mae: 0.025418, mean_q: 0.029649
 58295/100000: episode: 7974, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001134, mae: 0.021804, mean_q: 0.026171
 58305/100000: episode: 7975, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001011, mae: 0.024972, mean_q: 0.027360
 58315/100000: episode: 7976, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000746, mae: 0.016654, mean_q: 0.023477
 58325/100000: episode: 7977, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002279, mae: 0.031267, mean_q: 0.027261
 58335/100000: episode: 7978, duration: 0.098s, episode steps: 10, steps per second: 102, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001667, mae: 0.024676, mean_q: 0.025393
 58345/100000: episode: 7979, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001656, mae: 0.025623, mean_q: 0.027835
 58355/100000: episode: 7980, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000460, mae: 0.018303, mean_q: 0.017780
 58365/100000: episode: 7981, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000843, mae: 0.023646, mean_q: 0.029929
 58375/100000: episode: 7982, duration: 0.070s, episode steps: 10, steps per second: 144, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000763, mae: 0.019508, mean_q: 0.022186
 58385/100000: episode: 7983, duration: 0.091s, episode steps: 10, steps per second: 109, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001757, mae: 0.021644, mean_q: 0.028870
 58395/100000: episode: 7984, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000733, mae: 0.018249, mean_q: 0.020585
 58405/100000: episode: 7985, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000860, mae: 0.017082, mean_q: 0.023652
 58415/100000: episode: 7986, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001441, mae: 0.021786, mean_q: 0.027545
 58425/100000: episode: 7987, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000656, mae: 0.018506, mean_q: 0.022667
 58435/100000: episode: 7988, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000741, mae: 0.021326, mean_q: 0.019592
 58445/100000: episode: 7989, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000694, mae: 0.019534, mean_q: 0.020602
 58455/100000: episode: 7990, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000644, mae: 0.018095, mean_q: 0.018842
 58465/100000: episode: 7991, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001466, mae: 0.025005, mean_q: 0.031965
 58475/100000: episode: 7992, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000405, mae: 0.013214, mean_q: 0.013855
 58485/100000: episode: 7993, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000695, mae: 0.015709, mean_q: 0.020492
 58495/100000: episode: 7994, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000727, mae: 0.016519, mean_q: 0.017297
 58505/100000: episode: 7995, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000608, mae: 0.015755, mean_q: 0.020858
 58515/100000: episode: 7996, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000889, mae: 0.017263, mean_q: 0.020550
 58525/100000: episode: 7997, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001748, mae: 0.019107, mean_q: 0.023233
 58535/100000: episode: 7998, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000801, mae: 0.021421, mean_q: 0.029805
 58545/100000: episode: 7999, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001613, mae: 0.022397, mean_q: 0.027966
 58555/100000: episode: 8000, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000721, mae: 0.017689, mean_q: 0.020249
 58565/100000: episode: 8001, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000663, mae: 0.018172, mean_q: 0.018384
 58575/100000: episode: 8002, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000810, mae: 0.019497, mean_q: 0.021653
 58585/100000: episode: 8003, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000954, mae: 0.019835, mean_q: 0.020785
 58595/100000: episode: 8004, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000665, mae: 0.014935, mean_q: 0.019414
 58605/100000: episode: 8005, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.001691, mae: 0.020889, mean_q: 0.020005
 58615/100000: episode: 8006, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002120, mae: 0.026825, mean_q: 0.029578
 58625/100000: episode: 8007, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000710, mae: 0.015411, mean_q: 0.020332
 58635/100000: episode: 8008, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000505, mae: 0.016466, mean_q: 0.016580
 58645/100000: episode: 8009, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001000, mae: 0.018109, mean_q: 0.022401
 58655/100000: episode: 8010, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000738, mae: 0.018089, mean_q: 0.018096
 58665/100000: episode: 8011, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001942, mae: 0.021556, mean_q: 0.024791
 58675/100000: episode: 8012, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000765, mae: 0.022922, mean_q: 0.017111
 58685/100000: episode: 8013, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001946, mae: 0.024519, mean_q: 0.031413
 58695/100000: episode: 8014, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001009, mae: 0.019536, mean_q: 0.026851
[Info] 1-TH LEVEL FOUND: 0.03332057595252991, Considering 12/100 traces
 58705/100000: episode: 8015, duration: 0.750s, episode steps: 10, steps per second: 13, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001760, mae: 0.021122, mean_q: 0.019942
 58713/100000: episode: 8016, duration: 0.040s, episode steps: 8, steps per second: 201, episode reward: 0.114, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001911, mae: 0.025879, mean_q: 0.019739
 58721/100000: episode: 8017, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000594, mae: 0.015985, mean_q: 0.017084
 58725/100000: episode: 8018, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001088, mae: 0.020330, mean_q: 0.025018
 58729/100000: episode: 8019, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001168, mae: 0.022057, mean_q: 0.029424
 58737/100000: episode: 8020, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.001086, mae: 0.019478, mean_q: 0.022667
 58745/100000: episode: 8021, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.035, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001006, mae: 0.023332, mean_q: 0.025207
 58753/100000: episode: 8022, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000665, mae: 0.018334, mean_q: 0.016364
 58761/100000: episode: 8023, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.001667, mae: 0.019638, mean_q: 0.022782
 58769/100000: episode: 8024, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.036, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.002206, mae: 0.024116, mean_q: 0.016210
 58777/100000: episode: 8025, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001260, mae: 0.028511, mean_q: 0.032230
 58785/100000: episode: 8026, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.067, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000747, mae: 0.021243, mean_q: 0.025549
 58793/100000: episode: 8027, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.102, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.002182, mae: 0.027572, mean_q: 0.030211
 58801/100000: episode: 8028, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.001993, mae: 0.025857, mean_q: 0.021025
 58809/100000: episode: 8029, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.001389, mae: 0.027571, mean_q: 0.027588
 58817/100000: episode: 8030, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.044, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.001016, mae: 0.023262, mean_q: 0.028962
 58825/100000: episode: 8031, duration: 0.064s, episode steps: 8, steps per second: 125, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.002101, mae: 0.030236, mean_q: 0.027819
 58833/100000: episode: 8032, duration: 0.053s, episode steps: 8, steps per second: 150, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001985, mae: 0.026321, mean_q: 0.019367
 58841/100000: episode: 8033, duration: 0.049s, episode steps: 8, steps per second: 163, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000925, mae: 0.020731, mean_q: 0.024284
 58849/100000: episode: 8034, duration: 0.049s, episode steps: 8, steps per second: 162, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000498, mae: 0.015461, mean_q: 0.018350
 58857/100000: episode: 8035, duration: 0.049s, episode steps: 8, steps per second: 163, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000646, mae: 0.016978, mean_q: 0.020189
 58865/100000: episode: 8036, duration: 0.050s, episode steps: 8, steps per second: 161, episode reward: 0.032, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000637, mae: 0.019727, mean_q: 0.021372
 58873/100000: episode: 8037, duration: 0.049s, episode steps: 8, steps per second: 165, episode reward: 0.030, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000487, mae: 0.014294, mean_q: 0.020976
 58881/100000: episode: 8038, duration: 0.050s, episode steps: 8, steps per second: 161, episode reward: 0.039, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001374, mae: 0.023359, mean_q: 0.031513
 58885/100000: episode: 8039, duration: 0.029s, episode steps: 4, steps per second: 139, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000870, mae: 0.021062, mean_q: 0.013689
 58893/100000: episode: 8040, duration: 0.044s, episode steps: 8, steps per second: 184, episode reward: 0.079, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.002228, mae: 0.027847, mean_q: 0.036622
 58901/100000: episode: 8041, duration: 0.040s, episode steps: 8, steps per second: 198, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.001578, mae: 0.027643, mean_q: 0.027706
 58909/100000: episode: 8042, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.128, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000989, mae: 0.017147, mean_q: 0.019238
 58917/100000: episode: 8043, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000521, mae: 0.016175, mean_q: 0.018978
 58925/100000: episode: 8044, duration: 0.040s, episode steps: 8, steps per second: 201, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.001115, mae: 0.021189, mean_q: 0.027716
 58933/100000: episode: 8045, duration: 0.040s, episode steps: 8, steps per second: 198, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000889, mae: 0.020369, mean_q: 0.026393
 58941/100000: episode: 8046, duration: 0.040s, episode steps: 8, steps per second: 201, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000728, mae: 0.018167, mean_q: 0.019579
 58949/100000: episode: 8047, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.015, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000457, mae: 0.014418, mean_q: 0.020043
 58957/100000: episode: 8048, duration: 0.040s, episode steps: 8, steps per second: 201, episode reward: 0.130, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000933, mae: 0.019042, mean_q: 0.020611
 58965/100000: episode: 8049, duration: 0.040s, episode steps: 8, steps per second: 201, episode reward: 0.065, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000827, mae: 0.022408, mean_q: 0.026585
 58973/100000: episode: 8050, duration: 0.040s, episode steps: 8, steps per second: 201, episode reward: 0.028, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000534, mae: 0.018801, mean_q: 0.012290
 58977/100000: episode: 8051, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003482, mae: 0.033229, mean_q: 0.044063
 58985/100000: episode: 8052, duration: 0.040s, episode steps: 8, steps per second: 201, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000915, mae: 0.023412, mean_q: 0.018562
 58993/100000: episode: 8053, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.002152, mae: 0.024608, mean_q: 0.030728
 59001/100000: episode: 8054, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.028, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000782, mae: 0.019443, mean_q: 0.020186
 59009/100000: episode: 8055, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.001609, mae: 0.022070, mean_q: 0.025477
 59017/100000: episode: 8056, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.214, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000742, mae: 0.023526, mean_q: 0.021035
 59025/100000: episode: 8057, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.177, mean reward: 0.022 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.002167, mae: 0.024880, mean_q: 0.025876
 59029/100000: episode: 8058, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001266, mae: 0.026809, mean_q: 0.033819
 59037/100000: episode: 8059, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.085, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001046, mae: 0.029074, mean_q: 0.024722
 59045/100000: episode: 8060, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000835, mae: 0.021943, mean_q: 0.016780
 59053/100000: episode: 8061, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.177, mean reward: 0.022 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.002262, mae: 0.025662, mean_q: 0.029138
 59061/100000: episode: 8062, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.128, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.001829, mae: 0.022822, mean_q: 0.025680
 59065/100000: episode: 8063, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001008, mae: 0.022245, mean_q: 0.028668
 59073/100000: episode: 8064, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.067, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.001693, mae: 0.020306, mean_q: 0.017349
 59081/100000: episode: 8065, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.146, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.000640, mae: 0.021771, mean_q: 0.019548
 59089/100000: episode: 8066, duration: 0.043s, episode steps: 8, steps per second: 187, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000728, mae: 0.021745, mean_q: 0.021056
 59097/100000: episode: 8067, duration: 0.041s, episode steps: 8, steps per second: 194, episode reward: 0.030, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000767, mae: 0.019693, mean_q: 0.023301
 59105/100000: episode: 8068, duration: 0.047s, episode steps: 8, steps per second: 169, episode reward: 0.085, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000747, mae: 0.017044, mean_q: 0.023172
 59113/100000: episode: 8069, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.065, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001192, mae: 0.023810, mean_q: 0.029403
 59121/100000: episode: 8070, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000689, mae: 0.019228, mean_q: 0.009861
 59129/100000: episode: 8071, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.812 [-1.000, 11.000], loss: 0.001248, mae: 0.028752, mean_q: 0.022247
 59133/100000: episode: 8072, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001040, mae: 0.028311, mean_q: 0.041623
 59141/100000: episode: 8073, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.028, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001061, mae: 0.025006, mean_q: 0.028614
 59149/100000: episode: 8074, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.079, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000808, mae: 0.017244, mean_q: 0.022350
 59157/100000: episode: 8075, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.002436, mae: 0.023296, mean_q: 0.027528
 59161/100000: episode: 8076, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001211, mae: 0.022689, mean_q: 0.034852
 59169/100000: episode: 8077, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.020, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.001720, mae: 0.032904, mean_q: 0.023910
 59177/100000: episode: 8078, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.049, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000742, mae: 0.020937, mean_q: 0.016623
 59185/100000: episode: 8079, duration: 0.039s, episode steps: 8, steps per second: 208, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.001036, mae: 0.019726, mean_q: 0.025575
 59193/100000: episode: 8080, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.091, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.001932, mae: 0.021006, mean_q: 0.024579
 59197/100000: episode: 8081, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002910, mae: 0.031854, mean_q: 0.048630
 59205/100000: episode: 8082, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.098, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.001217, mae: 0.025412, mean_q: 0.020740
 59213/100000: episode: 8083, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.001375, mae: 0.024537, mean_q: 0.021614
 59217/100000: episode: 8084, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000895, mae: 0.026351, mean_q: 0.035489
 59225/100000: episode: 8085, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.071, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.000986, mae: 0.025604, mean_q: 0.012931
 59233/100000: episode: 8086, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.028, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001525, mae: 0.025182, mean_q: 0.029322
 59241/100000: episode: 8087, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.000717, mae: 0.020129, mean_q: 0.022104
 59249/100000: episode: 8088, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.065, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000643, mae: 0.018837, mean_q: 0.021267
 59257/100000: episode: 8089, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.071, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.001791, mae: 0.019267, mean_q: 0.018369
 59265/100000: episode: 8090, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.038, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000851, mae: 0.020781, mean_q: 0.026852
 59273/100000: episode: 8091, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.020, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000900, mae: 0.017395, mean_q: 0.022077
 59281/100000: episode: 8092, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000743, mae: 0.017590, mean_q: 0.024743
 59289/100000: episode: 8093, duration: 0.040s, episode steps: 8, steps per second: 199, episode reward: 0.020, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.000954, mae: 0.019821, mean_q: 0.028313
 59297/100000: episode: 8094, duration: 0.041s, episode steps: 8, steps per second: 197, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000698, mae: 0.019856, mean_q: 0.023603
 59305/100000: episode: 8095, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.054, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.001394, mae: 0.024614, mean_q: 0.031176
 59313/100000: episode: 8096, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.102, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.003104, mae: 0.027284, mean_q: 0.024838
 59321/100000: episode: 8097, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.032, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.002000, mae: 0.030541, mean_q: 0.040104
 59329/100000: episode: 8098, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.220, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.001746, mae: 0.034659, mean_q: 0.033342
 59337/100000: episode: 8099, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.013, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000994, mae: 0.025742, mean_q: 0.019710
 59345/100000: episode: 8100, duration: 0.044s, episode steps: 8, steps per second: 181, episode reward: 0.079, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001102, mae: 0.025552, mean_q: 0.027030
 59353/100000: episode: 8101, duration: 0.041s, episode steps: 8, steps per second: 194, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.001000, mae: 0.025005, mean_q: 0.033087
 59357/100000: episode: 8102, duration: 0.023s, episode steps: 4, steps per second: 178, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000799, mae: 0.020884, mean_q: 0.005054
[Info] 2-TH LEVEL FOUND: 0.0787079930305481, Considering 21/100 traces
 59361/100000: episode: 8103, duration: 0.742s, episode steps: 4, steps per second: 5, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000793, mae: 0.022209, mean_q: 0.029009
 59367/100000: episode: 8104, duration: 0.040s, episode steps: 6, steps per second: 148, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000727, mae: 0.019769, mean_q: 0.019188
 59373/100000: episode: 8105, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000853, mae: 0.020426, mean_q: 0.026335
 59379/100000: episode: 8106, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000765, mae: 0.021393, mean_q: 0.012696
 59385/100000: episode: 8107, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001322, mae: 0.030798, mean_q: 0.039141
 59391/100000: episode: 8108, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000945, mae: 0.025802, mean_q: 0.022830
 59397/100000: episode: 8109, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001255, mae: 0.023146, mean_q: 0.025930
 59403/100000: episode: 8110, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002226, mae: 0.023892, mean_q: 0.028766
 59409/100000: episode: 8111, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000858, mae: 0.023698, mean_q: 0.015579
[Info] FALSIFICATION!
 59414/100000: episode: 8112, duration: 0.276s, episode steps: 5, steps per second: 18, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000741, mae: 0.021997, mean_q: 0.022783
 59420/100000: episode: 8113, duration: 0.032s, episode steps: 6, steps per second: 186, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000485, mae: 0.015350, mean_q: 0.017440
 59426/100000: episode: 8114, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002469, mae: 0.023263, mean_q: 0.029590
 59432/100000: episode: 8115, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001962, mae: 0.025061, mean_q: 0.026917
 59438/100000: episode: 8116, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001366, mae: 0.024490, mean_q: 0.031328
 59444/100000: episode: 8117, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001682, mae: 0.025958, mean_q: 0.043321
 59450/100000: episode: 8118, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000695, mae: 0.021044, mean_q: 0.011569
 59456/100000: episode: 8119, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000783, mae: 0.018401, mean_q: 0.019436
 59462/100000: episode: 8120, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000753, mae: 0.018582, mean_q: 0.023352
 59468/100000: episode: 8121, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002305, mae: 0.021062, mean_q: 0.025339
 59474/100000: episode: 8122, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002290, mae: 0.031744, mean_q: 0.036313
 59480/100000: episode: 8123, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002759, mae: 0.035524, mean_q: 0.016870
 59486/100000: episode: 8124, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.003940, mae: 0.032935, mean_q: 0.026973
 59492/100000: episode: 8125, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001356, mae: 0.031086, mean_q: 0.035502
 59498/100000: episode: 8126, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001275, mae: 0.026930, mean_q: 0.031952
 59504/100000: episode: 8127, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001651, mae: 0.025787, mean_q: 0.037690
 59510/100000: episode: 8128, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000701, mae: 0.023424, mean_q: 0.017535
 59516/100000: episode: 8129, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002053, mae: 0.025833, mean_q: 0.033348
 59522/100000: episode: 8130, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000504, mae: 0.016680, mean_q: 0.020778
 59528/100000: episode: 8131, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001821, mae: 0.028899, mean_q: 0.039497
 59534/100000: episode: 8132, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001044, mae: 0.021145, mean_q: 0.024475
 59540/100000: episode: 8133, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.002694, mae: 0.032229, mean_q: 0.037936
 59546/100000: episode: 8134, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003653, mae: 0.033738, mean_q: 0.034396
 59552/100000: episode: 8135, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000746, mae: 0.021563, mean_q: 0.024996
 59558/100000: episode: 8136, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001973, mae: 0.035143, mean_q: 0.032845
 59564/100000: episode: 8137, duration: 0.038s, episode steps: 6, steps per second: 158, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000848, mae: 0.020716, mean_q: 0.017645
 59570/100000: episode: 8138, duration: 0.038s, episode steps: 6, steps per second: 157, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001871, mae: 0.026839, mean_q: 0.043328
 59576/100000: episode: 8139, duration: 0.037s, episode steps: 6, steps per second: 162, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.001151, mae: 0.026650, mean_q: 0.036531
 59582/100000: episode: 8140, duration: 0.038s, episode steps: 6, steps per second: 158, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001561, mae: 0.028097, mean_q: 0.026538
 59588/100000: episode: 8141, duration: 0.039s, episode steps: 6, steps per second: 155, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002269, mae: 0.027657, mean_q: 0.028235
 59594/100000: episode: 8142, duration: 0.036s, episode steps: 6, steps per second: 165, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001230, mae: 0.028225, mean_q: 0.022795
 59600/100000: episode: 8143, duration: 0.036s, episode steps: 6, steps per second: 165, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001096, mae: 0.026169, mean_q: 0.037119
 59606/100000: episode: 8144, duration: 0.038s, episode steps: 6, steps per second: 158, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000529, mae: 0.015550, mean_q: 0.015064
 59612/100000: episode: 8145, duration: 0.037s, episode steps: 6, steps per second: 160, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.002041, mae: 0.023375, mean_q: 0.028019
 59618/100000: episode: 8146, duration: 0.037s, episode steps: 6, steps per second: 162, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000720, mae: 0.016477, mean_q: 0.026448
 59624/100000: episode: 8147, duration: 0.037s, episode steps: 6, steps per second: 162, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001439, mae: 0.024878, mean_q: 0.031764
 59630/100000: episode: 8148, duration: 0.038s, episode steps: 6, steps per second: 157, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000896, mae: 0.021120, mean_q: 0.024423
 59636/100000: episode: 8149, duration: 0.034s, episode steps: 6, steps per second: 174, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001459, mae: 0.023263, mean_q: 0.029695
[Info] FALSIFICATION!
 59641/100000: episode: 8150, duration: 0.277s, episode steps: 5, steps per second: 18, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.001080, mae: 0.028145, mean_q: 0.038968
[Info] FALSIFICATION!
 59646/100000: episode: 8151, duration: 0.191s, episode steps: 5, steps per second: 26, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000910, mae: 0.023730, mean_q: 0.027247
 59652/100000: episode: 8152, duration: 0.032s, episode steps: 6, steps per second: 186, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001392, mae: 0.026040, mean_q: 0.032981
 59658/100000: episode: 8153, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000940, mae: 0.025297, mean_q: 0.028629
 59664/100000: episode: 8154, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001280, mae: 0.024488, mean_q: 0.033003
 59670/100000: episode: 8155, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001254, mae: 0.026052, mean_q: 0.025178
 59676/100000: episode: 8156, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001157, mae: 0.025346, mean_q: 0.042456
 59682/100000: episode: 8157, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001489, mae: 0.027499, mean_q: 0.038774
[Info] FALSIFICATION!
 59687/100000: episode: 8158, duration: 0.276s, episode steps: 5, steps per second: 18, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000807, mae: 0.018865, mean_q: 0.023426
 59693/100000: episode: 8159, duration: 0.031s, episode steps: 6, steps per second: 192, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001000, mae: 0.023923, mean_q: 0.032040
 59699/100000: episode: 8160, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001294, mae: 0.024771, mean_q: 0.026836
 59705/100000: episode: 8161, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002718, mae: 0.026994, mean_q: 0.037449
 59711/100000: episode: 8162, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001221, mae: 0.024331, mean_q: 0.031891
 59717/100000: episode: 8163, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001032, mae: 0.021246, mean_q: 0.028988
 59723/100000: episode: 8164, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001269, mae: 0.023210, mean_q: 0.037695
 59729/100000: episode: 8165, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001074, mae: 0.022200, mean_q: 0.030264
 59735/100000: episode: 8166, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001622, mae: 0.024537, mean_q: 0.034003
[Info] FALSIFICATION!
 59740/100000: episode: 8167, duration: 0.274s, episode steps: 5, steps per second: 18, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000940, mae: 0.024607, mean_q: 0.035910
 59746/100000: episode: 8168, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001783, mae: 0.033560, mean_q: 0.032723
 59752/100000: episode: 8169, duration: 0.032s, episode steps: 6, steps per second: 186, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001004, mae: 0.024185, mean_q: 0.021683
 59758/100000: episode: 8170, duration: 0.031s, episode steps: 6, steps per second: 197, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001212, mae: 0.026944, mean_q: 0.028833
 59764/100000: episode: 8171, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001036, mae: 0.026762, mean_q: 0.019062
 59770/100000: episode: 8172, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.002922, mae: 0.034643, mean_q: 0.042912
 59776/100000: episode: 8173, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.002610, mae: 0.033537, mean_q: 0.027383
 59782/100000: episode: 8174, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.002600, mae: 0.048263, mean_q: 0.050747
 59788/100000: episode: 8175, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001256, mae: 0.034933, mean_q: 0.040853
 59794/100000: episode: 8176, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002074, mae: 0.024254, mean_q: 0.017755
 59800/100000: episode: 8177, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001405, mae: 0.025770, mean_q: 0.038822
 59806/100000: episode: 8178, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001032, mae: 0.025228, mean_q: 0.015439
 59812/100000: episode: 8179, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001256, mae: 0.029621, mean_q: 0.032449
 59818/100000: episode: 8180, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000666, mae: 0.020866, mean_q: 0.018737
 59824/100000: episode: 8181, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001172, mae: 0.020756, mean_q: 0.020222
[Info] Complete ISplit Iteration
[Info] Levels: [0.033320576, 0.07870799, 0.8744018]
[Info] Cond. Prob: [0.12, 0.21, 0.05]
[Info] Error Prob: 0.0012599999999999998

 59830/100000: episode: 8182, duration: 0.824s, episode steps: 6, steps per second: 7, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001299, mae: 0.029587, mean_q: 0.040741
 59840/100000: episode: 8183, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000959, mae: 0.025188, mean_q: 0.023082
 59850/100000: episode: 8184, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001331, mae: 0.022680, mean_q: 0.023411
 59860/100000: episode: 8185, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000773, mae: 0.020056, mean_q: 0.025424
 59870/100000: episode: 8186, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001124, mae: 0.024629, mean_q: 0.025366
 59880/100000: episode: 8187, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001592, mae: 0.030322, mean_q: 0.031709
 59890/100000: episode: 8188, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000891, mae: 0.029196, mean_q: 0.015176
 59900/100000: episode: 8189, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001771, mae: 0.029278, mean_q: 0.030827
 59910/100000: episode: 8190, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000629, mae: 0.015462, mean_q: 0.016163
 59920/100000: episode: 8191, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001817, mae: 0.025955, mean_q: 0.027913
 59930/100000: episode: 8192, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001069, mae: 0.023511, mean_q: 0.026591
 59940/100000: episode: 8193, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001099, mae: 0.024380, mean_q: 0.026514
 59950/100000: episode: 8194, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002361, mae: 0.029268, mean_q: 0.042434
 59960/100000: episode: 8195, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002236, mae: 0.031559, mean_q: 0.023423
 59970/100000: episode: 8196, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.003214, mae: 0.032064, mean_q: 0.035608
 59980/100000: episode: 8197, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000938, mae: 0.027366, mean_q: 0.022514
 59990/100000: episode: 8198, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000965, mae: 0.022947, mean_q: 0.022410
 60000/100000: episode: 8199, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001087, mae: 0.021593, mean_q: 0.026169
 60010/100000: episode: 8200, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.001327, mae: 0.024610, mean_q: 0.031497
 60020/100000: episode: 8201, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000817, mae: 0.017156, mean_q: 0.025770
 60030/100000: episode: 8202, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001193, mae: 0.021688, mean_q: 0.028028
 60040/100000: episode: 8203, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000776, mae: 0.016648, mean_q: 0.019831
 60050/100000: episode: 8204, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001273, mae: 0.021767, mean_q: 0.034284
 60060/100000: episode: 8205, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001862, mae: 0.025215, mean_q: 0.021591
 60070/100000: episode: 8206, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000994, mae: 0.020864, mean_q: 0.025875
 60080/100000: episode: 8207, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001878, mae: 0.027997, mean_q: 0.027098
 60090/100000: episode: 8208, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000899, mae: 0.020887, mean_q: 0.029548
 60100/100000: episode: 8209, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000689, mae: 0.014159, mean_q: 0.016171
 60110/100000: episode: 8210, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000985, mae: 0.022143, mean_q: 0.027430
 60120/100000: episode: 8211, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000645, mae: 0.017281, mean_q: 0.019458
 60130/100000: episode: 8212, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000819, mae: 0.023182, mean_q: 0.023656
 60140/100000: episode: 8213, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.002561, mae: 0.022845, mean_q: 0.024534
 60150/100000: episode: 8214, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000973, mae: 0.019329, mean_q: 0.020979
 60160/100000: episode: 8215, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002039, mae: 0.027633, mean_q: 0.040214
 60170/100000: episode: 8216, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000877, mae: 0.020243, mean_q: 0.024264
 60180/100000: episode: 8217, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000975, mae: 0.019671, mean_q: 0.021368
 60190/100000: episode: 8218, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001392, mae: 0.027303, mean_q: 0.032545
 60200/100000: episode: 8219, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000836, mae: 0.022516, mean_q: 0.023445
 60210/100000: episode: 8220, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001025, mae: 0.020741, mean_q: 0.025452
 60220/100000: episode: 8221, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001158, mae: 0.021687, mean_q: 0.027761
 60230/100000: episode: 8222, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000653, mae: 0.016116, mean_q: 0.017999
 60240/100000: episode: 8223, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001171, mae: 0.023838, mean_q: 0.024256
 60250/100000: episode: 8224, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000993, mae: 0.020157, mean_q: 0.023356
 60260/100000: episode: 8225, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000919, mae: 0.020632, mean_q: 0.019949
 60270/100000: episode: 8226, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001205, mae: 0.020575, mean_q: 0.027300
 60280/100000: episode: 8227, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000517, mae: 0.014729, mean_q: 0.013680
 60290/100000: episode: 8228, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001016, mae: 0.020080, mean_q: 0.029515
 60300/100000: episode: 8229, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000732, mae: 0.018320, mean_q: 0.014485
 60310/100000: episode: 8230, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000967, mae: 0.020370, mean_q: 0.021264
 60320/100000: episode: 8231, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000709, mae: 0.019224, mean_q: 0.018335
 60330/100000: episode: 8232, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000768, mae: 0.017203, mean_q: 0.018089
 60340/100000: episode: 8233, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001748, mae: 0.023500, mean_q: 0.025380
 60350/100000: episode: 8234, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000490, mae: 0.015659, mean_q: 0.017259
 60360/100000: episode: 8235, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000939, mae: 0.020375, mean_q: 0.027198
 60370/100000: episode: 8236, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000618, mae: 0.014994, mean_q: 0.022209
 60380/100000: episode: 8237, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000475, mae: 0.015603, mean_q: 0.017657
 60390/100000: episode: 8238, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000988, mae: 0.018381, mean_q: 0.025606
 60400/100000: episode: 8239, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000611, mae: 0.015553, mean_q: 0.021444
 60410/100000: episode: 8240, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000703, mae: 0.015956, mean_q: 0.017425
 60420/100000: episode: 8241, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000981, mae: 0.018729, mean_q: 0.024350
 60430/100000: episode: 8242, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001332, mae: 0.016651, mean_q: 0.017955
 60440/100000: episode: 8243, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000791, mae: 0.021125, mean_q: 0.026307
 60450/100000: episode: 8244, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000660, mae: 0.020294, mean_q: 0.017839
 60460/100000: episode: 8245, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001041, mae: 0.023582, mean_q: 0.021748
 60470/100000: episode: 8246, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000436, mae: 0.015535, mean_q: 0.013095
 60480/100000: episode: 8247, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000660, mae: 0.014753, mean_q: 0.021007
 60490/100000: episode: 8248, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000646, mae: 0.016174, mean_q: 0.016119
 60500/100000: episode: 8249, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000601, mae: 0.015937, mean_q: 0.019604
 60510/100000: episode: 8250, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001335, mae: 0.018199, mean_q: 0.019090
 60520/100000: episode: 8251, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000659, mae: 0.020634, mean_q: 0.016433
 60530/100000: episode: 8252, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000808, mae: 0.019222, mean_q: 0.020850
 60540/100000: episode: 8253, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001508, mae: 0.018973, mean_q: 0.021013
 60550/100000: episode: 8254, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000924, mae: 0.018026, mean_q: 0.019436
 60560/100000: episode: 8255, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001445, mae: 0.017540, mean_q: 0.019595
 60570/100000: episode: 8256, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000474, mae: 0.012581, mean_q: 0.016899
 60580/100000: episode: 8257, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000827, mae: 0.016262, mean_q: 0.021672
 60590/100000: episode: 8258, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000576, mae: 0.014452, mean_q: 0.014429
 60600/100000: episode: 8259, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000954, mae: 0.019277, mean_q: 0.021303
 60610/100000: episode: 8260, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000612, mae: 0.015020, mean_q: 0.018273
 60620/100000: episode: 8261, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000665, mae: 0.018415, mean_q: 0.015279
 60630/100000: episode: 8262, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000902, mae: 0.022264, mean_q: 0.020937
 60640/100000: episode: 8263, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000812, mae: 0.022248, mean_q: 0.016406
 60650/100000: episode: 8264, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000523, mae: 0.017054, mean_q: 0.013971
 60660/100000: episode: 8265, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000551, mae: 0.020536, mean_q: 0.015834
 60670/100000: episode: 8266, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000333, mae: 0.014854, mean_q: 0.010671
 60680/100000: episode: 8267, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000354, mae: 0.013610, mean_q: 0.014965
 60690/100000: episode: 8268, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000684, mae: 0.017746, mean_q: 0.014429
 60700/100000: episode: 8269, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001770, mae: 0.020531, mean_q: 0.020202
 60710/100000: episode: 8270, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000711, mae: 0.021510, mean_q: 0.020342
 60720/100000: episode: 8271, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000849, mae: 0.019464, mean_q: 0.020164
 60730/100000: episode: 8272, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000497, mae: 0.014223, mean_q: 0.015994
 60740/100000: episode: 8273, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000585, mae: 0.012756, mean_q: 0.013562
 60750/100000: episode: 8274, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000598, mae: 0.016354, mean_q: 0.017898
 60760/100000: episode: 8275, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000515, mae: 0.015087, mean_q: 0.016389
 60770/100000: episode: 8276, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000594, mae: 0.016311, mean_q: 0.015262
 60780/100000: episode: 8277, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002115, mae: 0.026856, mean_q: 0.024373
 60790/100000: episode: 8278, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000672, mae: 0.017909, mean_q: 0.025484
 60800/100000: episode: 8279, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000834, mae: 0.016619, mean_q: 0.018658
 60810/100000: episode: 8280, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000651, mae: 0.018469, mean_q: 0.020887
 60820/100000: episode: 8281, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000626, mae: 0.016692, mean_q: 0.017386
[Info] 1-TH LEVEL FOUND: 0.05957883596420288, Considering 11/100 traces
 60830/100000: episode: 8282, duration: 0.711s, episode steps: 10, steps per second: 14, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000934, mae: 0.017044, mean_q: 0.022160
 60834/100000: episode: 8283, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000998, mae: 0.019329, mean_q: 0.024425
 60836/100000: episode: 8284, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000892, mae: 0.023123, mean_q: 0.013828
 60838/100000: episode: 8285, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000351, mae: 0.012635, mean_q: 0.010681
 60842/100000: episode: 8286, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001428, mae: 0.025818, mean_q: 0.037416
 60844/100000: episode: 8287, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000851, mae: 0.019371, mean_q: 0.025396
 60846/100000: episode: 8288, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000749, mae: 0.017328, mean_q: 0.015616
 60852/100000: episode: 8289, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000493, mae: 0.014177, mean_q: 0.016978
 60856/100000: episode: 8290, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000423, mae: 0.013408, mean_q: 0.018954
 60860/100000: episode: 8291, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000789, mae: 0.015379, mean_q: 0.021032
 60864/100000: episode: 8292, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000263, mae: 0.010967, mean_q: 0.014145
 60870/100000: episode: 8293, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001423, mae: 0.022261, mean_q: 0.029183
 60872/100000: episode: 8294, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000321, mae: 0.013605, mean_q: 0.018867
 60876/100000: episode: 8295, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000720, mae: 0.018746, mean_q: 0.022423
 60878/100000: episode: 8296, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005156, mae: 0.029864, mean_q: 0.032874
 60882/100000: episode: 8297, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000645, mae: 0.020600, mean_q: 0.035303
 60884/100000: episode: 8298, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000490, mae: 0.018232, mean_q: 0.005876
 60888/100000: episode: 8299, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000822, mae: 0.017159, mean_q: 0.017429
 60894/100000: episode: 8300, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000477, mae: 0.016751, mean_q: 0.019026
 60896/100000: episode: 8301, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001398, mae: 0.024212, mean_q: 0.028011
 60902/100000: episode: 8302, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000536, mae: 0.014554, mean_q: 0.023406
 60904/100000: episode: 8303, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000120, mae: 0.008452, mean_q: 0.008544
 60908/100000: episode: 8304, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000482, mae: 0.015104, mean_q: 0.008372
 60912/100000: episode: 8305, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000568, mae: 0.018512, mean_q: 0.022537
 60916/100000: episode: 8306, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001094, mae: 0.022565, mean_q: 0.025480
 60918/100000: episode: 8307, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000468, mae: 0.015022, mean_q: 0.015312
 60924/100000: episode: 8308, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000798, mae: 0.015319, mean_q: 0.020045
 60930/100000: episode: 8309, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000350, mae: 0.012082, mean_q: 0.010545
 60936/100000: episode: 8310, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000720, mae: 0.019112, mean_q: 0.022960
 60940/100000: episode: 8311, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000833, mae: 0.017125, mean_q: 0.022557
 60944/100000: episode: 8312, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000445, mae: 0.012364, mean_q: 0.013488
 60948/100000: episode: 8313, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000646, mae: 0.013377, mean_q: 0.013665
 60950/100000: episode: 8314, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001038, mae: 0.017413, mean_q: 0.028631
 60954/100000: episode: 8315, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000830, mae: 0.014125, mean_q: 0.018533
 60956/100000: episode: 8316, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000283, mae: 0.014379, mean_q: 0.010056
 60960/100000: episode: 8317, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002173, mae: 0.015790, mean_q: 0.019074
 60962/100000: episode: 8318, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000401, mae: 0.015485, mean_q: 0.026721
 60968/100000: episode: 8319, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000940, mae: 0.017681, mean_q: 0.016965
 60972/100000: episode: 8320, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000695, mae: 0.017057, mean_q: 0.024862
 60976/100000: episode: 8321, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000449, mae: 0.015961, mean_q: 0.018131
 60982/100000: episode: 8322, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000910, mae: 0.016170, mean_q: 0.013700
 60984/100000: episode: 8323, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001305, mae: 0.019114, mean_q: 0.017786
 60988/100000: episode: 8324, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001048, mae: 0.026176, mean_q: 0.033157
 60994/100000: episode: 8325, duration: 0.032s, episode steps: 6, steps per second: 185, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000715, mae: 0.019808, mean_q: 0.012358
 61000/100000: episode: 8326, duration: 0.031s, episode steps: 6, steps per second: 192, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000886, mae: 0.016942, mean_q: 0.022436
 61006/100000: episode: 8327, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.002704, mae: 0.028410, mean_q: 0.041187
 61008/100000: episode: 8328, duration: 0.014s, episode steps: 2, steps per second: 143, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001225, mae: 0.026917, mean_q: 0.012793
 61012/100000: episode: 8329, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000560, mae: 0.018873, mean_q: 0.014883
 61016/100000: episode: 8330, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002334, mae: 0.024885, mean_q: 0.028588
 61020/100000: episode: 8331, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000739, mae: 0.023991, mean_q: 0.011614
 61024/100000: episode: 8332, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000790, mae: 0.021892, mean_q: 0.023649
 61028/100000: episode: 8333, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000841, mae: 0.020653, mean_q: 0.021607
 61030/100000: episode: 8334, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000188, mae: 0.010832, mean_q: 0.009141
 61032/100000: episode: 8335, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000410, mae: 0.014005, mean_q: 0.019201
 61038/100000: episode: 8336, duration: 0.036s, episode steps: 6, steps per second: 165, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000374, mae: 0.011892, mean_q: 0.018389
 61040/100000: episode: 8337, duration: 0.017s, episode steps: 2, steps per second: 115, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001394, mae: 0.029755, mean_q: 0.026749
 61042/100000: episode: 8338, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001120, mae: 0.019377, mean_q: 0.039237
 61044/100000: episode: 8339, duration: 0.016s, episode steps: 2, steps per second: 122, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004663, mae: 0.024471, mean_q: 0.022878
 61048/100000: episode: 8340, duration: 0.026s, episode steps: 4, steps per second: 153, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000431, mae: 0.016369, mean_q: 0.023306
 61054/100000: episode: 8341, duration: 0.037s, episode steps: 6, steps per second: 163, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000951, mae: 0.020636, mean_q: 0.016165
 61058/100000: episode: 8342, duration: 0.028s, episode steps: 4, steps per second: 141, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001198, mae: 0.022462, mean_q: 0.038319
 61062/100000: episode: 8343, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000905, mae: 0.020470, mean_q: 0.022873
 61066/100000: episode: 8344, duration: 0.025s, episode steps: 4, steps per second: 161, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002584, mae: 0.025321, mean_q: 0.036723
 61070/100000: episode: 8345, duration: 0.029s, episode steps: 4, steps per second: 140, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000872, mae: 0.024902, mean_q: 0.022372
 61076/100000: episode: 8346, duration: 0.037s, episode steps: 6, steps per second: 163, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.001159, mae: 0.022963, mean_q: 0.037565
 61078/100000: episode: 8347, duration: 0.014s, episode steps: 2, steps per second: 138, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000570, mae: 0.015756, mean_q: 0.010220
 61084/100000: episode: 8348, duration: 0.035s, episode steps: 6, steps per second: 170, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000796, mae: 0.019348, mean_q: 0.027880
 61088/100000: episode: 8349, duration: 0.029s, episode steps: 4, steps per second: 140, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000808, mae: 0.021208, mean_q: 0.012926
 61094/100000: episode: 8350, duration: 0.037s, episode steps: 6, steps per second: 162, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000686, mae: 0.020390, mean_q: 0.032054
 61100/100000: episode: 8351, duration: 0.034s, episode steps: 6, steps per second: 177, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000671, mae: 0.020962, mean_q: 0.008294
 61106/100000: episode: 8352, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001272, mae: 0.031341, mean_q: 0.026500
 61110/100000: episode: 8353, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001129, mae: 0.028273, mean_q: 0.039076
 61116/100000: episode: 8354, duration: 0.032s, episode steps: 6, steps per second: 185, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000479, mae: 0.020672, mean_q: 0.004527
 61118/100000: episode: 8355, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004099, mae: 0.028630, mean_q: 0.035708
 61120/100000: episode: 8356, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001603, mae: 0.036863, mean_q: 0.059273
 61122/100000: episode: 8357, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000555, mae: 0.016558, mean_q: 0.006044
 61126/100000: episode: 8358, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000948, mae: 0.024452, mean_q: 0.014549
 61130/100000: episode: 8359, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000874, mae: 0.028040, mean_q: 0.040301
 61132/100000: episode: 8360, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000685, mae: 0.024163, mean_q: -0.004970
 61136/100000: episode: 8361, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000668, mae: 0.019891, mean_q: 0.027665
 61142/100000: episode: 8362, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000737, mae: 0.018962, mean_q: 0.019900
 61146/100000: episode: 8363, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000877, mae: 0.021232, mean_q: 0.019319
 61148/100000: episode: 8364, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001759, mae: 0.035274, mean_q: 0.048765
 61150/100000: episode: 8365, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000695, mae: 0.018827, mean_q: 0.018007
 61152/100000: episode: 8366, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000240, mae: 0.015670, mean_q: 0.000716
 61156/100000: episode: 8367, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000965, mae: 0.026273, mean_q: 0.035302
 61158/100000: episode: 8368, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000910, mae: 0.017708, mean_q: 0.017078
 61162/100000: episode: 8369, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000413, mae: 0.016078, mean_q: 0.023289
 61166/100000: episode: 8370, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000576, mae: 0.018111, mean_q: 0.013248
[Info] 2-TH LEVEL FOUND: 0.24891388416290283, Considering 10/100 traces
 61168/100000: episode: 8371, duration: 0.756s, episode steps: 2, steps per second: 3, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000641, mae: 0.016849, mean_q: 0.011018
 61172/100000: episode: 8372, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002055, mae: 0.027154, mean_q: 0.033030
 61176/100000: episode: 8373, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000873, mae: 0.020967, mean_q: 0.028554
 61180/100000: episode: 8374, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001168, mae: 0.023592, mean_q: 0.031253
 61184/100000: episode: 8375, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000850, mae: 0.024098, mean_q: 0.014813
 61188/100000: episode: 8376, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000589, mae: 0.020871, mean_q: 0.029528
 61192/100000: episode: 8377, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000621, mae: 0.016668, mean_q: 0.009377
 61196/100000: episode: 8378, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000763, mae: 0.023559, mean_q: 0.029217
 61200/100000: episode: 8379, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003760, mae: 0.030127, mean_q: 0.035832
[Info] FALSIFICATION!
 61203/100000: episode: 8380, duration: 0.270s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001017, mae: 0.024208, mean_q: 0.017709
 61207/100000: episode: 8381, duration: 0.024s, episode steps: 4, steps per second: 166, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000382, mae: 0.016368, mean_q: 0.007448
 61211/100000: episode: 8382, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000548, mae: 0.021065, mean_q: 0.022098
 61215/100000: episode: 8383, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000887, mae: 0.022906, mean_q: 0.015890
 61219/100000: episode: 8384, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000883, mae: 0.023157, mean_q: 0.033797
 61223/100000: episode: 8385, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000396, mae: 0.017153, mean_q: 0.010125
 61227/100000: episode: 8386, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000764, mae: 0.024983, mean_q: 0.031969
 61231/100000: episode: 8387, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000674, mae: 0.018467, mean_q: 0.012309
 61235/100000: episode: 8388, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000495, mae: 0.015719, mean_q: 0.023517
[Info] FALSIFICATION!
 61238/100000: episode: 8389, duration: 0.269s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000674, mae: 0.017093, mean_q: 0.017074
[Info] FALSIFICATION!
 61241/100000: episode: 8390, duration: 0.234s, episode steps: 3, steps per second: 13, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000658, mae: 0.021139, mean_q: 0.025437
 61245/100000: episode: 8391, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001171, mae: 0.023358, mean_q: 0.033662
 61249/100000: episode: 8392, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001208, mae: 0.026396, mean_q: 0.013497
 61253/100000: episode: 8393, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003460, mae: 0.036680, mean_q: 0.044144
[Info] FALSIFICATION!
 61256/100000: episode: 8394, duration: 0.273s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000986, mae: 0.022252, mean_q: 0.024510
[Info] FALSIFICATION!
 61259/100000: episode: 8395, duration: 0.271s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000993, mae: 0.024028, mean_q: 0.019831
 61263/100000: episode: 8396, duration: 0.024s, episode steps: 4, steps per second: 170, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001289, mae: 0.031710, mean_q: 0.044754
 61267/100000: episode: 8397, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.004583, mae: 0.035560, mean_q: 0.012519
 61271/100000: episode: 8398, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003002, mae: 0.038700, mean_q: 0.053486
[Info] FALSIFICATION!
 61274/100000: episode: 8399, duration: 0.270s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.004280, mae: 0.045068, mean_q: 0.032016
 61278/100000: episode: 8400, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001048, mae: 0.025475, mean_q: 0.033978
 61282/100000: episode: 8401, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.001228, mae: 0.022918, mean_q: 0.029746
 61286/100000: episode: 8402, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001117, mae: 0.022878, mean_q: 0.024650
[Info] FALSIFICATION!
 61289/100000: episode: 8403, duration: 0.179s, episode steps: 3, steps per second: 17, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001058, mae: 0.017007, mean_q: 0.024656
 61293/100000: episode: 8404, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001131, mae: 0.023703, mean_q: 0.033532
 61297/100000: episode: 8405, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000522, mae: 0.019294, mean_q: 0.009132
[Info] FALSIFICATION!
 61300/100000: episode: 8406, duration: 0.272s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000620, mae: 0.019185, mean_q: 0.021125
 61304/100000: episode: 8407, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001765, mae: 0.035180, mean_q: 0.054984
 61308/100000: episode: 8408, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000814, mae: 0.022410, mean_q: 0.009316
 61312/100000: episode: 8409, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001292, mae: 0.024679, mean_q: 0.033565
 61316/100000: episode: 8410, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001329, mae: 0.025068, mean_q: 0.038803
 61320/100000: episode: 8411, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001153, mae: 0.023418, mean_q: 0.033744
 61324/100000: episode: 8412, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001814, mae: 0.029537, mean_q: 0.037719
 61328/100000: episode: 8413, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001256, mae: 0.029311, mean_q: 0.018763
 61332/100000: episode: 8414, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001801, mae: 0.037382, mean_q: 0.052337
 61336/100000: episode: 8415, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001302, mae: 0.023724, mean_q: 0.029456
 61340/100000: episode: 8416, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001593, mae: 0.026657, mean_q: 0.027689
[Info] FALSIFICATION!
 61343/100000: episode: 8417, duration: 0.272s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001188, mae: 0.025562, mean_q: 0.026931
 61347/100000: episode: 8418, duration: 0.024s, episode steps: 4, steps per second: 170, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001438, mae: 0.025687, mean_q: 0.036108
 61351/100000: episode: 8419, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000965, mae: 0.020889, mean_q: 0.028504
 61355/100000: episode: 8420, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001033, mae: 0.020255, mean_q: 0.023492
 61359/100000: episode: 8421, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001356, mae: 0.026740, mean_q: 0.041288
 61363/100000: episode: 8422, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001598, mae: 0.022630, mean_q: 0.029845
[Info] FALSIFICATION!
 61366/100000: episode: 8423, duration: 0.272s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000785, mae: 0.019618, mean_q: 0.018056
 61370/100000: episode: 8424, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001481, mae: 0.025177, mean_q: 0.028341
 61374/100000: episode: 8425, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001623, mae: 0.026681, mean_q: 0.033842
 61378/100000: episode: 8426, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000677, mae: 0.019238, mean_q: 0.013434
 61382/100000: episode: 8427, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001652, mae: 0.027074, mean_q: 0.041566
 61386/100000: episode: 8428, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000927, mae: 0.024827, mean_q: 0.029522
 61390/100000: episode: 8429, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001795, mae: 0.030449, mean_q: 0.039798
 61394/100000: episode: 8430, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001386, mae: 0.024002, mean_q: 0.023459
 61398/100000: episode: 8431, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.001010, mae: 0.022933, mean_q: 0.026191
 61402/100000: episode: 8432, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001556, mae: 0.025682, mean_q: 0.035991
 61406/100000: episode: 8433, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001093, mae: 0.025600, mean_q: 0.028075
[Info] FALSIFICATION!
 61409/100000: episode: 8434, duration: 0.272s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001763, mae: 0.024092, mean_q: 0.034965
[Info] FALSIFICATION!
 61412/100000: episode: 8435, duration: 0.275s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000295, mae: 0.012658, mean_q: 0.013721
 61416/100000: episode: 8436, duration: 0.034s, episode steps: 4, steps per second: 118, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000962, mae: 0.019093, mean_q: 0.022698
 61420/100000: episode: 8437, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001268, mae: 0.020128, mean_q: 0.032321
[Info] FALSIFICATION!
 61423/100000: episode: 8438, duration: 0.206s, episode steps: 3, steps per second: 15, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002096, mae: 0.031935, mean_q: 0.056819
 61427/100000: episode: 8439, duration: 0.029s, episode steps: 4, steps per second: 140, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001498, mae: 0.027272, mean_q: 0.030617
 61431/100000: episode: 8440, duration: 0.028s, episode steps: 4, steps per second: 141, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000993, mae: 0.024677, mean_q: 0.032830
 61435/100000: episode: 8441, duration: 0.027s, episode steps: 4, steps per second: 149, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001327, mae: 0.024386, mean_q: 0.016484
 61439/100000: episode: 8442, duration: 0.025s, episode steps: 4, steps per second: 160, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001516, mae: 0.027143, mean_q: 0.035181
 61443/100000: episode: 8443, duration: 0.029s, episode steps: 4, steps per second: 137, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001587, mae: 0.026446, mean_q: 0.033766
 61447/100000: episode: 8444, duration: 0.025s, episode steps: 4, steps per second: 163, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002333, mae: 0.034357, mean_q: 0.057426
 61451/100000: episode: 8445, duration: 0.027s, episode steps: 4, steps per second: 147, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001573, mae: 0.028003, mean_q: 0.036658
 61455/100000: episode: 8446, duration: 0.027s, episode steps: 4, steps per second: 147, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003392, mae: 0.030673, mean_q: 0.034377
 61459/100000: episode: 8447, duration: 0.025s, episode steps: 4, steps per second: 163, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.001267, mae: 0.026020, mean_q: 0.035368
 61463/100000: episode: 8448, duration: 0.023s, episode steps: 4, steps per second: 170, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000766, mae: 0.018474, mean_q: 0.018741
 61467/100000: episode: 8449, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.004522, mae: 0.040782, mean_q: 0.071943
 61471/100000: episode: 8450, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000720, mae: 0.019166, mean_q: 0.019144
 61475/100000: episode: 8451, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.004266, mae: 0.036269, mean_q: 0.042325
 61479/100000: episode: 8452, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002349, mae: 0.039624, mean_q: 0.059107
 61483/100000: episode: 8453, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001145, mae: 0.026583, mean_q: 0.017116
 61487/100000: episode: 8454, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001558, mae: 0.027051, mean_q: 0.041035
[Info] FALSIFICATION!
 61490/100000: episode: 8455, duration: 0.179s, episode steps: 3, steps per second: 17, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002118, mae: 0.028951, mean_q: 0.045121
 61494/100000: episode: 8456, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.001980, mae: 0.034992, mean_q: 0.052823
 61498/100000: episode: 8457, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001717, mae: 0.030143, mean_q: 0.041834
 61502/100000: episode: 8458, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001904, mae: 0.028859, mean_q: 0.045245
 61506/100000: episode: 8459, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001146, mae: 0.021059, mean_q: 0.027168
 61510/100000: episode: 8460, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001877, mae: 0.026685, mean_q: 0.048133
[Info] Complete ISplit Iteration
[Info] Levels: [0.059578836, 0.24891388, 1.0125111]
[Info] Cond. Prob: [0.11, 0.1, 0.14]
[Info] Error Prob: 0.0015400000000000004

 61514/100000: episode: 8461, duration: 0.835s, episode steps: 4, steps per second: 5, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002030, mae: 0.029735, mean_q: 0.056395
 61524/100000: episode: 8462, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002040, mae: 0.036800, mean_q: 0.040461
 61534/100000: episode: 8463, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001958, mae: 0.033870, mean_q: 0.043718
 61544/100000: episode: 8464, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.002279, mae: 0.029822, mean_q: 0.037747
 61554/100000: episode: 8465, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002250, mae: 0.036655, mean_q: 0.045371
 61564/100000: episode: 8466, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001460, mae: 0.026512, mean_q: 0.030959
 61574/100000: episode: 8467, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001338, mae: 0.025076, mean_q: 0.042063
 61584/100000: episode: 8468, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002771, mae: 0.029228, mean_q: 0.049752
 61594/100000: episode: 8469, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002073, mae: 0.036690, mean_q: 0.057411
 61604/100000: episode: 8470, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002087, mae: 0.037200, mean_q: 0.036178
 61614/100000: episode: 8471, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002337, mae: 0.033582, mean_q: 0.029739
 61624/100000: episode: 8472, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002218, mae: 0.027352, mean_q: 0.033548
 61634/100000: episode: 8473, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.003159, mae: 0.038833, mean_q: 0.041177
 61644/100000: episode: 8474, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001991, mae: 0.033483, mean_q: 0.031462
 61654/100000: episode: 8475, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001742, mae: 0.029586, mean_q: 0.031359
 61664/100000: episode: 8476, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001493, mae: 0.029072, mean_q: 0.030008
 61674/100000: episode: 8477, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001627, mae: 0.028697, mean_q: 0.039007
 61684/100000: episode: 8478, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002053, mae: 0.025171, mean_q: 0.035133
 61694/100000: episode: 8479, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002363, mae: 0.026123, mean_q: 0.035769
 61704/100000: episode: 8480, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001940, mae: 0.030064, mean_q: 0.036171
 61714/100000: episode: 8481, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.002093, mae: 0.030933, mean_q: 0.032769
 61724/100000: episode: 8482, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001492, mae: 0.027032, mean_q: 0.033679
 61734/100000: episode: 8483, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002087, mae: 0.035444, mean_q: 0.039369
 61744/100000: episode: 8484, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001306, mae: 0.024763, mean_q: 0.028333
 61754/100000: episode: 8485, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001850, mae: 0.030983, mean_q: 0.042126
 61764/100000: episode: 8486, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002511, mae: 0.031480, mean_q: 0.045480
 61774/100000: episode: 8487, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001734, mae: 0.032720, mean_q: 0.047096
 61784/100000: episode: 8488, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001623, mae: 0.031033, mean_q: 0.039651
 61794/100000: episode: 8489, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002620, mae: 0.032013, mean_q: 0.034812
 61804/100000: episode: 8490, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001329, mae: 0.025981, mean_q: 0.032825
 61814/100000: episode: 8491, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001773, mae: 0.032170, mean_q: 0.040437
 61824/100000: episode: 8492, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002183, mae: 0.035352, mean_q: 0.048167
 61834/100000: episode: 8493, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002931, mae: 0.038327, mean_q: 0.049321
 61844/100000: episode: 8494, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002760, mae: 0.043242, mean_q: 0.024272
 61854/100000: episode: 8495, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.002028, mae: 0.032726, mean_q: 0.040669
 61864/100000: episode: 8496, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001410, mae: 0.026799, mean_q: 0.029381
 61874/100000: episode: 8497, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.003025, mae: 0.033430, mean_q: 0.045505
 61884/100000: episode: 8498, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001693, mae: 0.025317, mean_q: 0.032033
 61894/100000: episode: 8499, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001184, mae: 0.019836, mean_q: 0.017437
 61904/100000: episode: 8500, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001734, mae: 0.027424, mean_q: 0.024827
 61914/100000: episode: 8501, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002389, mae: 0.025159, mean_q: 0.030576
 61924/100000: episode: 8502, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002292, mae: 0.032756, mean_q: 0.046455
 61934/100000: episode: 8503, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002027, mae: 0.033788, mean_q: 0.036983
 61944/100000: episode: 8504, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001164, mae: 0.026429, mean_q: 0.025056
 61954/100000: episode: 8505, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001666, mae: 0.030026, mean_q: 0.030918
 61964/100000: episode: 8506, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001644, mae: 0.025346, mean_q: 0.035121
 61974/100000: episode: 8507, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001926, mae: 0.025800, mean_q: 0.030605
 61984/100000: episode: 8508, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002157, mae: 0.031198, mean_q: 0.055922
 61994/100000: episode: 8509, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002352, mae: 0.028965, mean_q: 0.042752
 62004/100000: episode: 8510, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001679, mae: 0.026546, mean_q: 0.032431
 62014/100000: episode: 8511, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001656, mae: 0.025595, mean_q: 0.021974
 62024/100000: episode: 8512, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001811, mae: 0.031829, mean_q: 0.036034
 62034/100000: episode: 8513, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000951, mae: 0.024853, mean_q: 0.029395
 62044/100000: episode: 8514, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001231, mae: 0.021781, mean_q: 0.032303
 62054/100000: episode: 8515, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002034, mae: 0.026126, mean_q: 0.039163
 62064/100000: episode: 8516, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001864, mae: 0.031356, mean_q: 0.033054
 62074/100000: episode: 8517, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000909, mae: 0.019489, mean_q: 0.023070
 62084/100000: episode: 8518, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001122, mae: 0.022715, mean_q: 0.026586
 62094/100000: episode: 8519, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001990, mae: 0.023593, mean_q: 0.040402
 62104/100000: episode: 8520, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001859, mae: 0.025930, mean_q: 0.027181
 62114/100000: episode: 8521, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001504, mae: 0.027069, mean_q: 0.031196
 62124/100000: episode: 8522, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001502, mae: 0.026825, mean_q: 0.032531
 62134/100000: episode: 8523, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001713, mae: 0.027233, mean_q: 0.035324
 62144/100000: episode: 8524, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001535, mae: 0.025514, mean_q: 0.035832
 62154/100000: episode: 8525, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001366, mae: 0.025755, mean_q: 0.028695
 62164/100000: episode: 8526, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001312, mae: 0.028447, mean_q: 0.034962
 62174/100000: episode: 8527, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001877, mae: 0.022667, mean_q: 0.036417
 62184/100000: episode: 8528, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001538, mae: 0.025189, mean_q: 0.033512
 62194/100000: episode: 8529, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002537, mae: 0.032398, mean_q: 0.042244
 62204/100000: episode: 8530, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001452, mae: 0.027425, mean_q: 0.026716
 62214/100000: episode: 8531, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001221, mae: 0.020974, mean_q: 0.030658
 62224/100000: episode: 8532, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002277, mae: 0.023410, mean_q: 0.032514
 62234/100000: episode: 8533, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001114, mae: 0.021505, mean_q: 0.026586
 62244/100000: episode: 8534, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001747, mae: 0.029289, mean_q: 0.024253
 62254/100000: episode: 8535, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001691, mae: 0.024191, mean_q: 0.024030
 62264/100000: episode: 8536, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001832, mae: 0.022786, mean_q: 0.030416
 62274/100000: episode: 8537, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001162, mae: 0.019451, mean_q: 0.026491
 62284/100000: episode: 8538, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001148, mae: 0.019160, mean_q: 0.035819
 62294/100000: episode: 8539, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002555, mae: 0.027290, mean_q: 0.046922
 62304/100000: episode: 8540, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001911, mae: 0.024028, mean_q: 0.032968
 62314/100000: episode: 8541, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001600, mae: 0.025392, mean_q: 0.040255
 62324/100000: episode: 8542, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001687, mae: 0.024228, mean_q: 0.043462
 62334/100000: episode: 8543, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001694, mae: 0.024752, mean_q: 0.029854
 62344/100000: episode: 8544, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001410, mae: 0.024402, mean_q: 0.035093
 62354/100000: episode: 8545, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001586, mae: 0.026208, mean_q: 0.037078
 62364/100000: episode: 8546, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002467, mae: 0.032215, mean_q: 0.051840
 62374/100000: episode: 8547, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001578, mae: 0.021728, mean_q: 0.031022
 62384/100000: episode: 8548, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001178, mae: 0.022709, mean_q: 0.026554
 62394/100000: episode: 8549, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001944, mae: 0.029590, mean_q: 0.033509
 62404/100000: episode: 8550, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001795, mae: 0.034658, mean_q: 0.047393
 62414/100000: episode: 8551, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001378, mae: 0.029696, mean_q: 0.034491
 62424/100000: episode: 8552, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001372, mae: 0.029283, mean_q: 0.019986
 62434/100000: episode: 8553, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001606, mae: 0.029240, mean_q: 0.027400
 62444/100000: episode: 8554, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002013, mae: 0.024760, mean_q: 0.028007
 62454/100000: episode: 8555, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001192, mae: 0.025044, mean_q: 0.038443
 62464/100000: episode: 8556, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001148, mae: 0.022911, mean_q: 0.034204
 62474/100000: episode: 8557, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001176, mae: 0.019340, mean_q: 0.023487
 62484/100000: episode: 8558, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000972, mae: 0.020168, mean_q: 0.030935
 62494/100000: episode: 8559, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001292, mae: 0.024118, mean_q: 0.027896
 62504/100000: episode: 8560, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002088, mae: 0.031259, mean_q: 0.043966
[Info] 1-TH LEVEL FOUND: 0.002985745668411255, Considering 17/100 traces
 62514/100000: episode: 8561, duration: 0.659s, episode steps: 10, steps per second: 15, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001554, mae: 0.028546, mean_q: 0.036581
 62522/100000: episode: 8562, duration: 0.041s, episode steps: 8, steps per second: 196, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.875 [-1.000, 11.000], loss: 0.001207, mae: 0.024419, mean_q: 0.035129
 62530/100000: episode: 8563, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.002068, mae: 0.024094, mean_q: 0.027574
 62538/100000: episode: 8564, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.022, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.002440, mae: 0.031746, mean_q: 0.051279
 62546/100000: episode: 8565, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.059, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.001946, mae: 0.024931, mean_q: 0.034670
 62554/100000: episode: 8566, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.035, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001294, mae: 0.028110, mean_q: 0.040355
 62562/100000: episode: 8567, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.215, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001651, mae: 0.028613, mean_q: 0.032054
 62570/100000: episode: 8568, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.097, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000759, mae: 0.017029, mean_q: 0.023147
 62578/100000: episode: 8569, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.097, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.000829, mae: 0.020502, mean_q: 0.024556
 62586/100000: episode: 8570, duration: 0.038s, episode steps: 8, steps per second: 208, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000893, mae: 0.018838, mean_q: 0.027170
 62594/100000: episode: 8571, duration: 0.039s, episode steps: 8, steps per second: 206, episode reward: 0.049, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.002400, mae: 0.026083, mean_q: 0.038808
 62602/100000: episode: 8572, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.039, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001891, mae: 0.024551, mean_q: 0.039822
 62610/100000: episode: 8573, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.001679, mae: 0.023806, mean_q: 0.029755
 62618/100000: episode: 8574, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.215, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001509, mae: 0.025373, mean_q: 0.032742
 62626/100000: episode: 8575, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.134, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.002133, mae: 0.024285, mean_q: 0.026974
 62634/100000: episode: 8576, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.000926, mae: 0.022377, mean_q: 0.018386
 62642/100000: episode: 8577, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.263, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.938 [-1.000, 11.000], loss: 0.001358, mae: 0.024144, mean_q: 0.033043
 62650/100000: episode: 8578, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.015, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.002151, mae: 0.024307, mean_q: 0.034723
 62658/100000: episode: 8579, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.348, mean reward: 0.044 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001651, mae: 0.019265, mean_q: 0.022461
 62666/100000: episode: 8580, duration: 0.038s, episode steps: 8, steps per second: 213, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.000936, mae: 0.019840, mean_q: 0.034047
 62674/100000: episode: 8581, duration: 0.037s, episode steps: 8, steps per second: 215, episode reward: 0.013, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.938 [-1.000, 11.000], loss: 0.001583, mae: 0.023039, mean_q: 0.033405
 62682/100000: episode: 8582, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.028, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.002161, mae: 0.026410, mean_q: 0.038805
 62690/100000: episode: 8583, duration: 0.040s, episode steps: 8, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.812 [-1.000, 11.000], loss: 0.001381, mae: 0.024567, mean_q: 0.031104
 62698/100000: episode: 8584, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.065, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001431, mae: 0.020959, mean_q: 0.035034
 62706/100000: episode: 8585, duration: 0.039s, episode steps: 8, steps per second: 204, episode reward: 0.030, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.001532, mae: 0.022370, mean_q: 0.023580
 62714/100000: episode: 8586, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.001374, mae: 0.022933, mean_q: 0.035273
 62722/100000: episode: 8587, duration: 0.037s, episode steps: 8, steps per second: 214, episode reward: 0.348, mean reward: 0.044 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002046, mae: 0.025880, mean_q: 0.038220
 62730/100000: episode: 8588, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.250 [-1.000, 11.000], loss: 0.002060, mae: 0.027683, mean_q: 0.042370
 62738/100000: episode: 8589, duration: 0.043s, episode steps: 8, steps per second: 184, episode reward: 0.215, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001809, mae: 0.026833, mean_q: 0.049180
 62746/100000: episode: 8590, duration: 0.050s, episode steps: 8, steps per second: 161, episode reward: 0.030, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.001045, mae: 0.020134, mean_q: 0.036582
 62754/100000: episode: 8591, duration: 0.050s, episode steps: 8, steps per second: 159, episode reward: 0.177, mean reward: 0.022 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.002238, mae: 0.027526, mean_q: 0.033966
 62762/100000: episode: 8592, duration: 0.048s, episode steps: 8, steps per second: 166, episode reward: 0.079, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001341, mae: 0.029562, mean_q: 0.040540
 62770/100000: episode: 8593, duration: 0.051s, episode steps: 8, steps per second: 157, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.001083, mae: 0.028144, mean_q: 0.033550
 62778/100000: episode: 8594, duration: 0.048s, episode steps: 8, steps per second: 167, episode reward: 0.067, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.001124, mae: 0.023659, mean_q: 0.012083
 62786/100000: episode: 8595, duration: 0.049s, episode steps: 8, steps per second: 163, episode reward: 0.049, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001329, mae: 0.024553, mean_q: 0.033041
 62794/100000: episode: 8596, duration: 0.040s, episode steps: 8, steps per second: 199, episode reward: 0.083, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.000953, mae: 0.022836, mean_q: 0.034079
 62802/100000: episode: 8597, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.002469, mae: 0.026957, mean_q: 0.036905
 62810/100000: episode: 8598, duration: 0.041s, episode steps: 8, steps per second: 194, episode reward: 0.038, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001674, mae: 0.024403, mean_q: 0.030213
 62818/100000: episode: 8599, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.087, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.001369, mae: 0.024447, mean_q: 0.029556
 62826/100000: episode: 8600, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.098, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.002202, mae: 0.030731, mean_q: 0.040855
 62834/100000: episode: 8601, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.097, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.001299, mae: 0.024109, mean_q: 0.033392
 62842/100000: episode: 8602, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.039, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001550, mae: 0.028093, mean_q: 0.042061
 62850/100000: episode: 8603, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.028, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001624, mae: 0.025739, mean_q: 0.034793
 62858/100000: episode: 8604, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.002355, mae: 0.025720, mean_q: 0.036067
 62866/100000: episode: 8605, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.130, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.001996, mae: 0.024615, mean_q: 0.030701
 62874/100000: episode: 8606, duration: 0.038s, episode steps: 8, steps per second: 209, episode reward: 0.051, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.001357, mae: 0.025821, mean_q: 0.040161
 62882/100000: episode: 8607, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.055, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001726, mae: 0.027937, mean_q: 0.039852
 62890/100000: episode: 8608, duration: 0.039s, episode steps: 8, steps per second: 205, episode reward: 0.015, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.001490, mae: 0.024823, mean_q: 0.028873
 62898/100000: episode: 8609, duration: 0.039s, episode steps: 8, steps per second: 208, episode reward: 0.128, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.625 [-1.000, 11.000], loss: 0.001849, mae: 0.032113, mean_q: 0.040923
 62906/100000: episode: 8610, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.051, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.002876, mae: 0.035037, mean_q: 0.042214
 62914/100000: episode: 8611, duration: 0.038s, episode steps: 8, steps per second: 212, episode reward: 0.059, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.001808, mae: 0.028539, mean_q: 0.036051
 62922/100000: episode: 8612, duration: 0.038s, episode steps: 8, steps per second: 211, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.002522, mae: 0.028033, mean_q: 0.032817
 62930/100000: episode: 8613, duration: 0.042s, episode steps: 8, steps per second: 191, episode reward: 0.177, mean reward: 0.022 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.875 [-1.000, 11.000], loss: 0.001309, mae: 0.030048, mean_q: 0.022722
 62938/100000: episode: 8614, duration: 0.041s, episode steps: 8, steps per second: 193, episode reward: 0.146, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.812 [-1.000, 11.000], loss: 0.001851, mae: 0.032512, mean_q: 0.023696
 62946/100000: episode: 8615, duration: 0.048s, episode steps: 8, steps per second: 166, episode reward: 0.097, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.001618, mae: 0.030874, mean_q: 0.044435
 62954/100000: episode: 8616, duration: 0.047s, episode steps: 8, steps per second: 170, episode reward: 0.348, mean reward: 0.044 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001737, mae: 0.024671, mean_q: 0.037335
 62962/100000: episode: 8617, duration: 0.049s, episode steps: 8, steps per second: 164, episode reward: 0.067, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.562 [-1.000, 11.000], loss: 0.001330, mae: 0.022051, mean_q: 0.035741
 62970/100000: episode: 8618, duration: 0.047s, episode steps: 8, steps per second: 170, episode reward: 0.036, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.001142, mae: 0.018518, mean_q: 0.024984
 62978/100000: episode: 8619, duration: 0.048s, episode steps: 8, steps per second: 166, episode reward: 0.079, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001439, mae: 0.025411, mean_q: 0.041479
 62986/100000: episode: 8620, duration: 0.048s, episode steps: 8, steps per second: 168, episode reward: 0.114, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001992, mae: 0.031917, mean_q: 0.041712
 62994/100000: episode: 8621, duration: 0.048s, episode steps: 8, steps per second: 168, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.875 [-1.000, 11.000], loss: 0.002161, mae: 0.026857, mean_q: 0.040160
 63002/100000: episode: 8622, duration: 0.047s, episode steps: 8, steps per second: 171, episode reward: 0.044, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.001114, mae: 0.020833, mean_q: 0.033869
 63010/100000: episode: 8623, duration: 0.040s, episode steps: 8, steps per second: 199, episode reward: 0.020, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.125 [-1.000, 11.000], loss: 0.003387, mae: 0.033277, mean_q: 0.047010
 63018/100000: episode: 8624, duration: 0.040s, episode steps: 8, steps per second: 198, episode reward: 0.035, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.000983, mae: 0.026400, mean_q: 0.016771
 63026/100000: episode: 8625, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.263, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.938 [-1.000, 11.000], loss: 0.001258, mae: 0.028806, mean_q: 0.031862
 63034/100000: episode: 8626, duration: 0.040s, episode steps: 8, steps per second: 199, episode reward: 0.348, mean reward: 0.044 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001818, mae: 0.026892, mean_q: 0.038042
 63042/100000: episode: 8627, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.042, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001976, mae: 0.028088, mean_q: 0.033178
 63050/100000: episode: 8628, duration: 0.049s, episode steps: 8, steps per second: 162, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001337, mae: 0.026469, mean_q: 0.025984
 63058/100000: episode: 8629, duration: 0.042s, episode steps: 8, steps per second: 189, episode reward: 0.044, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.001160, mae: 0.021949, mean_q: 0.032370
 63066/100000: episode: 8630, duration: 0.041s, episode steps: 8, steps per second: 195, episode reward: 0.036, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.001204, mae: 0.020867, mean_q: 0.036051
 63074/100000: episode: 8631, duration: 0.042s, episode steps: 8, steps per second: 191, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001316, mae: 0.020697, mean_q: 0.032387
 63082/100000: episode: 8632, duration: 0.042s, episode steps: 8, steps per second: 192, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001258, mae: 0.023109, mean_q: 0.034710
 63090/100000: episode: 8633, duration: 0.040s, episode steps: 8, steps per second: 201, episode reward: 0.044, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.438 [-1.000, 11.000], loss: 0.001354, mae: 0.023371, mean_q: 0.026355
 63098/100000: episode: 8634, duration: 0.041s, episode steps: 8, steps per second: 197, episode reward: 0.348, mean reward: 0.044 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000945, mae: 0.019770, mean_q: 0.029797
 63106/100000: episode: 8635, duration: 0.039s, episode steps: 8, steps per second: 208, episode reward: 0.215, mean reward: 0.027 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001932, mae: 0.024224, mean_q: 0.033559
 63114/100000: episode: 8636, duration: 0.041s, episode steps: 8, steps per second: 195, episode reward: 0.013, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.001175, mae: 0.025005, mean_q: 0.043181
 63122/100000: episode: 8637, duration: 0.039s, episode steps: 8, steps per second: 203, episode reward: 0.048, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.312 [-1.000, 11.000], loss: 0.001597, mae: 0.027625, mean_q: 0.036760
 63130/100000: episode: 8638, duration: 0.039s, episode steps: 8, steps per second: 207, episode reward: 0.348, mean reward: 0.044 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001961, mae: 0.028031, mean_q: 0.047359
 63138/100000: episode: 8639, duration: 0.038s, episode steps: 8, steps per second: 210, episode reward: 0.039, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.375 [-1.000, 11.000], loss: 0.001000, mae: 0.019960, mean_q: 0.028483
 63146/100000: episode: 8640, duration: 0.040s, episode steps: 8, steps per second: 202, episode reward: 0.102, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.688 [-1.000, 11.000], loss: 0.001419, mae: 0.024840, mean_q: 0.035946
 63154/100000: episode: 8641, duration: 0.044s, episode steps: 8, steps per second: 181, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.000989, mae: 0.021118, mean_q: 0.032848
 63162/100000: episode: 8642, duration: 0.051s, episode steps: 8, steps per second: 155, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.188 [-1.000, 11.000], loss: 0.002627, mae: 0.028376, mean_q: 0.038385
 63170/100000: episode: 8643, duration: 0.049s, episode steps: 8, steps per second: 165, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.062 [-1.000, 11.000], loss: 0.001414, mae: 0.022400, mean_q: 0.029153
[Info] 2-TH LEVEL FOUND: 0.2092036008834839, Considering 12/100 traces
 63178/100000: episode: 8644, duration: 0.727s, episode steps: 8, steps per second: 11, episode reward: 0.082, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001572, mae: 0.023530, mean_q: 0.031572
 63182/100000: episode: 8645, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001661, mae: 0.027311, mean_q: 0.045549
 63186/100000: episode: 8646, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002024, mae: 0.031285, mean_q: 0.050672
 63190/100000: episode: 8647, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001457, mae: 0.025933, mean_q: 0.050399
[Info] FALSIFICATION!
 63193/100000: episode: 8648, duration: 0.177s, episode steps: 3, steps per second: 17, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002085, mae: 0.032574, mean_q: 0.035212
 63197/100000: episode: 8649, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000664, mae: 0.020135, mean_q: 0.027275
 63201/100000: episode: 8650, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001792, mae: 0.028334, mean_q: 0.030519
 63205/100000: episode: 8651, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002668, mae: 0.028156, mean_q: 0.049907
[Info] FALSIFICATION!
 63208/100000: episode: 8652, duration: 0.182s, episode steps: 3, steps per second: 16, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000698, mae: 0.014842, mean_q: 0.021224
 63212/100000: episode: 8653, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000964, mae: 0.023513, mean_q: 0.031918
[Info] FALSIFICATION!
 63215/100000: episode: 8654, duration: 0.179s, episode steps: 3, steps per second: 17, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001313, mae: 0.024177, mean_q: 0.028849
[Info] FALSIFICATION!
 63218/100000: episode: 8655, duration: 0.185s, episode steps: 3, steps per second: 16, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002070, mae: 0.028803, mean_q: 0.043393
 63222/100000: episode: 8656, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000980, mae: 0.021874, mean_q: 0.029883
[Info] FALSIFICATION!
 63225/100000: episode: 8657, duration: 0.188s, episode steps: 3, steps per second: 16, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001808, mae: 0.023577, mean_q: 0.022746
 63229/100000: episode: 8658, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000970, mae: 0.026033, mean_q: 0.039762
 63233/100000: episode: 8659, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000854, mae: 0.023746, mean_q: 0.014069
 63237/100000: episode: 8660, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002535, mae: 0.030026, mean_q: 0.050905
[Info] FALSIFICATION!
 63240/100000: episode: 8661, duration: 0.272s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001198, mae: 0.020425, mean_q: 0.028776
 63244/100000: episode: 8662, duration: 0.024s, episode steps: 4, steps per second: 166, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001100, mae: 0.021543, mean_q: 0.039006
 63248/100000: episode: 8663, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001868, mae: 0.027420, mean_q: 0.026917
 63252/100000: episode: 8664, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001557, mae: 0.022613, mean_q: 0.030017
 63256/100000: episode: 8665, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001512, mae: 0.029014, mean_q: 0.046196
 63260/100000: episode: 8666, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002731, mae: 0.028843, mean_q: 0.046303
 63264/100000: episode: 8667, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001748, mae: 0.028980, mean_q: 0.040679
[Info] FALSIFICATION!
 63267/100000: episode: 8668, duration: 0.278s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001177, mae: 0.020348, mean_q: 0.039945
 63271/100000: episode: 8669, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.002144, mae: 0.032317, mean_q: 0.058158
[Info] FALSIFICATION!
 63274/100000: episode: 8670, duration: 0.364s, episode steps: 3, steps per second: 8, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002961, mae: 0.037573, mean_q: 0.080222
 63278/100000: episode: 8671, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002340, mae: 0.033901, mean_q: 0.024962
 63282/100000: episode: 8672, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001474, mae: 0.030434, mean_q: 0.042649
 63286/100000: episode: 8673, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001590, mae: 0.027224, mean_q: 0.035739
[Info] FALSIFICATION!
 63289/100000: episode: 8674, duration: 0.281s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.003910, mae: 0.028909, mean_q: 0.021552
[Info] FALSIFICATION!
 63292/100000: episode: 8675, duration: 0.285s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002523, mae: 0.038512, mean_q: 0.068929
 63296/100000: episode: 8676, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000990, mae: 0.023941, mean_q: 0.019616
 63300/100000: episode: 8677, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001232, mae: 0.027506, mean_q: 0.037772
 63304/100000: episode: 8678, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001708, mae: 0.025187, mean_q: 0.053884
[Info] FALSIFICATION!
 63307/100000: episode: 8679, duration: 0.294s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002592, mae: 0.033029, mean_q: 0.048614
 63311/100000: episode: 8680, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001282, mae: 0.021310, mean_q: 0.030837
 63315/100000: episode: 8681, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000924, mae: 0.021267, mean_q: 0.032066
 63319/100000: episode: 8682, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001788, mae: 0.030506, mean_q: 0.063093
 63323/100000: episode: 8683, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001315, mae: 0.021163, mean_q: 0.045694
 63327/100000: episode: 8684, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001342, mae: 0.025773, mean_q: 0.059756
[Info] FALSIFICATION!
 63330/100000: episode: 8685, duration: 0.277s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.003559, mae: 0.038197, mean_q: 0.072060
[Info] FALSIFICATION!
 63333/100000: episode: 8686, duration: 0.275s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002454, mae: 0.030026, mean_q: 0.040552
[Info] FALSIFICATION!
 63336/100000: episode: 8687, duration: 0.273s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002026, mae: 0.025810, mean_q: 0.034237
 63340/100000: episode: 8688, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001865, mae: 0.024136, mean_q: 0.035828
 63344/100000: episode: 8689, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.001347, mae: 0.021607, mean_q: 0.027660
 63348/100000: episode: 8690, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.003068, mae: 0.039880, mean_q: 0.062611
 63352/100000: episode: 8691, duration: 0.040s, episode steps: 4, steps per second: 101, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.002473, mae: 0.034429, mean_q: 0.045600
 63356/100000: episode: 8692, duration: 0.052s, episode steps: 4, steps per second: 77, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001438, mae: 0.022501, mean_q: 0.045599
 63360/100000: episode: 8693, duration: 0.069s, episode steps: 4, steps per second: 58, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.004399, mae: 0.037980, mean_q: 0.046697
 63364/100000: episode: 8694, duration: 0.034s, episode steps: 4, steps per second: 117, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000552, mae: 0.020931, mean_q: 0.045483
 63368/100000: episode: 8695, duration: 0.030s, episode steps: 4, steps per second: 133, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002707, mae: 0.038601, mean_q: 0.049695
 63372/100000: episode: 8696, duration: 0.030s, episode steps: 4, steps per second: 132, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001793, mae: 0.032549, mean_q: 0.049385
 63376/100000: episode: 8697, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002979, mae: 0.032948, mean_q: 0.046364
[Info] FALSIFICATION!
 63379/100000: episode: 8698, duration: 0.312s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001896, mae: 0.029855, mean_q: 0.062377
 63383/100000: episode: 8699, duration: 0.036s, episode steps: 4, steps per second: 112, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001803, mae: 0.030047, mean_q: 0.058548
 63387/100000: episode: 8700, duration: 0.043s, episode steps: 4, steps per second: 93, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003241, mae: 0.034401, mean_q: 0.041090
 63391/100000: episode: 8701, duration: 0.032s, episode steps: 4, steps per second: 124, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002602, mae: 0.036208, mean_q: 0.039375
 63395/100000: episode: 8702, duration: 0.036s, episode steps: 4, steps per second: 112, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002193, mae: 0.035065, mean_q: 0.053844
 63399/100000: episode: 8703, duration: 0.034s, episode steps: 4, steps per second: 118, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002502, mae: 0.040264, mean_q: 0.064102
 63403/100000: episode: 8704, duration: 0.038s, episode steps: 4, steps per second: 106, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003959, mae: 0.045049, mean_q: 0.066750
 63407/100000: episode: 8705, duration: 0.034s, episode steps: 4, steps per second: 117, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001479, mae: 0.026827, mean_q: 0.037062
 63411/100000: episode: 8706, duration: 0.057s, episode steps: 4, steps per second: 70, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002371, mae: 0.036016, mean_q: 0.062048
[Info] FALSIFICATION!
 63414/100000: episode: 8707, duration: 0.367s, episode steps: 3, steps per second: 8, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002300, mae: 0.035211, mean_q: 0.023410
 63418/100000: episode: 8708, duration: 0.052s, episode steps: 4, steps per second: 77, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002576, mae: 0.033155, mean_q: 0.045939
 63422/100000: episode: 8709, duration: 0.053s, episode steps: 4, steps per second: 75, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002014, mae: 0.031530, mean_q: 0.038514
 63426/100000: episode: 8710, duration: 0.037s, episode steps: 4, steps per second: 109, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002893, mae: 0.034051, mean_q: 0.056903
 63430/100000: episode: 8711, duration: 0.044s, episode steps: 4, steps per second: 90, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.004486, mae: 0.046104, mean_q: 0.074771
 63434/100000: episode: 8712, duration: 0.052s, episode steps: 4, steps per second: 77, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.002964, mae: 0.042425, mean_q: 0.044831
 63438/100000: episode: 8713, duration: 0.040s, episode steps: 4, steps per second: 101, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.005074, mae: 0.055673, mean_q: 0.044088
 63442/100000: episode: 8714, duration: 0.051s, episode steps: 4, steps per second: 78, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.002534, mae: 0.044850, mean_q: 0.065173
[Info] FALSIFICATION!
 63445/100000: episode: 8715, duration: 0.352s, episode steps: 3, steps per second: 9, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002077, mae: 0.031718, mean_q: 0.043531
 63449/100000: episode: 8716, duration: 0.036s, episode steps: 4, steps per second: 112, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001835, mae: 0.031770, mean_q: 0.029909
 63453/100000: episode: 8717, duration: 0.051s, episode steps: 4, steps per second: 79, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002386, mae: 0.034523, mean_q: 0.057804
 63457/100000: episode: 8718, duration: 0.048s, episode steps: 4, steps per second: 84, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001122, mae: 0.022610, mean_q: 0.031990
[Info] FALSIFICATION!
 63460/100000: episode: 8719, duration: 0.304s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.004374, mae: 0.034213, mean_q: 0.038518
 63464/100000: episode: 8720, duration: 0.043s, episode steps: 4, steps per second: 93, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.004311, mae: 0.043025, mean_q: 0.068616
 63468/100000: episode: 8721, duration: 0.048s, episode steps: 4, steps per second: 84, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002755, mae: 0.037318, mean_q: 0.060359
 63472/100000: episode: 8722, duration: 0.050s, episode steps: 4, steps per second: 80, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002736, mae: 0.032900, mean_q: 0.039302
 63476/100000: episode: 8723, duration: 0.062s, episode steps: 4, steps per second: 65, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002087, mae: 0.035508, mean_q: 0.058717
 63480/100000: episode: 8724, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002089, mae: 0.029859, mean_q: 0.030110
[Info] FALSIFICATION!
 63483/100000: episode: 8725, duration: 0.305s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001405, mae: 0.026913, mean_q: 0.054854
 63487/100000: episode: 8726, duration: 0.047s, episode steps: 4, steps per second: 85, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.003690, mae: 0.043314, mean_q: 0.072602
 63491/100000: episode: 8727, duration: 0.037s, episode steps: 4, steps per second: 107, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002913, mae: 0.043845, mean_q: 0.023380
 63495/100000: episode: 8728, duration: 0.059s, episode steps: 4, steps per second: 68, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003349, mae: 0.044561, mean_q: 0.069319
 63499/100000: episode: 8729, duration: 0.038s, episode steps: 4, steps per second: 106, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002721, mae: 0.038581, mean_q: 0.055698
 63503/100000: episode: 8730, duration: 0.033s, episode steps: 4, steps per second: 121, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002361, mae: 0.035843, mean_q: 0.065019
 63507/100000: episode: 8731, duration: 0.042s, episode steps: 4, steps per second: 96, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001498, mae: 0.023513, mean_q: 0.036497
[Info] FALSIFICATION!
[Info] Complete ISplit Iteration
[Info] Levels: [0.0029857457, 0.2092036, 1.0801467]
[Info] Cond. Prob: [0.17, 0.12, 0.2]
[Info] Error Prob: 0.00408

 63510/100000: episode: 8732, duration: 1.916s, episode steps: 3, steps per second: 2, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.004669, mae: 0.032590, mean_q: 0.036925
 63520/100000: episode: 8733, duration: 0.066s, episode steps: 10, steps per second: 150, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.004932, mae: 0.045194, mean_q: 0.085719
 63530/100000: episode: 8734, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001947, mae: 0.029195, mean_q: 0.046574
 63540/100000: episode: 8735, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002819, mae: 0.037969, mean_q: 0.054095
 63550/100000: episode: 8736, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.003227, mae: 0.039301, mean_q: 0.060991
 63560/100000: episode: 8737, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.005444, mae: 0.048473, mean_q: 0.072418
 63570/100000: episode: 8738, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002543, mae: 0.033191, mean_q: 0.042294
 63580/100000: episode: 8739, duration: 0.091s, episode steps: 10, steps per second: 109, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.003105, mae: 0.037524, mean_q: 0.051715
 63590/100000: episode: 8740, duration: 0.083s, episode steps: 10, steps per second: 120, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002085, mae: 0.030619, mean_q: 0.041271
 63600/100000: episode: 8741, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002473, mae: 0.037390, mean_q: 0.067453
 63610/100000: episode: 8742, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002047, mae: 0.030352, mean_q: 0.052112
 63620/100000: episode: 8743, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.002882, mae: 0.036893, mean_q: 0.053711
 63630/100000: episode: 8744, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.003188, mae: 0.040497, mean_q: 0.059723
 63640/100000: episode: 8745, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002178, mae: 0.033973, mean_q: 0.053480
 63650/100000: episode: 8746, duration: 0.081s, episode steps: 10, steps per second: 124, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.004776, mae: 0.046968, mean_q: 0.073154
 63660/100000: episode: 8747, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.003252, mae: 0.041583, mean_q: 0.053580
 63670/100000: episode: 8748, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003829, mae: 0.043375, mean_q: 0.065370
 63680/100000: episode: 8749, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001823, mae: 0.032658, mean_q: 0.042246
 63690/100000: episode: 8750, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.003158, mae: 0.036269, mean_q: 0.053635
 63700/100000: episode: 8751, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.003154, mae: 0.036144, mean_q: 0.043025
 63710/100000: episode: 8752, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002967, mae: 0.035750, mean_q: 0.049789
 63720/100000: episode: 8753, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002075, mae: 0.032393, mean_q: 0.046793
 63730/100000: episode: 8754, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002071, mae: 0.030225, mean_q: 0.052363
 63740/100000: episode: 8755, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.003041, mae: 0.034886, mean_q: 0.060648
 63750/100000: episode: 8756, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.003807, mae: 0.036795, mean_q: 0.064423
 63760/100000: episode: 8757, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002302, mae: 0.032168, mean_q: 0.049344
 63770/100000: episode: 8758, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002496, mae: 0.034549, mean_q: 0.054504
 63780/100000: episode: 8759, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.004687, mae: 0.046664, mean_q: 0.061176
 63790/100000: episode: 8760, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.003427, mae: 0.039935, mean_q: 0.052411
 63800/100000: episode: 8761, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001954, mae: 0.029386, mean_q: 0.053455
 63810/100000: episode: 8762, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002084, mae: 0.027550, mean_q: 0.039552
 63820/100000: episode: 8763, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002952, mae: 0.031062, mean_q: 0.051924
 63830/100000: episode: 8764, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.002521, mae: 0.032844, mean_q: 0.042281
 63840/100000: episode: 8765, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003726, mae: 0.040449, mean_q: 0.054723
 63850/100000: episode: 8766, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002866, mae: 0.035178, mean_q: 0.067146
 63860/100000: episode: 8767, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003735, mae: 0.038160, mean_q: 0.049159
 63870/100000: episode: 8768, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001511, mae: 0.027111, mean_q: 0.032889
 63880/100000: episode: 8769, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002510, mae: 0.033893, mean_q: 0.039266
 63890/100000: episode: 8770, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002413, mae: 0.037732, mean_q: 0.051068
 63900/100000: episode: 8771, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002225, mae: 0.037192, mean_q: 0.071571
 63910/100000: episode: 8772, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.002414, mae: 0.028905, mean_q: 0.053913
 63920/100000: episode: 8773, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.003380, mae: 0.036285, mean_q: 0.062872
 63930/100000: episode: 8774, duration: 0.055s, episode steps: 10, steps per second: 180, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001719, mae: 0.028981, mean_q: 0.045574
 63940/100000: episode: 8775, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001609, mae: 0.025275, mean_q: 0.050095
 63950/100000: episode: 8776, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.003098, mae: 0.034628, mean_q: 0.061199
 63960/100000: episode: 8777, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.004150, mae: 0.038379, mean_q: 0.052519
 63970/100000: episode: 8778, duration: 0.064s, episode steps: 10, steps per second: 155, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002527, mae: 0.034016, mean_q: 0.049076
 63980/100000: episode: 8779, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.004214, mae: 0.038813, mean_q: 0.066154
 63990/100000: episode: 8780, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001933, mae: 0.029089, mean_q: 0.033853
 64000/100000: episode: 8781, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.002200, mae: 0.029618, mean_q: 0.051559
 64010/100000: episode: 8782, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.003218, mae: 0.034037, mean_q: 0.058700
 64020/100000: episode: 8783, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002815, mae: 0.036542, mean_q: 0.050466
 64030/100000: episode: 8784, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002003, mae: 0.025467, mean_q: 0.031861
 64040/100000: episode: 8785, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002363, mae: 0.033919, mean_q: 0.065796
 64050/100000: episode: 8786, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002885, mae: 0.041640, mean_q: 0.047943
 64060/100000: episode: 8787, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002467, mae: 0.030547, mean_q: 0.038831
 64070/100000: episode: 8788, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001649, mae: 0.025417, mean_q: 0.038039
 64080/100000: episode: 8789, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002826, mae: 0.033686, mean_q: 0.054673
 64090/100000: episode: 8790, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.002507, mae: 0.028253, mean_q: 0.047163
 64100/100000: episode: 8791, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.003563, mae: 0.035242, mean_q: 0.066888
 64110/100000: episode: 8792, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002091, mae: 0.031075, mean_q: 0.041701
 64120/100000: episode: 8793, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002428, mae: 0.029002, mean_q: 0.041419
 64130/100000: episode: 8794, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001847, mae: 0.026275, mean_q: 0.038073
 64140/100000: episode: 8795, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002393, mae: 0.030338, mean_q: 0.054218
 64150/100000: episode: 8796, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002832, mae: 0.039018, mean_q: 0.066129
 64160/100000: episode: 8797, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.003304, mae: 0.035606, mean_q: 0.046267
 64170/100000: episode: 8798, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001810, mae: 0.026057, mean_q: 0.036002
 64180/100000: episode: 8799, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002287, mae: 0.030873, mean_q: 0.049725
 64190/100000: episode: 8800, duration: 0.109s, episode steps: 10, steps per second: 92, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002735, mae: 0.028744, mean_q: 0.045213
 64200/100000: episode: 8801, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002685, mae: 0.036708, mean_q: 0.061223
 64210/100000: episode: 8802, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003940, mae: 0.042917, mean_q: 0.044856
 64220/100000: episode: 8803, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001934, mae: 0.035565, mean_q: 0.041336
 64230/100000: episode: 8804, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002884, mae: 0.037496, mean_q: 0.065142
 64240/100000: episode: 8805, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002852, mae: 0.037226, mean_q: 0.049731
 64250/100000: episode: 8806, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002151, mae: 0.029965, mean_q: 0.045671
 64260/100000: episode: 8807, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002559, mae: 0.025098, mean_q: 0.042758
 64270/100000: episode: 8808, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002746, mae: 0.023698, mean_q: 0.039322
 64280/100000: episode: 8809, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.003004, mae: 0.026953, mean_q: 0.036398
 64290/100000: episode: 8810, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001835, mae: 0.028788, mean_q: 0.038176
 64300/100000: episode: 8811, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002448, mae: 0.032198, mean_q: 0.054088
 64310/100000: episode: 8812, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002744, mae: 0.028634, mean_q: 0.051893
 64320/100000: episode: 8813, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001540, mae: 0.024485, mean_q: 0.048040
 64330/100000: episode: 8814, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001562, mae: 0.024664, mean_q: 0.038565
 64340/100000: episode: 8815, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002371, mae: 0.028969, mean_q: 0.046472
 64350/100000: episode: 8816, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.004070, mae: 0.039746, mean_q: 0.065224
 64360/100000: episode: 8817, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001882, mae: 0.029999, mean_q: 0.031404
 64370/100000: episode: 8818, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003627, mae: 0.034221, mean_q: 0.054871
 64380/100000: episode: 8819, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.004478, mae: 0.039505, mean_q: 0.062358
 64390/100000: episode: 8820, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001514, mae: 0.026968, mean_q: 0.043184
 64400/100000: episode: 8821, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002469, mae: 0.028392, mean_q: 0.041658
 64410/100000: episode: 8822, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001214, mae: 0.020905, mean_q: 0.028133
 64420/100000: episode: 8823, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001823, mae: 0.023790, mean_q: 0.033475
 64430/100000: episode: 8824, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.003112, mae: 0.030457, mean_q: 0.055744
 64440/100000: episode: 8825, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002923, mae: 0.033301, mean_q: 0.052248
 64450/100000: episode: 8826, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.003054, mae: 0.038714, mean_q: 0.045212
 64460/100000: episode: 8827, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.003177, mae: 0.032325, mean_q: 0.046052
 64470/100000: episode: 8828, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002046, mae: 0.025495, mean_q: 0.050404
 64480/100000: episode: 8829, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002422, mae: 0.028017, mean_q: 0.049542
 64490/100000: episode: 8830, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.003106, mae: 0.031957, mean_q: 0.042057
 64500/100000: episode: 8831, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.003237, mae: 0.034684, mean_q: 0.053050
[Info] 1-TH LEVEL FOUND: 0.03938859701156616, Considering 100/100 traces
 64510/100000: episode: 8832, duration: 0.896s, episode steps: 10, steps per second: 11, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002220, mae: 0.033932, mean_q: 0.057301
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.03938859701156616
 64511/100000: episode: 8833, duration: 0.492s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.008449, mae: 0.048695, mean_q: 0.046920
 64521/100000: episode: 8834, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001988, mae: 0.026840, mean_q: 0.040470
 64531/100000: episode: 8835, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003055, mae: 0.032552, mean_q: 0.057441
 64541/100000: episode: 8836, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002234, mae: 0.028633, mean_q: 0.034829
 64551/100000: episode: 8837, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001688, mae: 0.023249, mean_q: 0.037777
 64561/100000: episode: 8838, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002265, mae: 0.026843, mean_q: 0.048899
 64571/100000: episode: 8839, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002581, mae: 0.029941, mean_q: 0.042942
 64581/100000: episode: 8840, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001478, mae: 0.025853, mean_q: 0.029530
 64591/100000: episode: 8841, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002304, mae: 0.030164, mean_q: 0.051124
 64601/100000: episode: 8842, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002163, mae: 0.030157, mean_q: 0.051717
 64611/100000: episode: 8843, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001661, mae: 0.024784, mean_q: 0.039589
 64621/100000: episode: 8844, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.003725, mae: 0.034015, mean_q: 0.055366
 64631/100000: episode: 8845, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003112, mae: 0.037070, mean_q: 0.056239
 64641/100000: episode: 8846, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002662, mae: 0.031787, mean_q: 0.058885
 64651/100000: episode: 8847, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002264, mae: 0.032436, mean_q: 0.054999
 64661/100000: episode: 8848, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002525, mae: 0.027430, mean_q: 0.051979
 64671/100000: episode: 8849, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002899, mae: 0.028602, mean_q: 0.045132
 64681/100000: episode: 8850, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.002623, mae: 0.034512, mean_q: 0.057321
 64691/100000: episode: 8851, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.003168, mae: 0.034295, mean_q: 0.059756
 64701/100000: episode: 8852, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002452, mae: 0.032004, mean_q: 0.052838
 64711/100000: episode: 8853, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003429, mae: 0.031218, mean_q: 0.055051
 64721/100000: episode: 8854, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002384, mae: 0.034033, mean_q: 0.030100
 64731/100000: episode: 8855, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001804, mae: 0.027066, mean_q: 0.036030
 64741/100000: episode: 8856, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.003984, mae: 0.043583, mean_q: 0.051745
 64751/100000: episode: 8857, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002694, mae: 0.033327, mean_q: 0.046340
 64761/100000: episode: 8858, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002084, mae: 0.028029, mean_q: 0.049720
 64771/100000: episode: 8859, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002461, mae: 0.026015, mean_q: 0.047226
 64781/100000: episode: 8860, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001467, mae: 0.022555, mean_q: 0.050004
 64791/100000: episode: 8861, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.003034, mae: 0.033419, mean_q: 0.051737
 64801/100000: episode: 8862, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.003150, mae: 0.033644, mean_q: 0.056040
 64811/100000: episode: 8863, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.003256, mae: 0.038070, mean_q: 0.056284
 64821/100000: episode: 8864, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001888, mae: 0.026849, mean_q: 0.038885
 64831/100000: episode: 8865, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.002566, mae: 0.027835, mean_q: 0.053350
 64841/100000: episode: 8866, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.003546, mae: 0.036442, mean_q: 0.057315
 64851/100000: episode: 8867, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002016, mae: 0.034205, mean_q: 0.040488
 64861/100000: episode: 8868, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001476, mae: 0.026742, mean_q: 0.048635
 64871/100000: episode: 8869, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001384, mae: 0.023462, mean_q: 0.031178
 64881/100000: episode: 8870, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002229, mae: 0.027502, mean_q: 0.046416
 64891/100000: episode: 8871, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.003014, mae: 0.032524, mean_q: 0.036365
 64901/100000: episode: 8872, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002836, mae: 0.041232, mean_q: 0.054642
 64911/100000: episode: 8873, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.003663, mae: 0.037129, mean_q: 0.060198
 64921/100000: episode: 8874, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.002201, mae: 0.028379, mean_q: 0.038080
 64931/100000: episode: 8875, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.003150, mae: 0.031948, mean_q: 0.053351
 64941/100000: episode: 8876, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001959, mae: 0.026188, mean_q: 0.046462
 64951/100000: episode: 8877, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.004014, mae: 0.037405, mean_q: 0.050291
 64961/100000: episode: 8878, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002251, mae: 0.034254, mean_q: 0.045754
 64971/100000: episode: 8879, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002420, mae: 0.028629, mean_q: 0.039171
 64981/100000: episode: 8880, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002486, mae: 0.030678, mean_q: 0.041939
 64991/100000: episode: 8881, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003502, mae: 0.036772, mean_q: 0.065490
 65001/100000: episode: 8882, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002637, mae: 0.030852, mean_q: 0.052975
 65011/100000: episode: 8883, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.003361, mae: 0.030729, mean_q: 0.050711
 65021/100000: episode: 8884, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.002463, mae: 0.030989, mean_q: 0.060069
 65031/100000: episode: 8885, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.003236, mae: 0.030572, mean_q: 0.036657
 65041/100000: episode: 8886, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.004488, mae: 0.049916, mean_q: 0.052959
 65051/100000: episode: 8887, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003919, mae: 0.045761, mean_q: 0.065892
 65061/100000: episode: 8888, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.003604, mae: 0.033935, mean_q: 0.046832
 65071/100000: episode: 8889, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003801, mae: 0.032840, mean_q: 0.045251
 65081/100000: episode: 8890, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.002169, mae: 0.030009, mean_q: 0.041201
 65091/100000: episode: 8891, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002538, mae: 0.027710, mean_q: 0.043280
 65101/100000: episode: 8892, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.002425, mae: 0.031458, mean_q: 0.058991
 65111/100000: episode: 8893, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001870, mae: 0.025004, mean_q: 0.037578
 65121/100000: episode: 8894, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001622, mae: 0.025022, mean_q: 0.040175
 65131/100000: episode: 8895, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002709, mae: 0.032395, mean_q: 0.057330
 65141/100000: episode: 8896, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002053, mae: 0.029636, mean_q: 0.048876
 65151/100000: episode: 8897, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001559, mae: 0.026816, mean_q: 0.034890
 65161/100000: episode: 8898, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002173, mae: 0.032345, mean_q: 0.038693
 65171/100000: episode: 8899, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001631, mae: 0.024685, mean_q: 0.035112
 65181/100000: episode: 8900, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002563, mae: 0.029441, mean_q: 0.039031
 65191/100000: episode: 8901, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002121, mae: 0.026354, mean_q: 0.039453
 65201/100000: episode: 8902, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.003351, mae: 0.035866, mean_q: 0.047457
 65211/100000: episode: 8903, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002957, mae: 0.032930, mean_q: 0.048627
 65221/100000: episode: 8904, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002464, mae: 0.032883, mean_q: 0.063692
 65231/100000: episode: 8905, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002671, mae: 0.033762, mean_q: 0.053927
 65241/100000: episode: 8906, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.003458, mae: 0.035635, mean_q: 0.047990
 65251/100000: episode: 8907, duration: 0.088s, episode steps: 10, steps per second: 113, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002637, mae: 0.029414, mean_q: 0.042000
 65261/100000: episode: 8908, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002543, mae: 0.027532, mean_q: 0.030818
 65271/100000: episode: 8909, duration: 0.098s, episode steps: 10, steps per second: 102, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.003153, mae: 0.040538, mean_q: 0.056106
 65281/100000: episode: 8910, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001982, mae: 0.032150, mean_q: 0.031846
 65291/100000: episode: 8911, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.003588, mae: 0.035547, mean_q: 0.057023
 65301/100000: episode: 8912, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001709, mae: 0.032710, mean_q: 0.034472
 65311/100000: episode: 8913, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002768, mae: 0.034292, mean_q: 0.048138
 65321/100000: episode: 8914, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.003032, mae: 0.029264, mean_q: 0.036639
 65331/100000: episode: 8915, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001593, mae: 0.029811, mean_q: 0.044270
 65341/100000: episode: 8916, duration: 0.073s, episode steps: 10, steps per second: 138, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002931, mae: 0.032685, mean_q: 0.052632
 65351/100000: episode: 8917, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002492, mae: 0.031269, mean_q: 0.034623
 65361/100000: episode: 8918, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002731, mae: 0.036790, mean_q: 0.047837
 65371/100000: episode: 8919, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.003319, mae: 0.034792, mean_q: 0.052289
 65381/100000: episode: 8920, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001586, mae: 0.027674, mean_q: 0.042633
 65391/100000: episode: 8921, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002439, mae: 0.032235, mean_q: 0.052973
 65401/100000: episode: 8922, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002595, mae: 0.034930, mean_q: 0.040115
 65411/100000: episode: 8923, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002878, mae: 0.031167, mean_q: 0.050583
 65421/100000: episode: 8924, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.003288, mae: 0.032600, mean_q: 0.063503
 65431/100000: episode: 8925, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003178, mae: 0.033817, mean_q: 0.032512
 65441/100000: episode: 8926, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.003856, mae: 0.036573, mean_q: 0.045939
 65451/100000: episode: 8927, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002140, mae: 0.028374, mean_q: 0.040126
 65461/100000: episode: 8928, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002057, mae: 0.026518, mean_q: 0.033274
 65471/100000: episode: 8929, duration: 0.069s, episode steps: 10, steps per second: 146, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002392, mae: 0.022579, mean_q: 0.035057
 65481/100000: episode: 8930, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002397, mae: 0.026787, mean_q: 0.039068
 65491/100000: episode: 8931, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001751, mae: 0.026355, mean_q: 0.047576
 65501/100000: episode: 8932, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.002526, mae: 0.030983, mean_q: 0.044262
[Info] 1-TH LEVEL FOUND: 0.020885229110717773, Considering 10/100 traces
 65511/100000: episode: 8933, duration: 0.816s, episode steps: 10, steps per second: 12, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.003047, mae: 0.031525, mean_q: 0.055940
 65518/100000: episode: 8934, duration: 0.050s, episode steps: 7, steps per second: 139, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.001953, mae: 0.028839, mean_q: 0.036712
 65522/100000: episode: 8935, duration: 0.037s, episode steps: 4, steps per second: 107, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001524, mae: 0.021825, mean_q: 0.033655
 65526/100000: episode: 8936, duration: 0.043s, episode steps: 4, steps per second: 92, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001791, mae: 0.027752, mean_q: 0.041010
 65530/100000: episode: 8937, duration: 0.042s, episode steps: 4, steps per second: 95, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001134, mae: 0.019709, mean_q: 0.037299
 65534/100000: episode: 8938, duration: 0.050s, episode steps: 4, steps per second: 81, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001175, mae: 0.021675, mean_q: 0.034886
 65538/100000: episode: 8939, duration: 0.041s, episode steps: 4, steps per second: 97, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001133, mae: 0.020551, mean_q: 0.035904
 65545/100000: episode: 8940, duration: 0.080s, episode steps: 7, steps per second: 88, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001790, mae: 0.020959, mean_q: 0.027476
 65552/100000: episode: 8941, duration: 0.058s, episode steps: 7, steps per second: 120, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001429, mae: 0.022910, mean_q: 0.038474
 65556/100000: episode: 8942, duration: 0.025s, episode steps: 4, steps per second: 160, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001544, mae: 0.019181, mean_q: 0.031936
 65560/100000: episode: 8943, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004076, mae: 0.038379, mean_q: 0.074320
 65562/100000: episode: 8944, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001756, mae: 0.021143, mean_q: 0.025201
 65566/100000: episode: 8945, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.005225, mae: 0.043255, mean_q: 0.045169
 65570/100000: episode: 8946, duration: 0.024s, episode steps: 4, steps per second: 170, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002952, mae: 0.036352, mean_q: 0.060358
 65572/100000: episode: 8947, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001192, mae: 0.022112, mean_q: 0.039976
 65574/100000: episode: 8948, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001443, mae: 0.022498, mean_q: 0.039815
 65578/100000: episode: 8949, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.005477, mae: 0.038703, mean_q: 0.055313
 65582/100000: episode: 8950, duration: 0.031s, episode steps: 4, steps per second: 130, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.004225, mae: 0.031200, mean_q: 0.055722
 65589/100000: episode: 8951, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.002736, mae: 0.031660, mean_q: 0.041138
 65593/100000: episode: 8952, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001807, mae: 0.029585, mean_q: 0.021263
 65597/100000: episode: 8953, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002497, mae: 0.034075, mean_q: 0.051948
 65599/100000: episode: 8954, duration: 0.022s, episode steps: 2, steps per second: 90, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006342, mae: 0.030415, mean_q: 0.024747
 65603/100000: episode: 8955, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001580, mae: 0.031215, mean_q: 0.049399
 65605/100000: episode: 8956, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003471, mae: 0.040635, mean_q: 0.053721
 65607/100000: episode: 8957, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005612, mae: 0.059658, mean_q: 0.042640
 65609/100000: episode: 8958, duration: 0.015s, episode steps: 2, steps per second: 135, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002263, mae: 0.035165, mean_q: 0.040471
 65611/100000: episode: 8959, duration: 0.016s, episode steps: 2, steps per second: 128, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005849, mae: 0.042898, mean_q: 0.052097
 65615/100000: episode: 8960, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002681, mae: 0.047461, mean_q: 0.068999
 65617/100000: episode: 8961, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000715, mae: 0.018356, mean_q: 0.020054
 65621/100000: episode: 8962, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.005135, mae: 0.042111, mean_q: 0.039622
 65628/100000: episode: 8963, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.003508, mae: 0.029724, mean_q: 0.055323
 65635/100000: episode: 8964, duration: 0.045s, episode steps: 7, steps per second: 156, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004160, mae: 0.036295, mean_q: 0.055233
 65639/100000: episode: 8965, duration: 0.028s, episode steps: 4, steps per second: 144, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.004949, mae: 0.042845, mean_q: 0.076909
 65641/100000: episode: 8966, duration: 0.018s, episode steps: 2, steps per second: 113, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000591, mae: 0.019521, mean_q: 0.009344
 65648/100000: episode: 8967, duration: 0.038s, episode steps: 7, steps per second: 184, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.001628, mae: 0.022032, mean_q: 0.035819
 65650/100000: episode: 8968, duration: 0.015s, episode steps: 2, steps per second: 138, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003604, mae: 0.039317, mean_q: 0.045068
 65654/100000: episode: 8969, duration: 0.031s, episode steps: 4, steps per second: 129, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001619, mae: 0.018429, mean_q: 0.024416
 65661/100000: episode: 8970, duration: 0.038s, episode steps: 7, steps per second: 186, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.004070, mae: 0.038034, mean_q: 0.052386
 65663/100000: episode: 8971, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000153, mae: 0.013426, mean_q: -0.002499
 65667/100000: episode: 8972, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002746, mae: 0.024888, mean_q: 0.024834
 65671/100000: episode: 8973, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001961, mae: 0.022474, mean_q: 0.039168
 65675/100000: episode: 8974, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001914, mae: 0.027780, mean_q: 0.042598
 65679/100000: episode: 8975, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001525, mae: 0.026684, mean_q: 0.024805
 65681/100000: episode: 8976, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001521, mae: 0.023423, mean_q: 0.034558
 65688/100000: episode: 8977, duration: 0.041s, episode steps: 7, steps per second: 173, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.002325, mae: 0.031388, mean_q: 0.050045
 65692/100000: episode: 8978, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.004279, mae: 0.029394, mean_q: 0.030239
 65694/100000: episode: 8979, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000965, mae: 0.020656, mean_q: 0.029934
 65698/100000: episode: 8980, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001519, mae: 0.022259, mean_q: 0.039706
 65700/100000: episode: 8981, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001231, mae: 0.021620, mean_q: 0.019806
 65704/100000: episode: 8982, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001076, mae: 0.020174, mean_q: 0.027396
 65706/100000: episode: 8983, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000434, mae: 0.012172, mean_q: 0.019763
 65713/100000: episode: 8984, duration: 0.046s, episode steps: 7, steps per second: 152, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.002215, mae: 0.023165, mean_q: 0.038867
 65720/100000: episode: 8985, duration: 0.043s, episode steps: 7, steps per second: 163, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001485, mae: 0.022090, mean_q: 0.040879
 65724/100000: episode: 8986, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001965, mae: 0.026898, mean_q: 0.033644
 65726/100000: episode: 8987, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006540, mae: 0.047187, mean_q: 0.077413
 65733/100000: episode: 8988, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001358, mae: 0.023246, mean_q: 0.033197
 65740/100000: episode: 8989, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000691, mae: 0.016317, mean_q: 0.014880
 65747/100000: episode: 8990, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002901, mae: 0.027620, mean_q: 0.040580
 65751/100000: episode: 8991, duration: 0.029s, episode steps: 4, steps per second: 140, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001515, mae: 0.023573, mean_q: 0.036475
 65753/100000: episode: 8992, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003767, mae: 0.034401, mean_q: 0.049442
 65757/100000: episode: 8993, duration: 0.023s, episode steps: 4, steps per second: 170, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003183, mae: 0.029084, mean_q: 0.044776
 65759/100000: episode: 8994, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001542, mae: 0.023964, mean_q: 0.049706
 65766/100000: episode: 8995, duration: 0.072s, episode steps: 7, steps per second: 97, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.002352, mae: 0.029946, mean_q: 0.033304
 65768/100000: episode: 8996, duration: 0.035s, episode steps: 2, steps per second: 57, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003348, mae: 0.038788, mean_q: 0.061916
 65772/100000: episode: 8997, duration: 0.040s, episode steps: 4, steps per second: 101, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001690, mae: 0.023616, mean_q: 0.020794
 65774/100000: episode: 8998, duration: 0.015s, episode steps: 2, steps per second: 132, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003187, mae: 0.031437, mean_q: 0.018838
 65778/100000: episode: 8999, duration: 0.031s, episode steps: 4, steps per second: 129, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000581, mae: 0.018821, mean_q: 0.024337
 65782/100000: episode: 9000, duration: 0.039s, episode steps: 4, steps per second: 104, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002359, mae: 0.028416, mean_q: 0.036514
 65789/100000: episode: 9001, duration: 0.056s, episode steps: 7, steps per second: 125, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001953, mae: 0.028640, mean_q: 0.036657
 65791/100000: episode: 9002, duration: 0.017s, episode steps: 2, steps per second: 115, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001361, mae: 0.019070, mean_q: 0.026601
 65793/100000: episode: 9003, duration: 0.019s, episode steps: 2, steps per second: 106, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004677, mae: 0.028733, mean_q: 0.031272
 65797/100000: episode: 9004, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002457, mae: 0.028653, mean_q: 0.054967
 65801/100000: episode: 9005, duration: 0.026s, episode steps: 4, steps per second: 153, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002016, mae: 0.027557, mean_q: 0.038868
 65805/100000: episode: 9006, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000832, mae: 0.016493, mean_q: 0.020998
 65809/100000: episode: 9007, duration: 0.028s, episode steps: 4, steps per second: 144, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001033, mae: 0.019777, mean_q: 0.033443
 65813/100000: episode: 9008, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001760, mae: 0.024742, mean_q: 0.032235
 65815/100000: episode: 9009, duration: 0.015s, episode steps: 2, steps per second: 135, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000885, mae: 0.017177, mean_q: 0.028301
 65819/100000: episode: 9010, duration: 0.024s, episode steps: 4, steps per second: 170, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001036, mae: 0.019463, mean_q: 0.035908
 65823/100000: episode: 9011, duration: 0.025s, episode steps: 4, steps per second: 161, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000674, mae: 0.015376, mean_q: 0.018948
 65825/100000: episode: 9012, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001497, mae: 0.017323, mean_q: 0.020716
 65827/100000: episode: 9013, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004168, mae: 0.023514, mean_q: 0.022059
 65834/100000: episode: 9014, duration: 0.038s, episode steps: 7, steps per second: 186, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001324, mae: 0.023374, mean_q: 0.037101
 65836/100000: episode: 9015, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002021, mae: 0.029832, mean_q: 0.026763
 65838/100000: episode: 9016, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000392, mae: 0.011089, mean_q: 0.025161
 65842/100000: episode: 9017, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001698, mae: 0.022995, mean_q: 0.039635
 65846/100000: episode: 9018, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002736, mae: 0.020676, mean_q: 0.027587
 65848/100000: episode: 9019, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001314, mae: 0.016912, mean_q: 0.035038
 65850/100000: episode: 9020, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000495, mae: 0.013552, mean_q: 0.024389
 65852/100000: episode: 9021, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003111, mae: 0.030853, mean_q: 0.059523
 65856/100000: episode: 9022, duration: 0.023s, episode steps: 4, steps per second: 178, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001047, mae: 0.018319, mean_q: 0.018953
[Info] 2-TH LEVEL FOUND: 0.102081298828125, Considering 24/100 traces
 65858/100000: episode: 9023, duration: 0.729s, episode steps: 2, steps per second: 3, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001524, mae: 0.024812, mean_q: 0.050469
 65861/100000: episode: 9024, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001707, mae: 0.023002, mean_q: 0.045937
 65864/100000: episode: 9025, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002970, mae: 0.019532, mean_q: 0.014633
 65867/100000: episode: 9026, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001212, mae: 0.019800, mean_q: 0.036353
 65870/100000: episode: 9027, duration: 0.019s, episode steps: 3, steps per second: 156, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000352, mae: 0.012051, mean_q: 0.016371
 65873/100000: episode: 9028, duration: 0.021s, episode steps: 3, steps per second: 144, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000946, mae: 0.017547, mean_q: 0.021467
 65876/100000: episode: 9029, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001047, mae: 0.019283, mean_q: 0.040784
 65879/100000: episode: 9030, duration: 0.019s, episode steps: 3, steps per second: 156, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000513, mae: 0.014856, mean_q: 0.023662
 65882/100000: episode: 9031, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001281, mae: 0.023036, mean_q: 0.033755
 65885/100000: episode: 9032, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000584, mae: 0.013026, mean_q: 0.024012
 65888/100000: episode: 9033, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000609, mae: 0.013756, mean_q: 0.023298
 65891/100000: episode: 9034, duration: 0.021s, episode steps: 3, steps per second: 140, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001783, mae: 0.024434, mean_q: 0.039440
 65894/100000: episode: 9035, duration: 0.025s, episode steps: 3, steps per second: 120, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002681, mae: 0.031209, mean_q: 0.054397
 65897/100000: episode: 9036, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001469, mae: 0.023697, mean_q: 0.036542
 65900/100000: episode: 9037, duration: 0.019s, episode steps: 3, steps per second: 156, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000793, mae: 0.016458, mean_q: 0.029381
 65903/100000: episode: 9038, duration: 0.020s, episode steps: 3, steps per second: 147, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003619, mae: 0.028994, mean_q: 0.030011
 65906/100000: episode: 9039, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003444, mae: 0.028514, mean_q: 0.047184
 65911/100000: episode: 9040, duration: 0.031s, episode steps: 5, steps per second: 162, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001127, mae: 0.018792, mean_q: 0.018839
 65914/100000: episode: 9041, duration: 0.019s, episode steps: 3, steps per second: 157, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001993, mae: 0.031276, mean_q: 0.036359
 65917/100000: episode: 9042, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001467, mae: 0.018079, mean_q: 0.028059
 65920/100000: episode: 9043, duration: 0.019s, episode steps: 3, steps per second: 155, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001196, mae: 0.018726, mean_q: 0.023272
 65923/100000: episode: 9044, duration: 0.024s, episode steps: 3, steps per second: 125, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000992, mae: 0.018935, mean_q: 0.013200
 65926/100000: episode: 9045, duration: 0.024s, episode steps: 3, steps per second: 123, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001072, mae: 0.021002, mean_q: 0.032717
 65929/100000: episode: 9046, duration: 0.024s, episode steps: 3, steps per second: 123, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001342, mae: 0.025635, mean_q: 0.046538
 65932/100000: episode: 9047, duration: 0.029s, episode steps: 3, steps per second: 104, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000693, mae: 0.015173, mean_q: 0.018387
 65935/100000: episode: 9048, duration: 0.030s, episode steps: 3, steps per second: 101, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001310, mae: 0.020741, mean_q: 0.038151
 65938/100000: episode: 9049, duration: 0.027s, episode steps: 3, steps per second: 110, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000520, mae: 0.011371, mean_q: 0.020095
 65941/100000: episode: 9050, duration: 0.026s, episode steps: 3, steps per second: 115, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000528, mae: 0.011021, mean_q: 0.019926
 65946/100000: episode: 9051, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001690, mae: 0.021583, mean_q: 0.031949
 65949/100000: episode: 9052, duration: 0.025s, episode steps: 3, steps per second: 122, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001081, mae: 0.023777, mean_q: 0.038219
 65952/100000: episode: 9053, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001162, mae: 0.020692, mean_q: 0.030670
 65955/100000: episode: 9054, duration: 0.022s, episode steps: 3, steps per second: 137, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001278, mae: 0.019305, mean_q: 0.016847
 65958/100000: episode: 9055, duration: 0.021s, episode steps: 3, steps per second: 140, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000694, mae: 0.018558, mean_q: 0.033603
 65961/100000: episode: 9056, duration: 0.026s, episode steps: 3, steps per second: 116, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001120, mae: 0.021014, mean_q: 0.041918
 65964/100000: episode: 9057, duration: 0.025s, episode steps: 3, steps per second: 120, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001597, mae: 0.023218, mean_q: 0.023566
 65967/100000: episode: 9058, duration: 0.022s, episode steps: 3, steps per second: 138, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000142, mae: 0.008747, mean_q: 0.008325
 65970/100000: episode: 9059, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001433, mae: 0.024605, mean_q: 0.046129
 65973/100000: episode: 9060, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001895, mae: 0.024208, mean_q: 0.042031
 65976/100000: episode: 9061, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004548, mae: 0.027020, mean_q: 0.030408
 65979/100000: episode: 9062, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000918, mae: 0.019252, mean_q: 0.040031
 65982/100000: episode: 9063, duration: 0.022s, episode steps: 3, steps per second: 138, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001731, mae: 0.022140, mean_q: 0.035838
 65985/100000: episode: 9064, duration: 0.024s, episode steps: 3, steps per second: 126, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002293, mae: 0.031314, mean_q: 0.021432
 65988/100000: episode: 9065, duration: 0.021s, episode steps: 3, steps per second: 142, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001513, mae: 0.020692, mean_q: 0.022012
 65993/100000: episode: 9066, duration: 0.034s, episode steps: 5, steps per second: 148, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000665, mae: 0.019302, mean_q: 0.025239
 65996/100000: episode: 9067, duration: 0.035s, episode steps: 3, steps per second: 87, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003805, mae: 0.026492, mean_q: 0.032393
 65999/100000: episode: 9068, duration: 0.037s, episode steps: 3, steps per second: 82, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000538, mae: 0.017070, mean_q: 0.024768
 66004/100000: episode: 9069, duration: 0.035s, episode steps: 5, steps per second: 142, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001556, mae: 0.024595, mean_q: 0.034425
 66007/100000: episode: 9070, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000607, mae: 0.014086, mean_q: 0.022964
 66010/100000: episode: 9071, duration: 0.030s, episode steps: 3, steps per second: 101, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002245, mae: 0.027913, mean_q: 0.042008
 66013/100000: episode: 9072, duration: 0.023s, episode steps: 3, steps per second: 132, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000759, mae: 0.014533, mean_q: 0.024858
 66016/100000: episode: 9073, duration: 0.020s, episode steps: 3, steps per second: 152, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000868, mae: 0.014852, mean_q: 0.023451
 66019/100000: episode: 9074, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001043, mae: 0.023469, mean_q: 0.035730
 66022/100000: episode: 9075, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000665, mae: 0.016205, mean_q: 0.020577
 66025/100000: episode: 9076, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001197, mae: 0.018959, mean_q: 0.038496
 66028/100000: episode: 9077, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000807, mae: 0.018150, mean_q: 0.028542
 66031/100000: episode: 9078, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001024, mae: 0.017888, mean_q: 0.025875
 66034/100000: episode: 9079, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000907, mae: 0.015671, mean_q: 0.036601
 66037/100000: episode: 9080, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000937, mae: 0.018089, mean_q: 0.037123
 66040/100000: episode: 9081, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003005, mae: 0.024190, mean_q: 0.029210
 66043/100000: episode: 9082, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003238, mae: 0.028095, mean_q: 0.059235
 66046/100000: episode: 9083, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001478, mae: 0.019888, mean_q: 0.020662
 66049/100000: episode: 9084, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000781, mae: 0.015623, mean_q: 0.028143
 66052/100000: episode: 9085, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001161, mae: 0.023427, mean_q: 0.048690
 66057/100000: episode: 9086, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001005, mae: 0.019924, mean_q: 0.028501
 66060/100000: episode: 9087, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001799, mae: 0.018806, mean_q: 0.029154
 66063/100000: episode: 9088, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001545, mae: 0.020931, mean_q: 0.039094
 66068/100000: episode: 9089, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001254, mae: 0.019938, mean_q: 0.043494
 66071/100000: episode: 9090, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001338, mae: 0.017505, mean_q: 0.028480
 66074/100000: episode: 9091, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002350, mae: 0.028592, mean_q: 0.058112
 66077/100000: episode: 9092, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002709, mae: 0.022322, mean_q: 0.031667
 66080/100000: episode: 9093, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002234, mae: 0.026230, mean_q: 0.045053
 66083/100000: episode: 9094, duration: 0.021s, episode steps: 3, steps per second: 141, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000908, mae: 0.024582, mean_q: 0.003768
 66086/100000: episode: 9095, duration: 0.019s, episode steps: 3, steps per second: 162, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002067, mae: 0.028436, mean_q: 0.036351
 66089/100000: episode: 9096, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000672, mae: 0.017998, mean_q: 0.032372
 66092/100000: episode: 9097, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001970, mae: 0.030416, mean_q: 0.044140
 66095/100000: episode: 9098, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001932, mae: 0.024418, mean_q: 0.043182
[Info] 3-TH LEVEL FOUND: 0.13216155767440796, Considering 10/100 traces
 66100/100000: episode: 9099, duration: 0.718s, episode steps: 5, steps per second: 7, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000921, mae: 0.022124, mean_q: 0.039088
 66105/100000: episode: 9100, duration: 0.029s, episode steps: 5, steps per second: 174, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000745, mae: 0.015891, mean_q: 0.027398
 66110/100000: episode: 9101, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001380, mae: 0.021914, mean_q: 0.042489
 66115/100000: episode: 9102, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001428, mae: 0.025488, mean_q: 0.036049
 66120/100000: episode: 9103, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000678, mae: 0.015864, mean_q: 0.021202
 66125/100000: episode: 9104, duration: 0.028s, episode steps: 5, steps per second: 182, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001074, mae: 0.015125, mean_q: 0.025363
 66130/100000: episode: 9105, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002491, mae: 0.018904, mean_q: 0.029020
 66135/100000: episode: 9106, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000901, mae: 0.018565, mean_q: 0.030717
 66140/100000: episode: 9107, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001396, mae: 0.020825, mean_q: 0.037355
 66145/100000: episode: 9108, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000511, mae: 0.015030, mean_q: 0.011594
 66150/100000: episode: 9109, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.002875, mae: 0.028590, mean_q: 0.043417
 66155/100000: episode: 9110, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001876, mae: 0.023972, mean_q: 0.031571
 66160/100000: episode: 9111, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000849, mae: 0.019015, mean_q: 0.033917
 66165/100000: episode: 9112, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001587, mae: 0.020462, mean_q: 0.024824
 66170/100000: episode: 9113, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001259, mae: 0.020767, mean_q: 0.040038
 66175/100000: episode: 9114, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001716, mae: 0.023350, mean_q: 0.025088
[Info] FALSIFICATION!
 66179/100000: episode: 9115, duration: 0.287s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.004172, mae: 0.037825, mean_q: 0.055348
[Info] FALSIFICATION!
 66183/100000: episode: 9116, duration: 0.286s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.003720, mae: 0.028461, mean_q: 0.036700
 66188/100000: episode: 9117, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000721, mae: 0.016103, mean_q: 0.024383
 66193/100000: episode: 9118, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001123, mae: 0.014901, mean_q: 0.022635
 66198/100000: episode: 9119, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.001550, mae: 0.021423, mean_q: 0.041408
 66203/100000: episode: 9120, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001254, mae: 0.023631, mean_q: 0.034383
 66208/100000: episode: 9121, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000496, mae: 0.015053, mean_q: 0.026331
 66213/100000: episode: 9122, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001882, mae: 0.024595, mean_q: 0.035749
 66218/100000: episode: 9123, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002167, mae: 0.024260, mean_q: 0.028297
 66223/100000: episode: 9124, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000460, mae: 0.015474, mean_q: 0.021542
 66228/100000: episode: 9125, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000970, mae: 0.021756, mean_q: 0.023380
 66233/100000: episode: 9126, duration: 0.028s, episode steps: 5, steps per second: 176, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002790, mae: 0.029942, mean_q: 0.050513
 66238/100000: episode: 9127, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001427, mae: 0.021912, mean_q: 0.027794
 66243/100000: episode: 9128, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.001416, mae: 0.023396, mean_q: 0.040869
 66248/100000: episode: 9129, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001007, mae: 0.018341, mean_q: 0.015830
 66253/100000: episode: 9130, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000839, mae: 0.018824, mean_q: 0.030922
 66258/100000: episode: 9131, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001619, mae: 0.018891, mean_q: 0.032367
 66263/100000: episode: 9132, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.004686, mae: 0.036015, mean_q: 0.051428
[Info] FALSIFICATION!
 66267/100000: episode: 9133, duration: 0.285s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.003768, mae: 0.043536, mean_q: 0.058545
 66272/100000: episode: 9134, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001371, mae: 0.030039, mean_q: 0.042762
 66277/100000: episode: 9135, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003823, mae: 0.038633, mean_q: 0.073677
 66282/100000: episode: 9136, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002095, mae: 0.024432, mean_q: 0.036361
 66287/100000: episode: 9137, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001657, mae: 0.022516, mean_q: 0.039553
 66292/100000: episode: 9138, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002529, mae: 0.032639, mean_q: 0.046071
 66297/100000: episode: 9139, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001172, mae: 0.027873, mean_q: 0.047807
 66302/100000: episode: 9140, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002146, mae: 0.027972, mean_q: 0.040324
 66307/100000: episode: 9141, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002090, mae: 0.026690, mean_q: 0.029681
 66312/100000: episode: 9142, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002132, mae: 0.034451, mean_q: 0.059086
 66317/100000: episode: 9143, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001605, mae: 0.021810, mean_q: 0.025388
 66322/100000: episode: 9144, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001340, mae: 0.027414, mean_q: 0.051715
 66327/100000: episode: 9145, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002161, mae: 0.035471, mean_q: 0.011932
 66332/100000: episode: 9146, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001562, mae: 0.035843, mean_q: 0.058510
 66337/100000: episode: 9147, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002154, mae: 0.035056, mean_q: 0.041939
 66342/100000: episode: 9148, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001677, mae: 0.025278, mean_q: 0.034788
 66347/100000: episode: 9149, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002497, mae: 0.028380, mean_q: 0.043929
 66352/100000: episode: 9150, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001550, mae: 0.025720, mean_q: 0.034041
 66357/100000: episode: 9151, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001745, mae: 0.026287, mean_q: 0.049662
 66362/100000: episode: 9152, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002330, mae: 0.029900, mean_q: 0.028275
 66367/100000: episode: 9153, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001726, mae: 0.031567, mean_q: 0.044557
 66372/100000: episode: 9154, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002769, mae: 0.030059, mean_q: 0.029311
 66377/100000: episode: 9155, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002997, mae: 0.029696, mean_q: 0.042979
 66382/100000: episode: 9156, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.003118, mae: 0.033814, mean_q: 0.046745
 66387/100000: episode: 9157, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002864, mae: 0.028382, mean_q: 0.041867
 66392/100000: episode: 9158, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002529, mae: 0.033935, mean_q: 0.026264
 66397/100000: episode: 9159, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002823, mae: 0.034669, mean_q: 0.042240
[Info] FALSIFICATION!
 66401/100000: episode: 9160, duration: 0.292s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001420, mae: 0.027901, mean_q: 0.067994
[Info] FALSIFICATION!
 66405/100000: episode: 9161, duration: 0.289s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.002213, mae: 0.033368, mean_q: 0.038798
 66410/100000: episode: 9162, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001737, mae: 0.029094, mean_q: 0.047751
 66415/100000: episode: 9163, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002053, mae: 0.025652, mean_q: 0.039044
 66420/100000: episode: 9164, duration: 0.028s, episode steps: 5, steps per second: 176, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001438, mae: 0.017424, mean_q: 0.023242
 66425/100000: episode: 9165, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001610, mae: 0.022455, mean_q: 0.035041
 66430/100000: episode: 9166, duration: 0.033s, episode steps: 5, steps per second: 152, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001714, mae: 0.025098, mean_q: 0.046583
 66435/100000: episode: 9167, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000913, mae: 0.020091, mean_q: 0.023979
 66440/100000: episode: 9168, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001922, mae: 0.029135, mean_q: 0.048982
 66445/100000: episode: 9169, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000536, mae: 0.014193, mean_q: 0.011830
 66450/100000: episode: 9170, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.003992, mae: 0.031370, mean_q: 0.033049
 66455/100000: episode: 9171, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.004074, mae: 0.039209, mean_q: 0.063169
 66460/100000: episode: 9172, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001633, mae: 0.031108, mean_q: 0.029411
 66465/100000: episode: 9173, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002522, mae: 0.031615, mean_q: 0.040490
 66470/100000: episode: 9174, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.004697, mae: 0.034711, mean_q: 0.038345
 66475/100000: episode: 9175, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002665, mae: 0.040959, mean_q: 0.068203
 66480/100000: episode: 9176, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001789, mae: 0.039991, mean_q: 0.008469
 66485/100000: episode: 9177, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002652, mae: 0.044745, mean_q: 0.056585
 66490/100000: episode: 9178, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002433, mae: 0.027275, mean_q: 0.014096
 66495/100000: episode: 9179, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.004791, mae: 0.040707, mean_q: 0.059941
 66500/100000: episode: 9180, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.004882, mae: 0.043622, mean_q: 0.058382
 66505/100000: episode: 9181, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002758, mae: 0.034369, mean_q: 0.025998
 66510/100000: episode: 9182, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002405, mae: 0.036665, mean_q: 0.050723
 66515/100000: episode: 9183, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002386, mae: 0.038986, mean_q: 0.048207
 66520/100000: episode: 9184, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001186, mae: 0.025716, mean_q: 0.031948
[Info] FALSIFICATION!
 66524/100000: episode: 9185, duration: 0.290s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.002025, mae: 0.032451, mean_q: 0.030728
 66529/100000: episode: 9186, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000842, mae: 0.022546, mean_q: 0.037547
 66534/100000: episode: 9187, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002024, mae: 0.030970, mean_q: 0.036616
 66539/100000: episode: 9188, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002815, mae: 0.033015, mean_q: 0.056401
[Info] Complete ISplit Iteration
[Info] Levels: [0.02088523, 0.1020813, 0.13216156, 1.0309542]
[Info] Cond. Prob: [0.1, 0.24, 0.1, 0.06]
[Info] Error Prob: 0.000144

 66544/100000: episode: 9189, duration: 0.924s, episode steps: 5, steps per second: 5, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002949, mae: 0.039905, mean_q: 0.062079
 66554/100000: episode: 9190, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.004270, mae: 0.046215, mean_q: 0.052429
 66564/100000: episode: 9191, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001873, mae: 0.028642, mean_q: 0.028243
 66574/100000: episode: 9192, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002220, mae: 0.029947, mean_q: 0.038603
 66584/100000: episode: 9193, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.002645, mae: 0.040980, mean_q: 0.061307
 66594/100000: episode: 9194, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001004, mae: 0.020740, mean_q: 0.038457
 66604/100000: episode: 9195, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002940, mae: 0.032081, mean_q: 0.060092
 66614/100000: episode: 9196, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003481, mae: 0.030918, mean_q: 0.047617
 66624/100000: episode: 9197, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001411, mae: 0.022776, mean_q: 0.033843
 66634/100000: episode: 9198, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.002856, mae: 0.030085, mean_q: 0.047635
 66644/100000: episode: 9199, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001947, mae: 0.025574, mean_q: 0.046177
 66654/100000: episode: 9200, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002791, mae: 0.030314, mean_q: 0.049011
 66664/100000: episode: 9201, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.003425, mae: 0.034174, mean_q: 0.050764
 66674/100000: episode: 9202, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001848, mae: 0.027408, mean_q: 0.046367
 66684/100000: episode: 9203, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001952, mae: 0.023324, mean_q: 0.035039
 66694/100000: episode: 9204, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002942, mae: 0.030282, mean_q: 0.035893
 66704/100000: episode: 9205, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002981, mae: 0.034192, mean_q: 0.053601
 66714/100000: episode: 9206, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002026, mae: 0.034494, mean_q: 0.031890
 66724/100000: episode: 9207, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.002781, mae: 0.034964, mean_q: 0.046901
 66734/100000: episode: 9208, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001945, mae: 0.035472, mean_q: 0.058818
 66744/100000: episode: 9209, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002057, mae: 0.032802, mean_q: 0.050959
 66754/100000: episode: 9210, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.003041, mae: 0.034862, mean_q: 0.043931
 66764/100000: episode: 9211, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.002372, mae: 0.029477, mean_q: 0.043175
 66774/100000: episode: 9212, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002387, mae: 0.028736, mean_q: 0.049667
 66784/100000: episode: 9213, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001859, mae: 0.027308, mean_q: 0.036782
 66794/100000: episode: 9214, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.002628, mae: 0.034185, mean_q: 0.055050
 66804/100000: episode: 9215, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002369, mae: 0.033395, mean_q: 0.050875
 66814/100000: episode: 9216, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.002703, mae: 0.034016, mean_q: 0.055954
 66824/100000: episode: 9217, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002584, mae: 0.037758, mean_q: 0.040499
 66834/100000: episode: 9218, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001520, mae: 0.027695, mean_q: 0.029540
 66844/100000: episode: 9219, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002167, mae: 0.029613, mean_q: 0.038838
 66854/100000: episode: 9220, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001580, mae: 0.029600, mean_q: 0.042200
 66864/100000: episode: 9221, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.002510, mae: 0.030731, mean_q: 0.051431
 66874/100000: episode: 9222, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.003413, mae: 0.037516, mean_q: 0.055831
 66884/100000: episode: 9223, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003244, mae: 0.034325, mean_q: 0.043379
 66894/100000: episode: 9224, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001751, mae: 0.027435, mean_q: 0.045511
 66904/100000: episode: 9225, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001148, mae: 0.024814, mean_q: 0.046705
 66914/100000: episode: 9226, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001553, mae: 0.028509, mean_q: 0.031727
 66924/100000: episode: 9227, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001546, mae: 0.021696, mean_q: 0.035473
 66934/100000: episode: 9228, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001855, mae: 0.031994, mean_q: 0.038607
 66944/100000: episode: 9229, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001829, mae: 0.032980, mean_q: 0.048880
 66954/100000: episode: 9230, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.003322, mae: 0.034804, mean_q: 0.051661
 66964/100000: episode: 9231, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002031, mae: 0.027666, mean_q: 0.029432
 66974/100000: episode: 9232, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001671, mae: 0.025110, mean_q: 0.035783
 66984/100000: episode: 9233, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.001823, mae: 0.028817, mean_q: 0.040115
 66994/100000: episode: 9234, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001834, mae: 0.020662, mean_q: 0.031665
 67004/100000: episode: 9235, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.003351, mae: 0.031167, mean_q: 0.051916
 67014/100000: episode: 9236, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.003257, mae: 0.033940, mean_q: 0.049031
 67024/100000: episode: 9237, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.003662, mae: 0.034116, mean_q: 0.049883
 67034/100000: episode: 9238, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002797, mae: 0.032351, mean_q: 0.050585
 67044/100000: episode: 9239, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002443, mae: 0.025379, mean_q: 0.038672
 67054/100000: episode: 9240, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002047, mae: 0.027436, mean_q: 0.037327
 67064/100000: episode: 9241, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.003087, mae: 0.035931, mean_q: 0.047069
 67074/100000: episode: 9242, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002009, mae: 0.028081, mean_q: 0.040076
 67084/100000: episode: 9243, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001825, mae: 0.024923, mean_q: 0.040180
 67094/100000: episode: 9244, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.003604, mae: 0.027874, mean_q: 0.040868
 67104/100000: episode: 9245, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001771, mae: 0.024728, mean_q: 0.040874
 67114/100000: episode: 9246, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002300, mae: 0.030116, mean_q: 0.051745
 67124/100000: episode: 9247, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001520, mae: 0.026233, mean_q: 0.043449
 67134/100000: episode: 9248, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000958, mae: 0.019907, mean_q: 0.039087
 67144/100000: episode: 9249, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.002584, mae: 0.030082, mean_q: 0.039481
 67154/100000: episode: 9250, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.003912, mae: 0.036721, mean_q: 0.050769
 67164/100000: episode: 9251, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001954, mae: 0.027063, mean_q: 0.036783
 67174/100000: episode: 9252, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002127, mae: 0.031834, mean_q: 0.046623
 67184/100000: episode: 9253, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.003017, mae: 0.037344, mean_q: 0.047875
 67194/100000: episode: 9254, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001355, mae: 0.030547, mean_q: 0.046795
 67204/100000: episode: 9255, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002627, mae: 0.028493, mean_q: 0.048175
 67214/100000: episode: 9256, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002888, mae: 0.030886, mean_q: 0.045752
 67224/100000: episode: 9257, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002975, mae: 0.038451, mean_q: 0.047198
 67234/100000: episode: 9258, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002571, mae: 0.030848, mean_q: 0.041283
 67244/100000: episode: 9259, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.003363, mae: 0.036968, mean_q: 0.059884
 67254/100000: episode: 9260, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002605, mae: 0.033576, mean_q: 0.048588
 67264/100000: episode: 9261, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002440, mae: 0.031242, mean_q: 0.038718
 67274/100000: episode: 9262, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002968, mae: 0.032778, mean_q: 0.043830
 67284/100000: episode: 9263, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001773, mae: 0.024651, mean_q: 0.041820
 67294/100000: episode: 9264, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002229, mae: 0.026133, mean_q: 0.046413
 67304/100000: episode: 9265, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001727, mae: 0.024328, mean_q: 0.049061
 67314/100000: episode: 9266, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002393, mae: 0.025761, mean_q: 0.031368
 67324/100000: episode: 9267, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002098, mae: 0.032245, mean_q: 0.045779
 67334/100000: episode: 9268, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002346, mae: 0.029365, mean_q: 0.046691
 67344/100000: episode: 9269, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002073, mae: 0.023151, mean_q: 0.031303
 67354/100000: episode: 9270, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001492, mae: 0.026491, mean_q: 0.023407
 67364/100000: episode: 9271, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002515, mae: 0.032771, mean_q: 0.055165
 67374/100000: episode: 9272, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.002139, mae: 0.022645, mean_q: 0.035201
 67384/100000: episode: 9273, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.003097, mae: 0.034838, mean_q: 0.058823
 67394/100000: episode: 9274, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.003622, mae: 0.031127, mean_q: 0.042272
 67404/100000: episode: 9275, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002817, mae: 0.028282, mean_q: 0.043354
 67414/100000: episode: 9276, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001797, mae: 0.025071, mean_q: 0.040125
 67424/100000: episode: 9277, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002301, mae: 0.026418, mean_q: 0.036878
 67434/100000: episode: 9278, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002374, mae: 0.031398, mean_q: 0.042563
 67444/100000: episode: 9279, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002501, mae: 0.027348, mean_q: 0.036942
 67454/100000: episode: 9280, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.003072, mae: 0.038503, mean_q: 0.044322
 67464/100000: episode: 9281, duration: 0.083s, episode steps: 10, steps per second: 121, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.003883, mae: 0.042909, mean_q: 0.067210
 67474/100000: episode: 9282, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001732, mae: 0.032632, mean_q: 0.037570
 67484/100000: episode: 9283, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.002159, mae: 0.028746, mean_q: 0.035760
 67494/100000: episode: 9284, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001752, mae: 0.024840, mean_q: 0.037317
 67504/100000: episode: 9285, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001239, mae: 0.019017, mean_q: 0.029423
 67514/100000: episode: 9286, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002155, mae: 0.027244, mean_q: 0.040902
 67524/100000: episode: 9287, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001610, mae: 0.023259, mean_q: 0.039895
 67534/100000: episode: 9288, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.003291, mae: 0.034728, mean_q: 0.053386
[Info] 1-TH LEVEL FOUND: 0.0018732547760009766, Considering 10/100 traces
 67544/100000: episode: 9289, duration: 1.273s, episode steps: 10, steps per second: 8, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002588, mae: 0.033856, mean_q: 0.042380
 67551/100000: episode: 9290, duration: 0.100s, episode steps: 7, steps per second: 70, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.001584, mae: 0.029706, mean_q: 0.023376
 67558/100000: episode: 9291, duration: 0.093s, episode steps: 7, steps per second: 76, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.003047, mae: 0.037458, mean_q: 0.055261
 67565/100000: episode: 9292, duration: 0.084s, episode steps: 7, steps per second: 83, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.002093, mae: 0.029212, mean_q: 0.046070
 67572/100000: episode: 9293, duration: 0.062s, episode steps: 7, steps per second: 113, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.000748, mae: 0.019299, mean_q: 0.021661
 67575/100000: episode: 9294, duration: 0.030s, episode steps: 3, steps per second: 101, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001682, mae: 0.028620, mean_q: 0.042844
 67578/100000: episode: 9295, duration: 0.035s, episode steps: 3, steps per second: 86, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001420, mae: 0.024638, mean_q: 0.042941
 67581/100000: episode: 9296, duration: 0.034s, episode steps: 3, steps per second: 87, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001113, mae: 0.021646, mean_q: 0.028830
 67588/100000: episode: 9297, duration: 0.067s, episode steps: 7, steps per second: 104, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.002289, mae: 0.023810, mean_q: 0.035902
 67595/100000: episode: 9298, duration: 0.068s, episode steps: 7, steps per second: 103, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001771, mae: 0.026447, mean_q: 0.028863
 67602/100000: episode: 9299, duration: 0.044s, episode steps: 7, steps per second: 158, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001460, mae: 0.025520, mean_q: 0.041733
 67609/100000: episode: 9300, duration: 0.040s, episode steps: 7, steps per second: 176, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001738, mae: 0.022047, mean_q: 0.035074
 67616/100000: episode: 9301, duration: 0.045s, episode steps: 7, steps per second: 155, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001163, mae: 0.022432, mean_q: 0.043867
 67623/100000: episode: 9302, duration: 0.039s, episode steps: 7, steps per second: 181, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.003576, mae: 0.028604, mean_q: 0.038356
 67630/100000: episode: 9303, duration: 0.046s, episode steps: 7, steps per second: 154, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002836, mae: 0.029796, mean_q: 0.054809
 67637/100000: episode: 9304, duration: 0.057s, episode steps: 7, steps per second: 123, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.001391, mae: 0.022654, mean_q: 0.017933
 67644/100000: episode: 9305, duration: 0.058s, episode steps: 7, steps per second: 122, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.002448, mae: 0.027736, mean_q: 0.039177
 67651/100000: episode: 9306, duration: 0.046s, episode steps: 7, steps per second: 152, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001928, mae: 0.028177, mean_q: 0.043650
 67658/100000: episode: 9307, duration: 0.048s, episode steps: 7, steps per second: 147, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.003659, mae: 0.033850, mean_q: 0.059492
 67665/100000: episode: 9308, duration: 0.037s, episode steps: 7, steps per second: 188, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.001469, mae: 0.021771, mean_q: 0.034399
 67668/100000: episode: 9309, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003496, mae: 0.029432, mean_q: 0.045521
 67675/100000: episode: 9310, duration: 0.043s, episode steps: 7, steps per second: 164, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000926, mae: 0.017316, mean_q: 0.024401
 67682/100000: episode: 9311, duration: 0.045s, episode steps: 7, steps per second: 154, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.002025, mae: 0.023037, mean_q: 0.018136
 67689/100000: episode: 9312, duration: 0.059s, episode steps: 7, steps per second: 119, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.002230, mae: 0.033072, mean_q: 0.050890
 67696/100000: episode: 9313, duration: 0.055s, episode steps: 7, steps per second: 128, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.001037, mae: 0.021468, mean_q: 0.037122
 67703/100000: episode: 9314, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.001023, mae: 0.019225, mean_q: 0.026895
 67710/100000: episode: 9315, duration: 0.052s, episode steps: 7, steps per second: 135, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000944, mae: 0.021070, mean_q: 0.043947
 67717/100000: episode: 9316, duration: 0.045s, episode steps: 7, steps per second: 157, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001159, mae: 0.022449, mean_q: 0.031456
 67724/100000: episode: 9317, duration: 0.056s, episode steps: 7, steps per second: 125, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.002518, mae: 0.029350, mean_q: 0.048627
 67731/100000: episode: 9318, duration: 0.054s, episode steps: 7, steps per second: 130, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.002929, mae: 0.026521, mean_q: 0.039591
 67734/100000: episode: 9319, duration: 0.026s, episode steps: 3, steps per second: 114, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000339, mae: 0.017659, mean_q: 0.029340
 67737/100000: episode: 9320, duration: 0.021s, episode steps: 3, steps per second: 143, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001153, mae: 0.021883, mean_q: 0.034173
 67744/100000: episode: 9321, duration: 0.043s, episode steps: 7, steps per second: 162, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001884, mae: 0.021940, mean_q: 0.028821
 67751/100000: episode: 9322, duration: 0.046s, episode steps: 7, steps per second: 154, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001164, mae: 0.019371, mean_q: 0.017768
 67754/100000: episode: 9323, duration: 0.028s, episode steps: 3, steps per second: 106, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001807, mae: 0.028315, mean_q: 0.042383
 67761/100000: episode: 9324, duration: 0.053s, episode steps: 7, steps per second: 133, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001782, mae: 0.023477, mean_q: 0.032998
 67768/100000: episode: 9325, duration: 0.051s, episode steps: 7, steps per second: 136, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001494, mae: 0.020800, mean_q: 0.025178
 67775/100000: episode: 9326, duration: 0.055s, episode steps: 7, steps per second: 127, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000876, mae: 0.022801, mean_q: 0.016127
 67782/100000: episode: 9327, duration: 0.043s, episode steps: 7, steps per second: 164, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001761, mae: 0.030175, mean_q: 0.041058
 67789/100000: episode: 9328, duration: 0.050s, episode steps: 7, steps per second: 140, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000814, mae: 0.018305, mean_q: 0.017799
 67796/100000: episode: 9329, duration: 0.040s, episode steps: 7, steps per second: 175, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.001083, mae: 0.023194, mean_q: 0.039469
 67803/100000: episode: 9330, duration: 0.045s, episode steps: 7, steps per second: 155, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.002532, mae: 0.025614, mean_q: 0.042629
 67810/100000: episode: 9331, duration: 0.044s, episode steps: 7, steps per second: 159, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001917, mae: 0.019466, mean_q: 0.024522
 67817/100000: episode: 9332, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.003454, mae: 0.026328, mean_q: 0.040167
 67824/100000: episode: 9333, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000681, mae: 0.017874, mean_q: 0.025685
 67831/100000: episode: 9334, duration: 0.038s, episode steps: 7, steps per second: 184, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001084, mae: 0.016638, mean_q: 0.019697
 67834/100000: episode: 9335, duration: 0.025s, episode steps: 3, steps per second: 120, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004403, mae: 0.027380, mean_q: 0.030407
 67841/100000: episode: 9336, duration: 0.045s, episode steps: 7, steps per second: 157, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003773, mae: 0.032440, mean_q: 0.047281
 67848/100000: episode: 9337, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002426, mae: 0.029649, mean_q: 0.032915
 67855/100000: episode: 9338, duration: 0.040s, episode steps: 7, steps per second: 176, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001458, mae: 0.025324, mean_q: 0.034381
 67862/100000: episode: 9339, duration: 0.047s, episode steps: 7, steps per second: 150, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.002674, mae: 0.027340, mean_q: 0.032490
 67865/100000: episode: 9340, duration: 0.019s, episode steps: 3, steps per second: 155, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001397, mae: 0.020619, mean_q: 0.020501
 67872/100000: episode: 9341, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001749, mae: 0.026281, mean_q: 0.045067
 67879/100000: episode: 9342, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001220, mae: 0.019645, mean_q: 0.025920
 67886/100000: episode: 9343, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001757, mae: 0.021406, mean_q: 0.027793
 67893/100000: episode: 9344, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001677, mae: 0.021366, mean_q: 0.019047
 67900/100000: episode: 9345, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.001030, mae: 0.021183, mean_q: 0.026562
 67903/100000: episode: 9346, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001950, mae: 0.021284, mean_q: 0.021693
 67910/100000: episode: 9347, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.002197, mae: 0.023517, mean_q: 0.032090
 67917/100000: episode: 9348, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000637, mae: 0.014290, mean_q: 0.018007
 67924/100000: episode: 9349, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000909, mae: 0.017725, mean_q: 0.028682
 67931/100000: episode: 9350, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000828, mae: 0.017153, mean_q: 0.020833
 67938/100000: episode: 9351, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001290, mae: 0.015974, mean_q: 0.018460
 67945/100000: episode: 9352, duration: 0.036s, episode steps: 7, steps per second: 192, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000404, mae: 0.012459, mean_q: 0.017506
 67952/100000: episode: 9353, duration: 0.038s, episode steps: 7, steps per second: 183, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000719, mae: 0.019141, mean_q: 0.030895
 67959/100000: episode: 9354, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000655, mae: 0.018557, mean_q: 0.021257
 67966/100000: episode: 9355, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001054, mae: 0.021602, mean_q: 0.031004
 67969/100000: episode: 9356, duration: 0.020s, episode steps: 3, steps per second: 150, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001011, mae: 0.018873, mean_q: 0.018843
 67976/100000: episode: 9357, duration: 0.037s, episode steps: 7, steps per second: 187, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001003, mae: 0.025527, mean_q: 0.035800
 67983/100000: episode: 9358, duration: 0.039s, episode steps: 7, steps per second: 181, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000994, mae: 0.022776, mean_q: 0.031727
 67990/100000: episode: 9359, duration: 0.038s, episode steps: 7, steps per second: 183, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001463, mae: 0.020388, mean_q: 0.024951
 67997/100000: episode: 9360, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000767, mae: 0.018930, mean_q: 0.026346
 68004/100000: episode: 9361, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001701, mae: 0.023706, mean_q: 0.027896
 68011/100000: episode: 9362, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.002205, mae: 0.022660, mean_q: 0.032874
 68018/100000: episode: 9363, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000790, mae: 0.015434, mean_q: 0.013177
 68021/100000: episode: 9364, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000264, mae: 0.015032, mean_q: 0.022635
 68028/100000: episode: 9365, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000564, mae: 0.015728, mean_q: 0.018633
 68035/100000: episode: 9366, duration: 0.035s, episode steps: 7, steps per second: 197, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001536, mae: 0.017568, mean_q: 0.024090
 68042/100000: episode: 9367, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000956, mae: 0.018509, mean_q: 0.031170
 68049/100000: episode: 9368, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000836, mae: 0.014455, mean_q: 0.024281
 68056/100000: episode: 9369, duration: 0.038s, episode steps: 7, steps per second: 185, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.002448, mae: 0.025181, mean_q: 0.032909
 68063/100000: episode: 9370, duration: 0.038s, episode steps: 7, steps per second: 186, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000842, mae: 0.021761, mean_q: 0.011899
 68070/100000: episode: 9371, duration: 0.038s, episode steps: 7, steps per second: 186, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000638, mae: 0.018294, mean_q: 0.020399
 68073/100000: episode: 9372, duration: 0.019s, episode steps: 3, steps per second: 156, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004023, mae: 0.028686, mean_q: 0.037908
 68080/100000: episode: 9373, duration: 0.037s, episode steps: 7, steps per second: 192, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000912, mae: 0.023012, mean_q: 0.018757
 68087/100000: episode: 9374, duration: 0.045s, episode steps: 7, steps per second: 156, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000917, mae: 0.021472, mean_q: 0.030007
 68094/100000: episode: 9375, duration: 0.047s, episode steps: 7, steps per second: 150, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001597, mae: 0.019286, mean_q: 0.019735
 68101/100000: episode: 9376, duration: 0.043s, episode steps: 7, steps per second: 163, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000463, mae: 0.017553, mean_q: 0.017871
 68108/100000: episode: 9377, duration: 0.040s, episode steps: 7, steps per second: 173, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000552, mae: 0.014540, mean_q: 0.018581
 68115/100000: episode: 9378, duration: 0.037s, episode steps: 7, steps per second: 189, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000686, mae: 0.016080, mean_q: 0.021165
[Info] 2-TH LEVEL FOUND: 0.20387783646583557, Considering 12/100 traces
 68122/100000: episode: 9379, duration: 0.913s, episode steps: 7, steps per second: 8, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000355, mae: 0.012730, mean_q: 0.015568
 68126/100000: episode: 9380, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001206, mae: 0.020272, mean_q: 0.032578
 68130/100000: episode: 9381, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000470, mae: 0.012863, mean_q: 0.016113
 68134/100000: episode: 9382, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000979, mae: 0.015044, mean_q: 0.015374
 68138/100000: episode: 9383, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000374, mae: 0.015320, mean_q: 0.024856
 68142/100000: episode: 9384, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000366, mae: 0.013171, mean_q: 0.019600
 68146/100000: episode: 9385, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001136, mae: 0.020970, mean_q: 0.024553
 68150/100000: episode: 9386, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001085, mae: 0.019819, mean_q: 0.029253
 68154/100000: episode: 9387, duration: 0.045s, episode steps: 4, steps per second: 88, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000582, mae: 0.016441, mean_q: 0.020648
 68158/100000: episode: 9388, duration: 0.041s, episode steps: 4, steps per second: 98, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002127, mae: 0.018141, mean_q: 0.018022
 68162/100000: episode: 9389, duration: 0.029s, episode steps: 4, steps per second: 136, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000834, mae: 0.022992, mean_q: 0.039135
 68166/100000: episode: 9390, duration: 0.043s, episode steps: 4, steps per second: 94, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000588, mae: 0.015344, mean_q: 0.017300
 68170/100000: episode: 9391, duration: 0.032s, episode steps: 4, steps per second: 124, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002137, mae: 0.024686, mean_q: 0.025715
 68174/100000: episode: 9392, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000663, mae: 0.021657, mean_q: 0.025138
 68178/100000: episode: 9393, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001276, mae: 0.027606, mean_q: 0.020349
 68182/100000: episode: 9394, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002564, mae: 0.027334, mean_q: 0.039460
 68186/100000: episode: 9395, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001210, mae: 0.021097, mean_q: 0.026067
[Info] FALSIFICATION!
 68189/100000: episode: 9396, duration: 0.352s, episode steps: 3, steps per second: 9, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000508, mae: 0.015546, mean_q: 0.011181
 68193/100000: episode: 9397, duration: 0.056s, episode steps: 4, steps per second: 71, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000452, mae: 0.018724, mean_q: 0.024453
 68197/100000: episode: 9398, duration: 0.055s, episode steps: 4, steps per second: 73, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000835, mae: 0.018697, mean_q: 0.023994
 68201/100000: episode: 9399, duration: 0.046s, episode steps: 4, steps per second: 86, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.004158, mae: 0.027095, mean_q: 0.029382
 68205/100000: episode: 9400, duration: 0.058s, episode steps: 4, steps per second: 69, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000975, mae: 0.027302, mean_q: 0.037941
 68209/100000: episode: 9401, duration: 0.047s, episode steps: 4, steps per second: 84, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001022, mae: 0.024483, mean_q: 0.013936
 68213/100000: episode: 9402, duration: 0.057s, episode steps: 4, steps per second: 71, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.001012, mae: 0.029416, mean_q: 0.042181
 68217/100000: episode: 9403, duration: 0.060s, episode steps: 4, steps per second: 67, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002414, mae: 0.021762, mean_q: 0.021955
 68221/100000: episode: 9404, duration: 0.046s, episode steps: 4, steps per second: 87, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002059, mae: 0.023289, mean_q: 0.021405
 68225/100000: episode: 9405, duration: 0.049s, episode steps: 4, steps per second: 81, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003792, mae: 0.033358, mean_q: 0.050587
 68229/100000: episode: 9406, duration: 0.064s, episode steps: 4, steps per second: 62, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002055, mae: 0.025066, mean_q: 0.015181
 68233/100000: episode: 9407, duration: 0.050s, episode steps: 4, steps per second: 80, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.001116, mae: 0.022611, mean_q: 0.029921
 68237/100000: episode: 9408, duration: 0.042s, episode steps: 4, steps per second: 95, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002832, mae: 0.025701, mean_q: 0.029330
[Info] FALSIFICATION!
 68240/100000: episode: 9409, duration: 0.384s, episode steps: 3, steps per second: 8, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002844, mae: 0.033339, mean_q: 0.055089
 68244/100000: episode: 9410, duration: 0.038s, episode steps: 4, steps per second: 106, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001173, mae: 0.025746, mean_q: 0.041239
 68248/100000: episode: 9411, duration: 0.033s, episode steps: 4, steps per second: 122, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002423, mae: 0.028341, mean_q: 0.032309
 68252/100000: episode: 9412, duration: 0.048s, episode steps: 4, steps per second: 83, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001916, mae: 0.030250, mean_q: 0.041483
 68256/100000: episode: 9413, duration: 0.039s, episode steps: 4, steps per second: 102, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001016, mae: 0.018835, mean_q: 0.013707
 68260/100000: episode: 9414, duration: 0.042s, episode steps: 4, steps per second: 96, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000492, mae: 0.017904, mean_q: 0.030144
 68264/100000: episode: 9415, duration: 0.052s, episode steps: 4, steps per second: 77, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000882, mae: 0.023127, mean_q: 0.028755
 68268/100000: episode: 9416, duration: 0.029s, episode steps: 4, steps per second: 137, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000849, mae: 0.022101, mean_q: 0.028452
 68272/100000: episode: 9417, duration: 0.025s, episode steps: 4, steps per second: 161, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000312, mae: 0.014049, mean_q: 0.024724
 68276/100000: episode: 9418, duration: 0.026s, episode steps: 4, steps per second: 153, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000807, mae: 0.017524, mean_q: 0.023825
[Info] FALSIFICATION!
 68279/100000: episode: 9419, duration: 0.319s, episode steps: 3, steps per second: 9, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002982, mae: 0.021999, mean_q: 0.025716
 68283/100000: episode: 9420, duration: 0.046s, episode steps: 4, steps per second: 88, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001454, mae: 0.023083, mean_q: 0.036628
[Info] FALSIFICATION!
 68286/100000: episode: 9421, duration: 0.377s, episode steps: 3, steps per second: 8, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001884, mae: 0.026891, mean_q: 0.032635
 68290/100000: episode: 9422, duration: 0.045s, episode steps: 4, steps per second: 88, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000720, mae: 0.018169, mean_q: 0.023977
[Info] FALSIFICATION!
 68293/100000: episode: 9423, duration: 0.332s, episode steps: 3, steps per second: 9, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002668, mae: 0.031671, mean_q: 0.053243
 68297/100000: episode: 9424, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.002952, mae: 0.026971, mean_q: 0.036312
 68301/100000: episode: 9425, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000927, mae: 0.023616, mean_q: 0.038035
[Info] FALSIFICATION!
 68304/100000: episode: 9426, duration: 0.259s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002024, mae: 0.029925, mean_q: 0.028390
 68308/100000: episode: 9427, duration: 0.064s, episode steps: 4, steps per second: 62, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001581, mae: 0.027176, mean_q: 0.043020
 68312/100000: episode: 9428, duration: 0.054s, episode steps: 4, steps per second: 75, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002021, mae: 0.026399, mean_q: 0.036910
 68316/100000: episode: 9429, duration: 0.041s, episode steps: 4, steps per second: 99, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001097, mae: 0.019532, mean_q: 0.022919
 68320/100000: episode: 9430, duration: 0.041s, episode steps: 4, steps per second: 98, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000879, mae: 0.021302, mean_q: 0.037027
 68324/100000: episode: 9431, duration: 0.048s, episode steps: 4, steps per second: 84, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001025, mae: 0.022314, mean_q: 0.035048
 68328/100000: episode: 9432, duration: 0.039s, episode steps: 4, steps per second: 102, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002447, mae: 0.023521, mean_q: 0.028303
 68332/100000: episode: 9433, duration: 0.042s, episode steps: 4, steps per second: 95, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000993, mae: 0.021283, mean_q: 0.034917
 68336/100000: episode: 9434, duration: 0.038s, episode steps: 4, steps per second: 105, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001289, mae: 0.020752, mean_q: 0.029625
 68340/100000: episode: 9435, duration: 0.034s, episode steps: 4, steps per second: 117, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001457, mae: 0.024247, mean_q: 0.043075
 68344/100000: episode: 9436, duration: 0.029s, episode steps: 4, steps per second: 138, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001569, mae: 0.024282, mean_q: 0.036205
 68348/100000: episode: 9437, duration: 0.034s, episode steps: 4, steps per second: 118, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001168, mae: 0.026060, mean_q: 0.045654
 68352/100000: episode: 9438, duration: 0.031s, episode steps: 4, steps per second: 130, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001174, mae: 0.021617, mean_q: 0.021601
 68356/100000: episode: 9439, duration: 0.030s, episode steps: 4, steps per second: 134, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003150, mae: 0.027681, mean_q: 0.020219
 68360/100000: episode: 9440, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.004545, mae: 0.042891, mean_q: 0.057448
 68364/100000: episode: 9441, duration: 0.026s, episode steps: 4, steps per second: 155, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002221, mae: 0.035892, mean_q: 0.020902
 68368/100000: episode: 9442, duration: 0.025s, episode steps: 4, steps per second: 160, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002759, mae: 0.032746, mean_q: 0.036720
 68372/100000: episode: 9443, duration: 0.028s, episode steps: 4, steps per second: 143, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001418, mae: 0.027879, mean_q: 0.039854
[Info] FALSIFICATION!
 68375/100000: episode: 9444, duration: 0.297s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.005411, mae: 0.050448, mean_q: 0.036679
 68379/100000: episode: 9445, duration: 0.026s, episode steps: 4, steps per second: 154, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001001, mae: 0.024026, mean_q: 0.032914
 68383/100000: episode: 9446, duration: 0.024s, episode steps: 4, steps per second: 167, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001505, mae: 0.025725, mean_q: 0.041439
 68387/100000: episode: 9447, duration: 0.037s, episode steps: 4, steps per second: 108, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003185, mae: 0.031005, mean_q: 0.041672
 68391/100000: episode: 9448, duration: 0.033s, episode steps: 4, steps per second: 121, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001901, mae: 0.028526, mean_q: 0.047235
 68395/100000: episode: 9449, duration: 0.037s, episode steps: 4, steps per second: 109, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001012, mae: 0.021849, mean_q: 0.021786
 68399/100000: episode: 9450, duration: 0.037s, episode steps: 4, steps per second: 109, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001313, mae: 0.024010, mean_q: 0.038760
 68403/100000: episode: 9451, duration: 0.038s, episode steps: 4, steps per second: 104, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002543, mae: 0.025301, mean_q: 0.040415
 68407/100000: episode: 9452, duration: 0.027s, episode steps: 4, steps per second: 146, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000968, mae: 0.018468, mean_q: 0.028935
 68411/100000: episode: 9453, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000970, mae: 0.023745, mean_q: 0.028945
 68415/100000: episode: 9454, duration: 0.031s, episode steps: 4, steps per second: 130, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002757, mae: 0.030463, mean_q: 0.045732
 68419/100000: episode: 9455, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000847, mae: 0.025748, mean_q: 0.042514
 68423/100000: episode: 9456, duration: 0.026s, episode steps: 4, steps per second: 155, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000776, mae: 0.027578, mean_q: 0.009529
 68427/100000: episode: 9457, duration: 0.026s, episode steps: 4, steps per second: 152, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001030, mae: 0.029706, mean_q: 0.042930
 68431/100000: episode: 9458, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.002033, mae: 0.029086, mean_q: 0.043873
[Info] FALSIFICATION!
 68434/100000: episode: 9459, duration: 0.238s, episode steps: 3, steps per second: 13, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000748, mae: 0.018830, mean_q: 0.024631
 68438/100000: episode: 9460, duration: 0.032s, episode steps: 4, steps per second: 125, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001768, mae: 0.030111, mean_q: 0.048363
 68442/100000: episode: 9461, duration: 0.029s, episode steps: 4, steps per second: 136, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000553, mae: 0.017572, mean_q: 0.025987
 68446/100000: episode: 9462, duration: 0.027s, episode steps: 4, steps per second: 149, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003117, mae: 0.031749, mean_q: 0.044282
 68450/100000: episode: 9463, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001459, mae: 0.026076, mean_q: 0.047445
 68454/100000: episode: 9464, duration: 0.028s, episode steps: 4, steps per second: 141, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001737, mae: 0.030986, mean_q: 0.019591
 68458/100000: episode: 9465, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.001901, mae: 0.030733, mean_q: 0.037491
 68462/100000: episode: 9466, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002429, mae: 0.035996, mean_q: 0.061533
[Info] Complete ISplit Iteration
[Info] Levels: [0.0018732548, 0.20387784, 0.89929295]
[Info] Cond. Prob: [0.1, 0.12, 0.08]
[Info] Error Prob: 0.00096

 68466/100000: episode: 9467, duration: 0.766s, episode steps: 4, steps per second: 5, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001313, mae: 0.031307, mean_q: 0.016934
 68476/100000: episode: 9468, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.003575, mae: 0.039139, mean_q: 0.046730
 68486/100000: episode: 9469, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.004018, mae: 0.038656, mean_q: 0.049822
 68496/100000: episode: 9470, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002411, mae: 0.030362, mean_q: 0.036202
 68506/100000: episode: 9471, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.003664, mae: 0.037344, mean_q: 0.049848
 68516/100000: episode: 9472, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.003276, mae: 0.038594, mean_q: 0.051406
 68526/100000: episode: 9473, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003965, mae: 0.039481, mean_q: 0.061490
 68536/100000: episode: 9474, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002394, mae: 0.027742, mean_q: 0.038674
 68546/100000: episode: 9475, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.003146, mae: 0.035818, mean_q: 0.041242
 68556/100000: episode: 9476, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001276, mae: 0.027689, mean_q: 0.028600
 68566/100000: episode: 9477, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001127, mae: 0.021832, mean_q: 0.024946
 68576/100000: episode: 9478, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001158, mae: 0.025369, mean_q: 0.029169
 68586/100000: episode: 9479, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002107, mae: 0.031182, mean_q: 0.044029
 68596/100000: episode: 9480, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001296, mae: 0.025717, mean_q: 0.030979
 68606/100000: episode: 9481, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001250, mae: 0.024689, mean_q: 0.031000
 68616/100000: episode: 9482, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002324, mae: 0.030536, mean_q: 0.045058
 68626/100000: episode: 9483, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001255, mae: 0.023731, mean_q: 0.030357
 68636/100000: episode: 9484, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002245, mae: 0.028241, mean_q: 0.040948
 68646/100000: episode: 9485, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001361, mae: 0.024392, mean_q: 0.037719
 68656/100000: episode: 9486, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001557, mae: 0.025848, mean_q: 0.036316
 68666/100000: episode: 9487, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002473, mae: 0.032707, mean_q: 0.049888
 68676/100000: episode: 9488, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.002107, mae: 0.030465, mean_q: 0.049699
 68686/100000: episode: 9489, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001846, mae: 0.024540, mean_q: 0.039426
 68696/100000: episode: 9490, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001220, mae: 0.022164, mean_q: 0.031919
 68706/100000: episode: 9491, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001819, mae: 0.026735, mean_q: 0.042641
 68716/100000: episode: 9492, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001618, mae: 0.025803, mean_q: 0.039445
 68726/100000: episode: 9493, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002008, mae: 0.024906, mean_q: 0.039160
 68736/100000: episode: 9494, duration: 0.104s, episode steps: 10, steps per second: 96, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.003121, mae: 0.031602, mean_q: 0.055351
 68746/100000: episode: 9495, duration: 0.117s, episode steps: 10, steps per second: 85, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001356, mae: 0.022733, mean_q: 0.030357
 68756/100000: episode: 9496, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002664, mae: 0.029787, mean_q: 0.042121
 68766/100000: episode: 9497, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002240, mae: 0.028870, mean_q: 0.043342
 68776/100000: episode: 9498, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.002841, mae: 0.031714, mean_q: 0.046782
 68786/100000: episode: 9499, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002166, mae: 0.029019, mean_q: 0.039563
 68796/100000: episode: 9500, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001862, mae: 0.028086, mean_q: 0.045276
 68806/100000: episode: 9501, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.003107, mae: 0.033025, mean_q: 0.051944
 68816/100000: episode: 9502, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002623, mae: 0.031796, mean_q: 0.043479
 68826/100000: episode: 9503, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002633, mae: 0.031578, mean_q: 0.046912
 68836/100000: episode: 9504, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001566, mae: 0.028017, mean_q: 0.044713
 68846/100000: episode: 9505, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.004627, mae: 0.044496, mean_q: 0.064590
 68856/100000: episode: 9506, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002241, mae: 0.032002, mean_q: 0.040044
 68866/100000: episode: 9507, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002035, mae: 0.026600, mean_q: 0.035285
 68876/100000: episode: 9508, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001469, mae: 0.022542, mean_q: 0.029942
 68886/100000: episode: 9509, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002262, mae: 0.032592, mean_q: 0.043364
 68896/100000: episode: 9510, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002461, mae: 0.030529, mean_q: 0.042815
 68906/100000: episode: 9511, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002588, mae: 0.029468, mean_q: 0.039256
 68916/100000: episode: 9512, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002046, mae: 0.030239, mean_q: 0.043003
 68926/100000: episode: 9513, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002446, mae: 0.031716, mean_q: 0.049802
 68936/100000: episode: 9514, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001690, mae: 0.027768, mean_q: 0.037363
 68946/100000: episode: 9515, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000928, mae: 0.020022, mean_q: 0.030851
 68956/100000: episode: 9516, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002446, mae: 0.029681, mean_q: 0.039446
 68966/100000: episode: 9517, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002214, mae: 0.027203, mean_q: 0.040398
 68976/100000: episode: 9518, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002710, mae: 0.035576, mean_q: 0.051515
 68986/100000: episode: 9519, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001494, mae: 0.022203, mean_q: 0.028318
 68996/100000: episode: 9520, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000902, mae: 0.020498, mean_q: 0.030391
 69006/100000: episode: 9521, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001381, mae: 0.025550, mean_q: 0.041936
 69016/100000: episode: 9522, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001871, mae: 0.026514, mean_q: 0.042738
 69026/100000: episode: 9523, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001450, mae: 0.025500, mean_q: 0.038247
 69036/100000: episode: 9524, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002038, mae: 0.023716, mean_q: 0.035024
 69046/100000: episode: 9525, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002393, mae: 0.030020, mean_q: 0.041451
 69056/100000: episode: 9526, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001319, mae: 0.024555, mean_q: 0.033161
 69066/100000: episode: 9527, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.001949, mae: 0.024522, mean_q: 0.038394
 69076/100000: episode: 9528, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002130, mae: 0.028344, mean_q: 0.033906
 69086/100000: episode: 9529, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002050, mae: 0.029439, mean_q: 0.046347
 69096/100000: episode: 9530, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001449, mae: 0.029173, mean_q: 0.033130
 69106/100000: episode: 9531, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002290, mae: 0.035023, mean_q: 0.044681
 69116/100000: episode: 9532, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002595, mae: 0.035935, mean_q: 0.050169
 69126/100000: episode: 9533, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.003234, mae: 0.037019, mean_q: 0.038154
 69136/100000: episode: 9534, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002723, mae: 0.034200, mean_q: 0.042276
 69146/100000: episode: 9535, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002105, mae: 0.025874, mean_q: 0.034235
 69156/100000: episode: 9536, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002816, mae: 0.037932, mean_q: 0.043293
 69166/100000: episode: 9537, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.003509, mae: 0.035909, mean_q: 0.055305
 69176/100000: episode: 9538, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.002790, mae: 0.034505, mean_q: 0.042223
 69186/100000: episode: 9539, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001939, mae: 0.029899, mean_q: 0.034767
 69196/100000: episode: 9540, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002220, mae: 0.036506, mean_q: 0.040260
 69206/100000: episode: 9541, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.004201, mae: 0.046457, mean_q: 0.052902
 69216/100000: episode: 9542, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001326, mae: 0.028718, mean_q: 0.038655
 69226/100000: episode: 9543, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002386, mae: 0.027850, mean_q: 0.038380
 69236/100000: episode: 9544, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001399, mae: 0.024115, mean_q: 0.037727
 69246/100000: episode: 9545, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002543, mae: 0.030503, mean_q: 0.036946
 69256/100000: episode: 9546, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002914, mae: 0.031292, mean_q: 0.041548
 69266/100000: episode: 9547, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002598, mae: 0.030946, mean_q: 0.046885
 69276/100000: episode: 9548, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002634, mae: 0.029172, mean_q: 0.039102
 69286/100000: episode: 9549, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002260, mae: 0.031217, mean_q: 0.037248
 69296/100000: episode: 9550, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001497, mae: 0.028671, mean_q: 0.041054
 69306/100000: episode: 9551, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001208, mae: 0.027227, mean_q: 0.031960
 69316/100000: episode: 9552, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002651, mae: 0.030952, mean_q: 0.039615
 69326/100000: episode: 9553, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001305, mae: 0.025222, mean_q: 0.037809
 69336/100000: episode: 9554, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001087, mae: 0.021099, mean_q: 0.028830
 69346/100000: episode: 9555, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.003315, mae: 0.031410, mean_q: 0.048015
 69356/100000: episode: 9556, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002062, mae: 0.029305, mean_q: 0.033544
 69366/100000: episode: 9557, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002460, mae: 0.030959, mean_q: 0.042026
 69376/100000: episode: 9558, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002072, mae: 0.030388, mean_q: 0.035393
 69386/100000: episode: 9559, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001566, mae: 0.026490, mean_q: 0.038828
 69396/100000: episode: 9560, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002316, mae: 0.029068, mean_q: 0.040276
 69406/100000: episode: 9561, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002060, mae: 0.028322, mean_q: 0.040357
 69416/100000: episode: 9562, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002379, mae: 0.031776, mean_q: 0.049229
 69426/100000: episode: 9563, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001846, mae: 0.030456, mean_q: 0.041732
 69436/100000: episode: 9564, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.003708, mae: 0.039940, mean_q: 0.063498
 69446/100000: episode: 9565, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001056, mae: 0.024787, mean_q: 0.038006
 69456/100000: episode: 9566, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001481, mae: 0.022473, mean_q: 0.027695
[Info] 1-TH LEVEL FOUND: 0.05128726363182068, Considering 12/100 traces
 69466/100000: episode: 9567, duration: 0.699s, episode steps: 10, steps per second: 14, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.003322, mae: 0.032462, mean_q: 0.045530
 69468/100000: episode: 9568, duration: 0.019s, episode steps: 2, steps per second: 107, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000927, mae: 0.020458, mean_q: 0.044543
 69472/100000: episode: 9569, duration: 0.027s, episode steps: 4, steps per second: 147, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001531, mae: 0.028453, mean_q: 0.027243
 69474/100000: episode: 9570, duration: 0.017s, episode steps: 2, steps per second: 116, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001166, mae: 0.020791, mean_q: 0.028624
 69478/100000: episode: 9571, duration: 0.026s, episode steps: 4, steps per second: 154, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002201, mae: 0.034214, mean_q: 0.056982
 69480/100000: episode: 9572, duration: 0.017s, episode steps: 2, steps per second: 121, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001406, mae: 0.024218, mean_q: 0.041035
 69484/100000: episode: 9573, duration: 0.029s, episode steps: 4, steps per second: 136, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002313, mae: 0.028988, mean_q: 0.036859
 69486/100000: episode: 9574, duration: 0.016s, episode steps: 2, steps per second: 124, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001709, mae: 0.027513, mean_q: 0.055231
 69488/100000: episode: 9575, duration: 0.020s, episode steps: 2, steps per second: 98, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000724, mae: 0.018239, mean_q: 0.020644
 69490/100000: episode: 9576, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002348, mae: 0.037496, mean_q: 0.049197
 69494/100000: episode: 9577, duration: 0.033s, episode steps: 4, steps per second: 122, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001436, mae: 0.027848, mean_q: 0.035846
 69500/100000: episode: 9578, duration: 0.041s, episode steps: 6, steps per second: 148, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001813, mae: 0.027872, mean_q: 0.034524
 69504/100000: episode: 9579, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.004019, mae: 0.041752, mean_q: 0.056386
 69506/100000: episode: 9580, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001499, mae: 0.027453, mean_q: 0.050439
 69510/100000: episode: 9581, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001814, mae: 0.033621, mean_q: 0.030718
 69514/100000: episode: 9582, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002050, mae: 0.037936, mean_q: 0.055563
 69516/100000: episode: 9583, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000962, mae: 0.017954, mean_q: 0.030499
 69520/100000: episode: 9584, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002747, mae: 0.037862, mean_q: 0.046089
 69526/100000: episode: 9585, duration: 0.048s, episode steps: 6, steps per second: 124, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002138, mae: 0.033411, mean_q: 0.054509
 69528/100000: episode: 9586, duration: 0.023s, episode steps: 2, steps per second: 88, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001746, mae: 0.034646, mean_q: 0.025008
 69532/100000: episode: 9587, duration: 0.026s, episode steps: 4, steps per second: 155, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.003546, mae: 0.036435, mean_q: 0.050588
 69538/100000: episode: 9588, duration: 0.038s, episode steps: 6, steps per second: 157, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001891, mae: 0.035805, mean_q: 0.042644
 69540/100000: episode: 9589, duration: 0.015s, episode steps: 2, steps per second: 132, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002202, mae: 0.033564, mean_q: 0.042642
 69542/100000: episode: 9590, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002738, mae: 0.039791, mean_q: 0.057961
 69544/100000: episode: 9591, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004437, mae: 0.043811, mean_q: 0.069535
 69548/100000: episode: 9592, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001475, mae: 0.022970, mean_q: 0.025430
 69550/100000: episode: 9593, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003041, mae: 0.035500, mean_q: 0.060554
 69552/100000: episode: 9594, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002556, mae: 0.028498, mean_q: 0.044308
 69554/100000: episode: 9595, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002116, mae: 0.030551, mean_q: 0.045851
 69558/100000: episode: 9596, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.004478, mae: 0.043004, mean_q: 0.066216
 69562/100000: episode: 9597, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001375, mae: 0.027093, mean_q: 0.047911
 69564/100000: episode: 9598, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002259, mae: 0.029685, mean_q: 0.051148
 69566/100000: episode: 9599, duration: 0.018s, episode steps: 2, steps per second: 112, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005145, mae: 0.042261, mean_q: 0.067267
 69568/100000: episode: 9600, duration: 0.028s, episode steps: 2, steps per second: 73, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005401, mae: 0.047226, mean_q: 0.068772
 69570/100000: episode: 9601, duration: 0.029s, episode steps: 2, steps per second: 69, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000856, mae: 0.023681, mean_q: 0.014016
 69572/100000: episode: 9602, duration: 0.029s, episode steps: 2, steps per second: 68, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001913, mae: 0.027800, mean_q: 0.036095
 69576/100000: episode: 9603, duration: 0.037s, episode steps: 4, steps per second: 107, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002321, mae: 0.031676, mean_q: 0.047204
 69582/100000: episode: 9604, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001394, mae: 0.021229, mean_q: 0.027324
 69584/100000: episode: 9605, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001778, mae: 0.027264, mean_q: 0.040939
 69588/100000: episode: 9606, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000619, mae: 0.017455, mean_q: 0.025767
 69592/100000: episode: 9607, duration: 0.028s, episode steps: 4, steps per second: 143, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002717, mae: 0.030146, mean_q: 0.042160
 69596/100000: episode: 9608, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002781, mae: 0.028868, mean_q: 0.045143
 69598/100000: episode: 9609, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000739, mae: 0.022299, mean_q: 0.033344
 69600/100000: episode: 9610, duration: 0.018s, episode steps: 2, steps per second: 114, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001725, mae: 0.032381, mean_q: 0.043487
 69604/100000: episode: 9611, duration: 0.049s, episode steps: 4, steps per second: 82, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001395, mae: 0.024616, mean_q: 0.030066
 69608/100000: episode: 9612, duration: 0.036s, episode steps: 4, steps per second: 112, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003979, mae: 0.039653, mean_q: 0.060322
 69612/100000: episode: 9613, duration: 0.051s, episode steps: 4, steps per second: 78, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003403, mae: 0.032061, mean_q: 0.057189
 69618/100000: episode: 9614, duration: 0.079s, episode steps: 6, steps per second: 76, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001307, mae: 0.026749, mean_q: 0.042123
 69622/100000: episode: 9615, duration: 0.036s, episode steps: 4, steps per second: 110, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001712, mae: 0.023914, mean_q: 0.044894
 69624/100000: episode: 9616, duration: 0.018s, episode steps: 2, steps per second: 114, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001234, mae: 0.018371, mean_q: 0.030407
 69628/100000: episode: 9617, duration: 0.047s, episode steps: 4, steps per second: 85, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001970, mae: 0.025807, mean_q: 0.034092
 69632/100000: episode: 9618, duration: 0.042s, episode steps: 4, steps per second: 96, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002222, mae: 0.028293, mean_q: 0.049794
 69634/100000: episode: 9619, duration: 0.024s, episode steps: 2, steps per second: 84, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001459, mae: 0.024764, mean_q: 0.046357
 69640/100000: episode: 9620, duration: 0.059s, episode steps: 6, steps per second: 102, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.002734, mae: 0.027804, mean_q: 0.033711
 69642/100000: episode: 9621, duration: 0.024s, episode steps: 2, steps per second: 85, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002525, mae: 0.033369, mean_q: 0.049994
 69646/100000: episode: 9622, duration: 0.040s, episode steps: 4, steps per second: 101, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002109, mae: 0.029458, mean_q: 0.050563
 69650/100000: episode: 9623, duration: 0.037s, episode steps: 4, steps per second: 108, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001707, mae: 0.027291, mean_q: 0.026591
 69652/100000: episode: 9624, duration: 0.022s, episode steps: 2, steps per second: 90, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002655, mae: 0.036484, mean_q: 0.059806
 69654/100000: episode: 9625, duration: 0.022s, episode steps: 2, steps per second: 92, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002804, mae: 0.032991, mean_q: 0.052186
 69658/100000: episode: 9626, duration: 0.033s, episode steps: 4, steps per second: 122, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001798, mae: 0.028917, mean_q: 0.043223
 69664/100000: episode: 9627, duration: 0.058s, episode steps: 6, steps per second: 104, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001697, mae: 0.028089, mean_q: 0.042011
 69668/100000: episode: 9628, duration: 0.050s, episode steps: 4, steps per second: 80, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001050, mae: 0.021787, mean_q: 0.035981
 69670/100000: episode: 9629, duration: 0.025s, episode steps: 2, steps per second: 79, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004678, mae: 0.034987, mean_q: 0.047149
 69674/100000: episode: 9630, duration: 0.042s, episode steps: 4, steps per second: 95, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001647, mae: 0.030062, mean_q: 0.045588
 69678/100000: episode: 9631, duration: 0.040s, episode steps: 4, steps per second: 101, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001460, mae: 0.026279, mean_q: 0.026253
 69682/100000: episode: 9632, duration: 0.039s, episode steps: 4, steps per second: 102, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002188, mae: 0.036693, mean_q: 0.062473
 69686/100000: episode: 9633, duration: 0.049s, episode steps: 4, steps per second: 82, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001925, mae: 0.025268, mean_q: 0.032747
 69688/100000: episode: 9634, duration: 0.021s, episode steps: 2, steps per second: 94, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002211, mae: 0.028657, mean_q: 0.038801
 69690/100000: episode: 9635, duration: 0.021s, episode steps: 2, steps per second: 95, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002296, mae: 0.035500, mean_q: 0.053473
 69692/100000: episode: 9636, duration: 0.021s, episode steps: 2, steps per second: 95, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001225, mae: 0.022976, mean_q: 0.037673
 69696/100000: episode: 9637, duration: 0.036s, episode steps: 4, steps per second: 110, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.006603, mae: 0.043716, mean_q: 0.055107
 69700/100000: episode: 9638, duration: 0.035s, episode steps: 4, steps per second: 113, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001325, mae: 0.028722, mean_q: 0.049499
 69704/100000: episode: 9639, duration: 0.032s, episode steps: 4, steps per second: 126, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.003174, mae: 0.045985, mean_q: 0.043276
 69708/100000: episode: 9640, duration: 0.029s, episode steps: 4, steps per second: 138, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001081, mae: 0.027038, mean_q: 0.036074
 69710/100000: episode: 9641, duration: 0.018s, episode steps: 2, steps per second: 111, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001707, mae: 0.035019, mean_q: 0.063473
 69714/100000: episode: 9642, duration: 0.026s, episode steps: 4, steps per second: 152, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003822, mae: 0.038686, mean_q: 0.047483
 69718/100000: episode: 9643, duration: 0.032s, episode steps: 4, steps per second: 124, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002771, mae: 0.030585, mean_q: 0.039913
 69720/100000: episode: 9644, duration: 0.019s, episode steps: 2, steps per second: 103, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002021, mae: 0.026805, mean_q: 0.044662
 69722/100000: episode: 9645, duration: 0.018s, episode steps: 2, steps per second: 113, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000970, mae: 0.024176, mean_q: 0.030831
 69724/100000: episode: 9646, duration: 0.019s, episode steps: 2, steps per second: 103, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002792, mae: 0.031147, mean_q: 0.039676
 69728/100000: episode: 9647, duration: 0.035s, episode steps: 4, steps per second: 114, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001277, mae: 0.023067, mean_q: 0.036703
 69730/100000: episode: 9648, duration: 0.022s, episode steps: 2, steps per second: 90, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001589, mae: 0.025287, mean_q: 0.056677
 69734/100000: episode: 9649, duration: 0.030s, episode steps: 4, steps per second: 132, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001155, mae: 0.021826, mean_q: 0.029249
 69738/100000: episode: 9650, duration: 0.034s, episode steps: 4, steps per second: 118, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001886, mae: 0.028362, mean_q: 0.039768
 69742/100000: episode: 9651, duration: 0.035s, episode steps: 4, steps per second: 114, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002382, mae: 0.026117, mean_q: 0.036792
 69744/100000: episode: 9652, duration: 0.014s, episode steps: 2, steps per second: 139, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001827, mae: 0.024818, mean_q: 0.032920
 69748/100000: episode: 9653, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000864, mae: 0.023724, mean_q: 0.015493
 69752/100000: episode: 9654, duration: 0.027s, episode steps: 4, steps per second: 149, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.005558, mae: 0.049762, mean_q: 0.075537
[Info] 2-TH LEVEL FOUND: 0.11886388063430786, Considering 31/100 traces
 69758/100000: episode: 9655, duration: 0.947s, episode steps: 6, steps per second: 6, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.002051, mae: 0.033823, mean_q: 0.032575
 69762/100000: episode: 9656, duration: 0.033s, episode steps: 4, steps per second: 121, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002341, mae: 0.032405, mean_q: 0.051658
 69765/100000: episode: 9657, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001824, mae: 0.027077, mean_q: 0.033142
 69768/100000: episode: 9658, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003449, mae: 0.031511, mean_q: 0.032447
 69771/100000: episode: 9659, duration: 0.021s, episode steps: 3, steps per second: 140, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003123, mae: 0.034199, mean_q: 0.051054
 69774/100000: episode: 9660, duration: 0.021s, episode steps: 3, steps per second: 141, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002487, mae: 0.034960, mean_q: 0.058006
 69777/100000: episode: 9661, duration: 0.025s, episode steps: 3, steps per second: 122, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001406, mae: 0.027371, mean_q: 0.024197
 69780/100000: episode: 9662, duration: 0.030s, episode steps: 3, steps per second: 99, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000863, mae: 0.021604, mean_q: 0.038174
 69783/100000: episode: 9663, duration: 0.027s, episode steps: 3, steps per second: 110, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001860, mae: 0.030303, mean_q: 0.037603
 69786/100000: episode: 9664, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001098, mae: 0.015809, mean_q: 0.019651
 69789/100000: episode: 9665, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001924, mae: 0.032995, mean_q: 0.057124
 69792/100000: episode: 9666, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002417, mae: 0.036167, mean_q: 0.065821
 69795/100000: episode: 9667, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001826, mae: 0.035212, mean_q: 0.036656
 69798/100000: episode: 9668, duration: 0.025s, episode steps: 3, steps per second: 119, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002972, mae: 0.036353, mean_q: 0.052518
 69801/100000: episode: 9669, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.006282, mae: 0.052431, mean_q: 0.078397
 69805/100000: episode: 9670, duration: 0.030s, episode steps: 4, steps per second: 134, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002561, mae: 0.038414, mean_q: 0.015372
 69809/100000: episode: 9671, duration: 0.028s, episode steps: 4, steps per second: 141, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002417, mae: 0.040496, mean_q: 0.059295
 69812/100000: episode: 9672, duration: 0.024s, episode steps: 3, steps per second: 123, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002774, mae: 0.032109, mean_q: 0.049984
 69815/100000: episode: 9673, duration: 0.026s, episode steps: 3, steps per second: 116, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002206, mae: 0.031884, mean_q: 0.021129
 69818/100000: episode: 9674, duration: 0.021s, episode steps: 3, steps per second: 145, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000542, mae: 0.021030, mean_q: 0.028347
 69821/100000: episode: 9675, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000748, mae: 0.018703, mean_q: 0.017068
 69824/100000: episode: 9676, duration: 0.023s, episode steps: 3, steps per second: 132, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004068, mae: 0.044789, mean_q: 0.055987
 69827/100000: episode: 9677, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001747, mae: 0.036291, mean_q: 0.068295
 69830/100000: episode: 9678, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001846, mae: 0.030836, mean_q: 0.034718
 69833/100000: episode: 9679, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002773, mae: 0.032193, mean_q: 0.033668
 69836/100000: episode: 9680, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.006394, mae: 0.058709, mean_q: 0.100447
 69839/100000: episode: 9681, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001753, mae: 0.032926, mean_q: 0.025128
 69842/100000: episode: 9682, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000877, mae: 0.020326, mean_q: 0.023885
 69845/100000: episode: 9683, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001485, mae: 0.034914, mean_q: 0.053663
 69848/100000: episode: 9684, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003555, mae: 0.042012, mean_q: 0.065268
 69851/100000: episode: 9685, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001684, mae: 0.032885, mean_q: 0.027638
 69855/100000: episode: 9686, duration: 0.024s, episode steps: 4, steps per second: 166, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001902, mae: 0.032616, mean_q: 0.046170
 69858/100000: episode: 9687, duration: 0.020s, episode steps: 3, steps per second: 149, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001617, mae: 0.035735, mean_q: 0.055640
 69861/100000: episode: 9688, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003006, mae: 0.031937, mean_q: 0.019637
 69864/100000: episode: 9689, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002255, mae: 0.035974, mean_q: 0.060570
 69867/100000: episode: 9690, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001458, mae: 0.026551, mean_q: 0.032424
 69870/100000: episode: 9691, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002209, mae: 0.035824, mean_q: 0.030188
 69873/100000: episode: 9692, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.005225, mae: 0.043814, mean_q: 0.052730
 69876/100000: episode: 9693, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.004892, mae: 0.048972, mean_q: 0.075675
 69880/100000: episode: 9694, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002486, mae: 0.048199, mean_q: 0.048715
 69883/100000: episode: 9695, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003149, mae: 0.029994, mean_q: 0.024128
 69886/100000: episode: 9696, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002398, mae: 0.039924, mean_q: 0.057474
 69889/100000: episode: 9697, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000967, mae: 0.027179, mean_q: 0.022561
 69892/100000: episode: 9698, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001416, mae: 0.030006, mean_q: 0.030742
 69895/100000: episode: 9699, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001211, mae: 0.026306, mean_q: 0.037084
 69898/100000: episode: 9700, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001448, mae: 0.023918, mean_q: 0.032349
 69901/100000: episode: 9701, duration: 0.017s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.005153, mae: 0.036986, mean_q: 0.040418
 69904/100000: episode: 9702, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000572, mae: 0.021710, mean_q: 0.031371
 69907/100000: episode: 9703, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003158, mae: 0.037195, mean_q: 0.037298
 69910/100000: episode: 9704, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002290, mae: 0.024828, mean_q: 0.030911
 69914/100000: episode: 9705, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.001463, mae: 0.027370, mean_q: 0.046416
 69917/100000: episode: 9706, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001927, mae: 0.028792, mean_q: 0.024474
 69921/100000: episode: 9707, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002377, mae: 0.031893, mean_q: 0.052526
 69924/100000: episode: 9708, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001725, mae: 0.029181, mean_q: 0.044583
 69927/100000: episode: 9709, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.005155, mae: 0.039465, mean_q: 0.042292
 69930/100000: episode: 9710, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003381, mae: 0.037206, mean_q: 0.061526
 69933/100000: episode: 9711, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.004462, mae: 0.040259, mean_q: 0.059024
[Info] FALSIFICATION!
 69936/100000: episode: 9712, duration: 0.503s, episode steps: 3, steps per second: 6, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.003696, mae: 0.044674, mean_q: 0.047773
 69940/100000: episode: 9713, duration: 0.058s, episode steps: 4, steps per second: 69, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.002596, mae: 0.032481, mean_q: 0.041175
 69943/100000: episode: 9714, duration: 0.039s, episode steps: 3, steps per second: 77, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001920, mae: 0.032271, mean_q: 0.042202
 69946/100000: episode: 9715, duration: 0.044s, episode steps: 3, steps per second: 68, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001097, mae: 0.018898, mean_q: 0.029771
 69949/100000: episode: 9716, duration: 0.037s, episode steps: 3, steps per second: 81, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003293, mae: 0.041456, mean_q: 0.064009
 69952/100000: episode: 9717, duration: 0.040s, episode steps: 3, steps per second: 75, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001588, mae: 0.027252, mean_q: 0.051023
 69955/100000: episode: 9718, duration: 0.042s, episode steps: 3, steps per second: 71, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003875, mae: 0.041361, mean_q: 0.069272
 69958/100000: episode: 9719, duration: 0.044s, episode steps: 3, steps per second: 68, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003861, mae: 0.038903, mean_q: 0.068023
 69961/100000: episode: 9720, duration: 0.030s, episode steps: 3, steps per second: 100, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001759, mae: 0.030619, mean_q: 0.041583
 69964/100000: episode: 9721, duration: 0.038s, episode steps: 3, steps per second: 80, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000845, mae: 0.021410, mean_q: 0.028143
 69967/100000: episode: 9722, duration: 0.027s, episode steps: 3, steps per second: 112, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001579, mae: 0.030327, mean_q: 0.047800
 69970/100000: episode: 9723, duration: 0.041s, episode steps: 3, steps per second: 73, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003375, mae: 0.029885, mean_q: 0.038446
[Info] Complete ISplit Iteration
[Info] Levels: [0.051287264, 0.11886388, 0.9035301]
[Info] Cond. Prob: [0.12, 0.31, 0.01]
[Info] Error Prob: 0.000372

 69973/100000: episode: 9724, duration: 1.546s, episode steps: 3, steps per second: 2, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002069, mae: 0.033811, mean_q: 0.064415
 69983/100000: episode: 9725, duration: 0.090s, episode steps: 10, steps per second: 112, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001790, mae: 0.027696, mean_q: 0.044347
 69993/100000: episode: 9726, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001881, mae: 0.024818, mean_q: 0.039354
 70003/100000: episode: 9727, duration: 0.077s, episode steps: 10, steps per second: 129, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001781, mae: 0.028283, mean_q: 0.045142
 70013/100000: episode: 9728, duration: 0.084s, episode steps: 10, steps per second: 120, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.002257, mae: 0.034272, mean_q: 0.048220
 70023/100000: episode: 9729, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002479, mae: 0.035730, mean_q: 0.051744
 70033/100000: episode: 9730, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.003516, mae: 0.032863, mean_q: 0.047586
 70043/100000: episode: 9731, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002095, mae: 0.031254, mean_q: 0.045311
 70053/100000: episode: 9732, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001678, mae: 0.031145, mean_q: 0.040799
 70063/100000: episode: 9733, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002244, mae: 0.032494, mean_q: 0.045309
 70073/100000: episode: 9734, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001879, mae: 0.028311, mean_q: 0.038061
 70083/100000: episode: 9735, duration: 0.096s, episode steps: 10, steps per second: 105, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002393, mae: 0.030717, mean_q: 0.048632
 70093/100000: episode: 9736, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.002370, mae: 0.032782, mean_q: 0.050318
 70103/100000: episode: 9737, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002405, mae: 0.029311, mean_q: 0.045737
 70113/100000: episode: 9738, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001813, mae: 0.027283, mean_q: 0.043804
 70123/100000: episode: 9739, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002135, mae: 0.025766, mean_q: 0.039538
 70133/100000: episode: 9740, duration: 0.068s, episode steps: 10, steps per second: 146, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.002302, mae: 0.030410, mean_q: 0.047822
 70143/100000: episode: 9741, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001181, mae: 0.031505, mean_q: 0.041852
 70153/100000: episode: 9742, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002760, mae: 0.036957, mean_q: 0.050530
 70163/100000: episode: 9743, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002098, mae: 0.029905, mean_q: 0.039492
 70173/100000: episode: 9744, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.003059, mae: 0.034966, mean_q: 0.045626
 70183/100000: episode: 9745, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002142, mae: 0.034650, mean_q: 0.039429
 70193/100000: episode: 9746, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.002870, mae: 0.035969, mean_q: 0.053349
 70203/100000: episode: 9747, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001704, mae: 0.029274, mean_q: 0.044242
 70213/100000: episode: 9748, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001421, mae: 0.029245, mean_q: 0.041337
 70223/100000: episode: 9749, duration: 0.078s, episode steps: 10, steps per second: 129, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.003148, mae: 0.033660, mean_q: 0.052257
 70233/100000: episode: 9750, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002260, mae: 0.032507, mean_q: 0.038136
 70243/100000: episode: 9751, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002171, mae: 0.030481, mean_q: 0.044853
 70253/100000: episode: 9752, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001539, mae: 0.026520, mean_q: 0.038185
 70263/100000: episode: 9753, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002077, mae: 0.027906, mean_q: 0.042936
 70273/100000: episode: 9754, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002567, mae: 0.029775, mean_q: 0.040415
 70283/100000: episode: 9755, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001617, mae: 0.026476, mean_q: 0.042827
 70293/100000: episode: 9756, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002340, mae: 0.027554, mean_q: 0.037038
 70303/100000: episode: 9757, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002567, mae: 0.031568, mean_q: 0.048177
 70313/100000: episode: 9758, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001963, mae: 0.030434, mean_q: 0.045856
 70323/100000: episode: 9759, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002266, mae: 0.031065, mean_q: 0.040308
 70333/100000: episode: 9760, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002097, mae: 0.034954, mean_q: 0.046797
 70343/100000: episode: 9761, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.003958, mae: 0.038934, mean_q: 0.050294
 70353/100000: episode: 9762, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002160, mae: 0.034719, mean_q: 0.045024
 70363/100000: episode: 9763, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001454, mae: 0.025640, mean_q: 0.034121
 70373/100000: episode: 9764, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001737, mae: 0.027765, mean_q: 0.042103
 70383/100000: episode: 9765, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001816, mae: 0.033028, mean_q: 0.048873
 70393/100000: episode: 9766, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.002670, mae: 0.034832, mean_q: 0.045423
 70403/100000: episode: 9767, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002423, mae: 0.034535, mean_q: 0.046460
 70413/100000: episode: 9768, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003205, mae: 0.036396, mean_q: 0.050728
 70423/100000: episode: 9769, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002006, mae: 0.030117, mean_q: 0.047776
 70433/100000: episode: 9770, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001648, mae: 0.025057, mean_q: 0.035773
 70443/100000: episode: 9771, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001782, mae: 0.025193, mean_q: 0.031038
 70453/100000: episode: 9772, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001616, mae: 0.028952, mean_q: 0.032177
 70463/100000: episode: 9773, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.003512, mae: 0.036257, mean_q: 0.056767
 70473/100000: episode: 9774, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001395, mae: 0.023395, mean_q: 0.026689
 70483/100000: episode: 9775, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.002358, mae: 0.029878, mean_q: 0.040786
 70493/100000: episode: 9776, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.004280, mae: 0.041326, mean_q: 0.066373
 70503/100000: episode: 9777, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002531, mae: 0.031483, mean_q: 0.040725
 70513/100000: episode: 9778, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002613, mae: 0.032004, mean_q: 0.049829
 70523/100000: episode: 9779, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001929, mae: 0.027679, mean_q: 0.039984
 70533/100000: episode: 9780, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001356, mae: 0.024951, mean_q: 0.036839
 70543/100000: episode: 9781, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003452, mae: 0.036310, mean_q: 0.052817
 70553/100000: episode: 9782, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001685, mae: 0.025894, mean_q: 0.037671
 70563/100000: episode: 9783, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001000, mae: 0.019153, mean_q: 0.025290
 70573/100000: episode: 9784, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002334, mae: 0.027204, mean_q: 0.034885
 70583/100000: episode: 9785, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002549, mae: 0.035895, mean_q: 0.060097
 70593/100000: episode: 9786, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001824, mae: 0.026111, mean_q: 0.036810
 70603/100000: episode: 9787, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000950, mae: 0.020901, mean_q: 0.028574
 70613/100000: episode: 9788, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001741, mae: 0.021819, mean_q: 0.032357
 70623/100000: episode: 9789, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001686, mae: 0.022991, mean_q: 0.028891
 70633/100000: episode: 9790, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002195, mae: 0.027465, mean_q: 0.039524
 70643/100000: episode: 9791, duration: 0.087s, episode steps: 10, steps per second: 114, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.002036, mae: 0.026553, mean_q: 0.046212
 70653/100000: episode: 9792, duration: 0.098s, episode steps: 10, steps per second: 102, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002087, mae: 0.027485, mean_q: 0.034483
 70663/100000: episode: 9793, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002431, mae: 0.026828, mean_q: 0.035050
 70673/100000: episode: 9794, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001102, mae: 0.019573, mean_q: 0.022688
 70683/100000: episode: 9795, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002180, mae: 0.029714, mean_q: 0.034392
 70693/100000: episode: 9796, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001561, mae: 0.023041, mean_q: 0.036370
 70703/100000: episode: 9797, duration: 0.081s, episode steps: 10, steps per second: 124, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002281, mae: 0.030457, mean_q: 0.043740
 70713/100000: episode: 9798, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001307, mae: 0.027257, mean_q: 0.026360
 70723/100000: episode: 9799, duration: 0.069s, episode steps: 10, steps per second: 146, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001001, mae: 0.019061, mean_q: 0.021036
 70733/100000: episode: 9800, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002282, mae: 0.022918, mean_q: 0.033494
 70743/100000: episode: 9801, duration: 0.109s, episode steps: 10, steps per second: 92, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001900, mae: 0.025351, mean_q: 0.032936
 70753/100000: episode: 9802, duration: 0.114s, episode steps: 10, steps per second: 87, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002691, mae: 0.030630, mean_q: 0.038768
 70763/100000: episode: 9803, duration: 0.089s, episode steps: 10, steps per second: 113, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002438, mae: 0.027647, mean_q: 0.045945
 70773/100000: episode: 9804, duration: 0.096s, episode steps: 10, steps per second: 105, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001612, mae: 0.023658, mean_q: 0.034177
 70783/100000: episode: 9805, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001434, mae: 0.023923, mean_q: 0.037637
 70793/100000: episode: 9806, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001425, mae: 0.021540, mean_q: 0.031643
 70803/100000: episode: 9807, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000517, mae: 0.013872, mean_q: 0.023922
 70813/100000: episode: 9808, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001173, mae: 0.022808, mean_q: 0.036912
 70823/100000: episode: 9809, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001233, mae: 0.022527, mean_q: 0.035466
 70833/100000: episode: 9810, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000936, mae: 0.020456, mean_q: 0.027324
 70843/100000: episode: 9811, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001803, mae: 0.025233, mean_q: 0.043505
 70853/100000: episode: 9812, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002688, mae: 0.031423, mean_q: 0.050030
 70863/100000: episode: 9813, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.001690, mae: 0.027669, mean_q: 0.041985
 70873/100000: episode: 9814, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002417, mae: 0.029277, mean_q: 0.042748
 70883/100000: episode: 9815, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001447, mae: 0.025078, mean_q: 0.035317
 70893/100000: episode: 9816, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002174, mae: 0.031271, mean_q: 0.029638
 70903/100000: episode: 9817, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.003265, mae: 0.039773, mean_q: 0.044668
 70913/100000: episode: 9818, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002255, mae: 0.028300, mean_q: 0.036988
 70923/100000: episode: 9819, duration: 0.072s, episode steps: 10, steps per second: 138, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000963, mae: 0.020004, mean_q: 0.023211
 70933/100000: episode: 9820, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000944, mae: 0.018902, mean_q: 0.029937
 70943/100000: episode: 9821, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001611, mae: 0.021805, mean_q: 0.027099
 70953/100000: episode: 9822, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002401, mae: 0.027865, mean_q: 0.041793
 70963/100000: episode: 9823, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002824, mae: 0.031337, mean_q: 0.049449
[Info] 1-TH LEVEL FOUND: 0.02721390128135681, Considering 11/100 traces
 70973/100000: episode: 9824, duration: 0.764s, episode steps: 10, steps per second: 13, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001345, mae: 0.022232, mean_q: 0.030396
 70975/100000: episode: 9825, duration: 0.016s, episode steps: 2, steps per second: 124, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003419, mae: 0.025015, mean_q: 0.033981
 70977/100000: episode: 9826, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000253, mae: 0.016342, mean_q: 0.019864
 70984/100000: episode: 9827, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001878, mae: 0.025954, mean_q: 0.035902
 70991/100000: episode: 9828, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001103, mae: 0.020689, mean_q: 0.030065
 70998/100000: episode: 9829, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001769, mae: 0.027107, mean_q: 0.044221
 71005/100000: episode: 9830, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000853, mae: 0.016510, mean_q: 0.026155
 71007/100000: episode: 9831, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003594, mae: 0.028188, mean_q: 0.033799
 71009/100000: episode: 9832, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000402, mae: 0.015841, mean_q: 0.024061
 71016/100000: episode: 9833, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000900, mae: 0.022312, mean_q: 0.022042
 71023/100000: episode: 9834, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.001432, mae: 0.027337, mean_q: 0.037947
 71026/100000: episode: 9835, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001460, mae: 0.021667, mean_q: 0.034900
 71028/100000: episode: 9836, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001146, mae: 0.025539, mean_q: 0.036086
 71035/100000: episode: 9837, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001499, mae: 0.023572, mean_q: 0.036604
 71038/100000: episode: 9838, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004799, mae: 0.037824, mean_q: 0.062114
 71045/100000: episode: 9839, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002240, mae: 0.024322, mean_q: 0.036335
 71052/100000: episode: 9840, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000499, mae: 0.014546, mean_q: 0.026299
 71059/100000: episode: 9841, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002947, mae: 0.028014, mean_q: 0.038994
 71062/100000: episode: 9842, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001793, mae: 0.027998, mean_q: 0.036666
 71069/100000: episode: 9843, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001770, mae: 0.027359, mean_q: 0.032996
 71072/100000: episode: 9844, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002675, mae: 0.029321, mean_q: 0.051031
 71079/100000: episode: 9845, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000911, mae: 0.019208, mean_q: 0.017775
 71086/100000: episode: 9846, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000560, mae: 0.015725, mean_q: 0.020465
 71093/100000: episode: 9847, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.002191, mae: 0.027577, mean_q: 0.041506
 71095/100000: episode: 9848, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001174, mae: 0.026940, mean_q: 0.005130
 71102/100000: episode: 9849, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001079, mae: 0.025547, mean_q: 0.022068
 71109/100000: episode: 9850, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000611, mae: 0.016369, mean_q: 0.015192
 71116/100000: episode: 9851, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001324, mae: 0.024405, mean_q: 0.038240
 71118/100000: episode: 9852, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002153, mae: 0.031088, mean_q: 0.042075
 71121/100000: episode: 9853, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002761, mae: 0.025259, mean_q: 0.033584
 71124/100000: episode: 9854, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001353, mae: 0.024903, mean_q: 0.035825
 71131/100000: episode: 9855, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001836, mae: 0.024232, mean_q: 0.036079
 71138/100000: episode: 9856, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000748, mae: 0.017977, mean_q: 0.019122
 71145/100000: episode: 9857, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000859, mae: 0.018799, mean_q: 0.020876
 71152/100000: episode: 9858, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001745, mae: 0.020600, mean_q: 0.030286
 71155/100000: episode: 9859, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002988, mae: 0.021823, mean_q: 0.030827
 71158/100000: episode: 9860, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002151, mae: 0.025732, mean_q: 0.036071
 71165/100000: episode: 9861, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.002007, mae: 0.030924, mean_q: 0.026216
 71168/100000: episode: 9862, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001857, mae: 0.029505, mean_q: 0.022284
 71170/100000: episode: 9863, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003020, mae: 0.048428, mean_q: 0.055634
 71172/100000: episode: 9864, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000903, mae: 0.020998, mean_q: 0.029824
 71179/100000: episode: 9865, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001885, mae: 0.030086, mean_q: 0.025010
 71181/100000: episode: 9866, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001258, mae: 0.033605, mean_q: 0.043486
 71183/100000: episode: 9867, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001260, mae: 0.022219, mean_q: 0.030243
 71185/100000: episode: 9868, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003007, mae: 0.035102, mean_q: 0.039833
 71187/100000: episode: 9869, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003088, mae: 0.026018, mean_q: 0.046402
 71194/100000: episode: 9870, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.002873, mae: 0.034147, mean_q: 0.043589
 71201/100000: episode: 9871, duration: 0.038s, episode steps: 7, steps per second: 185, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001787, mae: 0.023876, mean_q: 0.027847
 71208/100000: episode: 9872, duration: 0.035s, episode steps: 7, steps per second: 197, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001335, mae: 0.018928, mean_q: 0.020325
 71215/100000: episode: 9873, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001272, mae: 0.024103, mean_q: 0.034429
 71218/100000: episode: 9874, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001269, mae: 0.023897, mean_q: 0.034795
 71225/100000: episode: 9875, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001594, mae: 0.021225, mean_q: 0.027079
 71232/100000: episode: 9876, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001679, mae: 0.021644, mean_q: 0.026653
 71239/100000: episode: 9877, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.002578, mae: 0.028450, mean_q: 0.040364
 71241/100000: episode: 9878, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000875, mae: 0.023551, mean_q: 0.043021
 71244/100000: episode: 9879, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002250, mae: 0.021785, mean_q: 0.034265
 71246/100000: episode: 9880, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001023, mae: 0.021899, mean_q: 0.046194
 71253/100000: episode: 9881, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.002378, mae: 0.024048, mean_q: 0.030785
 71255/100000: episode: 9882, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002546, mae: 0.029933, mean_q: 0.036597
 71258/100000: episode: 9883, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003052, mae: 0.033439, mean_q: 0.047271
 71260/100000: episode: 9884, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000985, mae: 0.016961, mean_q: 0.032362
 71267/100000: episode: 9885, duration: 0.035s, episode steps: 7, steps per second: 197, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001864, mae: 0.022522, mean_q: 0.029461
 71270/100000: episode: 9886, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001884, mae: 0.026275, mean_q: 0.046330
 71277/100000: episode: 9887, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.002847, mae: 0.028176, mean_q: 0.039166
 71280/100000: episode: 9888, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000433, mae: 0.011632, mean_q: 0.016913
 71287/100000: episode: 9889, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001592, mae: 0.027218, mean_q: 0.035329
 71294/100000: episode: 9890, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001234, mae: 0.022788, mean_q: 0.028075
 71301/100000: episode: 9891, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001550, mae: 0.021406, mean_q: 0.022975
 71308/100000: episode: 9892, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001079, mae: 0.021763, mean_q: 0.026595
 71311/100000: episode: 9893, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002877, mae: 0.030435, mean_q: 0.036818
 71318/100000: episode: 9894, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000611, mae: 0.018345, mean_q: 0.029492
 71321/100000: episode: 9895, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003479, mae: 0.035220, mean_q: 0.059546
 71328/100000: episode: 9896, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.002548, mae: 0.026217, mean_q: 0.036337
 71330/100000: episode: 9897, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001629, mae: 0.029456, mean_q: 0.042261
 71337/100000: episode: 9898, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001624, mae: 0.028181, mean_q: 0.037336
 71340/100000: episode: 9899, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000597, mae: 0.015194, mean_q: 0.020551
 71347/100000: episode: 9900, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002445, mae: 0.032734, mean_q: 0.047230
 71350/100000: episode: 9901, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002407, mae: 0.030243, mean_q: 0.033378
 71352/100000: episode: 9902, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001723, mae: 0.034854, mean_q: 0.048682
 71359/100000: episode: 9903, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.002928, mae: 0.029198, mean_q: 0.034751
 71366/100000: episode: 9904, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.002915, mae: 0.033180, mean_q: 0.048724
 71368/100000: episode: 9905, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001327, mae: 0.030917, mean_q: 0.026067
 71370/100000: episode: 9906, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003999, mae: 0.030737, mean_q: 0.031499
 71373/100000: episode: 9907, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002895, mae: 0.035392, mean_q: 0.055304
 71380/100000: episode: 9908, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.003148, mae: 0.042083, mean_q: 0.040707
 71387/100000: episode: 9909, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001746, mae: 0.029240, mean_q: 0.036948
 71394/100000: episode: 9910, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001820, mae: 0.032235, mean_q: 0.029671
 71401/100000: episode: 9911, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001282, mae: 0.026334, mean_q: 0.041816
 71408/100000: episode: 9912, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001089, mae: 0.017881, mean_q: 0.026268
[Info] 2-TH LEVEL FOUND: 0.12150594592094421, Considering 23/100 traces
 71410/100000: episode: 9913, duration: 0.740s, episode steps: 2, steps per second: 3, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001904, mae: 0.029333, mean_q: 0.054215
 71415/100000: episode: 9914, duration: 0.028s, episode steps: 5, steps per second: 179, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.001075, mae: 0.022306, mean_q: 0.031194
 71420/100000: episode: 9915, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.001541, mae: 0.024889, mean_q: 0.042657
 71422/100000: episode: 9916, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000296, mae: 0.009382, mean_q: 0.006239
 71424/100000: episode: 9917, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001700, mae: 0.023577, mean_q: 0.044236
 71426/100000: episode: 9918, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001288, mae: 0.028690, mean_q: 0.041429
 71431/100000: episode: 9919, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002543, mae: 0.032831, mean_q: 0.049749
 71433/100000: episode: 9920, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000802, mae: 0.024392, mean_q: 0.024750
 71435/100000: episode: 9921, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000257, mae: 0.014726, mean_q: 0.016397
 71437/100000: episode: 9922, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003309, mae: 0.039103, mean_q: 0.061440
 71439/100000: episode: 9923, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.007026, mae: 0.047385, mean_q: 0.070093
 71441/100000: episode: 9924, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000928, mae: 0.018705, mean_q: 0.027827
 71446/100000: episode: 9925, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001944, mae: 0.021165, mean_q: 0.026097
 71448/100000: episode: 9926, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001723, mae: 0.030487, mean_q: 0.063441
 71450/100000: episode: 9927, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000185, mae: 0.014393, mean_q: 0.003446
 71452/100000: episode: 9928, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000437, mae: 0.012809, mean_q: 0.008827
 71454/100000: episode: 9929, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004185, mae: 0.040082, mean_q: 0.060279
 71459/100000: episode: 9930, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000904, mae: 0.025746, mean_q: 0.032536
 71461/100000: episode: 9931, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001785, mae: 0.033052, mean_q: 0.036856
 71463/100000: episode: 9932, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000884, mae: 0.017351, mean_q: 0.028082
 71465/100000: episode: 9933, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002264, mae: 0.036459, mean_q: 0.074288
 71470/100000: episode: 9934, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002213, mae: 0.028084, mean_q: 0.036948
 71475/100000: episode: 9935, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001490, mae: 0.027310, mean_q: 0.045437
 71480/100000: episode: 9936, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001239, mae: 0.024085, mean_q: 0.027093
 71482/100000: episode: 9937, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001284, mae: 0.021824, mean_q: 0.031452
 71487/100000: episode: 9938, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002339, mae: 0.021654, mean_q: 0.030173
[Info] FALSIFICATION!
 71491/100000: episode: 9939, duration: 0.258s, episode steps: 4, steps per second: 16, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001351, mae: 0.027980, mean_q: 0.052863
 71496/100000: episode: 9940, duration: 0.030s, episode steps: 5, steps per second: 168, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000983, mae: 0.020980, mean_q: 0.028953
 71498/100000: episode: 9941, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000989, mae: 0.021350, mean_q: 0.045292
 71503/100000: episode: 9942, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002192, mae: 0.031185, mean_q: 0.068704
 71508/100000: episode: 9943, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001067, mae: 0.019897, mean_q: 0.012900
 71513/100000: episode: 9944, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001265, mae: 0.024441, mean_q: 0.032474
 71518/100000: episode: 9945, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.003056, mae: 0.025492, mean_q: 0.040279
 71520/100000: episode: 9946, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001182, mae: 0.022799, mean_q: 0.038221
 71525/100000: episode: 9947, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002182, mae: 0.020854, mean_q: 0.026870
 71530/100000: episode: 9948, duration: 0.035s, episode steps: 5, steps per second: 144, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.003849, mae: 0.032196, mean_q: 0.028940
 71532/100000: episode: 9949, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000829, mae: 0.024865, mean_q: 0.042700
 71537/100000: episode: 9950, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.002875, mae: 0.036115, mean_q: 0.039284
 71542/100000: episode: 9951, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001276, mae: 0.027245, mean_q: 0.048294
 71544/100000: episode: 9952, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003912, mae: 0.032880, mean_q: 0.044135
 71546/100000: episode: 9953, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002206, mae: 0.029827, mean_q: 0.035019
[Info] FALSIFICATION!
 71550/100000: episode: 9954, duration: 0.279s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001744, mae: 0.025791, mean_q: 0.033131
 71555/100000: episode: 9955, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002767, mae: 0.026634, mean_q: 0.029717
 71557/100000: episode: 9956, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000709, mae: 0.016324, mean_q: 0.019106
 71559/100000: episode: 9957, duration: 0.014s, episode steps: 2, steps per second: 139, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001655, mae: 0.028817, mean_q: 0.022841
 71564/100000: episode: 9958, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001833, mae: 0.025390, mean_q: 0.040641
 71569/100000: episode: 9959, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002184, mae: 0.024953, mean_q: 0.041048
 71574/100000: episode: 9960, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001127, mae: 0.023595, mean_q: 0.027541
 71579/100000: episode: 9961, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002389, mae: 0.028738, mean_q: 0.041635
 71584/100000: episode: 9962, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002970, mae: 0.028905, mean_q: 0.036083
 71589/100000: episode: 9963, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001675, mae: 0.027099, mean_q: 0.036037
 71591/100000: episode: 9964, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001092, mae: 0.017181, mean_q: 0.026454
 71593/100000: episode: 9965, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005046, mae: 0.042593, mean_q: 0.062538
 71598/100000: episode: 9966, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.004424, mae: 0.038453, mean_q: 0.057582
 71600/100000: episode: 9967, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000981, mae: 0.019250, mean_q: 0.038372
 71602/100000: episode: 9968, duration: 0.016s, episode steps: 2, steps per second: 125, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001482, mae: 0.028734, mean_q: 0.040422
 71607/100000: episode: 9969, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001354, mae: 0.025966, mean_q: 0.031139
 71612/100000: episode: 9970, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.002042, mae: 0.025321, mean_q: 0.039408
 71614/100000: episode: 9971, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001579, mae: 0.028317, mean_q: 0.036929
 71616/100000: episode: 9972, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001488, mae: 0.028913, mean_q: 0.028921
 71618/100000: episode: 9973, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001632, mae: 0.024349, mean_q: 0.043582
 71620/100000: episode: 9974, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001452, mae: 0.024829, mean_q: 0.033649
 71625/100000: episode: 9975, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.003408, mae: 0.026112, mean_q: 0.029465
 71627/100000: episode: 9976, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003703, mae: 0.031565, mean_q: 0.055767
 71629/100000: episode: 9977, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001784, mae: 0.037026, mean_q: 0.042307
 71631/100000: episode: 9978, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001317, mae: 0.027911, mean_q: 0.016023
 71636/100000: episode: 9979, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001471, mae: 0.031444, mean_q: 0.043365
 71641/100000: episode: 9980, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001984, mae: 0.024726, mean_q: 0.016847
 71646/100000: episode: 9981, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001689, mae: 0.032988, mean_q: 0.052274
 71648/100000: episode: 9982, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002156, mae: 0.035998, mean_q: 0.032755
 71650/100000: episode: 9983, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002364, mae: 0.029637, mean_q: 0.043648
 71655/100000: episode: 9984, duration: 0.039s, episode steps: 5, steps per second: 127, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001350, mae: 0.026611, mean_q: 0.041075
 71660/100000: episode: 9985, duration: 0.038s, episode steps: 5, steps per second: 130, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.001328, mae: 0.023005, mean_q: 0.029303
 71662/100000: episode: 9986, duration: 0.014s, episode steps: 2, steps per second: 139, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000437, mae: 0.018324, mean_q: 0.031857
 71664/100000: episode: 9987, duration: 0.014s, episode steps: 2, steps per second: 142, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002008, mae: 0.028878, mean_q: 0.032021
 71669/100000: episode: 9988, duration: 0.035s, episode steps: 5, steps per second: 144, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001817, mae: 0.024496, mean_q: 0.032707
 71671/100000: episode: 9989, duration: 0.014s, episode steps: 2, steps per second: 139, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004783, mae: 0.036334, mean_q: 0.052717
[Info] Complete ISplit Iteration
[Info] Levels: [0.027213901, 0.121505946, 1.0237074]
[Info] Cond. Prob: [0.11, 0.23, 0.02]
[Info] Error Prob: 0.000506

 71673/100000: episode: 9990, duration: 1.141s, episode steps: 2, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001326, mae: 0.023586, mean_q: 0.038067
 71683/100000: episode: 9991, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002134, mae: 0.030817, mean_q: 0.043142
 71693/100000: episode: 9992, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000459, mae: 0.016005, mean_q: 0.021815
 71703/100000: episode: 9993, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001576, mae: 0.023928, mean_q: 0.036553
 71713/100000: episode: 9994, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002113, mae: 0.024588, mean_q: 0.034630
 71723/100000: episode: 9995, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001797, mae: 0.029773, mean_q: 0.037565
 71733/100000: episode: 9996, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000959, mae: 0.023148, mean_q: 0.030046
 71743/100000: episode: 9997, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001321, mae: 0.022346, mean_q: 0.033332
 71753/100000: episode: 9998, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003963, mae: 0.039219, mean_q: 0.060917
 71763/100000: episode: 9999, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001542, mae: 0.029245, mean_q: 0.040908
 71773/100000: episode: 10000, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001839, mae: 0.026934, mean_q: 0.039314
 71783/100000: episode: 10001, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001960, mae: 0.024793, mean_q: 0.037356
 71793/100000: episode: 10002, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001687, mae: 0.023953, mean_q: 0.032660
 71803/100000: episode: 10003, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002004, mae: 0.024166, mean_q: 0.029568
 71813/100000: episode: 10004, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002791, mae: 0.031828, mean_q: 0.046220
 71823/100000: episode: 10005, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001800, mae: 0.024352, mean_q: 0.034436
 71833/100000: episode: 10006, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001987, mae: 0.026356, mean_q: 0.035249
 71843/100000: episode: 10007, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001332, mae: 0.022564, mean_q: 0.027922
 71853/100000: episode: 10008, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001822, mae: 0.025480, mean_q: 0.039736
 71863/100000: episode: 10009, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002481, mae: 0.028430, mean_q: 0.037675
 71873/100000: episode: 10010, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002503, mae: 0.037418, mean_q: 0.028527
 71883/100000: episode: 10011, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001959, mae: 0.029991, mean_q: 0.032295
 71893/100000: episode: 10012, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002311, mae: 0.028840, mean_q: 0.044668
 71903/100000: episode: 10013, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.003117, mae: 0.035235, mean_q: 0.053163
 71913/100000: episode: 10014, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001538, mae: 0.025422, mean_q: 0.031520
 71923/100000: episode: 10015, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.003845, mae: 0.039446, mean_q: 0.047576
 71933/100000: episode: 10016, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001657, mae: 0.036442, mean_q: 0.035451
 71943/100000: episode: 10017, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001568, mae: 0.025171, mean_q: 0.027953
 71953/100000: episode: 10018, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.003758, mae: 0.032897, mean_q: 0.040031
 71963/100000: episode: 10019, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001866, mae: 0.029874, mean_q: 0.028563
 71973/100000: episode: 10020, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001708, mae: 0.028115, mean_q: 0.032446
 71983/100000: episode: 10021, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001605, mae: 0.027064, mean_q: 0.036277
 71993/100000: episode: 10022, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002193, mae: 0.027936, mean_q: 0.038072
 72003/100000: episode: 10023, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002113, mae: 0.025875, mean_q: 0.035346
 72013/100000: episode: 10024, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001937, mae: 0.027451, mean_q: 0.035766
 72023/100000: episode: 10025, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001803, mae: 0.025098, mean_q: 0.033022
 72033/100000: episode: 10026, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001508, mae: 0.022746, mean_q: 0.029783
 72043/100000: episode: 10027, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001220, mae: 0.021285, mean_q: 0.031871
 72053/100000: episode: 10028, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001291, mae: 0.019900, mean_q: 0.027294
 72063/100000: episode: 10029, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001137, mae: 0.024889, mean_q: 0.036013
 72073/100000: episode: 10030, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000788, mae: 0.019520, mean_q: 0.028784
 72083/100000: episode: 10031, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001273, mae: 0.020188, mean_q: 0.031034
 72093/100000: episode: 10032, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001944, mae: 0.023848, mean_q: 0.040770
 72103/100000: episode: 10033, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001479, mae: 0.020714, mean_q: 0.031251
 72113/100000: episode: 10034, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002516, mae: 0.033087, mean_q: 0.049444
 72123/100000: episode: 10035, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001283, mae: 0.024720, mean_q: 0.038227
 72133/100000: episode: 10036, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.002479, mae: 0.027292, mean_q: 0.042793
 72143/100000: episode: 10037, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001893, mae: 0.024644, mean_q: 0.029195
 72153/100000: episode: 10038, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002041, mae: 0.026784, mean_q: 0.035480
 72163/100000: episode: 10039, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002766, mae: 0.032968, mean_q: 0.047004
 72173/100000: episode: 10040, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002302, mae: 0.027474, mean_q: 0.035331
 72183/100000: episode: 10041, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.001426, mae: 0.022768, mean_q: 0.034097
 72193/100000: episode: 10042, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001480, mae: 0.021688, mean_q: 0.034533
 72203/100000: episode: 10043, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001440, mae: 0.016696, mean_q: 0.023486
 72213/100000: episode: 10044, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001693, mae: 0.024177, mean_q: 0.040468
 72223/100000: episode: 10045, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000942, mae: 0.021602, mean_q: 0.029574
 72233/100000: episode: 10046, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002480, mae: 0.029969, mean_q: 0.041995
 72243/100000: episode: 10047, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002514, mae: 0.031792, mean_q: 0.030385
 72253/100000: episode: 10048, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001752, mae: 0.029270, mean_q: 0.033587
 72263/100000: episode: 10049, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.003638, mae: 0.038233, mean_q: 0.055146
 72273/100000: episode: 10050, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002021, mae: 0.030397, mean_q: 0.040380
 72283/100000: episode: 10051, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001544, mae: 0.020560, mean_q: 0.028298
 72293/100000: episode: 10052, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001107, mae: 0.021604, mean_q: 0.024775
 72303/100000: episode: 10053, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001896, mae: 0.030893, mean_q: 0.043532
 72313/100000: episode: 10054, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001287, mae: 0.021924, mean_q: 0.033697
 72323/100000: episode: 10055, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000793, mae: 0.015961, mean_q: 0.019201
 72333/100000: episode: 10056, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001992, mae: 0.023995, mean_q: 0.034136
 72343/100000: episode: 10057, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001389, mae: 0.022717, mean_q: 0.038319
 72353/100000: episode: 10058, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001898, mae: 0.022495, mean_q: 0.032847
 72363/100000: episode: 10059, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002280, mae: 0.024382, mean_q: 0.043265
 72373/100000: episode: 10060, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002269, mae: 0.033099, mean_q: 0.031694
 72383/100000: episode: 10061, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.003155, mae: 0.035618, mean_q: 0.041884
 72393/100000: episode: 10062, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001675, mae: 0.024183, mean_q: 0.033974
 72403/100000: episode: 10063, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001632, mae: 0.026177, mean_q: 0.039988
 72413/100000: episode: 10064, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001303, mae: 0.026064, mean_q: 0.042669
 72423/100000: episode: 10065, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.003026, mae: 0.029182, mean_q: 0.034127
 72433/100000: episode: 10066, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002464, mae: 0.030483, mean_q: 0.026174
 72443/100000: episode: 10067, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001750, mae: 0.028501, mean_q: 0.028848
 72453/100000: episode: 10068, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001314, mae: 0.021695, mean_q: 0.033560
 72463/100000: episode: 10069, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002695, mae: 0.024987, mean_q: 0.036819
 72473/100000: episode: 10070, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001682, mae: 0.027698, mean_q: 0.035116
 72483/100000: episode: 10071, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001036, mae: 0.023195, mean_q: 0.032140
 72493/100000: episode: 10072, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001959, mae: 0.026305, mean_q: 0.047122
 72503/100000: episode: 10073, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001242, mae: 0.019993, mean_q: 0.032334
 72513/100000: episode: 10074, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001953, mae: 0.022067, mean_q: 0.036385
 72523/100000: episode: 10075, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002525, mae: 0.025467, mean_q: 0.037828
 72533/100000: episode: 10076, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.002026, mae: 0.028615, mean_q: 0.041259
 72543/100000: episode: 10077, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001331, mae: 0.020285, mean_q: 0.028478
 72553/100000: episode: 10078, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000984, mae: 0.019980, mean_q: 0.025615
 72563/100000: episode: 10079, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000696, mae: 0.016782, mean_q: 0.026070
 72573/100000: episode: 10080, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002883, mae: 0.027036, mean_q: 0.036862
 72583/100000: episode: 10081, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002180, mae: 0.029318, mean_q: 0.026595
 72593/100000: episode: 10082, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000935, mae: 0.017581, mean_q: 0.028995
 72603/100000: episode: 10083, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000976, mae: 0.016411, mean_q: 0.026875
 72613/100000: episode: 10084, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002008, mae: 0.019707, mean_q: 0.025771
 72623/100000: episode: 10085, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000906, mae: 0.018540, mean_q: 0.017984
 72633/100000: episode: 10086, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001454, mae: 0.023360, mean_q: 0.028459
 72643/100000: episode: 10087, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001781, mae: 0.023192, mean_q: 0.033505
 72653/100000: episode: 10088, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001748, mae: 0.019360, mean_q: 0.026226
 72663/100000: episode: 10089, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001981, mae: 0.023490, mean_q: 0.037400
[Info] 1-TH LEVEL FOUND: 0.04261770844459534, Considering 10/100 traces
 72673/100000: episode: 10090, duration: 0.721s, episode steps: 10, steps per second: 14, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000280, mae: 0.011717, mean_q: 0.011280
 72680/100000: episode: 10091, duration: 0.037s, episode steps: 7, steps per second: 191, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001651, mae: 0.022105, mean_q: 0.029639
 72687/100000: episode: 10092, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.002048, mae: 0.022728, mean_q: 0.033609
 72694/100000: episode: 10093, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002486, mae: 0.027241, mean_q: 0.042938
 72701/100000: episode: 10094, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001396, mae: 0.025247, mean_q: 0.015476
 72708/100000: episode: 10095, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000657, mae: 0.017589, mean_q: 0.016488
 72712/100000: episode: 10096, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001132, mae: 0.023868, mean_q: 0.038835
 72719/100000: episode: 10097, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.002350, mae: 0.027048, mean_q: 0.031058
 72726/100000: episode: 10098, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000596, mae: 0.014608, mean_q: 0.021213
 72730/100000: episode: 10099, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000463, mae: 0.014645, mean_q: 0.019708
 72737/100000: episode: 10100, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000441, mae: 0.014316, mean_q: 0.020725
 72741/100000: episode: 10101, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000221, mae: 0.011160, mean_q: 0.007315
 72748/100000: episode: 10102, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.001126, mae: 0.020804, mean_q: 0.039649
 72755/100000: episode: 10103, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001179, mae: 0.014019, mean_q: 0.017391
 72762/100000: episode: 10104, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000723, mae: 0.017905, mean_q: 0.028259
 72769/100000: episode: 10105, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000719, mae: 0.019942, mean_q: 0.020691
 72776/100000: episode: 10106, duration: 0.038s, episode steps: 7, steps per second: 184, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000864, mae: 0.016337, mean_q: 0.013541
 72783/100000: episode: 10107, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001583, mae: 0.018367, mean_q: 0.026407
 72787/100000: episode: 10108, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000364, mae: 0.011432, mean_q: 0.018356
 72794/100000: episode: 10109, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000677, mae: 0.016126, mean_q: 0.026232
 72801/100000: episode: 10110, duration: 0.037s, episode steps: 7, steps per second: 191, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000800, mae: 0.016680, mean_q: 0.018723
 72808/100000: episode: 10111, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000905, mae: 0.019237, mean_q: 0.019273
 72815/100000: episode: 10112, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001689, mae: 0.022330, mean_q: 0.033201
 72819/100000: episode: 10113, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001458, mae: 0.018130, mean_q: 0.021066
 72826/100000: episode: 10114, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000516, mae: 0.013670, mean_q: 0.013709
 72833/100000: episode: 10115, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000168, mae: 0.010235, mean_q: 0.014287
 72840/100000: episode: 10116, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001672, mae: 0.018909, mean_q: 0.021281
 72847/100000: episode: 10117, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.001029, mae: 0.013274, mean_q: 0.015666
 72854/100000: episode: 10118, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001194, mae: 0.019353, mean_q: 0.025965
 72861/100000: episode: 10119, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000581, mae: 0.016435, mean_q: 0.012191
 72868/100000: episode: 10120, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001341, mae: 0.024214, mean_q: 0.025678
 72875/100000: episode: 10121, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000772, mae: 0.017907, mean_q: 0.033419
 72879/100000: episode: 10122, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000642, mae: 0.017513, mean_q: 0.020666
 72886/100000: episode: 10123, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001066, mae: 0.015428, mean_q: 0.022551
 72893/100000: episode: 10124, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001482, mae: 0.018752, mean_q: 0.025416
 72900/100000: episode: 10125, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.001694, mae: 0.026542, mean_q: 0.014565
 72907/100000: episode: 10126, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001745, mae: 0.024293, mean_q: 0.028453
 72914/100000: episode: 10127, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001200, mae: 0.024218, mean_q: 0.016146
 72921/100000: episode: 10128, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000671, mae: 0.017954, mean_q: 0.025563
 72925/100000: episode: 10129, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000681, mae: 0.018975, mean_q: 0.022190
 72932/100000: episode: 10130, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000420, mae: 0.014640, mean_q: 0.017695
 72939/100000: episode: 10131, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000590, mae: 0.012406, mean_q: 0.017503
 72946/100000: episode: 10132, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001042, mae: 0.013839, mean_q: 0.021796
 72953/100000: episode: 10133, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.001604, mae: 0.021861, mean_q: 0.025734
 72957/100000: episode: 10134, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000338, mae: 0.015267, mean_q: 0.022958
 72964/100000: episode: 10135, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000555, mae: 0.015609, mean_q: 0.016170
 72968/100000: episode: 10136, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000224, mae: 0.014203, mean_q: 0.021435
 72972/100000: episode: 10137, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000396, mae: 0.013260, mean_q: 0.017533
 72979/100000: episode: 10138, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000371, mae: 0.012587, mean_q: 0.017900
 72986/100000: episode: 10139, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000484, mae: 0.012450, mean_q: 0.017843
 72990/100000: episode: 10140, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000307, mae: 0.011344, mean_q: 0.018775
 72997/100000: episode: 10141, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001618, mae: 0.016983, mean_q: 0.027644
 73004/100000: episode: 10142, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000207, mae: 0.012384, mean_q: 0.012930
 73011/100000: episode: 10143, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000751, mae: 0.014928, mean_q: 0.025955
 73015/100000: episode: 10144, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002300, mae: 0.020912, mean_q: 0.033189
 73022/100000: episode: 10145, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.001006, mae: 0.018656, mean_q: 0.026113
 73029/100000: episode: 10146, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000401, mae: 0.013148, mean_q: 0.017388
 73036/100000: episode: 10147, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002130, mae: 0.021470, mean_q: 0.028888
 73040/100000: episode: 10148, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000216, mae: 0.011836, mean_q: 0.005868
 73047/100000: episode: 10149, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000498, mae: 0.011997, mean_q: 0.016245
 73054/100000: episode: 10150, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000360, mae: 0.013865, mean_q: 0.019489
 73061/100000: episode: 10151, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000489, mae: 0.013949, mean_q: 0.022248
 73068/100000: episode: 10152, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000637, mae: 0.012625, mean_q: 0.013047
 73075/100000: episode: 10153, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000538, mae: 0.015315, mean_q: 0.023070
 73082/100000: episode: 10154, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000290, mae: 0.011503, mean_q: 0.011955
 73089/100000: episode: 10155, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000645, mae: 0.015993, mean_q: 0.021490
 73096/100000: episode: 10156, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000590, mae: 0.016230, mean_q: 0.018139
 73103/100000: episode: 10157, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000393, mae: 0.011888, mean_q: 0.014073
 73110/100000: episode: 10158, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001032, mae: 0.015801, mean_q: 0.025354
 73114/100000: episode: 10159, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001798, mae: 0.014801, mean_q: 0.023188
 73121/100000: episode: 10160, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000386, mae: 0.014272, mean_q: 0.021420
 73128/100000: episode: 10161, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000712, mae: 0.015894, mean_q: 0.023353
 73135/100000: episode: 10162, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000301, mae: 0.012828, mean_q: 0.015964
 73142/100000: episode: 10163, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001322, mae: 0.018495, mean_q: 0.025672
 73149/100000: episode: 10164, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000324, mae: 0.015270, mean_q: 0.012164
 73156/100000: episode: 10165, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000444, mae: 0.013498, mean_q: 0.012419
 73163/100000: episode: 10166, duration: 0.037s, episode steps: 7, steps per second: 191, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000424, mae: 0.016123, mean_q: 0.024460
 73167/100000: episode: 10167, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000278, mae: 0.013853, mean_q: 0.017383
 73174/100000: episode: 10168, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000331, mae: 0.012726, mean_q: 0.015521
 73181/100000: episode: 10169, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.001221, mae: 0.021004, mean_q: 0.024846
 73188/100000: episode: 10170, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.002872, mae: 0.028704, mean_q: 0.031448
 73195/100000: episode: 10171, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000469, mae: 0.016902, mean_q: 0.012092
 73199/100000: episode: 10172, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002297, mae: 0.027999, mean_q: 0.037014
 73206/100000: episode: 10173, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000723, mae: 0.022294, mean_q: 0.025216
 73213/100000: episode: 10174, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000916, mae: 0.021684, mean_q: 0.019696
 73220/100000: episode: 10175, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000719, mae: 0.014917, mean_q: 0.014889
 73227/100000: episode: 10176, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000875, mae: 0.015608, mean_q: 0.017066
 73234/100000: episode: 10177, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000295, mae: 0.011916, mean_q: 0.016534
 73241/100000: episode: 10178, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000663, mae: 0.015250, mean_q: 0.023497
 73248/100000: episode: 10179, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.001099, mae: 0.015562, mean_q: 0.021806
[Info] 2-TH LEVEL FOUND: 0.10882523655891418, Considering 16/100 traces
 73255/100000: episode: 10180, duration: 0.835s, episode steps: 7, steps per second: 8, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000403, mae: 0.013034, mean_q: 0.020030
 73260/100000: episode: 10181, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000921, mae: 0.015347, mean_q: 0.020279
 73265/100000: episode: 10182, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000308, mae: 0.012726, mean_q: 0.014969
 73270/100000: episode: 10183, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001856, mae: 0.020643, mean_q: 0.028403
 73275/100000: episode: 10184, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001331, mae: 0.024369, mean_q: 0.029470
 73280/100000: episode: 10185, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000758, mae: 0.017214, mean_q: 0.031369
[Info] FALSIFICATION!
 73284/100000: episode: 10186, duration: 0.261s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000200, mae: 0.009907, mean_q: 0.006834
 73289/100000: episode: 10187, duration: 0.030s, episode steps: 5, steps per second: 168, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000144, mae: 0.010469, mean_q: 0.014827
 73294/100000: episode: 10188, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000265, mae: 0.012600, mean_q: 0.014336
 73299/100000: episode: 10189, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001314, mae: 0.015517, mean_q: 0.022011
 73304/100000: episode: 10190, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000531, mae: 0.015390, mean_q: 0.022983
 73309/100000: episode: 10191, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000447, mae: 0.014992, mean_q: 0.019760
[Info] FALSIFICATION!
 73313/100000: episode: 10192, duration: 0.264s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000675, mae: 0.014098, mean_q: 0.017755
 73318/100000: episode: 10193, duration: 0.031s, episode steps: 5, steps per second: 160, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000375, mae: 0.014802, mean_q: 0.024503
[Info] FALSIFICATION!
 73322/100000: episode: 10194, duration: 0.263s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000739, mae: 0.017882, mean_q: 0.003912
 73327/100000: episode: 10195, duration: 0.031s, episode steps: 5, steps per second: 163, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000734, mae: 0.019527, mean_q: 0.029401
 73332/100000: episode: 10196, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001738, mae: 0.019922, mean_q: 0.032460
[Info] FALSIFICATION!
 73336/100000: episode: 10197, duration: 0.263s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.002106, mae: 0.030160, mean_q: 0.031266
 73341/100000: episode: 10198, duration: 0.030s, episode steps: 5, steps per second: 167, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000962, mae: 0.021252, mean_q: 0.028287
 73346/100000: episode: 10199, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001063, mae: 0.019431, mean_q: 0.032843
 73351/100000: episode: 10200, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000918, mae: 0.020165, mean_q: 0.016370
 73356/100000: episode: 10201, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001072, mae: 0.019081, mean_q: 0.027919
[Info] FALSIFICATION!
 73360/100000: episode: 10202, duration: 0.262s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.002146, mae: 0.019219, mean_q: 0.029833
 73365/100000: episode: 10203, duration: 0.031s, episode steps: 5, steps per second: 159, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000891, mae: 0.016238, mean_q: 0.028877
 73370/100000: episode: 10204, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000810, mae: 0.019424, mean_q: 0.023291
 73375/100000: episode: 10205, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000917, mae: 0.016995, mean_q: 0.026739
 73380/100000: episode: 10206, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000496, mae: 0.014801, mean_q: 0.025772
 73385/100000: episode: 10207, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000643, mae: 0.015650, mean_q: 0.023283
 73390/100000: episode: 10208, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001718, mae: 0.021903, mean_q: 0.035362
 73395/100000: episode: 10209, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001090, mae: 0.017078, mean_q: 0.022554
 73400/100000: episode: 10210, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000661, mae: 0.014972, mean_q: 0.019604
 73405/100000: episode: 10211, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001322, mae: 0.016934, mean_q: 0.019590
 73410/100000: episode: 10212, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000452, mae: 0.013312, mean_q: 0.019749
 73415/100000: episode: 10213, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001592, mae: 0.021128, mean_q: 0.032079
 73420/100000: episode: 10214, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000678, mae: 0.016311, mean_q: 0.026347
 73425/100000: episode: 10215, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000474, mae: 0.014025, mean_q: 0.020036
 73430/100000: episode: 10216, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000434, mae: 0.013133, mean_q: 0.017602
 73435/100000: episode: 10217, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001637, mae: 0.023453, mean_q: 0.037082
 73440/100000: episode: 10218, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001081, mae: 0.024927, mean_q: 0.035906
 73445/100000: episode: 10219, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000455, mae: 0.016753, mean_q: 0.017991
 73450/100000: episode: 10220, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001371, mae: 0.017010, mean_q: 0.017532
 73455/100000: episode: 10221, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.001517, mae: 0.023369, mean_q: 0.034598
 73460/100000: episode: 10222, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000867, mae: 0.020989, mean_q: 0.024283
 73465/100000: episode: 10223, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000846, mae: 0.018702, mean_q: 0.021025
 73470/100000: episode: 10224, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002225, mae: 0.022060, mean_q: 0.011536
 73475/100000: episode: 10225, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000796, mae: 0.021919, mean_q: 0.038088
 73480/100000: episode: 10226, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000566, mae: 0.016591, mean_q: 0.019775
 73485/100000: episode: 10227, duration: 0.029s, episode steps: 5, steps per second: 174, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002200, mae: 0.031648, mean_q: 0.049128
 73490/100000: episode: 10228, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002526, mae: 0.032699, mean_q: 0.034040
[Info] FALSIFICATION!
 73494/100000: episode: 10229, duration: 0.273s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000950, mae: 0.021814, mean_q: 0.035794
 73499/100000: episode: 10230, duration: 0.032s, episode steps: 5, steps per second: 158, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001038, mae: 0.025505, mean_q: 0.021115
 73504/100000: episode: 10231, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001165, mae: 0.027892, mean_q: 0.046975
 73509/100000: episode: 10232, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000740, mae: 0.022037, mean_q: 0.025010
 73514/100000: episode: 10233, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001266, mae: 0.022472, mean_q: 0.028142
 73519/100000: episode: 10234, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000666, mae: 0.022166, mean_q: 0.032762
 73524/100000: episode: 10235, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000560, mae: 0.017521, mean_q: 0.016009
 73529/100000: episode: 10236, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001102, mae: 0.021084, mean_q: 0.035784
 73534/100000: episode: 10237, duration: 0.029s, episode steps: 5, steps per second: 174, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001483, mae: 0.020884, mean_q: 0.028914
 73539/100000: episode: 10238, duration: 0.027s, episode steps: 5, steps per second: 189, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001306, mae: 0.019236, mean_q: 0.026690
[Info] FALSIFICATION!
 73543/100000: episode: 10239, duration: 0.278s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.001181, mae: 0.021623, mean_q: 0.034544
 73548/100000: episode: 10240, duration: 0.033s, episode steps: 5, steps per second: 154, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000936, mae: 0.019777, mean_q: 0.030213
 73553/100000: episode: 10241, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002526, mae: 0.031661, mean_q: 0.039081
 73558/100000: episode: 10242, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.002343, mae: 0.033428, mean_q: 0.019978
 73563/100000: episode: 10243, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001383, mae: 0.030349, mean_q: 0.035188
 73568/100000: episode: 10244, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000875, mae: 0.021968, mean_q: 0.023705
 73573/100000: episode: 10245, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000848, mae: 0.023011, mean_q: 0.029660
 73578/100000: episode: 10246, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001249, mae: 0.025047, mean_q: 0.043528
 73583/100000: episode: 10247, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001391, mae: 0.019590, mean_q: 0.023724
 73588/100000: episode: 10248, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001763, mae: 0.020892, mean_q: 0.030311
 73593/100000: episode: 10249, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001317, mae: 0.021395, mean_q: 0.036606
 73598/100000: episode: 10250, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000492, mae: 0.020170, mean_q: 0.015474
 73603/100000: episode: 10251, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000973, mae: 0.025111, mean_q: 0.037957
 73608/100000: episode: 10252, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001196, mae: 0.020091, mean_q: 0.024469
 73613/100000: episode: 10253, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000983, mae: 0.023185, mean_q: 0.040029
 73618/100000: episode: 10254, duration: 0.034s, episode steps: 5, steps per second: 147, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000687, mae: 0.020297, mean_q: 0.020699
 73623/100000: episode: 10255, duration: 0.033s, episode steps: 5, steps per second: 151, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001708, mae: 0.023879, mean_q: 0.034217
 73628/100000: episode: 10256, duration: 0.039s, episode steps: 5, steps per second: 129, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001488, mae: 0.024422, mean_q: 0.043004
 73633/100000: episode: 10257, duration: 0.045s, episode steps: 5, steps per second: 112, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000521, mae: 0.015425, mean_q: 0.021832
 73638/100000: episode: 10258, duration: 0.037s, episode steps: 5, steps per second: 136, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001108, mae: 0.021407, mean_q: 0.023951
 73643/100000: episode: 10259, duration: 0.044s, episode steps: 5, steps per second: 114, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.002734, mae: 0.029180, mean_q: 0.035692
 73648/100000: episode: 10260, duration: 0.036s, episode steps: 5, steps per second: 140, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000976, mae: 0.022512, mean_q: 0.032740
 73653/100000: episode: 10261, duration: 0.031s, episode steps: 5, steps per second: 163, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001565, mae: 0.018931, mean_q: 0.027178
 73658/100000: episode: 10262, duration: 0.032s, episode steps: 5, steps per second: 155, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000940, mae: 0.022636, mean_q: 0.035857
 73663/100000: episode: 10263, duration: 0.039s, episode steps: 5, steps per second: 128, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001823, mae: 0.028857, mean_q: 0.029608
[Info] Complete ISplit Iteration
[Info] Levels: [0.04261771, 0.10882524, 0.9725355]
[Info] Cond. Prob: [0.1, 0.16, 0.07]
[Info] Error Prob: 0.0011200000000000001

 73668/100000: episode: 10264, duration: 1.084s, episode steps: 5, steps per second: 5, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001188, mae: 0.025409, mean_q: 0.039688
 73678/100000: episode: 10265, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001347, mae: 0.022619, mean_q: 0.037372
 73688/100000: episode: 10266, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001068, mae: 0.022542, mean_q: 0.036257
 73698/100000: episode: 10267, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001304, mae: 0.021211, mean_q: 0.036435
 73708/100000: episode: 10268, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001192, mae: 0.021265, mean_q: 0.033719
 73718/100000: episode: 10269, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000893, mae: 0.021562, mean_q: 0.031442
 73728/100000: episode: 10270, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001550, mae: 0.023358, mean_q: 0.042384
 73738/100000: episode: 10271, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000683, mae: 0.018171, mean_q: 0.031068
 73748/100000: episode: 10272, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001627, mae: 0.022793, mean_q: 0.031957
 73758/100000: episode: 10273, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001839, mae: 0.027734, mean_q: 0.043207
 73768/100000: episode: 10274, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001067, mae: 0.025489, mean_q: 0.037303
 73778/100000: episode: 10275, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001645, mae: 0.024359, mean_q: 0.037516
 73788/100000: episode: 10276, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001482, mae: 0.027208, mean_q: 0.031314
 73798/100000: episode: 10277, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000842, mae: 0.021698, mean_q: 0.035712
 73808/100000: episode: 10278, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001683, mae: 0.027538, mean_q: 0.040088
 73818/100000: episode: 10279, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001886, mae: 0.030002, mean_q: 0.038997
 73828/100000: episode: 10280, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001098, mae: 0.021913, mean_q: 0.037961
 73838/100000: episode: 10281, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001350, mae: 0.026173, mean_q: 0.039888
 73848/100000: episode: 10282, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000904, mae: 0.020653, mean_q: 0.032259
 73858/100000: episode: 10283, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001582, mae: 0.026247, mean_q: 0.026792
 73868/100000: episode: 10284, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001212, mae: 0.022556, mean_q: 0.024518
 73878/100000: episode: 10285, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001391, mae: 0.023489, mean_q: 0.037806
 73888/100000: episode: 10286, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001420, mae: 0.021630, mean_q: 0.025978
 73898/100000: episode: 10287, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001105, mae: 0.021986, mean_q: 0.024131
 73908/100000: episode: 10288, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001255, mae: 0.025784, mean_q: 0.028133
 73918/100000: episode: 10289, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001104, mae: 0.020354, mean_q: 0.024721
 73928/100000: episode: 10290, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.002037, mae: 0.021627, mean_q: 0.034937
 73938/100000: episode: 10291, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001330, mae: 0.028390, mean_q: 0.026644
 73948/100000: episode: 10292, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001510, mae: 0.031190, mean_q: 0.042259
 73958/100000: episode: 10293, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001063, mae: 0.023405, mean_q: 0.035065
 73968/100000: episode: 10294, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002091, mae: 0.025723, mean_q: 0.041011
 73978/100000: episode: 10295, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001345, mae: 0.028447, mean_q: 0.026011
 73988/100000: episode: 10296, duration: 0.071s, episode steps: 10, steps per second: 142, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000822, mae: 0.022994, mean_q: 0.027032
 73998/100000: episode: 10297, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000922, mae: 0.019929, mean_q: 0.022083
 74008/100000: episode: 10298, duration: 0.062s, episode steps: 10, steps per second: 163, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001680, mae: 0.024530, mean_q: 0.032778
 74018/100000: episode: 10299, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001201, mae: 0.021774, mean_q: 0.029403
 74028/100000: episode: 10300, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000638, mae: 0.017027, mean_q: 0.018723
 74038/100000: episode: 10301, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001097, mae: 0.016953, mean_q: 0.028405
 74048/100000: episode: 10302, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001152, mae: 0.021105, mean_q: 0.031464
 74058/100000: episode: 10303, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000786, mae: 0.019500, mean_q: 0.026794
 74068/100000: episode: 10304, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001968, mae: 0.026475, mean_q: 0.045796
 74078/100000: episode: 10305, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001113, mae: 0.018898, mean_q: 0.026649
 74088/100000: episode: 10306, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001040, mae: 0.022257, mean_q: 0.022821
 74098/100000: episode: 10307, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000827, mae: 0.021165, mean_q: 0.025425
 74108/100000: episode: 10308, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001089, mae: 0.020433, mean_q: 0.025503
 74118/100000: episode: 10309, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000741, mae: 0.014845, mean_q: 0.019907
 74128/100000: episode: 10310, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002442, mae: 0.029198, mean_q: 0.040378
 74138/100000: episode: 10311, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000929, mae: 0.023359, mean_q: 0.020891
 74148/100000: episode: 10312, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001573, mae: 0.024789, mean_q: 0.027491
 74158/100000: episode: 10313, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000932, mae: 0.019902, mean_q: 0.028297
 74168/100000: episode: 10314, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000420, mae: 0.012835, mean_q: 0.018171
 74178/100000: episode: 10315, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001752, mae: 0.019276, mean_q: 0.028645
 74188/100000: episode: 10316, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001301, mae: 0.029169, mean_q: 0.021920
 74198/100000: episode: 10317, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001279, mae: 0.022998, mean_q: 0.029984
 74208/100000: episode: 10318, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001557, mae: 0.020246, mean_q: 0.025260
 74218/100000: episode: 10319, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001370, mae: 0.020658, mean_q: 0.026093
 74228/100000: episode: 10320, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001331, mae: 0.023973, mean_q: 0.038816
 74238/100000: episode: 10321, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001212, mae: 0.022243, mean_q: 0.033415
 74248/100000: episode: 10322, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000834, mae: 0.017768, mean_q: 0.022169
 74258/100000: episode: 10323, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000994, mae: 0.019545, mean_q: 0.029932
 74268/100000: episode: 10324, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000800, mae: 0.019266, mean_q: 0.023699
 74278/100000: episode: 10325, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000602, mae: 0.015333, mean_q: 0.020508
 74288/100000: episode: 10326, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000313, mae: 0.010312, mean_q: 0.017103
 74298/100000: episode: 10327, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000878, mae: 0.015943, mean_q: 0.026478
 74308/100000: episode: 10328, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000558, mae: 0.014307, mean_q: 0.025123
 74318/100000: episode: 10329, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001120, mae: 0.016904, mean_q: 0.022630
 74328/100000: episode: 10330, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000413, mae: 0.011525, mean_q: 0.014939
 74338/100000: episode: 10331, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000859, mae: 0.017658, mean_q: 0.028486
 74348/100000: episode: 10332, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001451, mae: 0.019660, mean_q: 0.027269
 74358/100000: episode: 10333, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001020, mae: 0.017772, mean_q: 0.027580
 74368/100000: episode: 10334, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001024, mae: 0.019518, mean_q: 0.029017
 74378/100000: episode: 10335, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000944, mae: 0.019845, mean_q: 0.021503
 74388/100000: episode: 10336, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000938, mae: 0.018758, mean_q: 0.025680
 74398/100000: episode: 10337, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000824, mae: 0.017044, mean_q: 0.025637
 74408/100000: episode: 10338, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000721, mae: 0.020781, mean_q: 0.027810
 74418/100000: episode: 10339, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000998, mae: 0.017308, mean_q: 0.021017
 74428/100000: episode: 10340, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000946, mae: 0.017075, mean_q: 0.027250
 74438/100000: episode: 10341, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001299, mae: 0.019439, mean_q: 0.020281
 74448/100000: episode: 10342, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001273, mae: 0.018979, mean_q: 0.024793
 74458/100000: episode: 10343, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001214, mae: 0.021226, mean_q: 0.021058
 74468/100000: episode: 10344, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001110, mae: 0.021381, mean_q: 0.013705
 74478/100000: episode: 10345, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001465, mae: 0.025517, mean_q: 0.028423
 74488/100000: episode: 10346, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001043, mae: 0.020257, mean_q: 0.022630
 74498/100000: episode: 10347, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000691, mae: 0.015954, mean_q: 0.025052
 74508/100000: episode: 10348, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000728, mae: 0.016989, mean_q: 0.024715
 74518/100000: episode: 10349, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000809, mae: 0.015546, mean_q: 0.024038
 74528/100000: episode: 10350, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001395, mae: 0.017772, mean_q: 0.024840
 74538/100000: episode: 10351, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000854, mae: 0.018925, mean_q: 0.026341
 74548/100000: episode: 10352, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000832, mae: 0.014304, mean_q: 0.018913
 74558/100000: episode: 10353, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000224, mae: 0.010417, mean_q: 0.014461
 74568/100000: episode: 10354, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000913, mae: 0.014681, mean_q: 0.019821
 74578/100000: episode: 10355, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001209, mae: 0.016732, mean_q: 0.018009
 74588/100000: episode: 10356, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001143, mae: 0.020207, mean_q: 0.018588
 74598/100000: episode: 10357, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000987, mae: 0.024644, mean_q: 0.023049
 74608/100000: episode: 10358, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000551, mae: 0.016036, mean_q: 0.018968
 74618/100000: episode: 10359, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000787, mae: 0.019438, mean_q: 0.022874
 74628/100000: episode: 10360, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000619, mae: 0.017168, mean_q: 0.024133
 74638/100000: episode: 10361, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000612, mae: 0.016608, mean_q: 0.021884
 74648/100000: episode: 10362, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000853, mae: 0.019312, mean_q: 0.023117
 74658/100000: episode: 10363, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000781, mae: 0.017790, mean_q: 0.027902
[Info] 1-TH LEVEL FOUND: 0.02111595869064331, Considering 10/100 traces
 74668/100000: episode: 10364, duration: 0.719s, episode steps: 10, steps per second: 14, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001434, mae: 0.019749, mean_q: 0.028942
 74675/100000: episode: 10365, duration: 0.037s, episode steps: 7, steps per second: 191, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.001119, mae: 0.023941, mean_q: 0.025920
 74682/100000: episode: 10366, duration: 0.037s, episode steps: 7, steps per second: 188, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001701, mae: 0.018168, mean_q: 0.021886
 74689/100000: episode: 10367, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000856, mae: 0.015036, mean_q: 0.017820
 74696/100000: episode: 10368, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000882, mae: 0.020624, mean_q: 0.024768
 74703/100000: episode: 10369, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000668, mae: 0.021762, mean_q: 0.022145
 74710/100000: episode: 10370, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.001830, mae: 0.022713, mean_q: 0.026536
 74717/100000: episode: 10371, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000602, mae: 0.016616, mean_q: 0.015598
 74724/100000: episode: 10372, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000631, mae: 0.020885, mean_q: 0.027369
 74731/100000: episode: 10373, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001439, mae: 0.022232, mean_q: 0.021113
 74738/100000: episode: 10374, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.001387, mae: 0.023570, mean_q: 0.022808
 74745/100000: episode: 10375, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000907, mae: 0.021749, mean_q: 0.032091
[Info] FALSIFICATION!
 74751/100000: episode: 10376, duration: 0.254s, episode steps: 6, steps per second: 24, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.001240, mae: 0.016970, mean_q: 0.021300
 74758/100000: episode: 10377, duration: 0.042s, episode steps: 7, steps per second: 168, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.001293, mae: 0.023478, mean_q: 0.047232
 74765/100000: episode: 10378, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.002144, mae: 0.023730, mean_q: 0.037128
 74772/100000: episode: 10379, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001267, mae: 0.019850, mean_q: 0.019566
 74779/100000: episode: 10380, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001460, mae: 0.025828, mean_q: 0.033993
 74786/100000: episode: 10381, duration: 0.037s, episode steps: 7, steps per second: 187, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000637, mae: 0.016698, mean_q: 0.024294
 74793/100000: episode: 10382, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000785, mae: 0.015949, mean_q: 0.021468
 74800/100000: episode: 10383, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.001034, mae: 0.019915, mean_q: 0.031039
 74807/100000: episode: 10384, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000598, mae: 0.015202, mean_q: 0.012009
 74814/100000: episode: 10385, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001239, mae: 0.019976, mean_q: 0.023945
 74821/100000: episode: 10386, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000713, mae: 0.015525, mean_q: 0.024413
 74828/100000: episode: 10387, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000443, mae: 0.013340, mean_q: 0.020676
 74835/100000: episode: 10388, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001387, mae: 0.018737, mean_q: 0.022962
 74842/100000: episode: 10389, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001185, mae: 0.022341, mean_q: 0.032888
 74849/100000: episode: 10390, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000736, mae: 0.017754, mean_q: 0.024840
 74856/100000: episode: 10391, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001170, mae: 0.018902, mean_q: 0.032580
 74863/100000: episode: 10392, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001123, mae: 0.017069, mean_q: 0.022835
 74870/100000: episode: 10393, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.001383, mae: 0.024497, mean_q: 0.042735
 74877/100000: episode: 10394, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001064, mae: 0.022528, mean_q: 0.024555
 74884/100000: episode: 10395, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000358, mae: 0.013384, mean_q: 0.012378
 74891/100000: episode: 10396, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001051, mae: 0.020350, mean_q: 0.030543
 74898/100000: episode: 10397, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000722, mae: 0.017147, mean_q: 0.027871
 74905/100000: episode: 10398, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000349, mae: 0.012780, mean_q: 0.011469
 74912/100000: episode: 10399, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001189, mae: 0.017837, mean_q: 0.023709
 74919/100000: episode: 10400, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000558, mae: 0.016496, mean_q: 0.026911
 74926/100000: episode: 10401, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000570, mae: 0.017149, mean_q: 0.024556
 74933/100000: episode: 10402, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000731, mae: 0.019344, mean_q: 0.021478
 74940/100000: episode: 10403, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000744, mae: 0.019248, mean_q: 0.027698
 74947/100000: episode: 10404, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000808, mae: 0.018173, mean_q: 0.022783
 74954/100000: episode: 10405, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000515, mae: 0.016126, mean_q: 0.024578
 74961/100000: episode: 10406, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000629, mae: 0.017330, mean_q: 0.017910
 74968/100000: episode: 10407, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000505, mae: 0.013605, mean_q: 0.016974
 74975/100000: episode: 10408, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001457, mae: 0.025511, mean_q: 0.035295
 74982/100000: episode: 10409, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 1.947, mean reward: 0.278 [0.007, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 7.857 [5.000, 11.000], loss: 0.001154, mae: 0.023677, mean_q: 0.028292
 74989/100000: episode: 10410, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000551, mae: 0.015679, mean_q: 0.013861
 74996/100000: episode: 10411, duration: 0.035s, episode steps: 7, steps per second: 197, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000895, mae: 0.016862, mean_q: 0.020612
 75003/100000: episode: 10412, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000928, mae: 0.018855, mean_q: 0.022632
 75010/100000: episode: 10413, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000400, mae: 0.014084, mean_q: 0.018835
 75017/100000: episode: 10414, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.001386, mae: 0.023180, mean_q: 0.031105
 75024/100000: episode: 10415, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001120, mae: 0.024780, mean_q: 0.022124
 75031/100000: episode: 10416, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000359, mae: 0.017854, mean_q: 0.013092
 75038/100000: episode: 10417, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000632, mae: 0.014946, mean_q: 0.025825
 75045/100000: episode: 10418, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001721, mae: 0.020934, mean_q: 0.032500
 75052/100000: episode: 10419, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001751, mae: 0.024952, mean_q: 0.024085
 75059/100000: episode: 10420, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000813, mae: 0.023171, mean_q: 0.030607
 75066/100000: episode: 10421, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001078, mae: 0.026381, mean_q: 0.039174
 75073/100000: episode: 10422, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001673, mae: 0.022821, mean_q: 0.021649
 75080/100000: episode: 10423, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000822, mae: 0.021845, mean_q: 0.034431
 75087/100000: episode: 10424, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000762, mae: 0.020618, mean_q: 0.025121
 75094/100000: episode: 10425, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.002061, mae: 0.027619, mean_q: 0.036961
 75101/100000: episode: 10426, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001222, mae: 0.023517, mean_q: 0.033914
 75108/100000: episode: 10427, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000836, mae: 0.020078, mean_q: 0.032878
 75115/100000: episode: 10428, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001427, mae: 0.019780, mean_q: 0.034245
 75122/100000: episode: 10429, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.001480, mae: 0.024742, mean_q: 0.038298
 75129/100000: episode: 10430, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000883, mae: 0.023401, mean_q: 0.027656
 75136/100000: episode: 10431, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.001359, mae: 0.024240, mean_q: 0.042966
 75143/100000: episode: 10432, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.001082, mae: 0.022540, mean_q: 0.023313
 75150/100000: episode: 10433, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000504, mae: 0.017999, mean_q: 0.025930
 75157/100000: episode: 10434, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001082, mae: 0.018039, mean_q: 0.026351
 75164/100000: episode: 10435, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000989, mae: 0.018520, mean_q: 0.033428
 75171/100000: episode: 10436, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000522, mae: 0.015104, mean_q: 0.024528
 75178/100000: episode: 10437, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000823, mae: 0.014601, mean_q: 0.019075
 75185/100000: episode: 10438, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.001677, mae: 0.025755, mean_q: 0.038001
 75192/100000: episode: 10439, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000600, mae: 0.018414, mean_q: 0.025577
 75199/100000: episode: 10440, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001789, mae: 0.022446, mean_q: 0.030008
 75206/100000: episode: 10441, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.002272, mae: 0.027566, mean_q: 0.034273
 75213/100000: episode: 10442, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001802, mae: 0.022577, mean_q: 0.040188
 75220/100000: episode: 10443, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001140, mae: 0.025854, mean_q: 0.027362
 75227/100000: episode: 10444, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001660, mae: 0.026055, mean_q: 0.035539
 75234/100000: episode: 10445, duration: 0.043s, episode steps: 7, steps per second: 164, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001295, mae: 0.020276, mean_q: 0.023882
 75241/100000: episode: 10446, duration: 0.039s, episode steps: 7, steps per second: 180, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001892, mae: 0.023196, mean_q: 0.024130
 75248/100000: episode: 10447, duration: 0.035s, episode steps: 7, steps per second: 197, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001155, mae: 0.020747, mean_q: 0.017563
 75255/100000: episode: 10448, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001478, mae: 0.027914, mean_q: 0.039735
 75262/100000: episode: 10449, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000740, mae: 0.024438, mean_q: 0.014364
 75269/100000: episode: 10450, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000662, mae: 0.017325, mean_q: 0.012933
 75276/100000: episode: 10451, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000914, mae: 0.025536, mean_q: 0.040174
 75283/100000: episode: 10452, duration: 0.037s, episode steps: 7, steps per second: 192, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.001835, mae: 0.030606, mean_q: 0.041778
[Info] FALSIFICATION!
 75289/100000: episode: 10453, duration: 0.268s, episode steps: 6, steps per second: 22, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.001953, mae: 0.029629, mean_q: 0.028306
[Info] Complete ISplit Iteration
[Info] Levels: [0.021115959, 1.1115764]
[Info] Cond. Prob: [0.1, 0.02]
[Info] Error Prob: 0.002

 75296/100000: episode: 10454, duration: 0.875s, episode steps: 7, steps per second: 8, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001869, mae: 0.028562, mean_q: 0.045081
 75306/100000: episode: 10455, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000909, mae: 0.022205, mean_q: 0.028280
 75316/100000: episode: 10456, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001805, mae: 0.027270, mean_q: 0.037587
 75326/100000: episode: 10457, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001019, mae: 0.022694, mean_q: 0.034148
 75336/100000: episode: 10458, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000662, mae: 0.017339, mean_q: 0.027142
 75346/100000: episode: 10459, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001055, mae: 0.023150, mean_q: 0.036679
 75356/100000: episode: 10460, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000531, mae: 0.015514, mean_q: 0.022372
 75366/100000: episode: 10461, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002053, mae: 0.022782, mean_q: 0.026790
 75376/100000: episode: 10462, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000685, mae: 0.020710, mean_q: 0.029272
 75386/100000: episode: 10463, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001160, mae: 0.020222, mean_q: 0.032800
 75396/100000: episode: 10464, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001815, mae: 0.028118, mean_q: 0.038840
 75406/100000: episode: 10465, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001091, mae: 0.019411, mean_q: 0.024108
 75416/100000: episode: 10466, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001792, mae: 0.028008, mean_q: 0.031560
 75426/100000: episode: 10467, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001065, mae: 0.026861, mean_q: 0.021703
 75436/100000: episode: 10468, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001687, mae: 0.027581, mean_q: 0.029897
 75446/100000: episode: 10469, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000828, mae: 0.020714, mean_q: 0.024431
 75456/100000: episode: 10470, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000842, mae: 0.019824, mean_q: 0.024777
 75466/100000: episode: 10471, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001136, mae: 0.022633, mean_q: 0.026758
 75476/100000: episode: 10472, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001023, mae: 0.019734, mean_q: 0.028607
 75486/100000: episode: 10473, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000680, mae: 0.017518, mean_q: 0.022529
 75496/100000: episode: 10474, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000647, mae: 0.017761, mean_q: 0.024878
 75506/100000: episode: 10475, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001109, mae: 0.019827, mean_q: 0.024472
 75516/100000: episode: 10476, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000999, mae: 0.022218, mean_q: 0.022125
 75526/100000: episode: 10477, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000709, mae: 0.021891, mean_q: 0.027546
 75536/100000: episode: 10478, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001499, mae: 0.022290, mean_q: 0.031337
 75546/100000: episode: 10479, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001427, mae: 0.027296, mean_q: 0.035187
 75556/100000: episode: 10480, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001387, mae: 0.027129, mean_q: 0.034290
 75566/100000: episode: 10481, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002425, mae: 0.027203, mean_q: 0.036783
 75576/100000: episode: 10482, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000741, mae: 0.019340, mean_q: 0.022184
 75586/100000: episode: 10483, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001892, mae: 0.022774, mean_q: 0.032298
 75596/100000: episode: 10484, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000719, mae: 0.020710, mean_q: 0.022027
 75606/100000: episode: 10485, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002105, mae: 0.026703, mean_q: 0.038750
 75616/100000: episode: 10486, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000897, mae: 0.020448, mean_q: 0.027685
 75626/100000: episode: 10487, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002083, mae: 0.023488, mean_q: 0.029153
 75636/100000: episode: 10488, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000896, mae: 0.018770, mean_q: 0.025015
 75646/100000: episode: 10489, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001162, mae: 0.020231, mean_q: 0.030590
 75656/100000: episode: 10490, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001095, mae: 0.019151, mean_q: 0.027736
 75666/100000: episode: 10491, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000963, mae: 0.017019, mean_q: 0.026427
 75676/100000: episode: 10492, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000687, mae: 0.016138, mean_q: 0.026593
 75686/100000: episode: 10493, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001005, mae: 0.017923, mean_q: 0.029704
 75696/100000: episode: 10494, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001790, mae: 0.021379, mean_q: 0.027062
 75706/100000: episode: 10495, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000952, mae: 0.024866, mean_q: 0.020322
 75716/100000: episode: 10496, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001104, mae: 0.023744, mean_q: 0.028975
 75726/100000: episode: 10497, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001522, mae: 0.025463, mean_q: 0.033601
 75736/100000: episode: 10498, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000978, mae: 0.024159, mean_q: 0.026074
 75746/100000: episode: 10499, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001960, mae: 0.025254, mean_q: 0.031592
 75756/100000: episode: 10500, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000782, mae: 0.021893, mean_q: 0.024268
 75766/100000: episode: 10501, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001101, mae: 0.020709, mean_q: 0.027577
 75776/100000: episode: 10502, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001426, mae: 0.020004, mean_q: 0.034588
 75786/100000: episode: 10503, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001408, mae: 0.021808, mean_q: 0.033869
 75796/100000: episode: 10504, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000745, mae: 0.016761, mean_q: 0.021437
 75806/100000: episode: 10505, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001402, mae: 0.021814, mean_q: 0.028275
 75816/100000: episode: 10506, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000700, mae: 0.019957, mean_q: 0.021577
 75826/100000: episode: 10507, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000714, mae: 0.018471, mean_q: 0.025412
 75836/100000: episode: 10508, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001177, mae: 0.016339, mean_q: 0.021240
 75846/100000: episode: 10509, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000620, mae: 0.017608, mean_q: 0.025889
 75856/100000: episode: 10510, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001615, mae: 0.020213, mean_q: 0.026605
 75866/100000: episode: 10511, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001753, mae: 0.020549, mean_q: 0.034051
 75876/100000: episode: 10512, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001914, mae: 0.023091, mean_q: 0.025921
 75886/100000: episode: 10513, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001438, mae: 0.024049, mean_q: 0.022315
 75896/100000: episode: 10514, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000991, mae: 0.021476, mean_q: 0.029955
 75906/100000: episode: 10515, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000543, mae: 0.016064, mean_q: 0.021782
 75916/100000: episode: 10516, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001315, mae: 0.018277, mean_q: 0.025241
 75926/100000: episode: 10517, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000882, mae: 0.017415, mean_q: 0.021147
 75936/100000: episode: 10518, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000588, mae: 0.015298, mean_q: 0.022929
 75946/100000: episode: 10519, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000990, mae: 0.015396, mean_q: 0.020784
 75956/100000: episode: 10520, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001669, mae: 0.020831, mean_q: 0.032488
 75966/100000: episode: 10521, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000998, mae: 0.017747, mean_q: 0.022054
 75976/100000: episode: 10522, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000978, mae: 0.019660, mean_q: 0.026063
 75986/100000: episode: 10523, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001599, mae: 0.019681, mean_q: 0.028769
 75996/100000: episode: 10524, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000748, mae: 0.016322, mean_q: 0.020525
 76006/100000: episode: 10525, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000828, mae: 0.018840, mean_q: 0.025785
 76016/100000: episode: 10526, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000707, mae: 0.018052, mean_q: 0.025555
 76026/100000: episode: 10527, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000874, mae: 0.013425, mean_q: 0.018587
 76036/100000: episode: 10528, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000924, mae: 0.017755, mean_q: 0.023057
 76046/100000: episode: 10529, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000708, mae: 0.012643, mean_q: 0.018851
 76056/100000: episode: 10530, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001365, mae: 0.021350, mean_q: 0.028115
 76066/100000: episode: 10531, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001051, mae: 0.015064, mean_q: 0.016326
 76076/100000: episode: 10532, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000518, mae: 0.017148, mean_q: 0.023162
 76086/100000: episode: 10533, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000694, mae: 0.014174, mean_q: 0.018948
 76096/100000: episode: 10534, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001089, mae: 0.018119, mean_q: 0.028346
 76106/100000: episode: 10535, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000521, mae: 0.014399, mean_q: 0.016468
 76116/100000: episode: 10536, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000642, mae: 0.012748, mean_q: 0.017067
 76126/100000: episode: 10537, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000765, mae: 0.014564, mean_q: 0.027589
 76136/100000: episode: 10538, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000288, mae: 0.011524, mean_q: 0.018929
 76146/100000: episode: 10539, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001229, mae: 0.016784, mean_q: 0.024775
 76156/100000: episode: 10540, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000556, mae: 0.012760, mean_q: 0.019760
 76166/100000: episode: 10541, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000456, mae: 0.013570, mean_q: 0.020700
 76176/100000: episode: 10542, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000965, mae: 0.015084, mean_q: 0.021050
 76186/100000: episode: 10543, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000707, mae: 0.015467, mean_q: 0.016124
 76196/100000: episode: 10544, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000723, mae: 0.015132, mean_q: 0.023279
 76206/100000: episode: 10545, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000909, mae: 0.015318, mean_q: 0.017361
 76216/100000: episode: 10546, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000809, mae: 0.016454, mean_q: 0.024817
 76226/100000: episode: 10547, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000665, mae: 0.016285, mean_q: 0.022377
 76236/100000: episode: 10548, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001288, mae: 0.016760, mean_q: 0.022749
 76246/100000: episode: 10549, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000926, mae: 0.017427, mean_q: 0.023071
 76256/100000: episode: 10550, duration: 0.091s, episode steps: 10, steps per second: 109, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000557, mae: 0.012320, mean_q: 0.013787
 76266/100000: episode: 10551, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000478, mae: 0.012432, mean_q: 0.020334
 76276/100000: episode: 10552, duration: 0.111s, episode steps: 10, steps per second: 90, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001027, mae: 0.016387, mean_q: 0.025658
 76286/100000: episode: 10553, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001177, mae: 0.017253, mean_q: 0.028996
[Info] 1-TH LEVEL FOUND: 0.016989290714263916, Considering 20/100 traces
 76296/100000: episode: 10554, duration: 1.091s, episode steps: 10, steps per second: 9, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000996, mae: 0.017078, mean_q: 0.017885
 76298/100000: episode: 10555, duration: 0.023s, episode steps: 2, steps per second: 86, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001075, mae: 0.017757, mean_q: 0.024565
 76303/100000: episode: 10556, duration: 0.070s, episode steps: 5, steps per second: 72, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001418, mae: 0.023854, mean_q: 0.029291
 76310/100000: episode: 10557, duration: 0.089s, episode steps: 7, steps per second: 78, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000285, mae: 0.015358, mean_q: 0.013416
 76312/100000: episode: 10558, duration: 0.020s, episode steps: 2, steps per second: 99, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000551, mae: 0.017439, mean_q: 0.022061
 76317/100000: episode: 10559, duration: 0.046s, episode steps: 5, steps per second: 109, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.001159, mae: 0.018048, mean_q: 0.027502
 76324/100000: episode: 10560, duration: 0.060s, episode steps: 7, steps per second: 117, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000951, mae: 0.015615, mean_q: 0.018892
 76326/100000: episode: 10561, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000862, mae: 0.014138, mean_q: 0.017698
 76333/100000: episode: 10562, duration: 0.052s, episode steps: 7, steps per second: 134, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000968, mae: 0.016014, mean_q: 0.025361
 76340/100000: episode: 10563, duration: 0.059s, episode steps: 7, steps per second: 118, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000196, mae: 0.010830, mean_q: 0.018356
 76342/100000: episode: 10564, duration: 0.024s, episode steps: 2, steps per second: 84, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000288, mae: 0.012110, mean_q: 0.016975
 76344/100000: episode: 10565, duration: 0.028s, episode steps: 2, steps per second: 71, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000447, mae: 0.015295, mean_q: 0.027743
 76346/100000: episode: 10566, duration: 0.024s, episode steps: 2, steps per second: 82, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001164, mae: 0.021144, mean_q: 0.040894
 76348/100000: episode: 10567, duration: 0.029s, episode steps: 2, steps per second: 68, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000615, mae: 0.018038, mean_q: 0.029472
 76350/100000: episode: 10568, duration: 0.019s, episode steps: 2, steps per second: 103, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000145, mae: 0.011570, mean_q: 0.003448
 76355/100000: episode: 10569, duration: 0.071s, episode steps: 5, steps per second: 70, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000582, mae: 0.015767, mean_q: 0.026368
 76357/100000: episode: 10570, duration: 0.024s, episode steps: 2, steps per second: 83, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003634, mae: 0.031104, mean_q: 0.054252
 76359/100000: episode: 10571, duration: 0.021s, episode steps: 2, steps per second: 96, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000543, mae: 0.013684, mean_q: 0.021034
 76361/100000: episode: 10572, duration: 0.026s, episode steps: 2, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000703, mae: 0.016020, mean_q: 0.017809
 76368/100000: episode: 10573, duration: 0.045s, episode steps: 7, steps per second: 155, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001111, mae: 0.017374, mean_q: 0.024587
 76370/100000: episode: 10574, duration: 0.025s, episode steps: 2, steps per second: 80, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000204, mae: 0.013060, mean_q: 0.021032
 76377/100000: episode: 10575, duration: 0.067s, episode steps: 7, steps per second: 104, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.000730, mae: 0.015017, mean_q: 0.017023
 76379/100000: episode: 10576, duration: 0.015s, episode steps: 2, steps per second: 130, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000569, mae: 0.017901, mean_q: 0.035767
 76386/100000: episode: 10577, duration: 0.055s, episode steps: 7, steps per second: 126, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000797, mae: 0.016467, mean_q: 0.016955
 76388/100000: episode: 10578, duration: 0.022s, episode steps: 2, steps per second: 90, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002564, mae: 0.026740, mean_q: 0.054910
 76390/100000: episode: 10579, duration: 0.026s, episode steps: 2, steps per second: 76, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000478, mae: 0.015694, mean_q: 0.022915
 76397/100000: episode: 10580, duration: 0.066s, episode steps: 7, steps per second: 106, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000492, mae: 0.014619, mean_q: 0.021631
 76404/100000: episode: 10581, duration: 0.070s, episode steps: 7, steps per second: 100, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001612, mae: 0.020909, mean_q: 0.036352
 76406/100000: episode: 10582, duration: 0.020s, episode steps: 2, steps per second: 99, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000290, mae: 0.012910, mean_q: 0.018395
 76408/100000: episode: 10583, duration: 0.021s, episode steps: 2, steps per second: 97, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001019, mae: 0.021387, mean_q: 0.044042
 76413/100000: episode: 10584, duration: 0.033s, episode steps: 5, steps per second: 153, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.001518, mae: 0.019310, mean_q: 0.037591
 76418/100000: episode: 10585, duration: 0.037s, episode steps: 5, steps per second: 136, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000486, mae: 0.018559, mean_q: 0.029106
 76425/100000: episode: 10586, duration: 0.039s, episode steps: 7, steps per second: 178, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.001030, mae: 0.018498, mean_q: 0.021967
 76430/100000: episode: 10587, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000565, mae: 0.017511, mean_q: 0.033646
 76432/100000: episode: 10588, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000514, mae: 0.018117, mean_q: -0.000580
[Info] FALSIFICATION!
 76438/100000: episode: 10589, duration: 0.304s, episode steps: 6, steps per second: 20, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000377, mae: 0.017086, mean_q: 0.025789
 76440/100000: episode: 10590, duration: 0.038s, episode steps: 2, steps per second: 53, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000217, mae: 0.013777, mean_q: 0.003525
 76442/100000: episode: 10591, duration: 0.032s, episode steps: 2, steps per second: 62, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000177, mae: 0.011592, mean_q: 0.011872
 76444/100000: episode: 10592, duration: 0.021s, episode steps: 2, steps per second: 95, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000615, mae: 0.022980, mean_q: 0.039322
 76449/100000: episode: 10593, duration: 0.036s, episode steps: 5, steps per second: 139, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000581, mae: 0.018820, mean_q: 0.020160
 76451/100000: episode: 10594, duration: 0.031s, episode steps: 2, steps per second: 64, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002511, mae: 0.027626, mean_q: 0.060875
 76453/100000: episode: 10595, duration: 0.022s, episode steps: 2, steps per second: 93, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000254, mae: 0.012302, mean_q: 0.005403
 76455/100000: episode: 10596, duration: 0.015s, episode steps: 2, steps per second: 129, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000030, mae: 0.005328, mean_q: 0.005238
 76462/100000: episode: 10597, duration: 0.040s, episode steps: 7, steps per second: 173, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000992, mae: 0.018076, mean_q: 0.023833
 76469/100000: episode: 10598, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000993, mae: 0.015332, mean_q: 0.020992
 76476/100000: episode: 10599, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000805, mae: 0.017619, mean_q: 0.026123
 76478/100000: episode: 10600, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001138, mae: 0.018246, mean_q: 0.036886
 76480/100000: episode: 10601, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000552, mae: 0.016633, mean_q: 0.021936
 76482/100000: episode: 10602, duration: 0.017s, episode steps: 2, steps per second: 115, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000560, mae: 0.017559, mean_q: 0.017927
 76484/100000: episode: 10603, duration: 0.014s, episode steps: 2, steps per second: 143, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001142, mae: 0.022724, mean_q: 0.041917
 76486/100000: episode: 10604, duration: 0.015s, episode steps: 2, steps per second: 132, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000355, mae: 0.010559, mean_q: 0.017056
 76488/100000: episode: 10605, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000567, mae: 0.014324, mean_q: 0.007968
 76493/100000: episode: 10606, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000518, mae: 0.016360, mean_q: 0.021750
 76495/100000: episode: 10607, duration: 0.031s, episode steps: 2, steps per second: 65, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000573, mae: 0.015988, mean_q: 0.031866
 76500/100000: episode: 10608, duration: 0.062s, episode steps: 5, steps per second: 81, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.001141, mae: 0.018514, mean_q: 0.018943
 76505/100000: episode: 10609, duration: 0.044s, episode steps: 5, steps per second: 113, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000465, mae: 0.016123, mean_q: 0.016694
 76507/100000: episode: 10610, duration: 0.020s, episode steps: 2, steps per second: 101, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001212, mae: 0.023203, mean_q: 0.032830
 76509/100000: episode: 10611, duration: 0.015s, episode steps: 2, steps per second: 130, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001749, mae: 0.020035, mean_q: 0.025868
 76516/100000: episode: 10612, duration: 0.056s, episode steps: 7, steps per second: 124, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000854, mae: 0.018776, mean_q: 0.029763
 76523/100000: episode: 10613, duration: 0.077s, episode steps: 7, steps per second: 91, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000971, mae: 0.018276, mean_q: 0.018245
 76525/100000: episode: 10614, duration: 0.014s, episode steps: 2, steps per second: 144, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001773, mae: 0.025280, mean_q: 0.038837
 76527/100000: episode: 10615, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000163, mae: 0.010391, mean_q: 0.018436
 76529/100000: episode: 10616, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001524, mae: 0.019781, mean_q: 0.032449
 76531/100000: episode: 10617, duration: 0.015s, episode steps: 2, steps per second: 130, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001303, mae: 0.019795, mean_q: 0.028824
 76533/100000: episode: 10618, duration: 0.016s, episode steps: 2, steps per second: 128, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000203, mae: 0.012316, mean_q: 0.020256
 76535/100000: episode: 10619, duration: 0.017s, episode steps: 2, steps per second: 118, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001548, mae: 0.021401, mean_q: 0.032028
 76537/100000: episode: 10620, duration: 0.019s, episode steps: 2, steps per second: 103, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000230, mae: 0.012980, mean_q: 0.002865
 76539/100000: episode: 10621, duration: 0.028s, episode steps: 2, steps per second: 73, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000155, mae: 0.009898, mean_q: 0.007929
 76541/100000: episode: 10622, duration: 0.017s, episode steps: 2, steps per second: 119, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000698, mae: 0.019669, mean_q: 0.033355
 76543/100000: episode: 10623, duration: 0.015s, episode steps: 2, steps per second: 132, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000780, mae: 0.014649, mean_q: 0.008766
 76545/100000: episode: 10624, duration: 0.020s, episode steps: 2, steps per second: 101, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001032, mae: 0.013843, mean_q: 0.016260
 76547/100000: episode: 10625, duration: 0.018s, episode steps: 2, steps per second: 113, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001677, mae: 0.025615, mean_q: 0.045566
 76549/100000: episode: 10626, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001473, mae: 0.019021, mean_q: 0.034451
 76551/100000: episode: 10627, duration: 0.014s, episode steps: 2, steps per second: 139, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001373, mae: 0.022403, mean_q: 0.008029
 76553/100000: episode: 10628, duration: 0.015s, episode steps: 2, steps per second: 130, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002867, mae: 0.027789, mean_q: 0.041259
 76555/100000: episode: 10629, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001084, mae: 0.025480, mean_q: 0.046847
 76557/100000: episode: 10630, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000348, mae: 0.018544, mean_q: 0.007610
 76562/100000: episode: 10631, duration: 0.039s, episode steps: 5, steps per second: 128, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000526, mae: 0.016851, mean_q: 0.021298
 76567/100000: episode: 10632, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000530, mae: 0.013963, mean_q: 0.015821
 76574/100000: episode: 10633, duration: 0.047s, episode steps: 7, steps per second: 147, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000797, mae: 0.018774, mean_q: 0.029307
[Info] Complete ISplit Iteration
[Info] Levels: [0.01698929, 1.1084741]
[Info] Cond. Prob: [0.2, 0.01]
[Info] Error Prob: 0.002

 76581/100000: episode: 10634, duration: 0.998s, episode steps: 7, steps per second: 7, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000646, mae: 0.019218, mean_q: 0.019652
 76591/100000: episode: 10635, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000230, mae: 0.011353, mean_q: 0.015831
 76601/100000: episode: 10636, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000722, mae: 0.014157, mean_q: 0.021625
 76611/100000: episode: 10637, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001271, mae: 0.016705, mean_q: 0.023255
 76621/100000: episode: 10638, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000551, mae: 0.015617, mean_q: 0.019504
 76631/100000: episode: 10639, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000746, mae: 0.018868, mean_q: 0.018007
 76641/100000: episode: 10640, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001318, mae: 0.024705, mean_q: 0.028020
 76651/100000: episode: 10641, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000985, mae: 0.022283, mean_q: 0.020483
 76661/100000: episode: 10642, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001039, mae: 0.017228, mean_q: 0.029135
 76671/100000: episode: 10643, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000473, mae: 0.015976, mean_q: 0.019046
 76681/100000: episode: 10644, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000985, mae: 0.017727, mean_q: 0.021625
 76691/100000: episode: 10645, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000473, mae: 0.016402, mean_q: 0.022301
 76701/100000: episode: 10646, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001280, mae: 0.018913, mean_q: 0.027663
 76711/100000: episode: 10647, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000726, mae: 0.018322, mean_q: 0.025213
 76721/100000: episode: 10648, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001123, mae: 0.018938, mean_q: 0.023020
 76731/100000: episode: 10649, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001043, mae: 0.017183, mean_q: 0.024937
 76741/100000: episode: 10650, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001247, mae: 0.019734, mean_q: 0.024608
 76751/100000: episode: 10651, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000448, mae: 0.014370, mean_q: 0.020207
 76761/100000: episode: 10652, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001108, mae: 0.020473, mean_q: 0.031360
 76771/100000: episode: 10653, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001507, mae: 0.019434, mean_q: 0.028871
 76781/100000: episode: 10654, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000526, mae: 0.015147, mean_q: 0.016602
 76791/100000: episode: 10655, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000564, mae: 0.015957, mean_q: 0.016789
 76801/100000: episode: 10656, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001552, mae: 0.028019, mean_q: 0.032876
 76811/100000: episode: 10657, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000794, mae: 0.019061, mean_q: 0.022564
 76821/100000: episode: 10658, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001457, mae: 0.021740, mean_q: 0.029434
 76831/100000: episode: 10659, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000813, mae: 0.016858, mean_q: 0.031099
 76841/100000: episode: 10660, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001011, mae: 0.019147, mean_q: 0.025335
 76851/100000: episode: 10661, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000768, mae: 0.017819, mean_q: 0.023440
 76861/100000: episode: 10662, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000783, mae: 0.016922, mean_q: 0.024162
 76871/100000: episode: 10663, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000473, mae: 0.014462, mean_q: 0.019866
 76881/100000: episode: 10664, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000526, mae: 0.013163, mean_q: 0.019419
 76891/100000: episode: 10665, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000483, mae: 0.014722, mean_q: 0.021723
 76901/100000: episode: 10666, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000759, mae: 0.017251, mean_q: 0.030586
 76911/100000: episode: 10667, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001079, mae: 0.019381, mean_q: 0.028859
 76921/100000: episode: 10668, duration: 0.071s, episode steps: 10, steps per second: 140, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000521, mae: 0.017134, mean_q: 0.024742
 76931/100000: episode: 10669, duration: 0.083s, episode steps: 10, steps per second: 121, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001379, mae: 0.018768, mean_q: 0.025519
 76941/100000: episode: 10670, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000610, mae: 0.016868, mean_q: 0.024198
 76951/100000: episode: 10671, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000760, mae: 0.020231, mean_q: 0.021703
 76961/100000: episode: 10672, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000506, mae: 0.019232, mean_q: 0.021295
 76971/100000: episode: 10673, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001646, mae: 0.021598, mean_q: 0.027595
 76981/100000: episode: 10674, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001756, mae: 0.021900, mean_q: 0.031050
 76991/100000: episode: 10675, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000606, mae: 0.016965, mean_q: 0.015777
 77001/100000: episode: 10676, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000996, mae: 0.020159, mean_q: 0.020225
 77011/100000: episode: 10677, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000495, mae: 0.014415, mean_q: 0.016101
 77021/100000: episode: 10678, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000569, mae: 0.018227, mean_q: 0.029852
 77031/100000: episode: 10679, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000942, mae: 0.018057, mean_q: 0.026691
 77041/100000: episode: 10680, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000630, mae: 0.016616, mean_q: 0.022098
 77051/100000: episode: 10681, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001120, mae: 0.016280, mean_q: 0.024649
 77061/100000: episode: 10682, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001018, mae: 0.019675, mean_q: 0.025524
 77071/100000: episode: 10683, duration: 0.109s, episode steps: 10, steps per second: 92, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001234, mae: 0.021011, mean_q: 0.027442
 77081/100000: episode: 10684, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000876, mae: 0.016865, mean_q: 0.023530
 77091/100000: episode: 10685, duration: 0.094s, episode steps: 10, steps per second: 107, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001143, mae: 0.018507, mean_q: 0.032014
 77101/100000: episode: 10686, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000444, mae: 0.013903, mean_q: 0.016628
 77111/100000: episode: 10687, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001265, mae: 0.018242, mean_q: 0.023250
 77121/100000: episode: 10688, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000982, mae: 0.018784, mean_q: 0.019200
 77131/100000: episode: 10689, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000980, mae: 0.019476, mean_q: 0.024274
 77141/100000: episode: 10690, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001238, mae: 0.019365, mean_q: 0.018347
 77151/100000: episode: 10691, duration: 0.060s, episode steps: 10, steps per second: 165, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000556, mae: 0.016103, mean_q: 0.021681
 77161/100000: episode: 10692, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001158, mae: 0.020702, mean_q: 0.030982
 77171/100000: episode: 10693, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000619, mae: 0.013526, mean_q: 0.018886
 77181/100000: episode: 10694, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000491, mae: 0.015264, mean_q: 0.017186
 77191/100000: episode: 10695, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000562, mae: 0.015017, mean_q: 0.017772
 77201/100000: episode: 10696, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000676, mae: 0.019858, mean_q: 0.019104
 77211/100000: episode: 10697, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000900, mae: 0.015425, mean_q: 0.019438
 77221/100000: episode: 10698, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000437, mae: 0.015821, mean_q: 0.020895
 77231/100000: episode: 10699, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000418, mae: 0.015055, mean_q: 0.018271
 77241/100000: episode: 10700, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000917, mae: 0.018904, mean_q: 0.020960
 77251/100000: episode: 10701, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001007, mae: 0.019347, mean_q: 0.027590
 77261/100000: episode: 10702, duration: 0.071s, episode steps: 10, steps per second: 142, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000653, mae: 0.018294, mean_q: 0.023562
 77271/100000: episode: 10703, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000468, mae: 0.012610, mean_q: 0.022831
 77281/100000: episode: 10704, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001107, mae: 0.016746, mean_q: 0.026080
 77291/100000: episode: 10705, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001121, mae: 0.016460, mean_q: 0.015418
 77301/100000: episode: 10706, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001445, mae: 0.019918, mean_q: 0.021904
 77311/100000: episode: 10707, duration: 0.105s, episode steps: 10, steps per second: 95, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000699, mae: 0.018250, mean_q: 0.016739
 77321/100000: episode: 10708, duration: 0.069s, episode steps: 10, steps per second: 146, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000605, mae: 0.015290, mean_q: 0.021099
 77331/100000: episode: 10709, duration: 0.088s, episode steps: 10, steps per second: 113, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000594, mae: 0.016307, mean_q: 0.018545
 77341/100000: episode: 10710, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000631, mae: 0.017643, mean_q: 0.023611
 77351/100000: episode: 10711, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000706, mae: 0.014892, mean_q: 0.030308
 77361/100000: episode: 10712, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000663, mae: 0.015520, mean_q: 0.024402
 77371/100000: episode: 10713, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001134, mae: 0.017942, mean_q: 0.024194
 77381/100000: episode: 10714, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001025, mae: 0.023917, mean_q: 0.031846
 77391/100000: episode: 10715, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000744, mae: 0.016756, mean_q: 0.016731
 77401/100000: episode: 10716, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000924, mae: 0.018954, mean_q: 0.024420
 77411/100000: episode: 10717, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000684, mae: 0.016202, mean_q: 0.020668
 77421/100000: episode: 10718, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000827, mae: 0.015943, mean_q: 0.018949
 77431/100000: episode: 10719, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000913, mae: 0.019106, mean_q: 0.030262
 77441/100000: episode: 10720, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000595, mae: 0.015415, mean_q: 0.023437
 77451/100000: episode: 10721, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001199, mae: 0.017989, mean_q: 0.021852
 77461/100000: episode: 10722, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001058, mae: 0.017775, mean_q: 0.026831
 77471/100000: episode: 10723, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000364, mae: 0.013623, mean_q: 0.015439
 77481/100000: episode: 10724, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001121, mae: 0.019935, mean_q: 0.026936
 77491/100000: episode: 10725, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000651, mae: 0.013998, mean_q: 0.019338
 77501/100000: episode: 10726, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000669, mae: 0.014385, mean_q: 0.020368
 77511/100000: episode: 10727, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000827, mae: 0.016900, mean_q: 0.021900
 77521/100000: episode: 10728, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001105, mae: 0.017234, mean_q: 0.024294
 77531/100000: episode: 10729, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000760, mae: 0.016226, mean_q: 0.017891
 77541/100000: episode: 10730, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000251, mae: 0.011958, mean_q: 0.012598
 77551/100000: episode: 10731, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001674, mae: 0.016969, mean_q: 0.025804
 77561/100000: episode: 10732, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001286, mae: 0.019827, mean_q: 0.021143
 77571/100000: episode: 10733, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000989, mae: 0.017877, mean_q: 0.024207
[Info] 1-TH LEVEL FOUND: 0.014974802732467651, Considering 100/100 traces
 77581/100000: episode: 10734, duration: 0.718s, episode steps: 10, steps per second: 14, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000818, mae: 0.016366, mean_q: 0.019794
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.014974802732467651
 77582/100000: episode: 10735, duration: 0.537s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000111, mae: 0.009834, mean_q: 0.010477
 77592/100000: episode: 10736, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000731, mae: 0.014889, mean_q: 0.017775
 77602/100000: episode: 10737, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000318, mae: 0.009408, mean_q: 0.013145
 77612/100000: episode: 10738, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000659, mae: 0.011624, mean_q: 0.018756
 77622/100000: episode: 10739, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000966, mae: 0.014532, mean_q: 0.017557
 77632/100000: episode: 10740, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000944, mae: 0.015172, mean_q: 0.019556
 77642/100000: episode: 10741, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000950, mae: 0.013104, mean_q: 0.017272
 77652/100000: episode: 10742, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001245, mae: 0.016497, mean_q: 0.029167
 77662/100000: episode: 10743, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001210, mae: 0.015543, mean_q: 0.028525
 77672/100000: episode: 10744, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000723, mae: 0.011400, mean_q: 0.017982
 77682/100000: episode: 10745, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000795, mae: 0.014209, mean_q: 0.020128
 77692/100000: episode: 10746, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000675, mae: 0.014589, mean_q: 0.019908
 77702/100000: episode: 10747, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000275, mae: 0.012538, mean_q: 0.017145
 77712/100000: episode: 10748, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001207, mae: 0.014586, mean_q: 0.017077
 77722/100000: episode: 10749, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000748, mae: 0.013270, mean_q: 0.019373
 77732/100000: episode: 10750, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000194, mae: 0.010391, mean_q: 0.013682
 77742/100000: episode: 10751, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001203, mae: 0.016672, mean_q: 0.024536
 77752/100000: episode: 10752, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000528, mae: 0.013902, mean_q: 0.017690
 77762/100000: episode: 10753, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000647, mae: 0.015018, mean_q: 0.023418
 77772/100000: episode: 10754, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000297, mae: 0.012218, mean_q: 0.016820
 77782/100000: episode: 10755, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000608, mae: 0.020188, mean_q: 0.022030
 77792/100000: episode: 10756, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001115, mae: 0.016002, mean_q: 0.023710
 77802/100000: episode: 10757, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001038, mae: 0.014310, mean_q: 0.017122
 77812/100000: episode: 10758, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000730, mae: 0.012926, mean_q: 0.017121
 77822/100000: episode: 10759, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000693, mae: 0.013343, mean_q: 0.019370
 77832/100000: episode: 10760, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000474, mae: 0.011975, mean_q: 0.016696
 77842/100000: episode: 10761, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000429, mae: 0.010349, mean_q: 0.012871
 77852/100000: episode: 10762, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000293, mae: 0.009042, mean_q: 0.010544
 77862/100000: episode: 10763, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000386, mae: 0.012148, mean_q: 0.019808
 77872/100000: episode: 10764, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000947, mae: 0.014189, mean_q: 0.021416
 77882/100000: episode: 10765, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000789, mae: 0.015433, mean_q: 0.022747
 77892/100000: episode: 10766, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001185, mae: 0.015156, mean_q: 0.015583
 77902/100000: episode: 10767, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000588, mae: 0.013775, mean_q: 0.015333
 77912/100000: episode: 10768, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000783, mae: 0.012120, mean_q: 0.011575
 77922/100000: episode: 10769, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000426, mae: 0.011582, mean_q: 0.017855
 77932/100000: episode: 10770, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000304, mae: 0.009231, mean_q: 0.014256
 77942/100000: episode: 10771, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000752, mae: 0.011353, mean_q: 0.015554
 77952/100000: episode: 10772, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000990, mae: 0.017190, mean_q: 0.018420
 77962/100000: episode: 10773, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000658, mae: 0.013561, mean_q: 0.015005
 77972/100000: episode: 10774, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000869, mae: 0.014663, mean_q: 0.016447
 77982/100000: episode: 10775, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000694, mae: 0.013945, mean_q: 0.014519
 77992/100000: episode: 10776, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001066, mae: 0.015000, mean_q: 0.027854
 78002/100000: episode: 10777, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000273, mae: 0.008083, mean_q: 0.012188
 78012/100000: episode: 10778, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000421, mae: 0.010691, mean_q: 0.011835
 78022/100000: episode: 10779, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000127, mae: 0.008873, mean_q: 0.011723
 78032/100000: episode: 10780, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000184, mae: 0.008439, mean_q: 0.008119
 78042/100000: episode: 10781, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000272, mae: 0.010186, mean_q: 0.012608
 78052/100000: episode: 10782, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000269, mae: 0.008641, mean_q: 0.014397
 78062/100000: episode: 10783, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000146, mae: 0.007755, mean_q: 0.010968
 78072/100000: episode: 10784, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000159, mae: 0.007079, mean_q: 0.011544
 78082/100000: episode: 10785, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000170, mae: 0.007723, mean_q: 0.009847
 78092/100000: episode: 10786, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000364, mae: 0.011347, mean_q: 0.015518
 78102/100000: episode: 10787, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000251, mae: 0.007470, mean_q: 0.008239
 78112/100000: episode: 10788, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000989, mae: 0.013306, mean_q: 0.013788
 78122/100000: episode: 10789, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000392, mae: 0.010449, mean_q: 0.012928
 78132/100000: episode: 10790, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000127, mae: 0.007109, mean_q: 0.007570
 78142/100000: episode: 10791, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000253, mae: 0.007710, mean_q: 0.008667
 78152/100000: episode: 10792, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000223, mae: 0.008988, mean_q: 0.009935
 78162/100000: episode: 10793, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000163, mae: 0.007416, mean_q: 0.009399
 78172/100000: episode: 10794, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000303, mae: 0.008714, mean_q: 0.013674
 78182/100000: episode: 10795, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000190, mae: 0.007852, mean_q: 0.007703
 78192/100000: episode: 10796, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000309, mae: 0.008410, mean_q: 0.012495
 78202/100000: episode: 10797, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000146, mae: 0.008414, mean_q: 0.008992
 78212/100000: episode: 10798, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000158, mae: 0.007491, mean_q: 0.012020
 78222/100000: episode: 10799, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000516, mae: 0.009920, mean_q: 0.015285
 78232/100000: episode: 10800, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000440, mae: 0.009200, mean_q: 0.009714
 78242/100000: episode: 10801, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000205, mae: 0.007502, mean_q: 0.009158
 78252/100000: episode: 10802, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000189, mae: 0.007525, mean_q: 0.012241
 78262/100000: episode: 10803, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000091, mae: 0.008182, mean_q: 0.008921
 78272/100000: episode: 10804, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000117, mae: 0.008745, mean_q: 0.009194
 78282/100000: episode: 10805, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000474, mae: 0.007774, mean_q: 0.009407
 78292/100000: episode: 10806, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000771, mae: 0.013255, mean_q: 0.014923
 78302/100000: episode: 10807, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000073, mae: 0.006994, mean_q: 0.004312
 78312/100000: episode: 10808, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000873, mae: 0.013297, mean_q: 0.014612
 78322/100000: episode: 10809, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000277, mae: 0.011105, mean_q: 0.010324
 78332/100000: episode: 10810, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000372, mae: 0.010953, mean_q: 0.015871
 78342/100000: episode: 10811, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000175, mae: 0.007479, mean_q: 0.009344
 78352/100000: episode: 10812, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000312, mae: 0.008474, mean_q: 0.012678
 78362/100000: episode: 10813, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000134, mae: 0.008074, mean_q: 0.010456
 78372/100000: episode: 10814, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000268, mae: 0.009436, mean_q: 0.012379
 78382/100000: episode: 10815, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000352, mae: 0.010106, mean_q: 0.014802
 78392/100000: episode: 10816, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000596, mae: 0.010741, mean_q: 0.015086
 78402/100000: episode: 10817, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000153, mae: 0.010776, mean_q: 0.008999
 78412/100000: episode: 10818, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000199, mae: 0.010533, mean_q: 0.015540
 78422/100000: episode: 10819, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000102, mae: 0.008242, mean_q: 0.008683
 78432/100000: episode: 10820, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000278, mae: 0.010997, mean_q: 0.008496
 78442/100000: episode: 10821, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000122, mae: 0.007914, mean_q: 0.005805
 78452/100000: episode: 10822, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000162, mae: 0.009646, mean_q: 0.009627
 78462/100000: episode: 10823, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000193, mae: 0.010344, mean_q: 0.010598
 78472/100000: episode: 10824, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000148, mae: 0.006456, mean_q: 0.008043
 78482/100000: episode: 10825, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000592, mae: 0.011348, mean_q: 0.010805
 78492/100000: episode: 10826, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000630, mae: 0.010080, mean_q: 0.013119
 78502/100000: episode: 10827, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000200, mae: 0.007404, mean_q: 0.008624
 78512/100000: episode: 10828, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000196, mae: 0.010585, mean_q: 0.013200
 78522/100000: episode: 10829, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000222, mae: 0.009390, mean_q: 0.013842
 78532/100000: episode: 10830, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000540, mae: 0.010419, mean_q: 0.008856
 78542/100000: episode: 10831, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000108, mae: 0.008980, mean_q: 0.006223
 78552/100000: episode: 10832, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000798, mae: 0.012569, mean_q: 0.013123
 78562/100000: episode: 10833, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000202, mae: 0.008123, mean_q: 0.011556
 78572/100000: episode: 10834, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000085, mae: 0.006657, mean_q: 0.007756
[Info] 1-TH LEVEL FOUND: 0.012285560369491577, Considering 13/100 traces
 78582/100000: episode: 10835, duration: 0.729s, episode steps: 10, steps per second: 14, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000567, mae: 0.010309, mean_q: 0.015960
 78586/100000: episode: 10836, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000280, mae: 0.008757, mean_q: 0.005251
 78593/100000: episode: 10837, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000306, mae: 0.011346, mean_q: 0.013430
 78600/100000: episode: 10838, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000581, mae: 0.014286, mean_q: 0.020960
 78607/100000: episode: 10839, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000127, mae: 0.011940, mean_q: 0.007370
 78611/100000: episode: 10840, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000053, mae: 0.007772, mean_q: 0.010354
 78615/100000: episode: 10841, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000085, mae: 0.007535, mean_q: 0.005547
 78619/100000: episode: 10842, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000445, mae: 0.009986, mean_q: 0.019141
 78623/100000: episode: 10843, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000482, mae: 0.013050, mean_q: 0.021474
 78627/100000: episode: 10844, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000138, mae: 0.010500, mean_q: 0.001679
 78634/100000: episode: 10845, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000147, mae: 0.009686, mean_q: 0.012590
 78638/100000: episode: 10846, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000666, mae: 0.012983, mean_q: 0.011485
 78645/100000: episode: 10847, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000115, mae: 0.008443, mean_q: 0.008964
 78649/100000: episode: 10848, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000048, mae: 0.006316, mean_q: 0.009250
 78653/100000: episode: 10849, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000172, mae: 0.008803, mean_q: 0.004620
 78657/100000: episode: 10850, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000389, mae: 0.011878, mean_q: 0.019280
 78664/100000: episode: 10851, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000711, mae: 0.012785, mean_q: 0.014682
 78671/100000: episode: 10852, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000629, mae: 0.013037, mean_q: 0.012095
 78678/100000: episode: 10853, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000149, mae: 0.011289, mean_q: 0.010304
 78685/100000: episode: 10854, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000345, mae: 0.014253, mean_q: 0.019852
 78692/100000: episode: 10855, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000152, mae: 0.012228, mean_q: 0.009546
 78699/100000: episode: 10856, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000787, mae: 0.014130, mean_q: 0.008361
 78706/100000: episode: 10857, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000177, mae: 0.012330, mean_q: 0.013883
 78713/100000: episode: 10858, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000549, mae: 0.012532, mean_q: 0.020735
 78717/100000: episode: 10859, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000546, mae: 0.011879, mean_q: 0.020754
 78724/100000: episode: 10860, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000347, mae: 0.010503, mean_q: 0.013567
 78728/100000: episode: 10861, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000645, mae: 0.011933, mean_q: 0.027033
 78732/100000: episode: 10862, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000087, mae: 0.007406, mean_q: 0.008992
 78739/100000: episode: 10863, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000113, mae: 0.008239, mean_q: 0.013690
 78746/100000: episode: 10864, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000779, mae: 0.013164, mean_q: 0.015239
 78750/100000: episode: 10865, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000324, mae: 0.011077, mean_q: 0.013397
 78757/100000: episode: 10866, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000364, mae: 0.012674, mean_q: 0.016250
 78761/100000: episode: 10867, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000187, mae: 0.011408, mean_q: 0.005134
 78768/100000: episode: 10868, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000382, mae: 0.010768, mean_q: 0.013454
 78772/100000: episode: 10869, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000522, mae: 0.012719, mean_q: 0.007560
 78776/100000: episode: 10870, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000116, mae: 0.010696, mean_q: 0.012685
 78780/100000: episode: 10871, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000087, mae: 0.008575, mean_q: 0.000203
 78787/100000: episode: 10872, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000370, mae: 0.011281, mean_q: 0.008649
 78794/100000: episode: 10873, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000119, mae: 0.010743, mean_q: 0.013493
 78798/100000: episode: 10874, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000118, mae: 0.008768, mean_q: 0.010781
 78802/100000: episode: 10875, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000426, mae: 0.011626, mean_q: 0.018028
 78809/100000: episode: 10876, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000058, mae: 0.006669, mean_q: 0.008645
 78813/100000: episode: 10877, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000071, mae: 0.006420, mean_q: 0.004024
 78820/100000: episode: 10878, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000136, mae: 0.009739, mean_q: 0.011452
 78824/100000: episode: 10879, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000094, mae: 0.007214, mean_q: 0.007780
 78831/100000: episode: 10880, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000277, mae: 0.009774, mean_q: 0.011132
 78838/100000: episode: 10881, duration: 0.037s, episode steps: 7, steps per second: 192, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000249, mae: 0.008774, mean_q: 0.013247
 78845/100000: episode: 10882, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000350, mae: 0.012308, mean_q: 0.019537
 78852/100000: episode: 10883, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000212, mae: 0.010585, mean_q: 0.007986
 78856/100000: episode: 10884, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000452, mae: 0.011460, mean_q: 0.015345
 78863/100000: episode: 10885, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000191, mae: 0.010061, mean_q: 0.014318
 78870/100000: episode: 10886, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000256, mae: 0.011238, mean_q: 0.016416
 78877/100000: episode: 10887, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000270, mae: 0.010175, mean_q: 0.014305
 78884/100000: episode: 10888, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000792, mae: 0.013769, mean_q: 0.019998
 78888/100000: episode: 10889, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000077, mae: 0.007143, mean_q: 0.005240
 78892/100000: episode: 10890, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000111, mae: 0.007167, mean_q: 0.009009
 78896/100000: episode: 10891, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000086, mae: 0.007926, mean_q: 0.011168
 78900/100000: episode: 10892, duration: 0.023s, episode steps: 4, steps per second: 170, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000431, mae: 0.011966, mean_q: 0.017146
 78907/100000: episode: 10893, duration: 0.035s, episode steps: 7, steps per second: 197, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000647, mae: 0.011814, mean_q: 0.013991
 78914/100000: episode: 10894, duration: 0.041s, episode steps: 7, steps per second: 170, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000116, mae: 0.008387, mean_q: 0.006936
 78918/100000: episode: 10895, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000118, mae: 0.007246, mean_q: 0.011389
 78925/100000: episode: 10896, duration: 0.038s, episode steps: 7, steps per second: 182, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000565, mae: 0.009764, mean_q: 0.013588
 78932/100000: episode: 10897, duration: 0.037s, episode steps: 7, steps per second: 191, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000075, mae: 0.007070, mean_q: 0.007405
 78939/100000: episode: 10898, duration: 0.039s, episode steps: 7, steps per second: 181, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000160, mae: 0.009418, mean_q: 0.013279
 78946/100000: episode: 10899, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000052, mae: 0.006199, mean_q: 0.008261
 78953/100000: episode: 10900, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.001080, mae: 0.013769, mean_q: 0.018717
 78960/100000: episode: 10901, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000223, mae: 0.008442, mean_q: 0.012340
 78967/100000: episode: 10902, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000275, mae: 0.008674, mean_q: 0.013150
 78974/100000: episode: 10903, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000085, mae: 0.008283, mean_q: 0.011477
 78981/100000: episode: 10904, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000282, mae: 0.009974, mean_q: 0.014762
 78985/100000: episode: 10905, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000221, mae: 0.011243, mean_q: 0.008820
 78992/100000: episode: 10906, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000986, mae: 0.013744, mean_q: 0.015707
 78996/100000: episode: 10907, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000552, mae: 0.010610, mean_q: 0.014288
[Info] FALSIFICATION!
 79002/100000: episode: 10908, duration: 0.271s, episode steps: 6, steps per second: 22, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.001146, mae: 0.016671, mean_q: 0.017611
 79009/100000: episode: 10909, duration: 0.038s, episode steps: 7, steps per second: 184, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000379, mae: 0.015463, mean_q: 0.019134
 79013/100000: episode: 10910, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000442, mae: 0.012775, mean_q: 0.019362
 79017/100000: episode: 10911, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000298, mae: 0.010655, mean_q: 0.010735
 79021/100000: episode: 10912, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000289, mae: 0.011888, mean_q: 0.026747
 79025/100000: episode: 10913, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000232, mae: 0.010501, mean_q: 0.017911
 79032/100000: episode: 10914, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000156, mae: 0.010220, mean_q: 0.012633
 79039/100000: episode: 10915, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000468, mae: 0.012103, mean_q: 0.022299
 79046/100000: episode: 10916, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000536, mae: 0.012922, mean_q: 0.013297
 79050/100000: episode: 10917, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000315, mae: 0.013253, mean_q: 0.018151
 79057/100000: episode: 10918, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000139, mae: 0.010847, mean_q: 0.011674
 79061/100000: episode: 10919, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000319, mae: 0.010071, mean_q: 0.018094
 79065/100000: episode: 10920, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000594, mae: 0.010975, mean_q: 0.020795
 79069/100000: episode: 10921, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000458, mae: 0.011749, mean_q: 0.014617
[Info] Complete ISplit Iteration
[Info] Levels: [0.01228556, 1.2160225]
[Info] Cond. Prob: [0.13, 0.01]
[Info] Error Prob: 0.0013000000000000002

 79076/100000: episode: 10922, duration: 0.864s, episode steps: 7, steps per second: 8, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.001177, mae: 0.015307, mean_q: 0.022357
 79086/100000: episode: 10923, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000348, mae: 0.018354, mean_q: 0.014271
 79096/100000: episode: 10924, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000323, mae: 0.013582, mean_q: 0.011912
 79106/100000: episode: 10925, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000728, mae: 0.014010, mean_q: 0.017914
 79116/100000: episode: 10926, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000316, mae: 0.014090, mean_q: 0.011916
 79126/100000: episode: 10927, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000359, mae: 0.014252, mean_q: 0.009325
 79136/100000: episode: 10928, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000454, mae: 0.016667, mean_q: 0.016603
 79146/100000: episode: 10929, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000421, mae: 0.011491, mean_q: 0.014594
 79156/100000: episode: 10930, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000210, mae: 0.011411, mean_q: 0.018078
 79166/100000: episode: 10931, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000322, mae: 0.013159, mean_q: 0.013188
 79176/100000: episode: 10932, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000895, mae: 0.012454, mean_q: 0.010378
 79186/100000: episode: 10933, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000590, mae: 0.012743, mean_q: 0.012570
 79196/100000: episode: 10934, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000968, mae: 0.011982, mean_q: 0.012021
 79206/100000: episode: 10935, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000167, mae: 0.009822, mean_q: 0.008995
 79216/100000: episode: 10936, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000352, mae: 0.010375, mean_q: 0.012943
 79226/100000: episode: 10937, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000462, mae: 0.010885, mean_q: 0.012149
 79236/100000: episode: 10938, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000139, mae: 0.007077, mean_q: 0.009272
 79246/100000: episode: 10939, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000318, mae: 0.009728, mean_q: 0.011349
 79256/100000: episode: 10940, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000073, mae: 0.006805, mean_q: 0.008383
 79266/100000: episode: 10941, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000260, mae: 0.009509, mean_q: 0.013857
 79276/100000: episode: 10942, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000294, mae: 0.009585, mean_q: 0.016798
 79286/100000: episode: 10943, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001100, mae: 0.013233, mean_q: 0.019979
 79296/100000: episode: 10944, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000164, mae: 0.011209, mean_q: 0.009634
 79306/100000: episode: 10945, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000229, mae: 0.011630, mean_q: 0.012928
 79316/100000: episode: 10946, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000391, mae: 0.009815, mean_q: 0.010181
 79326/100000: episode: 10947, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000155, mae: 0.009538, mean_q: 0.009558
 79336/100000: episode: 10948, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000225, mae: 0.010949, mean_q: 0.010336
 79346/100000: episode: 10949, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000178, mae: 0.009577, mean_q: 0.008053
 79356/100000: episode: 10950, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000149, mae: 0.009067, mean_q: 0.009092
 79366/100000: episode: 10951, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000096, mae: 0.008192, mean_q: 0.009633
 79376/100000: episode: 10952, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000826, mae: 0.011331, mean_q: 0.013398
 79386/100000: episode: 10953, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000204, mae: 0.008817, mean_q: 0.009063
 79396/100000: episode: 10954, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000266, mae: 0.009048, mean_q: 0.011518
 79406/100000: episode: 10955, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000516, mae: 0.011423, mean_q: 0.016420
 79416/100000: episode: 10956, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000383, mae: 0.010854, mean_q: 0.011471
 79426/100000: episode: 10957, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000489, mae: 0.012620, mean_q: 0.013597
 79436/100000: episode: 10958, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000088, mae: 0.007766, mean_q: 0.008165
 79446/100000: episode: 10959, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000183, mae: 0.008575, mean_q: 0.011312
 79456/100000: episode: 10960, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000088, mae: 0.007040, mean_q: 0.008053
 79466/100000: episode: 10961, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000099, mae: 0.006953, mean_q: 0.009433
 79476/100000: episode: 10962, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000074, mae: 0.006912, mean_q: 0.007114
 79486/100000: episode: 10963, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000378, mae: 0.009033, mean_q: 0.011556
 79496/100000: episode: 10964, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000530, mae: 0.009673, mean_q: 0.016190
 79506/100000: episode: 10965, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000222, mae: 0.007059, mean_q: 0.006881
 79516/100000: episode: 10966, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000216, mae: 0.008071, mean_q: 0.010209
 79526/100000: episode: 10967, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000230, mae: 0.010435, mean_q: 0.010624
 79536/100000: episode: 10968, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000091, mae: 0.007049, mean_q: 0.009309
 79546/100000: episode: 10969, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000090, mae: 0.007067, mean_q: 0.009044
 79556/100000: episode: 10970, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000425, mae: 0.010512, mean_q: 0.011373
 79566/100000: episode: 10971, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000326, mae: 0.009109, mean_q: 0.010224
 79576/100000: episode: 10972, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000336, mae: 0.008929, mean_q: 0.017604
 79586/100000: episode: 10973, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000133, mae: 0.008214, mean_q: 0.011024
 79596/100000: episode: 10974, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000313, mae: 0.008247, mean_q: 0.011423
 79606/100000: episode: 10975, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000208, mae: 0.008456, mean_q: 0.010450
 79616/100000: episode: 10976, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000200, mae: 0.007247, mean_q: 0.009251
 79626/100000: episode: 10977, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000076, mae: 0.006205, mean_q: 0.008776
 79636/100000: episode: 10978, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000198, mae: 0.008789, mean_q: 0.010095
 79646/100000: episode: 10979, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000081, mae: 0.006681, mean_q: 0.008566
 79656/100000: episode: 10980, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000091, mae: 0.007840, mean_q: 0.009456
 79666/100000: episode: 10981, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000075, mae: 0.006780, mean_q: 0.008738
 79676/100000: episode: 10982, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000119, mae: 0.008829, mean_q: 0.009662
 79686/100000: episode: 10983, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000290, mae: 0.008897, mean_q: 0.010600
 79696/100000: episode: 10984, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000337, mae: 0.010912, mean_q: 0.012748
 79706/100000: episode: 10985, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000081, mae: 0.007605, mean_q: 0.008732
 79716/100000: episode: 10986, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000588, mae: 0.009424, mean_q: 0.011825
 79726/100000: episode: 10987, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000222, mae: 0.008483, mean_q: 0.013170
 79736/100000: episode: 10988, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000341, mae: 0.007288, mean_q: 0.008440
 79746/100000: episode: 10989, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000448, mae: 0.009928, mean_q: 0.012905
 79756/100000: episode: 10990, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000158, mae: 0.010000, mean_q: 0.008850
 79766/100000: episode: 10991, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000094, mae: 0.007574, mean_q: 0.008308
 79776/100000: episode: 10992, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000048, mae: 0.005653, mean_q: 0.007213
 79786/100000: episode: 10993, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000215, mae: 0.007610, mean_q: 0.010071
 79796/100000: episode: 10994, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000087, mae: 0.007320, mean_q: 0.008816
 79806/100000: episode: 10995, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000321, mae: 0.008346, mean_q: 0.010488
 79816/100000: episode: 10996, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000310, mae: 0.008540, mean_q: 0.011743
 79826/100000: episode: 10997, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000080, mae: 0.006436, mean_q: 0.008221
 79836/100000: episode: 10998, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000215, mae: 0.007455, mean_q: 0.010006
 79846/100000: episode: 10999, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000196, mae: 0.008822, mean_q: 0.010451
 79856/100000: episode: 11000, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000305, mae: 0.007702, mean_q: 0.010375
 79866/100000: episode: 11001, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000040, mae: 0.004940, mean_q: 0.008377
 79876/100000: episode: 11002, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000284, mae: 0.008173, mean_q: 0.012506
 79886/100000: episode: 11003, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000045, mae: 0.004525, mean_q: 0.004880
 79896/100000: episode: 11004, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000380, mae: 0.008804, mean_q: 0.012718
 79906/100000: episode: 11005, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000233, mae: 0.007105, mean_q: 0.009872
 79916/100000: episode: 11006, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000130, mae: 0.005991, mean_q: 0.009172
 79926/100000: episode: 11007, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000342, mae: 0.009110, mean_q: 0.011884
 79936/100000: episode: 11008, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000138, mae: 0.006229, mean_q: 0.006748
 79946/100000: episode: 11009, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000442, mae: 0.009072, mean_q: 0.010487
 79956/100000: episode: 11010, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000111, mae: 0.008090, mean_q: 0.008128
 79966/100000: episode: 11011, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000178, mae: 0.008267, mean_q: 0.009275
 79976/100000: episode: 11012, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000147, mae: 0.008037, mean_q: 0.007301
 79986/100000: episode: 11013, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000138, mae: 0.006764, mean_q: 0.009710
 79996/100000: episode: 11014, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000295, mae: 0.007405, mean_q: 0.009993
 80006/100000: episode: 11015, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000433, mae: 0.008640, mean_q: 0.010324
 80016/100000: episode: 11016, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000253, mae: 0.007694, mean_q: 0.009296
 80026/100000: episode: 11017, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000078, mae: 0.005770, mean_q: 0.008579
 80036/100000: episode: 11018, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000099, mae: 0.008130, mean_q: 0.009032
 80046/100000: episode: 11019, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000278, mae: 0.009227, mean_q: 0.007298
 80056/100000: episode: 11020, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000156, mae: 0.008293, mean_q: 0.008511
 80066/100000: episode: 11021, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000209, mae: 0.009031, mean_q: 0.011068
[Info] 1-TH LEVEL FOUND: 0.015758782625198364, Considering 11/100 traces
 80076/100000: episode: 11022, duration: 0.734s, episode steps: 10, steps per second: 14, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000340, mae: 0.008533, mean_q: 0.011174
 80083/100000: episode: 11023, duration: 0.037s, episode steps: 7, steps per second: 191, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000064, mae: 0.006398, mean_q: 0.009068
 80090/100000: episode: 11024, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000314, mae: 0.007655, mean_q: 0.008477
 80097/100000: episode: 11025, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000088, mae: 0.007190, mean_q: 0.010070
 80099/100000: episode: 11026, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000156, mae: 0.008366, mean_q: 0.004850
 80101/100000: episode: 11027, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000043, mae: 0.005950, mean_q: 0.008608
 80108/100000: episode: 11028, duration: 0.037s, episode steps: 7, steps per second: 191, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000094, mae: 0.007534, mean_q: 0.006603
 80110/100000: episode: 11029, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000094, mae: 0.009806, mean_q: 0.012368
 80112/100000: episode: 11030, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000081, mae: 0.006958, mean_q: 0.001316
 80119/100000: episode: 11031, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000135, mae: 0.007486, mean_q: 0.009371
 80126/100000: episode: 11032, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000097, mae: 0.009089, mean_q: 0.007729
 80133/100000: episode: 11033, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000076, mae: 0.006833, mean_q: 0.010373
 80140/100000: episode: 11034, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000383, mae: 0.008858, mean_q: 0.013124
 80147/100000: episode: 11035, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000133, mae: 0.010485, mean_q: 0.008649
 80154/100000: episode: 11036, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000126, mae: 0.008122, mean_q: 0.007358
 80161/100000: episode: 11037, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000174, mae: 0.008210, mean_q: 0.009497
 80168/100000: episode: 11038, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000199, mae: 0.007715, mean_q: 0.009473
 80175/100000: episode: 11039, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000075, mae: 0.006457, mean_q: 0.006592
 80182/100000: episode: 11040, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000102, mae: 0.006397, mean_q: 0.007666
 80189/100000: episode: 11041, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000117, mae: 0.008975, mean_q: 0.011705
 80196/100000: episode: 11042, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000138, mae: 0.007958, mean_q: 0.009060
 80203/100000: episode: 11043, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000321, mae: 0.011775, mean_q: 0.012193
 80210/100000: episode: 11044, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000342, mae: 0.009836, mean_q: 0.013696
 80217/100000: episode: 11045, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000207, mae: 0.009653, mean_q: 0.010973
 80224/100000: episode: 11046, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000147, mae: 0.008058, mean_q: 0.006611
 80231/100000: episode: 11047, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000070, mae: 0.006813, mean_q: 0.007380
 80233/100000: episode: 11048, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000533, mae: 0.013860, mean_q: 0.022299
 80240/100000: episode: 11049, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000100, mae: 0.006591, mean_q: 0.007998
 80242/100000: episode: 11050, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000112, mae: 0.008912, mean_q: 0.011440
 80249/100000: episode: 11051, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000734, mae: 0.012140, mean_q: 0.016331
 80256/100000: episode: 11052, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000262, mae: 0.012661, mean_q: 0.014957
 80263/100000: episode: 11053, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000122, mae: 0.007725, mean_q: 0.010489
 80270/100000: episode: 11054, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000073, mae: 0.005827, mean_q: 0.006730
 80277/100000: episode: 11055, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000094, mae: 0.006804, mean_q: 0.011101
 80279/100000: episode: 11056, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000092, mae: 0.005612, mean_q: 0.005038
 80286/100000: episode: 11057, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000094, mae: 0.006970, mean_q: 0.011503
 80293/100000: episode: 11058, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000043, mae: 0.005922, mean_q: 0.007397
 80300/100000: episode: 11059, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000086, mae: 0.008556, mean_q: 0.011549
 80302/100000: episode: 11060, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000170, mae: 0.007185, mean_q: 0.005209
 80309/100000: episode: 11061, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000123, mae: 0.008087, mean_q: 0.009437
 80311/100000: episode: 11062, duration: 0.014s, episode steps: 2, steps per second: 144, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000463, mae: 0.011289, mean_q: 0.011526
 80318/100000: episode: 11063, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000190, mae: 0.009763, mean_q: 0.010794
 80325/100000: episode: 11064, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000221, mae: 0.008224, mean_q: 0.010406
 80327/100000: episode: 11065, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001427, mae: 0.015822, mean_q: 0.028482
 80334/100000: episode: 11066, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000151, mae: 0.008024, mean_q: 0.007097
 80341/100000: episode: 11067, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000355, mae: 0.012293, mean_q: 0.014258
 80348/100000: episode: 11068, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000431, mae: 0.009469, mean_q: 0.014641
 80350/100000: episode: 11069, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001096, mae: 0.012212, mean_q: 0.015550
 80352/100000: episode: 11070, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001563, mae: 0.014373, mean_q: 0.011988
 80359/100000: episode: 11071, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000153, mae: 0.011585, mean_q: 0.010557
 80361/100000: episode: 11072, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000072, mae: 0.007511, mean_q: 0.010342
 80368/100000: episode: 11073, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000250, mae: 0.007520, mean_q: 0.007843
[Info] FALSIFICATION!
 80374/100000: episode: 11074, duration: 0.174s, episode steps: 6, steps per second: 34, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000422, mae: 0.010479, mean_q: 0.013037
 80376/100000: episode: 11075, duration: 0.014s, episode steps: 2, steps per second: 144, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000065, mae: 0.007413, mean_q: 0.010191
 80383/100000: episode: 11076, duration: 0.037s, episode steps: 7, steps per second: 188, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000289, mae: 0.012044, mean_q: 0.014999
 80390/100000: episode: 11077, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000617, mae: 0.012432, mean_q: 0.012157
 80392/100000: episode: 11078, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000058, mae: 0.006696, mean_q: 0.007908
 80399/100000: episode: 11079, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000105, mae: 0.008816, mean_q: 0.008273
 80406/100000: episode: 11080, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000502, mae: 0.013713, mean_q: 0.008051
 80413/100000: episode: 11081, duration: 0.036s, episode steps: 7, steps per second: 192, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000246, mae: 0.009814, mean_q: 0.009626
 80420/100000: episode: 11082, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000571, mae: 0.013686, mean_q: 0.014320
 80427/100000: episode: 11083, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000366, mae: 0.010178, mean_q: 0.009104
 80434/100000: episode: 11084, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000357, mae: 0.008917, mean_q: 0.009993
 80436/100000: episode: 11085, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000074, mae: 0.008259, mean_q: 0.013167
 80443/100000: episode: 11086, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000137, mae: 0.009380, mean_q: 0.008894
 80450/100000: episode: 11087, duration: 0.036s, episode steps: 7, steps per second: 193, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000153, mae: 0.011525, mean_q: 0.012370
 80457/100000: episode: 11088, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000990, mae: 0.018313, mean_q: 0.016527
 80459/100000: episode: 11089, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001488, mae: 0.017331, mean_q: 0.012423
 80466/100000: episode: 11090, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000166, mae: 0.013588, mean_q: 0.007641
 80473/100000: episode: 11091, duration: 0.037s, episode steps: 7, steps per second: 188, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000413, mae: 0.013874, mean_q: 0.016862
 80475/100000: episode: 11092, duration: 0.015s, episode steps: 2, steps per second: 135, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000311, mae: 0.011178, mean_q: 0.009537
 80482/100000: episode: 11093, duration: 0.038s, episode steps: 7, steps per second: 184, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000265, mae: 0.009957, mean_q: 0.010622
 80489/100000: episode: 11094, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000480, mae: 0.013580, mean_q: 0.012586
 80491/100000: episode: 11095, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000143, mae: 0.009517, mean_q: 0.011116
 80498/100000: episode: 11096, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000498, mae: 0.008991, mean_q: 0.012369
 80505/100000: episode: 11097, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000136, mae: 0.009734, mean_q: 0.008701
 80507/100000: episode: 11098, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001148, mae: 0.018115, mean_q: 0.024585
 80514/100000: episode: 11099, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000539, mae: 0.012491, mean_q: 0.012339
 80521/100000: episode: 11100, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000244, mae: 0.010734, mean_q: 0.011669
 80528/100000: episode: 11101, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000242, mae: 0.012322, mean_q: 0.010485
 80535/100000: episode: 11102, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000239, mae: 0.012964, mean_q: 0.017234
 80542/100000: episode: 11103, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000110, mae: 0.009424, mean_q: 0.010173
 80549/100000: episode: 11104, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000188, mae: 0.011375, mean_q: 0.013476
 80551/100000: episode: 11105, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001359, mae: 0.014506, mean_q: 0.018560
 80558/100000: episode: 11106, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000593, mae: 0.015097, mean_q: 0.017324
 80565/100000: episode: 11107, duration: 0.038s, episode steps: 7, steps per second: 185, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000213, mae: 0.011610, mean_q: 0.013043
 80567/100000: episode: 11108, duration: 0.016s, episode steps: 2, steps per second: 125, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000030, mae: 0.005057, mean_q: 0.007775
 80574/100000: episode: 11109, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000461, mae: 0.012253, mean_q: 0.015859
 80581/100000: episode: 11110, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000310, mae: 0.010547, mean_q: 0.017112
[Info] Complete ISplit Iteration
[Info] Levels: [0.015758783, 0.92538583]
[Info] Cond. Prob: [0.11, 0.01]
[Info] Error Prob: 0.0011

 80588/100000: episode: 11111, duration: 0.859s, episode steps: 7, steps per second: 8, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000606, mae: 0.012234, mean_q: 0.018345
 80598/100000: episode: 11112, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000420, mae: 0.010144, mean_q: 0.013636
 80608/100000: episode: 11113, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000329, mae: 0.010467, mean_q: 0.013421
 80618/100000: episode: 11114, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000206, mae: 0.013330, mean_q: 0.012382
 80628/100000: episode: 11115, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000218, mae: 0.010132, mean_q: 0.012473
 80638/100000: episode: 11116, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000403, mae: 0.011032, mean_q: 0.013621
 80648/100000: episode: 11117, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000243, mae: 0.012132, mean_q: 0.010725
 80658/100000: episode: 11118, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000156, mae: 0.008255, mean_q: 0.011196
 80668/100000: episode: 11119, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000068, mae: 0.007175, mean_q: 0.010343
 80678/100000: episode: 11120, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000278, mae: 0.008099, mean_q: 0.010336
 80688/100000: episode: 11121, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000452, mae: 0.010932, mean_q: 0.014060
 80698/100000: episode: 11122, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000275, mae: 0.008443, mean_q: 0.011354
 80708/100000: episode: 11123, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000137, mae: 0.009303, mean_q: 0.013152
 80718/100000: episode: 11124, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000323, mae: 0.010329, mean_q: 0.014675
 80728/100000: episode: 11125, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000490, mae: 0.011746, mean_q: 0.012640
 80738/100000: episode: 11126, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000406, mae: 0.010342, mean_q: 0.015982
 80748/100000: episode: 11127, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000357, mae: 0.013096, mean_q: 0.016411
 80758/100000: episode: 11128, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000168, mae: 0.009248, mean_q: 0.013401
 80768/100000: episode: 11129, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000423, mae: 0.009975, mean_q: 0.011369
 80778/100000: episode: 11130, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000164, mae: 0.010021, mean_q: 0.011108
 80788/100000: episode: 11131, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000186, mae: 0.008398, mean_q: 0.011844
 80798/100000: episode: 11132, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000419, mae: 0.010108, mean_q: 0.016052
 80808/100000: episode: 11133, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000320, mae: 0.010949, mean_q: 0.013756
 80818/100000: episode: 11134, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000121, mae: 0.008140, mean_q: 0.008641
 80828/100000: episode: 11135, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000160, mae: 0.009716, mean_q: 0.013461
 80838/100000: episode: 11136, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000128, mae: 0.008519, mean_q: 0.009920
 80848/100000: episode: 11137, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000636, mae: 0.013712, mean_q: 0.014697
 80858/100000: episode: 11138, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000783, mae: 0.013160, mean_q: 0.018144
 80868/100000: episode: 11139, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000196, mae: 0.012379, mean_q: 0.012296
 80878/100000: episode: 11140, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000120, mae: 0.010776, mean_q: 0.008912
 80888/100000: episode: 11141, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000193, mae: 0.009778, mean_q: 0.013479
 80898/100000: episode: 11142, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000241, mae: 0.008993, mean_q: 0.011625
 80908/100000: episode: 11143, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000416, mae: 0.013542, mean_q: 0.017252
 80918/100000: episode: 11144, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000170, mae: 0.009464, mean_q: 0.010441
 80928/100000: episode: 11145, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000398, mae: 0.011071, mean_q: 0.011477
 80938/100000: episode: 11146, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000384, mae: 0.012197, mean_q: 0.013283
 80948/100000: episode: 11147, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000339, mae: 0.011991, mean_q: 0.016387
 80958/100000: episode: 11148, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000472, mae: 0.013726, mean_q: 0.013989
 80968/100000: episode: 11149, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000374, mae: 0.011965, mean_q: 0.012271
 80978/100000: episode: 11150, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000160, mae: 0.010753, mean_q: 0.013673
 80988/100000: episode: 11151, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000209, mae: 0.009815, mean_q: 0.011970
 80998/100000: episode: 11152, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000254, mae: 0.010046, mean_q: 0.013653
 81008/100000: episode: 11153, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000233, mae: 0.012276, mean_q: 0.012517
 81018/100000: episode: 11154, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000626, mae: 0.012340, mean_q: 0.013637
 81028/100000: episode: 11155, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000152, mae: 0.010083, mean_q: 0.008858
 81038/100000: episode: 11156, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000153, mae: 0.011159, mean_q: 0.010393
 81048/100000: episode: 11157, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000101, mae: 0.007694, mean_q: 0.009793
 81058/100000: episode: 11158, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000354, mae: 0.010960, mean_q: 0.012327
 81068/100000: episode: 11159, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000245, mae: 0.010134, mean_q: 0.012352
 81078/100000: episode: 11160, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000530, mae: 0.011201, mean_q: 0.011203
 81088/100000: episode: 11161, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000188, mae: 0.007960, mean_q: 0.011213
 81098/100000: episode: 11162, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000082, mae: 0.006966, mean_q: 0.008207
 81108/100000: episode: 11163, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000151, mae: 0.009048, mean_q: 0.011398
 81118/100000: episode: 11164, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000348, mae: 0.009613, mean_q: 0.011663
 81128/100000: episode: 11165, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000495, mae: 0.013922, mean_q: 0.013748
 81138/100000: episode: 11166, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000122, mae: 0.010241, mean_q: 0.007860
 81148/100000: episode: 11167, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000127, mae: 0.009724, mean_q: 0.011547
 81158/100000: episode: 11168, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000077, mae: 0.007389, mean_q: 0.008110
 81168/100000: episode: 11169, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000075, mae: 0.006929, mean_q: 0.008995
 81178/100000: episode: 11170, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000186, mae: 0.007539, mean_q: 0.009745
 81188/100000: episode: 11171, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000112, mae: 0.008696, mean_q: 0.010266
 81198/100000: episode: 11172, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000223, mae: 0.007132, mean_q: 0.006966
 81208/100000: episode: 11173, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000308, mae: 0.010505, mean_q: 0.013159
 81218/100000: episode: 11174, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000260, mae: 0.010804, mean_q: 0.009452
 81228/100000: episode: 11175, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000146, mae: 0.012001, mean_q: 0.011116
 81238/100000: episode: 11176, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000445, mae: 0.013722, mean_q: 0.010909
 81248/100000: episode: 11177, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000193, mae: 0.012766, mean_q: 0.008573
 81258/100000: episode: 11178, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000831, mae: 0.016938, mean_q: 0.011111
 81268/100000: episode: 11179, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000251, mae: 0.014081, mean_q: 0.010073
 81278/100000: episode: 11180, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000140, mae: 0.010284, mean_q: 0.009797
 81288/100000: episode: 11181, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000136, mae: 0.008910, mean_q: 0.009892
 81298/100000: episode: 11182, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000936, mae: 0.014743, mean_q: 0.019756
 81308/100000: episode: 11183, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000380, mae: 0.011733, mean_q: 0.011161
 81318/100000: episode: 11184, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000104, mae: 0.008227, mean_q: 0.008780
 81328/100000: episode: 11185, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000356, mae: 0.009474, mean_q: 0.011775
 81338/100000: episode: 11186, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000324, mae: 0.008770, mean_q: 0.009411
 81348/100000: episode: 11187, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000488, mae: 0.011413, mean_q: 0.014642
 81358/100000: episode: 11188, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000246, mae: 0.010541, mean_q: 0.010373
 81368/100000: episode: 11189, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000179, mae: 0.011021, mean_q: 0.010524
 81378/100000: episode: 11190, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000448, mae: 0.012169, mean_q: 0.011555
 81388/100000: episode: 11191, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000306, mae: 0.009764, mean_q: 0.010682
 81398/100000: episode: 11192, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000107, mae: 0.009541, mean_q: 0.008751
 81408/100000: episode: 11193, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000401, mae: 0.012812, mean_q: 0.012364
 81418/100000: episode: 11194, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000343, mae: 0.012028, mean_q: 0.011888
 81428/100000: episode: 11195, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000129, mae: 0.009845, mean_q: 0.011337
 81438/100000: episode: 11196, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000154, mae: 0.008791, mean_q: 0.010798
 81448/100000: episode: 11197, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000806, mae: 0.013639, mean_q: 0.015089
 81458/100000: episode: 11198, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000411, mae: 0.011377, mean_q: 0.009948
 81468/100000: episode: 11199, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000342, mae: 0.012487, mean_q: 0.010015
 81478/100000: episode: 11200, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000512, mae: 0.010915, mean_q: 0.013962
 81488/100000: episode: 11201, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000101, mae: 0.009183, mean_q: 0.010161
 81498/100000: episode: 11202, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000448, mae: 0.009861, mean_q: 0.013003
 81508/100000: episode: 11203, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000064, mae: 0.006626, mean_q: 0.008044
 81518/100000: episode: 11204, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000249, mae: 0.008819, mean_q: 0.011506
 81528/100000: episode: 11205, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000450, mae: 0.012743, mean_q: 0.011541
 81538/100000: episode: 11206, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000523, mae: 0.012114, mean_q: 0.015353
 81548/100000: episode: 11207, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000208, mae: 0.008933, mean_q: 0.011118
 81558/100000: episode: 11208, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000527, mae: 0.012937, mean_q: 0.014510
 81568/100000: episode: 11209, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000235, mae: 0.011012, mean_q: 0.011261
 81578/100000: episode: 11210, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000477, mae: 0.012640, mean_q: 0.012757
[Info] 1-TH LEVEL FOUND: 0.03303864598274231, Considering 11/100 traces
 81588/100000: episode: 11211, duration: 0.875s, episode steps: 10, steps per second: 11, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000156, mae: 0.008039, mean_q: 0.010093
 81592/100000: episode: 11212, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000644, mae: 0.013855, mean_q: 0.014192
 81596/100000: episode: 11213, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000073, mae: 0.007600, mean_q: 0.011245
 81600/100000: episode: 11214, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000072, mae: 0.006927, mean_q: 0.007348
 81604/100000: episode: 11215, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000409, mae: 0.011611, mean_q: 0.012502
 81608/100000: episode: 11216, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000301, mae: 0.006829, mean_q: 0.009143
 81612/100000: episode: 11217, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000140, mae: 0.009252, mean_q: 0.015844
 81616/100000: episode: 11218, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000132, mae: 0.009434, mean_q: 0.008605
 81622/100000: episode: 11219, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000110, mae: 0.008522, mean_q: 0.011531
 81626/100000: episode: 11220, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000077, mae: 0.006400, mean_q: 0.010667
 81632/100000: episode: 11221, duration: 0.034s, episode steps: 6, steps per second: 178, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000084, mae: 0.008113, mean_q: 0.010368
 81638/100000: episode: 11222, duration: 0.031s, episode steps: 6, steps per second: 191, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000098, mae: 0.007475, mean_q: 0.008045
 81644/100000: episode: 11223, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000069, mae: 0.007215, mean_q: 0.008762
 81648/100000: episode: 11224, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000128, mae: 0.010249, mean_q: 0.014397
 81652/100000: episode: 11225, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000567, mae: 0.012872, mean_q: 0.018859
 81656/100000: episode: 11226, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000427, mae: 0.012454, mean_q: 0.018460
 81662/100000: episode: 11227, duration: 0.031s, episode steps: 6, steps per second: 193, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000354, mae: 0.015013, mean_q: 0.012611
 81666/100000: episode: 11228, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000123, mae: 0.010735, mean_q: 0.014003
 81672/100000: episode: 11229, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000215, mae: 0.010129, mean_q: 0.012361
 81678/100000: episode: 11230, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000132, mae: 0.007790, mean_q: 0.012211
 81684/100000: episode: 11231, duration: 0.033s, episode steps: 6, steps per second: 183, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000324, mae: 0.011479, mean_q: 0.017717
 81688/100000: episode: 11232, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000382, mae: 0.012226, mean_q: 0.023106
 81694/100000: episode: 11233, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000164, mae: 0.008508, mean_q: 0.014242
 81698/100000: episode: 11234, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000274, mae: 0.010483, mean_q: 0.012544
 81702/100000: episode: 11235, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000170, mae: 0.008514, mean_q: 0.011583
 81706/100000: episode: 11236, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000227, mae: 0.009012, mean_q: 0.013102
 81712/100000: episode: 11237, duration: 0.032s, episode steps: 6, steps per second: 189, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.002429, mae: 0.018804, mean_q: 0.017578
 81716/100000: episode: 11238, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000928, mae: 0.014265, mean_q: 0.021165
 81720/100000: episode: 11239, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000196, mae: 0.012216, mean_q: 0.001996
 81724/100000: episode: 11240, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000579, mae: 0.016724, mean_q: 0.021056
 81728/100000: episode: 11241, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000110, mae: 0.010994, mean_q: -0.000226
 81732/100000: episode: 11242, duration: 0.026s, episode steps: 4, steps per second: 157, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000748, mae: 0.013305, mean_q: 0.012965
 81736/100000: episode: 11243, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000565, mae: 0.010540, mean_q: 0.007158
 81740/100000: episode: 11244, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000544, mae: 0.013691, mean_q: 0.011041
 81744/100000: episode: 11245, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000070, mae: 0.008103, mean_q: 0.009560
 81750/100000: episode: 11246, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000361, mae: 0.011723, mean_q: 0.009660
 81754/100000: episode: 11247, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000986, mae: 0.012276, mean_q: 0.016172
 81760/100000: episode: 11248, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000194, mae: 0.011628, mean_q: 0.005442
 81764/100000: episode: 11249, duration: 0.024s, episode steps: 4, steps per second: 167, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000094, mae: 0.009496, mean_q: 0.015030
 81768/100000: episode: 11250, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000100, mae: 0.009305, mean_q: 0.004156
 81772/100000: episode: 11251, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000130, mae: 0.011804, mean_q: 0.018775
 81776/100000: episode: 11252, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000311, mae: 0.012946, mean_q: 0.003327
 81780/100000: episode: 11253, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000287, mae: 0.019540, mean_q: 0.029287
 81784/100000: episode: 11254, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000287, mae: 0.019371, mean_q: -0.003320
 81788/100000: episode: 11255, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000480, mae: 0.015456, mean_q: 0.024850
 81792/100000: episode: 11256, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000238, mae: 0.012558, mean_q: 0.003821
 81798/100000: episode: 11257, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000243, mae: 0.013628, mean_q: 0.017398
 81802/100000: episode: 11258, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000168, mae: 0.012185, mean_q: 0.006392
 81806/100000: episode: 11259, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000240, mae: 0.012553, mean_q: 0.019728
 81810/100000: episode: 11260, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000090, mae: 0.007905, mean_q: 0.006825
 81814/100000: episode: 11261, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000073, mae: 0.006695, mean_q: 0.009211
 81818/100000: episode: 11262, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000320, mae: 0.009578, mean_q: 0.015149
 81822/100000: episode: 11263, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000148, mae: 0.008844, mean_q: 0.011491
 81828/100000: episode: 11264, duration: 0.034s, episode steps: 6, steps per second: 179, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000420, mae: 0.011747, mean_q: 0.023195
 81832/100000: episode: 11265, duration: 0.029s, episode steps: 4, steps per second: 138, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001483, mae: 0.018633, mean_q: 0.015117
 81836/100000: episode: 11266, duration: 0.028s, episode steps: 4, steps per second: 143, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000162, mae: 0.011384, mean_q: 0.012318
 81842/100000: episode: 11267, duration: 0.036s, episode steps: 6, steps per second: 165, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000570, mae: 0.012452, mean_q: 0.017283
 81848/100000: episode: 11268, duration: 0.033s, episode steps: 6, steps per second: 182, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001945, mae: 0.014239, mean_q: 0.013808
 81852/100000: episode: 11269, duration: 0.028s, episode steps: 4, steps per second: 145, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000460, mae: 0.017261, mean_q: 0.025491
 81858/100000: episode: 11270, duration: 0.033s, episode steps: 6, steps per second: 179, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000557, mae: 0.012038, mean_q: 0.015058
 81862/100000: episode: 11271, duration: 0.027s, episode steps: 4, steps per second: 147, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000264, mae: 0.012552, mean_q: 0.010716
 81866/100000: episode: 11272, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000231, mae: 0.012474, mean_q: 0.016142
 81872/100000: episode: 11273, duration: 0.033s, episode steps: 6, steps per second: 182, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000157, mae: 0.009679, mean_q: 0.007287
 81876/100000: episode: 11274, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000317, mae: 0.010859, mean_q: 0.017200
 81880/100000: episode: 11275, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000205, mae: 0.009621, mean_q: 0.013942
 81884/100000: episode: 11276, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000364, mae: 0.010816, mean_q: 0.015012
 81888/100000: episode: 11277, duration: 0.029s, episode steps: 4, steps per second: 138, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000816, mae: 0.014240, mean_q: 0.018306
 81894/100000: episode: 11278, duration: 0.036s, episode steps: 6, steps per second: 167, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000331, mae: 0.012131, mean_q: 0.012820
 81898/100000: episode: 11279, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001041, mae: 0.016106, mean_q: 0.022125
 81904/100000: episode: 11280, duration: 0.034s, episode steps: 6, steps per second: 178, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000162, mae: 0.011703, mean_q: 0.013668
 81908/100000: episode: 11281, duration: 0.028s, episode steps: 4, steps per second: 140, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000826, mae: 0.014446, mean_q: 0.015269
 81912/100000: episode: 11282, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000670, mae: 0.015072, mean_q: 0.017517
 81916/100000: episode: 11283, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000894, mae: 0.014262, mean_q: 0.006463
 81920/100000: episode: 11284, duration: 0.026s, episode steps: 4, steps per second: 153, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000220, mae: 0.013813, mean_q: 0.021467
 81924/100000: episode: 11285, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000168, mae: 0.012210, mean_q: 0.007590
 81930/100000: episode: 11286, duration: 0.034s, episode steps: 6, steps per second: 175, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001603, mae: 0.016246, mean_q: 0.016238
 81934/100000: episode: 11287, duration: 0.028s, episode steps: 4, steps per second: 145, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000634, mae: 0.016909, mean_q: 0.019970
 81938/100000: episode: 11288, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000420, mae: 0.015237, mean_q: 0.021144
 81942/100000: episode: 11289, duration: 0.028s, episode steps: 4, steps per second: 143, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000279, mae: 0.013147, mean_q: 0.019161
 81948/100000: episode: 11290, duration: 0.038s, episode steps: 6, steps per second: 157, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000232, mae: 0.012777, mean_q: 0.010241
 81954/100000: episode: 11291, duration: 0.043s, episode steps: 6, steps per second: 139, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000494, mae: 0.012274, mean_q: 0.013167
 81960/100000: episode: 11292, duration: 0.037s, episode steps: 6, steps per second: 160, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000294, mae: 0.012487, mean_q: 0.017565
 81964/100000: episode: 11293, duration: 0.028s, episode steps: 4, steps per second: 141, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000683, mae: 0.014151, mean_q: 0.014111
 81970/100000: episode: 11294, duration: 0.036s, episode steps: 6, steps per second: 168, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000175, mae: 0.011107, mean_q: 0.016945
 81976/100000: episode: 11295, duration: 0.033s, episode steps: 6, steps per second: 181, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000147, mae: 0.011151, mean_q: 0.012605
 81980/100000: episode: 11296, duration: 0.028s, episode steps: 4, steps per second: 142, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000418, mae: 0.013376, mean_q: 0.021220
 81984/100000: episode: 11297, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000151, mae: 0.010099, mean_q: 0.013153
 81988/100000: episode: 11298, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000253, mae: 0.013115, mean_q: 0.022297
 81994/100000: episode: 11299, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000244, mae: 0.011644, mean_q: 0.013496
[Info] 2-TH LEVEL FOUND: 0.07679539918899536, Considering 19/100 traces
 81998/100000: episode: 11300, duration: 0.721s, episode steps: 4, steps per second: 6, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000128, mae: 0.010019, mean_q: 0.015066
 82003/100000: episode: 11301, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000197, mae: 0.011046, mean_q: 0.009415
 82008/100000: episode: 11302, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000151, mae: 0.010250, mean_q: 0.013560
 82013/100000: episode: 11303, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000235, mae: 0.010808, mean_q: 0.015664
 82018/100000: episode: 11304, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000631, mae: 0.013693, mean_q: 0.021259
 82023/100000: episode: 11305, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000398, mae: 0.010779, mean_q: 0.008462
 82028/100000: episode: 11306, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000147, mae: 0.011852, mean_q: 0.016269
 82033/100000: episode: 11307, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000196, mae: 0.013582, mean_q: 0.012808
 82038/100000: episode: 11308, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000615, mae: 0.014873, mean_q: 0.013343
 82043/100000: episode: 11309, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000327, mae: 0.012349, mean_q: 0.017290
 82048/100000: episode: 11310, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000271, mae: 0.009567, mean_q: 0.010275
 82053/100000: episode: 11311, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001009, mae: 0.018820, mean_q: 0.027372
 82058/100000: episode: 11312, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000713, mae: 0.015646, mean_q: 0.025826
 82063/100000: episode: 11313, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000651, mae: 0.015154, mean_q: 0.014543
 82068/100000: episode: 11314, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000173, mae: 0.011611, mean_q: 0.017181
 82073/100000: episode: 11315, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000180, mae: 0.010392, mean_q: 0.016048
 82078/100000: episode: 11316, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000249, mae: 0.010862, mean_q: 0.016171
 82083/100000: episode: 11317, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000207, mae: 0.010262, mean_q: 0.015298
 82088/100000: episode: 11318, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000259, mae: 0.012050, mean_q: 0.018634
 82093/100000: episode: 11319, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000488, mae: 0.016439, mean_q: 0.011565
 82098/100000: episode: 11320, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002514, mae: 0.028019, mean_q: 0.040154
 82103/100000: episode: 11321, duration: 0.028s, episode steps: 5, steps per second: 179, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.003372, mae: 0.032516, mean_q: 0.023725
 82108/100000: episode: 11322, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000418, mae: 0.015193, mean_q: 0.020215
 82113/100000: episode: 11323, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000298, mae: 0.014337, mean_q: 0.009039
 82118/100000: episode: 11324, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002083, mae: 0.022064, mean_q: 0.029895
 82123/100000: episode: 11325, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000539, mae: 0.019620, mean_q: 0.016229
 82128/100000: episode: 11326, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001542, mae: 0.017997, mean_q: 0.021356
[Info] FALSIFICATION!
 82132/100000: episode: 11327, duration: 0.238s, episode steps: 4, steps per second: 17, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000369, mae: 0.015970, mean_q: 0.022842
 82137/100000: episode: 11328, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000488, mae: 0.016116, mean_q: 0.010728
 82142/100000: episode: 11329, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000604, mae: 0.014636, mean_q: 0.016419
 82147/100000: episode: 11330, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002273, mae: 0.021489, mean_q: 0.023913
 82152/100000: episode: 11331, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000358, mae: 0.018466, mean_q: 0.009812
 82157/100000: episode: 11332, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001267, mae: 0.025138, mean_q: 0.041317
 82162/100000: episode: 11333, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000681, mae: 0.016351, mean_q: 0.008043
 82167/100000: episode: 11334, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000545, mae: 0.020149, mean_q: 0.027717
 82172/100000: episode: 11335, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000294, mae: 0.015408, mean_q: 0.014240
 82177/100000: episode: 11336, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000332, mae: 0.013011, mean_q: 0.018322
 82182/100000: episode: 11337, duration: 0.030s, episode steps: 5, steps per second: 164, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000761, mae: 0.016356, mean_q: 0.023057
 82187/100000: episode: 11338, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000246, mae: 0.014649, mean_q: 0.021718
 82192/100000: episode: 11339, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000333, mae: 0.015444, mean_q: 0.014884
 82197/100000: episode: 11340, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000462, mae: 0.014025, mean_q: 0.018349
[Info] FALSIFICATION!
 82201/100000: episode: 11341, duration: 0.175s, episode steps: 4, steps per second: 23, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000837, mae: 0.017149, mean_q: 0.022952
 82206/100000: episode: 11342, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001801, mae: 0.017470, mean_q: 0.022571
 82211/100000: episode: 11343, duration: 0.029s, episode steps: 5, steps per second: 170, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000860, mae: 0.018473, mean_q: 0.016205
 82216/100000: episode: 11344, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000855, mae: 0.018698, mean_q: 0.027897
[Info] FALSIFICATION!
 82220/100000: episode: 11345, duration: 0.268s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000814, mae: 0.019149, mean_q: 0.016102
 82225/100000: episode: 11346, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000663, mae: 0.019330, mean_q: 0.030269
 82230/100000: episode: 11347, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000659, mae: 0.019729, mean_q: 0.016178
 82235/100000: episode: 11348, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000418, mae: 0.016383, mean_q: 0.018284
 82240/100000: episode: 11349, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000834, mae: 0.015486, mean_q: 0.016535
 82245/100000: episode: 11350, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000960, mae: 0.017111, mean_q: 0.021172
 82250/100000: episode: 11351, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.002280, mae: 0.020083, mean_q: 0.025227
 82255/100000: episode: 11352, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000815, mae: 0.022808, mean_q: 0.031947
 82260/100000: episode: 11353, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000680, mae: 0.019745, mean_q: 0.018409
 82265/100000: episode: 11354, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000298, mae: 0.013755, mean_q: 0.011807
 82270/100000: episode: 11355, duration: 0.030s, episode steps: 5, steps per second: 168, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001850, mae: 0.021754, mean_q: 0.026860
 82275/100000: episode: 11356, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000344, mae: 0.015682, mean_q: 0.013981
 82280/100000: episode: 11357, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000384, mae: 0.014654, mean_q: 0.016858
 82285/100000: episode: 11358, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000300, mae: 0.014479, mean_q: 0.015586
 82290/100000: episode: 11359, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000424, mae: 0.015403, mean_q: 0.015566
 82295/100000: episode: 11360, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000552, mae: 0.015767, mean_q: 0.018152
 82300/100000: episode: 11361, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001395, mae: 0.021290, mean_q: 0.029182
 82305/100000: episode: 11362, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000218, mae: 0.012959, mean_q: 0.014995
 82310/100000: episode: 11363, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.001662, mae: 0.016219, mean_q: 0.014978
 82315/100000: episode: 11364, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000330, mae: 0.015649, mean_q: 0.018882
 82320/100000: episode: 11365, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001926, mae: 0.025058, mean_q: 0.031098
 82325/100000: episode: 11366, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000731, mae: 0.018999, mean_q: 0.010398
 82330/100000: episode: 11367, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000550, mae: 0.017631, mean_q: 0.026028
 82335/100000: episode: 11368, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000540, mae: 0.016582, mean_q: 0.014348
 82340/100000: episode: 11369, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000635, mae: 0.018585, mean_q: 0.030371
 82345/100000: episode: 11370, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000391, mae: 0.014488, mean_q: 0.014939
 82350/100000: episode: 11371, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000261, mae: 0.014883, mean_q: 0.014474
 82355/100000: episode: 11372, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000807, mae: 0.018222, mean_q: 0.027791
 82360/100000: episode: 11373, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000190, mae: 0.012349, mean_q: 0.016568
 82365/100000: episode: 11374, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000305, mae: 0.013288, mean_q: 0.021250
 82370/100000: episode: 11375, duration: 0.029s, episode steps: 5, steps per second: 174, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000125, mae: 0.008794, mean_q: 0.012504
 82375/100000: episode: 11376, duration: 0.028s, episode steps: 5, steps per second: 179, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000245, mae: 0.009998, mean_q: 0.018981
 82380/100000: episode: 11377, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000170, mae: 0.009951, mean_q: 0.013905
 82385/100000: episode: 11378, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000991, mae: 0.016229, mean_q: 0.025946
 82390/100000: episode: 11379, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000790, mae: 0.016096, mean_q: 0.023756
[Info] FALSIFICATION!
 82394/100000: episode: 11380, duration: 0.174s, episode steps: 4, steps per second: 23, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000926, mae: 0.017844, mean_q: 0.027950
[Info] Complete ISplit Iteration
[Info] Levels: [0.033038646, 0.0767954, 0.8362254]
[Info] Cond. Prob: [0.11, 0.19, 0.04]
[Info] Error Prob: 0.000836

 82399/100000: episode: 11381, duration: 0.893s, episode steps: 5, steps per second: 6, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001978, mae: 0.018672, mean_q: 0.021979
 82409/100000: episode: 11382, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000995, mae: 0.018849, mean_q: 0.027556
 82419/100000: episode: 11383, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001068, mae: 0.019369, mean_q: 0.023317
 82429/100000: episode: 11384, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000865, mae: 0.019323, mean_q: 0.020852
 82439/100000: episode: 11385, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000456, mae: 0.017070, mean_q: 0.017907
 82449/100000: episode: 11386, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.003270, mae: 0.033597, mean_q: 0.026306
 82459/100000: episode: 11387, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001235, mae: 0.030782, mean_q: 0.026231
 82469/100000: episode: 11388, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000968, mae: 0.026405, mean_q: 0.025472
 82479/100000: episode: 11389, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000858, mae: 0.023150, mean_q: 0.027343
 82489/100000: episode: 11390, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000736, mae: 0.020282, mean_q: 0.021950
 82499/100000: episode: 11391, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000791, mae: 0.021272, mean_q: 0.028919
 82509/100000: episode: 11392, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000983, mae: 0.017950, mean_q: 0.023179
 82519/100000: episode: 11393, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001139, mae: 0.020932, mean_q: 0.034143
 82529/100000: episode: 11394, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000870, mae: 0.018388, mean_q: 0.027635
 82539/100000: episode: 11395, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000609, mae: 0.017472, mean_q: 0.023526
 82549/100000: episode: 11396, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000667, mae: 0.015215, mean_q: 0.016455
 82559/100000: episode: 11397, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000746, mae: 0.017103, mean_q: 0.021605
 82569/100000: episode: 11398, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001487, mae: 0.025613, mean_q: 0.034489
 82579/100000: episode: 11399, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000550, mae: 0.017937, mean_q: 0.019568
 82589/100000: episode: 11400, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000531, mae: 0.013577, mean_q: 0.019388
 82599/100000: episode: 11401, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000858, mae: 0.016589, mean_q: 0.024936
 82609/100000: episode: 11402, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000821, mae: 0.017036, mean_q: 0.025268
 82619/100000: episode: 11403, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000773, mae: 0.015699, mean_q: 0.021179
 82629/100000: episode: 11404, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000614, mae: 0.019250, mean_q: 0.026793
 82639/100000: episode: 11405, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000874, mae: 0.017867, mean_q: 0.024231
 82649/100000: episode: 11406, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001032, mae: 0.018171, mean_q: 0.024555
 82659/100000: episode: 11407, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001581, mae: 0.023668, mean_q: 0.033731
 82669/100000: episode: 11408, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000776, mae: 0.022196, mean_q: 0.016473
 82679/100000: episode: 11409, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001276, mae: 0.021550, mean_q: 0.029029
 82689/100000: episode: 11410, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000738, mae: 0.017080, mean_q: 0.023296
 82699/100000: episode: 11411, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000929, mae: 0.019760, mean_q: 0.026769
 82709/100000: episode: 11412, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001072, mae: 0.018150, mean_q: 0.021250
 82719/100000: episode: 11413, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000495, mae: 0.016266, mean_q: 0.023675
 82729/100000: episode: 11414, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001142, mae: 0.020060, mean_q: 0.031788
 82739/100000: episode: 11415, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000623, mae: 0.015105, mean_q: 0.023112
 82749/100000: episode: 11416, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001240, mae: 0.018707, mean_q: 0.025287
 82759/100000: episode: 11417, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000856, mae: 0.022564, mean_q: 0.027904
 82769/100000: episode: 11418, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000988, mae: 0.021812, mean_q: 0.033829
 82779/100000: episode: 11419, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000964, mae: 0.020561, mean_q: 0.031963
 82789/100000: episode: 11420, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000636, mae: 0.016976, mean_q: 0.022957
 82799/100000: episode: 11421, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000324, mae: 0.014731, mean_q: 0.015628
 82809/100000: episode: 11422, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001018, mae: 0.019661, mean_q: 0.025645
 82819/100000: episode: 11423, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000518, mae: 0.017002, mean_q: 0.024998
 82829/100000: episode: 11424, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001087, mae: 0.018681, mean_q: 0.021434
 82839/100000: episode: 11425, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000978, mae: 0.018539, mean_q: 0.023793
 82849/100000: episode: 11426, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000656, mae: 0.016640, mean_q: 0.021556
 82859/100000: episode: 11427, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001947, mae: 0.017355, mean_q: 0.021271
 82869/100000: episode: 11428, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000652, mae: 0.021912, mean_q: 0.014665
 82879/100000: episode: 11429, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.001697, mae: 0.032237, mean_q: 0.027645
 82889/100000: episode: 11430, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001279, mae: 0.023096, mean_q: 0.024608
 82899/100000: episode: 11431, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000481, mae: 0.018088, mean_q: 0.024828
 82909/100000: episode: 11432, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000575, mae: 0.016476, mean_q: 0.023095
 82919/100000: episode: 11433, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001223, mae: 0.020040, mean_q: 0.030664
 82929/100000: episode: 11434, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000634, mae: 0.017423, mean_q: 0.024736
 82939/100000: episode: 11435, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000599, mae: 0.016087, mean_q: 0.026408
 82949/100000: episode: 11436, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001339, mae: 0.020593, mean_q: 0.027683
 82959/100000: episode: 11437, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000898, mae: 0.018510, mean_q: 0.019955
 82969/100000: episode: 11438, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000854, mae: 0.019760, mean_q: 0.029066
 82979/100000: episode: 11439, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002215, mae: 0.024465, mean_q: 0.026475
 82989/100000: episode: 11440, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001378, mae: 0.023551, mean_q: 0.035214
 82999/100000: episode: 11441, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000584, mae: 0.017248, mean_q: 0.020622
 83009/100000: episode: 11442, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000470, mae: 0.015077, mean_q: 0.020903
 83019/100000: episode: 11443, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000474, mae: 0.014102, mean_q: 0.018921
 83029/100000: episode: 11444, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001017, mae: 0.018753, mean_q: 0.024981
 83039/100000: episode: 11445, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000687, mae: 0.021494, mean_q: 0.022117
 83049/100000: episode: 11446, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000526, mae: 0.019273, mean_q: 0.022496
 83059/100000: episode: 11447, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000666, mae: 0.015694, mean_q: 0.022716
 83069/100000: episode: 11448, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000632, mae: 0.014708, mean_q: 0.019670
 83079/100000: episode: 11449, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001407, mae: 0.020316, mean_q: 0.026326
 83089/100000: episode: 11450, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000901, mae: 0.020125, mean_q: 0.023134
 83099/100000: episode: 11451, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001167, mae: 0.020793, mean_q: 0.026413
 83109/100000: episode: 11452, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000734, mae: 0.015886, mean_q: 0.021906
 83119/100000: episode: 11453, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000665, mae: 0.015586, mean_q: 0.021421
 83129/100000: episode: 11454, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000781, mae: 0.018436, mean_q: 0.021968
 83139/100000: episode: 11455, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000406, mae: 0.014127, mean_q: 0.018900
 83149/100000: episode: 11456, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000614, mae: 0.013412, mean_q: 0.019094
 83159/100000: episode: 11457, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002235, mae: 0.019010, mean_q: 0.021012
 83169/100000: episode: 11458, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000767, mae: 0.022188, mean_q: 0.020220
 83179/100000: episode: 11459, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000877, mae: 0.022836, mean_q: 0.021280
 83189/100000: episode: 11460, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000458, mae: 0.015438, mean_q: 0.017637
 83199/100000: episode: 11461, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001033, mae: 0.016550, mean_q: 0.024178
 83209/100000: episode: 11462, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000563, mae: 0.015503, mean_q: 0.023619
 83219/100000: episode: 11463, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000494, mae: 0.014262, mean_q: 0.020457
 83229/100000: episode: 11464, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001220, mae: 0.020837, mean_q: 0.032453
 83239/100000: episode: 11465, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001080, mae: 0.022652, mean_q: 0.030322
 83249/100000: episode: 11466, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000813, mae: 0.019391, mean_q: 0.029113
 83259/100000: episode: 11467, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000923, mae: 0.015468, mean_q: 0.022190
 83269/100000: episode: 11468, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000562, mae: 0.014783, mean_q: 0.015485
 83279/100000: episode: 11469, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000147, mae: 0.009673, mean_q: 0.013496
 83289/100000: episode: 11470, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000406, mae: 0.011853, mean_q: 0.017421
 83299/100000: episode: 11471, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000334, mae: 0.011549, mean_q: 0.016110
 83309/100000: episode: 11472, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001264, mae: 0.017408, mean_q: 0.021577
 83319/100000: episode: 11473, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001278, mae: 0.017605, mean_q: 0.023833
 83329/100000: episode: 11474, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000634, mae: 0.015233, mean_q: 0.022446
 83339/100000: episode: 11475, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000469, mae: 0.011612, mean_q: 0.016267
 83349/100000: episode: 11476, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000340, mae: 0.011282, mean_q: 0.018437
 83359/100000: episode: 11477, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000386, mae: 0.012549, mean_q: 0.020648
 83369/100000: episode: 11478, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000676, mae: 0.014939, mean_q: 0.021943
 83379/100000: episode: 11479, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000698, mae: 0.015815, mean_q: 0.023903
 83389/100000: episode: 11480, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000428, mae: 0.015458, mean_q: 0.020796
[Info] 1-TH LEVEL FOUND: 0.034272342920303345, Considering 12/100 traces
 83399/100000: episode: 11481, duration: 0.661s, episode steps: 10, steps per second: 15, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000692, mae: 0.015632, mean_q: 0.020352
 83401/100000: episode: 11482, duration: 0.014s, episode steps: 2, steps per second: 140, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003731, mae: 0.021089, mean_q: 0.021118
 83407/100000: episode: 11483, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000617, mae: 0.013543, mean_q: 0.026279
 83411/100000: episode: 11484, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000706, mae: 0.017068, mean_q: 0.026440
 83415/100000: episode: 11485, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000956, mae: 0.015034, mean_q: 0.018874
 83417/100000: episode: 11486, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000188, mae: 0.011903, mean_q: 0.019056
 83419/100000: episode: 11487, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000259, mae: 0.012731, mean_q: 0.022646
 83425/100000: episode: 11488, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000777, mae: 0.016336, mean_q: 0.020017
 83429/100000: episode: 11489, duration: 0.024s, episode steps: 4, steps per second: 170, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000435, mae: 0.016110, mean_q: 0.026840
 83431/100000: episode: 11490, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000141, mae: 0.011184, mean_q: 0.007724
 83433/100000: episode: 11491, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000218, mae: 0.009142, mean_q: 0.010810
 83439/100000: episode: 11492, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000663, mae: 0.012981, mean_q: 0.014001
 83443/100000: episode: 11493, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000300, mae: 0.012412, mean_q: 0.016826
 83449/100000: episode: 11494, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000263, mae: 0.014213, mean_q: 0.016886
 83451/100000: episode: 11495, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005768, mae: 0.028359, mean_q: 0.017231
 83455/100000: episode: 11496, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000506, mae: 0.018789, mean_q: 0.027225
 83457/100000: episode: 11497, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000178, mae: 0.012999, mean_q: 0.007427
 83463/100000: episode: 11498, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002938, mae: 0.027394, mean_q: 0.036047
 83469/100000: episode: 11499, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000603, mae: 0.019441, mean_q: 0.009187
 83471/100000: episode: 11500, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002800, mae: 0.030057, mean_q: 0.036364
 83473/100000: episode: 11501, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001391, mae: 0.019024, mean_q: 0.032538
 83479/100000: episode: 11502, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000741, mae: 0.019102, mean_q: 0.012577
 83485/100000: episode: 11503, duration: 0.032s, episode steps: 6, steps per second: 189, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000811, mae: 0.018649, mean_q: 0.018809
 83491/100000: episode: 11504, duration: 0.032s, episode steps: 6, steps per second: 190, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000766, mae: 0.017066, mean_q: 0.025386
 83497/100000: episode: 11505, duration: 0.032s, episode steps: 6, steps per second: 187, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000545, mae: 0.016280, mean_q: 0.022109
 83503/100000: episode: 11506, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000629, mae: 0.013357, mean_q: 0.016674
 83507/100000: episode: 11507, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000437, mae: 0.014354, mean_q: 0.024286
 83509/100000: episode: 11508, duration: 0.014s, episode steps: 2, steps per second: 142, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000214, mae: 0.012544, mean_q: 0.020905
 83513/100000: episode: 11509, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001410, mae: 0.019957, mean_q: 0.025499
 83515/100000: episode: 11510, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000130, mae: 0.008415, mean_q: 0.012099
 83519/100000: episode: 11511, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000812, mae: 0.016028, mean_q: 0.021814
 83523/100000: episode: 11512, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000385, mae: 0.014640, mean_q: 0.024471
 83527/100000: episode: 11513, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000248, mae: 0.016026, mean_q: 0.010175
 83529/100000: episode: 11514, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000681, mae: 0.017247, mean_q: 0.018490
 83535/100000: episode: 11515, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000549, mae: 0.015393, mean_q: 0.017449
 83537/100000: episode: 11516, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001003, mae: 0.017029, mean_q: 0.011699
 83543/100000: episode: 11517, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000515, mae: 0.016040, mean_q: 0.023884
 83545/100000: episode: 11518, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000195, mae: 0.011061, mean_q: 0.012135
 83549/100000: episode: 11519, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000728, mae: 0.013947, mean_q: 0.018364
 83551/100000: episode: 11520, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001001, mae: 0.015799, mean_q: 0.022976
 83557/100000: episode: 11521, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000450, mae: 0.014302, mean_q: 0.015008
 83559/100000: episode: 11522, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000398, mae: 0.017816, mean_q: 0.027505
 83565/100000: episode: 11523, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000893, mae: 0.014583, mean_q: 0.021977
 83567/100000: episode: 11524, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000842, mae: 0.014574, mean_q: 0.020946
 83573/100000: episode: 11525, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001000, mae: 0.018612, mean_q: 0.023686
 83575/100000: episode: 11526, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000156, mae: 0.012392, mean_q: 0.021749
 83577/100000: episode: 11527, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000440, mae: 0.015092, mean_q: 0.014036
 83579/100000: episode: 11528, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000982, mae: 0.019126, mean_q: 0.013803
 83585/100000: episode: 11529, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000790, mae: 0.018105, mean_q: 0.028783
 83589/100000: episode: 11530, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000804, mae: 0.016170, mean_q: 0.012453
 83591/100000: episode: 11531, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000260, mae: 0.016719, mean_q: 0.024811
 83597/100000: episode: 11532, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000328, mae: 0.014819, mean_q: 0.018400
 83603/100000: episode: 11533, duration: 0.031s, episode steps: 6, steps per second: 197, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.002177, mae: 0.023115, mean_q: 0.031712
 83605/100000: episode: 11534, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000890, mae: 0.018048, mean_q: 0.027823
 83611/100000: episode: 11535, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000376, mae: 0.018400, mean_q: 0.010889
 83617/100000: episode: 11536, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000561, mae: 0.016124, mean_q: 0.014017
 83619/100000: episode: 11537, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000494, mae: 0.015600, mean_q: 0.026089
 83621/100000: episode: 11538, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003002, mae: 0.031107, mean_q: 0.035425
 83627/100000: episode: 11539, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000509, mae: 0.015353, mean_q: 0.012882
[Info] FALSIFICATION!
 83632/100000: episode: 11540, duration: 0.257s, episode steps: 5, steps per second: 19, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000485, mae: 0.015218, mean_q: 0.020485
 83634/100000: episode: 11541, duration: 0.015s, episode steps: 2, steps per second: 133, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001174, mae: 0.017799, mean_q: 0.029037
 83638/100000: episode: 11542, duration: 0.024s, episode steps: 4, steps per second: 170, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000286, mae: 0.014171, mean_q: 0.018363
 83642/100000: episode: 11543, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000889, mae: 0.017569, mean_q: 0.022997
 83648/100000: episode: 11544, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000595, mae: 0.017208, mean_q: 0.023823
 83654/100000: episode: 11545, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002249, mae: 0.024655, mean_q: 0.029181
 83656/100000: episode: 11546, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000288, mae: 0.014059, mean_q: 0.020651
 83662/100000: episode: 11547, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001303, mae: 0.026451, mean_q: 0.021565
 83664/100000: episode: 11548, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000260, mae: 0.015352, mean_q: 0.022785
 83668/100000: episode: 11549, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001116, mae: 0.020449, mean_q: 0.028079
 83674/100000: episode: 11550, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000843, mae: 0.016206, mean_q: 0.018538
 83678/100000: episode: 11551, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000697, mae: 0.012826, mean_q: 0.019005
 83682/100000: episode: 11552, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000400, mae: 0.015353, mean_q: 0.024156
 83688/100000: episode: 11553, duration: 0.031s, episode steps: 6, steps per second: 197, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000581, mae: 0.016538, mean_q: 0.018680
 83692/100000: episode: 11554, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000693, mae: 0.019295, mean_q: 0.027693
 83694/100000: episode: 11555, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000367, mae: 0.013838, mean_q: 0.021738
 83698/100000: episode: 11556, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001971, mae: 0.019572, mean_q: 0.020266
 83700/100000: episode: 11557, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000431, mae: 0.017473, mean_q: 0.031669
 83704/100000: episode: 11558, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000671, mae: 0.018527, mean_q: 0.021739
 83710/100000: episode: 11559, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000596, mae: 0.016783, mean_q: 0.022005
 83712/100000: episode: 11560, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000900, mae: 0.018877, mean_q: 0.023443
 83716/100000: episode: 11561, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000289, mae: 0.014914, mean_q: 0.016965
 83718/100000: episode: 11562, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002184, mae: 0.026298, mean_q: 0.030448
 83720/100000: episode: 11563, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001330, mae: 0.022647, mean_q: 0.009705
 83724/100000: episode: 11564, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001521, mae: 0.020490, mean_q: 0.028334
 83726/100000: episode: 11565, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000196, mae: 0.012320, mean_q: 0.020819
 83728/100000: episode: 11566, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001359, mae: 0.024252, mean_q: 0.031532
 83734/100000: episode: 11567, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003484, mae: 0.024194, mean_q: 0.025437
 83738/100000: episode: 11568, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000704, mae: 0.021234, mean_q: 0.038647
[Info] Complete ISplit Iteration
[Info] Levels: [0.034272343, 0.9791135]
[Info] Cond. Prob: [0.12, 0.01]
[Info] Error Prob: 0.0012

 83744/100000: episode: 11569, duration: 0.739s, episode steps: 6, steps per second: 8, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000704, mae: 0.022708, mean_q: 0.015843
 83754/100000: episode: 11570, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001208, mae: 0.021762, mean_q: 0.020990
 83764/100000: episode: 11571, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001577, mae: 0.020920, mean_q: 0.025872
 83774/100000: episode: 11572, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001405, mae: 0.023468, mean_q: 0.021915
 83784/100000: episode: 11573, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000607, mae: 0.019041, mean_q: 0.019947
 83794/100000: episode: 11574, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000359, mae: 0.013588, mean_q: 0.018479
 83804/100000: episode: 11575, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000600, mae: 0.014292, mean_q: 0.019646
 83814/100000: episode: 11576, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000522, mae: 0.013963, mean_q: 0.020469
 83824/100000: episode: 11577, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000943, mae: 0.016771, mean_q: 0.023715
 83834/100000: episode: 11578, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001564, mae: 0.018261, mean_q: 0.022252
 83844/100000: episode: 11579, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000431, mae: 0.013668, mean_q: 0.015945
 83854/100000: episode: 11580, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001336, mae: 0.019569, mean_q: 0.019896
 83864/100000: episode: 11581, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000643, mae: 0.017004, mean_q: 0.022049
 83874/100000: episode: 11582, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000669, mae: 0.014305, mean_q: 0.020038
 83884/100000: episode: 11583, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001258, mae: 0.018827, mean_q: 0.025076
 83894/100000: episode: 11584, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000434, mae: 0.015700, mean_q: 0.017827
 83904/100000: episode: 11585, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000532, mae: 0.012090, mean_q: 0.015651
 83914/100000: episode: 11586, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000763, mae: 0.015793, mean_q: 0.023476
 83924/100000: episode: 11587, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000890, mae: 0.016920, mean_q: 0.022911
 83934/100000: episode: 11588, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000518, mae: 0.013699, mean_q: 0.019569
 83944/100000: episode: 11589, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001409, mae: 0.018579, mean_q: 0.025930
 83954/100000: episode: 11590, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000317, mae: 0.014413, mean_q: 0.017078
 83964/100000: episode: 11591, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000449, mae: 0.011276, mean_q: 0.016302
 83974/100000: episode: 11592, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001084, mae: 0.018732, mean_q: 0.025776
 83984/100000: episode: 11593, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001404, mae: 0.021838, mean_q: 0.023276
 83994/100000: episode: 11594, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001510, mae: 0.021958, mean_q: 0.029140
 84004/100000: episode: 11595, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001034, mae: 0.020969, mean_q: 0.026594
 84014/100000: episode: 11596, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000776, mae: 0.018083, mean_q: 0.018141
 84024/100000: episode: 11597, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000583, mae: 0.016283, mean_q: 0.022591
 84034/100000: episode: 11598, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000596, mae: 0.014387, mean_q: 0.018823
 84044/100000: episode: 11599, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000733, mae: 0.016583, mean_q: 0.023267
 84054/100000: episode: 11600, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002081, mae: 0.026932, mean_q: 0.028896
 84064/100000: episode: 11601, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000583, mae: 0.020810, mean_q: 0.022480
 84074/100000: episode: 11602, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000307, mae: 0.013245, mean_q: 0.016499
 84084/100000: episode: 11603, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001267, mae: 0.018344, mean_q: 0.022878
 84094/100000: episode: 11604, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000843, mae: 0.017925, mean_q: 0.023797
 84104/100000: episode: 11605, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001291, mae: 0.017553, mean_q: 0.019919
 84114/100000: episode: 11606, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000679, mae: 0.018700, mean_q: 0.027222
 84124/100000: episode: 11607, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000727, mae: 0.019328, mean_q: 0.027325
 84134/100000: episode: 11608, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000653, mae: 0.017043, mean_q: 0.023229
 84144/100000: episode: 11609, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000652, mae: 0.018647, mean_q: 0.023921
 84154/100000: episode: 11610, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000377, mae: 0.012471, mean_q: 0.015932
 84164/100000: episode: 11611, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000783, mae: 0.017782, mean_q: 0.029295
 84174/100000: episode: 11612, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000668, mae: 0.016779, mean_q: 0.029177
 84184/100000: episode: 11613, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001426, mae: 0.022012, mean_q: 0.020767
 84194/100000: episode: 11614, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000973, mae: 0.019211, mean_q: 0.023079
 84204/100000: episode: 11615, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001485, mae: 0.018809, mean_q: 0.025548
 84214/100000: episode: 11616, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000829, mae: 0.019248, mean_q: 0.022239
 84224/100000: episode: 11617, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000977, mae: 0.021582, mean_q: 0.028888
 84234/100000: episode: 11618, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001345, mae: 0.020049, mean_q: 0.027116
 84244/100000: episode: 11619, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000969, mae: 0.019442, mean_q: 0.025751
 84254/100000: episode: 11620, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000814, mae: 0.016298, mean_q: 0.020009
 84264/100000: episode: 11621, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000537, mae: 0.015108, mean_q: 0.020262
 84274/100000: episode: 11622, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001258, mae: 0.017904, mean_q: 0.026147
 84284/100000: episode: 11623, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000655, mae: 0.018460, mean_q: 0.024501
 84294/100000: episode: 11624, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001275, mae: 0.018110, mean_q: 0.022351
 84304/100000: episode: 11625, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000641, mae: 0.018061, mean_q: 0.025005
 84314/100000: episode: 11626, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000832, mae: 0.017313, mean_q: 0.026415
 84324/100000: episode: 11627, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000573, mae: 0.014476, mean_q: 0.016594
 84334/100000: episode: 11628, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000304, mae: 0.013816, mean_q: 0.015717
 84344/100000: episode: 11629, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000522, mae: 0.016110, mean_q: 0.018939
 84354/100000: episode: 11630, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000742, mae: 0.018244, mean_q: 0.025513
 84364/100000: episode: 11631, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001557, mae: 0.025195, mean_q: 0.030769
 84374/100000: episode: 11632, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000476, mae: 0.018426, mean_q: 0.017673
 84384/100000: episode: 11633, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000467, mae: 0.017388, mean_q: 0.021407
 84394/100000: episode: 11634, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000929, mae: 0.018245, mean_q: 0.023153
 84404/100000: episode: 11635, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000638, mae: 0.016611, mean_q: 0.023048
 84414/100000: episode: 11636, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000898, mae: 0.018205, mean_q: 0.023831
 84424/100000: episode: 11637, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000373, mae: 0.014462, mean_q: 0.016916
 84434/100000: episode: 11638, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000340, mae: 0.013265, mean_q: 0.022815
 84444/100000: episode: 11639, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000559, mae: 0.016504, mean_q: 0.023959
 84454/100000: episode: 11640, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000388, mae: 0.014283, mean_q: 0.020863
 84464/100000: episode: 11641, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000837, mae: 0.016722, mean_q: 0.023194
 84474/100000: episode: 11642, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000218, mae: 0.011741, mean_q: 0.016087
 84484/100000: episode: 11643, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000987, mae: 0.018927, mean_q: 0.030398
 84494/100000: episode: 11644, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000582, mae: 0.016146, mean_q: 0.025410
 84504/100000: episode: 11645, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000780, mae: 0.015668, mean_q: 0.022400
 84514/100000: episode: 11646, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001703, mae: 0.021838, mean_q: 0.031029
 84524/100000: episode: 11647, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000668, mae: 0.015717, mean_q: 0.020602
 84534/100000: episode: 11648, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001062, mae: 0.021045, mean_q: 0.032536
 84544/100000: episode: 11649, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001829, mae: 0.020726, mean_q: 0.032127
 84554/100000: episode: 11650, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000887, mae: 0.018361, mean_q: 0.020907
 84564/100000: episode: 11651, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001564, mae: 0.019526, mean_q: 0.023765
 84574/100000: episode: 11652, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000546, mae: 0.015789, mean_q: 0.020116
 84584/100000: episode: 11653, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000529, mae: 0.014463, mean_q: 0.017216
 84594/100000: episode: 11654, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001105, mae: 0.018021, mean_q: 0.024893
 84604/100000: episode: 11655, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000986, mae: 0.018027, mean_q: 0.026320
 84614/100000: episode: 11656, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001002, mae: 0.013508, mean_q: 0.019379
 84624/100000: episode: 11657, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000596, mae: 0.014173, mean_q: 0.022094
 84634/100000: episode: 11658, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000555, mae: 0.014141, mean_q: 0.016448
 84644/100000: episode: 11659, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000654, mae: 0.015121, mean_q: 0.019109
 84654/100000: episode: 11660, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001461, mae: 0.020802, mean_q: 0.026746
 84664/100000: episode: 11661, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000652, mae: 0.018827, mean_q: 0.024427
 84674/100000: episode: 11662, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000450, mae: 0.014844, mean_q: 0.017077
 84684/100000: episode: 11663, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000837, mae: 0.017496, mean_q: 0.024312
 84694/100000: episode: 11664, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000882, mae: 0.018382, mean_q: 0.022238
 84704/100000: episode: 11665, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000328, mae: 0.011712, mean_q: 0.015456
 84714/100000: episode: 11666, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000477, mae: 0.012879, mean_q: 0.018794
 84724/100000: episode: 11667, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000779, mae: 0.015892, mean_q: 0.020919
 84734/100000: episode: 11668, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000517, mae: 0.013043, mean_q: 0.018328
[Info] 1-TH LEVEL FOUND: 0.031164586544036865, Considering 12/100 traces
 84744/100000: episode: 11669, duration: 0.667s, episode steps: 10, steps per second: 15, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000237, mae: 0.011187, mean_q: 0.015574
 84751/100000: episode: 11670, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000727, mae: 0.015506, mean_q: 0.016635
 84753/100000: episode: 11671, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001755, mae: 0.028669, mean_q: 0.039394
 84757/100000: episode: 11672, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000637, mae: 0.018782, mean_q: 0.019142
 84761/100000: episode: 11673, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000411, mae: 0.017624, mean_q: 0.020163
 84763/100000: episode: 11674, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000593, mae: 0.019915, mean_q: 0.028248
 84765/100000: episode: 11675, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000436, mae: 0.015003, mean_q: 0.017434
 84769/100000: episode: 11676, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000885, mae: 0.016489, mean_q: 0.024212
 84776/100000: episode: 11677, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000320, mae: 0.014122, mean_q: 0.017918
 84783/100000: episode: 11678, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000521, mae: 0.016964, mean_q: 0.026007
 84790/100000: episode: 11679, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000656, mae: 0.013570, mean_q: 0.018124
 84792/100000: episode: 11680, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000612, mae: 0.012177, mean_q: 0.021112
 84799/100000: episode: 11681, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000443, mae: 0.013707, mean_q: 0.021376
 84801/100000: episode: 11682, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001178, mae: 0.016462, mean_q: 0.019100
 84803/100000: episode: 11683, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000332, mae: 0.011111, mean_q: 0.009220
 84810/100000: episode: 11684, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000348, mae: 0.012679, mean_q: 0.018382
 84814/100000: episode: 11685, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000324, mae: 0.013402, mean_q: 0.013234
 84816/100000: episode: 11686, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000407, mae: 0.012236, mean_q: 0.020132
 84823/100000: episode: 11687, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.002752, mae: 0.022448, mean_q: 0.027462
 84830/100000: episode: 11688, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000827, mae: 0.020062, mean_q: 0.027608
 84834/100000: episode: 11689, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002217, mae: 0.026681, mean_q: 0.034443
 84836/100000: episode: 11690, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000853, mae: 0.028656, mean_q: 0.040398
 84843/100000: episode: 11691, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.001480, mae: 0.030202, mean_q: 0.015974
 84847/100000: episode: 11692, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000606, mae: 0.019070, mean_q: 0.027198
 84854/100000: episode: 11693, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000904, mae: 0.018832, mean_q: 0.020782
 84861/100000: episode: 11694, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000303, mae: 0.012201, mean_q: 0.013658
 84868/100000: episode: 11695, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000350, mae: 0.014805, mean_q: 0.020323
 84875/100000: episode: 11696, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.002223, mae: 0.020734, mean_q: 0.027734
 84879/100000: episode: 11697, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000362, mae: 0.015773, mean_q: 0.020096
 84883/100000: episode: 11698, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000735, mae: 0.021120, mean_q: 0.016867
 84890/100000: episode: 11699, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000408, mae: 0.015382, mean_q: 0.017770
 84894/100000: episode: 11700, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000234, mae: 0.014289, mean_q: 0.017592
 84896/100000: episode: 11701, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000532, mae: 0.019283, mean_q: 0.027326
 84900/100000: episode: 11702, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000407, mae: 0.016519, mean_q: 0.017440
 84904/100000: episode: 11703, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000234, mae: 0.012247, mean_q: 0.019813
 84911/100000: episode: 11704, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000522, mae: 0.013990, mean_q: 0.018007
 84915/100000: episode: 11705, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000619, mae: 0.014561, mean_q: 0.021666
 84922/100000: episode: 11706, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000693, mae: 0.014087, mean_q: 0.020229
 84926/100000: episode: 11707, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000625, mae: 0.012141, mean_q: 0.015130
 84933/100000: episode: 11708, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000655, mae: 0.015060, mean_q: 0.018760
 84940/100000: episode: 11709, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000613, mae: 0.016227, mean_q: 0.021751
 84947/100000: episode: 11710, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001889, mae: 0.019996, mean_q: 0.026641
 84951/100000: episode: 11711, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000816, mae: 0.020743, mean_q: 0.036794
 84953/100000: episode: 11712, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000427, mae: 0.020202, mean_q: 0.013606
 84960/100000: episode: 11713, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001176, mae: 0.019248, mean_q: 0.030454
 84967/100000: episode: 11714, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000368, mae: 0.012386, mean_q: 0.018587
 84974/100000: episode: 11715, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000838, mae: 0.016724, mean_q: 0.025589
 84981/100000: episode: 11716, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000752, mae: 0.015265, mean_q: 0.023830
 84985/100000: episode: 11717, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001121, mae: 0.019061, mean_q: 0.019738
 84992/100000: episode: 11718, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 1.947, mean reward: 0.278 [0.007, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 7.857 [5.000, 11.000], loss: 0.001270, mae: 0.020638, mean_q: 0.023674
 84996/100000: episode: 11719, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001454, mae: 0.021238, mean_q: 0.027225
 85000/100000: episode: 11720, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001246, mae: 0.016978, mean_q: 0.019451
 85002/100000: episode: 11721, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000264, mae: 0.015928, mean_q: 0.022880
 85006/100000: episode: 11722, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000195, mae: 0.013109, mean_q: 0.010795
 85013/100000: episode: 11723, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001576, mae: 0.021326, mean_q: 0.025684
 85017/100000: episode: 11724, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000914, mae: 0.021376, mean_q: 0.012775
 85019/100000: episode: 11725, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000719, mae: 0.012631, mean_q: 0.022045
 85026/100000: episode: 11726, duration: 0.037s, episode steps: 7, steps per second: 191, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000766, mae: 0.016916, mean_q: 0.020455
 85033/100000: episode: 11727, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000582, mae: 0.016889, mean_q: 0.025737
 85035/100000: episode: 11728, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000602, mae: 0.014499, mean_q: 0.019276
 85039/100000: episode: 11729, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000419, mae: 0.015682, mean_q: 0.024156
 85046/100000: episode: 11730, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000412, mae: 0.018182, mean_q: 0.023877
[Info] FALSIFICATION!
 85052/100000: episode: 11731, duration: 0.177s, episode steps: 6, steps per second: 34, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000772, mae: 0.017182, mean_q: 0.029445
 85054/100000: episode: 11732, duration: 0.014s, episode steps: 2, steps per second: 142, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000612, mae: 0.018784, mean_q: 0.009997
 85061/100000: episode: 11733, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000335, mae: 0.016142, mean_q: 0.019406
 85065/100000: episode: 11734, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002397, mae: 0.019363, mean_q: 0.021213
 85067/100000: episode: 11735, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000374, mae: 0.014830, mean_q: 0.023239
 85074/100000: episode: 11736, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000872, mae: 0.019530, mean_q: 0.022533
 85081/100000: episode: 11737, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000939, mae: 0.018942, mean_q: 0.024025
 85085/100000: episode: 11738, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001465, mae: 0.020624, mean_q: 0.024476
 85092/100000: episode: 11739, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000472, mae: 0.013728, mean_q: 0.019592
 85096/100000: episode: 11740, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000776, mae: 0.017487, mean_q: 0.016697
 85103/100000: episode: 11741, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000563, mae: 0.014918, mean_q: 0.020751
 85110/100000: episode: 11742, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000879, mae: 0.014344, mean_q: 0.022755
 85114/100000: episode: 11743, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000377, mae: 0.012054, mean_q: 0.016692
 85116/100000: episode: 11744, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000350, mae: 0.013037, mean_q: 0.021260
 85123/100000: episode: 11745, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.002013, mae: 0.021708, mean_q: 0.028716
 85127/100000: episode: 11746, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000480, mae: 0.017001, mean_q: 0.015630
 85134/100000: episode: 11747, duration: 0.037s, episode steps: 7, steps per second: 189, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.001057, mae: 0.020948, mean_q: 0.029241
 85138/100000: episode: 11748, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000412, mae: 0.013242, mean_q: 0.010828
 85142/100000: episode: 11749, duration: 0.024s, episode steps: 4, steps per second: 170, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002046, mae: 0.029455, mean_q: 0.044180
 85149/100000: episode: 11750, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001521, mae: 0.020367, mean_q: 0.023782
 85156/100000: episode: 11751, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000562, mae: 0.020917, mean_q: 0.021779
 85160/100000: episode: 11752, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001379, mae: 0.022444, mean_q: 0.034991
 85167/100000: episode: 11753, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000365, mae: 0.015505, mean_q: 0.013280
 85171/100000: episode: 11754, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001683, mae: 0.024560, mean_q: 0.036487
 85178/100000: episode: 11755, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000936, mae: 0.021738, mean_q: 0.024088
 85182/100000: episode: 11756, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000697, mae: 0.017782, mean_q: 0.032415
[Info] Complete ISplit Iteration
[Info] Levels: [0.031164587, 1.0886815]
[Info] Cond. Prob: [0.12, 0.01]
[Info] Error Prob: 0.0012

 85184/100000: episode: 11757, duration: 0.805s, episode steps: 2, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004187, mae: 0.029556, mean_q: 0.032519
 85194/100000: episode: 11758, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001403, mae: 0.022144, mean_q: 0.024152
 85204/100000: episode: 11759, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000591, mae: 0.014627, mean_q: 0.014521
 85214/100000: episode: 11760, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000617, mae: 0.015760, mean_q: 0.019972
 85224/100000: episode: 11761, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001572, mae: 0.017892, mean_q: 0.022952
 85234/100000: episode: 11762, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000680, mae: 0.019479, mean_q: 0.027245
 85244/100000: episode: 11763, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001678, mae: 0.023145, mean_q: 0.025943
 85254/100000: episode: 11764, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001653, mae: 0.019238, mean_q: 0.019030
 85264/100000: episode: 11765, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000805, mae: 0.019198, mean_q: 0.021311
 85274/100000: episode: 11766, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000842, mae: 0.018772, mean_q: 0.021652
 85284/100000: episode: 11767, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.001050, mae: 0.018038, mean_q: 0.023607
 85294/100000: episode: 11768, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000549, mae: 0.014636, mean_q: 0.020164
 85304/100000: episode: 11769, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000698, mae: 0.014135, mean_q: 0.019279
 85314/100000: episode: 11770, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000663, mae: 0.015417, mean_q: 0.020342
 85324/100000: episode: 11771, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001158, mae: 0.016179, mean_q: 0.019659
 85334/100000: episode: 11772, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000809, mae: 0.018122, mean_q: 0.020324
 85344/100000: episode: 11773, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000575, mae: 0.016069, mean_q: 0.016306
 85354/100000: episode: 11774, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001519, mae: 0.020509, mean_q: 0.024837
 85364/100000: episode: 11775, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001704, mae: 0.024597, mean_q: 0.027997
 85374/100000: episode: 11776, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000903, mae: 0.019869, mean_q: 0.023796
 85384/100000: episode: 11777, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000509, mae: 0.014951, mean_q: 0.019217
 85394/100000: episode: 11778, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000730, mae: 0.015112, mean_q: 0.021217
 85404/100000: episode: 11779, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000685, mae: 0.017560, mean_q: 0.022334
 85414/100000: episode: 11780, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000539, mae: 0.016419, mean_q: 0.021053
 85424/100000: episode: 11781, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001436, mae: 0.016885, mean_q: 0.020616
 85434/100000: episode: 11782, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000656, mae: 0.017050, mean_q: 0.023684
 85444/100000: episode: 11783, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001122, mae: 0.016648, mean_q: 0.024646
 85454/100000: episode: 11784, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001150, mae: 0.020193, mean_q: 0.025828
 85464/100000: episode: 11785, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000643, mae: 0.015460, mean_q: 0.020658
 85474/100000: episode: 11786, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000858, mae: 0.018606, mean_q: 0.025394
 85484/100000: episode: 11787, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001659, mae: 0.019657, mean_q: 0.024800
 85494/100000: episode: 11788, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000954, mae: 0.015120, mean_q: 0.022595
 85504/100000: episode: 11789, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001108, mae: 0.020917, mean_q: 0.025896
 85514/100000: episode: 11790, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000672, mae: 0.015661, mean_q: 0.024844
 85524/100000: episode: 11791, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000996, mae: 0.018160, mean_q: 0.023961
 85534/100000: episode: 11792, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000766, mae: 0.018107, mean_q: 0.025389
 85544/100000: episode: 11793, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000360, mae: 0.013473, mean_q: 0.022886
 85554/100000: episode: 11794, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001126, mae: 0.022034, mean_q: 0.029981
 85564/100000: episode: 11795, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000483, mae: 0.014635, mean_q: 0.023992
 85574/100000: episode: 11796, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000380, mae: 0.013057, mean_q: 0.019515
 85584/100000: episode: 11797, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000501, mae: 0.015249, mean_q: 0.026470
 85594/100000: episode: 11798, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000954, mae: 0.020697, mean_q: 0.020842
 85604/100000: episode: 11799, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000400, mae: 0.014728, mean_q: 0.019462
 85614/100000: episode: 11800, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001287, mae: 0.020342, mean_q: 0.025585
 85624/100000: episode: 11801, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000970, mae: 0.016968, mean_q: 0.023656
 85634/100000: episode: 11802, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001297, mae: 0.020528, mean_q: 0.032579
 85644/100000: episode: 11803, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001521, mae: 0.021210, mean_q: 0.028232
 85654/100000: episode: 11804, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000637, mae: 0.015753, mean_q: 0.021987
 85664/100000: episode: 11805, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000794, mae: 0.015753, mean_q: 0.018256
 85674/100000: episode: 11806, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000607, mae: 0.014523, mean_q: 0.019607
 85684/100000: episode: 11807, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000570, mae: 0.013709, mean_q: 0.018255
 85694/100000: episode: 11808, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000654, mae: 0.015783, mean_q: 0.021086
 85704/100000: episode: 11809, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000531, mae: 0.015412, mean_q: 0.022991
 85714/100000: episode: 11810, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000266, mae: 0.012630, mean_q: 0.018882
 85724/100000: episode: 11811, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000790, mae: 0.016655, mean_q: 0.020271
 85734/100000: episode: 11812, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000400, mae: 0.017227, mean_q: 0.015974
 85744/100000: episode: 11813, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000636, mae: 0.017809, mean_q: 0.022416
 85754/100000: episode: 11814, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000628, mae: 0.015519, mean_q: 0.017789
 85764/100000: episode: 11815, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000366, mae: 0.013702, mean_q: 0.016616
 85774/100000: episode: 11816, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000493, mae: 0.015052, mean_q: 0.018555
 85784/100000: episode: 11817, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000895, mae: 0.015099, mean_q: 0.022379
 85794/100000: episode: 11818, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000978, mae: 0.017953, mean_q: 0.027442
 85804/100000: episode: 11819, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000564, mae: 0.015683, mean_q: 0.020026
 85814/100000: episode: 11820, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002015, mae: 0.019386, mean_q: 0.024322
 85824/100000: episode: 11821, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000954, mae: 0.018048, mean_q: 0.023372
 85834/100000: episode: 11822, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000891, mae: 0.019179, mean_q: 0.019845
 85844/100000: episode: 11823, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000694, mae: 0.016909, mean_q: 0.021072
 85854/100000: episode: 11824, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000500, mae: 0.014940, mean_q: 0.021779
 85864/100000: episode: 11825, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000942, mae: 0.016407, mean_q: 0.025460
 85874/100000: episode: 11826, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001015, mae: 0.016392, mean_q: 0.024573
 85884/100000: episode: 11827, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000328, mae: 0.013025, mean_q: 0.018766
 85894/100000: episode: 11828, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000855, mae: 0.016850, mean_q: 0.021264
 85904/100000: episode: 11829, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001271, mae: 0.019376, mean_q: 0.020826
 85914/100000: episode: 11830, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001225, mae: 0.022015, mean_q: 0.027464
 85924/100000: episode: 11831, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000798, mae: 0.016194, mean_q: 0.023893
 85934/100000: episode: 11832, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000601, mae: 0.014874, mean_q: 0.021743
 85944/100000: episode: 11833, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000577, mae: 0.017200, mean_q: 0.019648
 85954/100000: episode: 11834, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000664, mae: 0.017470, mean_q: 0.022084
 85964/100000: episode: 11835, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000822, mae: 0.018330, mean_q: 0.022903
 85974/100000: episode: 11836, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000989, mae: 0.018653, mean_q: 0.023757
 85984/100000: episode: 11837, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001174, mae: 0.018020, mean_q: 0.023894
 85994/100000: episode: 11838, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001102, mae: 0.023355, mean_q: 0.023739
 86004/100000: episode: 11839, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000828, mae: 0.022926, mean_q: 0.021877
 86014/100000: episode: 11840, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000608, mae: 0.016497, mean_q: 0.015326
 86024/100000: episode: 11841, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000697, mae: 0.018809, mean_q: 0.020027
 86034/100000: episode: 11842, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000772, mae: 0.017836, mean_q: 0.021077
 86044/100000: episode: 11843, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000305, mae: 0.012828, mean_q: 0.019269
 86054/100000: episode: 11844, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000808, mae: 0.016389, mean_q: 0.023400
 86064/100000: episode: 11845, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000463, mae: 0.014521, mean_q: 0.017761
 86074/100000: episode: 11846, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000856, mae: 0.015639, mean_q: 0.019835
 86084/100000: episode: 11847, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000912, mae: 0.014950, mean_q: 0.021599
 86094/100000: episode: 11848, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000434, mae: 0.012852, mean_q: 0.018210
 86104/100000: episode: 11849, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000648, mae: 0.015488, mean_q: 0.023464
 86114/100000: episode: 11850, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000416, mae: 0.012532, mean_q: 0.020514
 86124/100000: episode: 11851, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001261, mae: 0.017731, mean_q: 0.026140
 86134/100000: episode: 11852, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001189, mae: 0.016892, mean_q: 0.025407
 86144/100000: episode: 11853, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001291, mae: 0.017172, mean_q: 0.019111
 86154/100000: episode: 11854, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000796, mae: 0.016776, mean_q: 0.019081
 86164/100000: episode: 11855, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001267, mae: 0.019230, mean_q: 0.024421
 86174/100000: episode: 11856, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001554, mae: 0.021352, mean_q: 0.024180
[Info] 1-TH LEVEL FOUND: 0.048650383949279785, Considering 10/100 traces
 86184/100000: episode: 11857, duration: 0.725s, episode steps: 10, steps per second: 14, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000652, mae: 0.017970, mean_q: 0.016825
 86186/100000: episode: 11858, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000324, mae: 0.018063, mean_q: 0.025220
 86190/100000: episode: 11859, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000458, mae: 0.015377, mean_q: 0.007543
 86194/100000: episode: 11860, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000527, mae: 0.014912, mean_q: 0.027417
 86196/100000: episode: 11861, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000224, mae: 0.011662, mean_q: 0.013478
 86200/100000: episode: 11862, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000399, mae: 0.011538, mean_q: 0.012428
 86202/100000: episode: 11863, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000518, mae: 0.015494, mean_q: 0.029101
 86206/100000: episode: 11864, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000440, mae: 0.014674, mean_q: 0.011747
 86208/100000: episode: 11865, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000531, mae: 0.015793, mean_q: 0.012168
 86210/100000: episode: 11866, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000260, mae: 0.016227, mean_q: 0.030720
 86212/100000: episode: 11867, duration: 0.014s, episode steps: 2, steps per second: 142, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001114, mae: 0.019137, mean_q: 0.026077
 86216/100000: episode: 11868, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000248, mae: 0.013904, mean_q: 0.015383
 86220/100000: episode: 11869, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000226, mae: 0.013155, mean_q: 0.019318
 86226/100000: episode: 11870, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000636, mae: 0.013077, mean_q: 0.015574
 86232/100000: episode: 11871, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000524, mae: 0.014796, mean_q: 0.022509
 86234/100000: episode: 11872, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000947, mae: 0.012142, mean_q: 0.017929
 86236/100000: episode: 11873, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000238, mae: 0.011776, mean_q: 0.015031
 86242/100000: episode: 11874, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000420, mae: 0.011676, mean_q: 0.020426
 86244/100000: episode: 11875, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000190, mae: 0.011191, mean_q: 0.011637
 86246/100000: episode: 11876, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002801, mae: 0.026101, mean_q: 0.043453
 86250/100000: episode: 11877, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000661, mae: 0.011017, mean_q: 0.014474
 86254/100000: episode: 11878, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000612, mae: 0.012422, mean_q: 0.018477
 86258/100000: episode: 11879, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001010, mae: 0.015943, mean_q: 0.019042
 86260/100000: episode: 11880, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000130, mae: 0.009187, mean_q: 0.015354
 86264/100000: episode: 11881, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000827, mae: 0.016090, mean_q: 0.021539
 86268/100000: episode: 11882, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000846, mae: 0.016364, mean_q: 0.019698
 86272/100000: episode: 11883, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000235, mae: 0.011170, mean_q: 0.020955
 86274/100000: episode: 11884, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001695, mae: 0.022585, mean_q: 0.026935
 86276/100000: episode: 11885, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001559, mae: 0.019876, mean_q: 0.039798
 86278/100000: episode: 11886, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001132, mae: 0.014339, mean_q: 0.023626
 86282/100000: episode: 11887, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000469, mae: 0.015230, mean_q: 0.017596
 86284/100000: episode: 11888, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002307, mae: 0.024684, mean_q: 0.044977
 86288/100000: episode: 11889, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000513, mae: 0.013524, mean_q: 0.020105
 86292/100000: episode: 11890, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000835, mae: 0.017601, mean_q: 0.026551
 86294/100000: episode: 11891, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001006, mae: 0.016855, mean_q: 0.025825
 86300/100000: episode: 11892, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000866, mae: 0.016176, mean_q: 0.018735
 86302/100000: episode: 11893, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000714, mae: 0.015380, mean_q: 0.023177
 86304/100000: episode: 11894, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005020, mae: 0.021384, mean_q: 0.016378
 86306/100000: episode: 11895, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000999, mae: 0.014604, mean_q: 0.020236
 86310/100000: episode: 11896, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000348, mae: 0.011647, mean_q: 0.014751
 86316/100000: episode: 11897, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001669, mae: 0.016824, mean_q: 0.022714
 86318/100000: episode: 11898, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000329, mae: 0.014345, mean_q: 0.023151
 86322/100000: episode: 11899, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000688, mae: 0.018332, mean_q: 0.020359
 86324/100000: episode: 11900, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000445, mae: 0.015878, mean_q: 0.012501
 86326/100000: episode: 11901, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001283, mae: 0.020918, mean_q: 0.022794
 86328/100000: episode: 11902, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001384, mae: 0.019622, mean_q: 0.026960
 86332/100000: episode: 11903, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000168, mae: 0.009700, mean_q: 0.015952
 86334/100000: episode: 11904, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000574, mae: 0.014845, mean_q: 0.022026
 86338/100000: episode: 11905, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000196, mae: 0.012504, mean_q: 0.012109
 86340/100000: episode: 11906, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000114, mae: 0.009077, mean_q: 0.011443
 86342/100000: episode: 11907, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001548, mae: 0.021087, mean_q: 0.025944
 86346/100000: episode: 11908, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000677, mae: 0.011615, mean_q: 0.011305
 86350/100000: episode: 11909, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000344, mae: 0.012115, mean_q: 0.019119
 86354/100000: episode: 11910, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002942, mae: 0.022477, mean_q: 0.020527
 86356/100000: episode: 11911, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000239, mae: 0.015462, mean_q: 0.023423
 86358/100000: episode: 11912, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000471, mae: 0.020559, mean_q: 0.001544
 86362/100000: episode: 11913, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000505, mae: 0.019431, mean_q: 0.021981
 86364/100000: episode: 11914, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000120, mae: 0.011314, mean_q: 0.013902
 86368/100000: episode: 11915, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000528, mae: 0.015756, mean_q: 0.012771
 86374/100000: episode: 11916, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000720, mae: 0.014763, mean_q: 0.022886
 86378/100000: episode: 11917, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000299, mae: 0.011535, mean_q: 0.014296
 86382/100000: episode: 11918, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000323, mae: 0.012978, mean_q: 0.016899
 86384/100000: episode: 11919, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001711, mae: 0.020747, mean_q: 0.035123
 86388/100000: episode: 11920, duration: 0.026s, episode steps: 4, steps per second: 155, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000444, mae: 0.014579, mean_q: 0.018000
 86390/100000: episode: 11921, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000670, mae: 0.012769, mean_q: 0.021753
 86392/100000: episode: 11922, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000525, mae: 0.012703, mean_q: 0.021262
 86396/100000: episode: 11923, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000163, mae: 0.010915, mean_q: 0.014380
 86402/100000: episode: 11924, duration: 0.032s, episode steps: 6, steps per second: 187, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000929, mae: 0.014199, mean_q: 0.017566
 86406/100000: episode: 11925, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000195, mae: 0.012515, mean_q: 0.018105
 86408/100000: episode: 11926, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.004257, mae: 0.029401, mean_q: 0.031014
 86412/100000: episode: 11927, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000568, mae: 0.017101, mean_q: 0.023453
 86418/100000: episode: 11928, duration: 0.031s, episode steps: 6, steps per second: 192, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000758, mae: 0.018795, mean_q: 0.026408
 86422/100000: episode: 11929, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000409, mae: 0.014663, mean_q: 0.020196
 86424/100000: episode: 11930, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000143, mae: 0.008656, mean_q: 0.007696
 86430/100000: episode: 11931, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000674, mae: 0.015182, mean_q: 0.018304
 86432/100000: episode: 11932, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000535, mae: 0.011807, mean_q: 0.019632
 86436/100000: episode: 11933, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000347, mae: 0.013202, mean_q: 0.017003
 86438/100000: episode: 11934, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000537, mae: 0.016316, mean_q: 0.030751
 86440/100000: episode: 11935, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000493, mae: 0.016359, mean_q: 0.021671
 86442/100000: episode: 11936, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000493, mae: 0.015232, mean_q: 0.009478
 86444/100000: episode: 11937, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001266, mae: 0.019615, mean_q: 0.050023
 86448/100000: episode: 11938, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000255, mae: 0.011756, mean_q: 0.015171
 86450/100000: episode: 11939, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001699, mae: 0.017906, mean_q: 0.019889
 86452/100000: episode: 11940, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000172, mae: 0.010104, mean_q: 0.006012
 86454/100000: episode: 11941, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001382, mae: 0.016610, mean_q: 0.022058
 86456/100000: episode: 11942, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001018, mae: 0.014018, mean_q: 0.018304
 86458/100000: episode: 11943, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000165, mae: 0.009255, mean_q: 0.006516
 86460/100000: episode: 11944, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000890, mae: 0.014025, mean_q: 0.017603
 86462/100000: episode: 11945, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000240, mae: 0.013263, mean_q: 0.017895
 86464/100000: episode: 11946, duration: 0.014s, episode steps: 2, steps per second: 144, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000214, mae: 0.010811, mean_q: 0.012728
[Info] 2-TH LEVEL FOUND: 0.06676223874092102, Considering 25/100 traces
 86468/100000: episode: 11947, duration: 0.729s, episode steps: 4, steps per second: 5, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001001, mae: 0.015170, mean_q: 0.020415
 86471/100000: episode: 11948, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001168, mae: 0.017091, mean_q: 0.013625
 86476/100000: episode: 11949, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001479, mae: 0.021741, mean_q: 0.029247
 86479/100000: episode: 11950, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000189, mae: 0.013236, mean_q: 0.013213
 86482/100000: episode: 11951, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003302, mae: 0.021440, mean_q: 0.021471
 86485/100000: episode: 11952, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001098, mae: 0.018956, mean_q: 0.027854
 86490/100000: episode: 11953, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000684, mae: 0.014387, mean_q: 0.013345
 86495/100000: episode: 11954, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001000, mae: 0.020601, mean_q: 0.029398
 86498/100000: episode: 11955, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000179, mae: 0.010552, mean_q: 0.008694
 86501/100000: episode: 11956, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000565, mae: 0.013796, mean_q: 0.022384
 86504/100000: episode: 11957, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002558, mae: 0.022548, mean_q: 0.026595
 86509/100000: episode: 11958, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000178, mae: 0.008719, mean_q: 0.010183
 86512/100000: episode: 11959, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000662, mae: 0.013340, mean_q: 0.012835
 86515/100000: episode: 11960, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000871, mae: 0.018590, mean_q: 0.018552
 86518/100000: episode: 11961, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000423, mae: 0.017129, mean_q: 0.020302
 86523/100000: episode: 11962, duration: 0.029s, episode steps: 5, steps per second: 170, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002369, mae: 0.021969, mean_q: 0.025257
 86526/100000: episode: 11963, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001220, mae: 0.023506, mean_q: 0.036103
 86529/100000: episode: 11964, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000701, mae: 0.017082, mean_q: 0.013972
 86534/100000: episode: 11965, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000665, mae: 0.017140, mean_q: 0.020966
 86537/100000: episode: 11966, duration: 0.022s, episode steps: 3, steps per second: 138, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002282, mae: 0.022934, mean_q: 0.022078
 86540/100000: episode: 11967, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000697, mae: 0.018184, mean_q: 0.029890
 86543/100000: episode: 11968, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000697, mae: 0.014537, mean_q: 0.013508
 86548/100000: episode: 11969, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000901, mae: 0.019173, mean_q: 0.016162
 86551/100000: episode: 11970, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000395, mae: 0.013315, mean_q: 0.016699
 86554/100000: episode: 11971, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000446, mae: 0.011217, mean_q: 0.009668
 86559/100000: episode: 11972, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001012, mae: 0.015460, mean_q: 0.025385
 86562/100000: episode: 11973, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002608, mae: 0.020986, mean_q: 0.024810
 86567/100000: episode: 11974, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000268, mae: 0.015683, mean_q: 0.014518
 86572/100000: episode: 11975, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000250, mae: 0.011903, mean_q: 0.016439
 86575/100000: episode: 11976, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000995, mae: 0.017487, mean_q: 0.013559
 86578/100000: episode: 11977, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000678, mae: 0.018316, mean_q: 0.025481
 86581/100000: episode: 11978, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000447, mae: 0.014649, mean_q: 0.015885
 86584/100000: episode: 11979, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000336, mae: 0.011133, mean_q: 0.005726
 86587/100000: episode: 11980, duration: 0.027s, episode steps: 3, steps per second: 113, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000197, mae: 0.012279, mean_q: 0.016144
 86590/100000: episode: 11981, duration: 0.039s, episode steps: 3, steps per second: 77, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000899, mae: 0.016994, mean_q: 0.013068
 86593/100000: episode: 11982, duration: 0.043s, episode steps: 3, steps per second: 70, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000316, mae: 0.010268, mean_q: 0.011175
 86596/100000: episode: 11983, duration: 0.039s, episode steps: 3, steps per second: 76, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000136, mae: 0.008373, mean_q: 0.007985
 86599/100000: episode: 11984, duration: 0.028s, episode steps: 3, steps per second: 106, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000457, mae: 0.015262, mean_q: 0.020605
 86604/100000: episode: 11985, duration: 0.033s, episode steps: 5, steps per second: 153, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000133, mae: 0.010078, mean_q: 0.013595
 86609/100000: episode: 11986, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000951, mae: 0.015748, mean_q: 0.026124
 86612/100000: episode: 11987, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000784, mae: 0.017413, mean_q: 0.010333
 86617/100000: episode: 11988, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000338, mae: 0.013926, mean_q: 0.017903
 86622/100000: episode: 11989, duration: 0.036s, episode steps: 5, steps per second: 137, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000643, mae: 0.015423, mean_q: 0.012051
 86625/100000: episode: 11990, duration: 0.033s, episode steps: 3, steps per second: 91, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000123, mae: 0.009669, mean_q: 0.014687
 86628/100000: episode: 11991, duration: 0.036s, episode steps: 3, steps per second: 84, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001102, mae: 0.014493, mean_q: 0.017201
 86633/100000: episode: 11992, duration: 0.050s, episode steps: 5, steps per second: 101, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000505, mae: 0.012528, mean_q: 0.017185
 86636/100000: episode: 11993, duration: 0.034s, episode steps: 3, steps per second: 88, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000131, mae: 0.009623, mean_q: 0.008638
 86639/100000: episode: 11994, duration: 0.034s, episode steps: 3, steps per second: 87, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000632, mae: 0.015405, mean_q: 0.020981
 86642/100000: episode: 11995, duration: 0.025s, episode steps: 3, steps per second: 119, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000215, mae: 0.011679, mean_q: 0.017452
 86645/100000: episode: 11996, duration: 0.030s, episode steps: 3, steps per second: 100, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000259, mae: 0.013878, mean_q: 0.012583
 86650/100000: episode: 11997, duration: 0.056s, episode steps: 5, steps per second: 89, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000352, mae: 0.014301, mean_q: 0.020412
 86653/100000: episode: 11998, duration: 0.037s, episode steps: 3, steps per second: 81, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000957, mae: 0.017302, mean_q: 0.023872
 86658/100000: episode: 11999, duration: 0.048s, episode steps: 5, steps per second: 104, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000515, mae: 0.012135, mean_q: 0.018333
 86663/100000: episode: 12000, duration: 0.054s, episode steps: 5, steps per second: 93, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000209, mae: 0.010167, mean_q: 0.011627
 86666/100000: episode: 12001, duration: 0.032s, episode steps: 3, steps per second: 93, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000238, mae: 0.012038, mean_q: 0.013305
 86669/100000: episode: 12002, duration: 0.041s, episode steps: 3, steps per second: 74, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000422, mae: 0.012768, mean_q: 0.025191
 86674/100000: episode: 12003, duration: 0.035s, episode steps: 5, steps per second: 143, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000598, mae: 0.014183, mean_q: 0.016291
 86679/100000: episode: 12004, duration: 0.044s, episode steps: 5, steps per second: 113, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000130, mae: 0.008783, mean_q: 0.012335
 86684/100000: episode: 12005, duration: 0.039s, episode steps: 5, steps per second: 130, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000152, mae: 0.010104, mean_q: 0.008784
 86687/100000: episode: 12006, duration: 0.029s, episode steps: 3, steps per second: 104, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000170, mae: 0.011754, mean_q: 0.018487
 86692/100000: episode: 12007, duration: 0.032s, episode steps: 5, steps per second: 158, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000561, mae: 0.011511, mean_q: 0.010688
 86695/100000: episode: 12008, duration: 0.029s, episode steps: 3, steps per second: 103, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000335, mae: 0.011421, mean_q: 0.014822
 86698/100000: episode: 12009, duration: 0.026s, episode steps: 3, steps per second: 115, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000110, mae: 0.008165, mean_q: 0.011501
 86701/100000: episode: 12010, duration: 0.036s, episode steps: 3, steps per second: 83, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000652, mae: 0.016077, mean_q: 0.019874
 86706/100000: episode: 12011, duration: 0.063s, episode steps: 5, steps per second: 79, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000256, mae: 0.008552, mean_q: 0.010968
 86709/100000: episode: 12012, duration: 0.042s, episode steps: 3, steps per second: 71, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000143, mae: 0.011032, mean_q: 0.015799
 86712/100000: episode: 12013, duration: 0.037s, episode steps: 3, steps per second: 81, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000150, mae: 0.009962, mean_q: 0.010209
 86715/100000: episode: 12014, duration: 0.020s, episode steps: 3, steps per second: 148, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001088, mae: 0.015365, mean_q: 0.024358
 86718/100000: episode: 12015, duration: 0.024s, episode steps: 3, steps per second: 125, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000993, mae: 0.018503, mean_q: 0.032521
 86721/100000: episode: 12016, duration: 0.020s, episode steps: 3, steps per second: 149, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000371, mae: 0.014737, mean_q: 0.015489
 86724/100000: episode: 12017, duration: 0.023s, episode steps: 3, steps per second: 133, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001174, mae: 0.019099, mean_q: 0.024513
 86727/100000: episode: 12018, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000290, mae: 0.012906, mean_q: 0.018833
 86732/100000: episode: 12019, duration: 0.043s, episode steps: 5, steps per second: 115, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000237, mae: 0.012908, mean_q: 0.007415
 86735/100000: episode: 12020, duration: 0.021s, episode steps: 3, steps per second: 142, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000180, mae: 0.012861, mean_q: 0.021914
 86738/100000: episode: 12021, duration: 0.031s, episode steps: 3, steps per second: 98, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001449, mae: 0.019161, mean_q: 0.025326
[Info] 3-TH LEVEL FOUND: 0.19371971487998962, Considering 12/100 traces
 86743/100000: episode: 12022, duration: 1.330s, episode steps: 5, steps per second: 4, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000204, mae: 0.009798, mean_q: 0.014815
 86747/100000: episode: 12023, duration: 0.039s, episode steps: 4, steps per second: 103, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000512, mae: 0.011161, mean_q: 0.016186
 86751/100000: episode: 12024, duration: 0.041s, episode steps: 4, steps per second: 97, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000556, mae: 0.014057, mean_q: 0.012745
 86755/100000: episode: 12025, duration: 0.043s, episode steps: 4, steps per second: 93, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000205, mae: 0.012647, mean_q: 0.015621
 86759/100000: episode: 12026, duration: 0.046s, episode steps: 4, steps per second: 88, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000904, mae: 0.014658, mean_q: 0.016900
 86763/100000: episode: 12027, duration: 0.057s, episode steps: 4, steps per second: 70, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000503, mae: 0.010086, mean_q: 0.013196
 86767/100000: episode: 12028, duration: 0.051s, episode steps: 4, steps per second: 79, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000528, mae: 0.010577, mean_q: 0.016530
 86771/100000: episode: 12029, duration: 0.032s, episode steps: 4, steps per second: 124, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000176, mae: 0.011562, mean_q: 0.016505
 86775/100000: episode: 12030, duration: 0.040s, episode steps: 4, steps per second: 99, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000364, mae: 0.010353, mean_q: 0.013577
 86779/100000: episode: 12031, duration: 0.035s, episode steps: 4, steps per second: 114, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000520, mae: 0.012429, mean_q: 0.017459
 86783/100000: episode: 12032, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000256, mae: 0.012472, mean_q: 0.012183
 86787/100000: episode: 12033, duration: 0.030s, episode steps: 4, steps per second: 134, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001821, mae: 0.018630, mean_q: 0.025177
 86791/100000: episode: 12034, duration: 0.030s, episode steps: 4, steps per second: 135, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000370, mae: 0.016292, mean_q: 0.022220
 86795/100000: episode: 12035, duration: 0.033s, episode steps: 4, steps per second: 123, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000498, mae: 0.015524, mean_q: 0.025571
 86799/100000: episode: 12036, duration: 0.062s, episode steps: 4, steps per second: 65, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000903, mae: 0.014613, mean_q: 0.019347
 86803/100000: episode: 12037, duration: 0.035s, episode steps: 4, steps per second: 115, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000174, mae: 0.009809, mean_q: 0.014299
 86807/100000: episode: 12038, duration: 0.027s, episode steps: 4, steps per second: 151, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000255, mae: 0.009725, mean_q: 0.013783
 86811/100000: episode: 12039, duration: 0.039s, episode steps: 4, steps per second: 103, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000499, mae: 0.014577, mean_q: 0.022946
 86815/100000: episode: 12040, duration: 0.029s, episode steps: 4, steps per second: 138, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001337, mae: 0.020441, mean_q: 0.035420
 86819/100000: episode: 12041, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002190, mae: 0.022750, mean_q: 0.029849
 86823/100000: episode: 12042, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000875, mae: 0.014759, mean_q: 0.022065
[Info] FALSIFICATION!
 86826/100000: episode: 12043, duration: 0.322s, episode steps: 3, steps per second: 9, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001370, mae: 0.022238, mean_q: 0.025138
 86830/100000: episode: 12044, duration: 0.043s, episode steps: 4, steps per second: 93, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001280, mae: 0.021313, mean_q: 0.027691
 86834/100000: episode: 12045, duration: 0.035s, episode steps: 4, steps per second: 113, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000193, mae: 0.012657, mean_q: 0.007378
 86838/100000: episode: 12046, duration: 0.024s, episode steps: 4, steps per second: 163, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000425, mae: 0.017120, mean_q: 0.014580
 86842/100000: episode: 12047, duration: 0.024s, episode steps: 4, steps per second: 164, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000149, mae: 0.012044, mean_q: 0.014591
 86846/100000: episode: 12048, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.002490, mae: 0.019705, mean_q: 0.017609
 86850/100000: episode: 12049, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001733, mae: 0.021653, mean_q: 0.026842
 86854/100000: episode: 12050, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000903, mae: 0.020766, mean_q: 0.019916
 86858/100000: episode: 12051, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001350, mae: 0.023433, mean_q: 0.038954
 86862/100000: episode: 12052, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000456, mae: 0.014028, mean_q: 0.017088
 86866/100000: episode: 12053, duration: 0.025s, episode steps: 4, steps per second: 161, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001399, mae: 0.019267, mean_q: 0.025297
 86870/100000: episode: 12054, duration: 0.052s, episode steps: 4, steps per second: 77, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000430, mae: 0.015945, mean_q: 0.011244
 86874/100000: episode: 12055, duration: 0.053s, episode steps: 4, steps per second: 76, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000993, mae: 0.020244, mean_q: 0.024667
 86878/100000: episode: 12056, duration: 0.027s, episode steps: 4, steps per second: 150, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001160, mae: 0.022258, mean_q: 0.026139
 86882/100000: episode: 12057, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000827, mae: 0.017486, mean_q: 0.029208
 86886/100000: episode: 12058, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000945, mae: 0.023203, mean_q: 0.017814
 86890/100000: episode: 12059, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000489, mae: 0.015030, mean_q: 0.015455
 86894/100000: episode: 12060, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000249, mae: 0.012338, mean_q: 0.014130
 86898/100000: episode: 12061, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000374, mae: 0.013431, mean_q: 0.013916
 86902/100000: episode: 12062, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000308, mae: 0.014921, mean_q: 0.022768
 86906/100000: episode: 12063, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001414, mae: 0.020168, mean_q: 0.033541
[Info] FALSIFICATION!
 86909/100000: episode: 12064, duration: 0.305s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000841, mae: 0.018934, mean_q: 0.029896
[Info] FALSIFICATION!
 86912/100000: episode: 12065, duration: 0.310s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001666, mae: 0.020777, mean_q: 0.018517
 86916/100000: episode: 12066, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.005465, mae: 0.031240, mean_q: 0.034041
 86920/100000: episode: 12067, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000602, mae: 0.023875, mean_q: 0.029505
 86924/100000: episode: 12068, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.001496, mae: 0.030765, mean_q: 0.018999
 86928/100000: episode: 12069, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002833, mae: 0.032269, mean_q: 0.034994
 86932/100000: episode: 12070, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.002276, mae: 0.032981, mean_q: 0.025638
[Info] FALSIFICATION!
 86935/100000: episode: 12071, duration: 0.179s, episode steps: 3, steps per second: 17, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000474, mae: 0.017405, mean_q: 0.018952
 86939/100000: episode: 12072, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000971, mae: 0.020242, mean_q: 0.025163
 86943/100000: episode: 12073, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001617, mae: 0.024739, mean_q: 0.035757
 86947/100000: episode: 12074, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000160, mae: 0.010155, mean_q: 0.012875
 86951/100000: episode: 12075, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003281, mae: 0.033230, mean_q: 0.049300
 86955/100000: episode: 12076, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000931, mae: 0.023441, mean_q: 0.029936
 86959/100000: episode: 12077, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000827, mae: 0.022378, mean_q: 0.025048
 86963/100000: episode: 12078, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000707, mae: 0.020200, mean_q: 0.026792
 86967/100000: episode: 12079, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000410, mae: 0.015327, mean_q: 0.011459
 86971/100000: episode: 12080, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001057, mae: 0.016992, mean_q: 0.021944
 86975/100000: episode: 12081, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000868, mae: 0.017145, mean_q: 0.027043
 86979/100000: episode: 12082, duration: 0.028s, episode steps: 4, steps per second: 142, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.004968, mae: 0.033841, mean_q: 0.039338
 86983/100000: episode: 12083, duration: 0.041s, episode steps: 4, steps per second: 99, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001565, mae: 0.027017, mean_q: 0.029000
[Info] FALSIFICATION!
 86986/100000: episode: 12084, duration: 0.306s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001358, mae: 0.020151, mean_q: 0.029940
 86990/100000: episode: 12085, duration: 0.025s, episode steps: 4, steps per second: 160, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001437, mae: 0.022275, mean_q: 0.028938
 86994/100000: episode: 12086, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.001131, mae: 0.024724, mean_q: 0.031297
[Info] FALSIFICATION!
 86997/100000: episode: 12087, duration: 0.277s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000675, mae: 0.018369, mean_q: 0.019847
 87001/100000: episode: 12088, duration: 0.034s, episode steps: 4, steps per second: 118, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000221, mae: 0.012490, mean_q: 0.018235
 87005/100000: episode: 12089, duration: 0.028s, episode steps: 4, steps per second: 141, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000523, mae: 0.016442, mean_q: 0.021886
 87009/100000: episode: 12090, duration: 0.036s, episode steps: 4, steps per second: 111, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000936, mae: 0.016716, mean_q: 0.027505
[Info] FALSIFICATION!
 87012/100000: episode: 12091, duration: 0.292s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.005053, mae: 0.034087, mean_q: 0.040122
[Info] FALSIFICATION!
 87015/100000: episode: 12092, duration: 0.287s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.003270, mae: 0.034779, mean_q: 0.057561
 87019/100000: episode: 12093, duration: 0.027s, episode steps: 4, steps per second: 150, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003956, mae: 0.051686, mean_q: 0.023232
 87023/100000: episode: 12094, duration: 0.024s, episode steps: 4, steps per second: 167, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003155, mae: 0.041197, mean_q: 0.049479
 87027/100000: episode: 12095, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002095, mae: 0.036637, mean_q: 0.037942
 87031/100000: episode: 12096, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000748, mae: 0.027425, mean_q: 0.005729
 87035/100000: episode: 12097, duration: 0.039s, episode steps: 4, steps per second: 103, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003587, mae: 0.040078, mean_q: 0.058413
 87039/100000: episode: 12098, duration: 0.028s, episode steps: 4, steps per second: 143, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001028, mae: 0.025044, mean_q: 0.022399
[Info] FALSIFICATION!
 87042/100000: episode: 12099, duration: 0.302s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.004419, mae: 0.029035, mean_q: 0.042910
 87046/100000: episode: 12100, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000999, mae: 0.026012, mean_q: 0.039703
[Info] FALSIFICATION!
 87049/100000: episode: 12101, duration: 0.286s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001016, mae: 0.024487, mean_q: 0.018654
 87053/100000: episode: 12102, duration: 0.026s, episode steps: 4, steps per second: 152, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002953, mae: 0.038390, mean_q: 0.038456
[Info] FALSIFICATION!
 87056/100000: episode: 12103, duration: 0.300s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.001427, mae: 0.023070, mean_q: 0.024478
[Info] FALSIFICATION!
 87059/100000: episode: 12104, duration: 0.311s, episode steps: 3, steps per second: 10, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.002420, mae: 0.030816, mean_q: 0.033695
 87063/100000: episode: 12105, duration: 0.061s, episode steps: 4, steps per second: 66, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000731, mae: 0.015393, mean_q: 0.019939
 87067/100000: episode: 12106, duration: 0.049s, episode steps: 4, steps per second: 82, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000996, mae: 0.020142, mean_q: 0.017658
 87071/100000: episode: 12107, duration: 0.045s, episode steps: 4, steps per second: 89, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002753, mae: 0.026668, mean_q: 0.034647
 87075/100000: episode: 12108, duration: 0.053s, episode steps: 4, steps per second: 76, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003267, mae: 0.028383, mean_q: 0.045949
 87079/100000: episode: 12109, duration: 0.047s, episode steps: 4, steps per second: 85, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001248, mae: 0.020937, mean_q: 0.035541
[Info] Complete ISplit Iteration
[Info] Levels: [0.048650384, 0.06676224, 0.19371971, 1.0229245]
[Info] Cond. Prob: [0.1, 0.25, 0.12, 0.12]
[Info] Error Prob: 0.00035999999999999997

 87083/100000: episode: 12110, duration: 1.116s, episode steps: 4, steps per second: 4, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000754, mae: 0.022222, mean_q: 0.019413
 87093/100000: episode: 12111, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000875, mae: 0.019958, mean_q: 0.025833
 87103/100000: episode: 12112, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001984, mae: 0.024422, mean_q: 0.037389
 87113/100000: episode: 12113, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001852, mae: 0.023678, mean_q: 0.036986
 87123/100000: episode: 12114, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000783, mae: 0.017604, mean_q: 0.023099
 87133/100000: episode: 12115, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001152, mae: 0.020086, mean_q: 0.037584
 87143/100000: episode: 12116, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001817, mae: 0.022222, mean_q: 0.038795
 87153/100000: episode: 12117, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001581, mae: 0.024115, mean_q: 0.035548
 87163/100000: episode: 12118, duration: 0.108s, episode steps: 10, steps per second: 93, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001586, mae: 0.025597, mean_q: 0.048611
 87173/100000: episode: 12119, duration: 0.088s, episode steps: 10, steps per second: 114, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002706, mae: 0.027180, mean_q: 0.033877
 87183/100000: episode: 12120, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001606, mae: 0.029370, mean_q: 0.032000
 87193/100000: episode: 12121, duration: 0.078s, episode steps: 10, steps per second: 129, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001457, mae: 0.026440, mean_q: 0.035657
 87203/100000: episode: 12122, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.003091, mae: 0.028985, mean_q: 0.047201
 87213/100000: episode: 12123, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001080, mae: 0.020395, mean_q: 0.027062
 87223/100000: episode: 12124, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.003051, mae: 0.027094, mean_q: 0.037012
 87233/100000: episode: 12125, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001229, mae: 0.025392, mean_q: 0.032147
 87243/100000: episode: 12126, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002383, mae: 0.029640, mean_q: 0.041910
 87253/100000: episode: 12127, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002647, mae: 0.025511, mean_q: 0.033181
 87263/100000: episode: 12128, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001734, mae: 0.027599, mean_q: 0.038312
 87273/100000: episode: 12129, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002172, mae: 0.025244, mean_q: 0.032273
 87283/100000: episode: 12130, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001951, mae: 0.027503, mean_q: 0.035650
 87293/100000: episode: 12131, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001985, mae: 0.029333, mean_q: 0.037088
 87303/100000: episode: 12132, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002293, mae: 0.030001, mean_q: 0.039797
 87313/100000: episode: 12133, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001840, mae: 0.023769, mean_q: 0.023476
 87323/100000: episode: 12134, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002152, mae: 0.033077, mean_q: 0.036939
 87333/100000: episode: 12135, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001706, mae: 0.025852, mean_q: 0.029664
 87343/100000: episode: 12136, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001879, mae: 0.026411, mean_q: 0.034861
 87353/100000: episode: 12137, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001501, mae: 0.024000, mean_q: 0.034035
 87363/100000: episode: 12138, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002204, mae: 0.028548, mean_q: 0.037012
 87373/100000: episode: 12139, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001185, mae: 0.020323, mean_q: 0.027312
 87383/100000: episode: 12140, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001754, mae: 0.024045, mean_q: 0.031409
 87393/100000: episode: 12141, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001798, mae: 0.023235, mean_q: 0.033501
 87403/100000: episode: 12142, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001402, mae: 0.024742, mean_q: 0.039143
 87413/100000: episode: 12143, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002448, mae: 0.024355, mean_q: 0.037222
 87423/100000: episode: 12144, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.002204, mae: 0.030428, mean_q: 0.042733
 87433/100000: episode: 12145, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001705, mae: 0.023357, mean_q: 0.028728
 87443/100000: episode: 12146, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001599, mae: 0.022058, mean_q: 0.032312
 87453/100000: episode: 12147, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001453, mae: 0.020705, mean_q: 0.028770
 87463/100000: episode: 12148, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002693, mae: 0.031741, mean_q: 0.047029
 87473/100000: episode: 12149, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002016, mae: 0.026068, mean_q: 0.030384
 87483/100000: episode: 12150, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001729, mae: 0.029496, mean_q: 0.038116
 87493/100000: episode: 12151, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001558, mae: 0.021889, mean_q: 0.024576
 87503/100000: episode: 12152, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001456, mae: 0.022488, mean_q: 0.030343
 87513/100000: episode: 12153, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002069, mae: 0.026470, mean_q: 0.036996
 87523/100000: episode: 12154, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001939, mae: 0.026408, mean_q: 0.034466
 87533/100000: episode: 12155, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001991, mae: 0.025904, mean_q: 0.035639
 87543/100000: episode: 12156, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001288, mae: 0.022284, mean_q: 0.030816
 87553/100000: episode: 12157, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001351, mae: 0.018403, mean_q: 0.023433
 87563/100000: episode: 12158, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001830, mae: 0.025662, mean_q: 0.033179
 87573/100000: episode: 12159, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002311, mae: 0.028871, mean_q: 0.042812
 87583/100000: episode: 12160, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001087, mae: 0.021962, mean_q: 0.036477
 87593/100000: episode: 12161, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001283, mae: 0.019642, mean_q: 0.031070
 87603/100000: episode: 12162, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001148, mae: 0.018920, mean_q: 0.027040
 87613/100000: episode: 12163, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001310, mae: 0.020042, mean_q: 0.030720
 87623/100000: episode: 12164, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002652, mae: 0.030700, mean_q: 0.038665
 87633/100000: episode: 12165, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.001949, mae: 0.024509, mean_q: 0.033605
 87643/100000: episode: 12166, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.002325, mae: 0.027895, mean_q: 0.039879
 87653/100000: episode: 12167, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001784, mae: 0.023348, mean_q: 0.034222
 87663/100000: episode: 12168, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002462, mae: 0.028946, mean_q: 0.046964
 87673/100000: episode: 12169, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.002947, mae: 0.030932, mean_q: 0.042793
 87683/100000: episode: 12170, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002932, mae: 0.031548, mean_q: 0.040841
 87693/100000: episode: 12171, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002857, mae: 0.036147, mean_q: 0.038073
 87703/100000: episode: 12172, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001792, mae: 0.023850, mean_q: 0.026650
 87713/100000: episode: 12173, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001857, mae: 0.032867, mean_q: 0.036108
 87723/100000: episode: 12174, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000897, mae: 0.020712, mean_q: 0.023784
 87733/100000: episode: 12175, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001031, mae: 0.018104, mean_q: 0.024048
 87743/100000: episode: 12176, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.003124, mae: 0.028887, mean_q: 0.041346
 87753/100000: episode: 12177, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001814, mae: 0.025015, mean_q: 0.040675
 87763/100000: episode: 12178, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001679, mae: 0.021882, mean_q: 0.027746
 87773/100000: episode: 12179, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001761, mae: 0.026407, mean_q: 0.044161
 87783/100000: episode: 12180, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002011, mae: 0.025913, mean_q: 0.040508
 87793/100000: episode: 12181, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001818, mae: 0.021982, mean_q: 0.027599
 87803/100000: episode: 12182, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000785, mae: 0.016999, mean_q: 0.023371
 87813/100000: episode: 12183, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000700, mae: 0.015855, mean_q: 0.025028
 87823/100000: episode: 12184, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001796, mae: 0.020916, mean_q: 0.026165
 87833/100000: episode: 12185, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000763, mae: 0.018127, mean_q: 0.030372
 87843/100000: episode: 12186, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001329, mae: 0.022056, mean_q: 0.037876
 87853/100000: episode: 12187, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002200, mae: 0.027238, mean_q: 0.038502
 87863/100000: episode: 12188, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001750, mae: 0.023133, mean_q: 0.035342
 87873/100000: episode: 12189, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001657, mae: 0.026278, mean_q: 0.026503
 87883/100000: episode: 12190, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001683, mae: 0.024194, mean_q: 0.035091
 87893/100000: episode: 12191, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002154, mae: 0.026747, mean_q: 0.043406
 87903/100000: episode: 12192, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.002049, mae: 0.026865, mean_q: 0.030262
 87913/100000: episode: 12193, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001974, mae: 0.023228, mean_q: 0.033620
 87923/100000: episode: 12194, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002274, mae: 0.028076, mean_q: 0.049791
 87933/100000: episode: 12195, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001839, mae: 0.032467, mean_q: 0.036973
 87943/100000: episode: 12196, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001858, mae: 0.023937, mean_q: 0.026075
 87953/100000: episode: 12197, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000756, mae: 0.016776, mean_q: 0.023569
 87963/100000: episode: 12198, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.003117, mae: 0.030330, mean_q: 0.045914
 87973/100000: episode: 12199, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001701, mae: 0.024081, mean_q: 0.034052
 87983/100000: episode: 12200, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001051, mae: 0.017325, mean_q: 0.021912
 87993/100000: episode: 12201, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001384, mae: 0.020100, mean_q: 0.027441
 88003/100000: episode: 12202, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002052, mae: 0.026082, mean_q: 0.035057
 88013/100000: episode: 12203, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002035, mae: 0.027060, mean_q: 0.034304
 88023/100000: episode: 12204, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001182, mae: 0.020617, mean_q: 0.023592
 88033/100000: episode: 12205, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001817, mae: 0.023338, mean_q: 0.026260
 88043/100000: episode: 12206, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001808, mae: 0.024402, mean_q: 0.029073
 88053/100000: episode: 12207, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000886, mae: 0.019546, mean_q: 0.027595
 88063/100000: episode: 12208, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001612, mae: 0.020867, mean_q: 0.029178
 88073/100000: episode: 12209, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002859, mae: 0.024760, mean_q: 0.034755
[Info] 1-TH LEVEL FOUND: 0.025870084762573242, Considering 100/100 traces
 88083/100000: episode: 12210, duration: 0.737s, episode steps: 10, steps per second: 14, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000899, mae: 0.019797, mean_q: 0.018478
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.025870084762573242
 88084/100000: episode: 12211, duration: 0.442s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.003445, mae: 0.032616, mean_q: 0.061493
 88094/100000: episode: 12212, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001377, mae: 0.021448, mean_q: 0.024942
 88104/100000: episode: 12213, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001627, mae: 0.021702, mean_q: 0.026642
 88114/100000: episode: 12214, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001207, mae: 0.017480, mean_q: 0.028894
 88124/100000: episode: 12215, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001074, mae: 0.018420, mean_q: 0.034328
 88134/100000: episode: 12216, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001929, mae: 0.030809, mean_q: 0.047736
 88144/100000: episode: 12217, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002005, mae: 0.024331, mean_q: 0.021189
 88154/100000: episode: 12218, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000806, mae: 0.017879, mean_q: 0.027352
 88164/100000: episode: 12219, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001953, mae: 0.021525, mean_q: 0.031793
 88174/100000: episode: 12220, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000513, mae: 0.016780, mean_q: 0.020595
 88184/100000: episode: 12221, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001740, mae: 0.019452, mean_q: 0.030886
 88194/100000: episode: 12222, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001390, mae: 0.022420, mean_q: 0.043900
 88204/100000: episode: 12223, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001634, mae: 0.021764, mean_q: 0.040697
 88214/100000: episode: 12224, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001292, mae: 0.019346, mean_q: 0.028197
 88224/100000: episode: 12225, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001800, mae: 0.021906, mean_q: 0.027612
 88234/100000: episode: 12226, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001781, mae: 0.020330, mean_q: 0.027906
 88244/100000: episode: 12227, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002395, mae: 0.025202, mean_q: 0.039535
 88254/100000: episode: 12228, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001584, mae: 0.025204, mean_q: 0.038941
 88264/100000: episode: 12229, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002184, mae: 0.024023, mean_q: 0.039900
 88274/100000: episode: 12230, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001920, mae: 0.024276, mean_q: 0.037094
 88284/100000: episode: 12231, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002040, mae: 0.023134, mean_q: 0.027890
 88294/100000: episode: 12232, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001380, mae: 0.019457, mean_q: 0.025689
 88304/100000: episode: 12233, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001164, mae: 0.017547, mean_q: 0.028281
 88314/100000: episode: 12234, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001311, mae: 0.021618, mean_q: 0.030034
 88324/100000: episode: 12235, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001575, mae: 0.020258, mean_q: 0.029112
 88334/100000: episode: 12236, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000798, mae: 0.015801, mean_q: 0.020826
 88344/100000: episode: 12237, duration: 0.045s, episode steps: 10, steps per second: 225, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001264, mae: 0.017260, mean_q: 0.026431
 88354/100000: episode: 12238, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001236, mae: 0.015407, mean_q: 0.023255
 88364/100000: episode: 12239, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000960, mae: 0.018452, mean_q: 0.026778
 88374/100000: episode: 12240, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001381, mae: 0.017742, mean_q: 0.023063
 88384/100000: episode: 12241, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001665, mae: 0.020961, mean_q: 0.032327
 88394/100000: episode: 12242, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000647, mae: 0.014743, mean_q: 0.020708
 88404/100000: episode: 12243, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001715, mae: 0.017538, mean_q: 0.028063
 88414/100000: episode: 12244, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001164, mae: 0.018764, mean_q: 0.030058
 88424/100000: episode: 12245, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002114, mae: 0.025842, mean_q: 0.036290
 88434/100000: episode: 12246, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002868, mae: 0.030835, mean_q: 0.043658
 88444/100000: episode: 12247, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001639, mae: 0.020695, mean_q: 0.023812
 88454/100000: episode: 12248, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002325, mae: 0.026952, mean_q: 0.039847
 88464/100000: episode: 12249, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001499, mae: 0.021040, mean_q: 0.034396
 88474/100000: episode: 12250, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001607, mae: 0.020660, mean_q: 0.027386
 88484/100000: episode: 12251, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001413, mae: 0.019039, mean_q: 0.023883
 88494/100000: episode: 12252, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001566, mae: 0.022591, mean_q: 0.032969
 88504/100000: episode: 12253, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000872, mae: 0.017151, mean_q: 0.023817
 88514/100000: episode: 12254, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001828, mae: 0.024795, mean_q: 0.035137
 88524/100000: episode: 12255, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002392, mae: 0.021990, mean_q: 0.023303
 88534/100000: episode: 12256, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001261, mae: 0.020871, mean_q: 0.025358
 88544/100000: episode: 12257, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001062, mae: 0.017523, mean_q: 0.021102
 88554/100000: episode: 12258, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001369, mae: 0.023206, mean_q: 0.035385
 88564/100000: episode: 12259, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001584, mae: 0.021140, mean_q: 0.030729
 88574/100000: episode: 12260, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001036, mae: 0.018291, mean_q: 0.027248
 88584/100000: episode: 12261, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002019, mae: 0.025011, mean_q: 0.040033
 88594/100000: episode: 12262, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002925, mae: 0.031544, mean_q: 0.047823
 88604/100000: episode: 12263, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001521, mae: 0.021626, mean_q: 0.033350
 88614/100000: episode: 12264, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001204, mae: 0.018216, mean_q: 0.021346
 88624/100000: episode: 12265, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002354, mae: 0.023330, mean_q: 0.031352
 88634/100000: episode: 12266, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001363, mae: 0.022087, mean_q: 0.033109
 88644/100000: episode: 12267, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001953, mae: 0.026064, mean_q: 0.038270
 88654/100000: episode: 12268, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002491, mae: 0.023274, mean_q: 0.030465
 88664/100000: episode: 12269, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.001946, mae: 0.021430, mean_q: 0.025332
 88674/100000: episode: 12270, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002969, mae: 0.030453, mean_q: 0.045604
 88684/100000: episode: 12271, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001236, mae: 0.020826, mean_q: 0.024359
 88694/100000: episode: 12272, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001286, mae: 0.017277, mean_q: 0.021644
 88704/100000: episode: 12273, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001242, mae: 0.018373, mean_q: 0.025982
 88714/100000: episode: 12274, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001421, mae: 0.018455, mean_q: 0.030629
 88724/100000: episode: 12275, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001040, mae: 0.018383, mean_q: 0.030153
 88734/100000: episode: 12276, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001511, mae: 0.018570, mean_q: 0.034288
 88744/100000: episode: 12277, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001688, mae: 0.022390, mean_q: 0.035690
 88754/100000: episode: 12278, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001520, mae: 0.020081, mean_q: 0.031667
 88764/100000: episode: 12279, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001492, mae: 0.021590, mean_q: 0.029573
 88774/100000: episode: 12280, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001086, mae: 0.015808, mean_q: 0.022251
 88784/100000: episode: 12281, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001436, mae: 0.021266, mean_q: 0.027829
 88794/100000: episode: 12282, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001517, mae: 0.019646, mean_q: 0.029407
 88804/100000: episode: 12283, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.001561, mae: 0.021599, mean_q: 0.037306
 88814/100000: episode: 12284, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000722, mae: 0.014839, mean_q: 0.025257
 88824/100000: episode: 12285, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002313, mae: 0.023883, mean_q: 0.033778
 88834/100000: episode: 12286, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001725, mae: 0.024457, mean_q: 0.036872
 88844/100000: episode: 12287, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001254, mae: 0.018241, mean_q: 0.026792
 88854/100000: episode: 12288, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000874, mae: 0.017434, mean_q: 0.024413
 88864/100000: episode: 12289, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002418, mae: 0.024045, mean_q: 0.032291
 88874/100000: episode: 12290, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001771, mae: 0.022894, mean_q: 0.034217
 88884/100000: episode: 12291, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001348, mae: 0.018382, mean_q: 0.023089
 88894/100000: episode: 12292, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001753, mae: 0.024153, mean_q: 0.029136
 88904/100000: episode: 12293, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002060, mae: 0.026445, mean_q: 0.037576
 88914/100000: episode: 12294, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001064, mae: 0.019986, mean_q: 0.030190
 88924/100000: episode: 12295, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001026, mae: 0.017850, mean_q: 0.032155
 88934/100000: episode: 12296, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001709, mae: 0.021177, mean_q: 0.036743
 88944/100000: episode: 12297, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001429, mae: 0.022699, mean_q: 0.037266
 88954/100000: episode: 12298, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001228, mae: 0.018679, mean_q: 0.028352
 88964/100000: episode: 12299, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002154, mae: 0.025570, mean_q: 0.036790
 88974/100000: episode: 12300, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000895, mae: 0.015407, mean_q: 0.022294
 88984/100000: episode: 12301, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002327, mae: 0.028032, mean_q: 0.038351
 88994/100000: episode: 12302, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001350, mae: 0.021099, mean_q: 0.025400
 89004/100000: episode: 12303, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001479, mae: 0.020405, mean_q: 0.031558
 89014/100000: episode: 12304, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001868, mae: 0.024154, mean_q: 0.043943
 89024/100000: episode: 12305, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.001735, mae: 0.025283, mean_q: 0.037815
 89034/100000: episode: 12306, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001867, mae: 0.024341, mean_q: 0.041486
 89044/100000: episode: 12307, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.002173, mae: 0.025386, mean_q: 0.040110
 89054/100000: episode: 12308, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001446, mae: 0.020632, mean_q: 0.026295
 89064/100000: episode: 12309, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001655, mae: 0.022345, mean_q: 0.031463
 89074/100000: episode: 12310, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001777, mae: 0.023033, mean_q: 0.035396
[Info] 1-TH LEVEL FOUND: 0.03711119294166565, Considering 11/100 traces
 89084/100000: episode: 12311, duration: 0.658s, episode steps: 10, steps per second: 15, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001629, mae: 0.023454, mean_q: 0.033847
 89088/100000: episode: 12312, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001103, mae: 0.018126, mean_q: 0.023906
 89094/100000: episode: 12313, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002447, mae: 0.023819, mean_q: 0.033988
 89098/100000: episode: 12314, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000863, mae: 0.024389, mean_q: 0.031730
 89104/100000: episode: 12315, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001800, mae: 0.024993, mean_q: 0.039182
 89110/100000: episode: 12316, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001685, mae: 0.027132, mean_q: 0.031617
 89116/100000: episode: 12317, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000872, mae: 0.016707, mean_q: 0.025996
 89120/100000: episode: 12318, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002453, mae: 0.031775, mean_q: 0.053429
 89124/100000: episode: 12319, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002747, mae: 0.032584, mean_q: 0.071393
 89130/100000: episode: 12320, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.002440, mae: 0.029133, mean_q: 0.034842
 89136/100000: episode: 12321, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001076, mae: 0.018596, mean_q: 0.028141
 89140/100000: episode: 12322, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001710, mae: 0.021390, mean_q: 0.023164
 89146/100000: episode: 12323, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002081, mae: 0.022807, mean_q: 0.033223
 89150/100000: episode: 12324, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001907, mae: 0.020298, mean_q: 0.031320
 89154/100000: episode: 12325, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001070, mae: 0.025352, mean_q: 0.037228
 89158/100000: episode: 12326, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001181, mae: 0.025020, mean_q: 0.020693
 89164/100000: episode: 12327, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001265, mae: 0.021276, mean_q: 0.033654
 89168/100000: episode: 12328, duration: 0.020s, episode steps: 4, steps per second: 198, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002751, mae: 0.024667, mean_q: 0.032192
 89172/100000: episode: 12329, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000978, mae: 0.018032, mean_q: 0.028507
 89178/100000: episode: 12330, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001590, mae: 0.020726, mean_q: 0.027110
 89184/100000: episode: 12331, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000950, mae: 0.014166, mean_q: 0.021177
 89190/100000: episode: 12332, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001796, mae: 0.025227, mean_q: 0.045319
 89194/100000: episode: 12333, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001878, mae: 0.022477, mean_q: 0.024422
 89198/100000: episode: 12334, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000622, mae: 0.017894, mean_q: 0.027116
 89204/100000: episode: 12335, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001252, mae: 0.020921, mean_q: 0.033942
 89208/100000: episode: 12336, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000795, mae: 0.017858, mean_q: 0.021946
 89214/100000: episode: 12337, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001424, mae: 0.024590, mean_q: 0.046586
 89218/100000: episode: 12338, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001530, mae: 0.023727, mean_q: 0.029717
 89222/100000: episode: 12339, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002374, mae: 0.028439, mean_q: 0.052878
 89228/100000: episode: 12340, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000522, mae: 0.015424, mean_q: 0.016912
 89232/100000: episode: 12341, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001735, mae: 0.025615, mean_q: 0.053022
 89238/100000: episode: 12342, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.003167, mae: 0.027252, mean_q: 0.034719
 89244/100000: episode: 12343, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.003634, mae: 0.030507, mean_q: 0.039193
 89250/100000: episode: 12344, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.002492, mae: 0.034919, mean_q: 0.030240
 89254/100000: episode: 12345, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002246, mae: 0.030000, mean_q: 0.038306
 89260/100000: episode: 12346, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001638, mae: 0.024089, mean_q: 0.030470
 89264/100000: episode: 12347, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002450, mae: 0.029437, mean_q: 0.044089
 89268/100000: episode: 12348, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003013, mae: 0.031414, mean_q: 0.038035
 89272/100000: episode: 12349, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001229, mae: 0.022790, mean_q: 0.042759
 89276/100000: episode: 12350, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002796, mae: 0.031077, mean_q: 0.043743
 89280/100000: episode: 12351, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002291, mae: 0.027352, mean_q: 0.046038
 89284/100000: episode: 12352, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000890, mae: 0.019439, mean_q: 0.034257
 89290/100000: episode: 12353, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001445, mae: 0.020142, mean_q: 0.023235
 89296/100000: episode: 12354, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001327, mae: 0.017588, mean_q: 0.028822
 89300/100000: episode: 12355, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001524, mae: 0.022450, mean_q: 0.048949
 89304/100000: episode: 12356, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001852, mae: 0.020763, mean_q: 0.036348
 89310/100000: episode: 12357, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.002889, mae: 0.026693, mean_q: 0.042077
 89316/100000: episode: 12358, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.003579, mae: 0.033314, mean_q: 0.053719
 89322/100000: episode: 12359, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002268, mae: 0.027946, mean_q: 0.034090
 89326/100000: episode: 12360, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000860, mae: 0.018156, mean_q: 0.020823
[Info] FALSIFICATION!
 89331/100000: episode: 12361, duration: 0.259s, episode steps: 5, steps per second: 19, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.001940, mae: 0.018606, mean_q: 0.023194
 89335/100000: episode: 12362, duration: 0.025s, episode steps: 4, steps per second: 160, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001328, mae: 0.020324, mean_q: 0.022514
 89339/100000: episode: 12363, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000747, mae: 0.018460, mean_q: 0.023538
 89343/100000: episode: 12364, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003246, mae: 0.026935, mean_q: 0.037524
 89349/100000: episode: 12365, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001784, mae: 0.020572, mean_q: 0.027218
 89355/100000: episode: 12366, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001424, mae: 0.022175, mean_q: 0.034321
 89359/100000: episode: 12367, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002324, mae: 0.028486, mean_q: 0.042035
 89363/100000: episode: 12368, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001420, mae: 0.018199, mean_q: 0.028386
 89369/100000: episode: 12369, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001214, mae: 0.019748, mean_q: 0.028221
 89375/100000: episode: 12370, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002200, mae: 0.021788, mean_q: 0.028068
[Info] FALSIFICATION!
 89380/100000: episode: 12371, duration: 0.257s, episode steps: 5, steps per second: 19, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000891, mae: 0.016945, mean_q: 0.028813
 89386/100000: episode: 12372, duration: 0.033s, episode steps: 6, steps per second: 180, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001626, mae: 0.022029, mean_q: 0.026982
 89392/100000: episode: 12373, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001727, mae: 0.022634, mean_q: 0.031432
 89398/100000: episode: 12374, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002636, mae: 0.029711, mean_q: 0.050367
 89402/100000: episode: 12375, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002247, mae: 0.026160, mean_q: 0.030790
 89406/100000: episode: 12376, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002233, mae: 0.032105, mean_q: 0.054451
 89410/100000: episode: 12377, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001124, mae: 0.027983, mean_q: 0.019832
 89416/100000: episode: 12378, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.002361, mae: 0.031146, mean_q: 0.048760
 89422/100000: episode: 12379, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000979, mae: 0.021904, mean_q: 0.028720
 89428/100000: episode: 12380, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003146, mae: 0.030745, mean_q: 0.054053
 89434/100000: episode: 12381, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.001531, mae: 0.027930, mean_q: 0.048599
 89440/100000: episode: 12382, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002378, mae: 0.025915, mean_q: 0.049239
 89444/100000: episode: 12383, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000759, mae: 0.016596, mean_q: 0.021197
 89450/100000: episode: 12384, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002586, mae: 0.029531, mean_q: 0.051261
 89456/100000: episode: 12385, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000851, mae: 0.020514, mean_q: 0.028002
 89462/100000: episode: 12386, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001860, mae: 0.021982, mean_q: 0.023268
 89468/100000: episode: 12387, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001425, mae: 0.023554, mean_q: 0.033738
 89474/100000: episode: 12388, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001043, mae: 0.020173, mean_q: 0.023768
 89478/100000: episode: 12389, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001689, mae: 0.022949, mean_q: 0.028150
 89484/100000: episode: 12390, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001856, mae: 0.019419, mean_q: 0.027741
 89488/100000: episode: 12391, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000789, mae: 0.017672, mean_q: 0.026519
 89492/100000: episode: 12392, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001312, mae: 0.024952, mean_q: 0.046059
 89498/100000: episode: 12393, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001224, mae: 0.016076, mean_q: 0.024377
 89504/100000: episode: 12394, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000899, mae: 0.016865, mean_q: 0.025627
 89508/100000: episode: 12395, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002530, mae: 0.025354, mean_q: 0.042552
 89512/100000: episode: 12396, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002466, mae: 0.030461, mean_q: 0.045598
 89516/100000: episode: 12397, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001252, mae: 0.018657, mean_q: 0.027636
 89522/100000: episode: 12398, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001773, mae: 0.022176, mean_q: 0.026875
 89526/100000: episode: 12399, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000887, mae: 0.016127, mean_q: 0.033466
[Info] Complete ISplit Iteration
[Info] Levels: [0.037111193, 0.991812]
[Info] Cond. Prob: [0.11, 0.02]
[Info] Error Prob: 0.0022

 89532/100000: episode: 12400, duration: 0.831s, episode steps: 6, steps per second: 7, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001317, mae: 0.019896, mean_q: 0.032605
 89542/100000: episode: 12401, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.003124, mae: 0.027402, mean_q: 0.036548
 89552/100000: episode: 12402, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001366, mae: 0.022755, mean_q: 0.032271
 89562/100000: episode: 12403, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001863, mae: 0.025189, mean_q: 0.040789
 89572/100000: episode: 12404, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001536, mae: 0.022167, mean_q: 0.043438
 89582/100000: episode: 12405, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.002146, mae: 0.023264, mean_q: 0.029618
 89592/100000: episode: 12406, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001480, mae: 0.021696, mean_q: 0.031123
 89602/100000: episode: 12407, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001117, mae: 0.016707, mean_q: 0.028073
 89612/100000: episode: 12408, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002346, mae: 0.026106, mean_q: 0.040431
 89622/100000: episode: 12409, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001063, mae: 0.019462, mean_q: 0.027281
 89632/100000: episode: 12410, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001776, mae: 0.022994, mean_q: 0.035330
 89642/100000: episode: 12411, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.002344, mae: 0.022796, mean_q: 0.032751
 89652/100000: episode: 12412, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001706, mae: 0.026816, mean_q: 0.041269
 89662/100000: episode: 12413, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001715, mae: 0.020090, mean_q: 0.029430
 89672/100000: episode: 12414, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001189, mae: 0.018610, mean_q: 0.028439
 89682/100000: episode: 12415, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002100, mae: 0.026974, mean_q: 0.037166
 89692/100000: episode: 12416, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001558, mae: 0.028221, mean_q: 0.033448
 89702/100000: episode: 12417, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000699, mae: 0.022096, mean_q: 0.028011
 89712/100000: episode: 12418, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001794, mae: 0.025069, mean_q: 0.036233
 89722/100000: episode: 12419, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001708, mae: 0.019974, mean_q: 0.028333
 89732/100000: episode: 12420, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001217, mae: 0.018318, mean_q: 0.027801
 89742/100000: episode: 12421, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001877, mae: 0.024264, mean_q: 0.037501
 89752/100000: episode: 12422, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002439, mae: 0.028781, mean_q: 0.038858
 89762/100000: episode: 12423, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002225, mae: 0.027428, mean_q: 0.040317
 89772/100000: episode: 12424, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001714, mae: 0.024281, mean_q: 0.036466
 89782/100000: episode: 12425, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002134, mae: 0.026103, mean_q: 0.044595
 89792/100000: episode: 12426, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.002590, mae: 0.030339, mean_q: 0.046345
 89802/100000: episode: 12427, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001718, mae: 0.024048, mean_q: 0.036710
 89812/100000: episode: 12428, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000878, mae: 0.017357, mean_q: 0.023814
 89822/100000: episode: 12429, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001137, mae: 0.018496, mean_q: 0.024301
 89832/100000: episode: 12430, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001571, mae: 0.022320, mean_q: 0.034726
 89842/100000: episode: 12431, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001476, mae: 0.023095, mean_q: 0.033327
 89852/100000: episode: 12432, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002024, mae: 0.025631, mean_q: 0.040815
 89862/100000: episode: 12433, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001643, mae: 0.024068, mean_q: 0.031203
 89872/100000: episode: 12434, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001927, mae: 0.030533, mean_q: 0.048950
 89882/100000: episode: 12435, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000990, mae: 0.017123, mean_q: 0.033212
 89892/100000: episode: 12436, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001788, mae: 0.020512, mean_q: 0.035114
 89902/100000: episode: 12437, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001353, mae: 0.017986, mean_q: 0.021182
 89912/100000: episode: 12438, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001447, mae: 0.020518, mean_q: 0.031832
 89922/100000: episode: 12439, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002267, mae: 0.026013, mean_q: 0.041103
 89932/100000: episode: 12440, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001649, mae: 0.024348, mean_q: 0.035330
 89942/100000: episode: 12441, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001496, mae: 0.020563, mean_q: 0.026652
 89952/100000: episode: 12442, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001247, mae: 0.020779, mean_q: 0.032336
 89962/100000: episode: 12443, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002371, mae: 0.027067, mean_q: 0.040147
 89972/100000: episode: 12444, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001590, mae: 0.025898, mean_q: 0.038464
 89982/100000: episode: 12445, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002222, mae: 0.028907, mean_q: 0.044922
 89992/100000: episode: 12446, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002052, mae: 0.028846, mean_q: 0.041891
 90002/100000: episode: 12447, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000876, mae: 0.019190, mean_q: 0.026938
 90012/100000: episode: 12448, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002288, mae: 0.024942, mean_q: 0.038157
 90022/100000: episode: 12449, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001517, mae: 0.026104, mean_q: 0.032914
 90032/100000: episode: 12450, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000994, mae: 0.019370, mean_q: 0.027223
 90042/100000: episode: 12451, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001206, mae: 0.018634, mean_q: 0.026999
 90052/100000: episode: 12452, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001248, mae: 0.019655, mean_q: 0.036209
 90062/100000: episode: 12453, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001705, mae: 0.021606, mean_q: 0.042023
 90072/100000: episode: 12454, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001442, mae: 0.018217, mean_q: 0.028139
 90082/100000: episode: 12455, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001450, mae: 0.018285, mean_q: 0.026470
 90092/100000: episode: 12456, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000989, mae: 0.017914, mean_q: 0.026937
 90102/100000: episode: 12457, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001367, mae: 0.020970, mean_q: 0.033389
 90112/100000: episode: 12458, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001175, mae: 0.018465, mean_q: 0.027919
 90122/100000: episode: 12459, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001369, mae: 0.017424, mean_q: 0.025398
 90132/100000: episode: 12460, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001229, mae: 0.020633, mean_q: 0.041127
 90142/100000: episode: 12461, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002538, mae: 0.024142, mean_q: 0.034141
 90152/100000: episode: 12462, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001737, mae: 0.023650, mean_q: 0.032258
 90162/100000: episode: 12463, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001136, mae: 0.018108, mean_q: 0.031235
 90172/100000: episode: 12464, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001717, mae: 0.020631, mean_q: 0.036687
 90182/100000: episode: 12465, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001807, mae: 0.024146, mean_q: 0.032808
 90192/100000: episode: 12466, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002485, mae: 0.025718, mean_q: 0.040933
 90202/100000: episode: 12467, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001232, mae: 0.023698, mean_q: 0.035577
 90212/100000: episode: 12468, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001744, mae: 0.026460, mean_q: 0.040294
 90222/100000: episode: 12469, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001536, mae: 0.022675, mean_q: 0.027550
 90232/100000: episode: 12470, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001296, mae: 0.022378, mean_q: 0.034680
 90242/100000: episode: 12471, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001464, mae: 0.024033, mean_q: 0.035423
 90252/100000: episode: 12472, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001449, mae: 0.020979, mean_q: 0.033110
 90262/100000: episode: 12473, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001395, mae: 0.019845, mean_q: 0.032198
 90272/100000: episode: 12474, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001799, mae: 0.027821, mean_q: 0.040146
 90282/100000: episode: 12475, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002023, mae: 0.028062, mean_q: 0.030136
 90292/100000: episode: 12476, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002613, mae: 0.026023, mean_q: 0.031286
 90302/100000: episode: 12477, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002734, mae: 0.032135, mean_q: 0.045148
 90312/100000: episode: 12478, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001797, mae: 0.028169, mean_q: 0.039320
 90322/100000: episode: 12479, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002402, mae: 0.026068, mean_q: 0.041230
 90332/100000: episode: 12480, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002346, mae: 0.026957, mean_q: 0.041322
 90342/100000: episode: 12481, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001057, mae: 0.017921, mean_q: 0.025817
 90352/100000: episode: 12482, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001166, mae: 0.019476, mean_q: 0.028665
 90362/100000: episode: 12483, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.003016, mae: 0.031992, mean_q: 0.053227
 90372/100000: episode: 12484, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001441, mae: 0.021342, mean_q: 0.029983
 90382/100000: episode: 12485, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001388, mae: 0.018834, mean_q: 0.031838
 90392/100000: episode: 12486, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000778, mae: 0.013210, mean_q: 0.022733
 90402/100000: episode: 12487, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001454, mae: 0.020706, mean_q: 0.030338
 90412/100000: episode: 12488, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001440, mae: 0.021567, mean_q: 0.037876
 90422/100000: episode: 12489, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001446, mae: 0.020311, mean_q: 0.035596
 90432/100000: episode: 12490, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001615, mae: 0.024690, mean_q: 0.034574
 90442/100000: episode: 12491, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002637, mae: 0.028374, mean_q: 0.039291
 90452/100000: episode: 12492, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001575, mae: 0.027076, mean_q: 0.030253
 90462/100000: episode: 12493, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.001542, mae: 0.023266, mean_q: 0.031227
 90472/100000: episode: 12494, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001396, mae: 0.023912, mean_q: 0.043053
 90482/100000: episode: 12495, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001791, mae: 0.024926, mean_q: 0.040626
 90492/100000: episode: 12496, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002309, mae: 0.024269, mean_q: 0.037825
 90502/100000: episode: 12497, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002167, mae: 0.026356, mean_q: 0.043635
 90512/100000: episode: 12498, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001487, mae: 0.023275, mean_q: 0.033683
 90522/100000: episode: 12499, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001098, mae: 0.016410, mean_q: 0.020918
[Info] 1-TH LEVEL FOUND: 0.023414045572280884, Considering 10/100 traces
 90532/100000: episode: 12500, duration: 0.696s, episode steps: 10, steps per second: 14, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002002, mae: 0.022717, mean_q: 0.030238
 90536/100000: episode: 12501, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001639, mae: 0.024967, mean_q: 0.038215
 90540/100000: episode: 12502, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000582, mae: 0.014249, mean_q: 0.024412
 90542/100000: episode: 12503, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000509, mae: 0.014725, mean_q: 0.022853
 90546/100000: episode: 12504, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003717, mae: 0.031597, mean_q: 0.046267
 90550/100000: episode: 12505, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002612, mae: 0.028931, mean_q: 0.041706
 90554/100000: episode: 12506, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000776, mae: 0.017405, mean_q: 0.025799
 90556/100000: episode: 12507, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001441, mae: 0.023194, mean_q: 0.027240
 90562/100000: episode: 12508, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001777, mae: 0.020700, mean_q: 0.032322
 90564/100000: episode: 12509, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002795, mae: 0.021292, mean_q: 0.017048
 90568/100000: episode: 12510, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000572, mae: 0.014941, mean_q: 0.027653
 90574/100000: episode: 12511, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001821, mae: 0.021862, mean_q: 0.024886
 90580/100000: episode: 12512, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001075, mae: 0.021434, mean_q: 0.029337
 90584/100000: episode: 12513, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002660, mae: 0.028982, mean_q: 0.050728
 90588/100000: episode: 12514, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002310, mae: 0.029667, mean_q: 0.050101
 90590/100000: episode: 12515, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003896, mae: 0.034230, mean_q: 0.046461
 90592/100000: episode: 12516, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002176, mae: 0.031375, mean_q: 0.064081
 90596/100000: episode: 12517, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000870, mae: 0.015438, mean_q: 0.026187
 90602/100000: episode: 12518, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001547, mae: 0.021275, mean_q: 0.030178
 90606/100000: episode: 12519, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002011, mae: 0.025268, mean_q: 0.034099
 90610/100000: episode: 12520, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001608, mae: 0.025380, mean_q: 0.034435
 90614/100000: episode: 12521, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002026, mae: 0.026747, mean_q: 0.034110
 90618/100000: episode: 12522, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.004637, mae: 0.032352, mean_q: 0.036967
 90622/100000: episode: 12523, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001533, mae: 0.018789, mean_q: 0.022010
 90624/100000: episode: 12524, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001957, mae: 0.027307, mean_q: 0.056165
 90626/100000: episode: 12525, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.003663, mae: 0.033779, mean_q: 0.047056
 90632/100000: episode: 12526, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002200, mae: 0.034488, mean_q: 0.025503
 90636/100000: episode: 12527, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001504, mae: 0.027075, mean_q: 0.032488
 90640/100000: episode: 12528, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002117, mae: 0.030541, mean_q: 0.028359
 90646/100000: episode: 12529, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002487, mae: 0.033002, mean_q: 0.052192
 90650/100000: episode: 12530, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000508, mae: 0.016763, mean_q: 0.011578
 90656/100000: episode: 12531, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001709, mae: 0.025570, mean_q: 0.046833
 90660/100000: episode: 12532, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002247, mae: 0.027207, mean_q: 0.043218
 90664/100000: episode: 12533, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001227, mae: 0.025374, mean_q: 0.033329
 90670/100000: episode: 12534, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000864, mae: 0.017765, mean_q: 0.026830
 90676/100000: episode: 12535, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001416, mae: 0.020900, mean_q: 0.034313
 90682/100000: episode: 12536, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001703, mae: 0.019054, mean_q: 0.032917
 90686/100000: episode: 12537, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001377, mae: 0.021041, mean_q: 0.027612
 90692/100000: episode: 12538, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000750, mae: 0.017672, mean_q: 0.032925
 90696/100000: episode: 12539, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000831, mae: 0.018046, mean_q: 0.027664
 90702/100000: episode: 12540, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001149, mae: 0.019153, mean_q: 0.030837
 90708/100000: episode: 12541, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001297, mae: 0.020688, mean_q: 0.032590
 90714/100000: episode: 12542, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.001972, mae: 0.020912, mean_q: 0.037430
 90718/100000: episode: 12543, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000963, mae: 0.018684, mean_q: 0.030056
 90724/100000: episode: 12544, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001347, mae: 0.021384, mean_q: 0.028243
 90726/100000: episode: 12545, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001522, mae: 0.020309, mean_q: 0.029637
 90730/100000: episode: 12546, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001583, mae: 0.021682, mean_q: 0.040128
 90732/100000: episode: 12547, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001335, mae: 0.020384, mean_q: 0.046440
 90734/100000: episode: 12548, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000394, mae: 0.013999, mean_q: 0.014722
 90738/100000: episode: 12549, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001610, mae: 0.022117, mean_q: 0.040101
 90744/100000: episode: 12550, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001320, mae: 0.018837, mean_q: 0.039271
 90748/100000: episode: 12551, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000855, mae: 0.013194, mean_q: 0.024720
 90752/100000: episode: 12552, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001817, mae: 0.022441, mean_q: 0.040191
 90756/100000: episode: 12553, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000400, mae: 0.013329, mean_q: 0.017903
 90760/100000: episode: 12554, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002816, mae: 0.023871, mean_q: 0.033148
 90762/100000: episode: 12555, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000186, mae: 0.010736, mean_q: 0.016220
 90768/100000: episode: 12556, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001881, mae: 0.025829, mean_q: 0.034207
 90772/100000: episode: 12557, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000922, mae: 0.015373, mean_q: 0.018160
 90774/100000: episode: 12558, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001252, mae: 0.020557, mean_q: 0.032209
[Info] FALSIFICATION!
 90779/100000: episode: 12559, duration: 0.257s, episode steps: 5, steps per second: 19, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000863, mae: 0.017534, mean_q: 0.026590
 90783/100000: episode: 12560, duration: 0.025s, episode steps: 4, steps per second: 161, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002646, mae: 0.025704, mean_q: 0.040123
 90785/100000: episode: 12561, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002127, mae: 0.025731, mean_q: 0.044219
 90787/100000: episode: 12562, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001094, mae: 0.020896, mean_q: 0.032697
 90789/100000: episode: 12563, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001172, mae: 0.019537, mean_q: 0.038903
 90793/100000: episode: 12564, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001526, mae: 0.020588, mean_q: 0.036225
 90797/100000: episode: 12565, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001599, mae: 0.020573, mean_q: 0.039312
 90801/100000: episode: 12566, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000402, mae: 0.010596, mean_q: 0.018039
 90805/100000: episode: 12567, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001521, mae: 0.021447, mean_q: 0.032003
 90811/100000: episode: 12568, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001312, mae: 0.020920, mean_q: 0.045600
 90813/100000: episode: 12569, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.005273, mae: 0.046340, mean_q: 0.103508
 90817/100000: episode: 12570, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.005040, mae: 0.035815, mean_q: 0.057160
 90819/100000: episode: 12571, duration: 0.012s, episode steps: 2, steps per second: 168, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000461, mae: 0.012082, mean_q: 0.021426
 90823/100000: episode: 12572, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000838, mae: 0.020471, mean_q: 0.033904
 90825/100000: episode: 12573, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001154, mae: 0.019072, mean_q: 0.023401
 90827/100000: episode: 12574, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001870, mae: 0.025725, mean_q: 0.037037
 90829/100000: episode: 12575, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002400, mae: 0.029541, mean_q: 0.032800
 90833/100000: episode: 12576, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001666, mae: 0.021996, mean_q: 0.038162
 90835/100000: episode: 12577, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000896, mae: 0.018966, mean_q: 0.028873
 90841/100000: episode: 12578, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000800, mae: 0.017932, mean_q: 0.029323
 90843/100000: episode: 12579, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001739, mae: 0.023179, mean_q: 0.034194
 90847/100000: episode: 12580, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001408, mae: 0.021418, mean_q: 0.046181
 90849/100000: episode: 12581, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000335, mae: 0.012048, mean_q: 0.021855
 90853/100000: episode: 12582, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000489, mae: 0.016386, mean_q: 0.026893
 90857/100000: episode: 12583, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000797, mae: 0.018774, mean_q: 0.017887
 90861/100000: episode: 12584, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002783, mae: 0.031749, mean_q: 0.053060
 90863/100000: episode: 12585, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002174, mae: 0.027976, mean_q: 0.057535
 90867/100000: episode: 12586, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001261, mae: 0.023354, mean_q: 0.033663
 90871/100000: episode: 12587, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001605, mae: 0.026900, mean_q: 0.043796
 90875/100000: episode: 12588, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000770, mae: 0.018536, mean_q: 0.027509
 90877/100000: episode: 12589, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001427, mae: 0.022837, mean_q: 0.038953
[Info] Complete ISplit Iteration
[Info] Levels: [0.023414046, 1.1568533]
[Info] Cond. Prob: [0.1, 0.01]
[Info] Error Prob: 0.001

 90881/100000: episode: 12590, duration: 0.829s, episode steps: 4, steps per second: 5, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002082, mae: 0.023230, mean_q: 0.044108
 90891/100000: episode: 12591, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001933, mae: 0.021078, mean_q: 0.039044
 90901/100000: episode: 12592, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001323, mae: 0.018324, mean_q: 0.033120
 90911/100000: episode: 12593, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001442, mae: 0.021316, mean_q: 0.037605
 90921/100000: episode: 12594, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.002065, mae: 0.024845, mean_q: 0.049191
 90931/100000: episode: 12595, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.002028, mae: 0.027885, mean_q: 0.045981
 90941/100000: episode: 12596, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.002705, mae: 0.026901, mean_q: 0.039982
 90951/100000: episode: 12597, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001937, mae: 0.025213, mean_q: 0.035991
 90961/100000: episode: 12598, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001844, mae: 0.025599, mean_q: 0.040379
 90971/100000: episode: 12599, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002551, mae: 0.029048, mean_q: 0.047446
 90981/100000: episode: 12600, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001697, mae: 0.024010, mean_q: 0.029042
 90991/100000: episode: 12601, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000921, mae: 0.019403, mean_q: 0.031573
 91001/100000: episode: 12602, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001365, mae: 0.021122, mean_q: 0.035945
 91011/100000: episode: 12603, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001926, mae: 0.021604, mean_q: 0.042416
 91021/100000: episode: 12604, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001191, mae: 0.017719, mean_q: 0.028508
 91031/100000: episode: 12605, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001504, mae: 0.021456, mean_q: 0.039322
 91041/100000: episode: 12606, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002516, mae: 0.026616, mean_q: 0.037233
 91051/100000: episode: 12607, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001485, mae: 0.023440, mean_q: 0.029973
 91061/100000: episode: 12608, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000360, mae: 0.012013, mean_q: 0.016537
 91071/100000: episode: 12609, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001991, mae: 0.024466, mean_q: 0.044561
 91081/100000: episode: 12610, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001028, mae: 0.016289, mean_q: 0.031247
 91091/100000: episode: 12611, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.002504, mae: 0.026693, mean_q: 0.041386
 91101/100000: episode: 12612, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001719, mae: 0.027229, mean_q: 0.039456
 91111/100000: episode: 12613, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000926, mae: 0.016633, mean_q: 0.019647
 91121/100000: episode: 12614, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001417, mae: 0.019704, mean_q: 0.025206
 91131/100000: episode: 12615, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002778, mae: 0.028163, mean_q: 0.039812
 91141/100000: episode: 12616, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001121, mae: 0.020570, mean_q: 0.030252
 91151/100000: episode: 12617, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000730, mae: 0.018806, mean_q: 0.026093
 91161/100000: episode: 12618, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000865, mae: 0.019059, mean_q: 0.039193
 91171/100000: episode: 12619, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.002312, mae: 0.021696, mean_q: 0.038632
 91181/100000: episode: 12620, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001127, mae: 0.018217, mean_q: 0.026658
 91191/100000: episode: 12621, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.001821, mae: 0.023050, mean_q: 0.030963
 91201/100000: episode: 12622, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000755, mae: 0.014197, mean_q: 0.023316
 91211/100000: episode: 12623, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000854, mae: 0.016893, mean_q: 0.032812
 91221/100000: episode: 12624, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000733, mae: 0.014844, mean_q: 0.029165
 91231/100000: episode: 12625, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000913, mae: 0.016190, mean_q: 0.022752
 91241/100000: episode: 12626, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001855, mae: 0.019430, mean_q: 0.029165
 91251/100000: episode: 12627, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000866, mae: 0.019624, mean_q: 0.027552
 91261/100000: episode: 12628, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001318, mae: 0.020278, mean_q: 0.033373
 91271/100000: episode: 12629, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001662, mae: 0.020772, mean_q: 0.028346
 91281/100000: episode: 12630, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001045, mae: 0.015793, mean_q: 0.021468
 91291/100000: episode: 12631, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000767, mae: 0.015783, mean_q: 0.019799
 91301/100000: episode: 12632, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.002260, mae: 0.026881, mean_q: 0.045149
 91311/100000: episode: 12633, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000584, mae: 0.015336, mean_q: 0.030294
 91321/100000: episode: 12634, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000959, mae: 0.015381, mean_q: 0.025502
 91331/100000: episode: 12635, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000674, mae: 0.013911, mean_q: 0.020718
 91341/100000: episode: 12636, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000858, mae: 0.015263, mean_q: 0.023752
 91351/100000: episode: 12637, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001405, mae: 0.016203, mean_q: 0.024040
 91361/100000: episode: 12638, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000579, mae: 0.017770, mean_q: 0.020878
 91371/100000: episode: 12639, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001817, mae: 0.021570, mean_q: 0.032323
 91381/100000: episode: 12640, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000908, mae: 0.014473, mean_q: 0.022583
 91391/100000: episode: 12641, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000574, mae: 0.013221, mean_q: 0.019724
 91401/100000: episode: 12642, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000634, mae: 0.013548, mean_q: 0.016472
 91411/100000: episode: 12643, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000360, mae: 0.012198, mean_q: 0.018382
 91421/100000: episode: 12644, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001171, mae: 0.016305, mean_q: 0.024578
 91431/100000: episode: 12645, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000829, mae: 0.012599, mean_q: 0.021570
 91441/100000: episode: 12646, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000450, mae: 0.011615, mean_q: 0.019785
 91451/100000: episode: 12647, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000556, mae: 0.011925, mean_q: 0.023898
 91461/100000: episode: 12648, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000587, mae: 0.012290, mean_q: 0.021669
 91471/100000: episode: 12649, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000889, mae: 0.011546, mean_q: 0.016899
 91481/100000: episode: 12650, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001182, mae: 0.015558, mean_q: 0.021809
 91491/100000: episode: 12651, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000886, mae: 0.014700, mean_q: 0.018353
 91501/100000: episode: 12652, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000731, mae: 0.012468, mean_q: 0.014986
 91511/100000: episode: 12653, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001103, mae: 0.012473, mean_q: 0.019451
 91521/100000: episode: 12654, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000201, mae: 0.010464, mean_q: 0.014075
 91531/100000: episode: 12655, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000416, mae: 0.012666, mean_q: 0.017418
 91541/100000: episode: 12656, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000222, mae: 0.009658, mean_q: 0.016658
 91551/100000: episode: 12657, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000271, mae: 0.010127, mean_q: 0.017821
 91561/100000: episode: 12658, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000276, mae: 0.009797, mean_q: 0.016610
 91571/100000: episode: 12659, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000603, mae: 0.009312, mean_q: 0.014614
 91581/100000: episode: 12660, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000227, mae: 0.009145, mean_q: 0.014637
 91591/100000: episode: 12661, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000627, mae: 0.011640, mean_q: 0.018525
 91601/100000: episode: 12662, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000953, mae: 0.011985, mean_q: 0.020271
 91611/100000: episode: 12663, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000507, mae: 0.010869, mean_q: 0.013096
 91621/100000: episode: 12664, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000596, mae: 0.011927, mean_q: 0.019301
 91631/100000: episode: 12665, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000392, mae: 0.009406, mean_q: 0.014663
 91641/100000: episode: 12666, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000322, mae: 0.008842, mean_q: 0.011790
 91651/100000: episode: 12667, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000518, mae: 0.008882, mean_q: 0.016067
 91661/100000: episode: 12668, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000452, mae: 0.009149, mean_q: 0.015086
 91671/100000: episode: 12669, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000244, mae: 0.008493, mean_q: 0.012264
 91681/100000: episode: 12670, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000395, mae: 0.009455, mean_q: 0.011659
 91691/100000: episode: 12671, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000349, mae: 0.009923, mean_q: 0.013334
 91701/100000: episode: 12672, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000272, mae: 0.009862, mean_q: 0.015467
 91711/100000: episode: 12673, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000498, mae: 0.008601, mean_q: 0.011758
 91721/100000: episode: 12674, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000526, mae: 0.010298, mean_q: 0.015541
 91731/100000: episode: 12675, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000443, mae: 0.010044, mean_q: 0.015826
 91741/100000: episode: 12676, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000234, mae: 0.008598, mean_q: 0.012111
 91751/100000: episode: 12677, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000119, mae: 0.007498, mean_q: 0.010595
 91761/100000: episode: 12678, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000504, mae: 0.011171, mean_q: 0.015789
 91771/100000: episode: 12679, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000402, mae: 0.009319, mean_q: 0.014159
 91781/100000: episode: 12680, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000153, mae: 0.007933, mean_q: 0.011645
 91791/100000: episode: 12681, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000123, mae: 0.006530, mean_q: 0.008608
 91801/100000: episode: 12682, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000236, mae: 0.007874, mean_q: 0.011469
 91811/100000: episode: 12683, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000806, mae: 0.009858, mean_q: 0.016402
 91821/100000: episode: 12684, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000174, mae: 0.008927, mean_q: 0.013903
 91831/100000: episode: 12685, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000331, mae: 0.009095, mean_q: 0.014425
 91841/100000: episode: 12686, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000862, mae: 0.015645, mean_q: 0.017488
 91851/100000: episode: 12687, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000708, mae: 0.014244, mean_q: 0.017907
 91861/100000: episode: 12688, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000216, mae: 0.011316, mean_q: 0.011661
 91871/100000: episode: 12689, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000107, mae: 0.008130, mean_q: 0.009567
[Info] 1-TH LEVEL FOUND: 0.02654343843460083, Considering 10/100 traces
 91881/100000: episode: 12690, duration: 0.704s, episode steps: 10, steps per second: 14, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000279, mae: 0.010087, mean_q: 0.012592
 91885/100000: episode: 12691, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001061, mae: 0.014091, mean_q: 0.023034
 91891/100000: episode: 12692, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000388, mae: 0.009462, mean_q: 0.010614
 91897/100000: episode: 12693, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000184, mae: 0.011129, mean_q: 0.016150
 91899/100000: episode: 12694, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000571, mae: 0.011850, mean_q: 0.016408
 91901/100000: episode: 12695, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000679, mae: 0.016788, mean_q: 0.024740
 91907/100000: episode: 12696, duration: 0.028s, episode steps: 6, steps per second: 211, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000606, mae: 0.013412, mean_q: 0.015778
 91911/100000: episode: 12697, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000103, mae: 0.008812, mean_q: 0.012316
 91915/100000: episode: 12698, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000670, mae: 0.012385, mean_q: 0.017989
 91919/100000: episode: 12699, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000326, mae: 0.010904, mean_q: 0.012011
 91925/100000: episode: 12700, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000097, mae: 0.007129, mean_q: 0.010388
 91927/100000: episode: 12701, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000401, mae: 0.012963, mean_q: 0.014175
 91933/100000: episode: 12702, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000306, mae: 0.010387, mean_q: 0.016155
 91939/100000: episode: 12703, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000158, mae: 0.009359, mean_q: 0.015827
 91943/100000: episode: 12704, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000216, mae: 0.011122, mean_q: 0.008296
 91947/100000: episode: 12705, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000338, mae: 0.013120, mean_q: 0.021920
 91951/100000: episode: 12706, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001147, mae: 0.018078, mean_q: 0.027223
 91955/100000: episode: 12707, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000136, mae: 0.008100, mean_q: 0.012539
 91959/100000: episode: 12708, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001088, mae: 0.015102, mean_q: 0.025498
 91963/100000: episode: 12709, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001924, mae: 0.017914, mean_q: 0.025160
 91967/100000: episode: 12710, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000103, mae: 0.007609, mean_q: 0.009446
 91971/100000: episode: 12711, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000669, mae: 0.010452, mean_q: 0.016375
 91975/100000: episode: 12712, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000142, mae: 0.010085, mean_q: 0.013153
 91981/100000: episode: 12713, duration: 0.028s, episode steps: 6, steps per second: 211, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000278, mae: 0.008993, mean_q: 0.010736
 91983/100000: episode: 12714, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000150, mae: 0.011649, mean_q: 0.017929
 91985/100000: episode: 12715, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000110, mae: 0.008469, mean_q: 0.019680
 91987/100000: episode: 12716, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000139, mae: 0.008905, mean_q: 0.007282
 91991/100000: episode: 12717, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000275, mae: 0.007853, mean_q: 0.010249
 91997/100000: episode: 12718, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000542, mae: 0.011162, mean_q: 0.016063
 92001/100000: episode: 12719, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000309, mae: 0.010228, mean_q: 0.013889
 92003/100000: episode: 12720, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000115, mae: 0.008701, mean_q: 0.014570
 92005/100000: episode: 12721, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000992, mae: 0.015809, mean_q: 0.023771
 92011/100000: episode: 12722, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000116, mae: 0.009363, mean_q: 0.010524
 92015/100000: episode: 12723, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000938, mae: 0.013729, mean_q: 0.013258
 92021/100000: episode: 12724, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000869, mae: 0.013802, mean_q: 0.015739
 92025/100000: episode: 12725, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000729, mae: 0.013246, mean_q: 0.020870
 92029/100000: episode: 12726, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000659, mae: 0.014586, mean_q: 0.014148
 92033/100000: episode: 12727, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000547, mae: 0.015103, mean_q: 0.025260
 92037/100000: episode: 12728, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000134, mae: 0.009740, mean_q: 0.013488
 92041/100000: episode: 12729, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000125, mae: 0.009124, mean_q: 0.014390
 92045/100000: episode: 12730, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000412, mae: 0.010703, mean_q: 0.013769
 92049/100000: episode: 12731, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000454, mae: 0.010577, mean_q: 0.018186
 92053/100000: episode: 12732, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000229, mae: 0.010140, mean_q: 0.014090
 92055/100000: episode: 12733, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000171, mae: 0.012002, mean_q: 0.012553
 92057/100000: episode: 12734, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000128, mae: 0.009861, mean_q: 0.015573
 92061/100000: episode: 12735, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000404, mae: 0.012006, mean_q: 0.021158
 92065/100000: episode: 12736, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000131, mae: 0.008551, mean_q: 0.012369
 92071/100000: episode: 12737, duration: 0.029s, episode steps: 6, steps per second: 210, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000422, mae: 0.010352, mean_q: 0.012958
 92073/100000: episode: 12738, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000996, mae: 0.015586, mean_q: 0.023218
 92079/100000: episode: 12739, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000467, mae: 0.011813, mean_q: 0.012354
 92081/100000: episode: 12740, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000849, mae: 0.012546, mean_q: 0.023573
 92087/100000: episode: 12741, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000392, mae: 0.012214, mean_q: 0.019832
 92089/100000: episode: 12742, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000488, mae: 0.015064, mean_q: 0.022013
 92093/100000: episode: 12743, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000124, mae: 0.009034, mean_q: 0.008502
 92097/100000: episode: 12744, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000114, mae: 0.010944, mean_q: 0.015477
 92101/100000: episode: 12745, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000092, mae: 0.008157, mean_q: 0.008734
 92103/100000: episode: 12746, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000312, mae: 0.015060, mean_q: 0.026188
 92107/100000: episode: 12747, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000245, mae: 0.010446, mean_q: 0.012530
 92109/100000: episode: 12748, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000095, mae: 0.007367, mean_q: 0.009580
 92113/100000: episode: 12749, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000292, mae: 0.010810, mean_q: 0.017325
 92117/100000: episode: 12750, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001121, mae: 0.014932, mean_q: 0.024762
 92121/100000: episode: 12751, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000323, mae: 0.010225, mean_q: 0.015774
 92125/100000: episode: 12752, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000099, mae: 0.008230, mean_q: 0.009156
 92129/100000: episode: 12753, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000073, mae: 0.007682, mean_q: 0.009935
 92135/100000: episode: 12754, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000304, mae: 0.012900, mean_q: 0.018493
 92137/100000: episode: 12755, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000330, mae: 0.011161, mean_q: 0.012954
 92139/100000: episode: 12756, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000159, mae: 0.009785, mean_q: 0.016124
 92141/100000: episode: 12757, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000413, mae: 0.013272, mean_q: 0.027208
 92143/100000: episode: 12758, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000146, mae: 0.009702, mean_q: 0.006578
 92147/100000: episode: 12759, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000424, mae: 0.014690, mean_q: 0.026195
 92151/100000: episode: 12760, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001067, mae: 0.014836, mean_q: 0.012071
 92155/100000: episode: 12761, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000139, mae: 0.010059, mean_q: 0.016607
 92159/100000: episode: 12762, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000405, mae: 0.012564, mean_q: 0.014528
 92163/100000: episode: 12763, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000242, mae: 0.010208, mean_q: 0.015121
 92165/100000: episode: 12764, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000065, mae: 0.006806, mean_q: 0.003786
 92171/100000: episode: 12765, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000804, mae: 0.012717, mean_q: 0.023078
 92175/100000: episode: 12766, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000195, mae: 0.010259, mean_q: 0.013659
 92179/100000: episode: 12767, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000409, mae: 0.012056, mean_q: 0.018566
 92185/100000: episode: 12768, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000396, mae: 0.010124, mean_q: 0.017489
 92191/100000: episode: 12769, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000107, mae: 0.008960, mean_q: 0.011077
 92195/100000: episode: 12770, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000125, mae: 0.009562, mean_q: 0.013882
 92197/100000: episode: 12771, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000150, mae: 0.008876, mean_q: 0.014125
 92201/100000: episode: 12772, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000916, mae: 0.011796, mean_q: 0.017655
 92203/100000: episode: 12773, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000804, mae: 0.013535, mean_q: 0.025858
 92207/100000: episode: 12774, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000114, mae: 0.007899, mean_q: 0.011508
 92209/100000: episode: 12775, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000228, mae: 0.009379, mean_q: 0.012060
 92211/100000: episode: 12776, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001503, mae: 0.015516, mean_q: 0.022826
 92213/100000: episode: 12777, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000171, mae: 0.009843, mean_q: 0.011778
 92217/100000: episode: 12778, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000361, mae: 0.011560, mean_q: 0.018197
 92223/100000: episode: 12779, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000167, mae: 0.009348, mean_q: 0.010163
[Info] 2-TH LEVEL FOUND: 0.10399273037910461, Considering 32/100 traces
 92225/100000: episode: 12780, duration: 0.686s, episode steps: 2, steps per second: 3, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000129, mae: 0.010433, mean_q: 0.018582
 92229/100000: episode: 12781, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000254, mae: 0.012465, mean_q: 0.014169
 92232/100000: episode: 12782, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000814, mae: 0.015999, mean_q: 0.028486
 92235/100000: episode: 12783, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000209, mae: 0.011775, mean_q: 0.013801
 92238/100000: episode: 12784, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001301, mae: 0.016231, mean_q: 0.019773
 92241/100000: episode: 12785, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000232, mae: 0.012673, mean_q: 0.019513
 92244/100000: episode: 12786, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000277, mae: 0.011753, mean_q: 0.012330
 92247/100000: episode: 12787, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000277, mae: 0.011286, mean_q: 0.015734
 92250/100000: episode: 12788, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000236, mae: 0.011458, mean_q: 0.012200
 92254/100000: episode: 12789, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000160, mae: 0.008323, mean_q: 0.009717
 92257/100000: episode: 12790, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000251, mae: 0.010324, mean_q: 0.013391
 92260/100000: episode: 12791, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000228, mae: 0.009143, mean_q: 0.011344
 92263/100000: episode: 12792, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000202, mae: 0.009117, mean_q: 0.013846
 92266/100000: episode: 12793, duration: 0.016s, episode steps: 3, steps per second: 186, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000819, mae: 0.015949, mean_q: 0.032703
 92269/100000: episode: 12794, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000378, mae: 0.011010, mean_q: 0.017960
 92272/100000: episode: 12795, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000465, mae: 0.012913, mean_q: 0.026112
 92275/100000: episode: 12796, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001244, mae: 0.016748, mean_q: 0.026108
 92278/100000: episode: 12797, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001947, mae: 0.020136, mean_q: 0.024510
 92281/100000: episode: 12798, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000433, mae: 0.018713, mean_q: 0.032378
 92284/100000: episode: 12799, duration: 0.016s, episode steps: 3, steps per second: 186, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000153, mae: 0.012556, mean_q: 0.007260
 92287/100000: episode: 12800, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000179, mae: 0.012224, mean_q: 0.009353
 92290/100000: episode: 12801, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000427, mae: 0.014811, mean_q: 0.024380
 92293/100000: episode: 12802, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000214, mae: 0.012043, mean_q: 0.002346
 92296/100000: episode: 12803, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000240, mae: 0.012258, mean_q: 0.016174
 92300/100000: episode: 12804, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000517, mae: 0.015468, mean_q: 0.019927
 92303/100000: episode: 12805, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001904, mae: 0.019928, mean_q: 0.027819
 92306/100000: episode: 12806, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000347, mae: 0.012475, mean_q: 0.009675
 92309/100000: episode: 12807, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000953, mae: 0.016786, mean_q: 0.019423
 92312/100000: episode: 12808, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000218, mae: 0.013209, mean_q: 0.019096
 92315/100000: episode: 12809, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000129, mae: 0.010240, mean_q: 0.011362
 92318/100000: episode: 12810, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001213, mae: 0.017916, mean_q: 0.020543
 92321/100000: episode: 12811, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001189, mae: 0.017771, mean_q: 0.033194
 92324/100000: episode: 12812, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000792, mae: 0.013966, mean_q: 0.021056
 92327/100000: episode: 12813, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000083, mae: 0.006452, mean_q: 0.008691
 92330/100000: episode: 12814, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000288, mae: 0.011511, mean_q: 0.024395
 92333/100000: episode: 12815, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000588, mae: 0.009479, mean_q: 0.012897
 92336/100000: episode: 12816, duration: 0.016s, episode steps: 3, steps per second: 187, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000154, mae: 0.010341, mean_q: 0.012601
 92339/100000: episode: 12817, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000111, mae: 0.009229, mean_q: 0.011840
 92342/100000: episode: 12818, duration: 0.026s, episode steps: 3, steps per second: 117, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000308, mae: 0.010439, mean_q: 0.012005
 92345/100000: episode: 12819, duration: 0.020s, episode steps: 3, steps per second: 149, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000378, mae: 0.012490, mean_q: 0.020879
 92349/100000: episode: 12820, duration: 0.040s, episode steps: 4, steps per second: 99, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000168, mae: 0.009781, mean_q: 0.012448
 92352/100000: episode: 12821, duration: 0.022s, episode steps: 3, steps per second: 138, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000105, mae: 0.008305, mean_q: 0.014081
 92355/100000: episode: 12822, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000427, mae: 0.013332, mean_q: 0.016449
 92358/100000: episode: 12823, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000738, mae: 0.013016, mean_q: 0.018155
 92361/100000: episode: 12824, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001468, mae: 0.020621, mean_q: 0.027015
 92364/100000: episode: 12825, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000864, mae: 0.016045, mean_q: 0.022354
 92367/100000: episode: 12826, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000095, mae: 0.008730, mean_q: 0.010455
 92370/100000: episode: 12827, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000127, mae: 0.008712, mean_q: 0.012569
[Info] FALSIFICATION!
 92373/100000: episode: 12828, duration: 0.169s, episode steps: 3, steps per second: 18, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000840, mae: 0.009763, mean_q: 0.013444
 92376/100000: episode: 12829, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000108, mae: 0.008185, mean_q: 0.012851
 92379/100000: episode: 12830, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000415, mae: 0.011011, mean_q: 0.014342
 92382/100000: episode: 12831, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000144, mae: 0.010007, mean_q: 0.012223
 92385/100000: episode: 12832, duration: 0.016s, episode steps: 3, steps per second: 187, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000095, mae: 0.008350, mean_q: 0.012736
 92389/100000: episode: 12833, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000355, mae: 0.009553, mean_q: 0.012235
 92392/100000: episode: 12834, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.003186, mae: 0.019839, mean_q: 0.023953
 92395/100000: episode: 12835, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000898, mae: 0.017036, mean_q: 0.028241
 92398/100000: episode: 12836, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001235, mae: 0.017655, mean_q: 0.019658
 92401/100000: episode: 12837, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000242, mae: 0.014078, mean_q: 0.018232
 92404/100000: episode: 12838, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000360, mae: 0.012748, mean_q: 0.012452
 92407/100000: episode: 12839, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000454, mae: 0.014339, mean_q: 0.014750
 92410/100000: episode: 12840, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000505, mae: 0.013809, mean_q: 0.021652
 92414/100000: episode: 12841, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000410, mae: 0.011936, mean_q: 0.015555
 92417/100000: episode: 12842, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001660, mae: 0.020122, mean_q: 0.027367
 92420/100000: episode: 12843, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000321, mae: 0.011819, mean_q: 0.015263
 92424/100000: episode: 12844, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000100, mae: 0.008597, mean_q: 0.014349
 92427/100000: episode: 12845, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000068, mae: 0.007839, mean_q: 0.007692
 92430/100000: episode: 12846, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000115, mae: 0.008892, mean_q: 0.014195
 92433/100000: episode: 12847, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000157, mae: 0.010035, mean_q: 0.010404
[Info] Complete ISplit Iteration
[Info] Levels: [0.026543438, 0.10399273, 0.96200776]
[Info] Cond. Prob: [0.1, 0.32, 0.01]
[Info] Error Prob: 0.00032

 92436/100000: episode: 12848, duration: 0.737s, episode steps: 3, steps per second: 4, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000119, mae: 0.009482, mean_q: 0.015441
 92446/100000: episode: 12849, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001475, mae: 0.016207, mean_q: 0.023840
 92456/100000: episode: 12850, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000984, mae: 0.016473, mean_q: 0.023915
 92466/100000: episode: 12851, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000982, mae: 0.017570, mean_q: 0.019851
 92476/100000: episode: 12852, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000459, mae: 0.015795, mean_q: 0.012760
 92486/100000: episode: 12853, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000830, mae: 0.014730, mean_q: 0.020040
 92496/100000: episode: 12854, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000385, mae: 0.011701, mean_q: 0.016675
 92506/100000: episode: 12855, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000673, mae: 0.011915, mean_q: 0.022047
 92516/100000: episode: 12856, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000853, mae: 0.016674, mean_q: 0.023180
 92526/100000: episode: 12857, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000835, mae: 0.019679, mean_q: 0.024163
 92536/100000: episode: 12858, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000325, mae: 0.012924, mean_q: 0.019077
 92546/100000: episode: 12859, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000693, mae: 0.015790, mean_q: 0.023819
 92556/100000: episode: 12860, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000232, mae: 0.010203, mean_q: 0.013660
 92566/100000: episode: 12861, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001071, mae: 0.015554, mean_q: 0.023178
 92576/100000: episode: 12862, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000736, mae: 0.017347, mean_q: 0.022046
 92586/100000: episode: 12863, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000253, mae: 0.012976, mean_q: 0.012559
 92596/100000: episode: 12864, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000394, mae: 0.014092, mean_q: 0.024252
 92606/100000: episode: 12865, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000413, mae: 0.011600, mean_q: 0.015641
 92616/100000: episode: 12866, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000583, mae: 0.014743, mean_q: 0.017877
 92626/100000: episode: 12867, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000528, mae: 0.013377, mean_q: 0.015689
 92636/100000: episode: 12868, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000139, mae: 0.009147, mean_q: 0.012036
 92646/100000: episode: 12869, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001243, mae: 0.015878, mean_q: 0.024086
 92656/100000: episode: 12870, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000928, mae: 0.016259, mean_q: 0.024786
 92666/100000: episode: 12871, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000372, mae: 0.012602, mean_q: 0.017390
 92676/100000: episode: 12872, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000181, mae: 0.009617, mean_q: 0.013221
 92686/100000: episode: 12873, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000452, mae: 0.013077, mean_q: 0.021047
 92696/100000: episode: 12874, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000490, mae: 0.014392, mean_q: 0.022755
 92706/100000: episode: 12875, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000772, mae: 0.013428, mean_q: 0.024722
 92716/100000: episode: 12876, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000612, mae: 0.012346, mean_q: 0.019969
 92726/100000: episode: 12877, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000623, mae: 0.012535, mean_q: 0.021846
 92736/100000: episode: 12878, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000319, mae: 0.010418, mean_q: 0.016158
 92746/100000: episode: 12879, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000961, mae: 0.015845, mean_q: 0.024121
 92756/100000: episode: 12880, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001768, mae: 0.017364, mean_q: 0.017970
 92766/100000: episode: 12881, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000499, mae: 0.017740, mean_q: 0.023057
 92776/100000: episode: 12882, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001366, mae: 0.020145, mean_q: 0.026425
 92786/100000: episode: 12883, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000680, mae: 0.015909, mean_q: 0.021074
 92796/100000: episode: 12884, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000388, mae: 0.014257, mean_q: 0.017091
 92806/100000: episode: 12885, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000199, mae: 0.011426, mean_q: 0.014463
 92816/100000: episode: 12886, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000721, mae: 0.011997, mean_q: 0.016444
 92826/100000: episode: 12887, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000415, mae: 0.013903, mean_q: 0.015438
 92836/100000: episode: 12888, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000994, mae: 0.017371, mean_q: 0.025610
 92846/100000: episode: 12889, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000606, mae: 0.012532, mean_q: 0.018835
 92856/100000: episode: 12890, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000342, mae: 0.012501, mean_q: 0.014321
 92866/100000: episode: 12891, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000570, mae: 0.014455, mean_q: 0.024722
 92876/100000: episode: 12892, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001397, mae: 0.018378, mean_q: 0.026586
 92886/100000: episode: 12893, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000284, mae: 0.013470, mean_q: 0.013259
 92896/100000: episode: 12894, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000152, mae: 0.011190, mean_q: 0.012793
 92906/100000: episode: 12895, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000350, mae: 0.011122, mean_q: 0.014189
 92916/100000: episode: 12896, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000451, mae: 0.014645, mean_q: 0.020698
 92926/100000: episode: 12897, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000468, mae: 0.013458, mean_q: 0.018334
 92936/100000: episode: 12898, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000573, mae: 0.013582, mean_q: 0.020826
 92946/100000: episode: 12899, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000285, mae: 0.010288, mean_q: 0.018244
 92956/100000: episode: 12900, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000739, mae: 0.016842, mean_q: 0.023113
 92966/100000: episode: 12901, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000232, mae: 0.011887, mean_q: 0.015131
 92976/100000: episode: 12902, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000801, mae: 0.017370, mean_q: 0.031585
 92986/100000: episode: 12903, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001236, mae: 0.017572, mean_q: 0.024455
 92996/100000: episode: 12904, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000744, mae: 0.018770, mean_q: 0.018397
 93006/100000: episode: 12905, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000448, mae: 0.012851, mean_q: 0.014575
 93016/100000: episode: 12906, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000323, mae: 0.011291, mean_q: 0.017122
 93026/100000: episode: 12907, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000554, mae: 0.012253, mean_q: 0.018452
 93036/100000: episode: 12908, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000931, mae: 0.019620, mean_q: 0.021442
 93046/100000: episode: 12909, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000751, mae: 0.016996, mean_q: 0.013042
 93056/100000: episode: 12910, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000312, mae: 0.014470, mean_q: 0.014986
 93066/100000: episode: 12911, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000690, mae: 0.013661, mean_q: 0.021594
 93076/100000: episode: 12912, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000936, mae: 0.015894, mean_q: 0.020577
 93086/100000: episode: 12913, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000681, mae: 0.012410, mean_q: 0.015443
 93096/100000: episode: 12914, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000153, mae: 0.010666, mean_q: 0.012856
 93106/100000: episode: 12915, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000877, mae: 0.014379, mean_q: 0.022119
 93116/100000: episode: 12916, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000550, mae: 0.012237, mean_q: 0.020201
 93126/100000: episode: 12917, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000273, mae: 0.010988, mean_q: 0.023801
 93136/100000: episode: 12918, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000402, mae: 0.011400, mean_q: 0.022332
 93146/100000: episode: 12919, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000148, mae: 0.009155, mean_q: 0.016099
 93156/100000: episode: 12920, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000935, mae: 0.014462, mean_q: 0.025974
 93166/100000: episode: 12921, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000816, mae: 0.014797, mean_q: 0.026950
 93176/100000: episode: 12922, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000229, mae: 0.010840, mean_q: 0.013512
 93186/100000: episode: 12923, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000999, mae: 0.018388, mean_q: 0.021825
 93196/100000: episode: 12924, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000370, mae: 0.012160, mean_q: 0.014316
 93206/100000: episode: 12925, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000379, mae: 0.012635, mean_q: 0.016202
 93216/100000: episode: 12926, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000634, mae: 0.013013, mean_q: 0.019936
 93226/100000: episode: 12927, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000987, mae: 0.014657, mean_q: 0.019504
 93236/100000: episode: 12928, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001190, mae: 0.018289, mean_q: 0.028343
 93246/100000: episode: 12929, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001062, mae: 0.017628, mean_q: 0.025604
 93256/100000: episode: 12930, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000418, mae: 0.011803, mean_q: 0.022238
 93266/100000: episode: 12931, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000764, mae: 0.014342, mean_q: 0.018696
 93276/100000: episode: 12932, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000313, mae: 0.010580, mean_q: 0.014489
 93286/100000: episode: 12933, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000457, mae: 0.012219, mean_q: 0.017743
 93296/100000: episode: 12934, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000719, mae: 0.014253, mean_q: 0.021082
 93306/100000: episode: 12935, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000875, mae: 0.013865, mean_q: 0.021993
 93316/100000: episode: 12936, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000397, mae: 0.013321, mean_q: 0.019757
 93326/100000: episode: 12937, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001094, mae: 0.015903, mean_q: 0.027323
 93336/100000: episode: 12938, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000702, mae: 0.017058, mean_q: 0.021472
 93346/100000: episode: 12939, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000557, mae: 0.015344, mean_q: 0.018168
 93356/100000: episode: 12940, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000693, mae: 0.016112, mean_q: 0.022846
 93366/100000: episode: 12941, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000270, mae: 0.010825, mean_q: 0.018129
 93376/100000: episode: 12942, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000253, mae: 0.010168, mean_q: 0.016382
 93386/100000: episode: 12943, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001081, mae: 0.016825, mean_q: 0.022243
 93396/100000: episode: 12944, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000220, mae: 0.012464, mean_q: 0.014697
 93406/100000: episode: 12945, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000337, mae: 0.012375, mean_q: 0.015288
 93416/100000: episode: 12946, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000438, mae: 0.012079, mean_q: 0.016195
 93426/100000: episode: 12947, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000363, mae: 0.009957, mean_q: 0.017369
[Info] 1-TH LEVEL FOUND: 0.027554720640182495, Considering 15/100 traces
 93436/100000: episode: 12948, duration: 0.692s, episode steps: 10, steps per second: 14, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000831, mae: 0.014303, mean_q: 0.019124
 93441/100000: episode: 12949, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000274, mae: 0.011663, mean_q: 0.014048
 93447/100000: episode: 12950, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000393, mae: 0.014607, mean_q: 0.020848
 93453/100000: episode: 12951, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000276, mae: 0.011640, mean_q: 0.017047
 93458/100000: episode: 12952, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000422, mae: 0.010982, mean_q: 0.015539
 93464/100000: episode: 12953, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000898, mae: 0.013290, mean_q: 0.018411
 93470/100000: episode: 12954, duration: 0.029s, episode steps: 6, steps per second: 210, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000598, mae: 0.013393, mean_q: 0.017956
 93476/100000: episode: 12955, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000955, mae: 0.015119, mean_q: 0.023755
 93481/100000: episode: 12956, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000827, mae: 0.012882, mean_q: 0.015087
 93486/100000: episode: 12957, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000178, mae: 0.012533, mean_q: 0.017191
 93491/100000: episode: 12958, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000421, mae: 0.011664, mean_q: 0.012532
 93496/100000: episode: 12959, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001074, mae: 0.018104, mean_q: 0.020991
 93501/100000: episode: 12960, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000356, mae: 0.012738, mean_q: 0.014579
 93506/100000: episode: 12961, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000619, mae: 0.013732, mean_q: 0.019200
 93511/100000: episode: 12962, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000756, mae: 0.013817, mean_q: 0.018366
 93516/100000: episode: 12963, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000755, mae: 0.013884, mean_q: 0.022355
 93521/100000: episode: 12964, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001099, mae: 0.012976, mean_q: 0.020736
 93527/100000: episode: 12965, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000644, mae: 0.012305, mean_q: 0.021397
 93532/100000: episode: 12966, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000995, mae: 0.015418, mean_q: 0.022131
 93537/100000: episode: 12967, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000309, mae: 0.010606, mean_q: 0.013047
 93543/100000: episode: 12968, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000249, mae: 0.011021, mean_q: 0.012078
 93549/100000: episode: 12969, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000477, mae: 0.011872, mean_q: 0.015969
 93554/100000: episode: 12970, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000429, mae: 0.011428, mean_q: 0.016248
 93560/100000: episode: 12971, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000102, mae: 0.008575, mean_q: 0.011202
 93565/100000: episode: 12972, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.001144, mae: 0.015609, mean_q: 0.020932
 93570/100000: episode: 12973, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000110, mae: 0.008576, mean_q: 0.012238
 93575/100000: episode: 12974, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000769, mae: 0.016095, mean_q: 0.020172
 93581/100000: episode: 12975, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000306, mae: 0.011310, mean_q: 0.019295
 93586/100000: episode: 12976, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000797, mae: 0.014992, mean_q: 0.021628
 93592/100000: episode: 12977, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000304, mae: 0.014392, mean_q: 0.017053
 93597/100000: episode: 12978, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000682, mae: 0.018205, mean_q: 0.022210
 93602/100000: episode: 12979, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.001145, mae: 0.018896, mean_q: 0.006511
 93608/100000: episode: 12980, duration: 0.028s, episode steps: 6, steps per second: 211, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000674, mae: 0.014231, mean_q: 0.017191
 93613/100000: episode: 12981, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000361, mae: 0.013140, mean_q: 0.019668
 93618/100000: episode: 12982, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000344, mae: 0.010941, mean_q: 0.015661
 93624/100000: episode: 12983, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001555, mae: 0.016554, mean_q: 0.024543
 93629/100000: episode: 12984, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000390, mae: 0.014457, mean_q: 0.020582
 93634/100000: episode: 12985, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000588, mae: 0.014594, mean_q: 0.025801
 93639/100000: episode: 12986, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000490, mae: 0.012976, mean_q: 0.012589
 93645/100000: episode: 12987, duration: 0.029s, episode steps: 6, steps per second: 210, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001606, mae: 0.017929, mean_q: 0.030366
 93650/100000: episode: 12988, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000169, mae: 0.011933, mean_q: 0.011340
 93656/100000: episode: 12989, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000739, mae: 0.014599, mean_q: 0.019765
 93661/100000: episode: 12990, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000911, mae: 0.014902, mean_q: 0.023303
 93667/100000: episode: 12991, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000171, mae: 0.010211, mean_q: 0.016265
 93672/100000: episode: 12992, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001120, mae: 0.017720, mean_q: 0.033025
 93677/100000: episode: 12993, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000170, mae: 0.007938, mean_q: 0.011992
 93682/100000: episode: 12994, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000408, mae: 0.010133, mean_q: 0.020473
 93687/100000: episode: 12995, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000404, mae: 0.011192, mean_q: 0.018214
 93692/100000: episode: 12996, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000275, mae: 0.009677, mean_q: 0.012469
 93697/100000: episode: 12997, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000215, mae: 0.010481, mean_q: 0.018066
 93702/100000: episode: 12998, duration: 0.024s, episode steps: 5, steps per second: 205, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000574, mae: 0.014343, mean_q: 0.020447
 93707/100000: episode: 12999, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000452, mae: 0.013841, mean_q: 0.021476
 93712/100000: episode: 13000, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000200, mae: 0.012607, mean_q: 0.020290
 93717/100000: episode: 13001, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000287, mae: 0.011345, mean_q: 0.013982
 93722/100000: episode: 13002, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000596, mae: 0.014512, mean_q: 0.024473
 93727/100000: episode: 13003, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000107, mae: 0.009322, mean_q: 0.015960
 93733/100000: episode: 13004, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000628, mae: 0.011970, mean_q: 0.010787
 93738/100000: episode: 13005, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000406, mae: 0.011496, mean_q: 0.018589
 93743/100000: episode: 13006, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000279, mae: 0.009566, mean_q: 0.017322
 93749/100000: episode: 13007, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000572, mae: 0.011988, mean_q: 0.016928
 93754/100000: episode: 13008, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000164, mae: 0.011027, mean_q: 0.015317
 93759/100000: episode: 13009, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000295, mae: 0.010871, mean_q: 0.012893
 93764/100000: episode: 13010, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000116, mae: 0.009506, mean_q: 0.013307
 93769/100000: episode: 13011, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.002902, mae: 0.022351, mean_q: 0.021317
 93774/100000: episode: 13012, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000298, mae: 0.014900, mean_q: 0.010599
 93779/100000: episode: 13013, duration: 0.025s, episode steps: 5, steps per second: 204, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000332, mae: 0.016357, mean_q: 0.008034
 93784/100000: episode: 13014, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000347, mae: 0.016283, mean_q: 0.022275
 93790/100000: episode: 13015, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000249, mae: 0.012824, mean_q: 0.016150
 93795/100000: episode: 13016, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000785, mae: 0.013654, mean_q: 0.018595
 93800/100000: episode: 13017, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000873, mae: 0.016180, mean_q: 0.026323
 93806/100000: episode: 13018, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001144, mae: 0.013044, mean_q: 0.013868
 93811/100000: episode: 13019, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000408, mae: 0.013522, mean_q: 0.011728
 93817/100000: episode: 13020, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000243, mae: 0.011238, mean_q: 0.016924
 93823/100000: episode: 13021, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000332, mae: 0.010933, mean_q: 0.014616
 93828/100000: episode: 13022, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000822, mae: 0.014037, mean_q: 0.019952
 93833/100000: episode: 13023, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000859, mae: 0.014804, mean_q: 0.018670
 93838/100000: episode: 13024, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000143, mae: 0.009454, mean_q: 0.008179
 93843/100000: episode: 13025, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000310, mae: 0.011938, mean_q: 0.012388
 93849/100000: episode: 13026, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000202, mae: 0.010292, mean_q: 0.016036
 93855/100000: episode: 13027, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000232, mae: 0.012193, mean_q: 0.016878
 93860/100000: episode: 13028, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000209, mae: 0.010722, mean_q: 0.012430
 93865/100000: episode: 13029, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000547, mae: 0.013046, mean_q: 0.017678
 93871/100000: episode: 13030, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000361, mae: 0.013318, mean_q: 0.016274
 93876/100000: episode: 13031, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000492, mae: 0.010589, mean_q: 0.014401
 93882/100000: episode: 13032, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001759, mae: 0.017325, mean_q: 0.020805
[Info] 2-TH LEVEL FOUND: 0.09957194328308105, Considering 28/100 traces
 93888/100000: episode: 13033, duration: 0.741s, episode steps: 6, steps per second: 8, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000273, mae: 0.012876, mean_q: 0.012128
 93891/100000: episode: 13034, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000146, mae: 0.008707, mean_q: 0.009582
 93894/100000: episode: 13035, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001198, mae: 0.018347, mean_q: 0.027262
 93897/100000: episode: 13036, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000364, mae: 0.014026, mean_q: 0.020439
 93900/100000: episode: 13037, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000149, mae: 0.010227, mean_q: 0.009173
 93904/100000: episode: 13038, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000421, mae: 0.012318, mean_q: 0.018835
 93907/100000: episode: 13039, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000279, mae: 0.011955, mean_q: 0.014161
 93910/100000: episode: 13040, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001105, mae: 0.019942, mean_q: 0.035486
 93913/100000: episode: 13041, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000140, mae: 0.011633, mean_q: 0.002900
 93916/100000: episode: 13042, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000852, mae: 0.017564, mean_q: 0.028242
 93920/100000: episode: 13043, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000191, mae: 0.011763, mean_q: 0.006635
 93923/100000: episode: 13044, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000998, mae: 0.015866, mean_q: 0.020696
 93926/100000: episode: 13045, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000587, mae: 0.012494, mean_q: 0.012124
 93930/100000: episode: 13046, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000101, mae: 0.009258, mean_q: 0.011980
 93933/100000: episode: 13047, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000172, mae: 0.010540, mean_q: 0.013335
 93937/100000: episode: 13048, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000087, mae: 0.008307, mean_q: 0.011534
 93940/100000: episode: 13049, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000140, mae: 0.010499, mean_q: 0.009228
 93943/100000: episode: 13050, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000624, mae: 0.012742, mean_q: 0.019117
 93946/100000: episode: 13051, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000864, mae: 0.015842, mean_q: 0.024335
 93949/100000: episode: 13052, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000289, mae: 0.009897, mean_q: 0.011211
 93952/100000: episode: 13053, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001875, mae: 0.019023, mean_q: 0.028296
 93955/100000: episode: 13054, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000246, mae: 0.015660, mean_q: 0.015610
 93958/100000: episode: 13055, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000162, mae: 0.010917, mean_q: 0.012137
 93961/100000: episode: 13056, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000256, mae: 0.010668, mean_q: 0.009795
 93964/100000: episode: 13057, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000136, mae: 0.009816, mean_q: 0.007136
 93967/100000: episode: 13058, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000126, mae: 0.010718, mean_q: 0.019162
 93970/100000: episode: 13059, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000114, mae: 0.009518, mean_q: 0.008085
 93974/100000: episode: 13060, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000189, mae: 0.010754, mean_q: 0.021220
 93977/100000: episode: 13061, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000201, mae: 0.011418, mean_q: 0.014315
 93980/100000: episode: 13062, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000183, mae: 0.013215, mean_q: 0.019482
 93984/100000: episode: 13063, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000090, mae: 0.009541, mean_q: 0.006441
 93988/100000: episode: 13064, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000508, mae: 0.015503, mean_q: 0.025899
 93991/100000: episode: 13065, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000492, mae: 0.012503, mean_q: 0.015793
 93994/100000: episode: 13066, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000177, mae: 0.010728, mean_q: 0.015282
 93997/100000: episode: 13067, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000136, mae: 0.009768, mean_q: 0.016698
 94000/100000: episode: 13068, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000652, mae: 0.013929, mean_q: 0.018419
 94003/100000: episode: 13069, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000956, mae: 0.014116, mean_q: 0.019903
 94006/100000: episode: 13070, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000439, mae: 0.011460, mean_q: 0.017875
 94009/100000: episode: 13071, duration: 0.016s, episode steps: 3, steps per second: 188, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000164, mae: 0.011518, mean_q: 0.020365
 94012/100000: episode: 13072, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001193, mae: 0.016165, mean_q: 0.020698
 94015/100000: episode: 13073, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000311, mae: 0.010680, mean_q: 0.016992
 94019/100000: episode: 13074, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000093, mae: 0.007996, mean_q: 0.006290
[Info] FALSIFICATION!
 94022/100000: episode: 13075, duration: 0.169s, episode steps: 3, steps per second: 18, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000857, mae: 0.012878, mean_q: 0.018586
 94025/100000: episode: 13076, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000710, mae: 0.013326, mean_q: 0.012885
 94029/100000: episode: 13077, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000289, mae: 0.011705, mean_q: 0.013401
 94032/100000: episode: 13078, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000675, mae: 0.013445, mean_q: 0.012586
 94035/100000: episode: 13079, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000352, mae: 0.011289, mean_q: 0.016127
 94038/100000: episode: 13080, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000831, mae: 0.014459, mean_q: 0.016115
 94041/100000: episode: 13081, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000082, mae: 0.007039, mean_q: 0.010807
 94045/100000: episode: 13082, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000531, mae: 0.012563, mean_q: 0.023209
 94048/100000: episode: 13083, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000795, mae: 0.013000, mean_q: 0.018141
 94051/100000: episode: 13084, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000142, mae: 0.009272, mean_q: 0.010761
 94054/100000: episode: 13085, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000127, mae: 0.008736, mean_q: 0.015500
 94057/100000: episode: 13086, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000329, mae: 0.010845, mean_q: 0.009250
 94061/100000: episode: 13087, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000344, mae: 0.012152, mean_q: 0.022145
 94064/100000: episode: 13088, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000137, mae: 0.008551, mean_q: 0.011332
 94067/100000: episode: 13089, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000375, mae: 0.012253, mean_q: 0.017557
 94070/100000: episode: 13090, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000680, mae: 0.013349, mean_q: 0.013775
 94073/100000: episode: 13091, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000131, mae: 0.010579, mean_q: 0.015005
 94076/100000: episode: 13092, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000550, mae: 0.011726, mean_q: 0.014445
 94079/100000: episode: 13093, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000140, mae: 0.010049, mean_q: 0.011666
 94082/100000: episode: 13094, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000592, mae: 0.012168, mean_q: 0.027348
 94085/100000: episode: 13095, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000536, mae: 0.012553, mean_q: 0.022166
 94088/100000: episode: 13096, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000137, mae: 0.010900, mean_q: 0.016422
 94091/100000: episode: 13097, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000758, mae: 0.013581, mean_q: 0.016592
 94094/100000: episode: 13098, duration: 0.016s, episode steps: 3, steps per second: 185, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001701, mae: 0.021497, mean_q: 0.041940
 94097/100000: episode: 13099, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000649, mae: 0.009440, mean_q: 0.015723
 94100/100000: episode: 13100, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000139, mae: 0.010408, mean_q: 0.015179
 94104/100000: episode: 13101, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001031, mae: 0.013532, mean_q: 0.019294
 94107/100000: episode: 13102, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000083, mae: 0.007353, mean_q: 0.012900
 94110/100000: episode: 13103, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000339, mae: 0.010835, mean_q: 0.010002
 94113/100000: episode: 13104, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001290, mae: 0.016233, mean_q: 0.021074
[Info] Complete ISplit Iteration
[Info] Levels: [0.02755472, 0.09957194, 1.0205281]
[Info] Cond. Prob: [0.15, 0.28, 0.03]
[Info] Error Prob: 0.00126

 94116/100000: episode: 13105, duration: 0.851s, episode steps: 3, steps per second: 4, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000697, mae: 0.016243, mean_q: 0.026129
 94126/100000: episode: 13106, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000500, mae: 0.014701, mean_q: 0.015803
 94136/100000: episode: 13107, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000429, mae: 0.011167, mean_q: 0.017441
 94146/100000: episode: 13108, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.001134, mae: 0.017034, mean_q: 0.027995
 94156/100000: episode: 13109, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000710, mae: 0.014227, mean_q: 0.019884
 94166/100000: episode: 13110, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001128, mae: 0.019728, mean_q: 0.026726
 94176/100000: episode: 13111, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000366, mae: 0.013433, mean_q: 0.014864
 94186/100000: episode: 13112, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000117, mae: 0.008893, mean_q: 0.014980
 94196/100000: episode: 13113, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001480, mae: 0.012994, mean_q: 0.016287
 94206/100000: episode: 13114, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000311, mae: 0.012785, mean_q: 0.018080
 94216/100000: episode: 13115, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000372, mae: 0.012598, mean_q: 0.013948
 94226/100000: episode: 13116, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001743, mae: 0.017238, mean_q: 0.022737
 94236/100000: episode: 13117, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000283, mae: 0.013862, mean_q: 0.019380
 94246/100000: episode: 13118, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000540, mae: 0.013000, mean_q: 0.019038
 94256/100000: episode: 13119, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000397, mae: 0.009014, mean_q: 0.012011
 94266/100000: episode: 13120, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000334, mae: 0.012260, mean_q: 0.015995
 94276/100000: episode: 13121, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000598, mae: 0.012353, mean_q: 0.021784
 94286/100000: episode: 13122, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000536, mae: 0.012834, mean_q: 0.019703
 94296/100000: episode: 13123, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000664, mae: 0.015574, mean_q: 0.023117
 94306/100000: episode: 13124, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001255, mae: 0.016066, mean_q: 0.025474
 94316/100000: episode: 13125, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000353, mae: 0.011190, mean_q: 0.017990
 94326/100000: episode: 13126, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000713, mae: 0.014939, mean_q: 0.017889
 94336/100000: episode: 13127, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000665, mae: 0.016017, mean_q: 0.020994
 94346/100000: episode: 13128, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000262, mae: 0.011648, mean_q: 0.012517
 94356/100000: episode: 13129, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000453, mae: 0.014371, mean_q: 0.022511
 94366/100000: episode: 13130, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000991, mae: 0.018802, mean_q: 0.032002
 94376/100000: episode: 13131, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001217, mae: 0.022894, mean_q: 0.024155
 94386/100000: episode: 13132, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000501, mae: 0.018616, mean_q: 0.017517
 94396/100000: episode: 13133, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000372, mae: 0.013629, mean_q: 0.018775
 94406/100000: episode: 13134, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001099, mae: 0.016785, mean_q: 0.025533
 94416/100000: episode: 13135, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000436, mae: 0.011761, mean_q: 0.017632
 94426/100000: episode: 13136, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000356, mae: 0.016233, mean_q: 0.016840
 94436/100000: episode: 13137, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000196, mae: 0.011360, mean_q: 0.013213
 94446/100000: episode: 13138, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000842, mae: 0.016091, mean_q: 0.020308
 94456/100000: episode: 13139, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000709, mae: 0.015928, mean_q: 0.019600
 94466/100000: episode: 13140, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000190, mae: 0.011874, mean_q: 0.012803
 94476/100000: episode: 13141, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000904, mae: 0.015358, mean_q: 0.018188
 94486/100000: episode: 13142, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001147, mae: 0.014456, mean_q: 0.019433
 94496/100000: episode: 13143, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000281, mae: 0.011847, mean_q: 0.013540
 94506/100000: episode: 13144, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000599, mae: 0.014620, mean_q: 0.020777
 94516/100000: episode: 13145, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000712, mae: 0.014892, mean_q: 0.020372
 94526/100000: episode: 13146, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000780, mae: 0.014654, mean_q: 0.019115
 94536/100000: episode: 13147, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000370, mae: 0.018204, mean_q: 0.013730
 94546/100000: episode: 13148, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000193, mae: 0.013764, mean_q: 0.014164
 94556/100000: episode: 13149, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000479, mae: 0.014499, mean_q: 0.014046
 94566/100000: episode: 13150, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000401, mae: 0.010747, mean_q: 0.015390
 94576/100000: episode: 13151, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001137, mae: 0.015352, mean_q: 0.018147
 94586/100000: episode: 13152, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000473, mae: 0.018005, mean_q: 0.016521
 94596/100000: episode: 13153, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000611, mae: 0.014831, mean_q: 0.016159
 94606/100000: episode: 13154, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001083, mae: 0.018411, mean_q: 0.022223
 94616/100000: episode: 13155, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001170, mae: 0.018830, mean_q: 0.024111
 94626/100000: episode: 13156, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000307, mae: 0.012206, mean_q: 0.014305
 94636/100000: episode: 13157, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000292, mae: 0.010289, mean_q: 0.012496
 94646/100000: episode: 13158, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000662, mae: 0.011603, mean_q: 0.013371
 94656/100000: episode: 13159, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000519, mae: 0.013094, mean_q: 0.017302
 94666/100000: episode: 13160, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000463, mae: 0.013471, mean_q: 0.017838
 94676/100000: episode: 13161, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000696, mae: 0.018443, mean_q: 0.018019
 94686/100000: episode: 13162, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000462, mae: 0.012314, mean_q: 0.017105
 94696/100000: episode: 13163, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000534, mae: 0.014047, mean_q: 0.019187
 94706/100000: episode: 13164, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000252, mae: 0.011581, mean_q: 0.014301
 94716/100000: episode: 13165, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000255, mae: 0.011680, mean_q: 0.014841
 94726/100000: episode: 13166, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000301, mae: 0.012285, mean_q: 0.015261
 94736/100000: episode: 13167, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000586, mae: 0.014276, mean_q: 0.022258
 94746/100000: episode: 13168, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000742, mae: 0.013030, mean_q: 0.018272
 94756/100000: episode: 13169, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000557, mae: 0.013884, mean_q: 0.017924
 94766/100000: episode: 13170, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000295, mae: 0.011239, mean_q: 0.012591
 94776/100000: episode: 13171, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000266, mae: 0.010752, mean_q: 0.013246
 94786/100000: episode: 13172, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000351, mae: 0.012013, mean_q: 0.017137
 94796/100000: episode: 13173, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000585, mae: 0.012471, mean_q: 0.020165
 94806/100000: episode: 13174, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000382, mae: 0.011896, mean_q: 0.019768
 94816/100000: episode: 13175, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000496, mae: 0.010979, mean_q: 0.018037
 94826/100000: episode: 13176, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000727, mae: 0.012172, mean_q: 0.018602
 94836/100000: episode: 13177, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000814, mae: 0.014682, mean_q: 0.022866
 94846/100000: episode: 13178, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000552, mae: 0.013689, mean_q: 0.017061
 94856/100000: episode: 13179, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000575, mae: 0.011864, mean_q: 0.017735
 94866/100000: episode: 13180, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000381, mae: 0.013418, mean_q: 0.016361
 94876/100000: episode: 13181, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000231, mae: 0.010860, mean_q: 0.019370
 94886/100000: episode: 13182, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000471, mae: 0.011912, mean_q: 0.016920
 94896/100000: episode: 13183, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000400, mae: 0.013004, mean_q: 0.020133
 94906/100000: episode: 13184, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000382, mae: 0.012744, mean_q: 0.022943
 94916/100000: episode: 13185, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000324, mae: 0.010583, mean_q: 0.017718
 94926/100000: episode: 13186, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000717, mae: 0.014305, mean_q: 0.023383
 94936/100000: episode: 13187, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000283, mae: 0.011336, mean_q: 0.015216
 94946/100000: episode: 13188, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001162, mae: 0.016129, mean_q: 0.023884
 94956/100000: episode: 13189, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000514, mae: 0.014275, mean_q: 0.017592
 94966/100000: episode: 13190, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000734, mae: 0.015793, mean_q: 0.024539
 94976/100000: episode: 13191, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000729, mae: 0.013737, mean_q: 0.020144
 94986/100000: episode: 13192, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001293, mae: 0.018277, mean_q: 0.022069
 94996/100000: episode: 13193, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000853, mae: 0.015530, mean_q: 0.017704
 95006/100000: episode: 13194, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000430, mae: 0.013904, mean_q: 0.017075
 95016/100000: episode: 13195, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000517, mae: 0.010944, mean_q: 0.015046
 95026/100000: episode: 13196, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000482, mae: 0.010673, mean_q: 0.015266
 95036/100000: episode: 13197, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000421, mae: 0.010065, mean_q: 0.013928
 95046/100000: episode: 13198, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000362, mae: 0.010923, mean_q: 0.015596
 95056/100000: episode: 13199, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000188, mae: 0.009167, mean_q: 0.014189
 95066/100000: episode: 13200, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000850, mae: 0.013924, mean_q: 0.018924
 95076/100000: episode: 13201, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000467, mae: 0.013533, mean_q: 0.020857
 95086/100000: episode: 13202, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000365, mae: 0.009557, mean_q: 0.014108
 95096/100000: episode: 13203, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000350, mae: 0.011306, mean_q: 0.016551
 95106/100000: episode: 13204, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000191, mae: 0.009853, mean_q: 0.013282
[Info] 1-TH LEVEL FOUND: 0.01870366930961609, Considering 10/100 traces
 95116/100000: episode: 13205, duration: 0.710s, episode steps: 10, steps per second: 14, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000544, mae: 0.012099, mean_q: 0.019861
 95123/100000: episode: 13206, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001031, mae: 0.013413, mean_q: 0.018327
 95130/100000: episode: 13207, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.001221, mae: 0.013801, mean_q: 0.014678
 95137/100000: episode: 13208, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000645, mae: 0.015782, mean_q: 0.013187
 95144/100000: episode: 13209, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.001392, mae: 0.017836, mean_q: 0.025476
 95151/100000: episode: 13210, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000859, mae: 0.016960, mean_q: 0.017579
 95158/100000: episode: 13211, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000271, mae: 0.014252, mean_q: 0.009528
 95164/100000: episode: 13212, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.018, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.583 [-1.000, 11.000], loss: 0.000202, mae: 0.011697, mean_q: 0.013797
 95170/100000: episode: 13213, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000109, mae: 0.007466, mean_q: 0.011599
 95176/100000: episode: 13214, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.034, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000186, mae: 0.011918, mean_q: 0.014981
 95183/100000: episode: 13215, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000843, mae: 0.016090, mean_q: 0.020754
 95189/100000: episode: 13216, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.010, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.417 [-1.000, 11.000], loss: 0.000434, mae: 0.015371, mean_q: 0.016190
 95195/100000: episode: 13217, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001195, mae: 0.015724, mean_q: 0.019968
 95201/100000: episode: 13218, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.023, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000545, mae: 0.016199, mean_q: 0.025269
 95208/100000: episode: 13219, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.100, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000541, mae: 0.013335, mean_q: 0.016252
 95214/100000: episode: 13220, duration: 0.031s, episode steps: 6, steps per second: 197, episode reward: 0.046, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001645, mae: 0.016052, mean_q: 0.017441
 95220/100000: episode: 13221, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000434, mae: 0.015512, mean_q: 0.012441
 95227/100000: episode: 13222, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000625, mae: 0.016152, mean_q: 0.014915
 95234/100000: episode: 13223, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000163, mae: 0.012155, mean_q: 0.013641
 95240/100000: episode: 13224, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000527, mae: 0.014826, mean_q: 0.019358
 95246/100000: episode: 13225, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000120, mae: 0.010223, mean_q: 0.011909
 95253/100000: episode: 13226, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000306, mae: 0.009504, mean_q: 0.009379
 95259/100000: episode: 13227, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000108, mae: 0.009807, mean_q: 0.010941
 95265/100000: episode: 13228, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.023, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000740, mae: 0.014154, mean_q: 0.021937
 95271/100000: episode: 13229, duration: 0.029s, episode steps: 6, steps per second: 210, episode reward: 0.034, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001143, mae: 0.016382, mean_q: 0.018972
 95277/100000: episode: 13230, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000609, mae: 0.013010, mean_q: 0.017829
 95283/100000: episode: 13231, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.077, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000832, mae: 0.018328, mean_q: 0.026524
 95289/100000: episode: 13232, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.077, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000365, mae: 0.011154, mean_q: 0.017459
 95295/100000: episode: 13233, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000357, mae: 0.008770, mean_q: 0.011864
 95301/100000: episode: 13234, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.077, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000749, mae: 0.014763, mean_q: 0.023028
 95308/100000: episode: 13235, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000619, mae: 0.011682, mean_q: 0.018801
 95314/100000: episode: 13236, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.046, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000677, mae: 0.012608, mean_q: 0.018619
 95320/100000: episode: 13237, duration: 0.031s, episode steps: 6, steps per second: 193, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000200, mae: 0.011029, mean_q: 0.019993
 95326/100000: episode: 13238, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.034, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000535, mae: 0.011944, mean_q: 0.015236
 95332/100000: episode: 13239, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000256, mae: 0.011859, mean_q: 0.019286
 95338/100000: episode: 13240, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000368, mae: 0.013284, mean_q: 0.022581
 95345/100000: episode: 13241, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001217, mae: 0.016976, mean_q: 0.024460
 95351/100000: episode: 13242, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000901, mae: 0.021835, mean_q: 0.022744
 95358/100000: episode: 13243, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000389, mae: 0.016807, mean_q: 0.019363
 95364/100000: episode: 13244, duration: 0.029s, episode steps: 6, steps per second: 210, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000211, mae: 0.015259, mean_q: 0.012293
 95370/100000: episode: 13245, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001353, mae: 0.012818, mean_q: 0.013798
 95376/100000: episode: 13246, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.018, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.583 [-1.000, 11.000], loss: 0.000434, mae: 0.014070, mean_q: 0.020143
 95383/100000: episode: 13247, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000610, mae: 0.013801, mean_q: 0.018939
 95389/100000: episode: 13248, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.077, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001199, mae: 0.014969, mean_q: 0.022840
 95396/100000: episode: 13249, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000921, mae: 0.016295, mean_q: 0.023103
 95402/100000: episode: 13250, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.018, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.583 [-1.000, 11.000], loss: 0.000826, mae: 0.017989, mean_q: 0.025666
 95408/100000: episode: 13251, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000425, mae: 0.013480, mean_q: 0.017756
 95415/100000: episode: 13252, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000367, mae: 0.012631, mean_q: 0.015679
 95421/100000: episode: 13253, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000314, mae: 0.009743, mean_q: 0.015254
 95428/100000: episode: 13254, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000941, mae: 0.015073, mean_q: 0.027143
 95434/100000: episode: 13255, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001615, mae: 0.019265, mean_q: 0.025713
 95441/100000: episode: 13256, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000266, mae: 0.011739, mean_q: 0.016191
 95447/100000: episode: 13257, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000127, mae: 0.010472, mean_q: 0.012221
 95453/100000: episode: 13258, duration: 0.032s, episode steps: 6, steps per second: 189, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.001238, mae: 0.013670, mean_q: 0.017831
[Info] FALSIFICATION!
 95459/100000: episode: 13259, duration: 0.263s, episode steps: 6, steps per second: 23, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000610, mae: 0.014607, mean_q: 0.023393
 95465/100000: episode: 13260, duration: 0.033s, episode steps: 6, steps per second: 181, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000488, mae: 0.014117, mean_q: 0.023099
 95471/100000: episode: 13261, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.077, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000895, mae: 0.014849, mean_q: 0.021460
 95477/100000: episode: 13262, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000651, mae: 0.013795, mean_q: 0.019926
 95483/100000: episode: 13263, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000707, mae: 0.014966, mean_q: 0.017429
 95489/100000: episode: 13264, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.030, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001252, mae: 0.016977, mean_q: 0.023337
 95496/100000: episode: 13265, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000579, mae: 0.015183, mean_q: 0.020730
 95503/100000: episode: 13266, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001017, mae: 0.019007, mean_q: 0.023791
 95509/100000: episode: 13267, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000498, mae: 0.012970, mean_q: 0.020381
 95515/100000: episode: 13268, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001067, mae: 0.010690, mean_q: 0.013981
 95521/100000: episode: 13269, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000393, mae: 0.013958, mean_q: 0.016160
 95527/100000: episode: 13270, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000186, mae: 0.012134, mean_q: 0.017336
 95534/100000: episode: 13271, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000322, mae: 0.010478, mean_q: 0.012923
 95540/100000: episode: 13272, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000903, mae: 0.016411, mean_q: 0.023418
 95547/100000: episode: 13273, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000384, mae: 0.015552, mean_q: 0.019760
 95553/100000: episode: 13274, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001471, mae: 0.018825, mean_q: 0.019713
 95559/100000: episode: 13275, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.010, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.417 [-1.000, 11.000], loss: 0.000714, mae: 0.018583, mean_q: 0.012084
 95565/100000: episode: 13276, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000202, mae: 0.013439, mean_q: 0.015531
 95572/100000: episode: 13277, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000309, mae: 0.011342, mean_q: 0.017498
 95578/100000: episode: 13278, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000371, mae: 0.011683, mean_q: 0.016273
 95584/100000: episode: 13279, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000113, mae: 0.008771, mean_q: 0.014106
 95590/100000: episode: 13280, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.010, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.417 [-1.000, 11.000], loss: 0.000109, mae: 0.008410, mean_q: 0.012084
 95596/100000: episode: 13281, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000132, mae: 0.008429, mean_q: 0.011523
 95602/100000: episode: 13282, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000115, mae: 0.008701, mean_q: 0.012465
 95608/100000: episode: 13283, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.034, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000379, mae: 0.012678, mean_q: 0.021891
 95614/100000: episode: 13284, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000511, mae: 0.013671, mean_q: 0.016114
 95620/100000: episode: 13285, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000867, mae: 0.014723, mean_q: 0.017377
 95626/100000: episode: 13286, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.018, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.583 [-1.000, 11.000], loss: 0.000309, mae: 0.014724, mean_q: 0.017912
 95632/100000: episode: 13287, duration: 0.029s, episode steps: 6, steps per second: 203, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000338, mae: 0.011862, mean_q: 0.019321
 95638/100000: episode: 13288, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000223, mae: 0.011795, mean_q: 0.009489
[Info] FALSIFICATION!
 95644/100000: episode: 13289, duration: 0.262s, episode steps: 6, steps per second: 23, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000496, mae: 0.014350, mean_q: 0.016566
 95650/100000: episode: 13290, duration: 0.033s, episode steps: 6, steps per second: 183, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001556, mae: 0.017728, mean_q: 0.027616
 95656/100000: episode: 13291, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000155, mae: 0.010469, mean_q: 0.016273
 95662/100000: episode: 13292, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.001608, mae: 0.020493, mean_q: 0.030644
 95668/100000: episode: 13293, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.023, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000205, mae: 0.013505, mean_q: 0.013624
 95674/100000: episode: 13294, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000425, mae: 0.013257, mean_q: 0.013700
[Info] Complete ISplit Iteration
[Info] Levels: [0.01870367, 1.0646282]
[Info] Cond. Prob: [0.1, 0.02]
[Info] Error Prob: 0.002

 95680/100000: episode: 13295, duration: 0.831s, episode steps: 6, steps per second: 7, episode reward: 0.023, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.001054, mae: 0.016516, mean_q: 0.023235
 95690/100000: episode: 13296, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000707, mae: 0.015648, mean_q: 0.020949
 95700/100000: episode: 13297, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000161, mae: 0.011691, mean_q: 0.013893
 95710/100000: episode: 13298, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000650, mae: 0.014104, mean_q: 0.024198
 95720/100000: episode: 13299, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000594, mae: 0.014317, mean_q: 0.023437
 95730/100000: episode: 13300, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000373, mae: 0.012240, mean_q: 0.017849
 95740/100000: episode: 13301, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000446, mae: 0.013778, mean_q: 0.024860
 95750/100000: episode: 13302, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000318, mae: 0.011664, mean_q: 0.018522
 95760/100000: episode: 13303, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000656, mae: 0.014048, mean_q: 0.026140
 95770/100000: episode: 13304, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000565, mae: 0.010095, mean_q: 0.017352
 95780/100000: episode: 13305, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000187, mae: 0.008964, mean_q: 0.011262
 95790/100000: episode: 13306, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000866, mae: 0.014933, mean_q: 0.022009
 95800/100000: episode: 13307, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000620, mae: 0.012527, mean_q: 0.018307
 95810/100000: episode: 13308, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000331, mae: 0.011566, mean_q: 0.021429
 95820/100000: episode: 13309, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000590, mae: 0.013220, mean_q: 0.020784
 95830/100000: episode: 13310, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000211, mae: 0.011055, mean_q: 0.014172
 95840/100000: episode: 13311, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000368, mae: 0.011039, mean_q: 0.015167
 95850/100000: episode: 13312, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000253, mae: 0.010056, mean_q: 0.016620
 95860/100000: episode: 13313, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000921, mae: 0.015480, mean_q: 0.022472
 95870/100000: episode: 13314, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000231, mae: 0.010672, mean_q: 0.013431
 95880/100000: episode: 13315, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000432, mae: 0.012058, mean_q: 0.017639
 95890/100000: episode: 13316, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000563, mae: 0.012172, mean_q: 0.018109
 95900/100000: episode: 13317, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000658, mae: 0.012254, mean_q: 0.018880
 95910/100000: episode: 13318, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000747, mae: 0.014331, mean_q: 0.021037
 95920/100000: episode: 13319, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001137, mae: 0.015167, mean_q: 0.019637
 95930/100000: episode: 13320, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000655, mae: 0.016422, mean_q: 0.019513
 95940/100000: episode: 13321, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000358, mae: 0.012440, mean_q: 0.015826
 95950/100000: episode: 13322, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000177, mae: 0.009644, mean_q: 0.015339
 95960/100000: episode: 13323, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000918, mae: 0.016070, mean_q: 0.026183
 95970/100000: episode: 13324, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000345, mae: 0.013871, mean_q: 0.018345
 95980/100000: episode: 13325, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000668, mae: 0.012921, mean_q: 0.019545
 95990/100000: episode: 13326, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000666, mae: 0.013401, mean_q: 0.024011
 96000/100000: episode: 13327, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000552, mae: 0.011677, mean_q: 0.016429
 96010/100000: episode: 13328, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000457, mae: 0.010744, mean_q: 0.014758
 96020/100000: episode: 13329, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000189, mae: 0.008921, mean_q: 0.013964
 96030/100000: episode: 13330, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001814, mae: 0.023278, mean_q: 0.030492
 96040/100000: episode: 13331, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002138, mae: 0.026266, mean_q: 0.022123
 96050/100000: episode: 13332, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000633, mae: 0.021904, mean_q: 0.019079
 96060/100000: episode: 13333, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000304, mae: 0.013727, mean_q: 0.014292
 96070/100000: episode: 13334, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000670, mae: 0.013119, mean_q: 0.014458
 96080/100000: episode: 13335, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000432, mae: 0.010369, mean_q: 0.015891
 96090/100000: episode: 13336, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001266, mae: 0.015268, mean_q: 0.022659
 96100/100000: episode: 13337, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001023, mae: 0.017950, mean_q: 0.026859
 96110/100000: episode: 13338, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000346, mae: 0.014792, mean_q: 0.019083
 96120/100000: episode: 13339, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000408, mae: 0.012698, mean_q: 0.018000
 96130/100000: episode: 13340, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000185, mae: 0.009798, mean_q: 0.015277
 96140/100000: episode: 13341, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000833, mae: 0.014264, mean_q: 0.020281
 96150/100000: episode: 13342, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000221, mae: 0.013833, mean_q: 0.016152
 96160/100000: episode: 13343, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000268, mae: 0.013503, mean_q: 0.015791
 96170/100000: episode: 13344, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001151, mae: 0.020462, mean_q: 0.028556
 96180/100000: episode: 13345, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001235, mae: 0.016985, mean_q: 0.018306
 96190/100000: episode: 13346, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000552, mae: 0.017512, mean_q: 0.017341
 96200/100000: episode: 13347, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000367, mae: 0.012967, mean_q: 0.017216
 96210/100000: episode: 13348, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000225, mae: 0.010421, mean_q: 0.014936
 96220/100000: episode: 13349, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000359, mae: 0.011156, mean_q: 0.017885
 96230/100000: episode: 13350, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000875, mae: 0.012284, mean_q: 0.018987
 96240/100000: episode: 13351, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000537, mae: 0.013474, mean_q: 0.017938
 96250/100000: episode: 13352, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000580, mae: 0.013230, mean_q: 0.018802
 96260/100000: episode: 13353, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001466, mae: 0.016855, mean_q: 0.025492
 96270/100000: episode: 13354, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000423, mae: 0.015738, mean_q: 0.020733
 96280/100000: episode: 13355, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000703, mae: 0.016582, mean_q: 0.022866
 96290/100000: episode: 13356, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000347, mae: 0.014428, mean_q: 0.014586
 96300/100000: episode: 13357, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000132, mae: 0.010209, mean_q: 0.012156
 96310/100000: episode: 13358, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000297, mae: 0.011378, mean_q: 0.018276
 96320/100000: episode: 13359, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000459, mae: 0.012018, mean_q: 0.018214
 96330/100000: episode: 13360, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000653, mae: 0.012615, mean_q: 0.020738
 96340/100000: episode: 13361, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000312, mae: 0.011340, mean_q: 0.016476
 96350/100000: episode: 13362, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000764, mae: 0.014416, mean_q: 0.027536
 96360/100000: episode: 13363, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000733, mae: 0.013380, mean_q: 0.020171
 96370/100000: episode: 13364, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000529, mae: 0.011926, mean_q: 0.015275
 96380/100000: episode: 13365, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000464, mae: 0.011964, mean_q: 0.015926
 96390/100000: episode: 13366, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000619, mae: 0.013927, mean_q: 0.017998
 96400/100000: episode: 13367, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000211, mae: 0.009760, mean_q: 0.010518
 96410/100000: episode: 13368, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000546, mae: 0.012448, mean_q: 0.017419
 96420/100000: episode: 13369, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000992, mae: 0.012650, mean_q: 0.018548
 96430/100000: episode: 13370, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000708, mae: 0.012025, mean_q: 0.017097
 96440/100000: episode: 13371, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000512, mae: 0.011469, mean_q: 0.016757
 96450/100000: episode: 13372, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000111, mae: 0.008194, mean_q: 0.010102
 96460/100000: episode: 13373, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000384, mae: 0.010325, mean_q: 0.015866
 96470/100000: episode: 13374, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000544, mae: 0.010766, mean_q: 0.017605
 96480/100000: episode: 13375, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000814, mae: 0.011594, mean_q: 0.017622
 96490/100000: episode: 13376, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000653, mae: 0.015454, mean_q: 0.017931
 96500/100000: episode: 13377, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000586, mae: 0.014936, mean_q: 0.017658
 96510/100000: episode: 13378, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000838, mae: 0.018308, mean_q: 0.020117
 96520/100000: episode: 13379, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000401, mae: 0.012282, mean_q: 0.014041
 96530/100000: episode: 13380, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000607, mae: 0.015072, mean_q: 0.021274
 96540/100000: episode: 13381, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000759, mae: 0.012464, mean_q: 0.016798
 96550/100000: episode: 13382, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000210, mae: 0.010520, mean_q: 0.014869
 96560/100000: episode: 13383, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000939, mae: 0.011719, mean_q: 0.015575
 96570/100000: episode: 13384, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000418, mae: 0.014307, mean_q: 0.019826
 96580/100000: episode: 13385, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000311, mae: 0.009891, mean_q: 0.014191
 96590/100000: episode: 13386, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000807, mae: 0.012945, mean_q: 0.019217
 96600/100000: episode: 13387, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000446, mae: 0.012492, mean_q: 0.015150
 96610/100000: episode: 13388, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000368, mae: 0.012276, mean_q: 0.015661
 96620/100000: episode: 13389, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000280, mae: 0.010673, mean_q: 0.018869
 96630/100000: episode: 13390, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000190, mae: 0.009052, mean_q: 0.016962
 96640/100000: episode: 13391, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000975, mae: 0.012504, mean_q: 0.018435
 96650/100000: episode: 13392, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000598, mae: 0.014603, mean_q: 0.016063
 96660/100000: episode: 13393, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000484, mae: 0.016310, mean_q: 0.019870
 96670/100000: episode: 13394, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000567, mae: 0.013355, mean_q: 0.018902
[Info] 1-TH LEVEL FOUND: 0.03245013952255249, Considering 12/100 traces
 96680/100000: episode: 13395, duration: 0.666s, episode steps: 10, steps per second: 15, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000665, mae: 0.011553, mean_q: 0.017431
 96685/100000: episode: 13396, duration: 0.034s, episode steps: 5, steps per second: 148, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000139, mae: 0.011073, mean_q: 0.010551
 96690/100000: episode: 13397, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.001050, mae: 0.013707, mean_q: 0.017230
 96695/100000: episode: 13398, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000306, mae: 0.012139, mean_q: 0.014262
 96700/100000: episode: 13399, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000069, mae: 0.007490, mean_q: 0.009947
 96705/100000: episode: 13400, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000995, mae: 0.016970, mean_q: 0.022601
 96710/100000: episode: 13401, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000638, mae: 0.010104, mean_q: 0.014955
 96715/100000: episode: 13402, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000535, mae: 0.010598, mean_q: 0.014692
 96720/100000: episode: 13403, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000191, mae: 0.010516, mean_q: 0.015135
 96726/100000: episode: 13404, duration: 0.031s, episode steps: 6, steps per second: 192, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000657, mae: 0.012300, mean_q: 0.016237
 96731/100000: episode: 13405, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000259, mae: 0.009196, mean_q: 0.013063
 96736/100000: episode: 13406, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000183, mae: 0.009049, mean_q: 0.012674
 96741/100000: episode: 13407, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000291, mae: 0.010534, mean_q: 0.022626
 96746/100000: episode: 13408, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000327, mae: 0.010815, mean_q: 0.011556
 96751/100000: episode: 13409, duration: 0.028s, episode steps: 5, steps per second: 182, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000253, mae: 0.010069, mean_q: 0.014023
 96756/100000: episode: 13410, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000280, mae: 0.010368, mean_q: 0.013478
 96761/100000: episode: 13411, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000710, mae: 0.011501, mean_q: 0.018379
 96766/100000: episode: 13412, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000737, mae: 0.012881, mean_q: 0.028853
 96771/100000: episode: 13413, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000378, mae: 0.010619, mean_q: 0.024953
 96776/100000: episode: 13414, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001339, mae: 0.016337, mean_q: 0.024822
 96781/100000: episode: 13415, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000274, mae: 0.010477, mean_q: 0.016870
 96786/100000: episode: 13416, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000085, mae: 0.006857, mean_q: 0.009833
 96791/100000: episode: 13417, duration: 0.044s, episode steps: 5, steps per second: 115, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000440, mae: 0.011226, mean_q: 0.018988
 96796/100000: episode: 13418, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000351, mae: 0.008651, mean_q: 0.011204
 96801/100000: episode: 13419, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000155, mae: 0.010167, mean_q: 0.015736
 96806/100000: episode: 13420, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001637, mae: 0.017285, mean_q: 0.023756
 96812/100000: episode: 13421, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000652, mae: 0.014391, mean_q: 0.015160
 96817/100000: episode: 13422, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000351, mae: 0.013700, mean_q: 0.017430
 96822/100000: episode: 13423, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000183, mae: 0.009948, mean_q: 0.009905
 96827/100000: episode: 13424, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000384, mae: 0.011982, mean_q: 0.020893
 96832/100000: episode: 13425, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000536, mae: 0.011092, mean_q: 0.015332
 96837/100000: episode: 13426, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000456, mae: 0.009621, mean_q: 0.015321
 96842/100000: episode: 13427, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000190, mae: 0.011403, mean_q: 0.014813
 96847/100000: episode: 13428, duration: 0.031s, episode steps: 5, steps per second: 162, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000254, mae: 0.009989, mean_q: 0.012395
 96852/100000: episode: 13429, duration: 0.029s, episode steps: 5, steps per second: 174, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000293, mae: 0.011757, mean_q: 0.021664
 96857/100000: episode: 13430, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000291, mae: 0.009871, mean_q: 0.010701
 96862/100000: episode: 13431, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000578, mae: 0.012472, mean_q: 0.020652
 96867/100000: episode: 13432, duration: 0.028s, episode steps: 5, steps per second: 176, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000209, mae: 0.010892, mean_q: 0.008358
 96872/100000: episode: 13433, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000303, mae: 0.010720, mean_q: 0.017471
 96877/100000: episode: 13434, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000085, mae: 0.007675, mean_q: 0.011155
 96882/100000: episode: 13435, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000657, mae: 0.012611, mean_q: 0.018332
 96887/100000: episode: 13436, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001131, mae: 0.015867, mean_q: 0.023361
 96892/100000: episode: 13437, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.001289, mae: 0.012713, mean_q: 0.018894
 96897/100000: episode: 13438, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000595, mae: 0.010734, mean_q: 0.012453
 96902/100000: episode: 13439, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000472, mae: 0.010408, mean_q: 0.013651
 96908/100000: episode: 13440, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000799, mae: 0.014312, mean_q: 0.021615
 96913/100000: episode: 13441, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000318, mae: 0.011367, mean_q: 0.012360
 96918/100000: episode: 13442, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000267, mae: 0.010887, mean_q: 0.014867
 96923/100000: episode: 13443, duration: 0.030s, episode steps: 5, steps per second: 166, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000391, mae: 0.010033, mean_q: 0.018202
 96928/100000: episode: 13444, duration: 0.037s, episode steps: 5, steps per second: 133, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000096, mae: 0.008987, mean_q: 0.011545
 96933/100000: episode: 13445, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000237, mae: 0.010401, mean_q: 0.016520
 96938/100000: episode: 13446, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000239, mae: 0.009875, mean_q: 0.014258
 96943/100000: episode: 13447, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000140, mae: 0.010599, mean_q: 0.018366
 96948/100000: episode: 13448, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000706, mae: 0.009594, mean_q: 0.015621
 96953/100000: episode: 13449, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000160, mae: 0.008040, mean_q: 0.010311
 96958/100000: episode: 13450, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000602, mae: 0.013444, mean_q: 0.026192
 96963/100000: episode: 13451, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001215, mae: 0.014462, mean_q: 0.021045
 96968/100000: episode: 13452, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000223, mae: 0.010110, mean_q: 0.016010
 96973/100000: episode: 13453, duration: 0.027s, episode steps: 5, steps per second: 189, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000269, mae: 0.008804, mean_q: 0.014415
 96978/100000: episode: 13454, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000451, mae: 0.010157, mean_q: 0.015713
 96983/100000: episode: 13455, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000234, mae: 0.009124, mean_q: 0.014910
 96988/100000: episode: 13456, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000612, mae: 0.011333, mean_q: 0.018088
 96993/100000: episode: 13457, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000065, mae: 0.006816, mean_q: 0.010875
 96999/100000: episode: 13458, duration: 0.031s, episode steps: 6, steps per second: 196, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000716, mae: 0.013499, mean_q: 0.021541
 97004/100000: episode: 13459, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000081, mae: 0.007069, mean_q: 0.010080
 97009/100000: episode: 13460, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000115, mae: 0.007554, mean_q: 0.013132
 97014/100000: episode: 13461, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000106, mae: 0.008406, mean_q: 0.013190
 97019/100000: episode: 13462, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000395, mae: 0.009200, mean_q: 0.013127
 97024/100000: episode: 13463, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000104, mae: 0.008358, mean_q: 0.014282
 97030/100000: episode: 13464, duration: 0.032s, episode steps: 6, steps per second: 189, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000312, mae: 0.009890, mean_q: 0.017823
 97035/100000: episode: 13465, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000220, mae: 0.010154, mean_q: 0.017609
 97040/100000: episode: 13466, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000459, mae: 0.009387, mean_q: 0.012976
 97045/100000: episode: 13467, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000187, mae: 0.008605, mean_q: 0.013778
 97050/100000: episode: 13468, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000085, mae: 0.007492, mean_q: 0.010811
 97055/100000: episode: 13469, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000336, mae: 0.009979, mean_q: 0.010819
 97060/100000: episode: 13470, duration: 0.028s, episode steps: 5, steps per second: 176, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000084, mae: 0.007895, mean_q: 0.011289
 97065/100000: episode: 13471, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000078, mae: 0.007301, mean_q: 0.011050
 97070/100000: episode: 13472, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000547, mae: 0.010066, mean_q: 0.015506
 97075/100000: episode: 13473, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000244, mae: 0.010727, mean_q: 0.015714
 97080/100000: episode: 13474, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000114, mae: 0.008576, mean_q: 0.014058
 97085/100000: episode: 13475, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000157, mae: 0.010615, mean_q: 0.017464
 97090/100000: episode: 13476, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000075, mae: 0.007365, mean_q: 0.009539
 97095/100000: episode: 13477, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000380, mae: 0.010061, mean_q: 0.013388
 97100/100000: episode: 13478, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000482, mae: 0.012416, mean_q: 0.017808
 97105/100000: episode: 13479, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001415, mae: 0.015302, mean_q: 0.021955
 97110/100000: episode: 13480, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000440, mae: 0.010394, mean_q: 0.014147
 97115/100000: episode: 13481, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000452, mae: 0.015013, mean_q: 0.013292
 97120/100000: episode: 13482, duration: 0.034s, episode steps: 5, steps per second: 146, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000196, mae: 0.010933, mean_q: 0.016617
[Info] 2-TH LEVEL FOUND: 0.0977695882320404, Considering 29/100 traces
 97125/100000: episode: 13483, duration: 0.685s, episode steps: 5, steps per second: 7, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000131, mae: 0.010498, mean_q: 0.015720
 97128/100000: episode: 13484, duration: 0.021s, episode steps: 3, steps per second: 141, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001292, mae: 0.016612, mean_q: 0.020369
 97131/100000: episode: 13485, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000194, mae: 0.010617, mean_q: 0.017342
[Info] FALSIFICATION!
 97135/100000: episode: 13486, duration: 0.268s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000345, mae: 0.011870, mean_q: 0.017691
 97138/100000: episode: 13487, duration: 0.021s, episode steps: 3, steps per second: 144, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000116, mae: 0.008769, mean_q: 0.013967
 97141/100000: episode: 13488, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000241, mae: 0.010295, mean_q: 0.020205
 97144/100000: episode: 13489, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001482, mae: 0.017807, mean_q: 0.023184
 97147/100000: episode: 13490, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001234, mae: 0.014374, mean_q: 0.023239
 97150/100000: episode: 13491, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000161, mae: 0.007512, mean_q: 0.010241
 97153/100000: episode: 13492, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000081, mae: 0.006971, mean_q: 0.010018
 97156/100000: episode: 13493, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001188, mae: 0.014550, mean_q: 0.020189
 97159/100000: episode: 13494, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000421, mae: 0.010411, mean_q: 0.014893
 97162/100000: episode: 13495, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000892, mae: 0.014412, mean_q: 0.014052
 97167/100000: episode: 13496, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000119, mae: 0.011382, mean_q: 0.013952
 97170/100000: episode: 13497, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000686, mae: 0.012458, mean_q: 0.022893
 97173/100000: episode: 13498, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000142, mae: 0.010557, mean_q: 0.015917
 97176/100000: episode: 13499, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000101, mae: 0.008750, mean_q: 0.013064
 97179/100000: episode: 13500, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000079, mae: 0.007259, mean_q: 0.012698
 97182/100000: episode: 13501, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000147, mae: 0.009873, mean_q: 0.014758
 97185/100000: episode: 13502, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000273, mae: 0.011696, mean_q: 0.019816
 97188/100000: episode: 13503, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000183, mae: 0.011655, mean_q: 0.015978
 97191/100000: episode: 13504, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000673, mae: 0.010939, mean_q: 0.017603
 97194/100000: episode: 13505, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000632, mae: 0.011139, mean_q: 0.016438
 97197/100000: episode: 13506, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000364, mae: 0.009501, mean_q: 0.013004
 97200/100000: episode: 13507, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000949, mae: 0.016036, mean_q: 0.023951
 97203/100000: episode: 13508, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000269, mae: 0.009047, mean_q: 0.014415
 97206/100000: episode: 13509, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000292, mae: 0.009277, mean_q: 0.013597
 97211/100000: episode: 13510, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000542, mae: 0.010751, mean_q: 0.017449
 97214/100000: episode: 13511, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000196, mae: 0.009061, mean_q: 0.016832
 97217/100000: episode: 13512, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000191, mae: 0.009087, mean_q: 0.014120
 97220/100000: episode: 13513, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001171, mae: 0.016277, mean_q: 0.024429
 97223/100000: episode: 13514, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000905, mae: 0.012118, mean_q: 0.012891
 97226/100000: episode: 13515, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000097, mae: 0.008650, mean_q: 0.017175
 97229/100000: episode: 13516, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000146, mae: 0.010189, mean_q: 0.016425
 97232/100000: episode: 13517, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000077, mae: 0.007595, mean_q: 0.012064
 97235/100000: episode: 13518, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000204, mae: 0.010933, mean_q: 0.024489
 97238/100000: episode: 13519, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000543, mae: 0.010503, mean_q: 0.013832
 97241/100000: episode: 13520, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000105, mae: 0.009066, mean_q: 0.015983
 97244/100000: episode: 13521, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000090, mae: 0.006863, mean_q: 0.009785
 97247/100000: episode: 13522, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000259, mae: 0.010402, mean_q: 0.014870
[Info] FALSIFICATION!
 97251/100000: episode: 13523, duration: 0.269s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000512, mae: 0.010405, mean_q: 0.015358
 97254/100000: episode: 13524, duration: 0.020s, episode steps: 3, steps per second: 150, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000139, mae: 0.011079, mean_q: 0.018300
[Info] FALSIFICATION!
 97258/100000: episode: 13525, duration: 0.270s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000279, mae: 0.012481, mean_q: 0.019898
 97261/100000: episode: 13526, duration: 0.019s, episode steps: 3, steps per second: 154, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000466, mae: 0.012704, mean_q: 0.021903
 97264/100000: episode: 13527, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000088, mae: 0.007831, mean_q: 0.015076
 97269/100000: episode: 13528, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000256, mae: 0.010171, mean_q: 0.018364
 97272/100000: episode: 13529, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000316, mae: 0.011843, mean_q: 0.019023
 97275/100000: episode: 13530, duration: 0.018s, episode steps: 3, steps per second: 162, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000382, mae: 0.009172, mean_q: 0.017449
 97278/100000: episode: 13531, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000800, mae: 0.013759, mean_q: 0.031802
 97281/100000: episode: 13532, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000342, mae: 0.012254, mean_q: 0.023028
 97284/100000: episode: 13533, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000383, mae: 0.012108, mean_q: 0.026374
 97287/100000: episode: 13534, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000176, mae: 0.010832, mean_q: 0.017395
 97290/100000: episode: 13535, duration: 0.016s, episode steps: 3, steps per second: 183, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001703, mae: 0.018421, mean_q: 0.035961
 97293/100000: episode: 13536, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000096, mae: 0.007454, mean_q: 0.009670
 97296/100000: episode: 13537, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000133, mae: 0.009848, mean_q: 0.018788
 97299/100000: episode: 13538, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000213, mae: 0.012594, mean_q: 0.008104
 97302/100000: episode: 13539, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002342, mae: 0.024792, mean_q: 0.031564
 97305/100000: episode: 13540, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001422, mae: 0.022194, mean_q: 0.021091
 97308/100000: episode: 13541, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000181, mae: 0.012583, mean_q: 0.017700
 97311/100000: episode: 13542, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000235, mae: 0.013251, mean_q: 0.019443
 97314/100000: episode: 13543, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000227, mae: 0.009466, mean_q: 0.015107
 97317/100000: episode: 13544, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001509, mae: 0.020235, mean_q: 0.029359
 97320/100000: episode: 13545, duration: 0.021s, episode steps: 3, steps per second: 140, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000600, mae: 0.014963, mean_q: 0.023291
 97323/100000: episode: 13546, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000550, mae: 0.013636, mean_q: 0.014490
 97326/100000: episode: 13547, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000138, mae: 0.011541, mean_q: 0.021821
 97329/100000: episode: 13548, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000341, mae: 0.014380, mean_q: 0.023854
 97332/100000: episode: 13549, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001261, mae: 0.019163, mean_q: 0.028134
 97335/100000: episode: 13550, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000102, mae: 0.008772, mean_q: 0.011967
 97338/100000: episode: 13551, duration: 0.021s, episode steps: 3, steps per second: 145, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000101, mae: 0.009615, mean_q: 0.016895
 97343/100000: episode: 13552, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.002107, mae: 0.017667, mean_q: 0.023296
 97346/100000: episode: 13553, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001089, mae: 0.015029, mean_q: 0.023459
[Info] Complete ISplit Iteration
[Info] Levels: [0.03245014, 0.09776959, 1.1498344]
[Info] Cond. Prob: [0.12, 0.29, 0.03]
[Info] Error Prob: 0.0010439999999999998

 97349/100000: episode: 13554, duration: 0.884s, episode steps: 3, steps per second: 3, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000687, mae: 0.015489, mean_q: 0.021134
 97359/100000: episode: 13555, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000425, mae: 0.014971, mean_q: 0.024595
 97369/100000: episode: 13556, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000251, mae: 0.012197, mean_q: 0.016308
 97379/100000: episode: 13557, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000242, mae: 0.010108, mean_q: 0.018493
 97389/100000: episode: 13558, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000696, mae: 0.013370, mean_q: 0.023104
 97399/100000: episode: 13559, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001006, mae: 0.013307, mean_q: 0.021557
 97409/100000: episode: 13560, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000955, mae: 0.014737, mean_q: 0.020687
 97419/100000: episode: 13561, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000696, mae: 0.014496, mean_q: 0.018590
 97429/100000: episode: 13562, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000537, mae: 0.011795, mean_q: 0.017459
 97439/100000: episode: 13563, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000225, mae: 0.011791, mean_q: 0.018677
 97449/100000: episode: 13564, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000494, mae: 0.012210, mean_q: 0.021100
 97459/100000: episode: 13565, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000146, mae: 0.010192, mean_q: 0.015283
 97469/100000: episode: 13566, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000232, mae: 0.009938, mean_q: 0.015622
 97479/100000: episode: 13567, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000566, mae: 0.010943, mean_q: 0.017800
 97489/100000: episode: 13568, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000248, mae: 0.013107, mean_q: 0.015899
 97499/100000: episode: 13569, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000346, mae: 0.013286, mean_q: 0.021364
 97509/100000: episode: 13570, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000310, mae: 0.012012, mean_q: 0.016680
 97519/100000: episode: 13571, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000166, mae: 0.009101, mean_q: 0.017013
 97529/100000: episode: 13572, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000529, mae: 0.011723, mean_q: 0.020561
 97539/100000: episode: 13573, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000702, mae: 0.014489, mean_q: 0.018047
 97549/100000: episode: 13574, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000805, mae: 0.015137, mean_q: 0.029024
 97559/100000: episode: 13575, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000210, mae: 0.011039, mean_q: 0.017095
 97569/100000: episode: 13576, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000525, mae: 0.012218, mean_q: 0.022469
 97579/100000: episode: 13577, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000342, mae: 0.011524, mean_q: 0.019131
 97589/100000: episode: 13578, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000629, mae: 0.013580, mean_q: 0.020146
 97599/100000: episode: 13579, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000823, mae: 0.014354, mean_q: 0.017942
 97609/100000: episode: 13580, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000556, mae: 0.013079, mean_q: 0.018345
 97619/100000: episode: 13581, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000935, mae: 0.014678, mean_q: 0.027278
 97629/100000: episode: 13582, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000555, mae: 0.014945, mean_q: 0.020310
 97639/100000: episode: 13583, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000358, mae: 0.012613, mean_q: 0.017415
 97649/100000: episode: 13584, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000687, mae: 0.013220, mean_q: 0.018600
 97659/100000: episode: 13585, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001370, mae: 0.016513, mean_q: 0.024905
 97669/100000: episode: 13586, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000952, mae: 0.017727, mean_q: 0.019474
 97679/100000: episode: 13587, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000300, mae: 0.014044, mean_q: 0.014039
 97689/100000: episode: 13588, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000520, mae: 0.013965, mean_q: 0.018513
 97699/100000: episode: 13589, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000484, mae: 0.015065, mean_q: 0.020851
 97709/100000: episode: 13590, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000565, mae: 0.014169, mean_q: 0.016702
 97719/100000: episode: 13591, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000271, mae: 0.010857, mean_q: 0.015122
 97729/100000: episode: 13592, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000969, mae: 0.016929, mean_q: 0.026123
 97739/100000: episode: 13593, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000344, mae: 0.013107, mean_q: 0.022163
 97749/100000: episode: 13594, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000330, mae: 0.012852, mean_q: 0.016903
 97759/100000: episode: 13595, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000261, mae: 0.010815, mean_q: 0.015597
 97769/100000: episode: 13596, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000683, mae: 0.012600, mean_q: 0.016522
 97779/100000: episode: 13597, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000707, mae: 0.014411, mean_q: 0.024996
 97789/100000: episode: 13598, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000185, mae: 0.012309, mean_q: 0.016423
 97799/100000: episode: 13599, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000665, mae: 0.015876, mean_q: 0.021778
 97809/100000: episode: 13600, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000663, mae: 0.015769, mean_q: 0.025089
 97819/100000: episode: 13601, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000502, mae: 0.013152, mean_q: 0.018505
 97829/100000: episode: 13602, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000203, mae: 0.011969, mean_q: 0.016772
 97839/100000: episode: 13603, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000268, mae: 0.010560, mean_q: 0.015596
 97849/100000: episode: 13604, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000838, mae: 0.013599, mean_q: 0.025228
 97859/100000: episode: 13605, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000289, mae: 0.010464, mean_q: 0.017913
 97869/100000: episode: 13606, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000241, mae: 0.009632, mean_q: 0.017365
 97879/100000: episode: 13607, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000588, mae: 0.012635, mean_q: 0.017592
 97889/100000: episode: 13608, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000805, mae: 0.014264, mean_q: 0.021168
 97899/100000: episode: 13609, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000430, mae: 0.013469, mean_q: 0.016944
 97909/100000: episode: 13610, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000332, mae: 0.012122, mean_q: 0.018196
 97919/100000: episode: 13611, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000360, mae: 0.010934, mean_q: 0.015152
 97929/100000: episode: 13612, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000842, mae: 0.016084, mean_q: 0.027641
 97939/100000: episode: 13613, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000312, mae: 0.010368, mean_q: 0.015883
 97949/100000: episode: 13614, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000525, mae: 0.013728, mean_q: 0.017918
 97959/100000: episode: 13615, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000609, mae: 0.016082, mean_q: 0.015469
 97969/100000: episode: 13616, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000394, mae: 0.016916, mean_q: 0.020234
 97979/100000: episode: 13617, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000592, mae: 0.015492, mean_q: 0.026201
 97989/100000: episode: 13618, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000195, mae: 0.010024, mean_q: 0.014993
 97999/100000: episode: 13619, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000498, mae: 0.012064, mean_q: 0.018639
 98009/100000: episode: 13620, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000975, mae: 0.014611, mean_q: 0.018842
 98019/100000: episode: 13621, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000555, mae: 0.013993, mean_q: 0.022463
 98029/100000: episode: 13622, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000568, mae: 0.016924, mean_q: 0.024952
 98039/100000: episode: 13623, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000196, mae: 0.011920, mean_q: 0.016587
 98049/100000: episode: 13624, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000381, mae: 0.014462, mean_q: 0.018402
 98059/100000: episode: 13625, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000490, mae: 0.013883, mean_q: 0.019808
 98069/100000: episode: 13626, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000858, mae: 0.014569, mean_q: 0.021148
 98079/100000: episode: 13627, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000228, mae: 0.010908, mean_q: 0.015959
 98089/100000: episode: 13628, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000207, mae: 0.009707, mean_q: 0.014198
 98099/100000: episode: 13629, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000483, mae: 0.010903, mean_q: 0.016126
 98109/100000: episode: 13630, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000286, mae: 0.011077, mean_q: 0.020395
 98119/100000: episode: 13631, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000189, mae: 0.008882, mean_q: 0.012639
 98129/100000: episode: 13632, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000264, mae: 0.010392, mean_q: 0.015042
 98139/100000: episode: 13633, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000471, mae: 0.012388, mean_q: 0.020245
 98149/100000: episode: 13634, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000155, mae: 0.008679, mean_q: 0.012585
 98159/100000: episode: 13635, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000319, mae: 0.010633, mean_q: 0.017833
 98169/100000: episode: 13636, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000401, mae: 0.011173, mean_q: 0.021557
 98179/100000: episode: 13637, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000217, mae: 0.009253, mean_q: 0.014884
 98189/100000: episode: 13638, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000169, mae: 0.008864, mean_q: 0.012199
 98199/100000: episode: 13639, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000385, mae: 0.008921, mean_q: 0.011713
 98209/100000: episode: 13640, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000384, mae: 0.011628, mean_q: 0.018795
 98219/100000: episode: 13641, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000376, mae: 0.010128, mean_q: 0.015331
 98229/100000: episode: 13642, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000419, mae: 0.011442, mean_q: 0.016898
 98239/100000: episode: 13643, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000432, mae: 0.012627, mean_q: 0.019869
 98249/100000: episode: 13644, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000636, mae: 0.012007, mean_q: 0.018453
 98259/100000: episode: 13645, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000139, mae: 0.008242, mean_q: 0.011264
 98269/100000: episode: 13646, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000678, mae: 0.012807, mean_q: 0.023940
 98279/100000: episode: 13647, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000498, mae: 0.009925, mean_q: 0.015568
 98289/100000: episode: 13648, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000162, mae: 0.008717, mean_q: 0.014289
 98299/100000: episode: 13649, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000202, mae: 0.011507, mean_q: 0.014473
 98309/100000: episode: 13650, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000679, mae: 0.012000, mean_q: 0.016069
 98319/100000: episode: 13651, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000457, mae: 0.012034, mean_q: 0.019219
 98329/100000: episode: 13652, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000549, mae: 0.011232, mean_q: 0.014542
 98339/100000: episode: 13653, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000477, mae: 0.010146, mean_q: 0.014096
[Info] 1-TH LEVEL FOUND: 0.02099350094795227, Considering 13/100 traces
 98349/100000: episode: 13654, duration: 0.942s, episode steps: 10, steps per second: 11, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000308, mae: 0.010176, mean_q: 0.015325
 98356/100000: episode: 13655, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000704, mae: 0.012912, mean_q: 0.012257
 98363/100000: episode: 13656, duration: 0.035s, episode steps: 7, steps per second: 201, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000280, mae: 0.010811, mean_q: 0.016516
 98369/100000: episode: 13657, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000641, mae: 0.011627, mean_q: 0.017739
 98375/100000: episode: 13658, duration: 0.031s, episode steps: 6, steps per second: 192, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000370, mae: 0.010817, mean_q: 0.015471
 98381/100000: episode: 13659, duration: 0.032s, episode steps: 6, steps per second: 190, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000234, mae: 0.011090, mean_q: 0.013723
 98387/100000: episode: 13660, duration: 0.033s, episode steps: 6, steps per second: 183, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000464, mae: 0.014381, mean_q: 0.020903
 98393/100000: episode: 13661, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001046, mae: 0.015646, mean_q: 0.024457
 98399/100000: episode: 13662, duration: 0.030s, episode steps: 6, steps per second: 203, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000909, mae: 0.016346, mean_q: 0.023272
 98406/100000: episode: 13663, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000223, mae: 0.012724, mean_q: 0.015710
 98413/100000: episode: 13664, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.001305, mae: 0.015916, mean_q: 0.019595
[Info] FALSIFICATION!
 98419/100000: episode: 13665, duration: 0.287s, episode steps: 6, steps per second: 21, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000623, mae: 0.014967, mean_q: 0.015741
 98425/100000: episode: 13666, duration: 0.032s, episode steps: 6, steps per second: 190, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000313, mae: 0.011452, mean_q: 0.015152
 98431/100000: episode: 13667, duration: 0.042s, episode steps: 6, steps per second: 142, episode reward: 0.077, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000113, mae: 0.009168, mean_q: 0.008188
 98438/100000: episode: 13668, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000327, mae: 0.010351, mean_q: 0.018521
 98445/100000: episode: 13669, duration: 0.037s, episode steps: 7, steps per second: 189, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000785, mae: 0.012488, mean_q: 0.015918
 98451/100000: episode: 13670, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000183, mae: 0.011086, mean_q: 0.015318
 98457/100000: episode: 13671, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000554, mae: 0.011783, mean_q: 0.022363
 98464/100000: episode: 13672, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000172, mae: 0.008261, mean_q: 0.014725
 98470/100000: episode: 13673, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000193, mae: 0.008760, mean_q: 0.015096
 98477/100000: episode: 13674, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000090, mae: 0.008326, mean_q: 0.014872
 98484/100000: episode: 13675, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000072, mae: 0.006999, mean_q: 0.013758
 98491/100000: episode: 13676, duration: 0.036s, episode steps: 7, steps per second: 195, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000374, mae: 0.010473, mean_q: 0.012704
 98497/100000: episode: 13677, duration: 0.043s, episode steps: 6, steps per second: 138, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000059, mae: 0.006866, mean_q: 0.010579
 98503/100000: episode: 13678, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.034, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000230, mae: 0.010314, mean_q: 0.020694
 98510/100000: episode: 13679, duration: 0.038s, episode steps: 7, steps per second: 182, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000204, mae: 0.010689, mean_q: 0.013890
 98516/100000: episode: 13680, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000061, mae: 0.007484, mean_q: 0.005818
 98523/100000: episode: 13681, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000160, mae: 0.009577, mean_q: 0.010246
 98529/100000: episode: 13682, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.030, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000514, mae: 0.012630, mean_q: 0.017474
 98535/100000: episode: 13683, duration: 0.035s, episode steps: 6, steps per second: 172, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000437, mae: 0.012690, mean_q: 0.021788
 98541/100000: episode: 13684, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000276, mae: 0.009803, mean_q: 0.013598
 98548/100000: episode: 13685, duration: 0.062s, episode steps: 7, steps per second: 112, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000437, mae: 0.011226, mean_q: 0.017172
 98554/100000: episode: 13686, duration: 0.069s, episode steps: 6, steps per second: 87, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000120, mae: 0.009164, mean_q: 0.013852
 98561/100000: episode: 13687, duration: 0.067s, episode steps: 7, steps per second: 105, episode reward: 1.947, mean reward: 0.278 [0.007, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 7.857 [5.000, 11.000], loss: 0.000125, mae: 0.008752, mean_q: 0.013593
 98567/100000: episode: 13688, duration: 0.046s, episode steps: 6, steps per second: 129, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000470, mae: 0.013038, mean_q: 0.022683
 98573/100000: episode: 13689, duration: 0.036s, episode steps: 6, steps per second: 168, episode reward: 0.010, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.417 [-1.000, 11.000], loss: 0.000186, mae: 0.010253, mean_q: 0.011302
 98580/100000: episode: 13690, duration: 0.045s, episode steps: 7, steps per second: 156, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000779, mae: 0.013113, mean_q: 0.020662
 98586/100000: episode: 13691, duration: 0.034s, episode steps: 6, steps per second: 178, episode reward: 0.010, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.417 [-1.000, 11.000], loss: 0.000456, mae: 0.011680, mean_q: 0.022809
 98593/100000: episode: 13692, duration: 0.038s, episode steps: 7, steps per second: 183, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000363, mae: 0.012455, mean_q: 0.011118
 98599/100000: episode: 13693, duration: 0.035s, episode steps: 6, steps per second: 171, episode reward: 0.023, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000203, mae: 0.010284, mean_q: 0.021440
 98605/100000: episode: 13694, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.077, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000094, mae: 0.008329, mean_q: 0.010721
 98611/100000: episode: 13695, duration: 0.073s, episode steps: 6, steps per second: 83, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000453, mae: 0.009333, mean_q: 0.018831
 98617/100000: episode: 13696, duration: 0.053s, episode steps: 6, steps per second: 113, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000228, mae: 0.008779, mean_q: 0.018883
 98624/100000: episode: 13697, duration: 0.037s, episode steps: 7, steps per second: 190, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000822, mae: 0.015126, mean_q: 0.020190
 98630/100000: episode: 13698, duration: 0.032s, episode steps: 6, steps per second: 185, episode reward: 0.010, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.417 [-1.000, 11.000], loss: 0.000255, mae: 0.012568, mean_q: 0.015535
 98636/100000: episode: 13699, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000088, mae: 0.008393, mean_q: 0.010148
 98642/100000: episode: 13700, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.010, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.417 [-1.000, 11.000], loss: 0.000209, mae: 0.009657, mean_q: 0.015864
 98648/100000: episode: 13701, duration: 0.032s, episode steps: 6, steps per second: 189, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000259, mae: 0.011172, mean_q: 0.019751
 98655/100000: episode: 13702, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000823, mae: 0.013392, mean_q: 0.019903
 98661/100000: episode: 13703, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.010, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.417 [-1.000, 11.000], loss: 0.000288, mae: 0.012351, mean_q: 0.017184
 98668/100000: episode: 13704, duration: 0.048s, episode steps: 7, steps per second: 147, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000866, mae: 0.016046, mean_q: 0.022340
 98675/100000: episode: 13705, duration: 0.076s, episode steps: 7, steps per second: 92, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000988, mae: 0.014608, mean_q: 0.018310
 98682/100000: episode: 13706, duration: 0.043s, episode steps: 7, steps per second: 164, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000197, mae: 0.011566, mean_q: 0.010847
 98689/100000: episode: 13707, duration: 0.038s, episode steps: 7, steps per second: 183, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000191, mae: 0.010591, mean_q: 0.019515
 98695/100000: episode: 13708, duration: 0.033s, episode steps: 6, steps per second: 184, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000276, mae: 0.009478, mean_q: 0.014427
 98701/100000: episode: 13709, duration: 0.032s, episode steps: 6, steps per second: 189, episode reward: 0.030, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000156, mae: 0.009906, mean_q: 0.031017
 98708/100000: episode: 13710, duration: 0.037s, episode steps: 7, steps per second: 191, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000113, mae: 0.008889, mean_q: 0.012185
 98714/100000: episode: 13711, duration: 0.039s, episode steps: 6, steps per second: 155, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000116, mae: 0.008396, mean_q: 0.012370
 98721/100000: episode: 13712, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000138, mae: 0.008405, mean_q: 0.016166
 98727/100000: episode: 13713, duration: 0.032s, episode steps: 6, steps per second: 190, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000143, mae: 0.009765, mean_q: 0.023849
[Info] FALSIFICATION!
 98733/100000: episode: 13714, duration: 0.401s, episode steps: 6, steps per second: 15, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000535, mae: 0.013069, mean_q: 0.017267
 98739/100000: episode: 13715, duration: 0.046s, episode steps: 6, steps per second: 130, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000218, mae: 0.013434, mean_q: 0.025990
 98745/100000: episode: 13716, duration: 0.049s, episode steps: 6, steps per second: 123, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000289, mae: 0.010628, mean_q: 0.020626
 98751/100000: episode: 13717, duration: 0.038s, episode steps: 6, steps per second: 156, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000925, mae: 0.015549, mean_q: 0.031557
 98758/100000: episode: 13718, duration: 0.052s, episode steps: 7, steps per second: 134, episode reward: 0.175, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000422, mae: 0.015130, mean_q: 0.013207
 98765/100000: episode: 13719, duration: 0.061s, episode steps: 7, steps per second: 114, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000359, mae: 0.011947, mean_q: 0.012024
 98771/100000: episode: 13720, duration: 0.036s, episode steps: 6, steps per second: 167, episode reward: 0.077, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000291, mae: 0.012478, mean_q: 0.015303
 98777/100000: episode: 13721, duration: 0.032s, episode steps: 6, steps per second: 190, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000456, mae: 0.012395, mean_q: 0.020176
 98783/100000: episode: 13722, duration: 0.032s, episode steps: 6, steps per second: 190, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000243, mae: 0.010744, mean_q: 0.011227
 98790/100000: episode: 13723, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000093, mae: 0.008781, mean_q: 0.008998
 98796/100000: episode: 13724, duration: 0.030s, episode steps: 6, steps per second: 198, episode reward: 0.077, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000246, mae: 0.010454, mean_q: 0.014451
 98802/100000: episode: 13725, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000434, mae: 0.011200, mean_q: 0.027284
 98808/100000: episode: 13726, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000261, mae: 0.010113, mean_q: 0.015502
 98815/100000: episode: 13727, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000157, mae: 0.009546, mean_q: 0.017735
 98821/100000: episode: 13728, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.014, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000297, mae: 0.011020, mean_q: 0.017154
 98827/100000: episode: 13729, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000295, mae: 0.010114, mean_q: 0.013896
 98833/100000: episode: 13730, duration: 0.032s, episode steps: 6, steps per second: 190, episode reward: 0.077, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000132, mae: 0.008283, mean_q: 0.017118
 98839/100000: episode: 13731, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000086, mae: 0.008059, mean_q: 0.012481
 98845/100000: episode: 13732, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000285, mae: 0.010544, mean_q: 0.023194
 98851/100000: episode: 13733, duration: 0.031s, episode steps: 6, steps per second: 193, episode reward: 0.046, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000561, mae: 0.012321, mean_q: 0.029269
 98857/100000: episode: 13734, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001124, mae: 0.012672, mean_q: 0.018831
 98864/100000: episode: 13735, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000307, mae: 0.010322, mean_q: 0.016095
 98870/100000: episode: 13736, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.023, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000421, mae: 0.011187, mean_q: 0.019696
 98876/100000: episode: 13737, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.023, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000129, mae: 0.008615, mean_q: 0.014833
 98882/100000: episode: 13738, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000990, mae: 0.016742, mean_q: 0.026091
 98889/100000: episode: 13739, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000177, mae: 0.011138, mean_q: 0.015753
 98895/100000: episode: 13740, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000499, mae: 0.012045, mean_q: 0.016630
[Info] Complete ISplit Iteration
[Info] Levels: [0.020993501, 1.1998985]
[Info] Cond. Prob: [0.13, 0.02]
[Info] Error Prob: 0.0026000000000000003

 98901/100000: episode: 13741, duration: 0.855s, episode steps: 6, steps per second: 7, episode reward: 0.018, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.583 [-1.000, 11.000], loss: 0.000950, mae: 0.017584, mean_q: 0.020261
 98911/100000: episode: 13742, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000197, mae: 0.011759, mean_q: 0.016141
 98921/100000: episode: 13743, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000297, mae: 0.010920, mean_q: 0.019006
 98931/100000: episode: 13744, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000207, mae: 0.010616, mean_q: 0.015059
 98941/100000: episode: 13745, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000397, mae: 0.012359, mean_q: 0.022035
 98951/100000: episode: 13746, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000194, mae: 0.009222, mean_q: 0.013485
 98961/100000: episode: 13747, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000284, mae: 0.010386, mean_q: 0.023294
 98971/100000: episode: 13748, duration: 0.098s, episode steps: 10, steps per second: 102, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000490, mae: 0.010697, mean_q: 0.024286
 98981/100000: episode: 13749, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000118, mae: 0.008734, mean_q: 0.013133
 98991/100000: episode: 13750, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000163, mae: 0.008603, mean_q: 0.015075
 99001/100000: episode: 13751, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000133, mae: 0.009413, mean_q: 0.017491
 99011/100000: episode: 13752, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000134, mae: 0.009358, mean_q: 0.013636
 99021/100000: episode: 13753, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000145, mae: 0.008989, mean_q: 0.013280
 99031/100000: episode: 13754, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000161, mae: 0.009116, mean_q: 0.017647
 99041/100000: episode: 13755, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000630, mae: 0.012542, mean_q: 0.023517
 99051/100000: episode: 13756, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000249, mae: 0.010754, mean_q: 0.016249
 99061/100000: episode: 13757, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000633, mae: 0.010886, mean_q: 0.019810
 99071/100000: episode: 13758, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000684, mae: 0.012115, mean_q: 0.022057
 99081/100000: episode: 13759, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000882, mae: 0.012370, mean_q: 0.017789
 99091/100000: episode: 13760, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000459, mae: 0.011097, mean_q: 0.015378
 99101/100000: episode: 13761, duration: 0.107s, episode steps: 10, steps per second: 94, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000910, mae: 0.013320, mean_q: 0.020538
 99111/100000: episode: 13762, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000915, mae: 0.017508, mean_q: 0.018163
 99121/100000: episode: 13763, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000810, mae: 0.015610, mean_q: 0.019773
 99131/100000: episode: 13764, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000215, mae: 0.012848, mean_q: 0.016020
 99141/100000: episode: 13765, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000523, mae: 0.014809, mean_q: 0.027278
 99151/100000: episode: 13766, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000458, mae: 0.013015, mean_q: 0.023520
 99161/100000: episode: 13767, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000614, mae: 0.011731, mean_q: 0.015713
 99171/100000: episode: 13768, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000303, mae: 0.012969, mean_q: 0.021701
 99181/100000: episode: 13769, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000531, mae: 0.013809, mean_q: 0.021548
 99191/100000: episode: 13770, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000230, mae: 0.013077, mean_q: 0.017623
 99201/100000: episode: 13771, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000376, mae: 0.014680, mean_q: 0.022765
 99211/100000: episode: 13772, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000751, mae: 0.012569, mean_q: 0.013244
 99221/100000: episode: 13773, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000152, mae: 0.009840, mean_q: 0.012036
 99231/100000: episode: 13774, duration: 0.078s, episode steps: 10, steps per second: 127, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000398, mae: 0.011973, mean_q: 0.020007
 99241/100000: episode: 13775, duration: 0.103s, episode steps: 10, steps per second: 97, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000446, mae: 0.013313, mean_q: 0.020213
 99251/100000: episode: 13776, duration: 0.055s, episode steps: 10, steps per second: 180, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000722, mae: 0.012326, mean_q: 0.017879
 99261/100000: episode: 13777, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000241, mae: 0.011224, mean_q: 0.015768
 99271/100000: episode: 13778, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000579, mae: 0.012376, mean_q: 0.021794
 99281/100000: episode: 13779, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000335, mae: 0.011490, mean_q: 0.019901
 99291/100000: episode: 13780, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000302, mae: 0.009901, mean_q: 0.019395
 99301/100000: episode: 13781, duration: 0.117s, episode steps: 10, steps per second: 86, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000937, mae: 0.013317, mean_q: 0.018988
 99311/100000: episode: 13782, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000398, mae: 0.013809, mean_q: 0.020368
 99321/100000: episode: 13783, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000230, mae: 0.009799, mean_q: 0.017575
 99331/100000: episode: 13784, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000181, mae: 0.008672, mean_q: 0.015582
 99341/100000: episode: 13785, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000854, mae: 0.011313, mean_q: 0.022900
 99351/100000: episode: 13786, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000334, mae: 0.013645, mean_q: 0.014693
 99361/100000: episode: 13787, duration: 0.104s, episode steps: 10, steps per second: 97, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000441, mae: 0.011812, mean_q: 0.019184
 99371/100000: episode: 13788, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000157, mae: 0.010447, mean_q: 0.016105
 99381/100000: episode: 13789, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000123, mae: 0.008291, mean_q: 0.025382
 99391/100000: episode: 13790, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000134, mae: 0.009381, mean_q: 0.015439
 99401/100000: episode: 13791, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001276, mae: 0.016439, mean_q: 0.026196
 99411/100000: episode: 13792, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000236, mae: 0.009524, mean_q: 0.014701
 99421/100000: episode: 13793, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000844, mae: 0.013814, mean_q: 0.022333
 99431/100000: episode: 13794, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000720, mae: 0.013494, mean_q: 0.017366
 99441/100000: episode: 13795, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000156, mae: 0.008613, mean_q: 0.011020
 99451/100000: episode: 13796, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000340, mae: 0.009971, mean_q: 0.017217
 99461/100000: episode: 13797, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000360, mae: 0.010442, mean_q: 0.014355
 99471/100000: episode: 13798, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000274, mae: 0.010613, mean_q: 0.015463
 99481/100000: episode: 13799, duration: 0.126s, episode steps: 10, steps per second: 80, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000411, mae: 0.011271, mean_q: 0.017874
 99491/100000: episode: 13800, duration: 0.069s, episode steps: 10, steps per second: 146, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000578, mae: 0.013294, mean_q: 0.022550
 99501/100000: episode: 13801, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000264, mae: 0.010577, mean_q: 0.016763
 99511/100000: episode: 13802, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000363, mae: 0.010875, mean_q: 0.020006
 99521/100000: episode: 13803, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000290, mae: 0.013168, mean_q: 0.017159
 99531/100000: episode: 13804, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000152, mae: 0.010439, mean_q: 0.016584
 99541/100000: episode: 13805, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000126, mae: 0.009259, mean_q: 0.015117
 99551/100000: episode: 13806, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000791, mae: 0.013022, mean_q: 0.024295
 99561/100000: episode: 13807, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000175, mae: 0.010648, mean_q: 0.015885
 99571/100000: episode: 13808, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000784, mae: 0.015037, mean_q: 0.024525
 99581/100000: episode: 13809, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000477, mae: 0.012282, mean_q: 0.016827
 99591/100000: episode: 13810, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000323, mae: 0.012004, mean_q: 0.020515
 99601/100000: episode: 13811, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000173, mae: 0.009802, mean_q: 0.016985
 99611/100000: episode: 13812, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001073, mae: 0.014282, mean_q: 0.025148
 99621/100000: episode: 13813, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000239, mae: 0.011719, mean_q: 0.011416
 99631/100000: episode: 13814, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000427, mae: 0.011982, mean_q: 0.016024
 99641/100000: episode: 13815, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000264, mae: 0.009646, mean_q: 0.016178
 99651/100000: episode: 13816, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001147, mae: 0.017606, mean_q: 0.016535
 99661/100000: episode: 13817, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000392, mae: 0.013230, mean_q: 0.020802
 99671/100000: episode: 13818, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000154, mae: 0.009109, mean_q: 0.013689
 99681/100000: episode: 13819, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000334, mae: 0.009834, mean_q: 0.013445
 99691/100000: episode: 13820, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000149, mae: 0.008539, mean_q: 0.011779
 99701/100000: episode: 13821, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000405, mae: 0.010514, mean_q: 0.015960
 99711/100000: episode: 13822, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000316, mae: 0.011392, mean_q: 0.029630
 99721/100000: episode: 13823, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000177, mae: 0.009547, mean_q: 0.017374
 99731/100000: episode: 13824, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000338, mae: 0.011340, mean_q: 0.016132
 99741/100000: episode: 13825, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000141, mae: 0.008630, mean_q: 0.015380
 99751/100000: episode: 13826, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000213, mae: 0.008484, mean_q: 0.014197
 99761/100000: episode: 13827, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000140, mae: 0.007950, mean_q: 0.018535
 99771/100000: episode: 13828, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000158, mae: 0.009262, mean_q: 0.016391
 99781/100000: episode: 13829, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000087, mae: 0.007456, mean_q: 0.020173
 99791/100000: episode: 13830, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000990, mae: 0.013660, mean_q: 0.020605
 99801/100000: episode: 13831, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000905, mae: 0.013403, mean_q: 0.018782
 99811/100000: episode: 13832, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000196, mae: 0.008440, mean_q: 0.014878
 99821/100000: episode: 13833, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000104, mae: 0.007083, mean_q: 0.016903
 99831/100000: episode: 13834, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000160, mae: 0.007905, mean_q: 0.013270
 99841/100000: episode: 13835, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000126, mae: 0.009803, mean_q: 0.012546
 99851/100000: episode: 13836, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000094, mae: 0.007739, mean_q: 0.010452
 99861/100000: episode: 13837, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000205, mae: 0.009585, mean_q: 0.016173
 99871/100000: episode: 13838, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001068, mae: 0.013174, mean_q: 0.016020
 99881/100000: episode: 13839, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000235, mae: 0.012928, mean_q: 0.014717
 99891/100000: episode: 13840, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000285, mae: 0.013587, mean_q: 0.013116
[Info] 1-TH LEVEL FOUND: 0.033400386571884155, Considering 10/100 traces
 99901/100000: episode: 13841, duration: 1.046s, episode steps: 10, steps per second: 10, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000156, mae: 0.011155, mean_q: 0.014494
 99906/100000: episode: 13842, duration: 0.040s, episode steps: 5, steps per second: 126, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000140, mae: 0.010401, mean_q: 0.017013
 99911/100000: episode: 13843, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000158, mae: 0.009525, mean_q: 0.016661
 99918/100000: episode: 13844, duration: 0.046s, episode steps: 7, steps per second: 151, episode reward: 0.112, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000910, mae: 0.011968, mean_q: 0.018361
 99923/100000: episode: 13845, duration: 0.038s, episode steps: 5, steps per second: 132, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000101, mae: 0.007873, mean_q: 0.008274
 99928/100000: episode: 13846, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000105, mae: 0.010132, mean_q: 0.012895
[Info] FALSIFICATION!
 99934/100000: episode: 13847, duration: 0.299s, episode steps: 6, steps per second: 20, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000801, mae: 0.011578, mean_q: 0.022771
 99939/100000: episode: 13848, duration: 0.035s, episode steps: 5, steps per second: 141, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000388, mae: 0.011443, mean_q: 0.017635
 99946/100000: episode: 13849, duration: 0.051s, episode steps: 7, steps per second: 137, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000116, mae: 0.008479, mean_q: 0.012836
 99953/100000: episode: 13850, duration: 0.059s, episode steps: 7, steps per second: 119, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000634, mae: 0.010002, mean_q: 0.013681
 99960/100000: episode: 13851, duration: 0.048s, episode steps: 7, steps per second: 145, episode reward: 0.034, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000145, mae: 0.008512, mean_q: 0.017444
 99967/100000: episode: 13852, duration: 0.060s, episode steps: 7, steps per second: 116, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000104, mae: 0.007628, mean_q: 0.010845
 99974/100000: episode: 13853, duration: 0.047s, episode steps: 7, steps per second: 148, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000089, mae: 0.007789, mean_q: 0.010393
 99981/100000: episode: 13854, duration: 0.040s, episode steps: 7, steps per second: 177, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000339, mae: 0.008890, mean_q: 0.016782
 99986/100000: episode: 13855, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000103, mae: 0.007157, mean_q: 0.011255
 99991/100000: episode: 13856, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000118, mae: 0.008219, mean_q: 0.015086
 99996/100000: episode: 13857, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000200, mae: 0.009068, mean_q: 0.022505
done, took 728.152 seconds
[Info] End Importance Splitting. Falsification occurred 186 times.
